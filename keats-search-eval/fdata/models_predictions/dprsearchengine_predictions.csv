"query_id","question","answer","relevance_score","rank","model","id","doc_id","course_id","lecture_id"
"1","What is a log space transducer?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","71.04309844970703","1","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"1","What is a log space transducer?","So what we're going to do, because we're in place, basically we have to have an array storing our end items. That's sort of the definition of in-place, just using n slots of memory exactly the size of the number of items in our structure. But we're obviously not going to use a regular unsorted array or a regular sorted array. We're going to use array just as sort of the underlying technology for how things are stored. But we'd really like logarithmic performance, which should make you think tree. Only way to get a log is the binary tree, more or less. So somehow, we want to embed a tree into an array. Let me grab an example.","70.79942321777344","2","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_6_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"1","What is a log space transducer?"," 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Relationships among models 
Informal Defn: Two models of computation are polynomially related 
if each can simulate the other with a polynomial overhead: 
So ! "" time → !$("") time on the other model, for some '. 
All reasonable deterministic models are polynomially related. 
• 1-tape TMs 
• multi-tape TMs 
• multi-dimensional TMs 
• random access machine (RAM) 
• cellular automata 
9 
","70.65534210205078","3","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_9_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"1","What is a log space transducer?","to talk about in the word RAM. A side effect of this assumption that array access should take constant time, and that accessing these positions in my memory should take constant time, is that we need to assume w is at least log n or so. w, remember, is the machine word size. In real computers, this is currently 64-- or 256, in some bizarre instructions. But we don't usually think of the machine as getting bigger over time, but you should think of the machine as getting bigger over time. This is a statement that says, the word size has to grow with n. It might faster than log n, but it has to grow at least as fast as log n. Why do I say that? Because if I have n things that I'm dealing with-- n, here, is the problem size. Maybe it's the array I'm trying to store-- whatever. If I'm having to deal with n things in my memory, at the very least, I need to be able to address them. I should be able to say, give me the ith one and represent that number i in a word. Otherwise-- because the machine is designed to only work with w-bit words in constant time, they'll want to be able to access the ith word in constant time, I need a word size that's at least log n just to address that and n things in my input. So this is a totally reasonable assumption. It may seem weird because you think of a real machine as having constant size, but a real machine has constant size RAM, also. My machine has 24 gigs of RAM, or whatever. That laptop has 8. But you don't think of that as changing over time. But of course, if you want it to process a larger input, you would buy more RAM. So eventually, when our n's get really, really big, we're going to have to increase w just so we can address that RAM. That's the intuition here. But this is a way to bridge reality, which are fixed machines, with theory. In. Algorithms, we care about scalability for very large n. We want to know what that growth function is and ignore the lead constant factor. That's what asymptotic notation is all about. And for that, we need a notion of word size also changing in this asymptotic way. All right. That would be more important next week, when we talk about hashing and why hashing is a reasonable thing to do. But let's move on to dynamic sequences, which is where things get interesting. I have the update here. We start with static sequences. All of these operations are still something we want to support in a dynamic sequence, but we add two dynamic operations-- somewhat controversial operations, very exciting. I want to be able to insert in the middle of my sequence and I want to be able to delete from the middle of my sequence. Here's my sequence, which I'm going to think of in a picture. I'm going to draw it as an array. But it's stored however it's stored. We don't know. This is an interface, not an implementation. So we have x 0, x 1, x 2, x 3. And let's say I insert at position 2. Position 2 is here. So I come in with my new x, and I would like x to be the new x 2, but I don't want to lose any information. If I did set_at 2, then I would erase this and replace it with x. But I want to do insert_at, which means all of these guys, conceptually, are going to shift over by 1 in terms of their indices. Then, I would get this picture that's one bigger. And now I've got the new x. I've got what was the old x 2, which I don't-- I hesitate to call x 2 because that's its old name, not its new name. I'm going to draw arrows to say, these guys get copied over. These ones are definitely unchanged. Our new x 2, which prime is x This is x3 prime, 4 prime, and so on. I want to be careful here-- and of course, the new n prime is n plus 1. I want to be careful about the labeling, because the key-- what makes insert_at interesting is that, later, when I call get_at, it's with the new indexing. So previously, if I did get_at at 2, I would get this value. And afterwards, if I did get_at at 2, I would get the new value. If I did get_at at 3 down here, I would get the value that used to be X 2. That's maybe hard to track. But this is a conceptually very useful thing to do, especially when you're inserting or deleting at the ends. So we're going to define, in particular, insert and delete first and last. These are sometimes given-- if you have an insert, it has an x. If you do a delete, it has no argument. This means insert_at the beginning of the array, which would be like adding it here. And insert_last means adding it on here. insert_last doesn't change the indices of any of the old items. That's a nice feature of insert_last. Insert-first changes all of them. They all get incremented by 1. And we're also interested in the similar things here. We could do get-first or -last or set-first or -last, which are the obvious special cases of get_at and set_at. Now, these special cases are particularly interesting in an algorithms context. If you were a mathematician, you would say, well, why do I even bother? This is just shorthand for a particular call to get or set. But what makes it interesting from a data structures perspective is that we care about algorithms for supporting these operations. And maybe, the algorithm for supporting get-first or set-first, or in particular, insert-first or insert_last, might be more efficient. Maybe we can solve this problem better than we can solve insert_at. So while, ideally, we could solve the entire dynamic sequence interface constant time preparation, that's not actually possible. You can prove that. But special cases of it-- where we're just inserting and leading from the end, say-- we can do that. That's why it's interesting to introduce special cases that we care about. Cool. That's the definition of the dynamic sequence interface. Now, we're going to actually solve it.","70.54998779296875","4","DPRSearchEngine","CHhwJjR0mZA.en-j3PyPqV-e1s_4_mp4","CHhwJjR0mZA.en-j3PyPqV-e1s","6.006","2"
"1","What is a log space transducer?","That was a brief tour of computational geometry. I work mostly in four different areas of algorithms-- geometry, data structures, graph algorithms, and what I call recreational algorithms. I think I made up that term. And let's go into data structures, which is represented by this class, 6.851. All of the classes I mentioned have online video lectures, especially for those watching at home on OpenCourseWare. Most of these classes are on OpenCourseWare, and if not, they're on my webpage. 6.851, Advanced Data Structures, is an extension of the sorts of data structures you've seen here, in 006 and the ones you will see in 6.046. I thought I would give you a flavor of one such result, which is a problem we've seen in this class done better. Suppose you want to store a dynamic ordered set. This is the set interface. Dynamic in the sense that I have insert and delete, and ordered in the sense that I want to support find-next and find-previous. Exactly which subset of the set interface you choose influences what data structure you've seen. We've seen, for dynamic sets, you want to use hashing. If you don't care about find-next, if you just care about find, then hashing is great-- constant expected. You can prove stronger things about hashing. And we do in that class. But if you want dynamic and ordered, you cannot do constant time per operation. You can prove that, which is cool. What data structure have we seen that solves this problem pretty well? Set AVL trees, which solve everything in log n. So log n is one competitor. Yeah. I'm interested in the word RAM model, which is the only model we've seen in this class. This happens to work in a stronger model. And we can do better than log n in the following-- it will take me a while before I get better, but here's, at least, a different bound we can get-- log w. This is via a structure called van Emde Boas, who is a person. AVL is two people. van Emde Boas, I've actually met. Log w-- remember, w is our word size. So this is a bit of a weird running time. It's great if w is log n, then this is log log n. And we know w is at least log n, but it could be bigger. We don't really have a sense of how big w could get. Maybe it's even n. Maybe it's big-- and then these are the same. Maybe it's bigger than n, and then this is maybe worse. But for most ws, this is actually pretty good-- and indeed, optimal. But it's not strictly better, in any sense, yet. On the other hand, there's another data structure which runs in log n divided by log w. This is called fusion trees. This was invented around the time that cold fusion was in the news, and so they wanted data structures to represent. We can achieve this bound or we can achieve this bound. And this bound is good is if w is large. This band as good if w is small. You can always take the min of the two, whatever is better. And in particular, the min of those two things is at most-- I think it's square root log n over log log n. If you want to bound just in terms of n, then the crossover point between these two is this place. And so you're always, at most, this, which is quite a bit better than the log n of AVL. We've got a square root and we've got a slight thing in the denominator. Pretty tiny. But the big thing is the square root. And that's kind of cool. And it turns out, that's pretty much optimal. In terms of an n bound, this is optimal. The min of these two, in general, is roughly optimal up to log log terms. For fun, I threw up the actual formula for the right-bound, which is tight up to constant factors of matching upper and lower bounds, which we talk about. It's min of three things-- four things, including log of w over a divided by log of log w over a log of log n over a. That's the last term that I just read. This was messy. Surprisingly, that is the right answer for this very particular problem-- a very natural problem. AUDIENCE: What is a? ERIK DEMAINE: A is the log of the space you're using. So it's the address size. Good question. If you throw it-- so it depends. If you have a polynomial space data structure, then basically, these are optimal. And this is generalizing to beyond that. Maybe you have a little bit more than polynomial space. Cool. So that's data structures. I'm going to jump ahead to graph algorithms, which, if you want to take this class, I recommend a time travel device.","70.48223876953125","5","DPRSearchEngine","4nXw-f6NJ9s.en-j3PyPqV-e1s_4_mp4","4nXw-f6NJ9s.en-j3PyPqV-e1s","6.006","21"
"1","What is a log space transducer?","So what do we got we've got a CPU. It can address memory. What are the operations I can do in this CPU? Generally, I have binary operations. I can compare to words in memory, and I can either do integer arithmetic, logical operations, bitwise operations-- but we're not going to use those so much in this class. And I can write and write from an address in memory, a word in constant time. Those are the operations that I have available to me on most CPUs.","69.58297729492188","6","DPRSearchEngine","ZA-tUyM_y7s.en-j3PyPqV-e1s_10_mp4","ZA-tUyM_y7s.en-j3PyPqV-e1s","6.006","1"
"1","What is a log space transducer?","now, quickly is not so quick right now. Because everything is order h. And in the worst case, h is linear. Because we can have a tree like this. But today, we're going to make-- we're going to guarantee that h is log n. And so the goal of today is to take all of these operations that run in order h time and get them to run an order log n time, just by modifying the data structure we've already seen. So we've done a lot of the hard work, just a little bit more work we need to do today on something called","69.4947280883789","7","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_2_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"1","What is a log space transducer?","[SQUEAKING] [RUSTLING] [CLICKING] ERIK DEMAINE: All right. Welcome back to 006 and our dynamic programming quadruple of lectures. We are over halfway through, into lecture three of four. Today, we're going to follow up on this idea of problem constraints and expansion that was mentioned, especially, towards the end of last lecture. We saw an example of subproblem expansion by a factor of 2 in the two-player game with coins where we wanted to have two versions of the game, one where I go first and one where you go first. So this was expanding the number of such problems by a factor of 2. Today, we'll see a bunch more examples of this idea, including in one setting we've seen already, which is Bellman-Ford, which you can think of as a dynamic program. Maybe it's a good time to mention that Bellman invented dynamic programming in the '50s. Same Bellman in the Bellman-Ford algorithm. This was actually an independent discovery by both of them-- and other people. He invented dynamic programming, and then, a few years later, he applied it to solve the single-source shortest paths problem. We saw them in the other order. We saw single-source shortest paths first, because it was a little easier. And now we're seeing the general framework that this fits into.","69.05476379394531","8","DPRSearchEngine","TDo3r5M1LNo.en-j3PyPqV-e1s_1_mp4","TDo3r5M1LNo.en-j3PyPqV-e1s","6.006","17"
"1","What is a log space transducer?","And let's do our review. So we are-- in order to talk about space complexity classes that are smaller than n, we had to introduce a new model, which was the two-tape model, where there was a read-only tape that had the input on it, which you normally would think of something very large-- the whole internet, or something so big that you can't read it into your local memory. And then you have a work tape, which is your local memory. And the way we're going to think about it in the context of log space is that that work tape is logarithmic in the size of the input. And that is enough to have small counters or pointers into the input, because a reference location of the input is just-- you only need log n bits to do that. So we gave a couple of examples of the L and NL-- of L and NL languages, so this language of ww reverse, as you may remember. So here is an input in ww reverse. It's a string follow-- it's a palindromic string, which is of even length. And so you can make a machine in log space here that can test whether its input is of that form. And the work tape is only-- all it needs is a pointer into the-- or a couple of pointers that refer to the corresponding places of the input that you're looking at at the moment. So you maybe start out looking at the two outside a's and then the b symbols that are next to that. And you can write down on your tape where you're looking currently. And so that's going to be enough for you to-- you may have to zigzag, of course, back and forth a lot in order to do that test. But that's completely fine, using the model. We're not going to be measuring time. We're only going to be focusing on how much space we're using. Another example that we gave is the PATH language, where you're given a graph, and a start node, and a target node. And you want to know, is there a path in this directed graph that goes from s to t? And that's the language that's also-- that language is in NL-- in fact, not known to be in L. So the way that would look, shifting to an input in the PATH language, you would have a graph represented, say, by a sequence of edges, and a start, and a target. And the work tape would keep track of the current node. So the nondeterministic machine would guess a path that takes you from s to t, node by node. And the work tape would keep track of the current node. OK, so I hope you have this-- develop a little bit of an intuition for these classes, L and NL. We're going to be spending the entire lecture today talking about that. OK. So as I mentioned, the L and NL problem is an unsolved problem. And it's very much analogous to the P versus NP problem, except, as I mentioned, as we'll show, that NL and its complement end up being the same, which is not something that seems to be the case for NP, though we don't know. Can we think of this as a multi-head Turing machine? I'm getting a question about that, which is, I think, you can. In fact, that's an alternative way that people look at it. You can think of it as having multiple-- you know, a head basically needs log space to store the location-- to store the location of where that head would be. So if you imagine having several different heads on the input tape, you can think of a log space machine as being sort of a Turing machine that has multiple heads on the input table. It's equivalent. Good question.","68.82634735107422","9","DPRSearchEngine","q3xvno_KgRY.en-j3PyPqV-e1s_2_mp4","q3xvno_KgRY.en-j3PyPqV-e1s","18.404J","20"
"1","What is a log space transducer?","[SQUEAKING][RUSTLING][CLICKING] JASON KU: Welcome, everybody, to our lecture 14 of 6.006. This is our last lecture on graph algorithms, in particular, the last lecture we'll have on weighted shortest paths. But we're going to talk about a slightly different problem today, different than single source shortest paths. We're going to be talking about all-pairs shortest paths. But first, let's review our single source shortest paths algorithms. We had BFS, DAG relaxation, Dijkstra, which we saw last time, which gets pretty close to linear. V log V plus E is pretty close to linear. It's much closer to linear than the general algorithm we have for solving single source shortest paths, namely, Bellman-Ford, which is a little bit more like quadratic. This is like the difference between-- for sparse graphs, this is like the difference between sorting, using insertion sort and n squared, and merge sort in N log N, for example. We're going to get actually quite a big bonus for large input sizes by using Dijkstra when we can. Today, we're going to be focusing","68.81678771972656","10","DPRSearchEngine","EmSmaW-ud6A.en-j3PyPqV-e1s_1_mp4","EmSmaW-ud6A.en-j3PyPqV-e1s","6.006","14"
"2","What does it imply about two low-degree polynomials if they agree on more than d places?","And other very important thing-- if I have two polynomials that are both low-degree, they cannot agree on very many places. That follows from what I just proved above. Because what I'll do is I take those two polynomials, and they look at the difference, which is also a low-degree polynomial. Every time there's an agreement between those two original polynomials, there's a zero of the difference polynomial. And because that difference polynomial cannot have too many zeroes, the two original polynomials cannot have too many agreements. So the corollary is that if x and y are both polynomials of degree at most d, and they're not the same polynomial, because then the difference would be the 0 polynomial, then the number of places where they're equal is at most d. So the proof is just letting p be","79.50152587890625","1","DPRSearchEngine","7J1HD9rqEB4.en-j3PyPqV-e1s_5_mp4","7J1HD9rqEB4.en-j3PyPqV-e1s","18.404J","24"
"2","What does it imply about two low-degree polynomials if they agree on more than d places?"," 
 
 
 
 
Clustering  Is  an Optimization Problem  
§Why not divide variability by size of cluster? 
◦ Big and bad worse than small and bad 
§Is optimization problem finding a C that minimizes 
dissimilarity(C)? 
◦ No, otherwise could put each example in its own 
cluster 
§Need a constraint, e.g., 
◦ Minimum distance between clusters 
◦ Number of clusters 
6.0002  LECTURE 12 
4 
","71.58395385742188","2","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_4_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"2","What does it imply about two low-degree polynomials if they agree on more than d places?","So there's at most d roots out of the q possibilities. And the last thing I'm going to introduce here is the multivariable version of this which is called, perhaps somewhat unfairly, but it's called the Schwartz-Zippel lemma, though in various forms, it had been known prior to their work. In some cases, the literature actually goes back a long ways. But anyway, this is called the Schwartz-Zippel lemma. Doesn't really matter, except to the people whose credit is being denied. But that's not one of us. So anyway, the Schwartz-Zippel lemma says that if you have now a polynomial in several variables, which is not the 0 polynomial, where each variable has low degree-- so if I say if it has degree at most d in each xi. So each variable is going to have at most an exponent of d appearing in that polynomial. And now if we pick random values to assign to all of those n variables from the field, the probability that we ended up with a root, that we ended up with a 0, is something you can bound. So it's m times d, so the number of variables times this maximum degree, divided by the size of the field. And this is going to come up later for us. And this is another fairly simple proof, a little bit more sophisticated than the one that we had above. And in fact, it uses that one as a lemma to prove this theorem. So we're going to-- not going to prove any of that, but I refer you to the book if you're curious. Yeah, so a couple of good questions here. What happens if these values are bigger than q, for example? Then it's not telling you anything. If d is bigger than q, m is bigger than q, or the product is bigger than q, then you learn nothing from this lemma-- from this theorem. So typically in applications, you're going to pick a large-- you're going to have the flexibility. You get to choose q to be something that you want. So we're going to pick the field to be big enough so that the m and d are going to be relatively small. In fact, d is going to end up being 1, as we will see. And m is the number of variables. So we're going to pick q, which is going to be substantially larger than the number of variables. And how is the degree defined in multivariable polynomials? If the polynomial has xy squared plus 3x to the 5th y squared z, you just pull out each variable separately. And you look at the maximum degree of that variable. So the x in that case had had a degree 5 appearance. The y had a degree 2 appearance. So you take the maximum over all of the variables of the degree of that variable. And that's going to be the bound on the degree of the polynomial. So in fact, in our case, d is going to be 1. So all of the variables-- there's not going to be any exponents on anything. Everything is going to be exponent 1.","70.77022552490234","3","DPRSearchEngine","7J1HD9rqEB4.en-j3PyPqV-e1s_7_mp4","7J1HD9rqEB4.en-j3PyPqV-e1s","18.404J","24"
"2","What does it imply about two low-degree polynomials if they agree on more than d places?","I know you don't believe it, but it is because notice what it says, it says the r squared value for the line is horrible. It accounts for less than 0.05% of the data. You could say, OK, I can see that. I look at it. It does a lousy job. On the other hand, the quadratic is really pretty good. It's accounting for about 84% of the variability in the data. This is a nice high value. It's not one, but it's a nice high value. So this is now reinforcing what I already knew, but in a nice way. It's telling me that that r squared value tells me that the quadratic is a much better fit than the linear fit was. But then you say maybe, wait a minute. I could have done this by just comparing the fits themselves. I already saw that. Part of my goal is how do I know if I've got the best fit possible or not. So I'm going to do the same thing, but now I'm going to run it with another set of degrees. I'm going to go over here. I'm going to take exactly the same code. But let's try it with a quadratic, with a quartic, an order eight, and an order 16 fit. So I'm going to take different size polynomials. As a quick aside, this is why I want to use the PyLab kind of code because now I'm simply optimizing over a 16-dimensional space. Every point in that 16-dimensional space defines a 16th-degree polynomial. And I can still use linear regression, meaning walking down the gradient, to find the best solution. I'm going to run this. And I get out a set of values. Looks good. And let's go look at them.","70.71796417236328","4","DPRSearchEngine","vIFKGFl1Cn8.en-qlPKC2UN_YU_18_mp4","vIFKGFl1Cn8.en-qlPKC2UN_YU","6.0002","9"
"2","What does it imply about two low-degree polynomials if they agree on more than d places?"," 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
Issues with k-means  
§Choosing the “wrong” k can lead to strange results  
◦ Consider  k = 3 
§Result can depend upon initial centroids 
◦ Number  of iterations 
◦ Even final result 
◦ Greedy algorithm can find different local optimas 
6.0002  LECTURE 12 
18 
","70.04420471191406","5","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_18_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"2","What does it imply about two low-degree polynomials if they agree on more than d places?","found by combining optimal solutions to local subproblems. So for example, when x is greater than 1 we can solve fib x by solving fib x minus 1 and fib x minus 2 and adding those two things together. So there is optimal substructure-- you solve these two smaller problems independently of each other and then combine the solutions in a fast way. You also have to have something called overlapping subproblems. This is why the memo worked. Finding an optimal solution has to involve solving the same problem multiple times. Even if you have optimal substructure, if you don't see the same problem more than once-- creating a memo. Well, it'll work, you can still create the memo. You'll just never find anything in it when you look things up because you're solving each problem once. So you have to be solving the same problem multiple times and you have to be able to solve it by combining solutions to smaller problems. Now, we've seen things with optimal substructure before. In some sense, merge sort worked that way-- we were combining separate problems. Did merge sort have overlapping subproblems? No, because-- well, I guess, it might have if the list had the same element many, many times. But we would expect, mostly not. Because each time we're solving a different problem, because we have different lists that we're now sorting and merging. So it has half of it but not the other. Dynamic programming will not help us for sorting, cannot be used to improve merge sort. Oh, well, nothing is a silver bullet. What about the knapsack problem? Does it have these two properties? We can look at it in terms of these pictures. And it's pretty clear that it does have optimal substructure because we're taking the left branch and the right branch and choosing the winner. But what about overlapping subproblems? Are we ever solving, in this case, the same problem-- add two nodes? Well, do any of these nodes look identical? In this case, no. We could write a dynamic programming solution to the knapsack problem-- and we will-- and run it on this example, and we'd get the right answer. We would get zero speedup. Because at each node, if you can see, the problems are different. We have different things in the knapsack or different things to consider. Never do we have the same contents and the same things left to decide. So ""maybe"" was not a bad answer if that was the answer you gave to this question. But let's look at a different menu. This menu happens to have two beers in it. Now, if we look at what happens, do we see two nodes that are solving the same problem? The answer is what? Yes or no? I haven't drawn the whole tree here. Well, you'll notice the answer is yes.","70.02706909179688","6","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_11_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"2","What does it imply about two low-degree polynomials if they agree on more than d places?"," 
 
 
 
 
 
Mitigating Dependence on Initial Centroids  
Try multiple sets of randomly chosen initial centroids  
Select “best” result 
best = kMeans(points)  
for t in range(numTrials):  
C = kMeans(points)  
if dissimilarity(C) < dissimilarity(best):  
best = C  
return best  
6.0002  LECTURE 12 
22 
","69.6507568359375","7","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_22_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"2","What does it imply about two low-degree polynomials if they agree on more than d places?","3 
Lecture 17: Dyn. Prog. III 
All-Pairs Shortest Paths: Floyd–Warshall 
• Could deﬁne subproblems δk(u, v) = minimum weight of path from u to v using at most k 
edges, as in Bellman–Ford 
• Resulting running time is |V | times Bellman–Ford, i.e., O(|V |2 · |E|) = O(|V |4) 
• Know a better algorithm from L14: Johnson achieves O(|V |2 log |V | + |V | · |E|) = O(|V |3) 
• Can achieve Θ(|V |3) running time (matching Johnson for dense graphs) with a simple dy­
namic program, called Floyd–Warshall 
• Number vertices so that V = {1, 2, . . . , |V |} 
1. Subproblems 
• d(u, v, k) = minimum weight of a path from u to v that only uses vertices from 
{1, 2, . . . , k} ∪{u, v} 
• For u, v ∈ V and 1 ≤ k ≤|V | 
2. Relate 
• x(u, v, k) = min{x(u, k, k − 1) + x(k, v, k − 1), x(u, v, k − 1)} 
• Only constant branching! No longer guessing previous vertex/edge 
3. Topological order 
• Increasing k: relation depends only on smaller k 
4. Base 
• x(u, u, 0) = 0 
• x(u, v, 0) = w(u, v) if (u, v) ∈ E 
• x(u, v, 0) = ∞ if none of the above 
5. Original problem 
• x(u, v, |V |) for all u, v ∈ V 
6. Time 
• O(|V |3) subproblems 
• Each O(1) work 
• O(|V |3) in total 
• Constant number of dependencies per subproblem brings the factor of O(|E|) in the 
running time down to O(|V |). 
","69.43671417236328","8","DPRSearchEngine","665523227a175e9e9ce26ea8d3e5b51c_MIT6_006S20_lec17_3_pdf","665523227a175e9e9ce26ea8d3e5b51c_MIT6_006S20_lec17","6.006","17"
"2","What does it imply about two low-degree polynomials if they agree on more than d places?","And we can both eyeball it and look at the numbers. Eyeballing it, there's that green line, still generally following the form of this pretty well. What about the purple line? The order 16 degree. Remember, that's the purple line from model 1, from training set 1. Wow, this misses a bunch of points, pretty badly. And in fact, look at the r-squared values. Order 2 and order 4, pretty good fit, accounts for all but about 14, 13% of the data. Look what happened to the degree 16, degrees 16 fit. Way down at last. 0.7. Last time around it was 0.997. What about the other direction? Taking the model built and the second data set, testing it on the first data set. Again, notice a nice fit for degree 2 and 4, not so good for degree 16. And just to give you a sense of this, I'm going to go back. There is the model one case. There is the model in the other case. You can see the model that accounts for variation in one doesn't account for the variation in the other, when I look at order 16 fit. OK, so what this says is something important. Now I can see. In fact, if I look back at this, if I were just looking at the coefficient of determination, this says, in order to predict other behavior, I'm better off with an order 2 or maybe order 4 polynomial. Those r-squared values are both the same. I happen to know it's order 2, because that's where I generated from. But that's a whole lot better than order 16. And what you're seeing here is an example of something that happens a lot in statistics. And in fact, I would suggest is often misused in fitting data to statistical samples. It's called overfitting. And what it means is I've let there be too many degrees of freedom in my model, too many free parameters. And what it's fitting isn't just the underlying process. It's also fitting to the noise. The message I want you to take out of this part of the lecture is, if we only fit the model to training data, and we look at how well it does, we could get what looks like a great fit, but we may actually have come up with far too complex a model. Order 16 instead of order 2. And the only way you are likely to detect that is to train on one test set and test on a different. And if you do that, it's likely to expose whether, in fact, I have done a good job of fitting or whether I have overfit to the data. There are lots of horror stories in the literature, especially from early days of machine learning of people overfitting to data and coming up with models that they thought wonderfully predicted an effect, and then when it ran on new data really hit the big one. All right, so this is something you want to try and stay away from. And the best way to do it is to do validation.","69.21100616455078","9","DPRSearchEngine","fQvg-hh9dUw.en-qlPKC2UN_YU_12_mp4","fQvg-hh9dUw.en-qlPKC2UN_YU","6.0002","10"
"2","What does it imply about two low-degree polynomials if they agree on more than d places?","The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high-quality educational resources for free. To make a donation, or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. JOHN GUTTAG: I'm a little reluctant to say good afternoon, given the weather, but I'll say it anyway. I guess now we all do know that we live in Boston. And I should say, I hope none of you were affected too much by the fire yesterday in Cambridge, but that seems to have been a pretty disastrous event for some. Anyway, here's the reading. This is a chapter in the book on clustering, a topic that Professor Grimson introduced last week. And I'm going to try and finish up with respect to this course today, though not with respect to everything there is to know about clustering. Quickly just reviewing where we were. We're in the unit of a course on machine learning, and we always follow the same paradigm. We observe some set of examples, which we call the training data. We try and infer something about the process that created those examples. And then we use inference techniques, different kinds of techniques, to make predictions about previously unseen data. We call that the test data. As Professor Grimson said, you can think of two broad classes. Supervised, where we have a set of examples and some label associated with the example-- Democrat, Republican, smart, dumb, whatever you want to associate with them-- and then we try and infer the labels. Or unsupervised, where we're given a set of feature vectors without labels, and then we attempt to group them into natural clusters. That's going to be today's topic, clustering. So clustering is an optimization problem. As we'll see later, supervised machine learning is also an optimization problem. Clustering's a rather simple one. We're going to start first with the notion of variability. So this little c is a single cluster, and we're going to talk about the variability in that cluster of the sum of the distance between the mean of the cluster and each example in the cluster. And then we square it. OK? Pretty straightforward. For the moment, we can just assume that we're using Euclidean distance as our distance metric. Minkowski with p equals two. So variability should look pretty similar to something we've seen before, right? It's not quite variance, right, but it's very close. In a minute, we'll look at why it's different. And then we can look at the dissimilarity of a set of clusters, a group of clusters, which I'm writing as capital C, and that's just the sum of all the variabilities. Now, if I had divided variability by the size of the cluster, what would I have? Something we've seen before. What would that be? Somebody? Isn't that just the variance? So the question is, why am I not doing that? If up til now, we always wanted to talk about variance, why suddenly am I not doing it? Why do I define this notion of variability instead of good old variance? Any thoughts? What am I accomplishing by not dividing by the size of the cluster? Or what would happen if I did divide by the size of the cluster? Yes. AUDIENCE: You normalize it? JOHN GUTTAG: Absolutely. I'd normalize it. That's exactly what it would be doing. And what might be good or bad about normalizing it? What does it essentially mean to normalize? It means that the penalty for a big cluster with a lot of variance in it is no higher than the penalty of a tiny little cluster with a lot of variance in it. By not normalizing, what I'm saying is I want to penalize big, highly-diverse clusters more than small, highly-diverse clusters. OK? And if you think about it, that probably makes sense. Big and bad is worse than small and bad. All right, so now we define the objective function. And can we say that the optimization problem we want to solve by clustering is simply finding a capital C that minimizes dissimilarity? Is that a reasonable definition? Well, hint-- no. What foolish thing could we do that would optimize that objective function? Yeah. AUDIENCE: You could have the same number of clusters as points? JOHN GUTTAG: Yeah. I can have the same number of clusters as points, assign each point to its own cluster, whoops. Ooh, almost a relay. The dissimilarity of each cluster would be 0. The variability would be 0, so the dissimilarity would be 0, and I just solved the problem. Well, that's clearly not a very useful thing to do. So, well, what do you think we do to get around that? Yeah. AUDIENCE: We apply a constraint? JOHN GUTTAG: We apply a constraint. Exactly. And so we have to pick some constraint. What would be a suitable constraint, for example? Well, maybe we'd say, OK, the clusters have to have some minimum distance between them. Or-- and this is the constraint we'll be using today-- we could constrain the number of clusters. Say, all right, I only want to have at most five clusters. Do the best you can to minimize dissimilarity, but you're not allowed to use more than five clusters. That's the most common constraint that gets placed in the problem. All right, we're going to look at two algorithms. Maybe I should say two methods, because there are multiple implementations of these methods. The first is called hierarchical clustering, and the second is called k-means. There should be an S on the word mean there. Sorry about that. All right, let's look at hierarchical clustering first.","68.6865005493164","10","DPRSearchEngine","esmzYhuFnds.en-qlPKC2UN_YU_1_mp4","esmzYhuFnds.en-qlPKC2UN_YU","6.0002","12"
"5","What is the significance of TQBF in proving that PSPACE properly includes NL?"," 
 
  
  
 
 
 
 
 
 
 
 
 
 
   
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Recap: Separating Complexity Classes 
L ⊆ NL 
≠
⊆ P ⊆ NP ⊆ PSPACE 
Space Hierarchy Theorem 
NL ⊆ SPACE log& ' ⊆, SPACE ' ⊆ PSPACE 
12 
Check-in 21.3 
Consider these two famous unsolved questions: 
1. 
Does L = P? 
2. 
Does P = PSPACE? 
What do the hierarchy theorems tell us about 
these questions? 
a) Nothing 
b) At least one of these has answer “NO” 
c) 
At least one of these has answer “YES” 
Check-in 21.3 
","80.40800476074219","1","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_12_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"5","What is the significance of TQBF in proving that PSPACE properly includes NL?"," 
 
 
 
 
  
 
 
  
 
 
Quick review of today 
1. The Formula Game 
2. Generalized Geography is PSPACE-complete 
3. Log space: L and NL 
4. Configuration graph 
5. NL ⊆ P 
9 
","79.00697326660156","2","DPRSearchEngine","fd9c1b8656c7def498dcf662f6750d87_MIT18_404f20_lec19_9_pdf","fd9c1b8656c7def498dcf662f6750d87_MIT18_404f20_lec19","18.404J","19"
"5","What is the significance of TQBF in proving that PSPACE properly includes NL?","  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
  
  
 
 
     
 
  
 
 
  
 
 
 
 
  
 
 
 
 
  
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
NL = coNL (part 2/4) – key idea 
SIMPLIFIED!! 
Theorem:  If some NL-machine computes !, then some NL-machine computes ""#$ℎ. 
Proof: “On input 〈', ), $〉 where ' has + nodes 
1. Compute ! 
2. , ←0 
3. For each node / 
4
' 
4. 
Nondeterministically pick a path from ) of length ≤+. 
If it ends at $ then output YES and stop. 
) 
If it ends at /, set , ←, + 1. 
! = |4|
5.  If , ≠! then reject. 
6. Output NO.” [found all ! reachable nodes and none were $} 
4 
","78.8555908203125","3","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_4_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"5","What is the significance of TQBF in proving that PSPACE properly includes NL?","  
 
 
 
 
 
 
 
 
 
 
  
 
  
 
  
  
 
 
     
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
NL = coNL (part 2/4) – key idea 
Theorem:  If some NL-machine computes !, then some NL-machine computes ""#$ℎ. 
Proof: “On input 〈', ), $〉 
1. Compute ! 
2. + ←0 
3. For each node . 
4. 
Nondeterministically go to (p) or (n) 
(p) Nondeterministically pick a path from ) to . of length ≤0. 
5
' 
If fail, then reject. 
)
If . = $, then output YES, else set + ←+ + 1. 
(n) Skip . and continue. 
! = |5|
5.  If + ≠! then reject. 
6. Output NO.” [found all ! reachable nodes and none were $} 
10 
","78.64268493652344","4","DPRSearchEngine","c9b742bd624556b45ac75ea2fb133b32_MIT18_404f20_lec20_10_pdf","c9b742bd624556b45ac75ea2fb133b32_MIT18_404f20_lec20","18.404J","20"
"5","What is the significance of TQBF in proving that PSPACE properly includes NL?","  
 
  
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
  
    
   
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
PSPACE
NL
)*+,
E 22
E #/
E #0
. . . 
. . . 
Review: Hierarchy Theorems 
Theorems: 
SPACE ! "" # 
⊆, SPACE "" # 
for space constructible "". 
TIME ! "" # / log "" # 
⊆, TIME "" # 
for time constructible "". 
TIM
SPACE 22 
TIM 
SPACE #/ SPACE #0 
TIM 
TIME #.
SPACE #. 
Check-in 22.1 
Which of these are known to be true? 
Check all that apply. 
(a) TIME 22 ⊆, TIME 2234 
TIME 2.2
Corollary: NL ⊆, PSPACE 
(b) TIME 22 ⊆, 
Implies )*+, ∉ NL because the polynomial-time reductions in 
(c) NTIME #. 
the proof that )*+, is PSPACE-complete can be done in log space. 
⊆, PSPACE 
(d) NP ⊆, PSPACE 
2 
Check-in 22.1 
","78.49596405029297","5","DPRSearchEngine","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_2_pdf","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22","18.404J","22"
"5","What is the significance of TQBF in proving that PSPACE properly includes NL?","  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
  
  
 
 
     
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
NL = coNL (part 2/4) – key idea 
Theorem:  If some NL-machine computes !, then some NL-machine computes ""#$ℎ. 
Proof: “On input 〈', ), $〉 where ' has + nodes 
1. Compute ! 
2. , ←0 
3. For each node / 
4. 
Nondeterministically go to (p) or (n) 
(p) Nondeterministically pick a path from ) to / of length ≤+. 
5
' 
If fail, then reject. 
)
If / = $, then output YES, else set , ←, + 1. 
(n) Skip / and continue. 
! = |5|
5.  If , ≠! then reject. 
6. Output NO.” [found all ! reachable nodes and none were $} 
3 
","78.34307861328125","6","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_3_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"5","What is the significance of TQBF in proving that PSPACE properly includes NL?","   
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
  
 
  
 
  
 
   
 
 
 
 
 
 
 
  
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
Review: NL ⊆ P 
Theorem: NL ⊆ P 
Proof: Say NTM "" decides # in space $ log ( . 
Defn: The configuration graph )*,, for "" on - has 
nodes: all configurations for "" on ­
edges: edge from ./ → .1 if ./ can yield .1 in 1 step. 
Claim: "" accepts - iff the configuration graph )*,, 
configuration graph )*,, 
.23453 
.466783 
iff "" accepts ­
has a path from .23453 to .466783 
Polynomial time algorithm 9 for #:
9 = “On input ­
1. Construct )*,,. [polynomial size] 
2. Accept if there is a path from .23453 to .466783. 
./ 
.1 
NL 
P 
Reject if not.” 
L = P? Unsolved 
L 
5 
","77.59626007080078","7","DPRSearchEngine","c9b742bd624556b45ac75ea2fb133b32_MIT18_404f20_lec20_5_pdf","c9b742bd624556b45ac75ea2fb133b32_MIT18_404f20_lec20","18.404J","20"
"5","What is the significance of TQBF in proving that PSPACE properly includes NL?","  
 
 
 
 
 
 
 
 
  
 
  
 
  
  
 
 
     
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
  
  
 
 
   
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
NL = coNL (part 3/4) 
YES, if ( has a path * to % of length ≤1 
Let #$%ℎ"" (, *, % = 8 NO, if not 
Let 6"" = 6"" (, * = / #$%ℎ"" (, *, / = YES} 
Let !"" = !"" (, * = |6""| 
Theorem:  If some NL-machine computes !"", then some NL-machine computes #$%ℎ"" . 
Proof: “On input 〈(, *, %〉 
1. Compute !"" 
(
2. , ←0 
3. For each node / 
4. 
Nondeterministically go to (p) or (n) 
!"" = |6""|
(p) Nondeterministically pick a path from * to / of length ≤1. 
If fail, then reject. 
If / = %, then output YES, else set , ←, + 1. 
(n) Skip / and continue. 
5.  If , ≠ !"" then reject. 
6. Output NO” [found all !"" reachable nodes and none were %} 
11 
6"" 
* 
","77.5166015625","8","DPRSearchEngine","c9b742bd624556b45ac75ea2fb133b32_MIT18_404f20_lec20_11_pdf","c9b742bd624556b45ac75ea2fb133b32_MIT18_404f20_lec20","18.404J","20"
"5","What is the significance of TQBF in proving that PSPACE properly includes NL?","  
 
 
 
 
 
 
 
 
  
 
  
 
  
  
 
 
     
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
  
  
 
 
   
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
NL = coNL (part 3/4) 
YES, if ( has a path * to % of length ≤1 
Let #$%ℎ"" (, *, % = 8 NO, if not 
Let 6"" = 6"" (, * = / #$%ℎ"" (, *, / = YES} 
Let !"" = !"" (, * = |6""| 
Theorem:  If some NL-machine computes !"", then some NL-machine computes #$%ℎ"" . 
Proof: “On input 〈(, *, %〉 
1. Compute !"" 
(
2. , ←0 
3. For each node / 
4. 
Nondeterministically go to (p) or (n) 
!"" = |6""|
(p) Nondeterministically pick a path from * to / of length ≤1. 
If fail, then reject. 
If / = %, then output YES, else set , ←, + 1. 
(n) Skip / and continue. 
5.  If , ≠ !"" then reject. 
6. Output NO” [found all !"" reachable nodes and none were %} 
5 
6"" 
* 
","77.51556396484375","9","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_5_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"5","What is the significance of TQBF in proving that PSPACE properly includes NL?","≤ 
≤ 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
   
 
 
 
  
  
 
 
 
  
 
 
 
 
Why
% and not
%'%()* when defining PSPACE-complete?
- Reductions should be “weaker” than the class. Otherwise all
problems in the class would be reducible to each other, and then 
all problems in the class would be complete.
Theorem: +,!- is PSPACE-complete
PSPACE-completeness 
Defn: ! is PSPACE-complete if 
1) ! ∈ PSPACE 
2) For all # ∈ PSPACE, # ≤% ! 
If ! is PSPACE-complete and ! ∈ P then P = PSPACE. 
Check-in 18.1 
Knowing that +,!- is PSPACE-complete, 
what can we conclude if +,!- ∈ NP? 
Check all that apply. 
(a) P = PSPACE 
(b) NP = PSPACE 
(c) P = NP 
(d) NP = coNP 
5 
PSPACE-complete 
NP-complete 
PSPACE = 
NPSPACE 
NP
P 
Think of complete problems as the “hardest” 
in their associated class. 
Check-in 18.1 
","77.24867248535156","10","DPRSearchEngine","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18_5_pdf","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18","18.404J","18"
"6","How does a pushdown automaton check if an input string is in the language of a given grammar?"," 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
              
 
 
 
 
 
 
 
 
 
 
 
Pushdown Automata (PDA) 
“head” 
a
b
a
b
a 
… 
a
Finite 
input appears on a “tape” 
control 
c 
Schematic diagram for DFA or NFA
(pushdown) 
d 
stack 
Schematic diagram for PDA 
d 
Operates like an NFA except can write-add or read-remove symbols 
from the top of stack. 
push 
pop 
Example: PDA for ! = 0$1$ & ≥0 
1) Read 0s from input, push onto stack until read 1. 
2) Read 1s from input, while popping 0s from stack. 
3) Enter accept state if stack is empty. (note: acceptance only at end of input) 
6 
","74.9746322631836","1","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_6_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"6","How does a pushdown automaton check if an input string is in the language of a given grammar?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
Use our knowledge that !TM is undecidable to show other 
problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
10 
","74.80296325683594","2","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_10_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"6","How does a pushdown automaton check if an input string is in the language of a given grammar?"," 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
   
 
    
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
Linearly Bounded Automata 
Defn: A linearly bounded automaton (LBA) is a 1-tape TM 
that cannot move its head off the input portion of the tape. 
LBA 
a a b a a b a 
Tape size adjusts to length of input. 
Let !LBA = &, ( LBA & accepts ( } 
Theorem:  !LBA is decidable 
Proof: (idea) If & on ( runs for long, it must be cycling. 
Decider for !LBA: 
Claim: For inputs of length ), an LBA can have 
.A−LBA = “On input &, ( 
only * ×)× Γ - different configurations. 
1.  Let ) = |(|. 
Therefore, if an LBA runs for longer, it must repeat some 
2. Run & on ( for * ×)× Γ - steps. 
configuration and thus will never halt. 
3. If has accepted, accept. 
4. If it has rejected or is still running, reject.” 
must be looping 
7 
","74.32673645019531","3","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_7_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"6","How does a pushdown automaton check if an input string is in the language of a given grammar?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
If we know that some problem (say !TM) is undecidable, 
we can use that to show other problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Recall Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
2 
","74.20024108886719","4","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_2_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"6","How does a pushdown automaton check if an input string is in the language of a given grammar?","  
 
  
 
 
  
 
  
 
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
  
 
 
   
-
Review: Probabilistic TMs and BPP 
coin flip step 
each choice has 
Defn: A probabilistic Turing machine (PTM) is a variant of a NTM 
where each computation step has 1 or 2 possible choices. 
deterministic 
step 
50% probability 
Defn: For ! ≥0 say PTM $  decides language % with error probability !  
if for every &, Pr[ $  gives the wrong answer about & ∈% ] ≤! . 
Defn: BPP = % some poly-time PTM decides % with error !  = +⁄,  } Check-in 24.1 
Actually using a probabilistic algorithm 
Amplification lemma: 2−. /01 2 
presupposes a source of randomness. 
Can we use a standard pseudo-random 
number generator (PRG) as the source? 
& ∈% 
& ∉% 
(a) Yes, but the result isn’t guaranteed.
(b) Yes, but it will run in exponential time.
Many 
Few 
Few 
Many 
(c) No, a TM cannot implement a PRG. 
accepting 
rejecting 
accepting 
rejecting 
(d) No, because that would show P = BPP.
2 
Check-in 24.1 
","73.52525329589844","5","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_2_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"6","How does a pushdown automaton check if an input string is in the language of a given grammar?"," 
 
 
 
 
 
   
  
 
  
 
 
   
 
 
  
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
  
 
 
 
 
 
 
Check-in 8.2 
Recall the Queue Automaton (QA) defined in Pset 2. 
It is similar to a PDA except that it is deterministic 
and it has a queue instead of a stack. 
Let !QA = { &, ( | & is a QA and & accepts (} 
Is !QA decidable? 
(a) Yes, because QA are similar to PDA and !PDA is decidable. 
(b) No, because “yes” would contradict results we now know. 
(c) We don’t have enough information to answer this question. 
8 
Check-in 8.2 
","73.41593933105469","6","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_8_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"6","How does a pushdown automaton check if an input string is in the language of a given grammar?"," 
  
 
  
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
   
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
    
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
PDA – Formal Definition 
Defn: A Pushdown Automaton (PDA) is a 6-tuple ("", Σ, Γ, &, '0, )) 
Σ input alphabet 
Γ stack alphabet 
&: Q×Σ.×Γ. → 0(""×Γ.) 
Accept if some thread is in the accept state 
& ', a, c = 
45, d , 47, e 
at the end of the input string. 
Example: PDA for 9 = {;;ℛ| ; ∈ 0,1 ∗} Sample input: 
0 1 1 1 1 0 
1) Read and push input symbols. 
Nondeterministically either repeat or go to (2). 
The nondeterministic forks replicate the stack. 
2) Read input symbols and pop stack symbols, compare. 
If ever ≠ then thread rejects. 
This language requires nondeterminism. 
Our PDA model is nondeterministic. 
3) Enter accept state if stack is empty. (do in “software”) 
7 
","72.81735229492188","7","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_7_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"6","How does a pushdown automaton check if an input string is in the language of a given grammar?"," 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
   
 
 
 
 
Write “Hello World”
Hello World
Write this sentence
Write this sentence
Write the following twice, the second time in quotes “Hello World”
Hello World “Hello World”
Cheating: TMs don’t have this self-reference primitive.
English Implementation 
Check-in 11.1 
Implementations of the Recursion Theorem have two parts, 
a Template and an Action. In the TM and English implementations, 
which is the Action part? 
(a) A and the upper phrase 
(b) A and the lower phrase 
(c) B and the upper phrase 
(d) B and the lower phrase. 
Write the following twice, the second time in quotes 
“Write the following twice, the second time in quotes” 
Write the following twice, the second time in quotes 
“Write the following twice, the second time in quotes” 
& 
% 
' 〈)〉 
Compute & = ' 〈)〉 
from % on tape. 
!""#$ 
Note on Pset Problem 6: Don’t need to worry about quoting. 
5 
Check-in 11.1 
&% 
","72.03175354003906","8","DPRSearchEngine","779043ea724131d008eae652d703938f_MIT18_404f20_lec11_5_pdf","779043ea724131d008eae652d703938f_MIT18_404f20_lec11","18.404J","11"
"6","How does a pushdown automaton check if an input string is in the language of a given grammar?"," 
 
 
 
 
 
 
 
 
  
 
 
   
 
 
  
 
 
 
  
 
 
   
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
'
a
a
a
b
b
b
˽
b
b
b
a
a
a
a
a
a
˽
a
a
a
˽
˽
˽
˽
˽
˽
˽
˽
˽
˽
˽
˽
Deciding ! = a#b# $ ≥0 even faster 
Theorem: A multi-tape TM ' can decide ! using ((*) steps. 
' = “On input , 
Analysis: 
1. Scan input to check if , ∈ a ∗ b ∗ , reject if not. 
( * steps 
2. Copy a’s to second tape. 
+((*) steps 
3. Match b’s with a’s on second tape. 
+((*) steps 
4. Accept if match, else reject. ” 
-----------------­
= ((*) steps 
5 
","71.9186782836914","9","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_5_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"6","How does a pushdown automaton check if an input string is in the language of a given grammar?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","71.83247375488281","10","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"7","Why is it conjectured that P ≠ NP even though polynomial-time algorithms are known to be powerful?","If you compare these two classes, P and NP. P, first of all, is going to be a subset of NP, both in terms of the way we defined it because, deterministic machines are a special case of non-deterministic machines. But also if you want to think about testing membership, if you can test membership easily then you can certainly verify it in terms of the certificate. You don't even need it. The certificate is irrelevant at that point. Because whatever the certificate is, you can still test yourself whether the input is in the language or not. The big question, as I mentioned, is whether these two classes are the same. So does being able to verify membership quickly, say with one of these certificates, allow you to dispense with the certificate? Not even need a certificate and just test it for yourself whether you're in the language. And do that in polynomial time. That's the question. For a problem like Hamiltonian path, do you need to search for the answer if you're doing it deterministically? Or can you somehow avoid that and just come up with the answer directly with a polynomial time solution? Nobody knows the answer to that. And it goes back, at this point, quite a long time. It's almost 60 years now. That problem has been around 60 years. No, that would be 50 years. No, 50 years, almost 50 years. Most people believe that P is different from NP. In other words, that there are problems in P-- in NP which are not in P. A candidate would be the Hamiltonian path problem. But it seems to be very hard to prove that. And part of the reason is, how do you prove that a problem like Hamiltonian path does not have a polynomial time algorithm. It's very tricky to do that, because the class of polynomial time algorithms is a very rich class. Polynomial time algorithms are very powerful. And to try to prove-- there's no clever way of solving the Hamiltonian path problem. It just seems to be beyond our present day mathematics. I believe someday somebody's going to solve it. But so far, no one has succeeded. So what I thought we would do is-- I think I have a check-in here.","77.16761779785156","1","DPRSearchEngine","1VhnDdQsELo.en-j3PyPqV-e1s_8_mp4","1VhnDdQsELo.en-j3PyPqV-e1s","18.404J","14"
"7","Why is it conjectured that P ≠ NP even though polynomial-time algorithms are known to be powerful?"," 
 
  
 
  
 
 
  
 
 
 
 
 
 
 
18.404/6.840 Lecture 22 
Last time: 
- Finished NL = coNL 
- Time and Space Hierarchy Theorems 
Today: (Sipser §9.2) 
- A “natural” intractable problem 
- Oracles and P versus NP 
1 
","76.49513244628906","2","DPRSearchEngine","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_1_pdf","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22","18.404J","22"
"7","Why is it conjectured that P ≠ NP even though polynomial-time algorithms are known to be powerful?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","74.46481323242188","3","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"7","Why is it conjectured that P ≠ NP even though polynomial-time algorithms are known to be powerful?","Intuition for P and NP
NP = All languages where can verify membership quickly
P  = All languages where can  test membership quickly
Examples of quickly verifying membership:
- !""#$""%!:  Give the Hamiltonian path. 
- &'#$'()%*(:  Give the factor. 
The Hamiltonian path and the factor are called short certificates of membership.
P ⊆NP
Question:  P = NP?  Famous unsolved problem (Cook 1971).
Conjecture:  P ≠ NP.   Some problems are NP and not in P. 
Hard to prove the conjecture because polynomial-time algorithms are powerful.
Example:  Show ""CFG ∈P.
NP
P
Check-in 14.1
Check-in 14.1
Let !""#$""%! be the complement of !""#$""%!.
So 0, 2, 3 ∈!""#$""%! if 0 does not have a Hamiltonian path from 2 to 3.  
Is !""#$""%! ∈NP?
(a) Yes, we can invert the accept/reject output of the NTM for !""#$""%!. 
(b) No, we cannot give a short certificate for a graph not to have a Hamiltonian path. 
(c) I don’t know.
6
","74.19879150390625","4","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_6_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"7","Why is it conjectured that P ≠ NP even though polynomial-time algorithms are known to be powerful?"," 
  
 
 
 
 
 
 
 
   
 
 
 
  
 
 
  
 
 
 
  
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
   
 
 
 
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
   
 
 
 
 
  
Unsolved Problem
Quick Review 
Defn: TIME ! "" 
= {%| some deterministic 1-tape TM ' decides % 
and ' runs in time ( ! "" } 
Defn: P = ⋃+ TIME(""+)
= polynomial time decidable languages 
./01 = 2, 4, ! 2 is a directed graph with a path from 4 to ! } 
Theorem: ./01 ∈ P 
2
1/'./01 = 2, 4, ! 2 is a directed graph with a path from 4 to !
4 
!
that goes through every node of 2 } 
1/'./01 ∈ P ? 
[connection to factoring] 
2 
","74.08218383789062","5","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_2_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"7","Why is it conjectured that P ≠ NP even though polynomial-time algorithms are known to be powerful?"," 
 
 
 
 
 
 
 
  
 
 
  
  
18.404/6.840 Lecture 15 
Last time: 
- NTIME ! "" , NP 
- P vs NP problem 
- Dynamic Programming, #CFG ∈ P 
- Polynomial-time reducibility 
Today: (Sipser §7.5) 
- NP-completeness 
1 
","74.02281188964844","6","DPRSearchEngine","c1aca7046a69c913721e5eb910a5fb21_MIT18_404f20_lec15_1_pdf","c1aca7046a69c913721e5eb910a5fb21_MIT18_404f20_lec15","18.404J","15"
"7","Why is it conjectured that P ≠ NP even though polynomial-time algorithms are known to be powerful?","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","74.00973510742188","7","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"7","Why is it conjectured that P ≠ NP even though polynomial-time algorithms are known to be powerful?","The next notion is NP-hardness. So in particular, I want to claim-- this is a theorem that exists in the literature-- that if P does not equal NP, then Tetris is not NP. So I said right here, Tetris is in EXP, but we don't know whether it's in NP. But in fact, we conjecture it is not NP because we conjecture that P does not equal NP. If you could prove this conjecture-- and there's a lot of theorems that are conditioned assuming P does not equal NP-- then we get some nice results, like Tetris cannot be solved in polynomial time. It cannot figure out whether I can win a Tetris game in polynomial time in the input size. Why? This is a consequence of another theorem, which is that Tetris is NP-hard. I'm going to define NP-hard informally first, and then I'll define it slightly more formally in a second. But this means, roughly, that Tetris is as hard as all problems in NP. So let me draw this in the picture. So NP-hard is this part. Did I leave myself enough room? Maybe not. Well, we'll squeeze it in. There's another region here for EXP-hard. So your problem being in NP was a positive result. It says you're no more difficult than this line. You're either at this position or to the left. Being in P was also a positive statement. It says you're here or to the left. Being in P is better than being in NP because this is a subset of that. NP-hard is a lower bound. It says, you are at this point, at this level of difficulty, or to the right. And so it goes from here off to infinity in difficulty. And EXP-hard says you're at least as hard as the right extent of the EXP set, or you're harder than that, in a sense that we will formalize in a moment. And this place right here, as you might imagine, is kind of interesting. It's exactly where NP meets NP-hard. This thing is called NP-complete. You probably have heard about NP-completeness, a famous notion. And this is what it means. It is, the problems that are in NP-- so they have a lucky algorithm that solves them, they can be verified, there are certificates that can be verified-- and they are NP-hard. So they're in NP, and they are the hardest among problems in NP. Now, they're not the hardest problem. There are actually many problems right here at this single level of difficulty called NP-complete. Among them is Tetris. There are many others, which I will list in a moment. So that is NP-completeness. So because these problems are the hardest problems in NP, if there's any problems here in between-- in NP minus P, then these must be among them. And so if you assume that P does not equal NP, as most people do, then you know that all problems at this right-most extreme of NP, the hardest of the problems in NP, they must not be NP. And that's why I can say, if P does not equal NP, Tetris is not NP, and also, any NP complete problem is not NP. OK, what does ""as hard as"" mean?","73.25643920898438","8","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_9_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"7","Why is it conjectured that P ≠ NP even though polynomial-time algorithms are known to be powerful?"," 
 
 
  
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
Computation with Oracles 
Let ! be any language. 
Defn: A TM "" with oracle for !, written ""#, is a TM equipped 
with a “black box” that can answer queries “is $ ∈!?” for free. 
Example: A TM with an oracle for &!' can decide all ( ∈ NP in polynomial time. 
Defn: P# = ( ( is decidable in polynomial time with an oracle for !} 
Thus NP ⊆ P+#, 
NP = P+#,? Probably No because coNP ⊆ P+#, 
Defn: NP# = ( ( is decidable in nondeterministic polynomial time with an oracle for !} 
Recall MIN-FORMULA = 7 7 is a minimal Boolean formula } 
Example: MIN−FORMULA ∈ NP+#, 
“On input 7 
1. Guess shorter formula 9 
2.  Use &!' oracle to solve the coNP problem: 7 and 9 are equivalent 
3. Accept if 7 and 9 are equivalent. Reject if not.” 
8 
","73.14776611328125","9","DPRSearchEngine","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_8_pdf","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22","18.404J","22"
"7","Why is it conjectured that P ≠ NP even though polynomial-time algorithms are known to be powerful?","you might find one way or the other more intuitive. They're equivalent. So as long as you understand at least one of them, it's good. NP is just a class of decision problems. So I define P and EXP and R arbitrary. They can be problems with any kind of output. But NP only makes sense for decision problems. And it's going to look almost like the definition of P-- problem solvable in polynomial time. We've just restricted to decision problems. But we're going to allow a strange kind of computer or algorithm, which I like to call a lucky algorithm. And this is going to relate to the notion of guessing that we talked about for the last four lectures in dynamic programming. With dynamic programming, we said, oh, there are all these different choices I could make. What's the right choice? I don't know, so I'd like to make a guess. And what that meant in terms of a real algorithm is, we tried all of the possibilities, and then took the max or the OR or whatever over all those possibilities. And so we were-- but what we were simulating is something that I call a lucky algorithm, which can make guesses and always makes the right guess. This is a computer that is impossible to buy. It would be great if you could buy a computer that's lucky. But we don't know how to build such a computer. So what does this mean? So informally, it means your algorithm can make lucky guesses, and it always makes the right guess. And whereas in DP, we had to try all the options and spend time for all of them, the lucky algorithm only has to spend time on the lucky guess, on the correct guess. More formally, this is called a non-deterministic model of computation. And this N is the-- the N in non-determinism is the N for NP. So this is non-deterministic polynomial time. So algorithm can make guesses. And then in the end, it should output yes or no. Like say if you're exploring a maze, this algorithm could say, should I go left or go right? I'm going to guess whether to go left or go right. And let's say it guesses left. And so then it just goes left. And then it reaches another junction. It says, should I go left or right? And it'll say, I'll guess, and it'll say, guess right this time. And in the end, if I get to some dead end maybe and I say no, or if I get to the destination I'm trying to get to, I say yes. So that's a non-deterministic algorithm. And what does it mean to run that algorithm? What does it mean for the guesses to be lucky? Here's what it means. These guesses are guaranteed-- which way you end up going is guaranteed to lead you to a yes if there is one-- if possible. So in my maze analogy, if my destination is reachable from my source, then I'm guaranteed, whenever I guessed left or right, I will choose a path that leads me to my destination. Whereas, if the destination is in some disconnected part of the maze and I can't get there, then I don't know what the guesses do. It doesn't really matter. Because no matter what I do, I'll end up in a dead end and say no. That's the model. As long as you have an algorithm that always outputs yes or no in polynomial time-- because we're only talking about polynomial time, lucky algorithms-- if there's any way to get to a yes, then your machine will magically find it without having to spend any time to make these decisions. So it's a pretty magical computer, and it's not a computer that exists in real life. But it's a computer that's great to program on. It's very powerful. You could solve lots of things with it. Yeah. AUDIENCE: If you had this magical computer, it can guess whether it's yes or no, why doesn't it just answer the question? ERIK DEMAINE: Right. So what if we-- so a nice check is, does this make all problems trivial, all decision problems? Maybe I should say, well, I don't know whether the answer to the problem is yes or no, so I'll just guess yes or no. This is problematic because-- so I might say, it will guess A or B, and if I choose the A option, I will output yes, and if I choose the B option, I will output no. In this model, that algorithm will always output yes. Because what it's saying is, if there's any way to get to a yes answer, I will do that way. And so such an algorithm that tries to cheat and just guess the whole answer to the problem will actually end up always saying yes, which means it doesn't solve a very interesting problem. It only solves the problem, which is represented by the bit vector 1111111, where all the answers are yes. But good check. Yeah. AUDIENCE: Does there have to be a bound of a number of things it has to choose between when it [AUDIO OUT] ERIK DEMAINE: Yes. AUDIENCE: Does it have an exponential number of them? ERIK DEMAINE: Exponential number of choices is OK. I usually like to think of it, as you can only guess one bit at a time. But we're allowed polynomial time, so you're actually allowed to guess polynomial number of bits. At that point, you can guess over an exponential size space, but not more than exponential. So it's-- yeah, polynomial time let's say in the one-bit guessing model. What did I say? Makes guesses-- let's add binary here. Otherwise we get some other class, which I don't want. OK, let's do an example, a real example of such an algorithm","72.54411315917969","10","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_6_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"9","What defines the class P in terms of time complexity and associated languages?"," 
 
  
  
 
 
 
 
 
 
 
  
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Review: Major Complexity Classes 
L ⊆ NL ⊆ P ⊆ NP ⊆ PSPACE 
≠ 
Today 
The time and space hierarchy theorems show that 
if a TM is given more time (or space) then it can do more.* 
* certain restrictions apply. 
For example: 
TIME #$ ⊆, TIME #% 
[ ⊆, means proper subset ] 
SPACE #$ ⊆, SPACE #% 
7 
","78.49327850341797","1","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_7_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"9","What defines the class P in terms of time complexity and associated languages?"," 
 
  
  
 
 
 
 
 
 
   
 
 
 
 
  
 
  
 
  
 
 
  
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
   
 
    
   
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
   
  
Time Hierarchy Theorem (1/2) 
Theorem: For any !: ℕ → ℕ where ! is time constructible 
there is a language % where % requires & ! ' 
time, i.e, 
1) % is decidable in & ! ' 
time, and 
2) % is not decidable in ( ! ' / log ! ' 
time 
- .
On other words, TIME (
⊆, TIME ! ' 
/01 - . 
Proof outline:  Give TM 3 where 
1) 3 runs in & ! ' 
time 
2) 3 ensures that 4(3) ≠ 4(8) for every TM 8 that runs in ( ! ' / log ! ' 
time . 
Let % = 4(3). 
10 
","77.70445251464844","2","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_10_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"9","What defines the class P in terms of time complexity and associated languages?"," 
 
 
  
 
   
   
  
   
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
  
 
   
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
Relationships between 
Time and SPACE Complexity 
Theorem: For ! "" ≥"" 
1) TIME ! "" 
⊆ SPACE ! "" 
2) SPACE ! "" 
⊆ TIME 2& ' ( 
= ⋃+ TIME ,' ( 
Proof: 
1) A TM that runs in !("") steps cannot use more than !("") tape cells. 
2) A TM that uses !("") tape cells cannot use more than ,' ( time 
without repeating a configuration and looping (for some ,). 
Corollary: P ⊆ PSPACE 
Theorem: NP ⊆ PSPACE [next slide] 
3 
","76.94812774658203","3","DPRSearchEngine","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17_3_pdf","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17","18.404J","17"
"9","What defines the class P in terms of time complexity and associated languages?"," 
 
 
 
  
 
 
  
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Intro to Complexity Theory 
Computability theory (1930s - 1950s): 
Is A decidable? 
Complexity theory (1960s - present): 
Is A decidable with restricted resources? 
(time/memory/…) 
Example: Let ! = a#b# $ ≥0 . 
Q: How many steps are needed to decide !? 
Depends on the input. 
We give an upper bound for all inputs of length '. 
Called “worst-case complexity”. 
2 
","76.9319839477539","4","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_2_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"9","What defines the class P in terms of time complexity and associated languages?","solve in a certain time bound, within a certain amount of time. So the time n-squared, for example, is all of the languages or all of the problems that you can solve in n-squared time. We're identifying problems with languages here. And the class P is the collection of all problems that you can solve or all languages that you can solve in polynomial time. So it's the union over all time n to the k-- so n-squared, n-cubed, n to the fifth power, and so on. Union out of all of those bounds. The associated languages, that's the class P. And we gave an example, this path problem. We gave an algorithm for path.","76.88121032714844","5","DPRSearchEngine","1VhnDdQsELo.en-j3PyPqV-e1s_2_mp4","1VhnDdQsELo.en-j3PyPqV-e1s","18.404J","14"
"9","What defines the class P in terms of time complexity and associated languages?"," 
 
   
 
 
 
 
 
 
 
   
  
 
 
 
  
 
 
  
 
 
 
  
 
 
 
 
 
 
 
  
 
 
  
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
   
 
 
 
 
 
  
 
 
 
 
 
 
 
The Class P 
Defn: P = ⋃# TIME(%#)
= polynomial time decidable languages 
• Invariant for all reasonable deterministic models 
• Corresponds roughly to realistically solvable problems 
+ 
-
Example: '()* = +, -, . + is a directed graph with a path from - to . } 
. 
Theorem:  '()* ∈ P 
Proof: 1 = “On input 〈+, -, .〉 
1.  Mark ­
2. Repeat until nothing new is marked: 
≤% iterations 
To show polynomial time: 
For each marked node 4: 
× ≤% iterations 
Each stage should be clearly 
Scan + to mark all 5 where 4, 5 is an edge × 8 %9 steps 
polynomial and the total 
3. Accept if . is marked. Reject if not. 
-------------------
number of steps polynomial. 
8(%:) steps 
10 
","74.73464965820312","6","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_10_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"9","What defines the class P in terms of time complexity and associated languages?","If you compare these two classes, P and NP. P, first of all, is going to be a subset of NP, both in terms of the way we defined it because, deterministic machines are a special case of non-deterministic machines. But also if you want to think about testing membership, if you can test membership easily then you can certainly verify it in terms of the certificate. You don't even need it. The certificate is irrelevant at that point. Because whatever the certificate is, you can still test yourself whether the input is in the language or not. The big question, as I mentioned, is whether these two classes are the same. So does being able to verify membership quickly, say with one of these certificates, allow you to dispense with the certificate? Not even need a certificate and just test it for yourself whether you're in the language. And do that in polynomial time. That's the question. For a problem like Hamiltonian path, do you need to search for the answer if you're doing it deterministically? Or can you somehow avoid that and just come up with the answer directly with a polynomial time solution? Nobody knows the answer to that. And it goes back, at this point, quite a long time. It's almost 60 years now. That problem has been around 60 years. No, that would be 50 years. No, 50 years, almost 50 years. Most people believe that P is different from NP. In other words, that there are problems in P-- in NP which are not in P. A candidate would be the Hamiltonian path problem. But it seems to be very hard to prove that. And part of the reason is, how do you prove that a problem like Hamiltonian path does not have a polynomial time algorithm. It's very tricky to do that, because the class of polynomial time algorithms is a very rich class. Polynomial time algorithms are very powerful. And to try to prove-- there's no clever way of solving the Hamiltonian path problem. It just seems to be beyond our present day mathematics. I believe someday somebody's going to solve it. But so far, no one has succeeded. So what I thought we would do is-- I think I have a check-in here.","73.92001342773438","7","DPRSearchEngine","1VhnDdQsELo.en-j3PyPqV-e1s_8_mp4","1VhnDdQsELo.en-j3PyPqV-e1s","18.404J","14"
"9","What defines the class P in terms of time complexity and associated languages?","Second half, Church-Turing thesis. So Church, this is going back into the bit of the history of the subject back to the 1930s. Back then people were interested in formulating the notion of what do we mean by algorithm. They didn't even call it algorithm. Some people call it procedure. Some people called it effective procedure. Some people called it effective calculation. But people had in their minds-- mathematicians have been dealing for centuries, thousands of years, with procedures for doing things. That's a very natural thing. And mathematical logicians, in particular Church and Turing, Turing somebody surely obviously you've heard of, Church maybe not. Church was Turing's thesis advisor, in fact. And they both were coming out of the mathematical logic field of mathematics and trying to use mathematical logic to formalize this intuitive notion of what we have had for centuries about what a procedure is, what is an algorithm. And back in those days, they came up with different ways of formalizing it. So here we had this notion of algorithm, which is kind of intuitive concept. Turing proposed Turing machine as a way of capturing that in a formal way, a mathematically precise way. Other people came up with other ways of doing it. And back then, it wasn't obvious that all of those different formulations would end up giving you equivalent concepts, equivalent notions. And in fact, they proved in fairly elaborate detail that the different methods that people came up with, there was the lambda calculus, there was rewriting systems, there were several methods that were proposed for formalizing this notion, and they all turned out to be equivalent to one another. Today that seems kind of obvious, even though I went to some effort to prove that just to give you a feeling for how those things go. If you have programs, if you have Pascal and Java, say, and thinking about what you can do mathematically in those-- I'm not talking about their ability to interface with Windows and so on, but just the mathematical capabilities. The capability of doing mathematical calculations or functions with a Pascal program or a Java program. It would be absurd to think there's some program that you can write in Java that you can't write in Pascal or Python. And the reason is we know you can compile Python into Java and you can compile Java back into Python. That tells you that the two systems, two programming languages are equivalent in power. That wasn't obvious from the get go to these folks. So they observed that all of the different efforts that came at formalizing algorithm, all were equivalent to one another. That was kind of a breakthrough moment when they realized that all of the ways that they've come up with, and once they got the idea, they realized all reasonable ways of doing it are always going to be equivalent. And so that suggested that they've really captured this notion of algorithm by any one of those methods, say a Turing machine. And that's what they took. You can't prove that, because algorithms are an intuitive notion. But the fact that we're able to capture that in a formal way, that's what we call today the Church-Turing thesis.","72.58429718017578","8","DPRSearchEngine","TTArY7ojshU.en-j3PyPqV-e1s_7_mp4","TTArY7ojshU.en-j3PyPqV-e1s","18.404J","6"
"9","What defines the class P in terms of time complexity and associated languages?","So what is the running time of Dijkstra? If I take a look at that algorithm over there-- well I guess let's switch these back up again. OK, so what does this do? We build once. Then we delete the minimum from the Q how many times? v times. We remove every vertex from our Q. Then for every possible edge, we may need to relax and decrease the key in our queue once for every outgoing edge. So the running time is B plus V times M plus E times D. OK. So how could we implement this priority queue? Well, if we use the stupidest priority queue in the world, here's a list of different implementations we could have for our priority queues. And when I say priority queue, I mean this priority queue. We're already implementing the changeable priority queue by linking it with a dictionary that's efficient If I just use an array, I can find the min in linear time, sure. And I don't have to update that array in any way. I mean, I can just keep the distances in my direct access array. I don't have to store a separate data structure. I just store the distances in my direct access array D, and so I can find it in constant time and I can update the values stored there. And then whenever I want the minimum, I can just loop through the whole thing. So that gives me a really fast decrease key,","72.55941772460938","9","DPRSearchEngine","NSHizBK9JD8.en-j3PyPqV-e1s_6_mp4","NSHizBK9JD8.en-j3PyPqV-e1s","6.006","13"
"9","What defines the class P in terms of time complexity and associated languages?"," 
 
  
  
 
 
 
 
 
 
 
 
 
 
   
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Recap: Separating Complexity Classes 
L ⊆ NL 
≠
⊆ P ⊆ NP ⊆ PSPACE 
Space Hierarchy Theorem 
NL ⊆ SPACE log& ' ⊆, SPACE ' ⊆ PSPACE 
12 
Check-in 21.3 
Consider these two famous unsolved questions: 
1. 
Does L = P? 
2. 
Does P = PSPACE? 
What do the hierarchy theorems tell us about 
these questions? 
a) Nothing 
b) At least one of these has answer “NO” 
c) 
At least one of these has answer “YES” 
Check-in 21.3 
","72.30070495605469","10","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_12_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"10","How can reducing a problem help in determining its complexity or decidability, and what are the two typical ways this can be used?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
Reducibility terminology 
Why do we use the term “reduce”? 
When we reduce ! to "", we show how to solve ! by using "" 
and conclude that ! is no harder than "". (suggests the ≤$ notation) 
Possibility 1: We bring !’s difficulty down to ""’s difficulty. 
Possibility 2: We bring ""’s difficulty up to !’s difficulty. 
11 
","71.33573150634766","1","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_11_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"10","How can reducing a problem help in determining its complexity or decidability, and what are the two typical ways this can be used?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","68.60497283935547","2","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"10","How can reducing a problem help in determining its complexity or decidability, and what are the two typical ways this can be used?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Getting a  Tighter Bound  
§Will drawing more samples help? 
◦ Let’s try  increasing from 1000 to 2000 
◦ Standard deviation goes from 0.943 to 0.946 
§How about larger samples? 
◦ Let’s try  increasing sample size from 100 to 200  
◦ Standard deviation goes from 0.943 to 0.662  
6.0002  LECTURE 8 
 
15
","67.49919891357422","3","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_15_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"10","How can reducing a problem help in determining its complexity or decidability, and what are the two typical ways this can be used?","In particular, adding constraints to subproblems, in some sense, lets us remember things about the subproblem that's calling us-- or about the past, is one way to think about it-- or in general, to ""remember state."" Just by adding more subproblems, we can remember more stuff-- not just what things we're working on, but some context. And that's what we'll see lots of examples of today. It will hopefully make sense by the end of the lecture. Then, we need to relate these subproblems with the recurrence relation-- actually, we usually just call it a relation. And the key idea here is to come up with a question that, if you knew the answer to that question, you could reduce the subproblem you're trying to solve to smaller subproblem solutions. This question is sort of the fundamental aspect of-- some fundamental aspect of a solution. Typically, when you're dealing with suffixes, you want to ask some question about the first item, s of i. When you're dealing with prefixes, you want to ask a question about some-- near the last item, s of i minus 1. And for substrings, who knows? Somewhere in the middle. We'll see an example of that today. Once you have-- oh, this is a reveal. Something coming later. Once you have identified such a question, the dynamic programming approach is, don't be smart about how to answer that question-- just locally brute force. Try all possible answers to the question. For each one, recurse, and take the best solution according to whatever metric you're trying to do, typically minimization or maximization. Another way to think of this local brute force, which I like to think in my head-- so maybe some people like this, some people don't-- is to think about guessing the answer to the question. So maybe the answer could be 0, 1, or 2. And my algorithm will say, guess which is the right answer. And I'll assume that my algorithm correctly guesses the answer and analyze that. So we can think of the program as going straight through-- guessing the answer and then recursing, and then combining the solutions however. But then, at the end, of course, we can't assume that the guess was correct. In fact, we have to loop over all of those guesses. So it's the same thing. Just, if you think of it this way, there's less looping in your program. But when you analyze it, definitely, the loop is really there. You have to pay for all of the possible answers. OK. Then we need to make sure this relation is acyclic, get a subproblem DAG. And I like to specify an explicit topological order to make that clear. We have base cases for the relation. We have to solve the original problem in terms of these subproblems, and then we analyze the running time, usually, as the number of subproblems times the non-recursive work in the relation. So recursion is free because we're multiplying by the number of subproblems. You can also sum over the subproblems. Sometimes that gives you a tighter bound. And then, of course, we also have to add on the running time we spend in the original problem. All right. That was a quick recap. Now, one problem we saw in this framework two lectures ago-- the first lecture was single-source shortest paths in a DAG, which, a lot of dynamic programs actually can be reduced to a single-source shortest paths in a DAG. In fact, the reverse is true. Single-source shortest paths in a DAG can be thought of. The DAG relaxation algorithm we saw is essentially a dynamic program where the subproblems are delta of s, v. The relation of delta of s, v is the min. So what are we thinking about here? We're guessing-- this is sort of a new phrase I want to add. Actually, I wrote it right here. The last edge, u, v, on a shortest s to v path. That's a delta of s, v. The problem we're trying to solve is, find shortest s to v path. And it's some path, and we don't know what it looks like, but some feature of the solution of this path we're trying to find is, well, what's the last edge? It comes from some vertex here, unless the path is of length 0 and s equals v. That's a special case dealt with in the base case. Otherwise, there's some vertex u before v. We don't know what it is, so we're going to locally brute force, or guess what the right answer is. So look at all incoming edges from u to v, and for each of them, take the recursive shortest path from s to u, plus the weight of the edge. So this is the guessing or local brute force perspective. And the reason this works is because G is acyclic, and so it has a topological order. Otherwise, if the graph has a cycle-- and that's the case we want to go to next-- this recursive call from delta of s, v to delta of s, u will have loops in it. And so you'll never evaluate this recursion. You'll never finish. You'll never minimalize. You'll be sad. It will take infinite time. So don't use this algorithm unless you have a DAG. For DAG, it's great. It's linear time. So that was a little review.","67.4539794921875","4","DPRSearchEngine","TDo3r5M1LNo.en-j3PyPqV-e1s_3_mp4","TDo3r5M1LNo.en-j3PyPqV-e1s","6.006","17"
"10","How can reducing a problem help in determining its complexity or decidability, and what are the two typical ways this can be used?"," 
 
 
 
  
 
 
  
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Intro to Complexity Theory 
Computability theory (1930s - 1950s): 
Is A decidable? 
Complexity theory (1960s - present): 
Is A decidable with restricted resources? 
(time/memory/…) 
Example: Let ! = a#b# $ ≥0 . 
Q: How many steps are needed to decide !? 
Depends on the input. 
We give an upper bound for all inputs of length '. 
Called “worst-case complexity”. 
2 
","67.34520721435547","5","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_2_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"10","How can reducing a problem help in determining its complexity or decidability, and what are the two typical ways this can be used?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","67.20054626464844","6","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"10","How can reducing a problem help in determining its complexity or decidability, and what are the two typical ways this can be used?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","67.14838409423828","7","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"10","How can reducing a problem help in determining its complexity or decidability, and what are the two typical ways this can be used?","§ Problem is exponen<al 
§ Have we overturned the laws of the universe? 
§ Is dynamic programming a miracle? 
§ No, but computa<onal complexity can be subtle 
§ Running <me of fastMaxVal is governed by number of 
dis<nct pairs, <toConsider, avail> 
◦Number of possible values of toConsider bounded 
by len(items)
◦Possible values of avail a bit harder to characterize 
◦Bounded by number of dis<nct sums of weights 
◦Covered in more detail in assigned reading 
How Can This Be? 
6.0002 LECTURE 2 
30 
","66.97470092773438","8","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_30_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"10","How can reducing a problem help in determining its complexity or decidability, and what are the two typical ways this can be used?","basically incremental algorithms that, kind of like Dijkstra, or kind of like Bellman-Ford, will incrementally update estimates to-- of a max flow and improve them over time. Then on the, basically, design paradigms, you've got more involved making your own divide-and-conquer algorithms, dynamic programming algorithms, greedy algorithms. Basically, they go a lot more in depth in terms of how to design these algorithms and these paradigms than we do in this class. And then the last thing is-- we only touched on complexity. And in a sense, 046 is only going to touch on complexity. It's a very big field. But it will give you the tools to be able to prove that something is NP-hard, whereas we just kind of say that, oh, there's this thing called a reduction. We didn't give you any problems in which you actually had to reduce one problem to another. And you'll do a lot more of that here. So, reductions. So in a big sense, 046 is really just a natural extension to the 006 material, plus some additional stuff, which I'm going to get to in a second. Yeah, question? AUDIENCE: Do you want to add randomization for time paradigms? JASON KU: I'm going to talk about that slightly in a separate-- I'll get to your question in just a second. I like to think of it as a separate topic, which I will go into right now. The separate topic I like to think of it as, instead of being the natural extension to the things in the 006 units, what I'm going to do is kind of relax either what it means to have a correct algorithm or relax what it means to-- what my model of computation is. So 006, this is kind of as an extension of 006. And this is kind of like 6.046 as change my definition of what it means to be correct or efficient. So we've already kind of done this a little bit in 006. Basically, one of the things that we can do,","66.55471801757812","9","DPRSearchEngine","2NMtS1ecb3o.en-j3PyPqV-e1s_8_mp4","2NMtS1ecb3o.en-j3PyPqV-e1s","6.006","20"
"10","How can reducing a problem help in determining its complexity or decidability, and what are the two typical ways this can be used?","§ Given remaining weight, maximize value by choosing 
among remaining items 
§ Set of previously chosen items, or even value of that 
set, doesn’t mafer! 
What Problem is Solved at Each Node? 
6.0002 LECTURE 2 
26 
","66.55267333984375","10","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_26_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"11","What is the class BPP?"," 
 
  
 
 
  
 
 
 
 
 
18.404/6.840 Lecture 25 
Last time: 
- Schwartz-Zippel Theorem 
- !""ROBP ∈ BPP 
Today: (Sipser §10.4) 
- Interactive Proof Systems 
- The class IP 
- Graph isomorphism problem 
- coNP ⊆ IP  (part 1) 
1 
","74.79275512695312","1","DPRSearchEngine","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25_1_pdf","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25","18.404J","25"
"11","What is the class BPP?"," 
 
  
 
 
 
 
 
 
  
 
 
 
 
  
  
  
  
18.404/6.840 Lecture 24 
Last time: 
- Probabilistic computation
- The class BPP
- Branching programs
- Arithmetization
- Started showing !""
ROBP ∈ BPP
Today: (Sipser §10.2)
- Finish !""
ROBP ∈ BPP
1 
","72.73902893066406","2","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_1_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"11","What is the class BPP?","Example:  Branching Programs
Defn: A branching program (BP) is a directed, acyclic (no cycles) graph that has
1.  Query nodes labeled !"" and having two outgoing edges labeled 0 and 1.
2.  Two output nodes labeled 0 and 1 and having no outgoing edges.
3.  A designated start node.
BP # with query nodes !$, … , !' describes a Boolean function (: 0,1 ' →{0,1}:
Follow the path designated by the query nodes’ outgoing edges 
from the start note until reach an output node.
Example:  For !$ = 1, !/ = 0, !0 = 1 we have ( 101 = 0 = output.
BPs are equivalent if they describe the same Boolean function.
Defn:  12BP =
#$, #/
#$ and #/ are equivalent BPs (written #$ ≡#/) } 
Theorem:  12BP is coNP-complete  (on pset 6)
12BP ∈BPP ?  Unknown. That would imply NP ⊆BPP and would be surprising!
Instead, consider a restricted problem.
!$
!0
!$
!/
!/
!0
0
1
0
1
0
1
0
1
0
1
0
1
0
1
5
","71.82526397705078","3","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_5_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"11","What is the class BPP?","Defn:  BPP = "" some poly-time PTM decides "" with error # = ⁄
% & }
Amplification lemma: If '% is a poly-time PTM with error #% < ⁄
% ) then, 
for any 0 < #) < ⁄
% ), there is an equivalent poly-time PTM ') with error #).  
Can strengthen to make #) < 2−,-./ 0 . 
Proof idea:  ') = “On input 1
1.  Run '% on 1 for 2 times and output the majority response.”
Details:  Calculation to obtain 2 and the improved error probability. 
Significance:  Can make the error probability so small it is negligible.
The Class BPP
3
","68.52429962158203","4","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_3_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"11","What is the class BPP?"," 
 
   
 
 
 
 
 
 
 
   
  
 
 
 
  
 
 
  
 
 
 
  
 
 
 
 
 
 
 
  
 
 
  
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
   
 
 
 
 
 
  
 
 
 
 
 
 
 
The Class P 
Defn: P = ⋃# TIME(%#)
= polynomial time decidable languages 
• Invariant for all reasonable deterministic models 
• Corresponds roughly to realistically solvable problems 
+ 
-
Example: '()* = +, -, . + is a directed graph with a path from - to . } 
. 
Theorem:  '()* ∈ P 
Proof: 1 = “On input 〈+, -, .〉 
1.  Mark ­
2. Repeat until nothing new is marked: 
≤% iterations 
To show polynomial time: 
For each marked node 4: 
× ≤% iterations 
Each stage should be clearly 
Scan + to mark all 5 where 4, 5 is an edge × 8 %9 steps 
polynomial and the total 
3. Accept if . is marked. Reject if not. 
-------------------
number of steps polynomial. 
8(%:) steps 
10 
","68.44488525390625","5","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_10_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"11","What is the class BPP?","  
 
  
 
 
  
 
  
 
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
  
 
 
   
-
Review: Probabilistic TMs and BPP 
coin flip step 
each choice has 
Defn: A probabilistic Turing machine (PTM) is a variant of a NTM 
where each computation step has 1 or 2 possible choices. 
deterministic 
step 
50% probability 
Defn: For ! ≥0 say PTM $  decides language % with error probability !  
if for every &, Pr[ $  gives the wrong answer about & ∈% ] ≤! . 
Defn: BPP = % some poly-time PTM decides % with error !  = +⁄,  } Check-in 24.1 
Actually using a probabilistic algorithm 
Amplification lemma: 2−. /01 2 
presupposes a source of randomness. 
Can we use a standard pseudo-random 
number generator (PRG) as the source? 
& ∈% 
& ∉% 
(a) Yes, but the result isn’t guaranteed.
(b) Yes, but it will run in exponential time.
Many 
Few 
Few 
Many 
(c) No, a TM cannot implement a PRG. 
accepting 
rejecting 
accepting 
rejecting 
(d) No, because that would show P = BPP.
2 
Check-in 24.1 
","67.17446899414062","6","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_2_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"11","What is the class BPP?"," 
 
  
 
 
 
 
 
 
  
 
 
 
 
 
 
  
18.404/6.840 Lecture 23 
Last time: 
- !""#$%↑ is EXPSPACE-complete 
- Thus !""#$%↑ ∉ PSPACE 
- Oracles and P versus NP 
Today: (Sipser §10.2) 
- Probabilistic computation 
- The class BPP 
- Branching programs 
1 
","66.47248840332031","7","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_1_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"11","What is the class BPP?","!""
!#
!#
0
1
0
1
!$
!$
0
1
0
1
0
1
0
1
1
1
1
1
1
1
1
0
0
0
0
0
0
0
0
0
0
Boolean Labeling
Show by example:  Input is  !"" = 0, !# = 1, !$ = 1
The BP follows its execution path.
Label all nodes and edges on the execution path with 1
and off the execution path with 0.
Output the label of the output node 1.
Alternative way to view BP computation
Obtain the labeling inductively by using these rules:
'
' ∧!)
' ∧!)
'""
'#
'$
'"" ∨'# ∨'$
!)
0 1
Label edges from nodes
Label nodes from incoming edges
8
","66.01268768310547","8","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_8_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"11","What is the class BPP?"," 
  
  
 
 
 
 
 
 
 
    
 
 
  
 
 
 
 
 
 
 
 
  
 
  
    
 
 
 
  
 
   
    [ V is deterministic ]
    [ V ignores P ]
[ We won’t prove. Idea: explore all possible interactions in poly space. ]
Facts about IP – Checkin 25.2 
Which of the following is true? 
Check all that apply 
a) NP ⊆ IP 
b) BPP ⊆ IP 
c) IP ⊆ PSPACE 
Surprising Theorem: PSPACE ⊆ IP so IP = PSPACE 
We will prove only a weaker statement: coNP ⊆ IP 
7 
","65.88021087646484","9","DPRSearchEngine","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25_7_pdf","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25","18.404J","25"
"11","What is the class BPP?","! ""
! #
! #
0
1
0 
1
0
1
0
1
Non-Boolean Labeling
Use the arithmetized interpretation of the BP’s computation 
to define its operation on non-Boolean inputs. 
Example:  ! "" = 2, ! # = 3
Output = −7
! (
0 1
)
) (1 −! ()
) ! (
) ""
) #
) -
) "" + ) # + ) -
1
−1 = 1 1 −2
1 2 = 2
2
8 = 2 + 6
2 = −1 1 −3
−3 = −1 3
2 3 = 6
2 1 −3 = −4
−1
−3 + −4 = −7
Recall labeling rules:
Algorithm sketch for 45 ROBP:  “On input : "" , : #
1.  Pick a random non-Boolean input assignment. 
2.  Evaluate : "" and : # on that assignment.
3.  If : "" and : # disagree then reject.
If they agree then accept.”
More details and correctness proof to come.  
First some algebra… 
6
","65.61917114257812","10","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_6_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"12","Why is proving a problem to be NP-complete considered strong evidence that it lacks a polynomial time solution?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
Use our knowledge that !TM is undecidable to show other 
problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
10 
","76.44465637207031","1","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_10_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"12","Why is proving a problem to be NP-complete considered strong evidence that it lacks a polynomial time solution?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
If we know that some problem (say !TM) is undecidable, 
we can use that to show other problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Recall Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
2 
","76.38832092285156","2","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_2_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"12","Why is proving a problem to be NP-complete considered strong evidence that it lacks a polynomial time solution?","Satisfiability Problem
Defn: A Boolean formula ! has Boolean variables (TRUE/FALSE values) 
and Boolean operations AND (∧), OR (∨), and NOT (¬). 
Defn: ! is satisfiable if ! evaluates to TRUE for some assignment to its variables.
Sometimes we use 1 for True and 0 for False.
Example:  Let ! =
& ∨' ∧(& ∨')
(Notation:  & means ¬&)  
Then ! is satisfiable  (x=1, y=0)  
Defn:  *+, =
!
! is a satisfiable Boolean formula}
Theorem (Cook, Levin 1971):    *+, ∈P  →P = NP 
Proof method:  polynomial time (mapping) reducibility
Check-in 14.3
Check-in 14.3
Is  *+, ∈NP?
(a) Yes.
(b) No. 
(c) I don’t know.
(d) No one knows.
11
","74.37031555175781","3","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_11_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"12","Why is proving a problem to be NP-complete considered strong evidence that it lacks a polynomial time solution?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
Reducibility terminology 
Why do we use the term “reduce”? 
When we reduce ! to "", we show how to solve ! by using "" 
and conclude that ! is no harder than "". (suggests the ≤$ notation) 
Possibility 1: We bring !’s difficulty down to ""’s difficulty. 
Possibility 2: We bring ""’s difficulty up to !’s difficulty. 
11 
","73.53302001953125","4","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_11_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"12","Why is proving a problem to be NP-complete considered strong evidence that it lacks a polynomial time solution?","§ In theory, yes 
§ In prac<ce, no! 
§ Dynamic programming to the rescue 
Is It Hopeless? 
6.0002 LECTURE 2 
14 
","72.70449829101562","5","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_14_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"12","Why is proving a problem to be NP-complete considered strong evidence that it lacks a polynomial time solution?"," 
 
    
 
 
 
 
 
 
 
 
 
     
 
 
 
 
 
     
 
 
  
 
 
 
     
 
 
  
 
     
 
 
  
 
     
 
 
  
 
 
 
  
  
 
 
   
 
 
 
   
 
 
Check-in 26.3 
P = NP ? 
a) YES. Deep learning will do !""# ∈ P, but we won’t understand how. 
b) NO. 
But we will never prove it.
c) NO. 
We will prove it but only after 100 years
d) NO. 
We will prove it in ' years, 20 ≤ ' ≤ 100
e) NO. 
We will prove it in ' years, 1 ≤ ' < 20
f) NO. 
One of us is writing up the proof now…
9 
Check-in 26.3 
","72.06045532226562","6","DPRSearchEngine","7ac944716e076209c3964e073929f42e_MIT18_404f20_lec26_9_pdf","7ac944716e076209c3964e073929f42e_MIT18_404f20_lec26","18.404J","26"
"12","Why is proving a problem to be NP-complete considered strong evidence that it lacks a polynomial time solution?","   
  
 
 
 
 
 
 
 
 
 
  
  
 
 
 
 
 
 
 
 
 
  
  
 
 
  
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
 
 
 
  
  
 
 
   
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
   
 
 
 
 
  
 
  
   
 
 
 
 
  
 
 
 
  
  
!""#$ and $""%!""#$ 
Example: $""%!""#$ = ', ), * ' is a directed graph with a path from ) to * 
and the path goes through every node of ' } 
Recall Theorem: !""#$ ∈ P 
Called a Hamiltonian path 
' 
Question: $""%!""#$ ∈ P ? 
“On input ', ), * 
1. Let - be the number of nodes in '. 
2. For each path of length - in ': 
test if - is a Hamiltonian path from ) to *. 
Accept if yes. 
3. Reject if all paths fail.” 
May be -! > 22 paths of length ­
so algorithm is exponential time 
not polynomial time. 
) 
* 
Check-in 12.3 
Is $""%!""#$ ∈ P ? 
(a) Definitely Yes. You have a polynomial-time algorithm. 
(b) Probably Yes. It should be similar to showing !""#$ ∈ P. 
(c) Toss up. 
(d) Probably No. Hard to beat the exponential algorithm. 
(e) Definitely No. You can prove it! 
Check-in 12.3 
11 
","72.05506134033203","7","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_11_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"12","Why is proving a problem to be NP-complete considered strong evidence that it lacks a polynomial time solution?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","71.94214630126953","8","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"12","Why is proving a problem to be NP-complete considered strong evidence that it lacks a polynomial time solution?"," 
  
 
 
 
 
 
 
 
   
 
 
 
  
 
 
  
 
 
 
  
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
   
 
 
 
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
   
 
 
 
 
  
Unsolved Problem
Quick Review 
Defn: TIME ! "" 
= {%| some deterministic 1-tape TM ' decides % 
and ' runs in time ( ! "" } 
Defn: P = ⋃+ TIME(""+)
= polynomial time decidable languages 
./01 = 2, 4, ! 2 is a directed graph with a path from 4 to ! } 
Theorem: ./01 ∈ P 
2
1/'./01 = 2, 4, ! 2 is a directed graph with a path from 4 to !
4 
!
that goes through every node of 2 } 
1/'./01 ∈ P ? 
[connection to factoring] 
2 
","71.8822021484375","9","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_2_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"12","Why is proving a problem to be NP-complete considered strong evidence that it lacks a polynomial time solution?","§ Problem is exponen<al 
§ Have we overturned the laws of the universe? 
§ Is dynamic programming a miracle? 
§ No, but computa<onal complexity can be subtle 
§ Running <me of fastMaxVal is governed by number of 
dis<nct pairs, <toConsider, avail> 
◦Number of possible values of toConsider bounded 
by len(items)
◦Possible values of avail a bit harder to characterize 
◦Bounded by number of dis<nct sums of weights 
◦Covered in more detail in assigned reading 
How Can This Be? 
6.0002 LECTURE 2 
30 
","71.5833511352539","10","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_30_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"13","What is the comparison mentioned between biology and physics regarding reducibility?","the concept of reducibility. So reducibility is going to be a theme. You've got to get comfortable with reducibility, OK. So we're going to be focusing more on the notion that if you reduce A to B, and you know A is hard, that tells you B is also hard. OK, so I'm going to say that a few times during the course of today's lecture to try to help you get it. All right, here's a check in. A little bit sort of off to the side. But I thought it was a fun check in more. The question is, some people say biology is reducible to physics. Well, maybe everything is reducible to physics since physics tells you about the laws of the universe. And biology is part of the universe. So my question to you is, do you think? And there's no right answer here.","74.58723449707031","1","DPRSearchEngine","N28g_YBXY8Y.en-j3PyPqV-e1s_5_mp4","N28g_YBXY8Y.en-j3PyPqV-e1s","18.404J","9"
"13","What is the comparison mentioned between biology and physics regarding reducibility?","biology reducible to physics? Maybe yes, or maybe there are some things like consciousness which cannot be reduced to physics. Or maybe we don't know. So I'm curious to know your thoughts. But it does kind of use in a sense the notion of reducible in the spirit of what I have in mind here. In the sense that if you could fully understand physics, would that allow you to fully understand biology? OK, here we are. We're almost-- kind of interesting, though not too unexpected I suppose. So we are, I think, just about done. 5 seconds, pick anything if you want to get credit for this and you haven't selected yet. Ready to go, ending polling. Here are the results. And as I say, there's no right answer here. But if I had been in the class, I would have picked B. But I'm not surprised, especially in an MIT crowd that A is the winner, all right. Let's continue. OK, so now we're going to use reducibility again. This is going to be yet another example like the HALT TM example, but a little bit harder. And we're going to be doing this. You know, next lecture, we're going to be doing more reducibilities but much harder. So we really got to get really comfortable, all right.","71.15650939941406","2","DPRSearchEngine","N28g_YBXY8Y.en-j3PyPqV-e1s_6_mp4","N28g_YBXY8Y.en-j3PyPqV-e1s","18.404J","9"
"13","What is the comparison mentioned between biology and physics regarding reducibility?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
    
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Reducibility – Concept 
If we have two languages (or problems) ! and "", then 
! is reducible to "" means that we can use "" to solve !. 
Example 1: Measuring the area of a rectangle 
is reducible to measuring the lengths of its sides. 
Example 2: We showed that !NFA is reducible to !DFA . 
Example 3: From Pset 2, PUSHER is reducible to 'CFG . 
(Idea- Convert push states to accept states.) 
If ! is reducible to "" then solving "" gives a solution to !. 
- then "" is easy →! is easy. 
- then ! is hard →"" is hard. 
this is the form we will use 
3 
Check-in 9.1 
Is Biology reducible to Physics? 
(a) Yes, all aspects of the physical world 
may be explained in terms of Physics, 
at least in principle. 
(b) No, some things in the world, maybe 
life, the brain, or consciousness, 
are beyond the realm pf Physics. 
(c) I’m on the fence on this question! 
Check-in 9.1 
","69.71013641357422","3","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_3_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"13","What is the comparison mentioned between biology and physics regarding reducibility?","I guess they still do in 8.01 maybe-- that every effect has a cause. An apple falls from the tree because of gravity, and you know where it's going to land. And the world can be understood causally. And people believed this really for quite a long time, most of history, until the early part of the 20th century, when the so-called Copenhagen doctrine was put forth. The doctrine there from Bohr and Heisenberg, two very famous physicists, was one of what they called causal nondeterminism. And their assertion was that the world at its very most fundamental level behaves in a way that you cannot predict. It's OK to make a statement that x is highly likely to occur, almost certain to occur, but for no case can you make a statement x will occur. Nothing has a probability of one. This was hard for us to imagine today, when we all know quantum mechanics. But at the turn of the century, this was a shocking statement. And two other very well-known physicists, Albert Einstein and Schrodinger, basically said, no, this is wrong. Bohr, Heisenberg, you guys are idiots. It's just not true. They probably didn't call them idiots. And this is most exemplified by Einstein's famous quote that ""God does not play dice,"" which is indicative of the fact that this was actually a discussion that permeated not just the world of physics, but society in general people really turned it into literally a religious issue, as did Einstein. Well, so now we should ask the question, does it really matter? And to illustrate that, I need two coins. I forgot to bring any coins with me. Does anyone got a coin they can lend me? AUDIENCE: I have some coins. JOHN GUTTAG: All right. Now, this is where I see how much the students trust me. Do I get a penny? Do I get a silver dollar? So what do we got here? This is someone who's entrusting me with quarters, not so bad. So we'll take these quarters, and we'll shake them up, and we'll put them down on the table. And now, we'll ask a question-- do we have two heads, two tails, or one head and one tail? So who thinks we have two heads? Who thinks we have two tails? Who thinks we have one of each? Well, clearly, everyone except a few people-- for example, the Indians fan, who clearly believe in the counterfactual-- made the most probabilistic decision. But in fact, there is no nondeterminism here. I know the answer. And so in some sense, it doesn't matter whether it's deterministic, because in fact, it's not causally nondeterministic. The answer is quite clear, but you don't know the answer. And so whether or not the world is inherently unpredictable, the fact that we never have complete knowledge of the world suggests that we might as well treat it as inherently unpredictable. And so this is called predictive nondeterminism. And this really is what's going to underline pretty much everything else we're going to be doing here. No comments about that? I wouldn't do that to you. Thank you. I know you are wishing to get interest on the money, but you don't get any. AUDIENCE: Was it heads or tails? JOHN GUTTAG: What was that? So when we think about nondeterminism in computation,","68.39798736572266","4","DPRSearchEngine","-1BnXEwHUok.en-qlPKC2UN_YU_2_mp4","-1BnXEwHUok.en-qlPKC2UN_YU","6.0002","4"
"13","What is the comparison mentioned between biology and physics regarding reducibility?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
Reducibility terminology 
Why do we use the term “reduce”? 
When we reduce ! to "", we show how to solve ! by using "" 
and conclude that ! is no harder than "". (suggests the ≤$ notation) 
Possibility 1: We bring !’s difficulty down to ""’s difficulty. 
Possibility 2: We bring ""’s difficulty up to !’s difficulty. 
11 
","68.09484100341797","5","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_11_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"13","What is the comparison mentioned between biology and physics regarding reducibility?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
Use our knowledge that !TM is undecidable to show other 
problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
10 
","66.31913757324219","6","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_10_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"13","What is the comparison mentioned between biology and physics regarding reducibility?","says, ""if you can't prove what you want to prove, demonstrate something else and pretend they are the same thing. In the daze that follows the collision of statistics with the human mind, hardly anyone will notice the difference."" And indeed, empirically, he seems to be right. So let's look at some examples. Here's one I like. This is from another famous statistician called Anscombe. And he invented this thing called Anscombe's Quartet. I take my hat off now. It's too hot in here. A bunch of numbers, 11 x, y pairs. I know you don't want to look at the numbers, so here are some statistics about them. Each of those pairs has the same mean value for x, the same mean for y, the same variance for x, the same variance for y. And then I went and I fit a linear regression model to it. And lo and behold, I got the same equation for everyone, y equals 0.5x plus 3. So that raises the question, if we go back, is there really much difference between these pairs of x and y? Are they really similar? And the answer is, that's what they look like if you plot them. So even though statistically they appear to be kind of the same, they could hardly be more different, right? Those are not the same distributions. So there's an important moral here, which is that statistics about data is not the same thing as the data itself. And this seems obvious, but it's amazing how easy it is to forget it. The number of papers I've read where I see a bunch of statistics about the data but don't see the data is enormous. And it's easy to lose track of the fact that the statistics don't tell the whole story. So the answer is the old Chinese proverb, a picture is worth a thousand words, I urge you, the first thing you should do when you get a data set, is plot it. If it's got too many points to plot all the points, subsample it and plot of subsample. Use some visualization tool to look at the data itself. Now, that said, pictures are wonderful. But you can lie with pictures. So here's an interesting chart. These are grades in 6.0001 by gender. So the males are blue and the females are pink. Sorry for being such a traditionalist. And as you can see, the women did way better than the men. Now, I know for some of you this is confirmation bias. You say, of course. Others say, impossible, But in fact, if you look carefully, you'll see that's not what this chart says at all. Because if you look at the axis here, you'll see that actually there's not much difference. Here's what I get if I plot it from 0 to 5. Yeah, the women did a little bit better. But that's not a statistically-significant difference. And by the way, when I plotted it last year for 6.0002, the blue was about that much higher than the pink. Don't read much into either of them. But the trick was here, I took the y-axis and ran it from 3.9 to 4.05. I cleverly chose my baseline in such a way to make the difference look much bigger than it is. Here I did the honest thing of put the baseline at 0 and run it to 5. Because that's the range of grades at MIT. And so when you look at a chart, it's important to keep in mind that you need to look at the axis labels and the scales.","66.27702331542969","7","DPRSearchEngine","K2SC-WPdT6k.en-qlPKC2UN_YU_6_mp4","K2SC-WPdT6k.en-qlPKC2UN_YU","6.0002","14"
"13","What is the comparison mentioned between biology and physics regarding reducibility?"," 
 
 
 
 
 
  
 
Newtonian Mechanics  
Every effect has a cause 
The world can be understood causally  
6.0002 LECTURE 4 
4
","66.09858703613281","8","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_4_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"13","What is the comparison mentioned between biology and physics regarding reducibility?"," 
 
  
Changing the Cutoff  
Try p = 0.1 
Try p = 0.9 
Accuracy = 0.493 
Accuracy = 0.656 
Sensitivity = 0.976 
Sensitivity = 0.176 
Specificity = 0.161 
Specificity = 0.984 
Pos. Pred. Val. = 0.444 
Pos. Pred. Val. = 0.882 
6.0002 LECTURE 13  
31  
","65.56629943847656","9","DPRSearchEngine","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13_31_pdf","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13","6.0002","13"
"13","What is the comparison mentioned between biology and physics regarding reducibility?","The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. JOHN GUTTAG: Hello, everybody. Well, here we are at the last lecture. We're going to finish talking about statistical sins and then do a little bit of a wrap-up. Let's look at a hot topic-- global fiction-- or global warming, fact or fiction. You've done a problem set related","65.22175598144531","10","DPRSearchEngine","iOZVbILaIZc.en-qlPKC2UN_YU_1_mp4","iOZVbILaIZc.en-qlPKC2UN_YU","6.0002","15"
"15","What condition must an NFA satisfy to accept the empty string when using closure under star?"," 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Generalized NFA 
Defn: A Generalized Nondeterministic Finite Automaton (GNFA) is 
similar to an NFA, but allows regular expressions as transition labels 
a
a ∗ b ∗ 
ab
!1 
#1 
#2 
For convenience we will assume: 
b 
ε 
- One accept state, separate from the start state 
∅ 
- One arrow from each state to each state, except 
a ∪ b 
aab 
a) only exiting the start state 
#3 
#4 
b) only entering the accept state 
ε 
We can easily modify a GNFA to have this special form. 
3 
","78.69898986816406","1","DPRSearchEngine","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3_3_pdf","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3","18.404J","3"
"15","What condition must an NFA satisfy to accept the empty string when using closure under star?"," 
 
 
 
 
 
  
  
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
  
Acceptance Problem for DFAs 
Let $DFA = !, # ! is a DFA and ! accepts #} 
Theorem: $DFA is decidable 
Proof: Give TM *A−DFA that decides $DFA . 
*A−DFA = “On input , 
Shorthand: 
1. 
Check that , has the form !, # where 
if not. 
On input !, # 
! is a DFA and # is a string; reject 
2. 
Simulate the computation of ! on #. 
3. 
If ! ends in an accept state then accept. 
If not then reject.” 
input tape contains !, # 
- = ./, … , .1 , Σ = 0,1 , 5 = ⋯, ./, 7 = ⋯ , # = 01101
*A−DFA 
! 
# 
.8 , 9 
work tape with current state and input head location 
3 
","76.28131866455078","2","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_3_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"15","What condition must an NFA satisfy to accept the empty string when using closure under star?"," 
 
 
  
  
 
 
  
 
  
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Emptiness Problem for DFAs 
Let !DFA = & & is a DFA and ' & = ∅} 
Theorem: !DFA is decidable 
Proof: Give TM *E−DFA that decides !DFA . 
*E−DFA = “On input & 
[IDEA: Check for a path from start to accept.] 
1. 
Mark start state. 
2. 
Repeat until no new state is marked: 
Mark every state that has an incoming arrow 
from a previously marked state. 
3. 
Accept if no accept state is marked. 
Reject if some accept state is marked.” 
5 
","74.99596405029297","3","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_5_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"15","What condition must an NFA satisfy to accept the empty string when using closure under star?"," 
 
 
    
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Return to Closure Properties 
Recall Theorem: If !"", !$ are regular languages, so is !"" ∪!$ 
(The class of regular languages is closed under union) 
New Proof (sketch): Given DFAs &"" and &$ recognizing !"" and !$ 
&$
&"" 
ε 
ε 
& 
Construct NFA & recognizing !"" ∪!$ 
Nondeterminism 
parallelism 
vs 
guessing 
7 
","74.5622329711914","4","DPRSearchEngine","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_7_pdf","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2","18.404J","2"
"15","What condition must an NFA satisfy to accept the empty string when using closure under star?"," 
 
    
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Closure under ∘ (concatenation) 
Theorem: If ""#, ""% are regular languages, so is ""#""% 
Proof sketch: Given DFAs &# and &# recognizing ""# and ""% 
Construct NFA & recognizing ""#""% 
& 
&%
&# 
ε
ε 
& should accept input ' 
if ' = )* where 
&# accepts ) and &% accepts *. 
' = 
)
* 
Nondeterministic &′ has the option 
to jump to &% when &# accepts. 
8 
","74.33436584472656","5","DPRSearchEngine","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_8_pdf","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2","18.404J","2"
"15","What condition must an NFA satisfy to accept the empty string when using closure under star?"," 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
a
-
)
⋯
Tableau for ! on "" 
Defn: An (accepting) tableau for NTM ! on "" is an #$×#$ table 
representing an computation history for ! on "" on an accepting branch 
of the nondeterministic computation. 
#$
#$
""* ⋯"", ˽ … ˽
&'
&
""( "")
← Start configuration for ! on "" 
Construct 45,7 to “say” ! accepts "".
⋮ 
45,7 “says” a tableau for ! on "" exists. 
45,7 = 4cell ∧ 4start ∧ 4move ∧ 4accept
⋯ &accept ⋯
← Accepting configuration 
4 
","73.14219665527344","6","DPRSearchEngine","8212b19fc5a34f500ca6acf03a3a7d74_MIT18_404f20_lec16_4_pdf","8212b19fc5a34f500ca6acf03a3a7d74_MIT18_404f20_lec16","18.404J","16"
"15","What condition must an NFA satisfy to accept the empty string when using closure under star?"," 
  
 
  
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
   
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
    
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
PDA – Formal Definition 
Defn: A Pushdown Automaton (PDA) is a 6-tuple ("", Σ, Γ, &, '0, )) 
Σ input alphabet 
Γ stack alphabet 
&: Q×Σ.×Γ. → 0(""×Γ.) 
Accept if some thread is in the accept state 
& ', a, c = 
45, d , 47, e 
at the end of the input string. 
Example: PDA for 9 = {;;ℛ| ; ∈ 0,1 ∗} Sample input: 
0 1 1 1 1 0 
1) Read and push input symbols. 
Nondeterministically either repeat or go to (2). 
The nondeterministic forks replicate the stack. 
2) Read input symbols and pop stack symbols, compare. 
If ever ≠ then thread rejects. 
This language requires nondeterminism. 
Our PDA model is nondeterministic. 
3) Enter accept state if stack is empty. (do in “software”) 
7 
","72.80288696289062","7","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_7_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"15","What condition must an NFA satisfy to accept the empty string when using closure under star?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
Use our knowledge that !TM is undecidable to show other 
problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
10 
","72.59764099121094","8","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_10_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"15","What condition must an NFA satisfy to accept the empty string when using closure under star?"," 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
  
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
  
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
ac 
al 
tr 
sta 
sta 
a 
c 
p 
e 
n 
r 
t 
h 
p 
s 
t sta 
e 
ab 
i 
t s 
ti 
s 
e 
o 
t 
n f 
a 
t 
te 
te 
u 
s 
nction 
NFA – Formal Definition 
!1 
a 
a 
#1 
#2 
b 
#3 
a,ε 
#4 
b 
Defn: A nondeterministic finite automaton (NFA) 
! is a 5-tuple ((, Σ, +, #0, -) 
Ways to think about nondeterminism: 
Computational: Fork new parallel thread and 
accept if any thread leads to an accept state. 
- all same as before except + 
Mathematical: Tree with branches. 
- +: (×Σε →2 ( = 4 4 ⊆(} 
Accept if any branch leads to an accept state. 
power set 
Σ ∪{ε} 
Magical: Guess at each nondeterministic step 
- In the !7 example: + #7, a = {#7, #9} 
which way to go. Machine always makes the 
+ #7, b = ∅ 
right guess that leads to accepting, if possible. 
5 
","72.43769073486328","9","DPRSearchEngine","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_5_pdf","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2","18.404J","2"
"15","What condition must an NFA satisfy to accept the empty string when using closure under star?"," 
  
  
  
 
  
 
 
 
 
  
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
  
  
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
!""! is undecidable 
Recall !""! = ! ! has a match } 
Theorem: !""! is undecidable 
Proof: Show %TM is reducible to !""!. Uses the computation history method. 
()
Technical assumption: Match must start with 
. Can fix this assumption. 
*) 
Assume that TM + decides !""! 
Construct TM , deciding %TM 
, = “on input -, / 
1. Construct PCP instance !0,1 where a match corresponds to 
a computation history for - on /. 
2.  Use + to determine whether !0,1 has a match. 
3. Accept if yes. Reject if no.” 
9 
","72.23429870605469","10","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_9_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"16","What arguments are made to support using a one-tape Turing machine as a model for defining time complexity classes?"," 
 
 
 
 
 
 
 
 
  
 
  
 
   
 
 
 
 
  
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Model Dependence 
Number of steps to decide ! = a#b# $ ≥0 depends on the model. 
• 1-tape TM: '() log )) 
• Multi-tape TM: '()) 
Computability theory: model independence (Church-Turing Thesis) 
Therefore model choice doesn’t matter. Mathematically nice. 
Complexity Theory: model dependence 
But dependence is low (polynomial) for reasonable deterministic models. 
We will focus on questions that do not depend on the model choice. 
So… we will continue to use the 1-tape TM as the basic model for complexity. 
6 
","81.7403564453125","1","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_6_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"16","What arguments are made to support using a one-tape Turing machine as a model for defining time complexity classes?"," 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Turing Machines (TMs) 
head 
˽ ˽
a
b
a 
. . .
b b
Finite 
read/write input tape 
control 
1) Head can read and write 
2) Head is two way (can move left or right) 
3) Tape is infinite (to the right) 
4) Infinitely many blanks “˽“ follow input 
5) Can accept or reject any time (not only at end of input) 
8 
","80.7655029296875","2","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_8_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"16","What arguments are made to support using a one-tape Turing machine as a model for defining time complexity classes?","of the reasonable models, they're all what are called polynomially related if each can simulate the other with, at most, a polynomial overhead. So if one of the machines can use this t of n time, the other machine that's simulating it would use t to the k of n time for some k. That's what it means for the two machines to be polynomially related. And all reasonable deterministic models are polynomially related. So as we've already seen, one tape and multi-tape Turing machines are polynomially related, because converting multi-tape to one tape blows you up by, at most, squaring. So k equals 2 in this case. Multidimensional Turing machines, again, polynomially related, the random access machine, which I'm not going to define, but it's the machine that you might imagine-- you would, I'm sure they must define in some form in the algorithms classes, polynomially related. Cellular automata, which are just arrays of finite automata that can communicate with each other, similarly. All the reasonable deterministic models, again, classical models, I'm not talking about quantum computing, are polynomially related. So we are-- that kind of justifies our choice in picking one of them, as long as we're going to ask questions which don't depend upon the polynomial.","80.76200866699219","3","DPRSearchEngine","asjAc90L8rE.en-j3PyPqV-e1s_10_mp4","asjAc90L8rE.en-j3PyPqV-e1s","18.404J","12"
"16","What arguments are made to support using a one-tape Turing machine as a model for defining time complexity classes?"," 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Relationships among models 
Informal Defn: Two models of computation are polynomially related 
if each can simulate the other with a polynomial overhead: 
So ! "" time → !$("") time on the other model, for some '. 
All reasonable deterministic models are polynomially related. 
• 1-tape TMs 
• multi-tape TMs 
• multi-dimensional TMs 
• random access machine (RAM) 
• cellular automata 
9 
","80.57545471191406","4","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_9_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"16","What arguments are made to support using a one-tape Turing machine as a model for defining time complexity classes?","Turing machines, as we set them up, they have-- on any input w, they have three possible outcomes. The Turing machine can halt and accept w, can halt and reject w, or it can go forever on w, which is rejecting by looping in our language. A Turing machine can recognize a language, the collection of old strings that it accepts. And if the Turing machine always halts, we say it decides the language, and it's a decider, and so therefore, that language is a decided language, a Turing decider. Often we just say decidable, because we don't really have a notion of deciding in other models, so we often talk about Turing-recognizable or just decidable. Or we'll sometimes just say recognizable, when we understand that we're talking about Turing machines. We briefly talked about encodings. When you write it inside brackets, some objects-- whatever they are-- could be strings, could be machines, could be graphs, could be polynomials-- we're representing them as strings, and maybe a collection of objects together represented as a string in order so that we can present that information as an input to a machine. And we talk about-- our languages our collections of strings. And a notation for writing a Turing machine is going to be simply that English description put inside quotation marks to represent our informal way of talking about the formal object that we could produce, if we wanted to. But we're never going to ask you to do that. OK, so now let me see. Let's just take a quick break, as I promised. If there's any quick questions here, you can ask. Let's see-- got a lot of questions here. All right, why don't we move on? And some of these things are good questions.","80.41128540039062","5","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_2_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"16","What arguments are made to support using a one-tape Turing machine as a model for defining time complexity classes?","  
 
  
 
 
  
 
  
 
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
  
 
 
   
-
Review: Probabilistic TMs and BPP 
coin flip step 
each choice has 
Defn: A probabilistic Turing machine (PTM) is a variant of a NTM 
where each computation step has 1 or 2 possible choices. 
deterministic 
step 
50% probability 
Defn: For ! ≥0 say PTM $  decides language % with error probability !  
if for every &, Pr[ $  gives the wrong answer about & ∈% ] ≤! . 
Defn: BPP = % some poly-time PTM decides % with error !  = +⁄,  } Check-in 24.1 
Actually using a probabilistic algorithm 
Amplification lemma: 2−. /01 2 
presupposes a source of randomness. 
Can we use a standard pseudo-random 
number generator (PRG) as the source? 
& ∈% 
& ∉% 
(a) Yes, but the result isn’t guaranteed.
(b) Yes, but it will run in exponential time.
Many 
Few 
Few 
Many 
(c) No, a TM cannot implement a PRG. 
accepting 
rejecting 
accepting 
rejecting 
(d) No, because that would show P = BPP.
2 
Check-in 24.1 
","80.34165954589844","6","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_2_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"16","What arguments are made to support using a one-tape Turing machine as a model for defining time complexity classes?"," 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
   
 
 
 
 
   
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
  
 
 
  
 
  
 
  
Turing machine model – review 
head 
˽ ˽ . . .
a
b
a
b
b
Finite 
read/write input tape 
control 
On input ! a TM "" may halt (enter #acc or #rej) 
) is T-recognizable if ) = +("") for some TM "". 
or loop (run forever). 
) is T-decidable if ) = +("") for some TM decider "". 
So "" has 3 possible outcomes for each input !: 
halts on all inputs 
1. Accept ! (enter #acc ) 
Turing machines model general-purpose computation. 
2. Reject ! by halting (enter #rej ) 
Q: Why pick this model? 
3. Reject ! by looping (running forever) 
A: Choice of model doesn't matter. 
All reasonable models are equivalent in power. 
Virtues of TMs: simplicity, familiarity. 
2 
","79.90584564208984","7","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_2_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"16","What arguments are made to support using a one-tape Turing machine as a model for defining time complexity classes?","And I'm happy to try to take questions along the way as we're waiting for the time to end. So let's see, let me put this up here. Let me try to take some of your questions. So someone is asking me about quantum computers as reasonable models of-- you may say a quantum computer is a reasonable model of computation. And that's fine. I would not say it's a reasonable model of deterministic computation, at least from our standpoint. Let's not quibble about the words. I'm not including quantum computers in the collection of machines that I have in mind right now when I'm talking about the reasonable models of deterministic computation that we're going to be discussing. Let's see. Oh, because a bunch of people apparently are asking the TAs why all regular languages can be done in order n. So if you think about a DFA, which processes an input of length n with n steps, and a DFA is I'm going to be a type of Turing machine that never writes on its tape, so if a DFA can do it in n steps, the Turing machine can do it in n steps. And so therefore, every regular language can be done in order n steps on a Turing machine. Not sure where the confusion is. So please message me if you're still not getting it. OK, somebody saying why are we using one tape Turing machines instead of random access? Wouldn't it be better to use the random access machines? If you were using-- if you're trying to do algorithms, yes. That's a more reasonable model. We're trying to prove things about the computation. And from that standpoint, we want to use as simple a model as possible. Trying to prove things using random access computers is possible. It'd be very messy. So that's why we don't use random access machines to prove the kinds of things we're going to be proving about computation that are really the meat and potatoes of this course. So I mean, there's compelling reasons why you would want to use a simple model like a Turing machine, but not a powerful model like a random access computer. So somebody's asking me, does the class time order n log log n have any elements? Yes, it has all the regular languages, but nothing else. Order n log log is it's only the regular languages. You have to go all the way up to n log n before you get something non-regular. Someone's asking me are we going to talk about how the random access model works? No. That's beyond the scope of this course, outside of what we're going to be doing. We're going to talk about Turing machines. Not because we care so much about Turing machines. But I'm trying to prove things about computation. And the Turing machines are a convenient vehicle for doing that. Our candle has burned out. Why don't we return, then, to the next slide. So everybody come back. So this answers one of the questions I got on the chat. What actually is the dependency between multi-tape Turing machines and one tape Turing machines? Can we bound that in general? Yes, we can. We're going to show that converting a multi-tape Turing machine to a one tape Turing machine can, at most, blow up the amount of time that's necessary by squaring. No, I acknowledge it's a lot. But it still allows you-- but it's still small compared with an exponential increase. And we're going to be focusing, in this course, on things like the difference between polynomial and exponential, not between the different-- not between the difference of-- not the difference between n squared and n cubed. That's going to be less of a factor, less of an issue for us. So the way I'm showing this theorem is that if you have a multi-tape Turing machine that can do a language in a certain amount of time, then it's in the time complexity class of that time bound squared. And the way I'm just saying that is because this is the bound that's utilizing the one tape model. So another way of saying that is converting multi-tape to one tape squares the amount of time you need at most. So the way we're going to prove that is simply by going back and remembering the conversion that we already presented from multi-tape to one tape. And observe that if we analyze that conversion, it just ends up squaring the amount of time that the multi-tape used. So why is that? So if you remember, let's just make sure we're all together on this, the way the single tape machine S simulates the multi tape Turing machine M is that it takes the contents of each of M's tapes, up to the place where there's infinitely many blanks. Obviously you don't store the infinite part. But the active portion of each of M's tapes, you're going to store them consecutively in separate blocks on S's tape, on S's only tape. And now every time M makes one move, S has to scan its entire tape to see what's under each of the heads and to do all the updating. So to simulate one step of M's computation, S is going to use order of t of n steps, where t of n is the total running time that M is going to use. So why is t of m steps coming up here? Well, that's because you have to measure how-- S is going to make a scan across its tape. How big can its tape be? Well M, if it's trying to use as much tape as possible, can use, at most, t of n tape on each of-- t of n cells on each of its tapes. So altogether, they're just going to be some constant number of times t of n cells on S's tape. Do you see that? So each one of these is going to be, at most, t of n long. So this all together is going to be order t of n long. Because what can M do? It could send its head out, say the head on this tape here, moving as fast as possible to the right, using as much tape as it can. But you can only use t of n cells in t of n time. So this is going to be order t of n. So one step of computation is going to be t of n steps on S's computation. But M itself has t of n steps. So it's going to be t of n times t of n for the total number of steps that S is going to end up using. And that's where the squaring comes from. Similar results, I'm not going to do lots of simulations of one model by another. I think that you'll get the idea. And you can, if you're interested, you can study those on your own. But you can convert multidimensional Turing machines to one tape Turing machines, one tape ordinary linear-- one tape, one dimensional machines.","79.66069793701172","8","DPRSearchEngine","asjAc90L8rE.en-j3PyPqV-e1s_9_mp4","asjAc90L8rE.en-j3PyPqV-e1s","18.404J","12"
"16","What arguments are made to support using a one-tape Turing machine as a model for defining time complexity classes?"," 
 
 
 
 
 
 
 
 
 
  
 
  
 
  
 
 
 
  
 
 
 
 
18.404/6.840 Lecture 7 
Last time: 
- Equivalence of variants of the Turing machine model 
a. Multi-tape TMs 
b. Nondeterministic TMs 
c. Enumerators 
- Church-Turing Thesis 
- Notation for encodings and TMs 
Today: (Sipser §4.1) 
- Decision procedures for automata and grammars 
1 
","79.27291870117188","9","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_1_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"16","What arguments are made to support using a one-tape Turing machine as a model for defining time complexity classes?"," 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
   
 
    
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
Linearly Bounded Automata 
Defn: A linearly bounded automaton (LBA) is a 1-tape TM 
that cannot move its head off the input portion of the tape. 
LBA 
a a b a a b a 
Tape size adjusts to length of input. 
Let !LBA = &, ( LBA & accepts ( } 
Theorem:  !LBA is decidable 
Proof: (idea) If & on ( runs for long, it must be cycling. 
Decider for !LBA: 
Claim: For inputs of length ), an LBA can have 
.A−LBA = “On input &, ( 
only * ×)× Γ - different configurations. 
1.  Let ) = |(|. 
Therefore, if an LBA runs for longer, it must repeat some 
2. Run & on ( for * ×)× Γ - steps. 
configuration and thus will never halt. 
3. If has accepted, accept. 
4. If it has rejected or is still running, reject.” 
must be looping 
7 
","79.0176773071289","10","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_7_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"17","What is the definition of EXPTIME in terms of complexity classes?","  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
Exponential Complexity Classes 
Defn: EXPTIME = ⋃"" TIME 2 $% 
EXPSPACE = ⋃"" SPACE 2 $% 
≠
Time Hierarchy Theorem 
L ⊆ NL 
≠
⊆ P ⊆ NP ⊆ PSPACE 
≠
⊆ EXPTIME ⊆ EXPSPACE 
Space Hierarchy Theorem 
Defn: & is EXPTIME-complete if 
1) 
& ∈ EXPTIME 
2) 
For all ( ∈ EXPTIME, ( ≤* & 
Same for EXPSPACE-complete 
Theorem:  If B is EXPTIME-complete then & ∉ P 
intractable 
Theorem:  If B is EXPSPACE-complete then & ∉ PSPACE (and & ∉ P) 
Next will exhibit an EXPSPACE-complete problem 
3 
","76.47392272949219","1","DPRSearchEngine","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_3_pdf","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22","18.404J","22"
"17","What is the definition of EXPTIME in terms of complexity classes?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","72.96165466308594","2","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"17","What is the definition of EXPTIME in terms of complexity classes?","[SQUEAKING][RUSTLING][CLICKING] ERIK DEMAINE: Today we're going to, in one lecture, cover an entire field, which is computational complexity. It's sort of-- it meets algorithms in an interesting way, which is, algorithms is mostly about showing how to solve problems well and showing that you can solve a problem well. And computational complexity is more about the lower bound side, proving that you can't prove-- you can't solve a problem very well, you can't find a good algorithm to solve it. We've seen a little bit about lower bounds several lectures ago, proving search and sorting lower bounds in a bounded branching decision tree model. But these are much stronger notions of badness. This is not about n versus n log n or constant versus log n. This is about polynomial versus exponential, which has been the sort of bread-and-butter model in this class. Polynomial is a good running time, and we're always striving for that. Exponential is usually pretty trivial to get. And so we're going to talk about some different-- they're called complexity classes that talk about this issue and different ways to prove hardness. This is a pretty high-level lecture, so you're not going to be expected to be able to prove hardness. But you'll get a flavor of what it's like, and this will segue nicely into other follow-on classes, which is-- we're at pretty much the end of 006, so natural to talk about what other things you might study. One result we'll prove today is that most problems actually have no algorithm, which is kind of shocking, and lots of other fun things. So let's get started with the notion of P. This is the set of all problems solvable in polynomial time. We talked about what polynomial time means a bunch last lecture. So just recall that polynomial time means polynomial in the problem size, which I'll denote as n here, the number of words in your input. OK, so these are the problems that are efficiently solvable. P is the set of all of them. And for contrast, EXP is the set of all problems solvable in exponential time. It's the problems solvable in exponential time. Exponential here means something like 2 to the n to the constant. That's one reasonable definition of exponential, so just the exponentiation of this-- of polynomial. So as you might expect, most-- every problem that we've talked about in this class so far can be solved in exponential time rather easily. And algorithms, in some sense, is about distinguishing these two, which problems are in P versus are in say EXP minus P. So to formalize this a little bit, I'm going to draw a picture, which is a bit of a simplification of reality, but for the purposes of this class will suffice, and I think is a really helpful way to think about things, which is to have a big axis for-- a single axis for, how hard is your problem, what is the difficulty of solving your problem? And I want to be sure to leave-- so the easiest problems are over here. And each problem is a dot on this axis. Hardest problems are way down the line. And I want to make sure to leave enough space for all the things that I care about. So P, I'm just going to call this segment up front. And then I'm going to have a bigger thing for exponential time. So this is just to say that P is nested inside EXP. Every problem that can be solved in polynomial time can also be solved in exponential time because polynomial is less than or equal to exponential. These are just upper bounds. Being an EXP means you're somewhere from this line to the left. Being in P means you're somewhere from this line to the left, in terms of difficulty. But formally, we would write P is contained in EXP as sets. In fact, they're also known to be different from each other. There are problems that can be solved in exponential time that cannot be solved in polynomial time. For example-- I'll put that here, sure. For example, n by n chess is in exponential time, but not polynomial time. So what is the n by chess problem? This is, I give you an n by n chessboard, and I describe to you a position. Here's where all the white pieces are. Here's where all the black pieces are. You can have an arbitrary number of queens and bishops and pawns of each color, of course, up to n squared of them so they don't overlap each other. And I want to know, does white win from this position? Let's say it's white to move. Can white win? And that problem can be solved in an exponential time by exploring the entire tree of all possible games. But it cannot-- but you can prove that it cannot be solved in polynomial time. So that's a nice example.","72.74015808105469","3","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_1_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"17","What is the definition of EXPTIME in terms of complexity classes?","So first, let's understand what we mean by the time used by a non-deterministic machine. And what we mean by the time used is, we're looking at each individual branch individually, separately. So a non-deterministic machine, we'll say, runs in a certain amount of time if all of the branches halt within that amount of time. So what we do not mean that the total amount of usage, the total amount of effort by adding up all the branches is at most T of n. It's just that each branch individually uses at most T of n. That's just going to be our definition. And it's going to turn out to be the right way to look at this to get something useful. So now we're going to define the analogous complexity class associated to non-deterministic computation, which we'll call non-deterministic time. So non-deterministic time T of n is the set of all languages that you can do with a non-deterministic machine that runs in order T of n time. Just think back to the definition we had for deterministic complexity, the time class-- or sometimes people call it dtime to emphasize the difference. But let's just say we're calling it in this course time versus ntime. So TIME[T(n)] is all of the language that you can do with the one-tape Turing machine that's deterministic. But this here is a non-deterministic Turing machine for non-deterministic time. So the picture that is good to have in your head here would be if you think of non-determinism in terms of a computation tree thinking of all the different branches of the non-determinism. All of those branches have to halt and they have to halt within the time bound. So imagine, here, this is T of n time. All of the branches have to halt within T of n steps for this, a non-deterministic Turing machine to be running in T of n time and to be doing a language in the NTIME[T(n)] class. And by analogy with what we did before, the class NP is the collection of all languages that you can do non-deterministically in polynomial time. So it's the union over all of the ntime classes where the bound is polynomial. OK, so a lot of this should look very familiar, but we've just added a bunch of non-deterministic and a bunch of Ns in place. But the definitions are very similar. And one of the motivations we had for looking at the class P was that it did not depend on the choice of model, as long as the model was deterministic and reasonable. And the class NP is also going to not depend on the choice of model, as long as it's a reasonable non-deterministic model. So it's again a very natural class to look at from a mathematical standpoint. And it also captures something interesting, kind of, from a practical standpoint - which we're going to talk about over the next couple of slides - which is that it captures the problems where you can easily verify when you're a member of the language. OK, so we'll talk about that. But if you take, for example, the Hamiltonian path problem. When you find a member of the language, so that is a graph that does have a Hamiltonian path from s to t, you can easily verify that's true by simply exhibiting the path. Not all problems can be verified in that way. But the problems that are in NP have that special feature-- that when you have a member of the language, there's a way to verify that you're a member. So we're going to talk about that, because that's really the key to understanding NP-- this notion of verification. OK, so let me go-- there was a good question here. Let me just see if I want to answer that. Yeah, I mean, this is a little bit of a longer question than I want to fully respond to but-- well, let's turn to my next slide, which maybe sort bringing that out anyway.","72.60455322265625","4","DPRSearchEngine","1VhnDdQsELo.en-j3PyPqV-e1s_5_mp4","1VhnDdQsELo.en-j3PyPqV-e1s","18.404J","14"
"17","What is the definition of EXPTIME in terms of complexity classes?"," 
 
 
 
  
 
 
  
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Intro to Complexity Theory 
Computability theory (1930s - 1950s): 
Is A decidable? 
Complexity theory (1960s - present): 
Is A decidable with restricted resources? 
(time/memory/…) 
Example: Let ! = a#b# $ ≥0 . 
Q: How many steps are needed to decide !? 
Depends on the input. 
We give an upper bound for all inputs of length '. 
Called “worst-case complexity”. 
2 
","72.57035827636719","5","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_2_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"17","What is the definition of EXPTIME in terms of complexity classes?"," 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 18: Pseudopolynomial 
Lecture 18: Pseudopolynomial 
Dynamic Programming Steps (SRT BOT) 
1. Subproblem deﬁnition 
subproblem x ∈ X 
• Describe the meaning of a subproblem in words, in terms of parameters 
• Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence 
• Often multiply possible subsets across multiple inputs 
• Often record partial state: add subproblems by incrementing some auxiliary variables 
• Often smaller integers than a given integer (today’s focus) 
2. Relate subproblem solutions recursively 
x(i) = f(x(j), . . .) for one or more j < i 
• Identify a question about a subproblem solution that, if you knew the answer to, reduces 
the subproblem to smaller subproblem(s) 
• Locally brute-force all possible answers to the question 
3. Topological order to argue relation is acyclic and subproblems form a DAG 
4. Base cases 
• State solutions for all (reachable) independent subproblems where relation breaks down 
5. Original problem 
• Show how to compute solution to original problem from solutions to subproblem(s) 
• Possibly use parent pointers to recover actual solution, not just objective function 
6. Time analysis 
P 
• 
work(x), or if work(x) = O(W ) for all x ∈ X, then |X| · O(W )
x∈X 
• work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time 
","71.72236633300781","6","DPRSearchEngine","mit6_006s20_lec18_1_pdf","mit6_006s20_lec18","6.006","18"
"17","What is the definition of EXPTIME in terms of complexity classes?","So E TM is the emptiness problem for Turing machines. Is this language empty? I'm just going to give you a machine. I want to know, is this language empty or not? Does it accept something or is this language empty? That's going to be undecidable, no surprise, proof by contradiction. And we're going to show that A TM is reducible to E TM. So these things often take a very similar form. And I'm going to try to use the same form. So if you're feeling shaky on it, at least you'll get the form of the way the solution goes and that will help you maybe plug-in to solve problems, OK.","71.39323425292969","7","DPRSearchEngine","N28g_YBXY8Y.en-j3PyPqV-e1s_7_mp4","N28g_YBXY8Y.en-j3PyPqV-e1s","18.404J","9"
"17","What is the definition of EXPTIME in terms of complexity classes?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","71.29692840576172","8","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"17","What is the definition of EXPTIME in terms of complexity classes?","§ Time based on number of nodes generated 
§ Number of levels is number of items to choose from 
§ Number of nodes at level i is 2i 
§ So, if there are n items the number of nodes is 
◦ ∑𝑖=0↑𝑖=𝑛▒​2↑𝑖   
◦ I.e., O(​2↑𝑛+1 ) 
§ An obvious op<miza<on: don’t explore parts of tree 
that violate constraint (e.g., too many calories) 
◦ Doesn’t change complexity 
§ Does this mean that brute force is never useful? 
◦ Let’s give it a try 
Computa#onal Complexity 
6.0002 LECTURE 2 
8 
","71.10018157958984","9","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_8_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"17","What is the definition of EXPTIME in terms of complexity classes?","Whereas this is kind of an approximation algorithm, I'm approximating my outputs, this is an approximation algorithm from the standpoint of, well, there's a lot of problems that I can't solve efficiently. They're NP-hard. They're in EXP or even harder problems. But maybe I'm OK with not getting the optimal solution. So this is in the domain of optimization problems. So most of the dynamic programming problems that we gave you were optimization problems. They're the shortest paths problems. Those are optimization problems. Basically, the possible outputs are ranked in some way-- the distance of a path that you return or something like that. They're ranked in some way. There is an optimal one-- the one with the smallest metric or something like that. Well, in an approximation algorithm what I do is, OK, I get that it's computationally difficult for you to give me the longest simple path in this graph, or the shortest possible route for my traveling salesman, but maybe that's OK. I mean, my engineering Spidey-sense tells me that within 10% is fine. So maybe instead of giving me the most optimal thing, can I give you an algorithm that's guaranteed to be within a certain distance from the optimal thing? Usually, we're looking for constant factor approximations which have low constant, or maybe even have to do for worse if such things don't exist. OK, so that's approximation algorithms. Can we get close to an optimal solution in polynomial time? OK. And then the last way we could change things in, especially future classes, though sometimes they talk about this in 046","70.76101684570312","10","DPRSearchEngine","2NMtS1ecb3o.en-j3PyPqV-e1s_11_mp4","2NMtS1ecb3o.en-j3PyPqV-e1s","6.006","20"
"18","Why is co-NP a subset of PSPACE?"," 
 
 
 
 
 
 
  
 
  
 
 
   
 
 
 
    
 
 
 
 
 
 
  
  
 
 
 
 
  
 
 
 
  
 
 
NP ⊆ PSPACE 
Theorem: NP ⊆ PSPACE 
Proof: 
1. ""#$ ∈ PSPACE 
2. If # ≤' ( and ( ∈ PSPACE then # ∈ PSPACE 
PSPACE 
Defn: coNP = # # ∈ NP}
*#+,#$* ∈ coNP 
coNP 
NP
$#-$./.01 = 2 all assignments satisfy 2} ∈ coNP 
coNP ⊆ PSPACE (because PSPACE = coPSPACE) 
Or possibly: 
P 
P = PSPACE ? Not known. 
P = NP = coNP = PSPACE 
4 
","85.47859191894531","1","DPRSearchEngine","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17_4_pdf","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17","18.404J","17"
"18","Why is co-NP a subset of PSPACE?","≤ 
≤ 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
   
 
 
 
  
  
 
 
 
  
 
 
 
 
Why
% and not
%'%()* when defining PSPACE-complete?
- Reductions should be “weaker” than the class. Otherwise all
problems in the class would be reducible to each other, and then 
all problems in the class would be complete.
Theorem: +,!- is PSPACE-complete
PSPACE-completeness 
Defn: ! is PSPACE-complete if 
1) ! ∈ PSPACE 
2) For all # ∈ PSPACE, # ≤% ! 
If ! is PSPACE-complete and ! ∈ P then P = PSPACE. 
Check-in 18.1 
Knowing that +,!- is PSPACE-complete, 
what can we conclude if +,!- ∈ NP? 
Check all that apply. 
(a) P = PSPACE 
(b) NP = PSPACE 
(c) P = NP 
(d) NP = coNP 
5 
PSPACE-complete 
NP-complete 
PSPACE = 
NPSPACE 
NP
P 
Think of complete problems as the “hardest” 
in their associated class. 
Check-in 18.1 
","77.21495819091797","2","DPRSearchEngine","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18_5_pdf","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18","18.404J","18"
"18","Why is co-NP a subset of PSPACE?"," 
 
  
  
 
 
 
 
 
 
 
 
 
 
   
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Recap: Separating Complexity Classes 
L ⊆ NL 
≠
⊆ P ⊆ NP ⊆ PSPACE 
Space Hierarchy Theorem 
NL ⊆ SPACE log& ' ⊆, SPACE ' ⊆ PSPACE 
12 
Check-in 21.3 
Consider these two famous unsolved questions: 
1. 
Does L = P? 
2. 
Does P = PSPACE? 
What do the hierarchy theorems tell us about 
these questions? 
a) Nothing 
b) At least one of these has answer “NO” 
c) 
At least one of these has answer “YES” 
Check-in 21.3 
","76.68516540527344","3","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_12_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"18","Why is co-NP a subset of PSPACE?","  
 
  
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
  
    
   
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
PSPACE
NL
)*+,
E 22
E #/
E #0
. . . 
. . . 
Review: Hierarchy Theorems 
Theorems: 
SPACE ! "" # 
⊆, SPACE "" # 
for space constructible "". 
TIME ! "" # / log "" # 
⊆, TIME "" # 
for time constructible "". 
TIM
SPACE 22 
TIM 
SPACE #/ SPACE #0 
TIM 
TIME #.
SPACE #. 
Check-in 22.1 
Which of these are known to be true? 
Check all that apply. 
(a) TIME 22 ⊆, TIME 2234 
TIME 2.2
Corollary: NL ⊆, PSPACE 
(b) TIME 22 ⊆, 
Implies )*+, ∉ NL because the polynomial-time reductions in 
(c) NTIME #. 
the proof that )*+, is PSPACE-complete can be done in log space. 
⊆, PSPACE 
(d) NP ⊆, PSPACE 
2 
Check-in 22.1 
","75.45659637451172","4","DPRSearchEngine","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_2_pdf","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22","18.404J","22"
"18","Why is co-NP a subset of PSPACE?","  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
   
 
  
 
  
 
  
  
 
 
 
#""#$ problem 
Defn: #""#$ = &, ( Boolean formula & has exactly ( satisfying assignments} 
Let #& = the number of satisfying assignments of Boolean formula &. 
So #""#$ = &, ( ( = #&} 
Defn: Language * is NP-hard if # ≤, * for every # ∈ NP. 
(Note: * is NP-complete if * is NP-hard and * ∈ NP.) 
Theorem: #""#$ is coNP-hard 
Proof: Show ""#$ ≤. #""#$ 
/ & = ⟨&, 0⟩ 
To show coNP ⊆ IP we will show #""#$ ∈ IP 
8 
","75.27120971679688","5","DPRSearchEngine","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25_8_pdf","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25","18.404J","25"
"18","Why is co-NP a subset of PSPACE?"," 
  
  
 
 
 
 
 
 
 
    
 
 
  
 
 
 
 
 
 
 
 
  
 
  
    
 
 
 
  
 
   
    [ V is deterministic ]
    [ V ignores P ]
[ We won’t prove. Idea: explore all possible interactions in poly space. ]
Facts about IP – Checkin 25.2 
Which of the following is true? 
Check all that apply 
a) NP ⊆ IP 
b) BPP ⊆ IP 
c) IP ⊆ PSPACE 
Surprising Theorem: PSPACE ⊆ IP so IP = PSPACE 
We will prove only a weaker statement: coNP ⊆ IP 
7 
","74.74113464355469","6","DPRSearchEngine","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25_7_pdf","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25","18.404J","25"
"18","Why is co-NP a subset of PSPACE?"," 
 
 
  
 
   
   
  
   
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
  
 
   
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
Relationships between 
Time and SPACE Complexity 
Theorem: For ! "" ≥"" 
1) TIME ! "" 
⊆ SPACE ! "" 
2) SPACE ! "" 
⊆ TIME 2& ' ( 
= ⋃+ TIME ,' ( 
Proof: 
1) A TM that runs in !("") steps cannot use more than !("") tape cells. 
2) A TM that uses !("") tape cells cannot use more than ,' ( time 
without repeating a configuration and looping (for some ,). 
Corollary: P ⊆ PSPACE 
Theorem: NP ⊆ PSPACE [next slide] 
3 
","74.59355926513672","7","DPRSearchEngine","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17_3_pdf","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17","18.404J","17"
"18","Why is co-NP a subset of PSPACE?","Intuition for P and NP
NP = All languages where can verify membership quickly
P  = All languages where can  test membership quickly
Examples of quickly verifying membership:
- !""#$""%!:  Give the Hamiltonian path. 
- &'#$'()%*(:  Give the factor. 
The Hamiltonian path and the factor are called short certificates of membership.
P ⊆NP
Question:  P = NP?  Famous unsolved problem (Cook 1971).
Conjecture:  P ≠ NP.   Some problems are NP and not in P. 
Hard to prove the conjecture because polynomial-time algorithms are powerful.
Example:  Show ""CFG ∈P.
NP
P
Check-in 14.1
Check-in 14.1
Let !""#$""%! be the complement of !""#$""%!.
So 0, 2, 3 ∈!""#$""%! if 0 does not have a Hamiltonian path from 2 to 3.  
Is !""#$""%! ∈NP?
(a) Yes, we can invert the accept/reject output of the NTM for !""#$""%!. 
(b) No, we cannot give a short certificate for a graph not to have a Hamiltonian path. 
(c) I don’t know.
6
","73.69770812988281","8","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_6_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"18","Why is co-NP a subset of PSPACE?","  
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
Review: SPACE Complexity 
Defn: Let !: ℕ→ℕ where ! % ≥%. Say TM ' runs in space !(%) if ' 
always halts and uses at most !(%) tape cells on all inputs of length %. 
An NTM ' runs in space !(%) if all branches halt and each branch uses at 
most !(%) tape cells on all inputs of length %. 
SPACE ! % 
= {,| some 1-tape TM decides , in space . ! % } 
NSPACE ! % 
= {,| some 1-tape NTM decides , in space . ! % } 
PSPACE = ⋃1 SPACE(%1) “polynomial space” 
NPSPACE = ⋃1 NSPACE(%1) 
“nondeterministic polynomial space” 
Today: PSPACE = NPSPACE 
Or possibly: 
P = NP = coNP = PSPACE 
2 
PSPACE 
= NPSPACE 
coNP 
NP 
P 
","73.53321838378906","9","DPRSearchEngine","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18_2_pdf","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18","18.404J","18"
"18","Why is co-NP a subset of PSPACE?"," 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
  
  
 
 
 
 
 
  
  
 
 
  
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
A “Natural” Intractable Problem 
Defn: !""REX = '(, '* '( and '* are equivalent regular expressions} 
Theorem:  !""REX ∈ PSPACE 
Proof: Later (if time) or exercise (uses Savitch’s theorem). 
-
Notation: If ' is a regular expression write '- to mean '' ⋯' (exponent is written in binary). 
Defn: !""/01↑ = '(, '* '( and '* are equivalent regular expressions with exponentiation} 
Theorem:  !""/01↑ is EXPSPACE-complete 
Proof: 1) !""/01↑ ∈ EXPSPACE 
2)  If 3 ∈ EXPSPACE then 3 ≤5 !""/01↑ 
1) Given regular expressions with exponentiation '( and '*, 
expand the exponentiation by using repeated concatenation and then use !""REX ∈ PSPACE. 
The expansion is exponentially larger, so gives an EXPSPACE algorithm for !""/01↑. 
2)  Let 3 ∈ EXPSPACE be decided by TM 6 in space 2 89 . 
Give a polynomial-time reduction : mapping 3 to !""/01↑. 
4 
","73.49803161621094","10","DPRSearchEngine","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_4_pdf","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22","18.404J","22"
"20","What is the main idea behind showing that coNP is a subset of IP?"," 
 
 
 
 
 
  
 
 
 
 
Quick review of today 
1. Introduced the interactive proof system model 
2. Defined the class IP 
3. Showed !""# ∈ IP 
4. Started showing #""&' ∈ IP to prove that coNP ⊆ IP 
12 
","82.27440643310547","1","DPRSearchEngine","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25_12_pdf","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25","18.404J","25"
"20","What is the main idea behind showing that coNP is a subset of IP?"," 
 
  
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
  
  
  
 
18.404/6.840 Lecture 26 
Last time: 
- Interactive Proof Systems 
- The class IP 
- Graph isomorphism problem, !""# ∈ IP 
- #""&' ∈ IP (part 1) 
Today: (Sipser §10.4) 
- Arithmetization of Boolean formulas 
- Finish #""&' ∈ IP and conclude that coNP ⊆ IP 
1 
","81.35948944091797","2","DPRSearchEngine","7ac944716e076209c3964e073929f42e_MIT18_404f20_lec26_1_pdf","7ac944716e076209c3964e073929f42e_MIT18_404f20_lec26","18.404J","26"
"20","What is the main idea behind showing that coNP is a subset of IP?"," 
 
  
 
 
  
 
 
 
 
 
18.404/6.840 Lecture 25 
Last time: 
- Schwartz-Zippel Theorem 
- !""ROBP ∈ BPP 
Today: (Sipser §10.4) 
- Interactive Proof Systems 
- The class IP 
- Graph isomorphism problem 
- coNP ⊆ IP  (part 1) 
1 
","80.6143798828125","3","DPRSearchEngine","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25_1_pdf","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25","18.404J","25"
"20","What is the main idea behind showing that coNP is a subset of IP?"," 
  
  
 
 
 
 
 
 
 
    
 
 
  
 
 
 
 
 
 
 
 
  
 
  
    
 
 
 
  
 
   
    [ V is deterministic ]
    [ V ignores P ]
[ We won’t prove. Idea: explore all possible interactions in poly space. ]
Facts about IP – Checkin 25.2 
Which of the following is true? 
Check all that apply 
a) NP ⊆ IP 
b) BPP ⊆ IP 
c) IP ⊆ PSPACE 
Surprising Theorem: PSPACE ⊆ IP so IP = PSPACE 
We will prove only a weaker statement: coNP ⊆ IP 
7 
","80.53064727783203","4","DPRSearchEngine","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25_7_pdf","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25","18.404J","25"
"20","What is the main idea behind showing that coNP is a subset of IP?","well, through what we did last time. But let's set the stage for that. So the surprising theorem, as I mentioned, is that IP equals PSPACE. One direction of that is a fairly standard simulation. With PSPACE, you can basically work your way through the tree of possibilities for an interactive proof protocol. And you can calculate the probability that the verifier would end up accepting if you had the best possible prover that would try to make the verifier accept. And you can just do that calculation. It's in the book. You're not going to be responsible for knowing that, actually. We haven't covered it in lecture. But it's not very hard. A little technical, I suppose. The other direction is the interesting one, and that's the direction we're going to be moving toward today. We won't quite get there, but the way it works is that to show that everything in PSPACE, which is kind of amazing, is contained with an IP. So everything in PSPACE can be done with an interactive proof system. And the way that is done is by using a PSPACE complete problem, TQBF, and showing that that problem itself is an IP. But we're not going to prove that. That would be sort of the next thing we would prove if we had a little bit more time. But we're going to be satisfied with just the somewhat weaker but very similar statement that coNP is contained in IP here. Again, still very surprising, because you have to be able to show, for example, that a formula is not satisfiable with a prover. How can a prover convince a verifier that a formula is not satisfiable? Showing that it is satisfiable, you just give the certificate, which is the satisfying assignment. But how do you show something's not satisfiable? It's unexpected. And the proof of that is pretty much similar, slightly is one kind of technical point which we don't have to get into. So it's slightly easier but very much in the same spirit. So remember this number set problem is you're given a formula and a number, and that number is supposed to be exactly the number of satisfying assignments of the formula. So in particular, a formula's unsatisfiable, then it would be paired with the number 0. And that's why the number set problem is coNP-hard, because you can easily reduce the unsatisfiability to number set. An unsatisfiability is coNP complete. OK, so remember we introduced this notation last time. This is going to be critical for understanding this proof. So let's go through it once again.","76.72152709960938","5","DPRSearchEngine","eEXSv0jChO4.en-j3PyPqV-e1s_3_mp4","eEXSv0jChO4.en-j3PyPqV-e1s","18.404J","26"
"20","What is the main idea behind showing that coNP is a subset of IP?"," 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
  
  
 
 
 
 
 
 
 
 
 
  
 
  
 
 
   
 
  
 
 
 
 
 
 
  
   
   
 
 
  
  
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
Interactive Proofs – formal model 
Two interacting parties 
Verifier (V): Probabilistic polynomial time TM 
Prover (P): Unlimited computational power 
Both P and V see input !. 
They exchange a polynomial number of polynomial-size messages. 
Then V accepts or rejects. 
Defn: Pr[ (V ↔ P) accepts ! ] = probability that V accepts when V interacts with P, given input !. 
Defn: IP = $ for some V and P (This P is an “honest” prover) 
! ∈$ → Pr [ (V ↔ P) accepts ! ] ≥ )⁄* 
! ∉$ → for any prover P, Pr [ (V ↔ P) 
, accepts ! ] ≤ .⁄* 
Think of ,P as a “crooked” prover trying to make V accept when it shouldn’t. 
An amplification lemma can improve the error probability from .⁄* to ./)0123 4 
5 
","75.82749938964844","6","DPRSearchEngine","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25_5_pdf","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25","18.404J","25"
"20","What is the main idea behind showing that coNP is a subset of IP?","[SQUEAKING] [RUSTLING] [CLICKING] MICHAEL SIPSER: Greetings, everybody. Welcome to our last lecture of the term. We have survived a semester online in 18.404 and we are going to conclude our last topic today, which is interactive proof systems that we started last time. And with the big-- well, the big theorem of interactive proof systems is that IP equals PSPACE. And we're going to give the main idea for that in a slightly weaker theorem, as we'll see. So why don't we jump in? So we have been doing interactive proofs. We gave an example of showing that the graph isomorphism problem, the complement of that is an IP, as I hope you remember. We had that interaction with the approver and a verifier. We're going to go through it quickly. Not that protocol, but just the setup. And then we're going to finish by showing that this number SAT problem is an IP and should conclude that coNP is a subset of IP. All right, so let's go for it. Yes.","75.31842041015625","7","DPRSearchEngine","eEXSv0jChO4.en-j3PyPqV-e1s_1_mp4","eEXSv0jChO4.en-j3PyPqV-e1s","18.404J","26"
"20","What is the main idea behind showing that coNP is a subset of IP?","  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
   
 
  
 
  
 
  
  
 
 
 
#""#$ problem 
Defn: #""#$ = &, ( Boolean formula & has exactly ( satisfying assignments} 
Let #& = the number of satisfying assignments of Boolean formula &. 
So #""#$ = &, ( ( = #&} 
Defn: Language * is NP-hard if # ≤, * for every # ∈ NP. 
(Note: * is NP-complete if * is NP-hard and * ∈ NP.) 
Theorem: #""#$ is coNP-hard 
Proof: Show ""#$ ≤. #""#$ 
/ & = ⟨&, 0⟩ 
To show coNP ⊆ IP we will show #""#$ ∈ IP 
8 
","74.13443756103516","8","DPRSearchEngine","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25_8_pdf","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25","18.404J","25"
"20","What is the main idea behind showing that coNP is a subset of IP?","So just remember, interactive proof systems, there are these two parties, the prover and the verifier. The prover has unlimited computational ability. I kind of model that as an army of students perhaps who can-- where we don't-- they can work all night. They can use computational resources. And the prover, however, we're not going to measure the computational power of the prover. That's unlimited. And so the prover can do things like find certificates. It can test whether things are satisfiable. It can factor numbers. We don't care. It can do whatever we'd like and there is no charge for the prover's computational demands. OK. So the setup we had was the prover and the verifier. Both see the input. The exchange of polynomial number of messages. And then the verifier accepts or rejects. And we had this notion of the probability that the verifier ends up accepting when paired with a particular prover. And what we want is that for strings in a language, that probability should be high for some prover. And for strings not in the language, that probability should be low no matter what the prover does. So there's nothing the prover can do. And the way it kind of suggests that at any prover. But whatever the prover's strategy cannot make the verifier accept with high probability. Just doesn't have enough information or it doesn't-- it's just not able to make the verifier accept with high probability. You might think of the prover as trying to make the verifier accept. So the P tilde is a crooked prover. I don't think that went down very well with everybody. So I have it here. Another way of looking at it, maybe it looks a little bit more like NP here where IP is the collection of languages where there's a verifier, just like we had. You can think of NP as having a verifier which can check certificates. Here the prover is going to be like the certificate so that for strings in the language, there's a prover which can interact with the verifier and make it accept a high probability. And you're not in the language, there is no prover, which can interact with the verifier and make the verifier accept with even more than low probability. What's important is this gap, just like with BPP, between acceptance or rejection. And that gap is there because we want to be able to use the amplification lemma. And if there was no gap, then you wouldn't be able to amplify and make the probability of acceptance extremely high when you want it to be in the language, when you're in the language, and extremely low when you're not in the language. OK. So I hope that refreshes your memory as to how that works.","73.86080932617188","9","DPRSearchEngine","eEXSv0jChO4.en-j3PyPqV-e1s_2_mp4","eEXSv0jChO4.en-j3PyPqV-e1s","18.404J","26"
"20","What is the main idea behind showing that coNP is a subset of IP?"," 
 
   
 
 
 
 
 
 
 
   
  
 
 
 
  
 
 
  
 
 
 
  
 
 
 
 
 
 
 
  
 
 
  
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
   
 
 
 
 
 
  
 
 
 
 
 
 
 
The Class P 
Defn: P = ⋃# TIME(%#)
= polynomial time decidable languages 
• Invariant for all reasonable deterministic models 
• Corresponds roughly to realistically solvable problems 
+ 
-
Example: '()* = +, -, . + is a directed graph with a path from - to . } 
. 
Theorem:  '()* ∈ P 
Proof: 1 = “On input 〈+, -, .〉 
1.  Mark ­
2. Repeat until nothing new is marked: 
≤% iterations 
To show polynomial time: 
For each marked node 4: 
× ≤% iterations 
Each stage should be clearly 
Scan + to mark all 5 where 4, 5 is an edge × 8 %9 steps 
polynomial and the total 
3. Accept if . is marked. Reject if not. 
-------------------
number of steps polynomial. 
8(%:) steps 
10 
","73.59425354003906","10","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_10_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"24","How is the size of the formula related to the tableau for a given NTM and input in the context of the Cook-Levin Theorem?"," 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
18.404/6.840 Lecture 16 
Last time: 
- NP-completeness 
- 3""#$ ≤P &'()*+ 
- 3""#$ ≤P ,#-.#$, 
Today: (Sipser §7.4) 
- Cook-Levin Theorem: ""#$ is NP-complete 
- 3""#$ is NP-complete 
1 
","73.83638763427734","1","DPRSearchEngine","8212b19fc5a34f500ca6acf03a3a7d74_MIT18_404f20_lec16_1_pdf","8212b19fc5a34f500ca6acf03a3a7d74_MIT18_404f20_lec16","18.404J","16"
"24","How is the size of the formula related to the tableau for a given NTM and input in the context of the Cook-Levin Theorem?"," 
 
 
 
 
  
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Constructing !"",$: 1st try 
% on & 
Recall: A tableau for % on & represents 
a computation history for % on & 
when % accepts &. 
Rows of that tableau are configurations. 
% runs in space 45, its tableau has: 
- 45 columns (max size of a configuration)
-8
- 6
rows (max number of steps) 
Constructing !"",$. Try Cook-Levin method. 
Then !"",$ will be as big as tableau. 
-8
But that is exponential: 45×6 
.
Too big! • 
7 
Tableau for % on &
'( &) &* &+ ⋯&-
a
'. &*
⋯
⋯
'accept ⋯
˽   … ˽
45
6(-8)
","72.1610336303711","2","DPRSearchEngine","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18_7_pdf","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18","18.404J","18"
"24","How is the size of the formula related to the tableau for a given NTM and input in the context of the Cook-Levin Theorem?"," 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
Law of Large Numbers  
In repeated independent tests with the same actual 
probability p of a particular outcome in each test, the 
chance that the fraction of times that outcome occurs 
differs from p converges to zero as the number of trials 
goes to infinity 
Does this imply that if 
deviations from expected 
behavior occur, these 
deviations are likely to be 
evened out by opposite 
deviations in the future? 
6.0002 LECTURE 6 
14
","71.74960327148438","3","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_14_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"24","How is the size of the formula related to the tableau for a given NTM and input in the context of the Cook-Levin Theorem?"," 
 
  
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
18.404/6.840 Lecture 17 
Last time: 
- Cook-Levin Theorem: !""# is NP-complete 
- 3!""# is NP-complete 
Today: (Sipser §8.1 – §8.2) 
- Space complexity 
- SPACE % & , NSPACE % & 
- PSPACE, NPSPACE 
- Relationship with TIME classes 
- Examples 
1 
","71.41764831542969","4","DPRSearchEngine","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17_1_pdf","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17","18.404J","17"
"24","How is the size of the formula related to the tableau for a given NTM and input in the context of the Cook-Levin Theorem?","0.5 times 0.4. You guys can figure that out. I think that's 0.2. So you'd expect that, that it should be much smaller than either of the first two probabilities. This is the most common rule, it's something we use all the time in probabilities, the so-called multiplicative law. We have to be careful about it, however, in that it only holds if the events are actually","71.00834655761719","5","DPRSearchEngine","-1BnXEwHUok.en-qlPKC2UN_YU_5_mp4","-1BnXEwHUok.en-qlPKC2UN_YU","6.0002","4"
"24","How is the size of the formula related to the tableau for a given NTM and input in the context of the Cook-Levin Theorem?"," 
   
 
  
  
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
   
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
Cook-Levin Theorem (idea) 
Theorem: !""# is NP-complete 
Proof: 1) !""# ∈ %& (done) 
2) Show that for each "" ∈ %& we have "" ≤( !""#: 
Let "" ∈ %& be decided by NTM ) in time *+ . 
Give a polynomial-time reduction , mapping "" to !""#. 
,: Σ∗→ formulas 
, 1 = 〈45,7〉
1 ∈ "" iff 45,7 is satisfiable 
Idea:  45,7 simulates ) on 1. Design 45,7 to “say” ) accepts 1. 
Satisfying assignment to 45,7 is a computation history for ) on 1. 
3 
","70.92679595947266","6","DPRSearchEngine","8212b19fc5a34f500ca6acf03a3a7d74_MIT18_404f20_lec16_3_pdf","8212b19fc5a34f500ca6acf03a3a7d74_MIT18_404f20_lec16","18.404J","16"
"24","How is the size of the formula related to the tableau for a given NTM and input in the context of the Cook-Levin Theorem?","This column is what we would get with the original recursive implementation where we didn't use a memo. And it was therefore 2 to the length of items. And as you can see, it gets really big or, as we say at the end, huge. But the number of calls grows incredibly slowly for the dynamic programming solution. In the beginning it's worth Oh, well. But by the time we get to the last number I wrote, we're looking at 43,000 versus some really big number I don't know how to pronounce-- 18 somethings. Incredible improvement in performance. And then at the end, it's a number we couldn't fit on the slide, even in tiny font. And yet, only 703,000 calls. How can this be? We know the problem is inherently exponential. Have we overturned the laws of the universe? Is dynamic programming a miracle in the liturgical sense? No. But the thing I want you to carry away is that computational complexity can be a very subtle notion. The running time of fastMaxVal is governed by the number of distinct pairs that we might be able to use as keys in the memo-- toConsider and available. The number of possible values of toConsider is small. It's bounded by the length of the items. If I have a 100 items, it's 0, 1, 2, up to a 100. The possible values of available weight is harder to characterize. But it's bounded by the number of distinct sums of weights you can get. If I start with 750 calories left, what are the possibilities? Well, in fact, in this case, maybe we can take only 750 because we're using with units. So it's small. But it's actually smaller than that because it has to do with the combinations of ways I can add up the units I have. I know this is complicated. It's not worth my going through the details in the lectures. It's covered in considerable detail in the assigned reading. Quickly summarizing lectures 1 and 2,","70.78386688232422","7","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_14_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"24","How is the size of the formula related to the tableau for a given NTM and input in the context of the Cook-Levin Theorem?","What do I do in the case when n equals size? I'm going to have to make my array bigger. This should sound just like static arrays. For static arrays, we made our array bigger every time we inserted. And that was this linear cost of allocation. We're going to do that sometimes. With static arrays, we had to do it every single time, because size equaled n. Now, we have some flexibility. We're only going to do it sometimes. It's like, cookies are a sometimes food, apparently, according to modern Cookie Monster. I don't understand. But if n equals size, we're going to allocate a new array of size-- any suggestions? AUDIENCE: Bigger. ERIK DEMAINE: Bigger. I like it. Greater than size. How much bigger? AUDIENCE: Twice. ERIK DEMAINE: Twice. JASON KU: Five things. ERIK DEMAINE: Five things. Size plus 5? Come on, Jason. Trolling me. All right. There are a couple of natural choices here. One is a constant factor larger. You could use 1.1, or 1.01, or two, or 5, or 10. They will all work. Or you could use Jason's trolling answer of size plus a constant, like 5. Why is this bad? Yeah? AUDIENCE: [INAUDIBLE] ERIK DEMAINE: You'll have to do it again. You'll have to resize frequently. When? Five steps later. In the original static array, we were reallocating every single time. That's like n plus 1. If we do n plus 5, that really doesn't change things if we ignore constant factors. Now, we'll have to spend linear time every five steps instead of linear time every one step. That's still linear time per operation, just, we're changing the constant factor. Whereas 2 times size, well, now we have to think a little bit harder.","70.6223373413086","8","DPRSearchEngine","CHhwJjR0mZA.en-j3PyPqV-e1s_7_mp4","CHhwJjR0mZA.en-j3PyPqV-e1s","6.006","2"
"24","How is the size of the formula related to the tableau for a given NTM and input in the context of the Cook-Levin Theorem?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 5: Linear Sorting 
Lecture 5: Linear Sorting 
Review 
• Comparison search lower bound: any decision tree with n nodes has height ≥dlg(n+1)e−1 
• Can do faster using random access indexing: an operation with linear branching factor! 
• Direct access array is fast, but may use a lot of space (Θ(u)) 
• Solve space problem by mapping (hashing) key space u down to m = Θ(n) 
• Hash tables give expected O(1) time operations, amortized if dynamic 
• Expectation input-independent: choose hash function randomly from universal hash family 
• Data structure overview! 
• Last time we achieved faster ﬁnd. Can we also achieve faster sort? 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
Direct Access Array 
u 
1 
1 
u 
u 
Hash Table 
n(e) 
1(e) 
1(a)(e) 
n 
n 
","70.37381744384766","9","DPRSearchEngine","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5_1_pdf","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5","6.006","5"
"24","How is the size of the formula related to the tableau for a given NTM and input in the context of the Cook-Levin Theorem?","And here it is. It's actually for something so important, very simple. It says that given a sufficiently large sample-- and I love terms like sufficiently large but we'll later put a little meat on that-- the following three things are true. The means of the samples in a set of samples, the so-called sample means will be approximately normally distributed. So that says if I take a sample-- and remember, a sample will have multiple examples. So just to remind people. A population is a set of examples. A sample is a subset of the population. So it too is a set of examples, typically. If this set is sufficiently large-- certainly 1 is not sufficiently large-- then it will be the case that the mean of the means-- so I take the mean of each sample and then I can now plot all of those means and so take the mean of those, right-- and they'll be normally distributed. Furthermore, this distribution will have a mean that is close to the mean of the population. The mean of the means will be close to the mean of the population. And the variance of the sample means will be close to the variance of the population divided by the sample size. This is really amazing that this is true and dramatically useful. So to get some insight, let's check it. To do that, postulate that we have this kind of miraculous die. So instead of a die that when you roll it you get a number 1, 2, 3, 4, 5, or 6, this particular die is continuous. It gives you a real number between 0 and 5, or maybe it's between 1 and 6, OK? So it's a continuous die. What we're going to do is roll it a lot of times. We're going to say, how many die? And then, how many times are we going to roll that number of die? So the number of die will be the sample size-- number of dice will be the sample size. And then we'll take a bunch of samples which I'm calling number of rolls. And then we'll plot it and I'm just choosing some bins and some colors and some style and various other things just to show you how we use the keyword arguments. Actually, I said the number of rolls is the number of trials. But it isn't quite that because I'm going to get the number of trials by dividing the number of rolls by the number of dice. So if I have more dice, I get to have fewer samples, more dice per sample, all right? Then we'll just do it. So it will be between 0 and 5 because random.random returns a number between 0 and 1 and I'm multiplying it by 5. And then we'll look at the means and we'll plot it all. Again, we're playing games with weights just to make the plot a little easier to read. And here's what we get. If we roll one die, the mean is very close to 2.5. Well, that's certainly what you'd expect, right? It's some random number between 0 and 5. 2.5 is a pretty good guess as to what it should average. And it has a standard deviation of 1.44. And that's a little harder to guess that that's what it would be. But you could figure it out with a little math or as I did here with the simulation. But now, if I roll 50 dice, well, again, the mean is close to 2.5. It's what you'd expect, right? I roll 50 die, I get the mean value of those 50. But look how much smaller the standard deviation is. More importantly, what we see here is that if we look at the value, the probability is flat for all possible values between 0 and 5 for a single die. But if we look at the distribution for the means, it's not quite Gaussian but it's pretty close. Why is it not Gaussian? Well, I didn't do it an infinite number of times. Did it quite a few, but not an infinite number. Enough that you didn't want to sit here while it ran. But you can see the amazing thing here that when I go from looking at 1 to looking at the mean of 50, suddenly I have a normal distribution. And that means that I can bring to bear on the problem the Central Limit Theorem. We can try it for roulette. Again I'm not going to make you sit through a million trials of 200 spins each. I'll do it only for fair roulette. And again, this is a very simple simulation, and we'll see what we get. And what we see is it's not quite normal, again, but it definitely has that shape. Now, it's going to be a little bit strange because I can't lose more than one, if I'm betting one. So it will never be quite normal because it's going to be truncated down on the left side, whereas the tail can be arbitrarily long. So again, mathematically it can't be normal but it's close enough in the main region, where most of the values lie, that we can get away with applying the empirical rule and looking at answers. And indeed as we saw, it does work. So what's the moral here? It doesn't matter what the shape of the distribution of the original values happen to be. If we're trying to estimate the mean using samples that are sufficiently large, the CLT will allow us to use the empirical rule when computing confidence intervals. Even if we go back and look at this anomaly over in the left, what do you think would happen if I, instead of had 200, have, say, 1,000? What's the probability of the average return being minus 1 of 1,000 bets? Much smaller than for 100 bets. To lose 1,000 times in a row is pretty unlikely. So to get all the way to the left is going to be less likely, and, therefore, the thing will start looking more and more normal as the samples get bigger. All right, and so we can use the CLT to justify using the empirical rule when we compute confidence intervals. All right, I want to look at one more example in detail. This is kind of an interesting one. You might think that randomness is of no use for, say, finding the value of pi because there's nothing random about that. Similarly, you might think that randomness was of no use in integrating a function, but in fact, the way those numerical algorithms work is they use randomness. What you're about to see is that randomness, and indeed things related to Monte Carlo simulations, can be enormously useful, even when you're computing something that is inherently not random like the value of pi here. And we won't ask you to remember that many digits on the quiz and the exam. All right, so what's pi? Well, people have known about pi for thousands and thousands of years. And what people knew was that there was some constant, we'll call it pi. It wasn't always called that. Such that it was equal to the circumference of a circle divided by the diameter, and furthermore, the area was going to be pi r squared. People knew that way back to the Babylonians and the Egyptians. What they didn't know is what that value was. The earliest known estimate of pi was by the Egyptians, on something called the Rhind Papyrus pictured here.","69.90548706054688","10","DPRSearchEngine","rUxP7TM8-wo.en-qlPKC2UN_YU_7_mp4","rUxP7TM8-wo.en-qlPKC2UN_YU","6.0002","7"
"25","What is the toy problem used to demonstrate the proof method similar to Hilbert’s 10th problem?"," 
 
 
 
 
 
 
   
 
  
  
 
 
 
 
   
 
 
 
 
 
  
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
  
 
 
Revisit Hilbert’s 10th Problem 
Recall ! = 〈$〉 polynomial $ &', &), … , &+ = 0 has integer solution) 
Hilbert’s 10th problem (1900): Is ! decidable? 
Theorem (1971): No 
Proof: Show -TM is reducible to !. [would take entire semester] 
Do toy problem instead which has a similar proof method. 
Toy problem: The Post Correspondence Problem. 
Method: The Computation History Method. 
3 
","80.49853515625","1","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_3_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"25","What is the toy problem used to demonstrate the proof method similar to Hilbert’s 10th problem?","It changes names every once in a while. And I mentioned it in the hardness complexity lecture, because this class is all about hardness proofs, analyzing fun games and puzzles. We saw the Tetris NP-hardness in that lecture. But you can also prove Super Mario Brothers is hard, or Portal is hard, or Mario Kart is hard, or The Witness, a modern video game, is hard. Or, one of our latest results is that Recurse-- that game in the top right-- is undecidable. There's no algorithm to play that game perfectly. And you can even download the level-- an example of the level and play it, if you dare. So that's a lot of-- we have a lot of fun in that world of hardness of different games and puzzles. Where do I want to go next? OK. Next topic is balloon twisting. Totally different. This is recreational, but not about hardness. This is an octahedron twisted from one balloon. I made another one on a stick. Each of these is made for one balloon. What graphs can you make for one balloon? Well, you should read our paper.","72.15097045898438","2","DPRSearchEngine","4nXw-f6NJ9s.en-j3PyPqV-e1s_6_mp4","4nXw-f6NJ9s.en-j3PyPqV-e1s","6.006","21"
"25","What is the toy problem used to demonstrate the proof method similar to Hilbert’s 10th problem?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
Use our knowledge that !TM is undecidable to show other 
problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
10 
","71.27903747558594","3","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_10_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"25","What is the toy problem used to demonstrate the proof method similar to Hilbert’s 10th problem?"," 
 
 
  
 
 
 
    
 
 
    
 
        
 
        
 
 
    
 
        
 
 
 
 
        
 
 
 
              
 
    
 
 
 
  
 
 
 
 
    
 
 
        
 
 
 
Monte Carlo Simulation  
def playRoulette(game, numSpins, pocket, bet): 
totPocket = 0 
for i in range(numSpins): 
game.spin()  
totPocket += game.betPocket(pocket, bet)  
if toPrint: 
print(numSpins, 'spins of', game) 
print('Expected return betting', pocket, '=',\\ 
str(100*totPocket/numSpins) + '%\\n') 
return (totPocket/numSpins) 
game = FairRoulette() 
for numSpins in (100, 1000000): 
for i in range(3): 
playRoulette(game, numSpins, 2, 1, True) 
6.0002 LECTURE 6 
12
","71.23236846923828","4","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_12_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"25","What is the toy problem used to demonstrate the proof method similar to Hilbert’s 10th problem?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
If we know that some problem (say !TM) is undecidable, 
we can use that to show other problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Recall Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
2 
","70.93074035644531","5","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_2_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"25","What is the toy problem used to demonstrate the proof method similar to Hilbert’s 10th problem?"," 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
Interactive Proofs – informal model 
Probabilistic 
polynomial time TM 
© Sesame Workshop. All rights reserved. This content 
is excluded from our Creative Commons license. For 
more information, see https://ocw.mit.edu/fairuse. 
Professor = Verifier (V) 
Unlimited 
computation 
Graduate Students = Prover (P) 
© Source unknown. All rights reserved. This content is excluded from our Creative 
Commons license. For more information, see https://ocw.mit.edu/fairuse. 
!
"" 
Professor wants to know if graphs ! and "" are isomorphic. 
- He asks his Students to figure out the answer. 
- But he doesn’t trust their answer. He must be convinced. 
If the Students claim that ! and "" are isomorphic, 
they can give the isomorphism and convince him. 
But what if they claim that ! and "" are not isomorphic? 
- The Professor randomly and secretly picks ! or "" and 
permutes it, then sends the result to the Students. 
- If Students can identify which graph the Professor picked 
reliably (repeat this 100 times), then he’s convinced. 
4 
","70.78705596923828","6","DPRSearchEngine","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25_4_pdf","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25","18.404J","25"
"25","What is the toy problem used to demonstrate the proof method similar to Hilbert’s 10th problem?","first, I'm going to start off by remembering Hilbert's tenth problem, which we discussed briefly a few lectures back, as you may remember. So that's a problem where you were given, say, some polynomial over several variables, like 3x squared y minus 15z plus 2xz equals 5. And you want to solve that problem. You want to find a solution that solves that equation, but you require that the solution involves only integers. So those are so-called diophantine problems because the requirement is that the solution be in integers. And Hilbert's problem was to ask for an algorithm. Not the language that he used, but doesn't matter. Essentially, he asked for an algorithm to test whether a polynomial has a solution in integers, whether the polynomial equation has a solution in integers. And as we now know, that problem was posed back in 1900, it took 71 years to find the solution, but the answer is no. There is no-- there is no such algorithm. We talked about this when we were discussing the Church-Turing thesis. And the method showing that there is no algorithm is by a reduction from ATM to that problem. So one can use exactly the method that we're using today to prove that problem is undecidable about polynomials. The only thing is is that the reduction, that single reduction, would take the entire semester. And I know that's in fact correct because when I was a graduate student, there was a woman in the math department at Berkeley, where I studied, and the whole course was to go through the proof of Hilbert's tenth problem, of the solution to Hilbert's tenth problem, the proof of the undecidability of the solution, of the undecidability of testing whether a polynomial has an integral solution. So the thing is is that involves some fairly hairy number theory in order to come up with the right polynomials to basically simulate the Turing machine. So that's kind of getting ahead of ourselves. That's what we're going to be doing today. But we're going to-- instead of looking at that problem because we don't have a whole semester to spend on it, we're going to look at a toy problem instead where there's no number theory, but it still has the same basic underlying idea that was employed in the solution to Hilbert's tenth problem. So that toy problem is called the post correspondence problem. And it's going to have some other utility for us. Well, the main reason we're studying it is just to illustrate the method. So and the method is going to be, as I have been saying, is this computation history method. OK, so why don't we-- we'll first talk about this post correspondence problem because that's very easy to understand, and then we'll spend a little time introducing that method. All right. So the post correspondence problem is as follows. You're given a bunch of pairs of strings. So here is one pair, t1 and b1. And I'm writing them as dominoes. I'm calling them dominoes because I'm writing one of the strings on top of the other string. In fact, I'm using t and b for top and bottom here. So this is t1 is the top string, b1 is the bottom string in the first domino. And then in the second domino, we have two other strings, a top and a bottom and so on. So we have these here, this collection of dominoes, as sort of the legal dominoes. And what the goal is, to find a sequence of those dominoes. So you want to pick from these dominoes here. You're allowed to repeat dominoes. So you want to pick a sequence of those dominoes, line them up next to each other, and so that the string that you get by reading along the top, all of the ts together, is going to be exactly the same as the string you get by reading along all the bottoms. I'll give you an example. So here, to write it down a little bit more formally, so what I'm calling a match is a sequence of these dominoes, so it's ti1, ti2. Well, it's i1 is the first domino, i2 is the second domino and so on. And then what you're going to have is all the top strings concatenated together is exactly the same as what you get by concatenating together all the bottom strings. So here's an example, and I think it'll become clear if you didn't understand it so far, but it'll be completely clear from the example, I hope. So here is a bunch of dominoes, four. And what I want to know is, is there some selection of these dominoes-- again, you can repeat dominoes. Otherwise, it would be not an interesting problem. So you can repeat these as many times as you like. And I want to pick these dominoes and line them up so that what you get by reading along the top is the same as what you get by reading along the bottom. So first of all, if you just stare at this and you're trying to make a match, you'll see that there's only one possible way to start this. For example, if you started with the third domino here, ba over aa, it would fail immediately because the b and the a are different. And if you use the second domino as your starting point, that would fail to match as well because aa would have to be-- the top string would start with aa, the bottom string would start with ab, and they could never be equal. So by looking at this, you can see that the only possible choice that you have is to start with the first domino. So I'm going to start to build a domino for you just so you can see it. So here's the match so you can see the process. So the match starts with the very first domino. And the way I'm going to write it is I'm going to take the dominoes and kind of skew them so that you can see how the top and bottom strings are lining up. But they're the same dominoes, they've just been-- I changed the shape. So this is the first domino, ab over aba. Now, the second domino in my match, it's got to start with an a as the leftmost symbol on the top string. So that would rule out this one, for example. But there might be several choices, and so it's not exactly obvious which one you should take. What I'm going to suggest is we take this one here. So we take aa over aba. You see it. aa over aba. It's just written-- I'm just skewing it so that I can line up the a over a, the b over b, the a over a and so on. So I'm starting to build this concatenation of the top being equal to the concatenation of the bottom. Following me so far, I hope? So now, what's next? So I need to have something where the top string is going to start with a ba. Fact, there's only one choice for that, so it's clearly going to have to be this domino is going to be next. So it's going to put a ba up here, but then it's going to force an aa down below because that's what this domino does. So this ba matches with that. Now we have the aa to deal with. So we're going to reuse this domino because that's the only one that starts with an aa. So we're going to reuse that one. Now we have aa and aba. Now we need something that starts with aba. I see two choices. Could be this one because this is consistent with-- at least it captures the ab. We could try putting this one over here, but a better choice would be to use this one because if we use this one, we finish the match. And therefore, we have found what we're looking for. And this collection of dominoes here has a match. Now, it's not always obvious. Some collections of dominoes may not have a match. And so the computational problem is, is there a match? And the theorem that we're going to prove today is that this problem is undecidable. Simple as it is, simple little combinatorial problem of trying to put together different tiles like that to form a match, there is no algorithm for solving that problem. And I think this is kind of interesting because it's the first example of a problem that we have where the underlying question does not really seem to have anything to do with computation. You might argue that ATM being undecidable is perhaps a little unsurprising after the fact because it's a problem about Turing machines, so you can imagine Turing machines are going to have a tough time answering. But here's a problem just about strings. And we're going to show it's undecidable. So just to formulate this as a language, I'm going to call the PCP language, is the collection of these PCP problems, PCP instances, which are just themselves, each one is a collection of dominoes. So it's the language of all collections of these dominoes where there is a match. So it's all of the PCP problems where you can solve them with a match. And we're going to prove that it's undecidable by showing that ATM is reducible to that PCP language. Now, before we do that, I'm going to have to-- I'm going to explain to you what the computation history method is in the first pla-- that we're going to be using. So before we do that, here's our first check-in for the day.","70.60994720458984","7","DPRSearchEngine","MGqoLm2aAgc.en-j3PyPqV-e1s_3_mp4","MGqoLm2aAgc.en-j3PyPqV-e1s","18.404J","10"
"25","What is the toy problem used to demonstrate the proof method similar to Hilbert’s 10th problem?","tell if the machine is looping or if it's really just taking a very long time? You can't. That's what we're going to prove not in today's lecture, but going to prove that on Thursday. You just can't tell. So if that's in reference to problem 5, you're going to have to find some other way of doing-- solving that problem without knowing whether the machine is actually ever going to halt.","70.20752716064453","8","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_3_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"25","What is the toy problem used to demonstrate the proof method similar to Hilbert’s 10th problem?","Hilbert’s 10th Problem
In 1900 David Hilbert posed 23 problems
#1)    Problem of the continuum  ( Does set ! exist where ℕ< ! < |ℝ| ? ).
#2)    Prove that the axioms of mathematics are consistent.
#10)  Give an algorithm for solving Diophantine equations. 
Diophantine equations:
Equations of polynomials where solutions must be integers.
Example:   3'( −2'+ −+(, = 7
solution:  ' = 1, + = 2, , = −2
Let 1 = 2 polynomial  2 '3, '(, … , '5 = 0 has a solution in integers)
Hilbert’s 10th problem:   Give an algorithm to decide 1. 
Matiyasevich proved in 1970:   1 is not decidable.  
Note:  1 is T-recognizable. 
David Hilbert
1862—1943 
© Source unknown. All rights reserved. This content is excluded from our Creative 
Commons license. For more information, see https://ocw.mit.edu/fairuse.
7
","70.18164825439453","9","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_7_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"25","What is the toy problem used to demonstrate the proof method similar to Hilbert’s 10th problem?","4 
Lecture 19: Complexity 
Examples of NP-complete Problems 
• Subset Sum from L18 (“weakly NP-complete” which is what allows a pseudopolynomial­
time algorithm, but no polynomial algorithm unless P = NP) 
• 3-Partition: given n integers, can you divide them into triples of equal sum? (“strongly 
NP-complete”: no pseudopolynomial-time algorithm unless P = NP) 
• Rectangle Packing: given n rectangles and a target rectangle whose area is the sum of the n 
rectangle areas, pack without overlap 
– Reduction from 3-Partition to Rectangle Packing: transform integer ai into 1 × ai rect-
P 
angle; set target rectangle to n/3 × ( 
i ai) /3 
• Jigsaw puzzles: given n pieces with possibly ambiguous tabs/pockets, ﬁt the pieces together 
– Reduction from Rectangle Packing: use uniquely matching tabs/pockets to force build­
ing rectangles and rectangular boundary; use one ambiguous tab/pocket for all other 
boundaries 
• Longest common subsequence of n strings 
• Longest simple path in a graph 
• Traveling Salesman Problem: shortest path that visits all vertices of a given graph (or deci­
sion version: is minimum weight ≤ d) 
• Shortest path amidst obstacles in 3D 
• 3-coloring given graph (but 2-coloring ∈ P) 
• Largest clique in a given graph 
• SAT: given a Boolean formula (made with AND, OR, NOT), is it every true? 
E.g., x AND NOT x is a NO input 
• Minesweeper, Sudoku, and most puzzles 
• Super Mario Bros., Legend of Zelda, Pok´emon, and most video games are NP-hard (many 
are harder) 
","69.8288345336914","10","DPRSearchEngine","fda666a4db1dc65b3d71be08115502bd_MIT6_006S20_lec19_4_pdf","fda666a4db1dc65b3d71be08115502bd_MIT6_006S20_lec19","6.006","19"
"27","What is the aim of marking all occurrences of terminals in the CFG when deciding the emptiness problem?"," 
 
 
  
  
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
    
  
 
 
 
 
 
  
 
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
S 
a
R 
T 
a
Emptiness Problem for CFGs 
Let !CFG = { ' | ' is a CFG and ) ' = ∅} 
Theorem: !CFG is decidable 
Proof: 
,E−CFG = “On input ' 
[IDEA: work backwards from terminals] 
1. Mark all occurrences of terminals in '. 
S → RTa
2. Repeat until no new variables are marked 
R → 
R
Tb
Tb
Mark all occurrences of variable A if 
A → B1B2 ⋯ B4 is a rule and all B5 were already marked. 
T → a 
3. 
Reject if the start variable is marked. 
Accept if not.” 
8 
","73.0794677734375","1","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_8_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"27","What is the aim of marking all occurrences of terminals in the CFG when deciding the emptiness problem?"," 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
Computation History Method - recap 
Computation History Method is useful for showing the undecidability 
of problems involving testing for the existence of some object. 
!
Is there an integral solution (to the polynomial equation)?
""LBA 
Is there some accepted string (for the LBA)?
&'& 
Is there a match (for the given dominos)?
())CFG Is there some rejected string (for the CFG)?
In each case, the object is the computation history in some form.
12
","72.43730163574219","2","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_12_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"27","What is the aim of marking all occurrences of terminals in the CFG when deciding the emptiness problem?"," 
 
 
  
  
 
 
  
 
  
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Emptiness Problem for DFAs 
Let !DFA = & & is a DFA and ' & = ∅} 
Theorem: !DFA is decidable 
Proof: Give TM *E−DFA that decides !DFA . 
*E−DFA = “On input & 
[IDEA: Check for a path from start to accept.] 
1. 
Mark start state. 
2. 
Repeat until no new state is marked: 
Mark every state that has an incoming arrow 
from a previously marked state. 
3. 
Accept if no accept state is marked. 
Reject if some accept state is marked.” 
5 
","72.23490905761719","3","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_5_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"27","What is the aim of marking all occurrences of terminals in the CFG when deciding the emptiness problem?"," 
 
 
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
  
 
  
 
  
 
 
  
 
 
   
 
 
   
 
 
 
 
TMs and Encodings – review 
A TM has 3 possible outcomes for each input !: 
1. Accept ! (enter ""acc ) 
2. Reject ! by halting (enter ""rej ) 
3. Reject ! by looping (running forever) 
( is T-recognizable if ( = *(,) for some TM ,. 
( is T-decidable if ( = *(,) for some TM decider ,. 
halts on all inputs 
〈/0, /2, … , /4〉 encodes objects /0, /2, … , /4 as a single string. 
Notation for writing a TM , is 
, = “On input ! 
[English description of the algorithm]” 
2 
","71.93447875976562","4","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_2_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"27","What is the aim of marking all occurrences of terminals in the CFG when deciding the emptiness problem?","emptiness problem for DFAs. I'm going to give you now a-- just a DFA-- B-- and no input. And I'm going to ask, is the language of that DFA the empty set, the empty language? You understand the problem, first of all? I'm just handing you in a DFA, and I want to know, does this DFA accept any strings at all, or is it just some dumb DFA-- it's just always very negative DFA, it just rejects everything-- and it has the empty language? How do you tell? Not super hard, if you think about how you would write a program to do that or how you would do it yourself-- so that's a decidable language again. So we're going to give now a Turing machine decider for that language. That decider says, well, I'm giving that DFA-- I want to know if its language is empty. And the idea is just what you would think. I'm going to see, is there a path from the start state of that DFA to the-- an accept state of the DFA? If there is such a path, then that DFA is going to have an input which goes along that path, and will be accepted. And so the language won't be empty. If there's no such path, then clearly, this DFA can never accept anything, and so this language will be empty. OK. Now, there are many different path algorithms. I think it would be a little bit sparse of me just-- some of you know algorithms. Some of you don't know path checking algorithms. I would like you to just to-- if you were giving this kind of an answer on a homework, to give me some sense of how that algorithm is going to work. Don't be too high level about it. So the one I have in mind is the breadth research, if you've heard of that. But it's very simple algorithm. What I'm going to use is kind of a marking procedure. So I'm going to start by coloring the-- here is this-- I should have indicated-- this is my DFAB. This is B over here. Should I try taking a chance of writing on this thing-- oops. This is B. Oh, great-- that didn't help. So this is B here. And the way I'm going to test if it has a path-- if it accepts an input is by seeing if there's a path from the start state to any one of the accept states. And I'm going to start it by marking the start state, and then marking all states that I can get to from previously marked states, and keep doing that until I can't get to anything new. There's going to be a series of iterations here marking more and more states until there's nothing new to mark, and then I say, did I mark any accept states? OK, so let's just see how I write that down in English. So I started marking the start state. I repeat until no new state is marked. I'm going to say, mark every state that has an incoming arrow from a previously marked state. Accept-- then, once I'm done with, that repeat loop-- accept if no accept state is marked, because that means-- don't forget, it's a little bit inverted from what you might think. I'm going to accept if there's no marked accept state, because that means there's no path to an accept state from the start state, which means the language is empty. And EDFA is the DFAs that have empty language, so I should be accepting those. If there's no way to get to an accept state, no accept state is marked. And reject if some accept state earmark, because then the language is not empty. OK, so that's all I wanted to say about that.","71.58627319335938","5","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_8_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"27","What is the aim of marking all occurrences of terminals in the CFG when deciding the emptiness problem?","Emptiness problem for CFGs-- hopefully you're getting comfortable","71.38230895996094","6","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_13_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"27","What is the aim of marking all occurrences of terminals in the CFG when deciding the emptiness problem?"," 
 
 
    
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Return to Closure Properties 
Recall Theorem: If !"", !$ are regular languages, so is !"" ∪!$ 
(The class of regular languages is closed under union) 
New Proof (sketch): Given DFAs &"" and &$ recognizing !"" and !$ 
&$
&"" 
ε 
ε 
& 
Construct NFA & recognizing !"" ∪!$ 
Nondeterminism 
parallelism 
vs 
guessing 
7 
","70.22630310058594","7","DPRSearchEngine","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_7_pdf","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2","18.404J","2"
"27","What is the aim of marking all occurrences of terminals in the CFG when deciding the emptiness problem?"," 
 
 
 
 
 
   
  
 
  
 
 
   
 
 
  
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
  
 
 
 
 
 
 
Check-in 8.2 
Recall the Queue Automaton (QA) defined in Pset 2. 
It is similar to a PDA except that it is deterministic 
and it has a queue instead of a stack. 
Let !QA = { &, ( | & is a QA and & accepts (} 
Is !QA decidable? 
(a) Yes, because QA are similar to PDA and !PDA is decidable. 
(b) No, because “yes” would contradict results we now know. 
(c) We don’t have enough information to answer this question. 
8 
Check-in 8.2 
","69.97293090820312","8","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_8_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"27","What is the aim of marking all occurrences of terminals in the CFG when deciding the emptiness problem?"," 
 
 
   
  
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
  
 
 
 
 
  
 
  
 
 
 
 
  
 
 
 
 
 
 
  
  
 
 
 
 
  
  
 
  
    
 
 
 
 
 
 
 
 
 
 
 
Converting CFGs to PDAs 
Theorem: If ! is a CFL then some PDA recognizes ! 
Proof: Convert !’s CFG to a PDA 
…
E → E+T | T 
PDA 
T → … 
F → … 
CFG 
$% 
E → E+T | T 
IDEA: PDA begins with starting variable and guesses substitutions. 
T → T×F | F
It keeps intermediate generated strings on stack. When done, compare with input. 
F → ( E ) | a
E
E 
T 
T 
Input: 
a
+
a
×
a
+
+ 
+ 
E 
E
T
T 
T 
× 
E+T 
E +  T  
F 
T+T×F 
T T × F 
Problem! Access below the top of stack is cheating! 
F+F×a 
F 
F
a
Instead, only substitute variables when on the top of stack. 
a+a×a 
a
a
a
If a terminal is on the top of stack, pop it and compare with input. Reject if ≠. 
8 
","69.86817932128906","9","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_8_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"27","What is the aim of marking all occurrences of terminals in the CFG when deciding the emptiness problem?"," 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
              
 
 
 
 
 
 
 
 
 
 
 
Pushdown Automata (PDA) 
“head” 
a
b
a
b
a 
… 
a
Finite 
input appears on a “tape” 
control 
c 
Schematic diagram for DFA or NFA
(pushdown) 
d 
stack 
Schematic diagram for PDA 
d 
Operates like an NFA except can write-add or read-remove symbols 
from the top of stack. 
push 
pop 
Example: PDA for ! = 0$1$ & ≥0 
1) Read 0s from input, push onto stack until read 1. 
2) Read 1s from input, while popping 0s from stack. 
3) Enter accept state if stack is empty. (note: acceptance only at end of input) 
6 
","69.80683898925781","10","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_6_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"29","What does it mean when we say that a set is uncountable?","Satisfiability Problem
Defn: A Boolean formula ! has Boolean variables (TRUE/FALSE values) 
and Boolean operations AND (∧), OR (∨), and NOT (¬). 
Defn: ! is satisfiable if ! evaluates to TRUE for some assignment to its variables.
Sometimes we use 1 for True and 0 for False.
Example:  Let ! =
& ∨' ∧(& ∨')
(Notation:  & means ¬&)  
Then ! is satisfiable  (x=1, y=0)  
Defn:  *+, =
!
! is a satisfiable Boolean formula}
Theorem (Cook, Levin 1971):    *+, ∈P  →P = NP 
Proof method:  polynomial time (mapping) reducibility
Check-in 14.3
Check-in 14.3
Is  *+, ∈NP?
(a) Yes.
(b) No. 
(c) I don’t know.
(d) No one knows.
11
","73.86559295654297","1","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_11_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"29","What does it mean when we say that a set is uncountable?"," 
  
  
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
  
 
 
 
  
!TM is undecidable 
Let !TM = { & | & is a TM and ( & = ∅} 
Theorem: !TM is undecidable 
Proof by contradiction. Show that +TM is reducible to !TM. 
Assume that !TM is decidable and show that +TM is decidable (false!). 
Let TM , decide !TM. 
Construct TM - deciding +TM. 
- = “On input &, / 
1. Transform & to new TM &0 = “On input 1 
1.  If 1 ≠/, reject. 
2. else run & on / 
3. Accept if & accepts.” 
2.  Use , to test whether ((&0) = ∅ 
3.  If YES [so & rejects /] then reject. 
If NO [so & accepts /] then accept. 
&0 works like & except that it 
always rejects strings 1 where 1 ≠/. 
if & accepts / 
So ( &0 = 5 /
∅ 
if & rejects / 
4 
","72.41654968261719","2","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_4_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"29","What does it mean when we say that a set is uncountable?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
Use our knowledge that !TM is undecidable to show other 
problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
10 
","70.84304809570312","3","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_10_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"29","What does it mean when we say that a set is uncountable?","This is just another word for being not in R. OK, and next thing I'd like to do is prove to you that most decision problems are uncomputable, or sketcher proof. So remember, decision problems are problems where the answer is just yes or no. This is a very special kind of problem. And even those, almost all of them, cannot be solved. So halting is an example of a problem we want-- we can't solve. This whole class, this 006, is about problems we can solve. But today I'm going to show you that, actually, those are in the minority. Most problems cannot be computed. This is very strange and also a little depressing. So we'll talk more about that in a moment. First let me argue why this is the case. So I'm going to be a little informal about what exactly is a computer program and what exactly is a decision problem. But roughly, all I need to do, the only level of precision I need is just to count how many are there. What is a computer program? Well, it's usually a file. What's a file? It's like a string of characters. What's a character? It's a string of bits. So a program is just, in the end, a string of bits, finite string of bits. We all understand that. Whatever language you define, in the end, every program is just a string of bits. And a string of bits we can translate into a number. So we can convert between strings of bits and numbers. When I say number, I mean what's usually called a natural number or a non-negative integer. This is usually represented by bold board bold-- blackboard bold capital N. So this is just 0, 1, 2, and so on. Now, what about decision problems? Decision problem is a specification of what we want to solve. So we can think of it as saying, for every input, is the answer yes or no? That's literally what a decision problem is. The only question is, what is an input? And we've talked about inputs and the size of inputs. And there's lots of different ways to measure them. But in the end, we can think of an input as a string of bits also. It's just a file. So a decision problem is a function from inputs to yes or no. And inputs we're going to say, well, that's a string of bits, which we can associate with a number in N. So here we can start to tie things together. So in other words, a program is a finite string of bits, and a problem is, in some sense, an infinite string of bits because there are infinitely many possible inputs. And for each of them, we specify yes or no. So this is basically an infinite string of bits. So we can imagine 011010001110, infinitely. Just some-- for every string of bits, we can say, OK, if your input is the number 0, here's the answer-- no. If your input is the number 1, then the answer is yes. If your input is the number 2, your answer is yes, and so on down this line. Every infinite string of bits corresponds to exactly one decision problem, which specifies for every possible input integer, which corresponds to a string of bits, what is the answer, yes or no? So this may seem subtle, or it may seem like not a big deal. This is a finite string of bits. This is an infinite string of bits. But mathematics has well studied this problem. And infinite strings of bits, there are very many of them, infinitely many. It's not surprising. There are also infinitely many integers. So maybe it doesn't seem that deep. But there's a difference in infinitude. Programs and integers are countably infinite. And infinite strings of bits are what's called uncountable. I think the most intuitive way to see this is, an infinite string of bits, if I put a decimal or a binary point in front, this encodes a real number between 0 and 1. So this is roughly a real number in 01. And when I'm writing approximately equal here, this really goes in both directions. Given a decision problem, I can define a string of bits, of course giving me the answer for all inputs. And I can convert that into a real number between 0 and 1. But also the other direction, if I take any real number, that is a corresponding decision problem. These are 1 to 1 bijection between them. And the bad news is, real numbers are uncountable, and natural numbers are countable, which means there's a lot more of these than there are these. So one way you might phrase this is, informally, the number of natural numbers is way smaller than the number of real numbers. And so from that, we derive that most problems are unsolvable, because every program solves exactly one decision problem. We can also run a program, conceptually, on all possible inputs, and we will figure out what function at solving. And if we don't allow random numbers in our program, which I'm not here, then every program solves exactly one decision problem. Possibly, it's even worse for us because multiple programs probably solve the same decision problem. They're just-- they add irrelevant lines of code or they don't do anything different. Or you run Bellman-Ford versus running Bellman-Ford five times, you'll get the same result. And that's actually the bad direction for us. We'd like to know whether there is a program that solves every decision problem. And because there are only this many programs and this many decision problems, it just-- there aren't enough to go around.","70.61509704589844","4","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_4_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"29","What does it mean when we say that a set is uncountable?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
If we know that some problem (say !TM) is undecidable, 
we can use that to show other problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Recall Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
2 
","69.99434661865234","5","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_2_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"29","What does it mean when we say that a set is uncountable?","So E TM is the emptiness problem for Turing machines. Is this language empty? I'm just going to give you a machine. I want to know, is this language empty or not? Does it accept something or is this language empty? That's going to be undecidable, no surprise, proof by contradiction. And we're going to show that A TM is reducible to E TM. So these things often take a very similar form. And I'm going to try to use the same form. So if you're feeling shaky on it, at least you'll get the form of the way the solution goes and that will help you maybe plug-in to solve problems, OK.","69.52408599853516","6","DPRSearchEngine","N28g_YBXY8Y.en-j3PyPqV-e1s_7_mp4","N28g_YBXY8Y.en-j3PyPqV-e1s","18.404J","9"
"29","What does it mean when we say that a set is uncountable?","Arithmetization Method
Method:  Simulate ∧and ∨with + and ×.
%&
0 1
'
' (1 −%&)
' %&
',
'-
'.
', + '- + '.
%,
%-
%-
0 1
0
1
%.
%.
0
1
0
1
0
1
0
1
Replace Boolean labeling with arithmetical labeling
Inductive rules:
Start node labeled 1
' ∧/ →'×/ = '/
'
→
1 −'
' ∨/ →' + / −'/
Works because the BP is acyclic.
The execution path can enter a node 
at most one time. 
' ∧%&
' ∧%&
', ∨'- ∨'.
9
","69.4747314453125","7","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_9_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"29","What does it mean when we say that a set is uncountable?","← 
/ 
 
 
 
  
  
 
 
  
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
  
      
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Proof:  (
) Convert
to equivalent TM
.
/ = for input !:
Simulate ' (on blank input).
Whenever ' prints 0, test 0 = !. 
Accept if = and continue otherwise.
Turing Enumerators 
˽ ˽ 
˽ ˽ 
˽ ˽ ˽ . . . 
Finite 
control 
read/write tape – initially blank 
printer 
Defn: A Turing Enumerator is a deterministic TM with a printer. 
It starts on a blank tape and it can print strings !"" , !$ , !% , … possibly going forever. 
Its language is the set of all strings it prints. It is a generator, not a recognizer. 
For enumerator ' we say ( ' = ! ' prints !}. 
Theorem:  A is T-recognizable iff + = ((') for some T-enumerator '. 
' 
Proof: (→) Convert TM / to equivalent enumerator '.
Check-in 6.1 
' = Simulate / on each !2 in Σ∗ = {6, 0,1,00,01,10, … } 
When converting TM / to enumerator ', 
If / accepts !2 then print !2 .
does ' always print the strings in string order? 
Continue with next !2 .
a) Yes. 
Problem: What if / on !2 loops? 
b) No. 
Fix: Simulate / on !"" , !$ , … , !2 for 9 steps, for 9 = 1,2, … 
Print those !2 which are accepted. 
Image of the printer © Source unknown. All rights reserved. This content is excluded from 
our Creative Commons license. For more information, see https://ocw.mit.edu/fairuse. 
Check-in 6.1 
5 
","69.36629486083984","8","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_5_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"29","What does it mean when we say that a set is uncountable?","    
 
 
 
  
 
 
 
 
   
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Ex 1: !TM is undecidable - new proof 
Theorem: !TM is not decidable 
Proof by contradiction: Assume some TM $ decides !TM. 
Consider the following TM %: 
% = “On input ' 
1. Get own description 〈%〉. 
2. Use $ on input 〈%, '〉 to determine whether % accepts '. 
3. Do the opposite of what $ says.” 
7 
","69.24083709716797","9","DPRSearchEngine","779043ea724131d008eae652d703938f_MIT18_404f20_lec11_7_pdf","779043ea724131d008eae652d703938f_MIT18_404f20_lec11","18.404J","11"
"29","What does it mean when we say that a set is uncountable?"," 
 
 
  
  
 
 
  
 
  
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Emptiness Problem for DFAs 
Let !DFA = & & is a DFA and ' & = ∅} 
Theorem: !DFA is decidable 
Proof: Give TM *E−DFA that decides !DFA . 
*E−DFA = “On input & 
[IDEA: Check for a path from start to accept.] 
1. 
Mark start state. 
2. 
Repeat until no new state is marked: 
Mark every state that has an incoming arrow 
from a previously marked state. 
3. 
Accept if no accept state is marked. 
Reject if some accept state is marked.” 
5 
","69.23477935791016","10","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_5_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"31","How is a 3CNF formula constructed from a formula \\((\\varphi)\\) using a reduction \\(f\\) while preserving satisfiability, and how does this relate to logical equivalence?"," 
 
  
  
 
 
 
 
 
 
   
 
 
 
 
  
 
  
 
  
 
 
  
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
   
 
    
   
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
   
  
Time Hierarchy Theorem (1/2) 
Theorem: For any !: ℕ → ℕ where ! is time constructible 
there is a language % where % requires & ! ' 
time, i.e, 
1) % is decidable in & ! ' 
time, and 
2) % is not decidable in ( ! ' / log ! ' 
time 
- .
On other words, TIME (
⊆, TIME ! ' 
/01 - . 
Proof outline:  Give TM 3 where 
1) 3 runs in & ! ' 
time 
2) 3 ensures that 4(3) ≠ 4(8) for every TM 8 that runs in ( ! ' / log ! ' 
time . 
Let % = 4(3). 
10 
","75.67282104492188","1","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_10_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"31","How is a 3CNF formula constructed from a formula \\((\\varphi)\\) using a reduction \\(f\\) while preserving satisfiability, and how does this relate to logical equivalence?"," 
 
 
    
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Return to Closure Properties 
Recall Theorem: If !"", !$ are regular languages, so is !"" ∪!$ 
(The class of regular languages is closed under union) 
New Proof (sketch): Given DFAs &"" and &$ recognizing !"" and !$ 
&$
&"" 
ε 
ε 
& 
Construct NFA & recognizing !"" ∪!$ 
Nondeterminism 
parallelism 
vs 
guessing 
7 
","75.43923950195312","2","DPRSearchEngine","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_7_pdf","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2","18.404J","2"
"31","How is a 3CNF formula constructed from a formula \\((\\varphi)\\) using a reduction \\(f\\) while preserving satisfiability, and how does this relate to logical equivalence?","§ Problem is exponen<al 
§ Have we overturned the laws of the universe? 
§ Is dynamic programming a miracle? 
§ No, but computa<onal complexity can be subtle 
§ Running <me of fastMaxVal is governed by number of 
dis<nct pairs, <toConsider, avail> 
◦Number of possible values of toConsider bounded 
by len(items)
◦Possible values of avail a bit harder to characterize 
◦Bounded by number of dis<nct sums of weights 
◦Covered in more detail in assigned reading 
How Can This Be? 
6.0002 LECTURE 2 
30 
","75.12249755859375","3","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_30_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"31","How is a 3CNF formula constructed from a formula \\((\\varphi)\\) using a reduction \\(f\\) while preserving satisfiability, and how does this relate to logical equivalence?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
If we know that some problem (say !TM) is undecidable, 
we can use that to show other problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Recall Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
2 
","74.95136260986328","4","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_2_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"31","How is a 3CNF formula constructed from a formula \\((\\varphi)\\) using a reduction \\(f\\) while preserving satisfiability, and how does this relate to logical equivalence?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
Use our knowledge that !TM is undecidable to show other 
problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
10 
","74.74591064453125","5","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_10_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"31","How is a 3CNF formula constructed from a formula \\((\\varphi)\\) using a reduction \\(f\\) while preserving satisfiability, and how does this relate to logical equivalence?","which, I think, most of us would agree was not a very big number. And let's look what's going on here. If you look at this, what in some sense seems really stupid about it? What is it doing that a rational person would not want to do if they could avoid it? It's bad enough to do something once. But to do the same thing over and over again is really wasteful. And if we look at this, we'll see, for example, that fib 4 is being computed here, and fib 4 is being computed here. Fib 3 is being considered here, and here, and here. And do you think we'll get a different answer for fib 3 in one place when we get it in the other place? You sure hope not. So you think, well, what should we do about this? How would we go about avoiding doing the same work over and over again? And there's kind of an obvious answer, and that answer is at the heart of dynamic programming. What's the answer? AUDIENCE: [INAUDIBLE] JOHN GUTTAG: Exactly. And I'm really happy that someone in the front row answered the question because I can throw it that far. You store the answer and then look it up when you need it. Because we know that we can look things up very quickly. Dictionary, despite what Eric said in his lecture, almost all the time works in constant time if you make it big enough, and it usually is in Python. We'll see later in the term how to do that trick. So you store it and then you'd never have to compute it again. And that's the basic trick behind dynamic programming. And it's something called memoization, as in you create a memo and you store it in the memo. So we see this here. Notice that what we're doing is trading time for space. It takes some space to store the old results, but negligible related to the time we save. So here's the trick. We're going to create a table to record what we've done. And then before computing fib of x, we'll check if the value has already been computed. If so, we just look it up and return it. Otherwise, we'll compute it-- it's the first time-- and store it in the table. Here is a fast implementation of Fibonacci that does that. It looks like the old one, except it's got an extra argument-- memo-- which is a dictionary. The first time we call it, the memo will be empty. It tries to return the value in the memo. If it's not there, an exception will get raised, we know that.","74.60002136230469","6","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_9_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"31","How is a 3CNF formula constructed from a formula \\((\\varphi)\\) using a reduction \\(f\\) while preserving satisfiability, and how does this relate to logical equivalence?","Satisfiability Problem
Defn: A Boolean formula ! has Boolean variables (TRUE/FALSE values) 
and Boolean operations AND (∧), OR (∨), and NOT (¬). 
Defn: ! is satisfiable if ! evaluates to TRUE for some assignment to its variables.
Sometimes we use 1 for True and 0 for False.
Example:  Let ! =
& ∨' ∧(& ∨')
(Notation:  & means ¬&)  
Then ! is satisfiable  (x=1, y=0)  
Defn:  *+, =
!
! is a satisfiable Boolean formula}
Theorem (Cook, Levin 1971):    *+, ∈P  →P = NP 
Proof method:  polynomial time (mapping) reducibility
Check-in 14.3
Check-in 14.3
Is  *+, ∈NP?
(a) Yes.
(b) No. 
(c) I don’t know.
(d) No one knows.
11
","74.50961303710938","7","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_11_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"31","How is a 3CNF formula constructed from a formula \\((\\varphi)\\) using a reduction \\(f\\) while preserving satisfiability, and how does this relate to logical equivalence?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
    
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Reducibility – Concept 
If we have two languages (or problems) ! and "", then 
! is reducible to "" means that we can use "" to solve !. 
Example 1: Measuring the area of a rectangle 
is reducible to measuring the lengths of its sides. 
Example 2: We showed that !NFA is reducible to !DFA . 
Example 3: From Pset 2, PUSHER is reducible to 'CFG . 
(Idea- Convert push states to accept states.) 
If ! is reducible to "" then solving "" gives a solution to !. 
- then "" is easy →! is easy. 
- then ! is hard →"" is hard. 
this is the form we will use 
3 
Check-in 9.1 
Is Biology reducible to Physics? 
(a) Yes, all aspects of the physical world 
may be explained in terms of Physics, 
at least in principle. 
(b) No, some things in the world, maybe 
life, the brain, or consciousness, 
are beyond the realm pf Physics. 
(c) I’m on the fence on this question! 
Check-in 9.1 
","74.43626403808594","8","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_3_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"31","How is a 3CNF formula constructed from a formula \\((\\varphi)\\) using a reduction \\(f\\) while preserving satisfiability, and how does this relate to logical equivalence?","  
  
  
  
 
 
 
  
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Equivalence of CFGs and PDAs 
Theorem: ! is a CFL iff* some PDA recognizes ! 
Done. 
In book.  You are responsible for knowing 
it is true, but not for knowing the proof. 
* “iff” = “if an only if” means the implication goes both ways. 
So we need to prove both directions: forward (→) and reverse (←). 
Check-in 4.3 
Is every Regular Language also 
a Context Free Language? 
(a) Yes 
(b) No 
(c) Not sure 
Check-in 4.3 
10 
","74.3743896484375","9","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_10_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"31","How is a 3CNF formula constructed from a formula \\((\\varphi)\\) using a reduction \\(f\\) while preserving satisfiability, and how does this relate to logical equivalence?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
Reducibility terminology 
Why do we use the term “reduce”? 
When we reduce ! to "", we show how to solve ! by using "" 
and conclude that ! is no harder than "". (suggests the ≤$ notation) 
Possibility 1: We bring !’s difficulty down to ""’s difficulty. 
Possibility 2: We bring ""’s difficulty up to !’s difficulty. 
11 
","74.24298095703125","10","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_11_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"32","What is meant by the collection of all languages being uncountable?","This is just another word for being not in R. OK, and next thing I'd like to do is prove to you that most decision problems are uncomputable, or sketcher proof. So remember, decision problems are problems where the answer is just yes or no. This is a very special kind of problem. And even those, almost all of them, cannot be solved. So halting is an example of a problem we want-- we can't solve. This whole class, this 006, is about problems we can solve. But today I'm going to show you that, actually, those are in the minority. Most problems cannot be computed. This is very strange and also a little depressing. So we'll talk more about that in a moment. First let me argue why this is the case. So I'm going to be a little informal about what exactly is a computer program and what exactly is a decision problem. But roughly, all I need to do, the only level of precision I need is just to count how many are there. What is a computer program? Well, it's usually a file. What's a file? It's like a string of characters. What's a character? It's a string of bits. So a program is just, in the end, a string of bits, finite string of bits. We all understand that. Whatever language you define, in the end, every program is just a string of bits. And a string of bits we can translate into a number. So we can convert between strings of bits and numbers. When I say number, I mean what's usually called a natural number or a non-negative integer. This is usually represented by bold board bold-- blackboard bold capital N. So this is just 0, 1, 2, and so on. Now, what about decision problems? Decision problem is a specification of what we want to solve. So we can think of it as saying, for every input, is the answer yes or no? That's literally what a decision problem is. The only question is, what is an input? And we've talked about inputs and the size of inputs. And there's lots of different ways to measure them. But in the end, we can think of an input as a string of bits also. It's just a file. So a decision problem is a function from inputs to yes or no. And inputs we're going to say, well, that's a string of bits, which we can associate with a number in N. So here we can start to tie things together. So in other words, a program is a finite string of bits, and a problem is, in some sense, an infinite string of bits because there are infinitely many possible inputs. And for each of them, we specify yes or no. So this is basically an infinite string of bits. So we can imagine 011010001110, infinitely. Just some-- for every string of bits, we can say, OK, if your input is the number 0, here's the answer-- no. If your input is the number 1, then the answer is yes. If your input is the number 2, your answer is yes, and so on down this line. Every infinite string of bits corresponds to exactly one decision problem, which specifies for every possible input integer, which corresponds to a string of bits, what is the answer, yes or no? So this may seem subtle, or it may seem like not a big deal. This is a finite string of bits. This is an infinite string of bits. But mathematics has well studied this problem. And infinite strings of bits, there are very many of them, infinitely many. It's not surprising. There are also infinitely many integers. So maybe it doesn't seem that deep. But there's a difference in infinitude. Programs and integers are countably infinite. And infinite strings of bits are what's called uncountable. I think the most intuitive way to see this is, an infinite string of bits, if I put a decimal or a binary point in front, this encodes a real number between 0 and 1. So this is roughly a real number in 01. And when I'm writing approximately equal here, this really goes in both directions. Given a decision problem, I can define a string of bits, of course giving me the answer for all inputs. And I can convert that into a real number between 0 and 1. But also the other direction, if I take any real number, that is a corresponding decision problem. These are 1 to 1 bijection between them. And the bad news is, real numbers are uncountable, and natural numbers are countable, which means there's a lot more of these than there are these. So one way you might phrase this is, informally, the number of natural numbers is way smaller than the number of real numbers. And so from that, we derive that most problems are unsolvable, because every program solves exactly one decision problem. We can also run a program, conceptually, on all possible inputs, and we will figure out what function at solving. And if we don't allow random numbers in our program, which I'm not here, then every program solves exactly one decision problem. Possibly, it's even worse for us because multiple programs probably solve the same decision problem. They're just-- they add irrelevant lines of code or they don't do anything different. Or you run Bellman-Ford versus running Bellman-Ford five times, you'll get the same result. And that's actually the bad direction for us. We'd like to know whether there is a program that solves every decision problem. And because there are only this many programs and this many decision problems, it just-- there aren't enough to go around.","64.76058197021484","1","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_4_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"32","What is meant by the collection of all languages being uncountable?","And the last of the regular operations is the so-called star operation, which is a unary operation. It applies to just a single language. And so what you do is now you're going to take-- to get a member of the star language, you're going to take a bunch of strings in the original language, A, you stick them together. Any number of members of A, you stick them together, and that becomes an element of the star language. And we'll do an example in a second if you didn't get that. But one important element is that when you have the star language, you can also allow it to stick zero elements together, and then you get the empty string. So that's always a member of the star language, the empty string. OK, so let's look at some examples. Let's say A is the language-- these are two strings here-- good, bad. And B is the language boy, girl. Now, if we take the union of those two, we get good, bad, boy, girl. That's kind of what you'd expect. And now let's take a look at the concatenation. Now, if you concatenate the A and the B language, you're going to get all possible ways of having an A string followed by all possible ways of having a B string. So you can get goodboy, goodgirl, badboy, badgirl. Now, looking at the star, well, that applies to just one language. So let's say it's the good, bad language from A. And so the A star that you get from that is all possible ways of sticking together the strings from A. So using no strings, you always get the empty string. That's always guaranteed to be a member of A. And then just taking one element of A, you get good, or another element, bad. But now two elements of A, you get goodgood or goodbad, and so on. Or three elements of A, goodgoodgood, goodgoodbad. And so, in fact, A star is going to be an infinite language if A itself contains any non-empty member. So if A is the empty language or if A contains just the language empty string, then A star will be not an infinite language. It'll just be the language empty string. But otherwise, it'll be an infinite language. I'm not even sure-- OK. I'm not-- [LAUGHS] I'm ignoring the chat here. I'm hoping people are getting-- are you guys are getting your questions answered by our TAs? How are we doing, Thomas? AUDIENCE: One question is, are the slides going to be posted? MICHAEL SIPSER: Are the slides going to be posted? Well, the whole lecture is going to be recorded. Is it helpful to have the slides separately? I can post the slides. Sure. Remind me if I don't, but I'll try to do that. Yes, it is helpful. I will do that. Yeah. Yeah, I will post the slides. Just, Thomas, it's your job to remind me. AUDIENCE: OK. MICHAEL SIPSER: All right, good. So we talked about the regular operations. Let's talk about the regular expressions. So regular expressions are-- just like you have the arithmetical operations, then you can get arithmetical expressions, like 1 plus 3 times 7. So now we're going to make expressions out of these operations. First of all, you have, the more atomic things, the building blocks of the expressions, which are going to be like elements of sigma, elements of the alphabet or the sigma itself as an alphabet symbol, or the empty language or the empty string. These are going to be the building blocks for the regular expressions. We'll do an example in a second. And then you combine those basic elements using the regular operations of union, concatenation, and star. So these are the atomic expressions, these are the composite expressions. So, for example, if you look at the expression 0 union 1 star-- so we can also write that as sigma star. Because if sigma is 0 and 1, then sigma star is the same thing as 0 union 1-- sigma is the same as 0 union 1. And that just gives all possible strings over sigma. So this is something you're going to see frequently. Sigma star means this is the language of all strings over the alphabet we're working with at that moment. Now, if you take sigma star 1, you just concatenate 1 onto all of the elements of sigma star, and that's going to give you all strings that end with a 1. Technically, you might imagine writing this with braces around the 1, but generally, we don't do that. We just-- single element sets, single element strings, we write without the braces, because it's clear enough without them, and it gets messy with them. So sigma star 1 is all strings that end with 1. Or, for example, you take sigma star 11 sigma star, that is all strings that contain 11. And we already saw that language once before. That's the language of that other machine that we presented one or two slides back. OK? Right. Yeah, but in terms of readings-- by the way, sorry, I don't know if it's helpful to you for me to do these interjections-- but the readings are listed also on the homework. So if you look at the posted homework 1, it tells you which chapters you should be reading now. And also, if you look at the course schedule, which is also on the home page, it has the whole course plan and which readings are for which dates. So it's all there for you. And so our goal here-- this is not an accident that sigma star 11 sigma star happens to be the same language as we saw before from the language of that finite automaton M1. In fact, that's a general phenomenon. Anything you can do with a regular expression, you can also do with a finite automaton and vice versa. They are equivalent in power with respect to the class of languages they describe. And we'll prove that. OK? So if you step back for a second and just let yourself appreciate this, it's kind of an amazing thing. Because finite automata, with the states and transitions, and the regular expressions, with these operations of union, concatenation, and star, they look totally different from one another. They look like they have nothing to do with one another. But, in fact, they both describe exactly the regular languages, the same class of languages. And so it's kind of a cool fact that you can prove, that these two very different looking systems actually are equivalent to one another. Can we get empty string from empty set? Yeah. There are a bunch of exotic cases, by the way. So empty language star is the language which has just the empty string. If you don't get that, chew on that one. But that is true.","64.52255249023438","2","DPRSearchEngine","9syvZr-9xwk.en-j3PyPqV-e1s_10_mp4","9syvZr-9xwk.en-j3PyPqV-e1s","18.404J","1"
"32","What is meant by the collection of all languages being uncountable?"," 
 
 
 
 
 
Class Field, continued  
def moveDrunk(self, drunk):  
if drunk not in self.drunks:  
raise ValueError('Drunk not in field')  
xDist, yDist = drunk.takeStep()  
#use move method of Location to get new location  
self.drunks[drunk] =\\  
self.drunks[drunk].move(xDist, yDist)  
Immutable or not? 
6.0002  LECTURE 5 
19 
","64.02989196777344","3","DPRSearchEngine","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_19_pdf","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5","6.0002","5"
"32","What is meant by the collection of all languages being uncountable?","So there's a lot of variations on the basics sorting problem and the different algorithms that are out there. Two vocabulary words are going to highlight really quick-- one is if your sort is destructive, what that means is that rather than reserving some new memory for my sorted array B and then putting a sorted version of A into B, a destructive algorithm is one that just overwrites A with a sorted version of A. Certainly the C++ interface does this. I assume the Python one does, too. I always forget this detail. In addition to destructive sorts, some sorts are in place, meaning that not only are they destructive, but they also don't use extra memory in the process of sorting. Really, you could imagine a sorting algorithm that has to reserve a bunch of scratch space to do its work, and then put it back into A. For instance, the world's dumbest destructive sort might be to call your non-destructive and then copy it back into A. But that would require order n space to do. So if my algorithm additionally has the property that it doesn't reserve any extra space, at least up to a constant, then we call that in place. OK. So those are our basic vocabulary words. And they're ways to understand the differences between different sorting algorithms. Yes? AUDIENCE: [INAUDIBLE] JUSTIN: Why do they end up using extra O(1) space? Oh yeah, sure. Any time I just make a temporary variable like a loop counter, that's going to count toward that order 1. But the important thing is that the number of variables I need","63.92993927001953","4","DPRSearchEngine","oS9aPzUNG-s.en-j3PyPqV-e1s_13_mp4","oS9aPzUNG-s.en-j3PyPqV-e1s","6.006","3"
"32","What is meant by the collection of all languages being uncountable?"," ! 
dist, numSamples = [], 1000000
for i in range(numSamples):
dist.append(random.gauss(0, 100))
weights = [1/numSamples]*len(dist)
v = pylab.hist(dist, bins = 100,
weights = [1/numSamples]*len(dist))
pylab.xlabel('x')
pylab.ylabel('Relative Frequency')
print('Fraction within ~200 of mean =',
sum(v[0][30:70]))
	

""
","63.65230178833008","5","DPRSearchEngine","3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7_3_pdf","3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7","6.0002","7"
"32","What is meant by the collection of all languages being uncountable?","which, I think, most of us would agree was not a very big number. And let's look what's going on here. If you look at this, what in some sense seems really stupid about it? What is it doing that a rational person would not want to do if they could avoid it? It's bad enough to do something once. But to do the same thing over and over again is really wasteful. And if we look at this, we'll see, for example, that fib 4 is being computed here, and fib 4 is being computed here. Fib 3 is being considered here, and here, and here. And do you think we'll get a different answer for fib 3 in one place when we get it in the other place? You sure hope not. So you think, well, what should we do about this? How would we go about avoiding doing the same work over and over again? And there's kind of an obvious answer, and that answer is at the heart of dynamic programming. What's the answer? AUDIENCE: [INAUDIBLE] JOHN GUTTAG: Exactly. And I'm really happy that someone in the front row answered the question because I can throw it that far. You store the answer and then look it up when you need it. Because we know that we can look things up very quickly. Dictionary, despite what Eric said in his lecture, almost all the time works in constant time if you make it big enough, and it usually is in Python. We'll see later in the term how to do that trick. So you store it and then you'd never have to compute it again. And that's the basic trick behind dynamic programming. And it's something called memoization, as in you create a memo and you store it in the memo. So we see this here. Notice that what we're doing is trading time for space. It takes some space to store the old results, but negligible related to the time we save. So here's the trick. We're going to create a table to record what we've done. And then before computing fib of x, we'll check if the value has already been computed. If so, we just look it up and return it. Otherwise, we'll compute it-- it's the first time-- and store it in the table. Here is a fast implementation of Fibonacci that does that. It looks like the old one, except it's got an extra argument-- memo-- which is a dictionary. The first time we call it, the memo will be empty. It tries to return the value in the memo. If it's not there, an exception will get raised, we know that.","63.58241653442383","6","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_9_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"32","What is meant by the collection of all languages being uncountable?"," 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
  
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
18.404/6.840 Lecture 12 
Last time: 
- Self-reproducing machines and The Recursion Theorem 
- Applications: 
a) New proof that !TM is undecidable 
b) $%&TM is T-unrecognizable (and so is any infinite subset of $%&TM) 
c) True but unprovable statements 
Today: (Sipser §7.1) 
- Introduction to Complexity Theory 
- Complexity classes; the Class P 
1 
","63.50105667114258","7","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_1_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"32","What is meant by the collection of all languages being uncountable?","found by combining optimal solutions to local subproblems. So for example, when x is greater than 1 we can solve fib x by solving fib x minus 1 and fib x minus 2 and adding those two things together. So there is optimal substructure-- you solve these two smaller problems independently of each other and then combine the solutions in a fast way. You also have to have something called overlapping subproblems. This is why the memo worked. Finding an optimal solution has to involve solving the same problem multiple times. Even if you have optimal substructure, if you don't see the same problem more than once-- creating a memo. Well, it'll work, you can still create the memo. You'll just never find anything in it when you look things up because you're solving each problem once. So you have to be solving the same problem multiple times and you have to be able to solve it by combining solutions to smaller problems. Now, we've seen things with optimal substructure before. In some sense, merge sort worked that way-- we were combining separate problems. Did merge sort have overlapping subproblems? No, because-- well, I guess, it might have if the list had the same element many, many times. But we would expect, mostly not. Because each time we're solving a different problem, because we have different lists that we're now sorting and merging. So it has half of it but not the other. Dynamic programming will not help us for sorting, cannot be used to improve merge sort. Oh, well, nothing is a silver bullet. What about the knapsack problem? Does it have these two properties? We can look at it in terms of these pictures. And it's pretty clear that it does have optimal substructure because we're taking the left branch and the right branch and choosing the winner. But what about overlapping subproblems? Are we ever solving, in this case, the same problem-- add two nodes? Well, do any of these nodes look identical? In this case, no. We could write a dynamic programming solution to the knapsack problem-- and we will-- and run it on this example, and we'd get the right answer. We would get zero speedup. Because at each node, if you can see, the problems are different. We have different things in the knapsack or different things to consider. Never do we have the same contents and the same things left to decide. So ""maybe"" was not a bad answer if that was the answer you gave to this question. But let's look at a different menu. This menu happens to have two beers in it. Now, if we look at what happens, do we see two nodes that are solving the same problem? The answer is what? Yes or no? I haven't drawn the whole tree here. Well, you'll notice the answer is yes.","63.320838928222656","8","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_11_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"32","What is meant by the collection of all languages being uncountable?"," 
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
  
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
  
 
 
 
 
 
 
 
 
 
  
Finite Automata – Computation 
Strings and languages 
-
A string is a finite sequence of symbols in Σ 
-
A language is a set of strings (finite or infinite) 
-
The empty string ε is the string of length 0 
Recognizing languages 
-
The empty language ø is the set with no strings 
- :(#) = {$| # accepts $} 
- :(#) is the language of # 
Defn:  # accepts string $ = $1$2 … $) each $* + Σ 
- # recognizes :(#) 
if there is a sequence of states ,0, ,1, ,2, , … , ,) + / 
where: 
- ,0 = 00 
- ,* = 1(,345, $*) for 1 ≤ * ≤) 
Defn: A language is regular if some 
- ,) + 8 
finite automaton recognizes it. 
8 
","63.22669982910156","9","DPRSearchEngine","b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1_8_pdf","b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1","18.404J","1"
"32","What is meant by the collection of all languages being uncountable?"," 
  
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
New in  Code  
§numpy.std is function in the numpy module that
returns the standard deviation
§random.sample(population, sampleSize) returns a list
containing sampleSize randomly chosen distinct
elements of population
◦Sampling without replacement
6.0002  LECTURE 8 
 
8
","62.805660247802734","10","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_8_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"33","What is the relationship between Turing machines and languages in terms of countability?"," 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Turing Machines (TMs) 
head 
˽ ˽
a
b
a 
. . .
b b
Finite 
read/write input tape 
control 
1) Head can read and write 
2) Head is two way (can move left or right) 
3) Tape is infinite (to the right) 
4) Infinitely many blanks “˽“ follow input 
5) Can accept or reject any time (not only at end of input) 
8 
","73.76895141601562","1","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_8_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"33","What is the relationship between Turing machines and languages in terms of countability?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
18.404/6.840 Lecture 5 
Last time: 
- Context free grammars (CFGs) 
- Context free languages (CFLs) 
- Pushdown automata (PDA) 
- Converting CFGs to PDAs 
Today: (Sipser §2.3, §3.1) 
- Proving languages not Context Free 
- Turing machines 
- T-recognizable and T-decidable languages 
1 
","72.65020751953125","2","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_1_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"33","What is the relationship between Turing machines and languages in terms of countability?"," 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Relationships among models 
Informal Defn: Two models of computation are polynomially related 
if each can simulate the other with a polynomial overhead: 
So ! "" time → !$("") time on the other model, for some '. 
All reasonable deterministic models are polynomially related. 
• 1-tape TMs 
• multi-tape TMs 
• multi-dimensional TMs 
• random access machine (RAM) 
• cellular automata 
9 
","71.80632781982422","3","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_9_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"33","What is the relationship between Turing machines and languages in terms of countability?","And a comparison model means-- is that the items, the objects I'm storing-- I can kind of think of them as black boxes. I don't get to touch these things, except the only way that I can distinguish between them is to say, given a key and an item, or two items, I can do a comparison on those keys. Are these keys the same? Is this key bigger than this one? Is it smaller than this one? Those are the only operations I get to do with them. Say, if the keys are numbers, I don't get to look at what number that is. I just get to take two keys and compare them. And actually, all of the search algorithms that we saw on Tuesday we're comparison sort algorithms. What you did was stepped through the program. At some point, you came to a branch and you looked at two keys, and you branched based on whether one key was bigger than another. That was a comparison. And then you move some stuff around, but that was the general paradigm. Those three sorting operations lived in this comparison model.","71.73538970947266","4","DPRSearchEngine","Nu8YGneFCWE.en-j3PyPqV-e1s_2_mp4","Nu8YGneFCWE.en-j3PyPqV-e1s","6.006","4"
"33","What is the relationship between Turing machines and languages in terms of countability?"," 
 
 
 
 
 
 
 
 
  
 
  
 
   
 
 
 
 
  
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Model Dependence 
Number of steps to decide ! = a#b# $ ≥0 depends on the model. 
• 1-tape TM: '() log )) 
• Multi-tape TM: '()) 
Computability theory: model independence (Church-Turing Thesis) 
Therefore model choice doesn’t matter. Mathematically nice. 
Complexity Theory: model dependence 
But dependence is low (polynomial) for reasonable deterministic models. 
We will focus on questions that do not depend on the model choice. 
So… we will continue to use the 1-tape TM as the basic model for complexity. 
6 
","71.71920776367188","5","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_6_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"33","What is the relationship between Turing machines and languages in terms of countability?","power of a Turing machine. That's a question that I'm going to postpone to later, because you're asking if a Turing machine can simulate itself. And we'll talk about things like that, but that's in a few weeks from now, so I'll hold off on that one. Decidable languages-- somebody's asking me a good question about closure properties of the class of decidable languages. Are they closed under intersection, union, and so on? Yes. And the decidable languages are also closed under complement. That should be something you should think about. But yes, that is true. The recognizable languages, however, are closed under union and intersection, but they are not closed under complement. So that we will prove on Thursday's lecture. So another question is, could we have just run B on w in this-- in solving this problem, instead of using reduced-- converting it to a new Turing machine-- the B prime? Well, yes, we could have just done that. OK. I think we better move on. I don't want to get too bogged down here-- got a lot of questions there, so sorry if I'm not getting to all of the questions. OK. Or you can write to the TAs too, obviously. I'm sure you are.","71.68304443359375","6","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_7_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"33","What is the relationship between Turing machines and languages in terms of countability?"," 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
 
  
 
  
 
 
 
18.404/6.840 Lecture 6 
Last time: 
- Proving languages not Context Free
- Turing machines
- Recognizers and deciders
- T-recognizable and T-decidable languages
Today: (Sipser §3.2 – §3.3) 
- Equivalence of variants of the Turing machine model
a. Multi-tape TMs
b. Nondeterministic TMs
c. Enumerators
- Church-Turing Thesis
- Notation for encodings and TMs
1 
","71.67697143554688","7","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_1_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"33","What is the relationship between Turing machines and languages in terms of countability?"," 
 
 
 
 
 
 
 
 
 
  
 
  
 
  
 
 
 
  
 
 
 
 
18.404/6.840 Lecture 7 
Last time: 
- Equivalence of variants of the Turing machine model 
a. Multi-tape TMs 
b. Nondeterministic TMs 
c. Enumerators 
- Church-Turing Thesis 
- Notation for encodings and TMs 
Today: (Sipser §4.1) 
- Decision procedures for automata and grammars 
1 
","71.58723449707031","8","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_1_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"33","What is the relationship between Turing machines and languages in terms of countability?","Notation for encodings and TMs
Notation for encoding objects into strings
- If ! is some object (e.g., polynomial, automaton, graph, etc.), 
we write 〈!〉to be an encoding of that object into a string.  
- If !$, !&, … , !( is a list of objects then we write 〈!$, !&, … , !(〉
to be an encoding of them together into a single string. 
Notation for writing Turing machines
We will use high-level English descriptions of algorithms when we describe TMs, 
knowing that we could (in principle) convert those descriptions into states, 
transition function, etc.  Our notation for writing a TM ) is
) = “On input +
[English description of the algorithm]”
Check-in 6.3
If , and - are strings, would ,- be a good choice 
for their encoding 〈,, -〉into a single string?
a)
Yes.
b)
No. 
Check-in 6.3
8
","71.54271697998047","9","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_8_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"33","What is the relationship between Turing machines and languages in terms of countability?","Let's see. Equivalence problem for DFAs-- now we're going to take things to the next level-- ask, are there two-- I'm going to give you two DFAs. And I want to know, do they describe the same language-- do they recognize the same language? OK? So how are we going to do that? So that's a decidable language. Here's the decider. My input now is going to be two DFAs-- again, represented as a string, because that's what Turing machines deal with as their inputs. But they can unpack that string into two DFAs. And there are several different ways to do this problem, and I'm sure I'm going to get suggestions with other ways to go. One thing you could do is just to feed in strings up to a certain length. Just like before, you can't feed in all possible strings and see if the machines ever behave differently on any of them, because that's an infinite operation, and we already decided we can't do that. Now, if you want to talk about this being a recognizer, instead of a decider, then you might be able to do something like that just to make sure your-- you have to be just careful. Let me not say more on that right now. But certainly, for a decider, you can't go forever. You can't have infinite operations. So you would have to have a cut-off. So you can feed in all possible strings up to some length, say, into A and B, and see if there's any difference. Now, we actually had a problem on that in the problem set 1, which said, if two DFAs have unequal languages, then they're going to see a difference. Then there's going to be a string which acts differently on them, which is of length, at most, the product of the number of states of those two machines. So you can either reference that problem-- that would be an adequate solution-- or reprove it or whatever. That would be fine. In fact, you can do even better than that, as the optional problem showed. You only have to go up to the sum of the number of states, not up to the product. But that's actually very difficult to show. I'm not going to prove it that way. I'm going to prove it in an entirely different way, which doesn't require any analysis at all-- no proving something about balance. I'm going to take advantage of something we've already shown, which is I'm going to make a new finite automaton, a new DFAC built out of A and B, which accepts all the strings on which A and B disagree. And I'll show you how to-- that's easy to do. So first of all, let's-- in terms of a picture, let's understand what this is. So here we have-- this is the language of A, this is the language of B written as a Venn diagram. And where are those places where they disagree? Well, they're either in A, but not in B, or in B, but not in A. I'm showing it to you here in terms of the blue region. That actually has a name called the symmetric difference of these two sets. These are the-- all of the members which are in exactly one out of the two, but not both. If you can make a machine C that would accept all of the strings in the blue region, then what do we do with that machine? We test of its length language is empty, which is what we've already shown how to do-- because of the blue region is empty, that means that L of A equals L of B. So I'm going to make a machine, a DFAC where the language of C is exactly that symmetric difference. It's all the strings in A intersected with the strings that are not in B-- so in A and not in B-- or in B and not-- then not an A-- take the union of those two parts. And how do we know we can make C? Well, we have those closure constructions, which we showed several lectures back. Those closure instructions can be implemented on a Turing machine. So a Turing machine can build the DFAC, and then use that test from a few slides back, the emptiness-- the last slide-- the emptiness tester for DFAs on C to see whether its language is empty. And now, if C's language is empty, then we know we can accept, because that means the two-- that L of A equals L of B. Otherwise, we can reject. OK? So here's a note-- I'm going to ask you a check-in. You can also use that time to send me a few more questions, if you want. OK, here's my check-in. OK, now, instead of testing equivalence of finite-- of DFAs, I want to test equivalence of regular expressions. So here are R1, R2. Regular expressions are called the EQ regular expressions","71.4226303100586","10","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_10_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"34","What does showing a one-to-one correspondence between languages and real numbers illustrate?","So first, we're going to introduce this concept of regular expressions-- which, again, these are things you may have run into in one way or another before. So we're going to introduce something called the regular operations. Now, I'm sure you're familiar with the arithmetical operations, like plus and times. Those apply to numbers. The operations we're going to talk about are operations that apply to languages. So they're going to take, let's say, two languages, you apply an operation, you're going to get back another language. Like the union operation, for example, that's one you probably have seen before. The union of two languages here is a collection of strings that are in either one or the other. But there are other operations, which you may not have seen before, that we're going to look at-- the concatenation operation, for example. So that says you're going to take a string from the first language and another string from the second language and stick them together. And it's called concatenating them. And you do that in all possible ways, and you're going to get the concatenation language from these two languages that you're starting with, A and B. The symbol we use for concatenation is this little circle. But often, we don't. We just suppress that and we write the two languages next to one another with the little circle implied.","69.37531280517578","1","DPRSearchEngine","9syvZr-9xwk.en-j3PyPqV-e1s_9_mp4","9syvZr-9xwk.en-j3PyPqV-e1s","18.404J","1"
"34","What does showing a one-to-one correspondence between languages and real numbers illustrate?","says, ""if you can't prove what you want to prove, demonstrate something else and pretend they are the same thing. In the daze that follows the collision of statistics with the human mind, hardly anyone will notice the difference."" And indeed, empirically, he seems to be right. So let's look at some examples. Here's one I like. This is from another famous statistician called Anscombe. And he invented this thing called Anscombe's Quartet. I take my hat off now. It's too hot in here. A bunch of numbers, 11 x, y pairs. I know you don't want to look at the numbers, so here are some statistics about them. Each of those pairs has the same mean value for x, the same mean for y, the same variance for x, the same variance for y. And then I went and I fit a linear regression model to it. And lo and behold, I got the same equation for everyone, y equals 0.5x plus 3. So that raises the question, if we go back, is there really much difference between these pairs of x and y? Are they really similar? And the answer is, that's what they look like if you plot them. So even though statistically they appear to be kind of the same, they could hardly be more different, right? Those are not the same distributions. So there's an important moral here, which is that statistics about data is not the same thing as the data itself. And this seems obvious, but it's amazing how easy it is to forget it. The number of papers I've read where I see a bunch of statistics about the data but don't see the data is enormous. And it's easy to lose track of the fact that the statistics don't tell the whole story. So the answer is the old Chinese proverb, a picture is worth a thousand words, I urge you, the first thing you should do when you get a data set, is plot it. If it's got too many points to plot all the points, subsample it and plot of subsample. Use some visualization tool to look at the data itself. Now, that said, pictures are wonderful. But you can lie with pictures. So here's an interesting chart. These are grades in 6.0001 by gender. So the males are blue and the females are pink. Sorry for being such a traditionalist. And as you can see, the women did way better than the men. Now, I know for some of you this is confirmation bias. You say, of course. Others say, impossible, But in fact, if you look carefully, you'll see that's not what this chart says at all. Because if you look at the axis here, you'll see that actually there's not much difference. Here's what I get if I plot it from 0 to 5. Yeah, the women did a little bit better. But that's not a statistically-significant difference. And by the way, when I plotted it last year for 6.0002, the blue was about that much higher than the pink. Don't read much into either of them. But the trick was here, I took the y-axis and ran it from 3.9 to 4.05. I cleverly chose my baseline in such a way to make the difference look much bigger than it is. Here I did the honest thing of put the baseline at 0 and run it to 5. Because that's the range of grades at MIT. And so when you look at a chart, it's important to keep in mind that you need to look at the axis labels and the scales.","68.98450469970703","2","DPRSearchEngine","K2SC-WPdT6k.en-qlPKC2UN_YU_6_mp4","K2SC-WPdT6k.en-qlPKC2UN_YU","6.0002","14"
"34","What does showing a one-to-one correspondence between languages and real numbers illustrate?","I'm going to make a bit of a digression into a branch of mathematics called set theory or it's a part of mathematical logic, where the method of diagonalization was first conceived of back in the late 19th century by a mathematician called Georg Cantor. And Cantor was considering the problem of, how do you compare the relative sizes of infinite sets? For finite sets, the problem of comparing-- somebody said that Cantor went crazy. That is true. And maybe I don't know why he went crazy. But he did go-- he had some mental problems, unfortunately. And so how do we compare the sizes of sets in general? If they're finite sets, we can just count them up. We can say, whoa, this set has 11 elements, and the other set has 10 elements. So the one with 11 is bigger. Or if they both have 11, they're the same size. Well, that's not going to work for infinite sets because you can't count them up. And so he had-- Cantor had the following idea for comparing the sizes of infinite sets. And that was, basically, to see whether you can have a function that would map from one set to the other set with certain properties. And those properties are called, traditionally, well, I mean, in the past, have been called the one-to-one and onto properties for the function. I'll tell you what that means. But the concept is very simple. So a one-to-one function is a function that's mapping from A to B. Those are the two sets whose sizes we're trying to compare. And the function being one-to-one just means that there are no collisions. If you have two different elements of A, they're never going to map onto the same element of B. So two different elements of A always map onto two different elements of B. So that's the one-to-one property. It's also called injective. And the other property is called onto or surjective, which is that the range of f has to be all of B. So you're not allowed to miss any elements, but you have to hit everything. And when you have both of those properties, the function is called a one-to-one correspondence or a bijection also, OK? Now another way of looking at it-- I don't want to make this more complicated than it needs to be. It just simply means that two sets are considered to be the same size if we can match up the elements with one set with elements of the other set. You just pair them up. For example, well, if you have finite sets, that idea, that informal idea just works exactly as you would expect. For example, if we have two sets-- here's a set of puppies. Here's a set of kittens. Now we want to show that those two sets have the same size. We could count them up, as I mentioned, and see that there are six elements in both. But counting up does not work for infinite sets. So we can just match up the elements of the puppies with the kittens, and then we know we have the same number of puppies as kittens. OK, now that has the advantage of it making sense when you have infinite sets. So we're just going to extend that idea and apply it to infinite sets too. And then we'll have a notion of what it means for two infinite sets to have the same size. And you might wonder, what do you get? Are all infinite sets of the same size when you use this notion or not? What happens? Well, some strange things do happen. But there actually are quite some interesting structure there that emerges. So anyway, I don't want to rush on. Questions on any of this? If you want to-- quick question. This, hopefully, was not too hard, but I want to make sure everybody's together with me on it, so we can pop in-- I'll give a few seconds for a chat if you have any questions. The range of the set is all of the elements that you hit as you look at the different possible elements of A. So all of the things that f hits, the standard notion of a range of a function. So the range of f has to be equal to B. You have to hit everything. All right, can you think of a one-to-one correspondence as a relabeling? Yeah, I'm not sure that's helpful. But, yes, you can think of as a relabeling of the elements in a sense, but yeah. I just think of it as a matching up.","68.6391372680664","3","DPRSearchEngine","3PzuSPQPEU4.en-j3PyPqV-e1s_4_mp4","3PzuSPQPEU4.en-j3PyPqV-e1s","18.404J","8"
"34","What does showing a one-to-one correspondence between languages and real numbers illustrate?","Let's see. Equivalence problem for DFAs-- now we're going to take things to the next level-- ask, are there two-- I'm going to give you two DFAs. And I want to know, do they describe the same language-- do they recognize the same language? OK? So how are we going to do that? So that's a decidable language. Here's the decider. My input now is going to be two DFAs-- again, represented as a string, because that's what Turing machines deal with as their inputs. But they can unpack that string into two DFAs. And there are several different ways to do this problem, and I'm sure I'm going to get suggestions with other ways to go. One thing you could do is just to feed in strings up to a certain length. Just like before, you can't feed in all possible strings and see if the machines ever behave differently on any of them, because that's an infinite operation, and we already decided we can't do that. Now, if you want to talk about this being a recognizer, instead of a decider, then you might be able to do something like that just to make sure your-- you have to be just careful. Let me not say more on that right now. But certainly, for a decider, you can't go forever. You can't have infinite operations. So you would have to have a cut-off. So you can feed in all possible strings up to some length, say, into A and B, and see if there's any difference. Now, we actually had a problem on that in the problem set 1, which said, if two DFAs have unequal languages, then they're going to see a difference. Then there's going to be a string which acts differently on them, which is of length, at most, the product of the number of states of those two machines. So you can either reference that problem-- that would be an adequate solution-- or reprove it or whatever. That would be fine. In fact, you can do even better than that, as the optional problem showed. You only have to go up to the sum of the number of states, not up to the product. But that's actually very difficult to show. I'm not going to prove it that way. I'm going to prove it in an entirely different way, which doesn't require any analysis at all-- no proving something about balance. I'm going to take advantage of something we've already shown, which is I'm going to make a new finite automaton, a new DFAC built out of A and B, which accepts all the strings on which A and B disagree. And I'll show you how to-- that's easy to do. So first of all, let's-- in terms of a picture, let's understand what this is. So here we have-- this is the language of A, this is the language of B written as a Venn diagram. And where are those places where they disagree? Well, they're either in A, but not in B, or in B, but not in A. I'm showing it to you here in terms of the blue region. That actually has a name called the symmetric difference of these two sets. These are the-- all of the members which are in exactly one out of the two, but not both. If you can make a machine C that would accept all of the strings in the blue region, then what do we do with that machine? We test of its length language is empty, which is what we've already shown how to do-- because of the blue region is empty, that means that L of A equals L of B. So I'm going to make a machine, a DFAC where the language of C is exactly that symmetric difference. It's all the strings in A intersected with the strings that are not in B-- so in A and not in B-- or in B and not-- then not an A-- take the union of those two parts. And how do we know we can make C? Well, we have those closure constructions, which we showed several lectures back. Those closure instructions can be implemented on a Turing machine. So a Turing machine can build the DFAC, and then use that test from a few slides back, the emptiness-- the last slide-- the emptiness tester for DFAs on C to see whether its language is empty. And now, if C's language is empty, then we know we can accept, because that means the two-- that L of A equals L of B. Otherwise, we can reject. OK? So here's a note-- I'm going to ask you a check-in. You can also use that time to send me a few more questions, if you want. OK, here's my check-in. OK, now, instead of testing equivalence of finite-- of DFAs, I want to test equivalence of regular expressions. So here are R1, R2. Regular expressions are called the EQ regular expressions","68.45040893554688","4","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_10_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"34","What does showing a one-to-one correspondence between languages and real numbers illustrate?","And a comparison model means-- is that the items, the objects I'm storing-- I can kind of think of them as black boxes. I don't get to touch these things, except the only way that I can distinguish between them is to say, given a key and an item, or two items, I can do a comparison on those keys. Are these keys the same? Is this key bigger than this one? Is it smaller than this one? Those are the only operations I get to do with them. Say, if the keys are numbers, I don't get to look at what number that is. I just get to take two keys and compare them. And actually, all of the search algorithms that we saw on Tuesday we're comparison sort algorithms. What you did was stepped through the program. At some point, you came to a branch and you looked at two keys, and you branched based on whether one key was bigger than another. That was a comparison. And then you move some stuff around, but that was the general paradigm. Those three sorting operations lived in this comparison model.","68.41984558105469","5","DPRSearchEngine","Nu8YGneFCWE.en-j3PyPqV-e1s_2_mp4","Nu8YGneFCWE.en-j3PyPqV-e1s","6.006","4"
"34","What does showing a one-to-one correspondence between languages and real numbers illustrate?","to be able to solve problems. So this is kind of like the ""let's make an algorithm"" part of the course. 1, solve hard computational problems. I guess ""hard"" here maybe should be in quotes because we saw in the last lecture what hard means in a technical sense. Hard could mean that there's no efficient algorithm that we know how to solve a problem on. That's getting a little bit of ahead of ourselves. Computational problems with algorithms is really the key part about this goal. It's kind of the same goal that you have in a class like 6.0001 or 6.009. You're trying to convince a computer that you solved a problem on a finite set of inputs. But really what this class is about is two other things, which is more about communication to people rather than computers. Your algorithm might be correct or efficient, but you need to be able to communicate that to humans. And that's what the other two goals are. So second one is argue correctness. Basically, the thing that I'm doing to my inputs is always going to lead me to a correct output. No matter what input I give it, any valid input-- there could be an infinite space of possible inputs, and in this class, that's the case, because we want our input size to grow arbitrarily large-- we need to be able to argue correctness that it's going to return me the correct thing no matter what my inputs are. And in order to do that, that's essentially-- that's 6.042. This whole class has basically been applied 6.042. I've given you some procedures, and you have to prove things about these procedures. Or most of the time, we proved it for you, and then you've used them as black boxes.","68.252197265625","6","DPRSearchEngine","2NMtS1ecb3o.en-j3PyPqV-e1s_2_mp4","2NMtS1ecb3o.en-j3PyPqV-e1s","6.006","20"
"34","What does showing a one-to-one correspondence between languages and real numbers illustrate?","equivalents of regular expressions. Can we now conclude that this problem is also decidable, either immediately from stuff we've already shown; or yes, but would take some significant extra work; or no, because intersection is not a regular operation? So let's see if I can pull that out here-- launch the polling. Here we go. OK, I think we're just about done here. Five seconds more-- OK, ready, set, end. All right. Yes, the correct answer is A. We have basically already shown this fact, because-- why is that? Because we have shown that we can convert-- if you're given two regular expressions, and we want to test whether they're equivalent, they generate the same language, we can convert them both to find out automata. We can convert them to NFAs, and then the NFAs to DFAs. And then we can apply what we've just showed about testing equivalence of DFAs. So yes, it really follows immediately from stuff we've already shown-- the conversion, number one, and then the testing of equivalence for DFAs. So there's not really any work to do here. And in fact, what I'm trying to illustrate with this check-in-- that, once you've shown how to do some kind of a test for one model, it-- going to apply for all of the equivalent models that we've shown to be equivalent, because the Turing machine can do the constructions which show the equivalence. OK, so let's move on. Somebody didn't get the poll. Did most people not get the poll? Well, I think most of you have gotten it. Did you? I'm not seeing a lot of complaints. So if you didn't get the poll, something is wrong with your setup, and you're going to have to take the recorded check-ins that are going to launch right after this lecture's over. Sorry. But you should figure out what's wrong with the setup there, because I think most people are getting these. OK, and with that, we're going to take a little break, and then we'll continue on afterward. Let me know how this is-- should I be speed a little speedier about the little mini breaks that we're taking, or is this good for you? Feedback is always-- I'm trying to make this as good as I can for all of you. OK, I think there's a mixture of between people saying that these breaks are good. Someone says they're a little overlong, so I'll try to tighten them up a little. Some folks are saying what-- more people should be asking the TAs. I don't know how the TAs are doing, in terms of their-- I'll check with them afterward-- how well this is going for them, in terms of the questions. But I think some amount of break is good so that we don't-- so there's time to be asking questions. Otherwise, what's the point of having a live lecture? So we will start promptly when this timer runs down. So be ready to go in 55 seconds from now. Just to confirm, to show the decidability of the equivalence of two regular expressions, do we need to show that we can use a Turing machine to convert them to two DFAs first? If you want to test whether two regular expressions are equivalent, you can give any procedure for doing that deciding you want. I'm just offering one simple way to do it that takes advantage of stuff we've already shown. But if you want to dig down and do some analysis of those regular expressions to show that they describe the same language, they generate the same language, be my guest. I think that's-- actually would be complicated to do that that way. OK, so we're just about ready to go here, so let's continue. And let me take this timer off here. All right. Now, we are going to talk a little about context-free grammars. So we talked about decision problems for finite automata. Let's talk about some for grammars. OK, now I'm going to give us an analogous problem. I'm going to give you a-- I'm calling it the acceptance problem, but-- just for consistency with everything else, but it's really the generating problem. So I'm giving you a grammar-- context-free grammar G and a string that's in a string. And I want to know, is it in the language of G? So does G generate w? I'm calling that the ACFG problem. So that's going to be a decidable again. These are getting slightly harder as we're moving along, so I'm giving you a grammar and a string, and I want to know, does the grammar generate that string? Well, it's not totally trivial to solve that. One thing you might try doing is looking at all possible things, all possible derivations from that grammar and see if any one of them leads to w-- leads you to generate w. Well, you have to be careful, because as I've-- as we've shown in some of our examples, you actually could have-- because you're allowed to have variables that can get converted to empty string, you might have very long intermediate strings being generated from a, grammar which then ultimately give you a small string of terminals that get generated, a small string in the language that gets produced. You certainly don't want to try every possible derivation, because there's infinitely many different derivations-- most of them generating, of course, things that are irrelevant to the string w. But you have to know how to cut things off, and it's not immediately obvious how you do that-- unless you have done the homework problems that I asked you to do, which I'm sure very many of you have not done-- the zero point X problems, because they're-- that's going to come in handy right now. And so I'll help you through that. Remember-- you should remember, but you may not have looked at it-- something called Chomsky normal form, which is for context-free grammars, but only allows the rules to be of a special kind. And they have to look like this. They can be a variable that goes to two variables, on the right-hand side, or a variable that goes to a terminal. Those are the only kinds of rules that you're allowed. This is a special case for the empty string, but let's ignore that for-- the start variable can also work to the empty string, if you want to have a-- the empty string in a language. But that's a special case. Let's ignore that. These are the only two kinds of rules that you can have in a Chomsky normal form grammar. Once you have a Chomsky normal form grammar-- well, first of all, there's two things. First of all, you can always convert any context-free grammar into Chomsky normal form. So that's given in the textbook. You do the obvious thing. I'm not going to spend time on it. And you don't have to know it. It's just a little bit tedious, but it's straightforward and it's there, if you're curious. But the second lemma's the thing that's important to us, which is that, if you have a grammar which is in Chomsky normal form and a string that's generated, every derivation of that string has exactly 2 times the length of the string minus 1 steps. If you think about it, this is a lemma-- very easy to prove. I think the homework problem asks you to prove that in the 0.2 or whatever it was in problem set 1-- or problem set 2-- I don't remember. Rules of this kind allow you to make the string one longer, and rules of this kind allow you to produce a new terminal symbol. If the length w is n, you're going to have n minus 1 of these and n of. Those that's why you get 2n minus 1 steps. But the point is that I don't really care exactly how many. It's just that we have a bound. And once you have that bound, life is good from the point of view of giving a Turing machine which is going to decide this language-- because here's the Turing machine. What it's going to do-- the first thing is it's going to convert G into Chomsky normal form. That we assume we know how to do. Now, we're going to try all derivations, but only those of length 2-- twice the length of the string minus 1, because if any derivation is going to generate w, it has to be this many steps, now that we know the grammar is in Chomsky normal form. OK, so we have converted this problem of one that might be a very unboundedly lengthy problem and to one where it's going to terminate after some fixed number of steps. And so therefore, we can accept, if any of those generate w, and reject if not. OK? Before moving on, so this answers the problem-- shows that this language is decidable, the ACFG language. So that's something that-- make sure you understand. We're basically trying old derivations of up to-- of a certain length, because that's all that's needed when the grammar is in that form. Now we're going to use that to prove a corollary, which is important for understanding how everything fits together. And that corollary states that every context-free language is a decidable language. Every context-free language is decidable. Now, why does that follow from this? Well, suppose you have a context-free language. We know that language is generated by some context-free grammar G. That's what it means. So then you can take that grammar G and you can build it into a Turing machine. So there's going to be a term machine which is constructed with the knowledge of G. And that Turing machine is going to take its w and run the ACFG algorithm with w combined with a G that's already built into it. So it's just going to stick that grammar G in front of w, and now we run the ACFG decider. It's going to say, does degenerate w? Well, that's going to be yes every time w is in A. And so this machine here now is going to end up accepting every string that's in A, because it's every string that G generates. So that is, I think, what I wanted to say about this. Now, I feel that this corollary here throws a little bit of a curveball. And we can just pause for a moment here just to make sure you're understanding this. The tricky thing about this corollary is-- that I often get-- a question I often get where-- is when we start off with a context-free language, who gives-- how do we get G? Because we need G to build a Turing machine M sub G. So we know A is a context-free language, but how do we know what G is? Well, the point is that we may not know what G is, but we know G exists, because that's a definition of A being a context-free language. It must have a context-free grammar, by definition. And so because G exists, I now know my Turing machine, M sub G, exists. And that's enough to know that A is decidable, because it has a decider that exists. Now, if you're not going to tell me the grammar for G, I'm not going to tell you the Turing machine which decides A. But both of them exist. So if you tell me G, then I can tell you the Turing machine. So it's a subtle, tricky issue there. A certain little element maybe of-- sometimes people call it non-constructive, because we're just, in a sense, showing just that something is existing. It does the job for us, because it shows that A is a decidable language. OK, so not so many questions here-- maybe the TAs are getting them. So let's move on. Here's another check-in. So now, can we conclude that A-- instead of ACFG, APDA is decidable? People are getting this one pretty fast. Another 10 seconds-- three seconds-- OK, going to shut it down-- end polling, share results. Yeah. So this problem here is APDA is decidable. I was almost wondering whether or not to give this poll, because it has-- it's true for the same reason as poll number 1, because we know how to convert PDAs-- or we stated we can convert PDAs to CFGs. And that conversion has given in the book. We didn't do in lecture, but I just stated you have to know that fact, but not necessarily know how to do it. That's OK. But the fact is true. The conversion is in the book, and it could be implemented on a Turing machine. So if you want to know whether a PDA's language is empty, you convert it to a context-free grammar and then use this procedure here to test whether it's a language--","67.9774169921875","7","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_11_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"34","What does showing a one-to-one correspondence between languages and real numbers illustrate?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
    
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Reducibility – Concept 
If we have two languages (or problems) ! and "", then 
! is reducible to "" means that we can use "" to solve !. 
Example 1: Measuring the area of a rectangle 
is reducible to measuring the lengths of its sides. 
Example 2: We showed that !NFA is reducible to !DFA . 
Example 3: From Pset 2, PUSHER is reducible to 'CFG . 
(Idea- Convert push states to accept states.) 
If ! is reducible to "" then solving "" gives a solution to !. 
- then "" is easy →! is easy. 
- then ! is hard →"" is hard. 
this is the form we will use 
3 
Check-in 9.1 
Is Biology reducible to Physics? 
(a) Yes, all aspects of the physical world 
may be explained in terms of Physics, 
at least in principle. 
(b) No, some things in the world, maybe 
life, the brain, or consciousness, 
are beyond the realm pf Physics. 
(c) I’m on the fence on this question! 
Check-in 9.1 
","67.95408630371094","8","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_3_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"34","What does showing a one-to-one correspondence between languages and real numbers illustrate?","So coming out of this notion of sets being of the same size with this notion of countable sets, as we'll see in a minute, so let's do an example. Let's take the set of natural numbers-- 1, 2, 3, 4, dot, dot, dot, dot, and the set of integers, which includes the natural numbers but also the negative numbers and zero. So the natural numbers are typically referred to as N. The integers are typically referred to as Z. And what do we think of the relative sizes of N and Z? Well, N is a subset of Z. It's a proper subset of Z. So you might, at first glance, think that Z is larger, and they're not really going to be of the same size. But actually, it turns out that there's a very simple way-- the arithmetic and the properties of infinite sets can be a little bit surprising. And there is a way of matching up all of the elements of Z with their own elements of N. And so you can show that following that definition, that these two sets are, in fact, of the same size. So let's just quickly go make sure you see that. So here is N. Here is Z I'm going to write down a table which shows how they match up. Here is the function f of n that I'm going to be describing. That's the one-to-one correspondence. And so here are the natural numbers-- dot, dot, dot, 1 through 7, dot, dot, dot. And here are the elements of Z that I'm going to be matching up. This is how the function is working. So one, I'm going to-- f of 1 is going to be 0. F of 2 is going to be minus 1. F of 3 is going to be 1. And I'm just giving you a way to match up each of the natural numbers with integers so that every single integer has its own natural number and vice versa. So 4 goes to minus 2. 5 goes to 2. 6 goes to minus 3. 7 goes to 3, and then minus 4, and then 4, and minus 5, and then 5, and so on. You're clearly going to cover all of the integers in this way. And each of the natural numbers is going to have its own integer. And there's never going to be any collisions. There's never going to be two natural numbers assigned to the same integer. So this meets the conditions of a one-to-one correspondence and shows that the natural numbers and the integers have the same size following this definition. OK, let's do one that's slightly more complicated and, perhaps, slightly more surprising, which is that if you consider all of the rational numbers, and then they have the same-- that is a collection. Even though the rational numbers seem to be much richer and more numerous than the integers, from this perspective, they have the same size. And for the simplicity of my presentation, I'm going to consider only the positive rational numbers, which I'm going to write as Q+. So those are all of the positive rational numbers that can be expressed as a ratio of two natural numbers. And I'm going to show that there is a one-to-one correspondence between these positive rational numbers and the natural numbers. OK, so here, I'm going to, again, make a table, just as I did up above-- so comparing the natural numbers and the positive rational numbers. And to do that, I'm going to write down over here on the side, just to help you see how I'm getting this table, a separate table that has all of the positive rational numbers appearing in a nicely organized way. Here are all of the rational numbers here that have 1 as a numerator, that have 2 as a numerator, and so on, and going through across the columns, the different denominators. So the numbers inside here represent all of the different rational numbers. And so whatever rational number you have, m over n, that's going to appear down the nth row in the nth column. That number is going to appear. So they're all going to show up. And I'm going to use this table here to fill out this function. So here are all the natural numbers. And the way I'm going to assign the rational numbers to appear over here is I'm just going to work my way in from the corner. And I'm going to do that by doing layers. So first, I'll take the 1 in this number here in this corner. Then, I'll do these three that surrounded it, and then these guys that surround that, and these guys sort of in shells going around the previous ones that I've already covered. OK, so let me illustrate that. So here's 1 over 1, my first rational number that I'm going to enter into the table, appearing right over there. So next, I'm going to go 2 over 1. That's going to appear in the table over there. Now, we have 2 over 2. Now that's actually a little bit problematic because 2 over 2 has already been done. And if we put that in-- because 2 over 2 equals 1 over 1. They're both the equal to the rational number 1. So if we put 2 over 2 in this table over here, then we would no longer have the one-to-one property because both 1 and 3 would be mapping to the same point. So we're just going to simply skip over 2 over 2. I'll show that as kind of graying it out. So we're not going to add that one on to the table onto my function. But so we'll skip over that. We'll go to 1 over 2, which has not been seen before. And then we're just going to continue doing the same thing, now going to this next shell out here. 3 over 1, 3 over 2, 3 over 3-- same thing, we're going to skip over that one-- 2 over 3, 1 over 3. I hope you're getting the idea. So I'm not going to fill this table. I ran out of room to fill out this table some more. But just to look at how the process is going to continue here, we get 4 over 1. Now 4 over 2, again, is a number we previously seen because that's the rational number 2. We saw that up here when we had 2 over 1, so we're going to have to skip that one. 4 over 3, 4 over 4-- that was going to skip. 3 over 4, and so on. OK? So by following this procedure, I'm going to be able to define this function. Now this function is not particularly nice in terms of having an elegant, closed form. But it is a totally legitimate function in the sense of being a mapping from natural numbers to the positive rational numbers. And it has the one-to-one correspondence property. So it pairs up each of the natural numbers with each of the positive rational numbers. They each get their own mate, in a sense. And so that shows that the rational numbers, despite the fact that they're dense, and they have all sorts of very more much bigger seeming, they really, from this perspective of the sizes of the sets, they have the same size as the natural numbers do. And so with that, it suggests that the following definition that a set is countable if it has the same size as the natural numbers or it's finite. From this perspective, we're going to be focusing on infinite sets. But yeah, countable or countably infinite, sometimes people say, if it has the same size as the natural numbers. Or otherwise, you have to include the finite sets as well. And countable means you can just go through the elements of the set as a list. So you can count them-- the first one, the second one, the third one, the fourth one, dot, dot, dot. And once you can do that, and that counting is going to hit everything, then you know can match them-- you can pair them up with the natural numbers. And so therefore, you have a countable set. OK. So as we've shown, both Z, the integers, and the positive rational numbers are countable sets. OK? Now you might think that, well, since we're allowing ourselves to do something as arbitrary, in a way, as this kind of a function to match up the natural numbers with whatever set you're trying to measure, that every set is going to be countable, if you think about it that way because it seems like you're allowing too many possibilities. And then all the infinite sets are going to end up being the same size as the natural numbers. Well, that is, in fact, is not true. And I don't know. Cantor, is the one who discovered that. I don't know if that was surprising or not. But it is interesting, I think, that there are different sizes of infinities. And so we're going to now take a look and see that. But I want to, again, I want to stop and make sure we're all together. Can we always find a closed formula for f, somebody's asking me. I don't know. For this particular f, you probably could, but it would probably be very messy. But in general, that's not a requirement, having a closed form for the mapping function. Any function is allowed as long as a one-to-one correspondence. Are we all together on this? Are we comfortable with the notion of some infinite sets having the same size as the natural numbers, and therefore, we're going to call them countable sets? And we're going to show some other sets are going to have more elements. They're going to be uncountable. They're going to be beyond-- strictly speaking, strictly larger sets in the sense that we won't be able to put them into a one-to-one correspondence with the integers. So is N the smallest infinity? Yes, N is the smallest one. So any infinity is going to have-- you're going to always-- I don't think you even need it-- you need a special-- whenever you have an infinite collection, you can always find a subset which is going to be a countable subset and is going to be the smallest of the infinities, but there are bigger ones. All right, why don't we move on?","67.6363525390625","9","DPRSearchEngine","3PzuSPQPEU4.en-j3PyPqV-e1s_5_mp4","3PzuSPQPEU4.en-j3PyPqV-e1s","18.404J","8"
"34","What does showing a one-to-one correspondence between languages and real numbers illustrate?","which, I think, most of us would agree was not a very big number. And let's look what's going on here. If you look at this, what in some sense seems really stupid about it? What is it doing that a rational person would not want to do if they could avoid it? It's bad enough to do something once. But to do the same thing over and over again is really wasteful. And if we look at this, we'll see, for example, that fib 4 is being computed here, and fib 4 is being computed here. Fib 3 is being considered here, and here, and here. And do you think we'll get a different answer for fib 3 in one place when we get it in the other place? You sure hope not. So you think, well, what should we do about this? How would we go about avoiding doing the same work over and over again? And there's kind of an obvious answer, and that answer is at the heart of dynamic programming. What's the answer? AUDIENCE: [INAUDIBLE] JOHN GUTTAG: Exactly. And I'm really happy that someone in the front row answered the question because I can throw it that far. You store the answer and then look it up when you need it. Because we know that we can look things up very quickly. Dictionary, despite what Eric said in his lecture, almost all the time works in constant time if you make it big enough, and it usually is in Python. We'll see later in the term how to do that trick. So you store it and then you'd never have to compute it again. And that's the basic trick behind dynamic programming. And it's something called memoization, as in you create a memo and you store it in the memo. So we see this here. Notice that what we're doing is trading time for space. It takes some space to store the old results, but negligible related to the time we save. So here's the trick. We're going to create a table to record what we've done. And then before computing fib of x, we'll check if the value has already been computed. If so, we just look it up and return it. Otherwise, we'll compute it-- it's the first time-- and store it in the table. Here is a fast implementation of Fibonacci that does that. It looks like the old one, except it's got an extra argument-- memo-- which is a dictionary. The first time we call it, the memo will be empty. It tries to return the value in the memo. If it's not there, an exception will get raised, we know that.","67.303955078125","10","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_9_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"35","What defines a Context Free Grammar (CFG)?"," 
 
 
 
 
 
 
 
 
 
 
Regular 
language 
Context Free 
language 
Regular 
languages 
Recap 
Recognizer 
DFA or NFA 
PDA 
Context Free 
languages 
Generator 
Regular 
expression 
Context Free 
Grammar 
11 
","79.98799896240234","1","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_11_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"35","What defines a Context Free Grammar (CFG)?","  
  
  
  
 
 
 
  
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Equivalence of CFGs and PDAs 
Theorem: ! is a CFL iff* some PDA recognizes ! 
Done. 
In book.  You are responsible for knowing 
it is true, but not for knowing the proof. 
* “iff” = “if an only if” means the implication goes both ways. 
So we need to prove both directions: forward (→) and reverse (←). 
Check-in 4.3 
Is every Regular Language also 
a Context Free Language? 
(a) Yes 
(b) No 
(c) Not sure 
Check-in 4.3 
10 
","76.65260314941406","2","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_10_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"35","What defines a Context Free Grammar (CFG)?"," 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
18.404/6.840 Lecture 4 
Last time: 
- Finite automata → regular expressions 
- Proving languages aren’t regular 
- Context free grammars 
Today: (Sipser §2.2) 
- Context free grammars (CFGs) – definition 
- Context free languages (CFLs) 
- Pushdown automata (PDA) 
- Converting CFGs to PDAs 
1 
","76.27400207519531","3","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_1_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"35","What defines a Context Free Grammar (CFG)?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
18.404/6.840 Lecture 5 
Last time: 
- Context free grammars (CFGs) 
- Context free languages (CFLs) 
- Pushdown automata (PDA) 
- Converting CFGs to PDAs 
Today: (Sipser §2.3, §3.1) 
- Proving languages not Context Free 
- Turing machines 
- T-recognizable and T-decidable languages 
1 
","75.38480377197266","4","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_1_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"35","What defines a Context Free Grammar (CFG)?","data, and I just said whether we're going to print something. You'll notice from this slide I've elighted the printed stuff. We'll come back in a later slide and look at what's in there. But for now I want to focus on actually building the model. I need to create two vectors, two lists in this case, the feature vectors and the labels. For e in examples, featurevectors.a ppend(e.getfeatures e.getfeatures e.getlabel. Couldn't be much simpler than that. Then, just because it wouldn't fit on a line on my slide, I've created this identifier called logistic regression, which is sklearn.linearmo del.logisticregression. So this is the thing I imported, and this is a class, and now I'll get a model by first creating an instance of the class, logistic regression. Here I'm getting an instance, and then I'll call dot fit with that instance, passing it feature vecs and labels. I now have built a logistic regression model, which is simply a set of weights for each of the variables. This makes sense? Now we're going to apply the model, and I think this is the last piece of Python I'm going to introduce this semester, in case you're tired of learning about Python. And this is at least list comprehension. This is how I'm going to build my set of test feature vectors.","74.45955657958984","5","DPRSearchEngine","eg8DJYwdMyg.en-qlPKC2UN_YU_7_mp4","eg8DJYwdMyg.en-qlPKC2UN_YU","6.0002","13"
"35","What defines a Context Free Grammar (CFG)?","   
  
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
  
    
 
 
 
  
 
 
 
 
 
 
 
 
Converting CFGs to PDAs (contd) 
Theorem: If ! is a CFL then some PDA recognizes ! 
Proof construction:  Convert the CFG for ! to the following PDA. 
1) Push the start symbol on the stack. 
2) If the top of stack is 
Variable: replace with right hand side of rule (nondet choice). 
Terminal: pop it and match with next input symbol. 
3) If the stack is empty, accept. 
a
+
a
×
a
Example: 
E
E
F
T
a 
+ 
T
T 
+
+
+
+
T 
× 
T
T
T
T 
F 
9 
#$ 
E → E+T | T 
T → T×F | F 
F → ( E ) | a 
E
E 
E+T 
E + T  
T+T×F 
T T × F 
F+F×a 
F 
F
a 
a+a×a 
a
a
a 
","74.42288208007812","6","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_9_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"35","What defines a Context Free Grammar (CFG)?"," 
 
 
 
 
 
 
 
 
Machine  Learning Paradigm  
§Observe set of examples: training data 
§Infer something about process that generated that 
data 
§Use inference to make predictions about previously 
unseen data: test data 
§Supervised: given a set of feature/label pairs, find a 
rule that predicts the label associated with a previously 
unseen input 
§Unsupervised: given a set of feature vectors (without 
labels) group them into “natural clusters” 
6.0002  LECTURE 12 
3 
","74.21003723144531","7","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_3_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"35","What defines a Context Free Grammar (CFG)?","is called a derivati 
for so 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
   
 
 
 
 
 
   
 
 
 
 
 
 
 
 
  
  
   
   
 
 
 
 
   
 
 
 
 
 
  
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
!
ution steps in !
on of - from ,. 
me CFG !. 
CFG – Formal Definition 
Defn: A Context Free Grammar (CFG) ! is a 4-tuple (#, Σ, &, ') 
# finite set of variables 
Σ finite set of terminal symbols 
& finite set of rules (rule form: # → # ∪Σ ∗ )
' start variable 
For ,, - ∈ # ∪Σ ∗ write 
Check-in 4.1 
1) , ⇒ ­ if can go from , to - with one substitution step in Which of these are valid CFGs? 
∗ 
2) , ⇒ - if can go from , to - with some number of substit 
90: 
B → 0B1 | ε 
91: 
S → 0S | S1 
, ⇒,0 ⇒,1 ⇒⋯⇒,3 = -
B1 → 1B 
R → RR 
If , = ' then it is a derivation of -. 
0B → 0B 
∗ 
a) 90 only 
5 ! = 6 6 ∈Σ∗ and ' ⇒ 6} 
b) 91 only 
Defn: 8 is a Context Free Language (CFL) if 8 = 5(!) 
c) Both 90 and 91 
d) Neither 
Check-in 4.1 
3 
","74.05973815917969","8","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_3_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"35","What defines a Context Free Grammar (CFG)?"," 
 
 
 
  
  
  
  
 
 
 
 
 
 
 
 
 
 
   
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
    
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
  
   
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
  
 
Equivalence of CFGs and PDAs 
Recall Theorem: ! is a CFL iff some PDA recognizes ! 
Done. 
Need to know the fact, not the proof 
Corollaries: 
1) Every regular language is a CFL. 
2) If ! is a CFL and "" is regular then ! ∩ "" is a CFL. 
Proof sketch of (2):  
While reading the input, the finite control of the PDA for ! simulates the DFA for "". 
Note 1: If ! and "" are CFLs then ! ∩ "" may not be a CFL (will show today). 
Therefore the class of CFLs is not closed under ∩. 
Note 2: The class of CFLs is closed under ∪,∘,∗ (see Pset 2). 
2 
","73.28742218017578","9","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_2_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"35","What defines a Context Free Grammar (CFG)?","DP shows !CFG ∈P
Theorem: !CFG ∈P 
Proof :  Use DP (Dynamic Programming) = recursion + memory.
& = “On input 〈), +, R〉
same as before
S
T
R
+
-
.
1.  For each way to divide + = -. and for each rule R →ST
2.       Use & to test 〈), -, S〉and 〈), ., T〉
3.       Accept if both accept
4.  Reject if none of the above accepted.”
Then decide !CFG by starting from G’s start variable.
Total number of calls is 0(23) so time used is polynomial. 
Alternately, solve all smaller sub-problems first: “bottom up” 
Check-in 14.2
Check-in 14.2
Suppose 5 is a CFL.   
Does that imply that 5 ∈P? 
(a) Yes
(b) No. 
9
","73.10022735595703","10","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_9_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"36","What is the role of the verifier in an interactive proof system?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
If we know that some problem (say !TM) is undecidable, 
we can use that to show other problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Recall Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
2 
","73.18086242675781","1","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_2_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"36","What is the role of the verifier in an interactive proof system?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
Use our knowledge that !TM is undecidable to show other 
problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
10 
","72.29400634765625","2","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_10_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"36","What is the role of the verifier in an interactive proof system?"," 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
  
  
 
 
 
 
 
 
 
 
 
  
 
  
 
 
   
 
  
 
 
 
 
 
 
  
   
   
 
 
  
  
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
Interactive Proofs – formal model 
Two interacting parties 
Verifier (V): Probabilistic polynomial time TM 
Prover (P): Unlimited computational power 
Both P and V see input !. 
They exchange a polynomial number of polynomial-size messages. 
Then V accepts or rejects. 
Defn: Pr[ (V ↔ P) accepts ! ] = probability that V accepts when V interacts with P, given input !. 
Defn: IP = $ for some V and P (This P is an “honest” prover) 
! ∈$ → Pr [ (V ↔ P) accepts ! ] ≥ )⁄* 
! ∉$ → for any prover P, Pr [ (V ↔ P) 
, accepts ! ] ≤ .⁄* 
Think of ,P as a “crooked” prover trying to make V accept when it shouldn’t. 
An amplification lemma can improve the error probability from .⁄* to ./)0123 4 
5 
","71.47367858886719","3","DPRSearchEngine","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25_5_pdf","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25","18.404J","25"
"36","What is the role of the verifier in an interactive proof system?","So just remember, interactive proof systems, there are these two parties, the prover and the verifier. The prover has unlimited computational ability. I kind of model that as an army of students perhaps who can-- where we don't-- they can work all night. They can use computational resources. And the prover, however, we're not going to measure the computational power of the prover. That's unlimited. And so the prover can do things like find certificates. It can test whether things are satisfiable. It can factor numbers. We don't care. It can do whatever we'd like and there is no charge for the prover's computational demands. OK. So the setup we had was the prover and the verifier. Both see the input. The exchange of polynomial number of messages. And then the verifier accepts or rejects. And we had this notion of the probability that the verifier ends up accepting when paired with a particular prover. And what we want is that for strings in a language, that probability should be high for some prover. And for strings not in the language, that probability should be low no matter what the prover does. So there's nothing the prover can do. And the way it kind of suggests that at any prover. But whatever the prover's strategy cannot make the verifier accept with high probability. Just doesn't have enough information or it doesn't-- it's just not able to make the verifier accept with high probability. You might think of the prover as trying to make the verifier accept. So the P tilde is a crooked prover. I don't think that went down very well with everybody. So I have it here. Another way of looking at it, maybe it looks a little bit more like NP here where IP is the collection of languages where there's a verifier, just like we had. You can think of NP as having a verifier which can check certificates. Here the prover is going to be like the certificate so that for strings in the language, there's a prover which can interact with the verifier and make it accept a high probability. And you're not in the language, there is no prover, which can interact with the verifier and make the verifier accept with even more than low probability. What's important is this gap, just like with BPP, between acceptance or rejection. And that gap is there because we want to be able to use the amplification lemma. And if there was no gap, then you wouldn't be able to amplify and make the probability of acceptance extremely high when you want it to be in the language, when you're in the language, and extremely low when you're not in the language. OK. So I hope that refreshes your memory as to how that works.","71.43094635009766","4","DPRSearchEngine","eEXSv0jChO4.en-j3PyPqV-e1s_2_mp4","eEXSv0jChO4.en-j3PyPqV-e1s","18.404J","26"
"36","What is the role of the verifier in an interactive proof system?"," 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
Interactive Proofs – informal model 
Probabilistic 
polynomial time TM 
© Sesame Workshop. All rights reserved. This content 
is excluded from our Creative Commons license. For 
more information, see https://ocw.mit.edu/fairuse. 
Professor = Verifier (V) 
Unlimited 
computation 
Graduate Students = Prover (P) 
© Source unknown. All rights reserved. This content is excluded from our Creative 
Commons license. For more information, see https://ocw.mit.edu/fairuse. 
!
"" 
Professor wants to know if graphs ! and "" are isomorphic. 
- He asks his Students to figure out the answer. 
- But he doesn’t trust their answer. He must be convinced. 
If the Students claim that ! and "" are isomorphic, 
they can give the isomorphism and convince him. 
But what if they claim that ! and "" are not isomorphic? 
- The Professor randomly and secretly picks ! or "" and 
permutes it, then sends the result to the Students. 
- If Students can identify which graph the Professor picked 
reliably (repeat this 100 times), then he’s convinced. 
4 
","70.43575286865234","5","DPRSearchEngine","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25_4_pdf","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25","18.404J","25"
"36","What is the role of the verifier in an interactive proof system?"," 
 
  
  
 
 
 
 
 
 
   
 
 
 
 
  
 
  
 
  
 
 
  
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
   
 
    
   
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
   
  
Time Hierarchy Theorem (1/2) 
Theorem: For any !: ℕ → ℕ where ! is time constructible 
there is a language % where % requires & ! ' 
time, i.e, 
1) % is decidable in & ! ' 
time, and 
2) % is not decidable in ( ! ' / log ! ' 
time 
- .
On other words, TIME (
⊆, TIME ! ' 
/01 - . 
Proof outline:  Give TM 3 where 
1) 3 runs in & ! ' 
time 
2) 3 ensures that 4(3) ≠ 4(8) for every TM 8 that runs in ( ! ' / log ! ' 
time . 
Let % = 4(3). 
10 
","69.75520324707031","6","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_10_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"36","What is the role of the verifier in an interactive proof system?","What are oracles? Oracles are a simple thing. But they are a useful concept for a number of reasons. Especially because they're going to tell us something interesting about methods, which may or may not be useful for proving the P versus NP question, when someday somebody hopefully does that. What is an oracle? An oracle is free information you're going to give to a Turing machine, which might affect the difficulty of solving problems. And the way we're going to represent that free information is, we're going to allow the Turing machine to test membership in some specified language, without charging for the work involved. I'm going to allow you have any language at all, some language A. And say a Turing machine with an oracle for A is written this way, M with a superscript A. It's a machine that has a black box that can answer questions. Is some string, which the machine can choose, in A or not? And it gets that answer in one step, effectively for free. So you can imagine, depending upon the language that you're providing to the machine, that may or may not be useful. For example, suppose I give you an oracle for the SAT language. That can be very useful. It could be very useful for deciding SAT, for example. Because now you don't have to go through a brute force search to solve SAT. You just ask the oracle. And the oracle is going to say, yes it's satisfiable, or no it's not satisfiable. But you can use that to solve other languages too, quickly. Because anything that you can do in NP, you can reduce to SAT. So you can convert it to a SAT question, which you can then ship up to the oracle, and the oracle is going to tell you the answer. The word ""oracle"" already sort of conveys something magical. We're not really going to be concerned with the operation of the oracle, so don't ask me how does the oracle work, or what does it correspond to in reality. It doesn't. It's just a mathematical device which provides this free information to the Turing machine, which enables it to compute certain things. It turns out to be a useful concept. It's used in cryptography, where you might imagine the oracle could provide the factors to some number, or the password to some system or something. Free information. And then what can you do with that? So this is a notion that comes up in other places. If we have an oracle, we can think of all of the things that you can compute in polynomial time relative to that oracle. So that's what we-- the terminology that people usually use is sometimes called relativism, or computation relative to having this extra information. So P with an A oracle is all of the language that you can decide in polynomial time if you have an oracle for A. Let's see. Yeah. Somebody's asking me, is it really free or does it cost one unit? Even just setting up the oracle and writing down the question to the oracle is going to take you some number of steps. So you're not going to be able do an infinite number of oracle calls in zero time. So charging one step or zero steps, not going to make a difference. Because you still have to formulate the question. As I pointed out, P with a SAT oracle-- so all the things you do in polynomial time with a SAT oracle includes NP. Does it perhaps include other stuff? Or does it equal NP? Would have been a good check-in question, but I'm not going to ask that. In fact, it seems like it contains other things too. Because co-NP is also contained within P, given a SAT oracle. Because the SAT oracle answer is both yes or no, depending upon the answer. So if the formula is unsatisfiable, the oracle is going to say no, it's not in the language. And now you can do the complement of the SAT problem as well. The unsatisfiability problem. So you can do all of co-NP in the same way. You can also define NP relative to some oracle. So all the things you can do with a non-deterministic Turing machine, where all of the branches have separately access. And they can ask multiple questions, by the way, of the oracle. Independently. Let's do another, a little bit of a more challenging example. The MIN-FORMULA language, which I hope you remember from your homework. So those are all of the formulas that do not have a shorter equivalent formula. They are minimal. You cannot make a smaller formula that's equivalent that gives you the same Boolean function. So you showed, for example, that that language is in P space, as I recall. And there was some other-- you had another two problems about that language. The complement of the MIN-FORMULA problem is in NP with a SAT oracle. So mull that over for a second and then we'll see why. Here's an algorithm, in NP with a SAT oracle algorithm. So in other words, now I want to kind of implement that strategy, which I argued in the homework problem was not legal. But now that I have the SAT oracle, it's going to make it possible where before it was not possible. So let's just understand what I mean by that. If I'm trying to do the non minimal formulas, namely the formulas that do have a shorter equivalent formula. I'm going to guess that shorter formula, called psi. The challenge before was testing whether that shorter formula was actually equivalent to phi. Because that's not obviously doable in polynomial time. But the equivalence problem for formulas is a co-NP problem. Or if you like to think about it the other way, any formula in equivalence is an NP problem, because you just have to-- the witness is the assignment on which they disagree. So two formulas are equivalent if they never disagree. And so that's a co-NP problem. A SAT oracle can solve a co-NP problem. Namely, the equivalence of the two formulas, the input formula and the one that you now deterministically guessed. And if it turns out that they are equivalent, a smaller formula is equivalent to the input formula, you know the input formula is not minimal. And so you can accept. And if it gets the wrong formula, it turns out not to be equivalent, then you reject on that branch of the non-determinism, just like we did before. And if the formula really was minimal, none of the branches is going to find a shorter equivalent formula. So that's why this problem here is in NP with a SAT oracle. So now we're going to try to investigate this on my-- we're getting near the end of the lecture. We're going to look at problems like, well, suppose I compare P with a SAT oracle and NP with a SAT oracle. Could those be the same? Well, there's reasons to believe those are not the same. But could there be any A where P with A oracle is the same as NP with an A oracle? It seems like no, but actually that's wrong. There is a language, there are languages for which NP with that oracle and P with that oracle are exactly the same. And that actually is an interest-- it's not just a curiosity, it actually has relevance to strategies for solving P versus NP. Hopefully I'll be able to have time to get to. Can we think of an oracle like a hash table? I think hashing is somehow different in spirit. I understand there's some similarity there, but I don't see the-- hashing is a way of finding sort of a short name for objects, which has a variety of different purposes why you might want to do that. So I don't really think it's the same. Let's see, an oracle question, OK, let's see. How do we use SAT oracle to solve whether two formulas are equivalent? OK, this is getting back to this point. How can we use a SAT oracle to solve whether two formulas are equivalent? Well, we can use a SAT oracle to solve any NP problem, because it's reducible to SAT. In other words-- P with a SAT oracle contains all of NP, so you have to make sure you understand that part. If you have the clique problem, you can reduce. If I give you a clique problem, which is an NP problem, and I want to use the oracle to test if the formula-- if the graph has a clique, I reduce that problem to a SAT problem using the Cook-Levin theorem. And knowing that a clique of a certain size is going to correspond to having a formula which is satisfiable, now I can ask the oracle. And if I can do NP problems, I can do co-NP problems, because P is a deterministic class. Even though it has an oracle, it's still deterministic. It can invert the answer. Something that non-deterministic machines cannot necessarily do. So I don't know, maybe that's-- let's move on. So there's an oracle where P to the A equals NP to the A, which kind of seems kind of amazing at some level. Because here's an oracle where the non-determinism-- if I give you that oracle, non-determinism doesn't help. And it's actually a language we've seen. It's TQBF. Why is that? Well, here's the whole proof. If I have NP with a TQBF oracle. Let's just check each of these steps. I claim I can do that with a non-deterministic polynomial space machine, which no longer has an oracle. The reason is that, if I have polynomial space, I can answer questions about TQBF without needing an oracle. I have enough space just to answer the question directly myself. And I use my non-determinism here to simulate the non-determinism of the NP machine. So every time the NP machine branches non-deterministically, so do I. Every time one of those branches asks the oracle a TQBF question, I just do my polynomial space algorithm to solve that question myself. But now NPSPACE equals PSPACE by Savitch's theorem. And because TQBF is PSPACE complete, for the very same reason that a SAT oracle allows me to do every NP problem, a TQBF problem allows me to do every PSPACE problem. And so I get NP contained within P for a TQBF oracle. And of course, you get the containment the other way immediately. So they're equal. What does that have to do with-- somebody said-- well, I'll just-- I don't want to run out of time. So I'll take any questions at the end. What does this got to do with the P versus NP problem? OK, so this is a very interesting connection. Remember, we just showed through a combination of today's lecture and yesterday's lecture, and I guess Thursday's lecture, that this problem, this equivalence problem, is not in PSPACE, and therefore it's not in P, and therefore it's intractable. That's what we just did. We showed it's complete for a class, which is provably outside of P, provably bigger than P. That's the kind of thing we would like to be able to do to separate P and NP. We would like to show that some other problem is not in P. Some other problem is intractable. Namely, SAT. If we could do SAT, then we're good. We've solved P and NP. So we already have an example of being able to do that. Could we use the same method? Which is something people did try to do many years ago, to show that SAT is not in P. So what is that method really? The guts of that method really comes from the hierarchy there. That's where you were actually proving problems that are hard. You're getting this problem with through the hierarchy construction that's provably outside of PSPACE. And outside of P. That's a diagonalization. And if you look carefully at what's going on there-- so we're going to say, no, we're not going to be able to solve SAT, show SAT's outside of P in the same way. And the reason is, suppose we could. Well the hierarchy theorems are proved by diagonalization. What I mean by that is that in the hierarchy theorem, there's a machine D, which is simulating some other machine, M. To remember what's going on there, remember that we made a machine which is going to make its language different from the language of every machine that's running with less space or with less time. That's how D was defined. It wants to make sure its language cannot be done in less space. So it makes sure that its language is different. It simulates the machines that use less space, and does something different from what they do. Well, that simulation-- if we had an oracle, if we're trying to show that if we provide both a simulator and the machine being simulated with the same oracle, the simulation still works. Every time the machine you're simulating asks a question, the simulator has the same oracle so it can also ask the same question, and can still do the simulation. So in other words, if you could prove P different from NP using basically a simulation, which is what a diagonalization is, then you would be able to prove that P is different from NP for every oracle. So if you can prove P different from NP by a diagonalization, that would also immediately prove that P is different from NP for every oracle. Because the argument is transparent to the oracle. If you just put the oracle down, everything still works. But-- here is the big but, it can't be that-- we know that P A is-- we know this is false. We just exhibit an oracle for which they're equal. It's not the case that P is different from NP for every oracle. Sometimes they're equal, for some oracles. So something that's just basically a very straightforward diagonalization, something that's at its core is a diagonalization, is not going to be enough to solve P and NP. Because otherwise it would prove that they're different for every oracle. And sometimes they're not different, for some oracles. That's an important insight for what kind of a method will not be adequate to prove P different from NP. And this comes up all the time. People who propose hypothetical solutions that they're trying to show P different from NP. One of the very first things people ask is, well, would that argument still work if you put an oracle there. Often it does, which points out there was a flaw. Anyway, last check in. So this is just a little test of your knowledge about oracles. Why don't we-- in our remaining minute here. Let's say 30 seconds. And then we'll do a wrap on this, and I'll point out which ones are right. Oh boy, we're all over the place on this one. You're liking them all. Well, I guess the ones that are false are lagging slightly. OK, let's conclude. Did I give you enough time there? Share results. So, in fact-- Yeah, so having an oracle for the complement is the same as having an oracle. So this is certainly true. NP SAT equal coNP SAT, we have no reason to believe that would be true, and we don't know it to be true. So B is not a good choice and that's the laggard here. MIN-FORMULA, well, is in PSPACE, and anything in PSPACE is reducible to TQBF, so this is certainly true. And same thing for NP with TQBF and coNP with TQBF. Once you have TQBF, you're going to get all of PSPACE. And as we pointed out, this is going to be equal as well. So why don't we end here. And I think that's my last slide. Oh no, there's my summary here. This is what we've done. And I will send you all off on your way. How does the interaction between the Turing machine and the oracle look? Yeah, I didn't define exactly how the machine interacts with an oracle. You can imagine having a separate tape where it writes the oracle question and then goes into a special query state. You can formalize it however you like. They're all going to be-- any reasonable way of formalizing it is going to come up with the same notion in the end. It does show that P with a TQBF oracle equals PSPACE. Yes, that is correct. Good point. Why do we need the oracle to be TQBF? Wouldn't SAT also work because it could solve any NP problem? So you're asking, does P with a SAT oracle equal NP with a SAT oracle? Not known. And believed not to be true, but we don't have a compelling reason for that. No one has any idea how to do that. Because, for example, we showed the complement of MIN-FORMULA is in NP with a SAT oracle. But no one knows how to do-- because there's sort of two levels of non-determinism there. There's guessing the smaller formula, and then guessing again to check the equivalence. And they really can't be combined, because one of them is sort of an exist type guessing, the other one is kind of a for all type guessing. No one knows how to do that in polynomial time with a SAT oracle. Generally believed that they're not the same. In the check-in, why was B false? B is the same question. Does NP with a SAT oracle equal coNP with a SAT oracle? I'm not saying it's false, it's just not known to be true. It doesn't follow from anything that we've shown so far. And I think that would be something that-- well, I guess it doesn't immediately imply any famous open problem. I wouldn't necessarily expect you to know that it's an unsolved problem, but it is. Could we have oracles for undecidable language? Absolutely. Would it be helpful? Well, if you're trying to solve an undecidable problem, it would be helpful. But people do study that. In fact, the original concept of oracles was presented, was derived in the computability theory. And a side note, you can talk about reducibility. No, I don't want to even go there. Too complicated. What is not known to be true? What is not known to be true is that NP with a SAT oracle equals coNP with a SAT oracle, or equals P with a SAT oracle. Nothing is known except the obvious relations among those. Those are all unknown, and just not known to be true or false. Is NP with a SAT oracle equal to NP? Probably not. NP with a SAT oracle, for one thing, contains coNP. Because it's even more powerful. We pointed out that P with a SAT oracle contains coNP. And so NP with a SAT oracle is going to be at least as good. And so it's going to contain coNP. And so, probably not going to be equal to NP unless shockingly unexpected things happen in our complexity world.","69.75402069091797","7","DPRSearchEngine","N32bnUliSzo.en-j3PyPqV-e1s_9_mp4","N32bnUliSzo.en-j3PyPqV-e1s","18.404J","22"
"36","What is the role of the verifier in an interactive proof system?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Monte Carlo Simulation  
A method of estimating the value of an unknown 
quantity using the principles of inferential statistics 
Inferential statistics 
◦ Population: a set of examples 
◦ Sample: a proper subset of a population 
◦ Key fact: a random sample tends to exhibit the same  
properties as the population from which it is drawn  
Exactly what we did with random walks 
6.0002 LECTURE 6 
4
","69.4327621459961","8","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_4_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"36","What is the role of the verifier in an interactive proof system?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
    
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Reducibility – Concept 
If we have two languages (or problems) ! and "", then 
! is reducible to "" means that we can use "" to solve !. 
Example 1: Measuring the area of a rectangle 
is reducible to measuring the lengths of its sides. 
Example 2: We showed that !NFA is reducible to !DFA . 
Example 3: From Pset 2, PUSHER is reducible to 'CFG . 
(Idea- Convert push states to accept states.) 
If ! is reducible to "" then solving "" gives a solution to !. 
- then "" is easy →! is easy. 
- then ! is hard →"" is hard. 
this is the form we will use 
3 
Check-in 9.1 
Is Biology reducible to Physics? 
(a) Yes, all aspects of the physical world 
may be explained in terms of Physics, 
at least in principle. 
(b) No, some things in the world, maybe 
life, the brain, or consciousness, 
are beyond the realm pf Physics. 
(c) I’m on the fence on this question! 
Check-in 9.1 
","69.33427429199219","9","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_3_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"36","What is the role of the verifier in an interactive proof system?","Lab So what it takes is two values, the usual x-axis and y-axis, and then it takes another list of the same length, or sequence of the same length, which is the y errors. And here I'm just going to say 1.96 times the standard deviations. Where these variables come from you can tell by looking at the code. And then I can say the format, I want an o to show the mean, and then a label. Fmt stands for format. errorbar has different keyword arguments than plot. You'll find that you look at different ways like histograms and bar plots, scatterplots-- they all have different available keyword arguments. So you have to look up each individually. But other than this, everything in the code should look very familiar to you. And when I run the code, I get this.","69.27415466308594","10","DPRSearchEngine","soZv_KKax3E.en-qlPKC2UN_YU_7_mp4","soZv_KKax3E.en-qlPKC2UN_YU","6.0002","8"
"37","What does it mean for a set to be T-recognizable in the context of showing that ! is T-recognizable iff there is a decidable set related to a collection of string pairs?"," 
 
 
 
   
 
 
 
 
 
 
 
 
 
   
 
 
 
 
  
 
 
  
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Closure Properties for Regular Languages 
Theorem: If !"", !$ are regular languages, so is !""!$ (closure under ∘) 
Recall proof attempt: Let &"" = ()"", Σ, +"", ,"", -"") recognize !"" 
&$ = ()$, Σ, +$, ,$, -$) recognize !$ 
Construct & = (), Σ, +, ,0, -) recognizing !""!$ 
&"" 
&$ 
& should accept input 0 
if 0 = 12 where 
&"" accepts 1 and &$ accepts 2. 
& 
0 
1
2 
Doesn’t work: Where to split 0? 
Hold off. Need new concept. 
3 
","87.77265930175781","1","DPRSearchEngine","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_3_pdf","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2","18.404J","2"
"37","What does it mean for a set to be T-recognizable in the context of showing that ! is T-recognizable iff there is a decidable set related to a collection of string pairs?","  
  
 
 
  
 
  
  
 
   
   
  
 
   
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
!TM is T-unrecognizable 
Recall !TM = { & | & is a TM and ( & = ∅} 
Theorem: !TM is T-unrecognizable 
Proof: Show +TM ≤- !TM 
Reduction function: . &, 0 
= &1 
Recall TM &1 = “On input 3 
1.  If 3 ≠0, reject.
Explanation: 
&, 0 ∈ +TM iff &1 ∈!TM 
2. else run & on 0
& rejects 0 iff ( &1 
= ∅ 
3. Accept if & accepts.” 
+TM 
. 
!TM 
9 
","86.67448425292969","2","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_9_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"37","What does it mean for a set to be T-recognizable in the context of showing that ! is T-recognizable iff there is a decidable set related to a collection of string pairs?"," 
 
 
    
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Return to Closure Properties 
Recall Theorem: If !"", !$ are regular languages, so is !"" ∪!$ 
(The class of regular languages is closed under union) 
New Proof (sketch): Given DFAs &"" and &$ recognizing !"" and !$ 
&$
&"" 
ε 
ε 
& 
Construct NFA & recognizing !"" ∪!$ 
Nondeterminism 
parallelism 
vs 
guessing 
7 
","85.82384490966797","3","DPRSearchEngine","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_7_pdf","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2","18.404J","2"
"37","What does it mean for a set to be T-recognizable in the context of showing that ! is T-recognizable iff there is a decidable set related to a collection of string pairs?"," 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
Reducibility – Templates 
To prove ! is undecidable: 
- Show undecidable "" is reducible to !. (often "" is ""TM ) 
- Template: Assume TM % decides !. 
Construct TM & deciding "". Contradiction. 
To prove ! is T-unrecognizable: 
- Show T-unrecognizable "" is mapping reducible to !. (often "" is ""TM) 
- Template: give reduction function '. 
8 
","85.4693603515625","4","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_8_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"37","What does it mean for a set to be T-recognizable in the context of showing that ! is T-recognizable iff there is a decidable set related to a collection of string pairs?","   
 
 
 
 
 
   
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
  
  
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
-
=
decidable
T-recognizable
Complement of
T recognizable
co-T-recognizable
!TM
!TM
!TM is T-unrecognizable 
Theorem: If ! and ! are T-recognizable then ! is decidable 
Proof: Let TM $% and $& recognize ! and !. 
Construct TM ' deciding !. 
' = “On input )
1. Run $% and $& on ) in parallel until one accepts. 
2.   If $% accepts then accept. 
If $& accepts then reject.” 
Corollary: !TM is T-unrecognizable 
Proof: !TM is T-recognizable but also undecidable 
Check-in 8.3 
From what we’ve learned, which closure properties 
can we prove for the class of T-recognizable languages? 
Choose all that apply. 
(a) Closed under union. 
(b) Closed under intersection. 
(c) Closed under complement. 
(d) Closed under concatenation. 
(e) Closed under star. 
Check-in 8.3 
9 
","85.24188232421875","5","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_9_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"37","What does it mean for a set to be T-recognizable in the context of showing that ! is T-recognizable iff there is a decidable set related to a collection of string pairs?"," 
 
   
 
 
 
 
 
 
 
   
 
 
 
 
  
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Closure Properties continued 
Theorem: If !"", !$ are regular languages, so is !""!$ (closure under ∘) 
Proof: Let &"" = ()"", Σ, +"", ,"", -"") recognize !"" 
&$ = ()$, Σ, +$, ,$, -$) recognize !$ 
Construct & = (), Σ, +, ,0, -) recognizing !""!$ 
& should accept input 0 
if 0 = 12 where 
&"" accepts 1 and &$ accepts 2. 
&$
&"" 
& 
0 
1
2 
Doesn’t work: Where to split 0? 
12 
","84.6319580078125","6","DPRSearchEngine","b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1_12_pdf","b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1","18.404J","1"
"37","What does it mean for a set to be T-recognizable in the context of showing that ! is T-recognizable iff there is a decidable set related to a collection of string pairs?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
If we know that some problem (say !TM) is undecidable, 
we can use that to show other problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Recall Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
2 
","84.25753784179688","7","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_2_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"37","What does it mean for a set to be T-recognizable in the context of showing that ! is T-recognizable iff there is a decidable set related to a collection of string pairs?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
Use our knowledge that !TM is undecidable to show other 
problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
10 
","84.24842834472656","8","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_10_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"37","What does it mean for a set to be T-recognizable in the context of showing that ! is T-recognizable iff there is a decidable set related to a collection of string pairs?","Polynomial Time Reducibility
Defn:  ! is polynomial time reducible to "" (! ≤$ "")  if ! ≤% ""
by a reduction function that is computable in polynomial time.
Theorem:  If ! ≤$ "" and  "" ∈P  then  ! ∈P.
!
""
'
' is computable in polynomial time
≤$
≤%
NP
P
(!)
Idea to show  (!) ∈P  →P = NP 
!TM
decidable
T-recognizable
Analogy with !TM
12
","83.72958374023438","9","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_12_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"37","What does it mean for a set to be T-recognizable in the context of showing that ! is T-recognizable iff there is a decidable set related to a collection of string pairs?"," 
  
  
  
 
  
 
 
 
 
  
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
  
  
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
!""! is undecidable 
Recall !""! = ! ! has a match } 
Theorem: !""! is undecidable 
Proof: Show %TM is reducible to !""!. Uses the computation history method. 
()
Technical assumption: Match must start with 
. Can fix this assumption. 
*) 
Assume that TM + decides !""! 
Construct TM , deciding %TM 
, = “on input -, / 
1. Construct PCP instance !0,1 where a match corresponds to 
a computation history for - on /. 
2.  Use + to determine whether !0,1 has a match. 
3. Accept if yes. Reject if no.” 
9 
","83.43612670898438","10","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_9_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"38","Which of the following statements about BPP and complexity classes are known to be true: BPP is closed under union, BPP is closed under complement, P ⊆ BPP, and BPP ⊆ PSPACE?","NP and BPP
Computation trees 
for ! on ""
"" ∈$
NP
≥1 accepting
Few accepting
Many rejecting
BPP
Many accepting
Few 
rejecting
all rejecting
"" ∉$
Check-in 23.1
Check-in 23.1
Which of these are known to be true?
Check all that apply.
(a) BPP is closed under union.
(b) BPP is closed under complement.
(c) P ⊆BPP
(d) BPP ⊆PSPACE
4
","86.44430541992188","1","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_4_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"38","Which of the following statements about BPP and complexity classes are known to be true: BPP is closed under union, BPP is closed under complement, P ⊆ BPP, and BPP ⊆ PSPACE?"," 
 
  
 
 
  
 
 
 
 
 
18.404/6.840 Lecture 25 
Last time: 
- Schwartz-Zippel Theorem 
- !""ROBP ∈ BPP 
Today: (Sipser §10.4) 
- Interactive Proof Systems 
- The class IP 
- Graph isomorphism problem 
- coNP ⊆ IP  (part 1) 
1 
","81.6142349243164","2","DPRSearchEngine","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25_1_pdf","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25","18.404J","25"
"38","Which of the following statements about BPP and complexity classes are known to be true: BPP is closed under union, BPP is closed under complement, P ⊆ BPP, and BPP ⊆ PSPACE?","Example:  Branching Programs
Defn: A branching program (BP) is a directed, acyclic (no cycles) graph that has
1.  Query nodes labeled !"" and having two outgoing edges labeled 0 and 1.
2.  Two output nodes labeled 0 and 1 and having no outgoing edges.
3.  A designated start node.
BP # with query nodes !$, … , !' describes a Boolean function (: 0,1 ' →{0,1}:
Follow the path designated by the query nodes’ outgoing edges 
from the start note until reach an output node.
Example:  For !$ = 1, !/ = 0, !0 = 1 we have ( 101 = 0 = output.
BPs are equivalent if they describe the same Boolean function.
Defn:  12BP =
#$, #/
#$ and #/ are equivalent BPs (written #$ ≡#/) } 
Theorem:  12BP is coNP-complete  (on pset 6)
12BP ∈BPP ?  Unknown. That would imply NP ⊆BPP and would be surprising!
Instead, consider a restricted problem.
!$
!0
!$
!/
!/
!0
0
1
0
1
0
1
0
1
0
1
0
1
0
1
5
","80.79527282714844","3","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_5_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"38","Which of the following statements about BPP and complexity classes are known to be true: BPP is closed under union, BPP is closed under complement, P ⊆ BPP, and BPP ⊆ PSPACE?"," 
 
  
 
 
 
 
 
 
  
 
 
 
 
 
 
  
18.404/6.840 Lecture 23 
Last time: 
- !""#$%↑ is EXPSPACE-complete 
- Thus !""#$%↑ ∉ PSPACE 
- Oracles and P versus NP 
Today: (Sipser §10.2) 
- Probabilistic computation 
- The class BPP 
- Branching programs 
1 
","80.53916931152344","4","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_1_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"38","Which of the following statements about BPP and complexity classes are known to be true: BPP is closed under union, BPP is closed under complement, P ⊆ BPP, and BPP ⊆ PSPACE?"," 
  
  
 
 
 
 
 
 
 
    
 
 
  
 
 
 
 
 
 
 
 
  
 
  
    
 
 
 
  
 
   
    [ V is deterministic ]
    [ V ignores P ]
[ We won’t prove. Idea: explore all possible interactions in poly space. ]
Facts about IP – Checkin 25.2 
Which of the following is true? 
Check all that apply 
a) NP ⊆ IP 
b) BPP ⊆ IP 
c) IP ⊆ PSPACE 
Surprising Theorem: PSPACE ⊆ IP so IP = PSPACE 
We will prove only a weaker statement: coNP ⊆ IP 
7 
","80.4271469116211","5","DPRSearchEngine","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25_7_pdf","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25","18.404J","25"
"38","Which of the following statements about BPP and complexity classes are known to be true: BPP is closed under union, BPP is closed under complement, P ⊆ BPP, and BPP ⊆ PSPACE?","  
 
  
 
 
  
 
  
 
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
  
 
 
   
-
Review: Probabilistic TMs and BPP 
coin flip step 
each choice has 
Defn: A probabilistic Turing machine (PTM) is a variant of a NTM 
where each computation step has 1 or 2 possible choices. 
deterministic 
step 
50% probability 
Defn: For ! ≥0 say PTM $  decides language % with error probability !  
if for every &, Pr[ $  gives the wrong answer about & ∈% ] ≤! . 
Defn: BPP = % some poly-time PTM decides % with error !  = +⁄,  } Check-in 24.1 
Actually using a probabilistic algorithm 
Amplification lemma: 2−. /01 2 
presupposes a source of randomness. 
Can we use a standard pseudo-random 
number generator (PRG) as the source? 
& ∈% 
& ∉% 
(a) Yes, but the result isn’t guaranteed.
(b) Yes, but it will run in exponential time.
Many 
Few 
Few 
Many 
(c) No, a TM cannot implement a PRG. 
accepting 
rejecting 
accepting 
rejecting 
(d) No, because that would show P = BPP.
2 
Check-in 24.1 
","79.22169494628906","6","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_2_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"38","Which of the following statements about BPP and complexity classes are known to be true: BPP is closed under union, BPP is closed under complement, P ⊆ BPP, and BPP ⊆ PSPACE?","Intuition for P and NP
NP = All languages where can verify membership quickly
P  = All languages where can  test membership quickly
Examples of quickly verifying membership:
- !""#$""%!:  Give the Hamiltonian path. 
- &'#$'()%*(:  Give the factor. 
The Hamiltonian path and the factor are called short certificates of membership.
P ⊆NP
Question:  P = NP?  Famous unsolved problem (Cook 1971).
Conjecture:  P ≠ NP.   Some problems are NP and not in P. 
Hard to prove the conjecture because polynomial-time algorithms are powerful.
Example:  Show ""CFG ∈P.
NP
P
Check-in 14.1
Check-in 14.1
Let !""#$""%! be the complement of !""#$""%!.
So 0, 2, 3 ∈!""#$""%! if 0 does not have a Hamiltonian path from 2 to 3.  
Is !""#$""%! ∈NP?
(a) Yes, we can invert the accept/reject output of the NTM for !""#$""%!. 
(b) No, we cannot give a short certificate for a graph not to have a Hamiltonian path. 
(c) I don’t know.
6
","78.96697235107422","7","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_6_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"38","Which of the following statements about BPP and complexity classes are known to be true: BPP is closed under union, BPP is closed under complement, P ⊆ BPP, and BPP ⊆ PSPACE?"," 
 
  
  
 
 
 
 
 
 
 
 
 
 
   
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Recap: Separating Complexity Classes 
L ⊆ NL 
≠
⊆ P ⊆ NP ⊆ PSPACE 
Space Hierarchy Theorem 
NL ⊆ SPACE log& ' ⊆, SPACE ' ⊆ PSPACE 
12 
Check-in 21.3 
Consider these two famous unsolved questions: 
1. 
Does L = P? 
2. 
Does P = PSPACE? 
What do the hierarchy theorems tell us about 
these questions? 
a) Nothing 
b) At least one of these has answer “NO” 
c) 
At least one of these has answer “YES” 
Check-in 21.3 
","78.46244812011719","8","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_12_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"38","Which of the following statements about BPP and complexity classes are known to be true: BPP is closed under union, BPP is closed under complement, P ⊆ BPP, and BPP ⊆ PSPACE?"," 
 
  
 
 
 
 
 
 
  
 
 
 
 
  
  
  
  
18.404/6.840 Lecture 24 
Last time: 
- Probabilistic computation
- The class BPP
- Branching programs
- Arithmetization
- Started showing !""
ROBP ∈ BPP
Today: (Sipser §10.2)
- Finish !""
ROBP ∈ BPP
1 
","78.07849884033203","9","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_1_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"38","Which of the following statements about BPP and complexity classes are known to be true: BPP is closed under union, BPP is closed under complement, P ⊆ BPP, and BPP ⊆ PSPACE?","Satisfiability Problem
Defn: A Boolean formula ! has Boolean variables (TRUE/FALSE values) 
and Boolean operations AND (∧), OR (∨), and NOT (¬). 
Defn: ! is satisfiable if ! evaluates to TRUE for some assignment to its variables.
Sometimes we use 1 for True and 0 for False.
Example:  Let ! =
& ∨' ∧(& ∨')
(Notation:  & means ¬&)  
Then ! is satisfiable  (x=1, y=0)  
Defn:  *+, =
!
! is a satisfiable Boolean formula}
Theorem (Cook, Levin 1971):    *+, ∈P  →P = NP 
Proof method:  polynomial time (mapping) reducibility
Check-in 14.3
Check-in 14.3
Is  *+, ∈NP?
(a) Yes.
(b) No. 
(c) I don’t know.
(d) No one knows.
11
","77.45841979980469","10","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_11_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"39","How is a regular expression converted to an equivalent NFA if it is atomic?"," 
 
   
 
 
 
 
 
 
   
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Regular Expressions → NFA 
Theorem: If "" is a regular expr and # = % "" then # is regular 
Proof: Convert "" to equivalent NFA &: 
If "" is atomic: 
Equivalent & is: 
) 
Example:  
"" = ) for ) ∈Σ 
Convert a ∪ ab ∗ to equivalent NFA 
"" = ε 
a
a:
"" = ∅ 
b
b: 
a 
ε 
b 
If "" is composite: 
ab: 
a 
"" = "". ∪""/ 
a ∪ ab: 
ε 
a 
ε 
b
"" = "". ∘""/ 
Use closure constructions 
ε
}
∗ 
a ∪ ab ∗ : 
ε
"" = "". 
a
ε
ε 
a 
ε 
b
ε 
10 
ε 
","73.63896179199219","1","DPRSearchEngine","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_10_pdf","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2","18.404J","2"
"39","How is a regular expression converted to an equivalent NFA if it is atomic?"," 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Generalized NFA 
Defn: A Generalized Nondeterministic Finite Automaton (GNFA) is 
similar to an NFA, but allows regular expressions as transition labels 
a
a ∗ b ∗ 
ab
!1 
#1 
#2 
For convenience we will assume: 
b 
ε 
- One accept state, separate from the start state 
∅ 
- One arrow from each state to each state, except 
a ∪ b 
aab 
a) only exiting the start state 
#3 
#4 
b) only entering the accept state 
ε 
We can easily modify a GNFA to have this special form. 
3 
","73.26895904541016","2","DPRSearchEngine","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3_3_pdf","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3","18.404J","3"
"39","How is a regular expression converted to an equivalent NFA if it is atomic?","equivalents of regular expressions. Can we now conclude that this problem is also decidable, either immediately from stuff we've already shown; or yes, but would take some significant extra work; or no, because intersection is not a regular operation? So let's see if I can pull that out here-- launch the polling. Here we go. OK, I think we're just about done here. Five seconds more-- OK, ready, set, end. All right. Yes, the correct answer is A. We have basically already shown this fact, because-- why is that? Because we have shown that we can convert-- if you're given two regular expressions, and we want to test whether they're equivalent, they generate the same language, we can convert them both to find out automata. We can convert them to NFAs, and then the NFAs to DFAs. And then we can apply what we've just showed about testing equivalence of DFAs. So yes, it really follows immediately from stuff we've already shown-- the conversion, number one, and then the testing of equivalence for DFAs. So there's not really any work to do here. And in fact, what I'm trying to illustrate with this check-in-- that, once you've shown how to do some kind of a test for one model, it-- going to apply for all of the equivalent models that we've shown to be equivalent, because the Turing machine can do the constructions which show the equivalence. OK, so let's move on. Somebody didn't get the poll. Did most people not get the poll? Well, I think most of you have gotten it. Did you? I'm not seeing a lot of complaints. So if you didn't get the poll, something is wrong with your setup, and you're going to have to take the recorded check-ins that are going to launch right after this lecture's over. Sorry. But you should figure out what's wrong with the setup there, because I think most people are getting these. OK, and with that, we're going to take a little break, and then we'll continue on afterward. Let me know how this is-- should I be speed a little speedier about the little mini breaks that we're taking, or is this good for you? Feedback is always-- I'm trying to make this as good as I can for all of you. OK, I think there's a mixture of between people saying that these breaks are good. Someone says they're a little overlong, so I'll try to tighten them up a little. Some folks are saying what-- more people should be asking the TAs. I don't know how the TAs are doing, in terms of their-- I'll check with them afterward-- how well this is going for them, in terms of the questions. But I think some amount of break is good so that we don't-- so there's time to be asking questions. Otherwise, what's the point of having a live lecture? So we will start promptly when this timer runs down. So be ready to go in 55 seconds from now. Just to confirm, to show the decidability of the equivalence of two regular expressions, do we need to show that we can use a Turing machine to convert them to two DFAs first? If you want to test whether two regular expressions are equivalent, you can give any procedure for doing that deciding you want. I'm just offering one simple way to do it that takes advantage of stuff we've already shown. But if you want to dig down and do some analysis of those regular expressions to show that they describe the same language, they generate the same language, be my guest. I think that's-- actually would be complicated to do that that way. OK, so we're just about ready to go here, so let's continue. And let me take this timer off here. All right. Now, we are going to talk a little about context-free grammars. So we talked about decision problems for finite automata. Let's talk about some for grammars. OK, now I'm going to give us an analogous problem. I'm going to give you a-- I'm calling it the acceptance problem, but-- just for consistency with everything else, but it's really the generating problem. So I'm giving you a grammar-- context-free grammar G and a string that's in a string. And I want to know, is it in the language of G? So does G generate w? I'm calling that the ACFG problem. So that's going to be a decidable again. These are getting slightly harder as we're moving along, so I'm giving you a grammar and a string, and I want to know, does the grammar generate that string? Well, it's not totally trivial to solve that. One thing you might try doing is looking at all possible things, all possible derivations from that grammar and see if any one of them leads to w-- leads you to generate w. Well, you have to be careful, because as I've-- as we've shown in some of our examples, you actually could have-- because you're allowed to have variables that can get converted to empty string, you might have very long intermediate strings being generated from a, grammar which then ultimately give you a small string of terminals that get generated, a small string in the language that gets produced. You certainly don't want to try every possible derivation, because there's infinitely many different derivations-- most of them generating, of course, things that are irrelevant to the string w. But you have to know how to cut things off, and it's not immediately obvious how you do that-- unless you have done the homework problems that I asked you to do, which I'm sure very many of you have not done-- the zero point X problems, because they're-- that's going to come in handy right now. And so I'll help you through that. Remember-- you should remember, but you may not have looked at it-- something called Chomsky normal form, which is for context-free grammars, but only allows the rules to be of a special kind. And they have to look like this. They can be a variable that goes to two variables, on the right-hand side, or a variable that goes to a terminal. Those are the only kinds of rules that you're allowed. This is a special case for the empty string, but let's ignore that for-- the start variable can also work to the empty string, if you want to have a-- the empty string in a language. But that's a special case. Let's ignore that. These are the only two kinds of rules that you can have in a Chomsky normal form grammar. Once you have a Chomsky normal form grammar-- well, first of all, there's two things. First of all, you can always convert any context-free grammar into Chomsky normal form. So that's given in the textbook. You do the obvious thing. I'm not going to spend time on it. And you don't have to know it. It's just a little bit tedious, but it's straightforward and it's there, if you're curious. But the second lemma's the thing that's important to us, which is that, if you have a grammar which is in Chomsky normal form and a string that's generated, every derivation of that string has exactly 2 times the length of the string minus 1 steps. If you think about it, this is a lemma-- very easy to prove. I think the homework problem asks you to prove that in the 0.2 or whatever it was in problem set 1-- or problem set 2-- I don't remember. Rules of this kind allow you to make the string one longer, and rules of this kind allow you to produce a new terminal symbol. If the length w is n, you're going to have n minus 1 of these and n of. Those that's why you get 2n minus 1 steps. But the point is that I don't really care exactly how many. It's just that we have a bound. And once you have that bound, life is good from the point of view of giving a Turing machine which is going to decide this language-- because here's the Turing machine. What it's going to do-- the first thing is it's going to convert G into Chomsky normal form. That we assume we know how to do. Now, we're going to try all derivations, but only those of length 2-- twice the length of the string minus 1, because if any derivation is going to generate w, it has to be this many steps, now that we know the grammar is in Chomsky normal form. OK, so we have converted this problem of one that might be a very unboundedly lengthy problem and to one where it's going to terminate after some fixed number of steps. And so therefore, we can accept, if any of those generate w, and reject if not. OK? Before moving on, so this answers the problem-- shows that this language is decidable, the ACFG language. So that's something that-- make sure you understand. We're basically trying old derivations of up to-- of a certain length, because that's all that's needed when the grammar is in that form. Now we're going to use that to prove a corollary, which is important for understanding how everything fits together. And that corollary states that every context-free language is a decidable language. Every context-free language is decidable. Now, why does that follow from this? Well, suppose you have a context-free language. We know that language is generated by some context-free grammar G. That's what it means. So then you can take that grammar G and you can build it into a Turing machine. So there's going to be a term machine which is constructed with the knowledge of G. And that Turing machine is going to take its w and run the ACFG algorithm with w combined with a G that's already built into it. So it's just going to stick that grammar G in front of w, and now we run the ACFG decider. It's going to say, does degenerate w? Well, that's going to be yes every time w is in A. And so this machine here now is going to end up accepting every string that's in A, because it's every string that G generates. So that is, I think, what I wanted to say about this. Now, I feel that this corollary here throws a little bit of a curveball. And we can just pause for a moment here just to make sure you're understanding this. The tricky thing about this corollary is-- that I often get-- a question I often get where-- is when we start off with a context-free language, who gives-- how do we get G? Because we need G to build a Turing machine M sub G. So we know A is a context-free language, but how do we know what G is? Well, the point is that we may not know what G is, but we know G exists, because that's a definition of A being a context-free language. It must have a context-free grammar, by definition. And so because G exists, I now know my Turing machine, M sub G, exists. And that's enough to know that A is decidable, because it has a decider that exists. Now, if you're not going to tell me the grammar for G, I'm not going to tell you the Turing machine which decides A. But both of them exist. So if you tell me G, then I can tell you the Turing machine. So it's a subtle, tricky issue there. A certain little element maybe of-- sometimes people call it non-constructive, because we're just, in a sense, showing just that something is existing. It does the job for us, because it shows that A is a decidable language. OK, so not so many questions here-- maybe the TAs are getting them. So let's move on. Here's another check-in. So now, can we conclude that A-- instead of ACFG, APDA is decidable? People are getting this one pretty fast. Another 10 seconds-- three seconds-- OK, going to shut it down-- end polling, share results. Yeah. So this problem here is APDA is decidable. I was almost wondering whether or not to give this poll, because it has-- it's true for the same reason as poll number 1, because we know how to convert PDAs-- or we stated we can convert PDAs to CFGs. And that conversion has given in the book. We didn't do in lecture, but I just stated you have to know that fact, but not necessarily know how to do it. That's OK. But the fact is true. The conversion is in the book, and it could be implemented on a Turing machine. So if you want to know whether a PDA's language is empty, you convert it to a context-free grammar and then use this procedure here to test whether it's a language--","72.673828125","3","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_11_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"39","How is a regular expression converted to an equivalent NFA if it is atomic?","a Generalized Nondeterministic Finite Automaton, or a Generalized NFA, or just simply a GNFA. So this is yet another variant of the finite automaton model. And conceptually, it's very simple. It's similar to the NFAs. I'll give you-- here's a picture of a GNFA named G, G1. Very similar to the NFAs. But if you look at it for a second, you'll see that the transitions have more complicated labels. For the NFAs, we're only allowing just single symbols, or the empty string, to appear on the labels. Now I'm actually allowing you to put full regular expressions on the labels for the automaton. Now, we have to understand how a GNFA processes its input. And the way it works is not complicated to understand. When you're getting an input string feeding-- when a GNFA is processing an input string, it starts at the start state, just like you would imagine. But now, to go along a transition, instead of reading just a single symbol, or the empty string, as in the case for the nondeterministic machine, it actually gets to read a whole string at one step, kind of, at one bite. It can read an entire string and go along that transition arrow, provided that chunk of the input that it read is in the regular expression that that transition has as its label. So for example, this-- you can go from q1 to q2 in one step in this GNFA by reading a, a, b, b off the input. So it reads all of those four symbols all at once. It just swoops them up and then moves from q1 to q2 in one step. And then, when it's in q2 it can read aab and move to q3. And q3 happens, there's nowhere to go. So this is going to be a nondeterministic machine. There might be several different ways of processing the input. And if any one of them gets to an accepting state at the end of the input, we say the GNFA accepts. So it's similar to nondeterministic-- to NFAs in the way the acceptance criterion works. So you could do an example. But hopefully the concept of how this works is reasonably-- you can at least buy it, that it processes the input in chunks at a time. And those chunks have to be described by the regular expressions on the transition arrows, as it moves along those transitions. So what we're going to do now is to convert not DFAs to regular expressions, we're going to convert GNFAs to regular expression. That's even harder, because GNFAs are-- allow you to do all sorts of other things besides just ordinary DFAs. So that's a harder job. Why am I making my life harder? Well, you'll see in a minute that it's going to actually turn out to be helpful to be working with a more powerful model in the way this construction is going to work. Now, before I dive in and do the construction from GNFAs to regular expressions, I'm going to make a simplifying assumption about the GNFAs. I'm going to put them in a special form that's going to make it easier to do the conversion. And that simpler form is, first of all, I'm going to assume the GNFA has just a single accepting state. And that accepting state is not allowed to be the start state. So it has to have just a single accepting state. I've already violated that convenient assumption in this GNFA, because I have here two accepting states. That's not what I want. I want to have just one. Well, the thing is, it's easy to obtain just one, just to modify the machine so that I have just one by adding a new accepting state which is branched to from the former accepting states by empty transitions. So I can always jump from q2 to q4 at any time without even reading any input, just going along this empty transition. And then I declassify the former accepting states as accepting. And now I have here just a single accepting state. And because it's going to be a new state that I added, it won't be the start state. And I have accomplished that one aspect of my assumption about the form of the GNFA. But there's another thing that I want to do, too. I want to assume-- as you will see, which is going to be convenient in my construction-- that we will have transition arrows going from every state to every other state. In fact, I want transition arrows going from every state even back to themselves. I want there to be-- all possible transition arrows should be present, with two exceptions. For the start state, there should be only transition arrows exiting the start state. And for the accepting state-- there's just one now-- there should be only transition arrows coming into the start state. So it's kind of what you would imagine as being reasonable. For the other states, which are not accepting or starting, there should be transition arrows leaving and coming from everywhere else. But for the start states, just leaving. And from the accept state, just coming in. And you could easily modify the machine to achieve that. Let's just see how to do that in one example. So from-- notice that from q3 to q2 there is no transition right now. And that's not good. That's not what I want. I want there to be a transition from q3 to q2. Well, I'll just add that transition in. But I'm going to label it with the empty language regular expression. So that means, yeah, the transition is there, but you never can take it. So it doesn't change the language that the machine is going to be recognizing. But it fulfills my assumption, my convenient assumption, that we have all of these transition arrows being present in the machine. So anyway, I hope you will buy it. It's not going to be-- if you don't quite get this, don't worry. It's not totally critical that you're following all these little adjustments and modifications to the GNFA. But it will be helpful to understand what GNFAs themselves-- how they work. So as I mentioned, we can easily modify","72.65220642089844","4","DPRSearchEngine","KAySmSEGc9U.en-j3PyPqV-e1s_3_mp4","KAySmSEGc9U.en-j3PyPqV-e1s","18.404J","3"
"39","How is a regular expression converted to an equivalent NFA if it is atomic?"," 
 
 
 
 
 
 
 
 
 
 
Regular 
language 
Context Free 
language 
Regular 
languages 
Recap 
Recognizer 
DFA or NFA 
PDA 
Context Free 
languages 
Generator 
Regular 
expression 
Context Free 
Grammar 
11 
","72.24259948730469","5","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_11_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"39","How is a regular expression converted to an equivalent NFA if it is atomic?","of this regular expression, and then combine them, using our closure instructions, to be NFAs for larger and larger subexpressions, until I get the NFA that's the equivalent of the entire expression. So let's just see how that goes. So the very most primitive parts, the smallest subexpressions here, are just the expressions for a and for b. So here's the one just for a. So this is the NFA which recognizes the language, which is just the one string a. Here is the NFA whose language is just the one string b. And now I want an NFA which accepts only the string ab. Now, of course, you could just do that by hand yourself. It's simple enough. But what I'm arguing is that we can do this automatically, using the closure construction for concatenation. Because really there's a hidden concatenation symbol. This is a concatenate b. So now for ab, I'm going to take the thing from a and the part from b-- so these two things that I had from before, and use the concatenation construction to combine them. You see that? So now I have automatically an NFA which does the language whose string is just ab, just the ab string. And it's not the simplest NFA. You can make a simpler one, but the virtue of this one is that I got it automatically just by following the closure construction. So now I'm going to do a more complex one, just the inside here, a union ab. So the way I'm going to build that is from the two parts, the a part and the ab part, the a part and the ab part. So here is the a part. Here's the ab part. I've already got those from before. It's really kind of a proof by induction here. But I think it's simple enough, we don't have to use that language. So we have the a part, the ab part. And now we are going to apply the closure under union construction to combine those into one machine. And remember how that worked. We had a new symbol here, which branches under empty string to the previous-- we're adding a new start state, which branches to the original start states under empty transition. And now this is an NFA for this language, a union ab. And lastly, now we're one step away from getting the star of this. And how are we going to do that? We're going to take this thing here and apply the construction for the star closure. And that's going to be an NFA which does a union ab star, which is what we wanted in the first place. So first, we're going to bring that one down. Because we've already built that one. And now remember how we built the closure under star. We made the accepting states return back to the start state, and we added a new start state to make sure we got the empty string in there that transitioned to the original start state under epsilon. OK? So that's all I wanted to say for today's lecture. Let's do a quick review. Very important concept, nondeterminism and nondeterministic finite automata-- we proved they were equivalent in power, showed the class of regular languages closed under concatenation in star. We showed how to do conversion of regular expressions to NFAs. So I think that is it for today's lecture. And thank you, all, for being here. I'll try to answer a few of these. ""Why does concatenation have order?"" Well, because it's an ordered construction. Is there a simple way to prove closure under concatenation without using nondeterminism? No. ""Why are the empty strings at the accept state? Can't they be at any state? Doesn't star make copies of any part of the input?"" No, it's only-- you have to think about what's going on. You have to branch back to the beginning only on an accept. Because that means you found a piece that's in the original language. ""Is there an automaton that can add some or subtract memory automata?"" Well, depends on what you mean by all that. But certainly, there are more powerful machines that we're going to study than finite automata. But yes, there is. And even finite automata can add and subtract, if you present the input in the right way. I would refer you to the first problem on the homework. So I think I'm going to check out then. Take care, everybody. Bye-bye.","72.05866241455078","6","DPRSearchEngine","oNsscmUwjMU.en-j3PyPqV-e1s_9_mp4","oNsscmUwjMU.en-j3PyPqV-e1s","18.404J","2"
"39","How is a regular expression converted to an equivalent NFA if it is atomic?","← 
/ 
 
 
 
  
  
 
 
  
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
  
      
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Proof:  (
) Convert
to equivalent TM
.
/ = for input !:
Simulate ' (on blank input).
Whenever ' prints 0, test 0 = !. 
Accept if = and continue otherwise.
Turing Enumerators 
˽ ˽ 
˽ ˽ 
˽ ˽ ˽ . . . 
Finite 
control 
read/write tape – initially blank 
printer 
Defn: A Turing Enumerator is a deterministic TM with a printer. 
It starts on a blank tape and it can print strings !"" , !$ , !% , … possibly going forever. 
Its language is the set of all strings it prints. It is a generator, not a recognizer. 
For enumerator ' we say ( ' = ! ' prints !}. 
Theorem:  A is T-recognizable iff + = ((') for some T-enumerator '. 
' 
Proof: (→) Convert TM / to equivalent enumerator '.
Check-in 6.1 
' = Simulate / on each !2 in Σ∗ = {6, 0,1,00,01,10, … } 
When converting TM / to enumerator ', 
If / accepts !2 then print !2 .
does ' always print the strings in string order? 
Continue with next !2 .
a) Yes. 
Problem: What if / on !2 loops? 
b) No. 
Fix: Simulate / on !"" , !$ , … , !2 for 9 steps, for 9 = 1,2, … 
Print those !2 which are accepted. 
Image of the printer © Source unknown. All rights reserved. This content is excluded from 
our Creative Commons license. For more information, see https://ocw.mit.edu/fairuse. 
Check-in 6.1 
5 
","71.58224487304688","7","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_5_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"39","How is a regular expression converted to an equivalent NFA if it is atomic?"," 
 
 
 
  
 
 
 
 
  
   
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
          
 
 
  
  
   
 
 
 
 
  
 
 
 
  
 
 
Nondeterminism doesn’t
correspond to a physical machine
we can build. However, it is useful
mathematically.
accept
reject
accept
reject
Nondeterministic Finite Automata 
a 
a
!1 
b 
a,ε 
#1
#2 
#3 
#4 
b 
New features of nondeterminism: 
- multiple paths possible (0, 1 or many at each step) 
- ε-transition is a “free” move without reading input 
- Accept input if some path leads to 
accept 
Check-in 2.1 
Example inputs: 
What does !' do on input aab ? 
- ab 
- aa 
(a) Accept 
- aba 
(b) Reject 
- abb 
(c) Both Accept and Reject 
Check-in 2.1 
4 
","71.27411651611328","8","DPRSearchEngine","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_4_pdf","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2","18.404J","2"
"39","How is a regular expression converted to an equivalent NFA if it is atomic?","Now let's do closure under star. And closure under star works very similarly, but now we're just going to have a single language. If A is regular, so is A star. So they're not a pair of languages, because a star is a unary operation applying to just a single language. So if we have a DFA recognizing A, in order to show that A star is regular, we have to construct a machine that recognizes A star. And the machine we're going to construct is as before and then an NFA. OK? So here is M, the DFA for A. And we're going to build an NFA M prime that recognizes A star. And let's think now, what does it mean to recognize A star? So if I'm going to give you an input, when is it in the star language? What does M prime have to do? So remember what star is. Star means you can take as many copies of you lot as you like of strings in the original language, and that's in the star language. So to determine if something is in the star language, you have to see, can I break it up into pieces which are all in the original language? So you want to see, can I take my input w and cut it up into a bunch of pieces-- four, in this case-- where each of those pieces are members of A, the members of the original language? So that's what M prime's job is. It has its input and wants to know, can I cut that input up into pieces, each of which are accepted by the original machine M? That's what M prime does. And if you think about it a little bit, really what's happening is that as soon as M-- so M prime is going to be simulating M. That's the way I like to think about this, as having M inside. So if you were going to be doing this yourself, you're going to take w. You're going to run it for a while. You'll see, oh, M is accepted. Now I have to start him over again to see if it accepts the next segment. So every time M accepts, you're going to restart M to see if it accepts another segment. And so by doing that, you're going to be cutting w up into different segments, each of which is accepted by M. Of course, it's never totally clear whether you should, for any given segment, you should cut it there or you should wait a little longer and find another, a later place to cut. But that's exactly the same problem that we had before with concatenation. And we solved it using nondeterminism, and we're going to solve it again using nondeterminism. So the way we're going to get that effect of starting the machine over again, once it's accepted, is by adding in epsilon transitions that go from the start states back to-- from the accept state back to the start state. So now every time M has accepted, it has an option-- not a requirement, but has an option. It can either stay continuing to process, or it could restart, making a cut at that point and trying to see if there's yet a second, another segment of the input that it's going to accept. And this is basically the whole thing, with one little problem that we need to deal with. And that is we need to make sure that M prime accepts the empty string. Because remember, the empty string is always a member of the star language. And as it's written right now, we're going to be requiring there to be at least one copy of at least one segment. We're not taking into account the possibility of no segments, which is the empty string. And the way we're going to get that is-- well, I mean, one thing, one way to get to add-- so we're missing the empty string right now. So how do we fix it? Basically, we're just going to take the construction we have on the screen, and we're going to adjust it to add in the empty string. Because it's possibly missing. One way to do that, which is tempting, but wrong, is to make the start state of M an accepting state for M prime. So we could have made this an accepting state, too. And now M prime is also going to accept the empty string. That's the good news. The problem is that the start date might be playing some other role in M besides just being the start. There might be times when M comes back to the start state later on. And if we make the start state the an accept state, it's going to suddenly start accepting a bunch of other things too, which might not be intended. So it's a bad idea to make the start state an accept state. Instead, we'll take the simple solution alternative of adding a new start state, which will never be returned to under any circumstances, and make that a new start-- an accept state as well. So here, we'll have to make this additional modification. So as I'm saying, this is what we need to do. And the way we'll do that is by adding a new start state, which is also an accept state, to make sure it accepts the empty string. And then that also can branch to start off M as before, if the string that's input is not the empty string. And so then M prime is actually going to have to do some work to see if it can be cut off, as it was doing before. So that's the proof of closure under star. I'm not going to do it anything beyond what I've just described. These proofs by picture are convincing enough, I hope. And if not, they are explained in somewhat more detail, somewhat more formally, in the textbook. But for the lecture, this is where I'm going to stop, with these two arguments. And so now-- oh, we have one quick check-in on this. So if M has n states, how many states does M prime have by this construction? So I'm not intending these to be very hard, more just to keep you awake. So how many states does M prime have? OK, maybe a little too easy even for a check-in. Yeah, everybody is getting this one. Because all you did was-- we added one new state. So the answer is as you have-- I think pretty much everybody is observing that it's number b. So I'm going to end the polling, and I'm going to share the results. And everybody got that one. And so let's continue on. And so the very last thing we're going to do today is show you how to convert regular expressions to NFAs, thereby showing that every language that you can describe with a regular expression is a regular language. On Tuesday, we'll show how to do the conversion in the other direction and so thereby showing that these two methods of describing languages are equivalent to one another. So here's our theorem. If R is a regular expression, and A is the language-- a set of strings that that regular expression describes, then A is regular. OK? So we're going to show how to convert. The strategy is to convert R to an equivalent NFA M. And so we have to think about, remember, these regular expressions that we introduced last time. These are these expressions that look like ab union b star, something like that-- so built up out of the regular operations from the primitive regular expressions that don't have any operations, that we're calling atomic. So if R is an atomic regular expression, it just looks like either just a single symbol or an empty string symbol or an empty language symbol. Or R can be a composite regular expression-- whoops. We're having a little-- yeah, so we have two possibilities here. R is either atomic or composite. And so let's look at what the equivalent expression is in each case. So if R is just the single letter regular expression-- that's a totally legitimate regular expression, just a regular expression 1. So that just describes the language of the string 1. So we have to make an NFA which accepts-- which recognizes just that language, accepts only the string 1. So it's a very simple NFA. It just starts in the start state. And on that single symbol, it branches to an accept state. And there were no other transitions allowed. So if you get anything else coming in besides that one, that string, which is just that one symbol, the NFA is going to reject it. If it's too long, if it gets aa coming in, well, there's nowhere to go from this accepting state on an A. So the machine is just going to die. It has to be in an accept state at the end of the input. Now, I want you think for yourself for a minute, how do we make an NFA which accepts only the empty string and no other strings? You can do that with just one state with an NFA, just this one here. The machine is going to start off in the start state, which is also immediately an accept state. So it accepts the empty string. But if anything else comes in, there's nowhere to go when the machine dies. So this machine accepts just the empty string. Or its language is the language with one element, the empty string. How about the empty language? Well, here's an NFA which has no accepting state, so it can't be accepting anything. Now, if we have a composite regular expression, we're already finished. Because we showed how to build up-- we showed constructions which give us closure under union, concatenation, and star. And those constructions are going to enable us to build up the NFAs that do the language of these more complex regular expressions built up out of the NFAs that do the individual parts. So if we already have NFAs that do R1 and R2, then the closure under union construction gives us an NFA that does R1 union R2 as a language. So I hope that's clear, but I'm going to do an example which will hopefully illustrate it. And it's going to show you-- basically, what I'm giving you is an automatic procedure for converting a regular expression into an equivalent NFA. So let's just see that procedure in action, which is really just following this recipe that I described for you. So here is a regular expression a union ab star. So this is a regular expression. It's some language. Whatever it is, I don't care. But I want to make an NFA which recognizes that same language. And the way I'm going to do that is first build","71.02365112304688","9","DPRSearchEngine","oNsscmUwjMU.en-j3PyPqV-e1s_8_mp4","oNsscmUwjMU.en-j3PyPqV-e1s","18.404J","2"
"39","How is a regular expression converted to an equivalent NFA if it is atomic?","  
 
 
  
 
 
 
    
 
    
 
 
        
 
        
 
            
 
        
 
            
  
    
 
          
 
    
 
 
    
 
          
 
 
 
 
A Simulation of Die Rolling  
def runSim(goal, numTrials, txt): 
total = 0 
for i in range(numTrials): 
result = '' 
for j in range(len(goal)): 
result += str(rollDie()) 
if result == goal: 
total += 1 
print('Actual probability of', txt, '=', 
round(1/(6**len(goal)), 8)) 
estProbability = round(total/numTrials, 8) 
print('Estimated Probability of', txt, '=', 
round(estProbability, 8)) 
runSim('11111', 1000, '11111') 
6.0002 LECTURE 4 
15
","70.54772186279297","10","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_15_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"41","How do the labeling rules for probabilities correspond to the TRUE rows in the Boolean function truth table?"," 
 
 
    
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Return to Closure Properties 
Recall Theorem: If !"", !$ are regular languages, so is !"" ∪!$ 
(The class of regular languages is closed under union) 
New Proof (sketch): Given DFAs &"" and &$ recognizing !"" and !$ 
&$
&"" 
ε 
ε 
& 
Construct NFA & recognizing !"" ∪!$ 
Nondeterminism 
parallelism 
vs 
guessing 
7 
","77.08106231689453","1","DPRSearchEngine","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_7_pdf","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2","18.404J","2"
"41","How do the labeling rules for probabilities correspond to the TRUE rows in the Boolean function truth table?"," 
 
 
 
   
 
 
 
 
 
 
 
 
 
   
 
 
 
 
  
 
 
  
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Closure Properties for Regular Languages 
Theorem: If !"", !$ are regular languages, so is !""!$ (closure under ∘) 
Recall proof attempt: Let &"" = ()"", Σ, +"", ,"", -"") recognize !"" 
&$ = ()$, Σ, +$, ,$, -$) recognize !$ 
Construct & = (), Σ, +, ,0, -) recognizing !""!$ 
&"" 
&$ 
& should accept input 0 
if 0 = 12 where 
&"" accepts 1 and &$ accepts 2. 
& 
0 
1
2 
Doesn’t work: Where to split 0? 
Hold off. Need new concept. 
3 
","75.54620361328125","2","DPRSearchEngine","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_3_pdf","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2","18.404J","2"
"41","How do the labeling rules for probabilities correspond to the TRUE rows in the Boolean function truth table?"," 
 
 
  
 
 
 
  
 
 
  
 
 
  
 
 
  
 
 
 
 
  
 
  
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
  
   
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
NO.
Oracles and P versus NP 
Theorem: There is an oracle ! where P "" = NP "" 
Proof: Let ! = $%&' 
NP()*+ ⊆ NPSPACE = PSPACE ⊆ P()*+ 
Relevance to the P versus NP question 
Recall: We showed -%./0↑ ∉ PSPACE. 
Could we show 3!$ ∉ P using a similar method? 
Reason: Suppose YES. 
The Hierarchy Theorems are proved by a diagonalization. 
In this diagonalization, the TM 4 simulates some TM 5. 
If both TMs were oracle TMs 4"" and 5"" with the same oracle !, 
the simulation and the diagonalization would still work. 
Therefore, if we could prove P ≠ NP by a diagonalization, 
we would also prove that P "" ≠ NP "" for every oracle !. 
But that is false! 
9 
Check-in 22.3 
Which of these are known to be true? 
Check all that apply. 
P7""( 
P7""( 
(a) 
= 
(b) NP7""( = coNP7""( 
(c) MIN-FORMULA ∈ P()*+ 
NP()*+ = coNP()*+ 
(d) 
Check-in 22.3 
","75.4998779296875","3","DPRSearchEngine","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_9_pdf","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22","18.404J","22"
"41","How do the labeling rules for probabilities correspond to the TRUE rows in the Boolean function truth table?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
Use our knowledge that !TM is undecidable to show other 
problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
10 
","75.30001068115234","4","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_10_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"41","How do the labeling rules for probabilities correspond to the TRUE rows in the Boolean function truth table?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
If we know that some problem (say !TM) is undecidable, 
we can use that to show other problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Recall Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
2 
","75.22392272949219","5","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_2_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"41","How do the labeling rules for probabilities correspond to the TRUE rows in the Boolean function truth table?","!""#$""%! is NP-complete
Theorem:  !""#$""%! is NP-complete
Proof:  Show 3'""% ≤) !""#$""%! (assumes 3'""% is NP-complete)
Idea:  “Simulate” variables and clauses with “gadgets” 
* =
,- ∨,/ ∨,0
∧
,- ∨,/ ∨,2
∧⋯∧
variable gadget
. . .
Zig-zag
clause gadget
4
〈6, 8, 9〉
,-
8
Zag-zig
Corresponds to setting ,- TRUE
Corresponds to setting ,- FALSE
7
","74.84466552734375","6","DPRSearchEngine","c1aca7046a69c913721e5eb910a5fb21_MIT18_404f20_lec15_7_pdf","c1aca7046a69c913721e5eb910a5fb21_MIT18_404f20_lec15","18.404J","15"
"41","How do the labeling rules for probabilities correspond to the TRUE rows in the Boolean function truth table?"," 
 
 
 
   
 
 
 
 
 
 
 
   
 
 
 
 
  
 
 
  
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
&$
1
&""
,
Closure Properties for Regular Languages 
Theorem: If !"", !$ are regular languages, so is !"" ∪!$ (closure under ∪) 
Proof: Let &"" = ()"", Σ, +"", ,"", -"") recognize !"" 
&$ = ()$, Σ, +$, ,$, -$) recognize !$ 
Construct & = (), Σ, +, ,0, -) recognizing !"" ∪!$ 
& should accept input 0 if either &"" or &$ accept 0. 
Components of 2:
Check-in 1.1 
) = )""×)$ 
In the proof, if &"" and &$ are finite automata 
= 
,"", ,$ ,"" ∈ )"" and ,$ ∈ )$}
where &"" has 8"" states and &$ has 8$ states 
,6 = (,"", ,$)
Then how many states does & have? 
(a) 8"" + 8$ 
+ ,, 1 , 7 = +"" ,, 7 , +$ 1, 7 
(b) 
8"" $ + 8$ $ 
- = -""×-$ NO! [gives intersection] 
(c) 8""×8$ 
- = -""×)$ ∪ )""×-$ 
Check-in 1.1 
11 
","74.58878326416016","7","DPRSearchEngine","b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1_11_pdf","b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1","18.404J","1"
"41","How do the labeling rules for probabilities correspond to the TRUE rows in the Boolean function truth table?","   
  
 
 
   
 
 
 
 
 
 
 
   
 
 
 
 
 
 
   
 
   
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
!""#$ ∈ PSPACE 
Theorem: !""#$ ∈ PSPACE 
Proof: “On input 〈'〉 
1. If ' has no quantifiers, then ' has no variables 
so either ' = True or ' = False.  Output accordingly. 
2. If ' = ∃+ , then evaluate , with + = TRUE and + = FALSE recursively. 
Accept if either accepts. Reject if not. 
3. If ' = ∀+ , then evaluate , with + = TRUE and + = FALSE recursively. 
Accept if both accept. Reject if not.” 
Space analysis: 
Each recursive level uses constant space (to record the + value). 
The recursion depth is the number of quantifiers, at most . = | ' |. 
So !""#$ ∈ SPACE(.) 
6 
","74.37293243408203","8","DPRSearchEngine","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17_6_pdf","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17","18.404J","17"
"41","How do the labeling rules for probabilities correspond to the TRUE rows in the Boolean function truth table?","Satisfiability Problem
Defn: A Boolean formula ! has Boolean variables (TRUE/FALSE values) 
and Boolean operations AND (∧), OR (∨), and NOT (¬). 
Defn: ! is satisfiable if ! evaluates to TRUE for some assignment to its variables.
Sometimes we use 1 for True and 0 for False.
Example:  Let ! =
& ∨' ∧(& ∨')
(Notation:  & means ¬&)  
Then ! is satisfiable  (x=1, y=0)  
Defn:  *+, =
!
! is a satisfiable Boolean formula}
Theorem (Cook, Levin 1971):    *+, ∈P  →P = NP 
Proof method:  polynomial time (mapping) reducibility
Check-in 14.3
Check-in 14.3
Is  *+, ∈NP?
(a) Yes.
(b) No. 
(c) I don’t know.
(d) No one knows.
11
","74.13153839111328","9","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_11_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"41","How do the labeling rules for probabilities correspond to the TRUE rows in the Boolean function truth table?"," 
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
(
&
&
Constructing the !! graph ! 
Illustrate construction by example 
Say "" = ∃%& ∀%( ∃%) ⋯ ∀%+ [ ( %& ∨%( ∨%) ) ∧(%& ∨%( ∨%1) ∧⋯∧( ⋯) ]
! = 
3( 
3+ 
Endgame 
∀
∃ should win if assignment satisfied all clauses
3+ 
∀ should win if some unsatisfied clause 
Implementation 
∃
∀ picks clause node claimed unsatisfied
∃ picks literal node claimed to satisfy the clause 
liar will be stuck 
TRUE 
FALSE 
∀ 
⋯
3
3
%)
%
%( 
%&
%( %1 
%( 
⋮ 
%5 
%& 
3& 
∃ 
∀ 
∀ 
I = ∃ 
II = ∀ 
∃ 
∀ 
∃
∃ 
∀ 
∃ 
6
∃ 6 
%&
%& 
3& 
3( 
∀ 
5 
","74.12803649902344","10","DPRSearchEngine","fd9c1b8656c7def498dcf662f6750d87_MIT18_404f20_lec19_5_pdf","fd9c1b8656c7def498dcf662f6750d87_MIT18_404f20_lec19","18.404J","19"
"42","What is a self-reproduction paradox?","  
 
 
 
 
  
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
Self-reproduction Paradox 
Suppose a Factory makes Cars 
- Complexity of Factory > Complexity of Car 
(because Factory needs instructions for Car + robots, tools, … ) 
Can a Factory make Factories? 
- Complexity of Factory > Complexity of Factory? 
- Seems impossible to have a self-reproducing machine 
But, living things self-reproduce 
How to resolve this paradox? 
© Source unknown. All rights reserved. This content is excluded from our Creative 
Commons license. For more information, see https://ocw.mit.edu/fairuse. 
Self-reproducing machines are possible! 
3 
","76.88813781738281","1","DPRSearchEngine","779043ea724131d008eae652d703938f_MIT18_404f20_lec11_3_pdf","779043ea724131d008eae652d703938f_MIT18_404f20_lec11","18.404J","11"
"42","What is a self-reproduction paradox?"," 
 
 
   
 
 
 
   
   
      
 
 
 
 
 
 
  
 
Stochastic Processes  
An ongoing process where the next state might depend on 
both the previous states and some random element 
def rollDie(): 
"""""" returns an int between 1 and 6"""""" 
def rollDie(): 
"""""" returns a randomly chosen int 
between 1 and 6"""""" 
6.0002 LECTURE 4 
8
","64.2565689086914","2","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_8_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"42","What is a self-reproduction paradox?","OK, so today's topic is about self-reference, self-reproducing machines, and the broader topic called the recursion theorem. So let me introduce it with what I would call the self-reproduction paradox. And that is, suppose you have a factory, like a Tesla effect or a car manufacturing factory. See, there's a picture of the factory, and it's producing cars. All right? So we have a factory that makes cars. And what can we say about the relative complexity of the cars compared with the factory, in some informal sense? So I would argue that you would be reasonable to say that the complexity of the factory is going to have to be greater than the complexity of the cars that it makes. Because not only does the factory have to know how to make the cars, so it has to have all the instructions and whatever things that go into a car, it has to be included in at least some kind of-- it has to be, in some sense, represented in the factory. But the factory also has to have other stuff-- the robots, and the other manufacturing items, tools, and so on-- for making the cars. So the factory has to have all the complexity of a car incorporated plus other things as well. And for that reason, one could imagine that the factory's complexity is more than the car's complexity. But now, suppose you want to have a factory that makes factories-- so imagine here's the picture-- or in general, a machine that makes copies of itself. Well, that seems, at first glance, to be impossible. Because not only does the factory obviously have to have all of the instructions for what a factory is like, but it needs to have all of the extra things that it would need to do the manufacturing. And so for that reason, it seems like it's not possible to have a machine make copies of itself. I mean, you would run into the very same problem if I asked you to produce a program in your favorite language that prints out itself-- an exact copy of the same code. You can always write a program which is going to print out some string, like Hello, world. That's easy because you just put Hello, world into some kind of a variable or some sort of a table into the program and say print that table. But if you want the program to print out a copy of itself, you can't take the whole program and stick that into a table because the program is going to have to be bigger than the table. And so, you're going to end up with something impossible happening. Because the program-- an entire copy of the program can't fit inside the program. You just get the program inside itself, inside itself, inside itself, forever. And so, you end up with an infinite program that way. So if you just kind of naively approach the problem for how to make a program which is going to print out a copy of itself, it's not so easy to do. But hopefully, after today's lecture, you will see that it is possible and in fact, how to do it. And not only that is an idle bit of curiosity, but there are actually applications for why you might want to do that, mainly within mathematics and in computer science theory. But there's even a kind of a real-world application, if you will, in a way too. So we'll get to that at the end. So it seems, as I'm saying, impossible to have a self-reproducing machine. But we know that in the world, there are things that make copies of themselves-- living things. So it seems like a paradox. Cells can make copies exactly of themselves. All living things can make copies of themselves. So how do they manage to get around this paradox? Well, in fact, it is no paradox because it is possible to make a machine that self-reproduces, that makes copies of itself. And this has been known for many years. Probably, it goes back to Von Neumann who wrote a famous paper on self-reproducing machines. OK, so self-reproducing machines are, in fact, possible.","62.96935272216797","3","DPRSearchEngine","N-_XmLanPYg.en-j3PyPqV-e1s_2_mp4","N-_XmLanPYg.en-j3PyPqV-e1s","18.404J","11"
"42","What is a self-reproduction paradox?"," 
 
 
 
 
 
 
A  Subclass of Field, part 2  
def moveDrunk(self, drunk):  
Field.moveDrunk(self, drunk)  
x = self.drunks[drunk].getX()  
y = self.drunks[drunk].getY()  
if (x, y) in self.wormholes:  
self.drunks[drunk] = self.wormholes[(x, y)]  
6.0002  LECTURE 5 
37 
","62.94081115722656","4","DPRSearchEngine","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_37_pdf","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5","6.0002","5"
"42","What is a self-reproduction paradox?","So the file is in the zip file I uploaded. It looks more or less like this. Right? So it's very straightforward. The outcomes are binary. 1 is a positive outcome. Strangely enough in the medical jargon, a death is a positive outcome. I guess maybe if you're responsible for the medical bills, it's positive. If you're the patient, it's hard to think of it as a good thing. Nevertheless, that's the way that they talk. And the others are all there, right?","62.151702880859375","5","DPRSearchEngine","esmzYhuFnds.en-qlPKC2UN_YU_8_mp4","esmzYhuFnds.en-qlPKC2UN_YU","6.0002","12"
"42","What is a self-reproduction paradox?"," 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
Law of Large Numbers  
In repeated independent tests with the same actual 
probability p of a particular outcome in each test, the 
chance that the fraction of times that outcome occurs 
differs from p converges to zero as the number of trials 
goes to infinity 
Does this imply that if 
deviations from expected 
behavior occur, these 
deviations are likely to be 
evened out by opposite 
deviations in the future? 
6.0002 LECTURE 6 
14
","61.16674041748047","6","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_14_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"42","What is a self-reproduction paradox?","What's the probability of at least two people in a group having the same birthday? There's a URL at the bottom. That's pointing to a Google form. I'd like please all of you who have a computing device to go to it and fill out your birthday. It's anonymous, so we won't know how old you are, don't worry. Actually, it's only the date. It's not the year. So suppose there were 367 people in the group, roughly the number of people who took the 6.0001 600 midterm. If they are 367 people, what's the probability of at least two of them sharing a birthday? One, by something called the pigeonhole principle. You got some number of holes. And if you have more pigeons than holes, two pigeons have to share a whole. What about smaller numbers? Well, if we make a simplifying assumption that each birthdate is equally likely, then there's actually a nice closed-form solution for it. Again, this is a question where it's easier to compute the opposite of what you're trying to do and subtract it from 1. And so this fraction is giving the probability of two people not sharing a birthday. The proof that this is right, it's a little bit elaborate. But you can trust me, it's accurate. But it's a formula, and it's not that complicated a formula. So numbers like 366 factorial are big. So let's approximate a solution. We'll right a simulation and see if we get the same answer that that formula gave us. So here's the code for that-- two arguments-- the number of people in the group and the number that we asking do they have the same birthday. So since I'm assuming for now that every birthday is equally likely, the possible dates range from 1 to 366, because some years have a February 29. I'll keep track of the number of people born in each date by starting with none. And then for p in the range of number of people, I'll make a random choice of the possible dates and increment that element of the list by 1. And then at the end, we can say, look at the maximum number of birthdays and see if it's greater than or equal to the number of same. So that tells us that. And then we can actually look at the birthday problem-- number of people, the number of same, and, as usual, the number of trials. So the number of hits is 0 for t in range number of trials. If sameDate is true, then we'll increment the number of hits by 1 and then as usual divide by the number of trials. And we'll try it for 10, 20, 40, and 100 people. And then just, we'll print the estimated probability","61.06247329711914","7","DPRSearchEngine","-1BnXEwHUok.en-qlPKC2UN_YU_9_mp4","-1BnXEwHUok.en-qlPKC2UN_YU","6.0002","4"
"42","What is a self-reproduction paradox?","provides information about the possible behaviors of a system. I say possible behaviors, because I'm particularly interested in stochastic systems. They're descriptive not prescriptive in the sense that they describe the possible outcomes. They don't tell you how to achieve possible outcomes. This is different from what we've looked at earlier in the course, where we looked at optimization models. So an optimization model is prescriptive. It tells you how to achieve an effect, how to get the most value out of your knapsack, how to find the shortest path from A to B in a graph. In contrast, a simulation model says, if I do this, here's what happens. It doesn't tell you how to make something happened. So it's very different, and it's why we need both, why we need optimization models and we need simulation models. We have to remember that a simulation model is only an approximation to reality. I put in an approximation to the distribution of birthdates, but it wasn't quite right. And as the very famous statistician George Box said, ""all models are wrong, but some are actually very useful."" In the next lecture, we'll look at a useful class of models. When do we use simulations? Typically, as we've just shown, to model systems that are mathematically intractable, like the birthday problem we just looked at. In other situations, to extract intermediate results-- something happens along the way to the answer. And as I hope you've seen that simulations are used because we can play what if games by successively refining it. We started with a simple simulation that assumed that we only asked the question of, do two people share a birthday. We showed how we could change it to ask do three people share a birthday. We then saw that we could change it to assume a different distribution of birthdates in the group. And so we can start with something simple. And we get it ever more complexed to answer questions what if. We're going to start in the next lecture by producing a simulation of a random walk. And with that, I'll stop. And see you guys soon.","60.96295166015625","8","DPRSearchEngine","-1BnXEwHUok.en-qlPKC2UN_YU_12_mp4","-1BnXEwHUok.en-qlPKC2UN_YU","6.0002","4"
"42","What is a self-reproduction paradox?","A pretty small number. But the probability of 26 consecutive reds when the previous 25 rolls were red is what? No, that. AUDIENCE: Oh, I thought you meant it had been 26 times again. JOHN GUTTAG: No, if you had 25 reds and then you spun the wheel once more, the probability of it having 26 reds is now 0.5, because these are independent events. Unless of course the wheel is rigged, and we're assuming it's not. People have a hard time accepting this, and I know it seems funny. But I guarantee there will be some point in the next month or so when you will find yourself thinking this way, that something has to even out. I did so badly on the midterm, I will have to do better on the final. That was mean, I'm sorry. All right, speaking of means-- see? Professor Grimson not the only one who can make bad jokes. There is something-- it's not the gambler's fallacy-- that's often confused with it, and that's called regression to the mean. This term was coined in 1885 by Francis Galton in a paper, of which I've shown you a page from it here.","60.80133819580078","9","DPRSearchEngine","OgO1gpXSUzU.en-j3PyPqV-e1s_8_mp4","OgO1gpXSUzU.en-j3PyPqV-e1s","6.0002","6"
"42","What is a self-reproduction paradox?","   
 
 
 
 
How  Likely Is it Just Bad Luck?  
A variant of cherry picking called  
multiple hypothesis testing 
6.0002  LECTURE 15 
14 
","60.54629135131836","10","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_13_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"43","What are the two conditions for a problem to be considered PSPACE-complete?","≤ 
≤ 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
   
 
 
 
  
  
 
 
 
  
 
 
 
 
Why
% and not
%'%()* when defining PSPACE-complete?
- Reductions should be “weaker” than the class. Otherwise all
problems in the class would be reducible to each other, and then 
all problems in the class would be complete.
Theorem: +,!- is PSPACE-complete
PSPACE-completeness 
Defn: ! is PSPACE-complete if 
1) ! ∈ PSPACE 
2) For all # ∈ PSPACE, # ≤% ! 
If ! is PSPACE-complete and ! ∈ P then P = PSPACE. 
Check-in 18.1 
Knowing that +,!- is PSPACE-complete, 
what can we conclude if +,!- ∈ NP? 
Check all that apply. 
(a) P = PSPACE 
(b) NP = PSPACE 
(c) P = NP 
(d) NP = coNP 
5 
PSPACE-complete 
NP-complete 
PSPACE = 
NPSPACE 
NP
P 
Think of complete problems as the “hardest” 
in their associated class. 
Check-in 18.1 
","80.41665649414062","1","DPRSearchEngine","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18_5_pdf","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18","18.404J","18"
"43","What are the two conditions for a problem to be considered PSPACE-complete?"," 
 
 
 
 
 
 
  
 
  
 
 
   
 
 
 
    
 
 
 
 
 
 
  
  
 
 
 
 
  
 
 
 
  
 
 
NP ⊆ PSPACE 
Theorem: NP ⊆ PSPACE 
Proof: 
1. ""#$ ∈ PSPACE 
2. If # ≤' ( and ( ∈ PSPACE then # ∈ PSPACE 
PSPACE 
Defn: coNP = # # ∈ NP}
*#+,#$* ∈ coNP 
coNP 
NP
$#-$./.01 = 2 all assignments satisfy 2} ∈ coNP 
coNP ⊆ PSPACE (because PSPACE = coPSPACE) 
Or possibly: 
P 
P = PSPACE ? Not known. 
P = NP = coNP = PSPACE 
4 
","77.35633850097656","2","DPRSearchEngine","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17_4_pdf","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17","18.404J","17"
"43","What are the two conditions for a problem to be considered PSPACE-complete?","Satisfiability Problem
Defn: A Boolean formula ! has Boolean variables (TRUE/FALSE values) 
and Boolean operations AND (∧), OR (∨), and NOT (¬). 
Defn: ! is satisfiable if ! evaluates to TRUE for some assignment to its variables.
Sometimes we use 1 for True and 0 for False.
Example:  Let ! =
& ∨' ∧(& ∨')
(Notation:  & means ¬&)  
Then ! is satisfiable  (x=1, y=0)  
Defn:  *+, =
!
! is a satisfiable Boolean formula}
Theorem (Cook, Levin 1971):    *+, ∈P  →P = NP 
Proof method:  polynomial time (mapping) reducibility
Check-in 14.3
Check-in 14.3
Is  *+, ∈NP?
(a) Yes.
(b) No. 
(c) I don’t know.
(d) No one knows.
11
","77.17356872558594","3","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_11_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"43","What are the two conditions for a problem to be considered PSPACE-complete?"," 
 
 
  
 
   
   
  
   
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
  
 
   
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
Relationships between 
Time and SPACE Complexity 
Theorem: For ! "" ≥"" 
1) TIME ! "" 
⊆ SPACE ! "" 
2) SPACE ! "" 
⊆ TIME 2& ' ( 
= ⋃+ TIME ,' ( 
Proof: 
1) A TM that runs in !("") steps cannot use more than !("") tape cells. 
2) A TM that uses !("") tape cells cannot use more than ,' ( time 
without repeating a configuration and looping (for some ,). 
Corollary: P ⊆ PSPACE 
Theorem: NP ⊆ PSPACE [next slide] 
3 
","76.06559753417969","4","DPRSearchEngine","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17_3_pdf","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17","18.404J","17"
"43","What are the two conditions for a problem to be considered PSPACE-complete?"," 
 
  
  
 
 
 
 
 
 
 
 
 
 
   
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Recap: Separating Complexity Classes 
L ⊆ NL 
≠
⊆ P ⊆ NP ⊆ PSPACE 
Space Hierarchy Theorem 
NL ⊆ SPACE log& ' ⊆, SPACE ' ⊆ PSPACE 
12 
Check-in 21.3 
Consider these two famous unsolved questions: 
1. 
Does L = P? 
2. 
Does P = PSPACE? 
What do the hierarchy theorems tell us about 
these questions? 
a) Nothing 
b) At least one of these has answer “NO” 
c) 
At least one of these has answer “YES” 
Check-in 21.3 
","75.53064727783203","5","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_12_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"43","What are the two conditions for a problem to be considered PSPACE-complete?","  
 
    
  
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
!! is PSPACE-complete 
Theorem: !! is PSPACE-complete 
Proof: 1) !! ∈ PSPACE (recursive algorithm, exercise) 
2) #$%& ≤( !! 
Give reduction ) from #$%& to !!. ) * 
= 〈!, .〉 
Construct ! to mimic the formula game on *.
! has Players I and II 
Player I plays role of ∃-Player in *. Ditto for Player II and the ∀-Player. 
⋯ ∧ ⋯ ∧ ⋯ 
) 
* = ∃23 ∀24 ∃25 ⋯ ∃/∀ 28 
assume in cnf 
! = 
4 
","75.46932983398438","6","DPRSearchEngine","fd9c1b8656c7def498dcf662f6750d87_MIT18_404f20_lec19_4_pdf","fd9c1b8656c7def498dcf662f6750d87_MIT18_404f20_lec19","18.404J","19"
"43","What are the two conditions for a problem to be considered PSPACE-complete?"," 
  
 
 
 
 
 
  
  
  
 
 
 
 
  
 
 
  
  
 
 
 
   
 
 
 
 
  
 
 
  
 
 
   
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
  
 
 
! 
""
' 
Quick Review 
Defn: ! is polynomial time reducible to "" (! ≤$ "") if ! ≤% "" 
by a reduction function that is computable in polynomial time. 
Theorem:  If ! ≤$ "" and "" ∈ P then ! ∈ P. 
' is computable in polynomial time 
NP = All languages where can verify membership quickly 
P = All languages where can test membership quickly 
?
P versus NP question: Does P = NP? 
P 
NP 
P = NP 
(!) = 
+ + is a satisfiable Boolean formula} 
Cook-Levin Theorem: (!) ∈ P → P = NP 
Proof plan: Show that every ! ∈ NP is polynomial time reducible to (!). 
2 
","74.46504974365234","7","DPRSearchEngine","c1aca7046a69c913721e5eb910a5fb21_MIT18_404f20_lec15_2_pdf","c1aca7046a69c913721e5eb910a5fb21_MIT18_404f20_lec15","18.404J","15"
"43","What are the two conditions for a problem to be considered PSPACE-complete?"," 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
  
  
 
 
 
 
 
  
  
 
 
  
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
A “Natural” Intractable Problem 
Defn: !""REX = '(, '* '( and '* are equivalent regular expressions} 
Theorem:  !""REX ∈ PSPACE 
Proof: Later (if time) or exercise (uses Savitch’s theorem). 
-
Notation: If ' is a regular expression write '- to mean '' ⋯' (exponent is written in binary). 
Defn: !""/01↑ = '(, '* '( and '* are equivalent regular expressions with exponentiation} 
Theorem:  !""/01↑ is EXPSPACE-complete 
Proof: 1) !""/01↑ ∈ EXPSPACE 
2)  If 3 ∈ EXPSPACE then 3 ≤5 !""/01↑ 
1) Given regular expressions with exponentiation '( and '*, 
expand the exponentiation by using repeated concatenation and then use !""REX ∈ PSPACE. 
The expansion is exponentially larger, so gives an EXPSPACE algorithm for !""/01↑. 
2)  Let 3 ∈ EXPSPACE be decided by TM 6 in space 2 89 . 
Give a polynomial-time reduction : mapping 3 to !""/01↑. 
4 
","73.38329315185547","8","DPRSearchEngine","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_4_pdf","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22","18.404J","22"
"43","What are the two conditions for a problem to be considered PSPACE-complete?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
Use our knowledge that !TM is undecidable to show other 
problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
10 
","73.35474395751953","9","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_10_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"43","What are the two conditions for a problem to be considered PSPACE-complete?","  
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
Review: SPACE Complexity 
Defn: Let !: ℕ→ℕ where ! % ≥%. Say TM ' runs in space !(%) if ' 
always halts and uses at most !(%) tape cells on all inputs of length %. 
An NTM ' runs in space !(%) if all branches halt and each branch uses at 
most !(%) tape cells on all inputs of length %. 
SPACE ! % 
= {,| some 1-tape TM decides , in space . ! % } 
NSPACE ! % 
= {,| some 1-tape NTM decides , in space . ! % } 
PSPACE = ⋃1 SPACE(%1) “polynomial space” 
NPSPACE = ⋃1 NSPACE(%1) 
“nondeterministic polynomial space” 
Today: PSPACE = NPSPACE 
Or possibly: 
P = NP = coNP = PSPACE 
2 
PSPACE 
= NPSPACE 
coNP 
NP 
P 
","73.30863189697266","10","DPRSearchEngine","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18_2_pdf","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18","18.404J","18"
"45","How is a configuration of a Turing machine represented as a string for proof purposes?","Turing machines, as we set them up, they have-- on any input w, they have three possible outcomes. The Turing machine can halt and accept w, can halt and reject w, or it can go forever on w, which is rejecting by looping in our language. A Turing machine can recognize a language, the collection of old strings that it accepts. And if the Turing machine always halts, we say it decides the language, and it's a decider, and so therefore, that language is a decided language, a Turing decider. Often we just say decidable, because we don't really have a notion of deciding in other models, so we often talk about Turing-recognizable or just decidable. Or we'll sometimes just say recognizable, when we understand that we're talking about Turing machines. We briefly talked about encodings. When you write it inside brackets, some objects-- whatever they are-- could be strings, could be machines, could be graphs, could be polynomials-- we're representing them as strings, and maybe a collection of objects together represented as a string in order so that we can present that information as an input to a machine. And we talk about-- our languages our collections of strings. And a notation for writing a Turing machine is going to be simply that English description put inside quotation marks to represent our informal way of talking about the formal object that we could produce, if we wanted to. But we're never going to ask you to do that. OK, so now let me see. Let's just take a quick break, as I promised. If there's any quick questions here, you can ask. Let's see-- got a lot of questions here. All right, why don't we move on? And some of these things are good questions.","77.40597534179688","1","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_2_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"45","How is a configuration of a Turing machine represented as a string for proof purposes?","Notation for encodings and TMs
Notation for encoding objects into strings
- If ! is some object (e.g., polynomial, automaton, graph, etc.), 
we write 〈!〉to be an encoding of that object into a string.  
- If !$, !&, … , !( is a list of objects then we write 〈!$, !&, … , !(〉
to be an encoding of them together into a single string. 
Notation for writing Turing machines
We will use high-level English descriptions of algorithms when we describe TMs, 
knowing that we could (in principle) convert those descriptions into states, 
transition function, etc.  Our notation for writing a TM ) is
) = “On input +
[English description of the algorithm]”
Check-in 6.3
If , and - are strings, would ,- be a good choice 
for their encoding 〈,, -〉into a single string?
a)
Yes.
b)
No. 
Check-in 6.3
8
","77.34803771972656","2","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_8_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"45","How is a configuration of a Turing machine represented as a string for proof purposes?","What are oracles? Oracles are a simple thing. But they are a useful concept for a number of reasons. Especially because they're going to tell us something interesting about methods, which may or may not be useful for proving the P versus NP question, when someday somebody hopefully does that. What is an oracle? An oracle is free information you're going to give to a Turing machine, which might affect the difficulty of solving problems. And the way we're going to represent that free information is, we're going to allow the Turing machine to test membership in some specified language, without charging for the work involved. I'm going to allow you have any language at all, some language A. And say a Turing machine with an oracle for A is written this way, M with a superscript A. It's a machine that has a black box that can answer questions. Is some string, which the machine can choose, in A or not? And it gets that answer in one step, effectively for free. So you can imagine, depending upon the language that you're providing to the machine, that may or may not be useful. For example, suppose I give you an oracle for the SAT language. That can be very useful. It could be very useful for deciding SAT, for example. Because now you don't have to go through a brute force search to solve SAT. You just ask the oracle. And the oracle is going to say, yes it's satisfiable, or no it's not satisfiable. But you can use that to solve other languages too, quickly. Because anything that you can do in NP, you can reduce to SAT. So you can convert it to a SAT question, which you can then ship up to the oracle, and the oracle is going to tell you the answer. The word ""oracle"" already sort of conveys something magical. We're not really going to be concerned with the operation of the oracle, so don't ask me how does the oracle work, or what does it correspond to in reality. It doesn't. It's just a mathematical device which provides this free information to the Turing machine, which enables it to compute certain things. It turns out to be a useful concept. It's used in cryptography, where you might imagine the oracle could provide the factors to some number, or the password to some system or something. Free information. And then what can you do with that? So this is a notion that comes up in other places. If we have an oracle, we can think of all of the things that you can compute in polynomial time relative to that oracle. So that's what we-- the terminology that people usually use is sometimes called relativism, or computation relative to having this extra information. So P with an A oracle is all of the language that you can decide in polynomial time if you have an oracle for A. Let's see. Yeah. Somebody's asking me, is it really free or does it cost one unit? Even just setting up the oracle and writing down the question to the oracle is going to take you some number of steps. So you're not going to be able do an infinite number of oracle calls in zero time. So charging one step or zero steps, not going to make a difference. Because you still have to formulate the question. As I pointed out, P with a SAT oracle-- so all the things you do in polynomial time with a SAT oracle includes NP. Does it perhaps include other stuff? Or does it equal NP? Would have been a good check-in question, but I'm not going to ask that. In fact, it seems like it contains other things too. Because co-NP is also contained within P, given a SAT oracle. Because the SAT oracle answer is both yes or no, depending upon the answer. So if the formula is unsatisfiable, the oracle is going to say no, it's not in the language. And now you can do the complement of the SAT problem as well. The unsatisfiability problem. So you can do all of co-NP in the same way. You can also define NP relative to some oracle. So all the things you can do with a non-deterministic Turing machine, where all of the branches have separately access. And they can ask multiple questions, by the way, of the oracle. Independently. Let's do another, a little bit of a more challenging example. The MIN-FORMULA language, which I hope you remember from your homework. So those are all of the formulas that do not have a shorter equivalent formula. They are minimal. You cannot make a smaller formula that's equivalent that gives you the same Boolean function. So you showed, for example, that that language is in P space, as I recall. And there was some other-- you had another two problems about that language. The complement of the MIN-FORMULA problem is in NP with a SAT oracle. So mull that over for a second and then we'll see why. Here's an algorithm, in NP with a SAT oracle algorithm. So in other words, now I want to kind of implement that strategy, which I argued in the homework problem was not legal. But now that I have the SAT oracle, it's going to make it possible where before it was not possible. So let's just understand what I mean by that. If I'm trying to do the non minimal formulas, namely the formulas that do have a shorter equivalent formula. I'm going to guess that shorter formula, called psi. The challenge before was testing whether that shorter formula was actually equivalent to phi. Because that's not obviously doable in polynomial time. But the equivalence problem for formulas is a co-NP problem. Or if you like to think about it the other way, any formula in equivalence is an NP problem, because you just have to-- the witness is the assignment on which they disagree. So two formulas are equivalent if they never disagree. And so that's a co-NP problem. A SAT oracle can solve a co-NP problem. Namely, the equivalence of the two formulas, the input formula and the one that you now deterministically guessed. And if it turns out that they are equivalent, a smaller formula is equivalent to the input formula, you know the input formula is not minimal. And so you can accept. And if it gets the wrong formula, it turns out not to be equivalent, then you reject on that branch of the non-determinism, just like we did before. And if the formula really was minimal, none of the branches is going to find a shorter equivalent formula. So that's why this problem here is in NP with a SAT oracle. So now we're going to try to investigate this on my-- we're getting near the end of the lecture. We're going to look at problems like, well, suppose I compare P with a SAT oracle and NP with a SAT oracle. Could those be the same? Well, there's reasons to believe those are not the same. But could there be any A where P with A oracle is the same as NP with an A oracle? It seems like no, but actually that's wrong. There is a language, there are languages for which NP with that oracle and P with that oracle are exactly the same. And that actually is an interest-- it's not just a curiosity, it actually has relevance to strategies for solving P versus NP. Hopefully I'll be able to have time to get to. Can we think of an oracle like a hash table? I think hashing is somehow different in spirit. I understand there's some similarity there, but I don't see the-- hashing is a way of finding sort of a short name for objects, which has a variety of different purposes why you might want to do that. So I don't really think it's the same. Let's see, an oracle question, OK, let's see. How do we use SAT oracle to solve whether two formulas are equivalent? OK, this is getting back to this point. How can we use a SAT oracle to solve whether two formulas are equivalent? Well, we can use a SAT oracle to solve any NP problem, because it's reducible to SAT. In other words-- P with a SAT oracle contains all of NP, so you have to make sure you understand that part. If you have the clique problem, you can reduce. If I give you a clique problem, which is an NP problem, and I want to use the oracle to test if the formula-- if the graph has a clique, I reduce that problem to a SAT problem using the Cook-Levin theorem. And knowing that a clique of a certain size is going to correspond to having a formula which is satisfiable, now I can ask the oracle. And if I can do NP problems, I can do co-NP problems, because P is a deterministic class. Even though it has an oracle, it's still deterministic. It can invert the answer. Something that non-deterministic machines cannot necessarily do. So I don't know, maybe that's-- let's move on. So there's an oracle where P to the A equals NP to the A, which kind of seems kind of amazing at some level. Because here's an oracle where the non-determinism-- if I give you that oracle, non-determinism doesn't help. And it's actually a language we've seen. It's TQBF. Why is that? Well, here's the whole proof. If I have NP with a TQBF oracle. Let's just check each of these steps. I claim I can do that with a non-deterministic polynomial space machine, which no longer has an oracle. The reason is that, if I have polynomial space, I can answer questions about TQBF without needing an oracle. I have enough space just to answer the question directly myself. And I use my non-determinism here to simulate the non-determinism of the NP machine. So every time the NP machine branches non-deterministically, so do I. Every time one of those branches asks the oracle a TQBF question, I just do my polynomial space algorithm to solve that question myself. But now NPSPACE equals PSPACE by Savitch's theorem. And because TQBF is PSPACE complete, for the very same reason that a SAT oracle allows me to do every NP problem, a TQBF problem allows me to do every PSPACE problem. And so I get NP contained within P for a TQBF oracle. And of course, you get the containment the other way immediately. So they're equal. What does that have to do with-- somebody said-- well, I'll just-- I don't want to run out of time. So I'll take any questions at the end. What does this got to do with the P versus NP problem? OK, so this is a very interesting connection. Remember, we just showed through a combination of today's lecture and yesterday's lecture, and I guess Thursday's lecture, that this problem, this equivalence problem, is not in PSPACE, and therefore it's not in P, and therefore it's intractable. That's what we just did. We showed it's complete for a class, which is provably outside of P, provably bigger than P. That's the kind of thing we would like to be able to do to separate P and NP. We would like to show that some other problem is not in P. Some other problem is intractable. Namely, SAT. If we could do SAT, then we're good. We've solved P and NP. So we already have an example of being able to do that. Could we use the same method? Which is something people did try to do many years ago, to show that SAT is not in P. So what is that method really? The guts of that method really comes from the hierarchy there. That's where you were actually proving problems that are hard. You're getting this problem with through the hierarchy construction that's provably outside of PSPACE. And outside of P. That's a diagonalization. And if you look carefully at what's going on there-- so we're going to say, no, we're not going to be able to solve SAT, show SAT's outside of P in the same way. And the reason is, suppose we could. Well the hierarchy theorems are proved by diagonalization. What I mean by that is that in the hierarchy theorem, there's a machine D, which is simulating some other machine, M. To remember what's going on there, remember that we made a machine which is going to make its language different from the language of every machine that's running with less space or with less time. That's how D was defined. It wants to make sure its language cannot be done in less space. So it makes sure that its language is different. It simulates the machines that use less space, and does something different from what they do. Well, that simulation-- if we had an oracle, if we're trying to show that if we provide both a simulator and the machine being simulated with the same oracle, the simulation still works. Every time the machine you're simulating asks a question, the simulator has the same oracle so it can also ask the same question, and can still do the simulation. So in other words, if you could prove P different from NP using basically a simulation, which is what a diagonalization is, then you would be able to prove that P is different from NP for every oracle. So if you can prove P different from NP by a diagonalization, that would also immediately prove that P is different from NP for every oracle. Because the argument is transparent to the oracle. If you just put the oracle down, everything still works. But-- here is the big but, it can't be that-- we know that P A is-- we know this is false. We just exhibit an oracle for which they're equal. It's not the case that P is different from NP for every oracle. Sometimes they're equal, for some oracles. So something that's just basically a very straightforward diagonalization, something that's at its core is a diagonalization, is not going to be enough to solve P and NP. Because otherwise it would prove that they're different for every oracle. And sometimes they're not different, for some oracles. That's an important insight for what kind of a method will not be adequate to prove P different from NP. And this comes up all the time. People who propose hypothetical solutions that they're trying to show P different from NP. One of the very first things people ask is, well, would that argument still work if you put an oracle there. Often it does, which points out there was a flaw. Anyway, last check in. So this is just a little test of your knowledge about oracles. Why don't we-- in our remaining minute here. Let's say 30 seconds. And then we'll do a wrap on this, and I'll point out which ones are right. Oh boy, we're all over the place on this one. You're liking them all. Well, I guess the ones that are false are lagging slightly. OK, let's conclude. Did I give you enough time there? Share results. So, in fact-- Yeah, so having an oracle for the complement is the same as having an oracle. So this is certainly true. NP SAT equal coNP SAT, we have no reason to believe that would be true, and we don't know it to be true. So B is not a good choice and that's the laggard here. MIN-FORMULA, well, is in PSPACE, and anything in PSPACE is reducible to TQBF, so this is certainly true. And same thing for NP with TQBF and coNP with TQBF. Once you have TQBF, you're going to get all of PSPACE. And as we pointed out, this is going to be equal as well. So why don't we end here. And I think that's my last slide. Oh no, there's my summary here. This is what we've done. And I will send you all off on your way. How does the interaction between the Turing machine and the oracle look? Yeah, I didn't define exactly how the machine interacts with an oracle. You can imagine having a separate tape where it writes the oracle question and then goes into a special query state. You can formalize it however you like. They're all going to be-- any reasonable way of formalizing it is going to come up with the same notion in the end. It does show that P with a TQBF oracle equals PSPACE. Yes, that is correct. Good point. Why do we need the oracle to be TQBF? Wouldn't SAT also work because it could solve any NP problem? So you're asking, does P with a SAT oracle equal NP with a SAT oracle? Not known. And believed not to be true, but we don't have a compelling reason for that. No one has any idea how to do that. Because, for example, we showed the complement of MIN-FORMULA is in NP with a SAT oracle. But no one knows how to do-- because there's sort of two levels of non-determinism there. There's guessing the smaller formula, and then guessing again to check the equivalence. And they really can't be combined, because one of them is sort of an exist type guessing, the other one is kind of a for all type guessing. No one knows how to do that in polynomial time with a SAT oracle. Generally believed that they're not the same. In the check-in, why was B false? B is the same question. Does NP with a SAT oracle equal coNP with a SAT oracle? I'm not saying it's false, it's just not known to be true. It doesn't follow from anything that we've shown so far. And I think that would be something that-- well, I guess it doesn't immediately imply any famous open problem. I wouldn't necessarily expect you to know that it's an unsolved problem, but it is. Could we have oracles for undecidable language? Absolutely. Would it be helpful? Well, if you're trying to solve an undecidable problem, it would be helpful. But people do study that. In fact, the original concept of oracles was presented, was derived in the computability theory. And a side note, you can talk about reducibility. No, I don't want to even go there. Too complicated. What is not known to be true? What is not known to be true is that NP with a SAT oracle equals coNP with a SAT oracle, or equals P with a SAT oracle. Nothing is known except the obvious relations among those. Those are all unknown, and just not known to be true or false. Is NP with a SAT oracle equal to NP? Probably not. NP with a SAT oracle, for one thing, contains coNP. Because it's even more powerful. We pointed out that P with a SAT oracle contains coNP. And so NP with a SAT oracle is going to be at least as good. And so it's going to contain coNP. And so, probably not going to be equal to NP unless shockingly unexpected things happen in our complexity world.","76.51162719726562","3","DPRSearchEngine","N32bnUliSzo.en-j3PyPqV-e1s_9_mp4","N32bnUliSzo.en-j3PyPqV-e1s","18.404J","22"
"45","How is a configuration of a Turing machine represented as a string for proof purposes?","So let me give you an example of how you would make a self-reproducing Turing machine. What do we mean by that? I mean a machine-- I'm going to call it SELF-- which ignores its input. So on any input, you turn it on, the machine grinds around for a while, and halts with a description of itself on the tape-- with the description of SELF, its own code, sitting on the tape. So very much like producing a program which would print out its own code, that's really what we're doing. So for that, we're going to first need a little lemma, which is a very simple lemma, but it looks worse than it is. So let me just read it out to you, and then I'll explain what its saying. Because what it's saying is extremely simple. So there's a computable function, I'm going to call it q, that maps strings to strings, which will take any string, w, and produce from w a Turing machine which will print w. OK? That's all it does. So as you know, if I give you a string, w, you could produce a Turing machine which would have w represented in the states and transitions of the machine. So that if you turn the machine on, the machine will output w. If I want you to give me a Turing machine that prints the string 1, 1, 0, 1 on the tape, you could do that-- I hope. And no matter what that string was, instead of 1, 1, 0, 0, or whatever, it's 20 0's and then five 1's, you could do that too. And in fact, there's a simple procedure that takes a string and maps that onto a Turing machine which prints out that string. So that's a computable function, which basically takes a string and converts it to something that evaluates to that string. And I'm calling it q. I don't know if this is helpful to you or not. It's kind of like it converts the string w to w in quotes. So q stands for quotes, in a way. So if that's helpful, then good. But anyway, Pw is a Turing machine. When you turn it on, it just prints out w and halts. And I can find Pw from w-- straightforward proof. So now, I'm going to tell you, assuming that we have that computable function, q, I'm going to tell you how to make this machine SELF. And it's not complicated. The Turing machine SELF is going to have","76.26585388183594","4","DPRSearchEngine","N-_XmLanPYg.en-j3PyPqV-e1s_3_mp4","N-_XmLanPYg.en-j3PyPqV-e1s","18.404J","11"
"45","How is a configuration of a Turing machine represented as a string for proof purposes?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
If we know that some problem (say !TM) is undecidable, 
we can use that to show other problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Recall Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
2 
","75.75920104980469","5","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_2_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"45","How is a configuration of a Turing machine represented as a string for proof purposes?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
Use our knowledge that !TM is undecidable to show other 
problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
10 
","75.51457214355469","6","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_10_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"45","How is a configuration of a Turing machine represented as a string for proof purposes?","So E TM is the emptiness problem for Turing machines. Is this language empty? I'm just going to give you a machine. I want to know, is this language empty or not? Does it accept something or is this language empty? That's going to be undecidable, no surprise, proof by contradiction. And we're going to show that A TM is reducible to E TM. So these things often take a very similar form. And I'm going to try to use the same form. So if you're feeling shaky on it, at least you'll get the form of the way the solution goes and that will help you maybe plug-in to solve problems, OK.","75.49718475341797","7","DPRSearchEngine","N28g_YBXY8Y.en-j3PyPqV-e1s_7_mp4","N28g_YBXY8Y.en-j3PyPqV-e1s","18.404J","9"
"45","How is a configuration of a Turing machine represented as a string for proof purposes?","← 
/ 
 
 
 
  
  
 
 
  
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
  
      
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Proof:  (
) Convert
to equivalent TM
.
/ = for input !:
Simulate ' (on blank input).
Whenever ' prints 0, test 0 = !. 
Accept if = and continue otherwise.
Turing Enumerators 
˽ ˽ 
˽ ˽ 
˽ ˽ ˽ . . . 
Finite 
control 
read/write tape – initially blank 
printer 
Defn: A Turing Enumerator is a deterministic TM with a printer. 
It starts on a blank tape and it can print strings !"" , !$ , !% , … possibly going forever. 
Its language is the set of all strings it prints. It is a generator, not a recognizer. 
For enumerator ' we say ( ' = ! ' prints !}. 
Theorem:  A is T-recognizable iff + = ((') for some T-enumerator '. 
' 
Proof: (→) Convert TM / to equivalent enumerator '.
Check-in 6.1 
' = Simulate / on each !2 in Σ∗ = {6, 0,1,00,01,10, … } 
When converting TM / to enumerator ', 
If / accepts !2 then print !2 .
does ' always print the strings in string order? 
Continue with next !2 .
a) Yes. 
Problem: What if / on !2 loops? 
b) No. 
Fix: Simulate / on !"" , !$ , … , !2 for 9 steps, for 9 = 1,2, … 
Print those !2 which are accepted. 
Image of the printer © Source unknown. All rights reserved. This content is excluded from 
our Creative Commons license. For more information, see https://ocw.mit.edu/fairuse. 
Check-in 6.1 
5 
","75.35359954833984","8","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_5_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"45","How is a configuration of a Turing machine represented as a string for proof purposes?"," 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Turing Machines (TMs) 
head 
˽ ˽
a
b
a 
. . .
b b
Finite 
read/write input tape 
control 
1) Head can read and write 
2) Head is two way (can move left or right) 
3) Tape is infinite (to the right) 
4) Infinitely many blanks “˽“ follow input 
5) Can accept or reject any time (not only at end of input) 
8 
","75.20586395263672","9","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_8_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"45","How is a configuration of a Turing machine represented as a string for proof purposes?","OK, so now let's talk about some more the computation, so strings and languages. A string is just a finite sequence of symbols from the alphabet. This class is not going to talk about infinite strings. All of our strings are going to be finite. There's other mathematical theories of automata and so on that talk about infinite inputs and infinite strings. We're not going to talk about that. Maybe rarely, we'll make it very clear, we'll talk about an infinite string, but that's going to be an exception. And a language is a set of strings. That's the traditional way that people in this subject refer to a set of strings. They call it a language-- really because the subject had its roots in linguistics, actually. And they were talking about-- they're trying to understand languages, human languages. So this is just a historical fact, and that's the terminology that's stuck. OK, so two special string-- a special string and a special language. The empty string is the string of length 0. This is a totally legitimate string that you are going to run into now and then. And there's the empty language, which is the set with no strings. These are not the same. They're not even of the same type of object. So don't confuse them with one another. I mean, you can have a set, a language, which has just one element, which is the empty string. That is not the empty set. That is a set-- that is not the empty language. That is a language that has one element in it, namely, the empty string. So those are separate things. OK, so here's a little bit of a mouthful here on the slide, defining what it means for an automaton to accept its input-- accepts its input string w. And we can define that formally. And it's a little technical looking, it's really not that bad. So if you have your input string w, which you can write as a sequence of symbols in the alphabet-- w1, w2, dot dot dot, wn, so like 01001. I'm just writing it out symbol by symbol here. So what does it mean for the machine to accept that input? So that means that there's a sequence of states in the machine, sequence of states of members of Q. So a sequence from Q, these are the states of the machine that satisfy these three properties down here. First of all-- and I'm thinking about the sequence that the machine goes through as it's processing the input w. So when does it accept w? If that sequence has the feature that it starts at the start state, each state legally follows the previous state according to the transition function. So that says the i-th member of the sequence is obtained by looking at the previous one-- the i minus first member of that sequence, the i minus first state in that sequence-- and then looking at what happens when you take the i-th input symbol. So as you look at the previous state and the next input symbol, you should get the next state. That's all that this is saying. And this should happen for each one of these guys. And lastly, for this to be accepted, the very last member here, where we ended up at the end of the input-- so you only care about this at the end of the input-- you have to be in an accepting state. So you can mathematically capture this notion of going along this path. And that's what-- I'm just trying to illustrate that we could describe all this very formally-- I'm not saying that's the best way to think about it all the time-- but that it can be done. And I think that's something worth appreciating. OK. So now in terms of, again, getting back-- we've said this once already, but in terms of the languages that the machine recognizes, it's the collection of strings that the machine accepts. Every machine accepts-- it might accept many strings, but it always recognizes one particular language, even if the machine accepts no strings-- then it recognizes the empty language. So a machine always recognizes one language, but it may have many, many strings that it's accepting. And we call that language the language of the machine. And we say that M recognizes that language. These three things mean the same thing. OK? And now important definition-- I try to reserve the most important things or the highlighted things to be in this light blue color, if you can see that. We say a language is a regular language if there's some finite automaton that recognizes it. OK? So there are going to be some languages that have associated to them finite automata that actually solve those languages, that recognize those languages. But there might be other languages-- and we'll see examples-- where you just can't solve them. You can't recognize them with a finite automaton. Those languages will not be regular languages. The regular ones are the ones that you can do with a finite automaton. That's the traditional terminology.","75.04460144042969","10","DPRSearchEngine","9syvZr-9xwk.en-j3PyPqV-e1s_7_mp4","9syvZr-9xwk.en-j3PyPqV-e1s","18.404J","1"
"46","What is the idea behind constructing a DFA from an NFA?","the acceptance problems for NFAs looked very similar, except B is going to be an NFA. That's going to be a decidable language too. And now we have Turing machine A-- DANFA, the decider for ANFA that decides ANFA. OK? So now, as promised, here's our new form for writing our Turing machine. On input B, w, we're assuming that B-- based on the context, sometimes you may want to say at this point, what B and w are. But from the context, we know what they are. They're going to be an NFA and an input w for that NFA. I do want to jump into the solution. First, before we actually look at the solution of this, we-- the Turing machine could simulate the NFA on input w. And you have to be careful on that simulation that you don't end up looping, because don't forget, an NFA could have epsilon moves, and could be looping on those epsilon moves. And so that would be a problem, if you're not careful about how you do that simulation. Now, I think, if you were going to simulate an NFA, you would be-- wouldn't follow loop around loops forever. And I think you can-- without getting-- because this is not the way I'm going to solve the problem-- you could find a way to avoid getting caught and getting stuck in loops for an NFA. So even though that looks like it could be a problem, in terms of looping forever, it turns out that it won't be a problem-- it wouldn't be a problem if you're careful. But I'm not going to solve it that way anyway, because I'm going to illustrate a different method for solving this problem. And that is we have exhibited before a way of converting NFAs to DFAs. So my Turing machine is going to solve the ANFA problem by converting its input, which is an NFA, to an equivalent DFA. I'm calling the NFA B and the DFA that I got-- converting it into B prime. And what's nice about that is that, first of all, we already know how to do that conversion, because we essentially went over that in lecture a few lectures back, and it's spelled out in full detail in the textbook. So that is a conversion we know how to do-- we'll assume we know how to do. And we can implement that Turing-- that conversion on a Turing machine. Then, once we have the equivalent DFA, what do we do with that? In the previous slide, we showed how to solve the problem for DFAs. So if we can convert the NFA to a DFA, and then we already know how to solve the problem for DFAs, then we're done. So that's how I'm going to say. We're going to convert the NFA to a DFA, and then I'm going to run that DADFA problem on the new machine that I produced. So remember that the-- this machine here decides the ADFA problem. And now I'm going to accept, if that new machine-- if that previous Turing machine accepts the DADFA problem the machine accepts, and I'm going to basically do whatever it does. If it accepts, I'll accept. If it rejects, then I'll reject. So I guess the thing that this illustrates is this idea of using a conversion construction inside a Turing machine, and then a previously constructed Turing machine basically as a subroutine. All this is perfectly legal, and it's the kind of thing we're going to be doing a lot of, and that you should be used to doing that-- get ready to be doing that on your homework too. And in fact, I'll give you another a little extra hint that problem 6 can be solved in this way. OK. All right, so here, let's pause briefly. OK, got some interesting questions here coming up-- somebody asked me, do we need to be explicit about how we're going to simulate that NFA or the DFA? Because we don't know how many states it has. You do know how many states it has. Once it's presented to you on the input, you can see, oh, this is a machine that has 12 states-- because you're given the machine, and then you can do the simulation. Let's see.","68.18045806884766","1","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_6_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"46","What is the idea behind constructing a DFA from an NFA?","which stands for the acceptance problem for DFAs-- is the collection of pairs. B and w-- B is a DFA. w is considered to be some other string, which will be an input to B. We're going to be thinking of it as an input to B. I put the two of them in brackets to represent the pair of them as a single string. We're not going to make explicit what the form of the encoding is. The only important thing is that the encoding should be something simple, but that the Turing machine can decode back into the DFA and this input string to that DFA. So anything reasonable is going to be a satisfactory encoding from us-- for us. So this is an encoding of the two of them into a string, and where B is a DFA, and B accepts w. So now, if you want to test if something's a member of ADFA, then, first of all, you want to make sure that the string itself that you're getting really encodes a DFA and a string. So it has to be the right form. And once you know that, then you have the DFA, you have the string w, and you're then going to do the obvious thing, which would be to simulate B on w and see if it's actually accepting w. So that's what the content of this slide is. I'm just going to write it down for you. So I'm going to give a Turing machine, which I'm going to call-- the name of that Turing machine is going to be D A DFA. To help you remember the function of this machine. This is a decider for the language below, the ADFA language. This is just a name, but-- so nothing fancy going on here, but just to help us remember, because I'm going to refer to some of these Turing machines later on. So this is the decider for ADFA. And I'm going to describe that machine for you, and that machine decides the ADFA language. So what does that mean? So that machine-- I'm describing it now in English, as I promised. We're going to take an input string s, and first, it's going to check that s has the right form, as I mentioned-- has the form which is the encoding of a DFA and a w. If it's not of that form, the Turing machine should reject that input right away. Now, I'm not going to go through the details of how that Turing machine is going to work, though I'll say a little bit more this time only just to give you a sense of how it actually might carry that out. If you don't believe that you can do it with a Turing machine, believe you could do it with your favorite programming language. That's good enough, because that's going to be-- that's equivalent to a Turing machine. So first, you check that the input's of the right form. Then you're going to simulate the computation of B on w. And then, if B ends up in an accept state, then we know B is accepting the input, and we should accept, and we do. If B does not end up in an accept state at the end of w, then we should reject, because B is not accepting w. OK? That's my description of this machine. Let's just turn to a little bit of details just to make sure we're comfortable with this. So here is our Turing machine-- D, the decider for ADFA. The input to that Turing machine, as I mentioned, is going to be B and w, provided it's of the right form. So that's what this string S is supposed to be of that form. And what does that mean? It's just an encoding of the machine w and the string-- the machine B and the string w. Let me just write it down. Here is B written down in some just completely explicit way, where you're just listing the states of B, the alphabet of B, the transition function as a table, the start state, and the set of accepting states-- just writing it down explicitly, as you might do it if you would just want to describe that machine in a completely formal way, and then writing down with the string is-- whatever it is. Once DADFA has that as its input, it can then go ahead and do that computation. And just to try to make it a little bit more explicit, I'm going to capture that here by saying, let's give that Turing machine an extra tape, because we already know that the multi-tape model is equivalent to the single tape model-- make our life perhaps a little easier. And in the course of doing that simulation, what do we want to keep track of? Well, what is the current state of B, the DFA, as we're reading the symbols of w? And where in w are we at right now? So I'll call that k, which is the input head location on w. How many symbols of w have we read? OK? And that's all I'm going to say about what this Turing machine D looks like. Oh, there's one more thing I do want to say for the-- that's coming up, because pretty much all of the Turing machines that we're going to talk about today and going forward are going to often want to check that their input is of the correct form. I don't want to repeat this every time, because that's going to be assumed. So my shorthand for that is to say my input is of the form I'm looking for, and that has built into it the check that the string-- the input string is of that form, and we're going to reject if it is not. So all of our Turing machines are going to start out, on input, the string is of a certain form, and then go out and do something with it. OK? OK, so let me try to answer a few of the questions that I've gotten here, because I think this is important as a way of getting us all started. Now, somebody asked me, can we use arguments of this form? Somebody asking, can we use-- can we give our description of a procedure, if I'm understanding this correctly, as using some other programming language? Well, typically, you just want to make sure you're understood. If you want to do that on a homework, I wouldn't advocate writing your algorithm in Java, because it's going to be hard to read. But write it down in some pseudo programming language if you want, just to make sure it's clear that-- what you're doing. Probably English is going to be the easiest for you-- even though this person says-- feels it would be easier to do it in terms of a formal language. Well, whatever's easier-- as long as we can understand it. This is a good question here I got to ask. What if B-- here's our B-- gets into a loop on w? Well, that's not going to happen. B is a DFA. DFAs-- they move from state to state every time they read a symbol of w. When they get to the end of w, it's the end of the story. There's no more computation to be done. So we know in exactly how many steps B is ever going to take on-- it's going to take the same number of steps as the length of the input. That's how many moves it gets to make. B as a DFA never loops. So that would be a problem if it did loop, but it doesn't. That input never does loop. So have we verified that D is a decider? Well, I think I just did. From my standpoint, we've said enough to be sure that D is a decider. There's never any reason for D to be-- for that DADFA Turing machine to be getting into a loop. The input head location is referring to where we are on the string w? Yes. And somebody's asking me, is this the level of detail for the homework? Yes. That's all I want. It's all I'm looking for. OK? Let us move on. I'm going to have to-- otherwise we'll never get anywhere. There are a lot of questions here. They're good questions. So why don't we go on? Some of these may get resolved as we're going to look at additional examples, because that's all of today is pretty much examples. Let's talk about the similar problem, the acceptance problem, but now for NFAs. So now, actually, NFAs can loop, so we have to think about what that possibly could look at.","66.72444915771484","2","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_5_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"46","What is the idea behind constructing a DFA from an NFA?","of this regular expression, and then combine them, using our closure instructions, to be NFAs for larger and larger subexpressions, until I get the NFA that's the equivalent of the entire expression. So let's just see how that goes. So the very most primitive parts, the smallest subexpressions here, are just the expressions for a and for b. So here's the one just for a. So this is the NFA which recognizes the language, which is just the one string a. Here is the NFA whose language is just the one string b. And now I want an NFA which accepts only the string ab. Now, of course, you could just do that by hand yourself. It's simple enough. But what I'm arguing is that we can do this automatically, using the closure construction for concatenation. Because really there's a hidden concatenation symbol. This is a concatenate b. So now for ab, I'm going to take the thing from a and the part from b-- so these two things that I had from before, and use the concatenation construction to combine them. You see that? So now I have automatically an NFA which does the language whose string is just ab, just the ab string. And it's not the simplest NFA. You can make a simpler one, but the virtue of this one is that I got it automatically just by following the closure construction. So now I'm going to do a more complex one, just the inside here, a union ab. So the way I'm going to build that is from the two parts, the a part and the ab part, the a part and the ab part. So here is the a part. Here's the ab part. I've already got those from before. It's really kind of a proof by induction here. But I think it's simple enough, we don't have to use that language. So we have the a part, the ab part. And now we are going to apply the closure under union construction to combine those into one machine. And remember how that worked. We had a new symbol here, which branches under empty string to the previous-- we're adding a new start state, which branches to the original start states under empty transition. And now this is an NFA for this language, a union ab. And lastly, now we're one step away from getting the star of this. And how are we going to do that? We're going to take this thing here and apply the construction for the star closure. And that's going to be an NFA which does a union ab star, which is what we wanted in the first place. So first, we're going to bring that one down. Because we've already built that one. And now remember how we built the closure under star. We made the accepting states return back to the start state, and we added a new start state to make sure we got the empty string in there that transitioned to the original start state under epsilon. OK? So that's all I wanted to say for today's lecture. Let's do a quick review. Very important concept, nondeterminism and nondeterministic finite automata-- we proved they were equivalent in power, showed the class of regular languages closed under concatenation in star. We showed how to do conversion of regular expressions to NFAs. So I think that is it for today's lecture. And thank you, all, for being here. I'll try to answer a few of these. ""Why does concatenation have order?"" Well, because it's an ordered construction. Is there a simple way to prove closure under concatenation without using nondeterminism? No. ""Why are the empty strings at the accept state? Can't they be at any state? Doesn't star make copies of any part of the input?"" No, it's only-- you have to think about what's going on. You have to branch back to the beginning only on an accept. Because that means you found a piece that's in the original language. ""Is there an automaton that can add some or subtract memory automata?"" Well, depends on what you mean by all that. But certainly, there are more powerful machines that we're going to study than finite automata. But yes, there is. And even finite automata can add and subtract, if you present the input in the right way. I would refer you to the first problem on the homework. So I think I'm going to check out then. Take care, everybody. Bye-bye.","66.39514923095703","3","DPRSearchEngine","oNsscmUwjMU.en-j3PyPqV-e1s_9_mp4","oNsscmUwjMU.en-j3PyPqV-e1s","18.404J","2"
"46","What is the idea behind constructing a DFA from an NFA?","So what we're going to do, because we're in place, basically we have to have an array storing our end items. That's sort of the definition of in-place, just using n slots of memory exactly the size of the number of items in our structure. But we're obviously not going to use a regular unsorted array or a regular sorted array. We're going to use array just as sort of the underlying technology for how things are stored. But we'd really like logarithmic performance, which should make you think tree. Only way to get a log is the binary tree, more or less. So somehow, we want to embed a tree into an array. Let me grab an example.","65.34735870361328","4","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_6_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"46","What is the idea behind constructing a DFA from an NFA?","I hope you're all refreshed and ready for the second half. So now that we have nondeterminism, we're going to use that as a tool to prove the closure properties that we were aiming for, starting from last lecture. OK. So remember, let's look at closure under a union. Now, we already did that, but I'm going to do it again, but this time, using nondeterminism. And you'll see how powerful nondeterminism is. Because it's going to allow us to do it almost with no effort. We'll start off the way we did before. I'm going to start off with two DFAs. But actually, these could be NFAs even. But let's say we started with the two DFAs for the two languages A1 and A2. And now we're going to construct an NFA, recognizing the union. And that's good enough, because we already know that we can convert NFAs to DFAs. And therefore, they do regular languages, too. OK. So now here are the two DFAs that do the languages A1 and A2. And what I'm going to do is I'm going to put them together into a bag of states, which is going to be M, the NFA that's going to do the union language. So remember-- what does M supposed to do? M is supposed to accept its input, if either M1 or M2 accept. So how is it going to do that? What it's going to do, we're going to add a new state to M, which is going to branch under epsilon transitions. And now you can start to see how useful these epsilon transitions are going to be for us. Going to branch under epsilon transitions to the two original start states of M1 and M2. And we're done. Why? Well, now, nondeterministically, as we get an input, w coming in to M-- and at the very beginning, even just right after it gets going, the very first thing that happens is it's going to branch to M1 and also branch to M2 nondeterministically as two possibilities. And then inside M1 and M2, it's going to actually start reading the input. And each one is going to be now following along as it would have originally the states corresponding to reading those input symbols. And M, as a combination of M1 and M2, is going to have a possibility for one state in M1 and one state in M2. And so M is going to have those combined into one package. And now at the end of the input, if either of these end up at an accepting state, then M is going to accept as a nondeterministic finite automaton. Because that's how nondeterminism works. You accept if either-- if any one of the branches ended up accepting-- which is just what you need for union. So when we're doing union, you want either one of these to be accepting. And the nondeterminism just is built conveniently to allow us to do the union almost for free. So you can again, thinking about nondeterminism as terms of parallelism, you could think of the nondeterministic machine as running in parallel M1 and M2 on the input. And if either one of them ends up accepting, M will accept. Or you can think about it in terms of that guessing that I referred to before, which means that as M is getting-- when it's just about to read the first symbols of its input, it guesses whether that's going to be an input accepted by M1 or an input accepted by M2. And the magic of nondeterminism is that it always guesses right. So that input happens to be an input that's going to be accepted by M2. M is going to guess that M2 is the right way to follow. And it's going to go in the M2 direction. Because nondeterminism, the magic is you always guess right. I wish that was true in real life. It would make exams a lot easier.","65.09062194824219","5","DPRSearchEngine","oNsscmUwjMU.en-j3PyPqV-e1s_6_mp4","oNsscmUwjMU.en-j3PyPqV-e1s","18.404J","2"
"46","What is the idea behind constructing a DFA from an NFA?","a Generalized Nondeterministic Finite Automaton, or a Generalized NFA, or just simply a GNFA. So this is yet another variant of the finite automaton model. And conceptually, it's very simple. It's similar to the NFAs. I'll give you-- here's a picture of a GNFA named G, G1. Very similar to the NFAs. But if you look at it for a second, you'll see that the transitions have more complicated labels. For the NFAs, we're only allowing just single symbols, or the empty string, to appear on the labels. Now I'm actually allowing you to put full regular expressions on the labels for the automaton. Now, we have to understand how a GNFA processes its input. And the way it works is not complicated to understand. When you're getting an input string feeding-- when a GNFA is processing an input string, it starts at the start state, just like you would imagine. But now, to go along a transition, instead of reading just a single symbol, or the empty string, as in the case for the nondeterministic machine, it actually gets to read a whole string at one step, kind of, at one bite. It can read an entire string and go along that transition arrow, provided that chunk of the input that it read is in the regular expression that that transition has as its label. So for example, this-- you can go from q1 to q2 in one step in this GNFA by reading a, a, b, b off the input. So it reads all of those four symbols all at once. It just swoops them up and then moves from q1 to q2 in one step. And then, when it's in q2 it can read aab and move to q3. And q3 happens, there's nowhere to go. So this is going to be a nondeterministic machine. There might be several different ways of processing the input. And if any one of them gets to an accepting state at the end of the input, we say the GNFA accepts. So it's similar to nondeterministic-- to NFAs in the way the acceptance criterion works. So you could do an example. But hopefully the concept of how this works is reasonably-- you can at least buy it, that it processes the input in chunks at a time. And those chunks have to be described by the regular expressions on the transition arrows, as it moves along those transitions. So what we're going to do now is to convert not DFAs to regular expressions, we're going to convert GNFAs to regular expression. That's even harder, because GNFAs are-- allow you to do all sorts of other things besides just ordinary DFAs. So that's a harder job. Why am I making my life harder? Well, you'll see in a minute that it's going to actually turn out to be helpful to be working with a more powerful model in the way this construction is going to work. Now, before I dive in and do the construction from GNFAs to regular expressions, I'm going to make a simplifying assumption about the GNFAs. I'm going to put them in a special form that's going to make it easier to do the conversion. And that simpler form is, first of all, I'm going to assume the GNFA has just a single accepting state. And that accepting state is not allowed to be the start state. So it has to have just a single accepting state. I've already violated that convenient assumption in this GNFA, because I have here two accepting states. That's not what I want. I want to have just one. Well, the thing is, it's easy to obtain just one, just to modify the machine so that I have just one by adding a new accepting state which is branched to from the former accepting states by empty transitions. So I can always jump from q2 to q4 at any time without even reading any input, just going along this empty transition. And then I declassify the former accepting states as accepting. And now I have here just a single accepting state. And because it's going to be a new state that I added, it won't be the start state. And I have accomplished that one aspect of my assumption about the form of the GNFA. But there's another thing that I want to do, too. I want to assume-- as you will see, which is going to be convenient in my construction-- that we will have transition arrows going from every state to every other state. In fact, I want transition arrows going from every state even back to themselves. I want there to be-- all possible transition arrows should be present, with two exceptions. For the start state, there should be only transition arrows exiting the start state. And for the accepting state-- there's just one now-- there should be only transition arrows coming into the start state. So it's kind of what you would imagine as being reasonable. For the other states, which are not accepting or starting, there should be transition arrows leaving and coming from everywhere else. But for the start states, just leaving. And from the accept state, just coming in. And you could easily modify the machine to achieve that. Let's just see how to do that in one example. So from-- notice that from q3 to q2 there is no transition right now. And that's not good. That's not what I want. I want there to be a transition from q3 to q2. Well, I'll just add that transition in. But I'm going to label it with the empty language regular expression. So that means, yeah, the transition is there, but you never can take it. So it doesn't change the language that the machine is going to be recognizing. But it fulfills my assumption, my convenient assumption, that we have all of these transition arrows being present in the machine. So anyway, I hope you will buy it. It's not going to be-- if you don't quite get this, don't worry. It's not totally critical that you're following all these little adjustments and modifications to the GNFA. But it will be helpful to understand what GNFAs themselves-- how they work. So as I mentioned, we can easily modify","64.54401397705078","6","DPRSearchEngine","KAySmSEGc9U.en-j3PyPqV-e1s_3_mp4","KAySmSEGc9U.en-j3PyPqV-e1s","18.404J","3"
"46","What is the idea behind constructing a DFA from an NFA?","OK, so the concept of reducibility is that we say one problem is reducible to another, say A reducible to B. It means that you can use B to solve A. That's what it means for A to be reducible to B. OK, so I'm going to give a bunch of sort of informal examples of that, or easy examples of that. And then we'll start to use it for real. So example 1, this is sort of really outside material from the course. But I think it's something you can appreciate. You know, everybody knows you can measure the area of a rectangle by measuring the lengths of the two sides, measuring the length and width of the rectangle. So in other words, if you had the problem of determining the area, you could reduce that problem to the problem of measuring the length and width of the rectangle. So here, we're taking one problem and reducing it to another problem. You know, it's conceivable that measuring the length and width is easier than it would be to measure the area directly by somehow covering the space with tiles, is one way of measuring it. But it tells you, you don't have to do that. The problem of measuring the area is easier than covering with tiles. You can just measure the length and width and you're done. So reducibility is a way of making problems easier by translating them into some easier problem. So here's another example that we've already seen. We didn't call it a reducibility. But if you remember back a couple of weeks ago, we were talking about the languages A NFA, and A DFA, the acceptance problems for NFAs and DFAs. And we gave a way of solving the A DFA problem. As you remember, the Turing machine simulated the finite automaton. And we solved the NFA problem not by doing it directly but by converting the NFA to a DFA and then using the solution for A DFA. In effect, what we were doing was we were reducing the A NFA problem to the A DFA problem. So let's do another example. Here's a problem. Here's an example that you again, probably didn't think about it this way.","64.38829803466797","7","DPRSearchEngine","N28g_YBXY8Y.en-j3PyPqV-e1s_3_mp4","N28g_YBXY8Y.en-j3PyPqV-e1s","18.404J","9"
"46","What is the idea behind constructing a DFA from an NFA?"," 
  
   
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
 
 
 
 
  
 
 
 
 
  
 
  
  
 
   
 
 
 
 
  
 
 
 
 
   
 
 
 
 
TM Configurations 
Defn: A configuration of a TM is a triple ("", $, %) where 
"" = the state, 
$ = the head position, 
% = tape contents 
representing a snapshot of the TM at a point in time. 
6 
˽ ˽ … 
""* 
a a a a a a b b b b b  
Configuration: (""*, 6, aaaaaabbbbb) 
%' 
%( 
Encoding as a string: aaaaa""*abbbbb 
Encode configuration ("", $, %) as the string %'""%( where 
% = %'%( and the head position is on the first symbol of %(. 
5 
","64.16905975341797","8","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_5_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"46","What is the idea behind constructing a DFA from an NFA?","for search. I'm not sure I see it. I'm not sure that's going to be a helpful way of thinking about this. So I'm not going to answer that right now. But you can ask that offline later if you want. Why is the recursion depth log t instead of log m? Well, how high is this thing? Initially it's t high. But every time we're doing a level, we're calling the recursion, we're cutting t in half. I'm solving this in general for b, but we starting off with b equal to t. t is the maximum size. So initially this is going to be t, and then it's going to be t over 2, then t over 4. So it's going to be log t levels before we get down to 1. Yeah. So somebody is asking, can we think of this as a memory stack? Yes, this is like-- that's the way your typical implementation of recursion is kind of with a stack, where you push when you make a call and you pop when you return from the call. Is it possible that v can appear during BL procedure on t? Is it possible that v can appear? I'm not sure what that means. It can reappear. So I'm starting with u to v. Is it possible that v might be one of these intermediate strings? Yeah. You're going to try every possible intermediate stream blindly. Including v is one of them. If you can reach v more quickly, well, great. I guess I have not dealt with the issue of what happens if you get to a-- technically it's going to work out because I'm allowing the difference to be in at most one place. So even if you get there early, you're allowed to not change anything, and that still is a legal step in the ladder. Yeah. I don't see how to do this from a bottom up perspective. Somebody's is asking is there a bottom up version of this. I don't think so. No, I don't think so. All right. Why don't we move on? So now we're going to see this proof again. But this time we're going to be proving that you can convert any NFA to a DFA with only a squaring increase. So really, well, let me just put that up there. So this is going to be Savitch's theorem, that among other things proves that PSPACE equals NPSPACE. So it says that you can convert a non-deterministic machine to a deterministic machine only squaring the amount of space. So you're comfortable with this notation here. Anything that you can do in f of n space non-deterministically you can do in f squared of n based deterministically. And we're going to accomplish that by converting an NTM to a deterministic TM but only squaring the space used. So n is going to convert it to an m. And now this proof is going to look very similar to the proof in the previous slide. It's the same proof. And the fact from the previous slide about ladder really is implied by this, because we had an easy algorithm to show that the latter problem is","64.16802215576172","9","DPRSearchEngine","aVv9WXwW95w.en-j3PyPqV-e1s_3_mp4","aVv9WXwW95w.en-j3PyPqV-e1s","18.404J","18"
"46","What is the idea behind constructing a DFA from an NFA?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Quick review of today 
1. We showed the decidability of various problems 
about automata and grammars:
!DFA , !NFA , &DFA , &'DFA , !CFG , &DFA 
2. We showed that !TM is T-recognizable. 
11 
","63.95344543457031","10","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_11_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"47","How does a probabilistic Turing machine decide a language with an error probability ε?"," 
 
 
 
 
 
 
 
 
  
 
  
 
   
 
 
 
 
  
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Model Dependence 
Number of steps to decide ! = a#b# $ ≥0 depends on the model. 
• 1-tape TM: '() log )) 
• Multi-tape TM: '()) 
Computability theory: model independence (Church-Turing Thesis) 
Therefore model choice doesn’t matter. Mathematically nice. 
Complexity Theory: model dependence 
But dependence is low (polynomial) for reasonable deterministic models. 
We will focus on questions that do not depend on the model choice. 
So… we will continue to use the 1-tape TM as the basic model for complexity. 
6 
","76.85923767089844","1","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_6_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"47","How does a probabilistic Turing machine decide a language with an error probability ε?","  
 
  
 
 
  
 
  
 
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
  
 
 
   
-
Review: Probabilistic TMs and BPP 
coin flip step 
each choice has 
Defn: A probabilistic Turing machine (PTM) is a variant of a NTM 
where each computation step has 1 or 2 possible choices. 
deterministic 
step 
50% probability 
Defn: For ! ≥0 say PTM $  decides language % with error probability !  
if for every &, Pr[ $  gives the wrong answer about & ∈% ] ≤! . 
Defn: BPP = % some poly-time PTM decides % with error !  = +⁄,  } Check-in 24.1 
Actually using a probabilistic algorithm 
Amplification lemma: 2−. /01 2 
presupposes a source of randomness. 
Can we use a standard pseudo-random 
number generator (PRG) as the source? 
& ∈% 
& ∉% 
(a) Yes, but the result isn’t guaranteed.
(b) Yes, but it will run in exponential time.
Many 
Few 
Few 
Many 
(c) No, a TM cannot implement a PRG. 
accepting 
rejecting 
accepting 
rejecting 
(d) No, because that would show P = BPP.
2 
Check-in 24.1 
","76.29904174804688","2","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_2_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"47","How does a probabilistic Turing machine decide a language with an error probability ε?"," 
 
 
 
 
 
 
 
 
 
  
 
  
 
  
 
 
 
  
 
 
 
 
18.404/6.840 Lecture 7 
Last time: 
- Equivalence of variants of the Turing machine model 
a. Multi-tape TMs 
b. Nondeterministic TMs 
c. Enumerators 
- Church-Turing Thesis 
- Notation for encodings and TMs 
Today: (Sipser §4.1) 
- Decision procedures for automata and grammars 
1 
","75.87535858154297","3","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_1_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"47","How does a probabilistic Turing machine decide a language with an error probability ε?","Turing machines, as we set them up, they have-- on any input w, they have three possible outcomes. The Turing machine can halt and accept w, can halt and reject w, or it can go forever on w, which is rejecting by looping in our language. A Turing machine can recognize a language, the collection of old strings that it accepts. And if the Turing machine always halts, we say it decides the language, and it's a decider, and so therefore, that language is a decided language, a Turing decider. Often we just say decidable, because we don't really have a notion of deciding in other models, so we often talk about Turing-recognizable or just decidable. Or we'll sometimes just say recognizable, when we understand that we're talking about Turing machines. We briefly talked about encodings. When you write it inside brackets, some objects-- whatever they are-- could be strings, could be machines, could be graphs, could be polynomials-- we're representing them as strings, and maybe a collection of objects together represented as a string in order so that we can present that information as an input to a machine. And we talk about-- our languages our collections of strings. And a notation for writing a Turing machine is going to be simply that English description put inside quotation marks to represent our informal way of talking about the formal object that we could produce, if we wanted to. But we're never going to ask you to do that. OK, so now let me see. Let's just take a quick break, as I promised. If there's any quick questions here, you can ask. Let's see-- got a lot of questions here. All right, why don't we move on? And some of these things are good questions.","75.46256256103516","4","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_2_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"47","How does a probabilistic Turing machine decide a language with an error probability ε?","What are oracles? Oracles are a simple thing. But they are a useful concept for a number of reasons. Especially because they're going to tell us something interesting about methods, which may or may not be useful for proving the P versus NP question, when someday somebody hopefully does that. What is an oracle? An oracle is free information you're going to give to a Turing machine, which might affect the difficulty of solving problems. And the way we're going to represent that free information is, we're going to allow the Turing machine to test membership in some specified language, without charging for the work involved. I'm going to allow you have any language at all, some language A. And say a Turing machine with an oracle for A is written this way, M with a superscript A. It's a machine that has a black box that can answer questions. Is some string, which the machine can choose, in A or not? And it gets that answer in one step, effectively for free. So you can imagine, depending upon the language that you're providing to the machine, that may or may not be useful. For example, suppose I give you an oracle for the SAT language. That can be very useful. It could be very useful for deciding SAT, for example. Because now you don't have to go through a brute force search to solve SAT. You just ask the oracle. And the oracle is going to say, yes it's satisfiable, or no it's not satisfiable. But you can use that to solve other languages too, quickly. Because anything that you can do in NP, you can reduce to SAT. So you can convert it to a SAT question, which you can then ship up to the oracle, and the oracle is going to tell you the answer. The word ""oracle"" already sort of conveys something magical. We're not really going to be concerned with the operation of the oracle, so don't ask me how does the oracle work, or what does it correspond to in reality. It doesn't. It's just a mathematical device which provides this free information to the Turing machine, which enables it to compute certain things. It turns out to be a useful concept. It's used in cryptography, where you might imagine the oracle could provide the factors to some number, or the password to some system or something. Free information. And then what can you do with that? So this is a notion that comes up in other places. If we have an oracle, we can think of all of the things that you can compute in polynomial time relative to that oracle. So that's what we-- the terminology that people usually use is sometimes called relativism, or computation relative to having this extra information. So P with an A oracle is all of the language that you can decide in polynomial time if you have an oracle for A. Let's see. Yeah. Somebody's asking me, is it really free or does it cost one unit? Even just setting up the oracle and writing down the question to the oracle is going to take you some number of steps. So you're not going to be able do an infinite number of oracle calls in zero time. So charging one step or zero steps, not going to make a difference. Because you still have to formulate the question. As I pointed out, P with a SAT oracle-- so all the things you do in polynomial time with a SAT oracle includes NP. Does it perhaps include other stuff? Or does it equal NP? Would have been a good check-in question, but I'm not going to ask that. In fact, it seems like it contains other things too. Because co-NP is also contained within P, given a SAT oracle. Because the SAT oracle answer is both yes or no, depending upon the answer. So if the formula is unsatisfiable, the oracle is going to say no, it's not in the language. And now you can do the complement of the SAT problem as well. The unsatisfiability problem. So you can do all of co-NP in the same way. You can also define NP relative to some oracle. So all the things you can do with a non-deterministic Turing machine, where all of the branches have separately access. And they can ask multiple questions, by the way, of the oracle. Independently. Let's do another, a little bit of a more challenging example. The MIN-FORMULA language, which I hope you remember from your homework. So those are all of the formulas that do not have a shorter equivalent formula. They are minimal. You cannot make a smaller formula that's equivalent that gives you the same Boolean function. So you showed, for example, that that language is in P space, as I recall. And there was some other-- you had another two problems about that language. The complement of the MIN-FORMULA problem is in NP with a SAT oracle. So mull that over for a second and then we'll see why. Here's an algorithm, in NP with a SAT oracle algorithm. So in other words, now I want to kind of implement that strategy, which I argued in the homework problem was not legal. But now that I have the SAT oracle, it's going to make it possible where before it was not possible. So let's just understand what I mean by that. If I'm trying to do the non minimal formulas, namely the formulas that do have a shorter equivalent formula. I'm going to guess that shorter formula, called psi. The challenge before was testing whether that shorter formula was actually equivalent to phi. Because that's not obviously doable in polynomial time. But the equivalence problem for formulas is a co-NP problem. Or if you like to think about it the other way, any formula in equivalence is an NP problem, because you just have to-- the witness is the assignment on which they disagree. So two formulas are equivalent if they never disagree. And so that's a co-NP problem. A SAT oracle can solve a co-NP problem. Namely, the equivalence of the two formulas, the input formula and the one that you now deterministically guessed. And if it turns out that they are equivalent, a smaller formula is equivalent to the input formula, you know the input formula is not minimal. And so you can accept. And if it gets the wrong formula, it turns out not to be equivalent, then you reject on that branch of the non-determinism, just like we did before. And if the formula really was minimal, none of the branches is going to find a shorter equivalent formula. So that's why this problem here is in NP with a SAT oracle. So now we're going to try to investigate this on my-- we're getting near the end of the lecture. We're going to look at problems like, well, suppose I compare P with a SAT oracle and NP with a SAT oracle. Could those be the same? Well, there's reasons to believe those are not the same. But could there be any A where P with A oracle is the same as NP with an A oracle? It seems like no, but actually that's wrong. There is a language, there are languages for which NP with that oracle and P with that oracle are exactly the same. And that actually is an interest-- it's not just a curiosity, it actually has relevance to strategies for solving P versus NP. Hopefully I'll be able to have time to get to. Can we think of an oracle like a hash table? I think hashing is somehow different in spirit. I understand there's some similarity there, but I don't see the-- hashing is a way of finding sort of a short name for objects, which has a variety of different purposes why you might want to do that. So I don't really think it's the same. Let's see, an oracle question, OK, let's see. How do we use SAT oracle to solve whether two formulas are equivalent? OK, this is getting back to this point. How can we use a SAT oracle to solve whether two formulas are equivalent? Well, we can use a SAT oracle to solve any NP problem, because it's reducible to SAT. In other words-- P with a SAT oracle contains all of NP, so you have to make sure you understand that part. If you have the clique problem, you can reduce. If I give you a clique problem, which is an NP problem, and I want to use the oracle to test if the formula-- if the graph has a clique, I reduce that problem to a SAT problem using the Cook-Levin theorem. And knowing that a clique of a certain size is going to correspond to having a formula which is satisfiable, now I can ask the oracle. And if I can do NP problems, I can do co-NP problems, because P is a deterministic class. Even though it has an oracle, it's still deterministic. It can invert the answer. Something that non-deterministic machines cannot necessarily do. So I don't know, maybe that's-- let's move on. So there's an oracle where P to the A equals NP to the A, which kind of seems kind of amazing at some level. Because here's an oracle where the non-determinism-- if I give you that oracle, non-determinism doesn't help. And it's actually a language we've seen. It's TQBF. Why is that? Well, here's the whole proof. If I have NP with a TQBF oracle. Let's just check each of these steps. I claim I can do that with a non-deterministic polynomial space machine, which no longer has an oracle. The reason is that, if I have polynomial space, I can answer questions about TQBF without needing an oracle. I have enough space just to answer the question directly myself. And I use my non-determinism here to simulate the non-determinism of the NP machine. So every time the NP machine branches non-deterministically, so do I. Every time one of those branches asks the oracle a TQBF question, I just do my polynomial space algorithm to solve that question myself. But now NPSPACE equals PSPACE by Savitch's theorem. And because TQBF is PSPACE complete, for the very same reason that a SAT oracle allows me to do every NP problem, a TQBF problem allows me to do every PSPACE problem. And so I get NP contained within P for a TQBF oracle. And of course, you get the containment the other way immediately. So they're equal. What does that have to do with-- somebody said-- well, I'll just-- I don't want to run out of time. So I'll take any questions at the end. What does this got to do with the P versus NP problem? OK, so this is a very interesting connection. Remember, we just showed through a combination of today's lecture and yesterday's lecture, and I guess Thursday's lecture, that this problem, this equivalence problem, is not in PSPACE, and therefore it's not in P, and therefore it's intractable. That's what we just did. We showed it's complete for a class, which is provably outside of P, provably bigger than P. That's the kind of thing we would like to be able to do to separate P and NP. We would like to show that some other problem is not in P. Some other problem is intractable. Namely, SAT. If we could do SAT, then we're good. We've solved P and NP. So we already have an example of being able to do that. Could we use the same method? Which is something people did try to do many years ago, to show that SAT is not in P. So what is that method really? The guts of that method really comes from the hierarchy there. That's where you were actually proving problems that are hard. You're getting this problem with through the hierarchy construction that's provably outside of PSPACE. And outside of P. That's a diagonalization. And if you look carefully at what's going on there-- so we're going to say, no, we're not going to be able to solve SAT, show SAT's outside of P in the same way. And the reason is, suppose we could. Well the hierarchy theorems are proved by diagonalization. What I mean by that is that in the hierarchy theorem, there's a machine D, which is simulating some other machine, M. To remember what's going on there, remember that we made a machine which is going to make its language different from the language of every machine that's running with less space or with less time. That's how D was defined. It wants to make sure its language cannot be done in less space. So it makes sure that its language is different. It simulates the machines that use less space, and does something different from what they do. Well, that simulation-- if we had an oracle, if we're trying to show that if we provide both a simulator and the machine being simulated with the same oracle, the simulation still works. Every time the machine you're simulating asks a question, the simulator has the same oracle so it can also ask the same question, and can still do the simulation. So in other words, if you could prove P different from NP using basically a simulation, which is what a diagonalization is, then you would be able to prove that P is different from NP for every oracle. So if you can prove P different from NP by a diagonalization, that would also immediately prove that P is different from NP for every oracle. Because the argument is transparent to the oracle. If you just put the oracle down, everything still works. But-- here is the big but, it can't be that-- we know that P A is-- we know this is false. We just exhibit an oracle for which they're equal. It's not the case that P is different from NP for every oracle. Sometimes they're equal, for some oracles. So something that's just basically a very straightforward diagonalization, something that's at its core is a diagonalization, is not going to be enough to solve P and NP. Because otherwise it would prove that they're different for every oracle. And sometimes they're not different, for some oracles. That's an important insight for what kind of a method will not be adequate to prove P different from NP. And this comes up all the time. People who propose hypothetical solutions that they're trying to show P different from NP. One of the very first things people ask is, well, would that argument still work if you put an oracle there. Often it does, which points out there was a flaw. Anyway, last check in. So this is just a little test of your knowledge about oracles. Why don't we-- in our remaining minute here. Let's say 30 seconds. And then we'll do a wrap on this, and I'll point out which ones are right. Oh boy, we're all over the place on this one. You're liking them all. Well, I guess the ones that are false are lagging slightly. OK, let's conclude. Did I give you enough time there? Share results. So, in fact-- Yeah, so having an oracle for the complement is the same as having an oracle. So this is certainly true. NP SAT equal coNP SAT, we have no reason to believe that would be true, and we don't know it to be true. So B is not a good choice and that's the laggard here. MIN-FORMULA, well, is in PSPACE, and anything in PSPACE is reducible to TQBF, so this is certainly true. And same thing for NP with TQBF and coNP with TQBF. Once you have TQBF, you're going to get all of PSPACE. And as we pointed out, this is going to be equal as well. So why don't we end here. And I think that's my last slide. Oh no, there's my summary here. This is what we've done. And I will send you all off on your way. How does the interaction between the Turing machine and the oracle look? Yeah, I didn't define exactly how the machine interacts with an oracle. You can imagine having a separate tape where it writes the oracle question and then goes into a special query state. You can formalize it however you like. They're all going to be-- any reasonable way of formalizing it is going to come up with the same notion in the end. It does show that P with a TQBF oracle equals PSPACE. Yes, that is correct. Good point. Why do we need the oracle to be TQBF? Wouldn't SAT also work because it could solve any NP problem? So you're asking, does P with a SAT oracle equal NP with a SAT oracle? Not known. And believed not to be true, but we don't have a compelling reason for that. No one has any idea how to do that. Because, for example, we showed the complement of MIN-FORMULA is in NP with a SAT oracle. But no one knows how to do-- because there's sort of two levels of non-determinism there. There's guessing the smaller formula, and then guessing again to check the equivalence. And they really can't be combined, because one of them is sort of an exist type guessing, the other one is kind of a for all type guessing. No one knows how to do that in polynomial time with a SAT oracle. Generally believed that they're not the same. In the check-in, why was B false? B is the same question. Does NP with a SAT oracle equal coNP with a SAT oracle? I'm not saying it's false, it's just not known to be true. It doesn't follow from anything that we've shown so far. And I think that would be something that-- well, I guess it doesn't immediately imply any famous open problem. I wouldn't necessarily expect you to know that it's an unsolved problem, but it is. Could we have oracles for undecidable language? Absolutely. Would it be helpful? Well, if you're trying to solve an undecidable problem, it would be helpful. But people do study that. In fact, the original concept of oracles was presented, was derived in the computability theory. And a side note, you can talk about reducibility. No, I don't want to even go there. Too complicated. What is not known to be true? What is not known to be true is that NP with a SAT oracle equals coNP with a SAT oracle, or equals P with a SAT oracle. Nothing is known except the obvious relations among those. Those are all unknown, and just not known to be true or false. Is NP with a SAT oracle equal to NP? Probably not. NP with a SAT oracle, for one thing, contains coNP. Because it's even more powerful. We pointed out that P with a SAT oracle contains coNP. And so NP with a SAT oracle is going to be at least as good. And so it's going to contain coNP. And so, probably not going to be equal to NP unless shockingly unexpected things happen in our complexity world.","74.5813217163086","5","DPRSearchEngine","N32bnUliSzo.en-j3PyPqV-e1s_9_mp4","N32bnUliSzo.en-j3PyPqV-e1s","18.404J","22"
"47","How does a probabilistic Turing machine decide a language with an error probability ε?"," 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Turing Machines (TMs) 
head 
˽ ˽
a
b
a 
. . .
b b
Finite 
read/write input tape 
control 
1) Head can read and write 
2) Head is two way (can move left or right) 
3) Tape is infinite (to the right) 
4) Infinitely many blanks “˽“ follow input 
5) Can accept or reject any time (not only at end of input) 
8 
","74.345703125","6","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_8_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"47","How does a probabilistic Turing machine decide a language with an error probability ε?","if an English description is possible for a Turing machine? Well, you can always write down an English description for any machine. It's-- might be very technical looking, but if you can write it down in a formal way as states and transitions, then you can simply write down an English description, which would just be, follow those states. OK, let's move on. OK, this is going to be our first example of a algorithm that's going to answer a question about automata. And it's a very simple problem. It's a very simple problem to solve, because we want to start out easy. The name of the problem is the acceptance problem for deterministic finite automata, acceptance problem for DFAs. And I'm going to express it, as I always do, as a language.","74.32449340820312","7","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_4_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"47","How does a probabilistic Turing machine decide a language with an error probability ε?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","74.03135681152344","8","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"47","How does a probabilistic Turing machine decide a language with an error probability ε?"," 
 
 
 
  
 
 
  
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Intro to Complexity Theory 
Computability theory (1930s - 1950s): 
Is A decidable? 
Complexity theory (1960s - present): 
Is A decidable with restricted resources? 
(time/memory/…) 
Example: Let ! = a#b# $ ≥0 . 
Q: How many steps are needed to decide !? 
Depends on the input. 
We give an upper bound for all inputs of length '. 
Called “worst-case complexity”. 
2 
","73.85323333740234","9","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_2_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"47","How does a probabilistic Turing machine decide a language with an error probability ε?"," 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
   
 
 
 
 
   
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
  
 
 
  
 
  
 
  
Turing machine model – review 
head 
˽ ˽ . . .
a
b
a
b
b
Finite 
read/write input tape 
control 
On input ! a TM "" may halt (enter #acc or #rej) 
) is T-recognizable if ) = +("") for some TM "". 
or loop (run forever). 
) is T-decidable if ) = +("") for some TM decider "". 
So "" has 3 possible outcomes for each input !: 
halts on all inputs 
1. Accept ! (enter #acc ) 
Turing machines model general-purpose computation. 
2. Reject ! by halting (enter #rej ) 
Q: Why pick this model? 
3. Reject ! by looping (running forever) 
A: Choice of model doesn't matter. 
All reasonable models are equivalent in power. 
Virtues of TMs: simplicity, familiarity. 
2 
","73.79386138916016","10","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_2_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"48","What is the role of the start variable in generating strings from a context-free grammar (CFG)?"," 
 
 
 
 
 
 
 
 
 
 
Regular 
language 
Context Free 
language 
Regular 
languages 
Recap 
Recognizer 
DFA or NFA 
PDA 
Context Free 
languages 
Generator 
Regular 
expression 
Context Free 
Grammar 
11 
","83.31878662109375","1","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_11_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"48","What is the role of the start variable in generating strings from a context-free grammar (CFG)?",";
/
def testGreedy(items, constraint, keyFunction):
taken, val = greedy(items, constraint, keyFunction)
print('Total value of items taken =', val)
for item in taken:
print('   ', item)
	

'
","76.39234161376953","2","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_25_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"48","What is the role of the start variable in generating strings from a context-free grammar (CFG)?","  
  
  
  
 
 
 
  
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Equivalence of CFGs and PDAs 
Theorem: ! is a CFL iff* some PDA recognizes ! 
Done. 
In book.  You are responsible for knowing 
it is true, but not for knowing the proof. 
* “iff” = “if an only if” means the implication goes both ways. 
So we need to prove both directions: forward (→) and reverse (←). 
Check-in 4.3 
Is every Regular Language also 
a Context Free Language? 
(a) Yes 
(b) No 
(c) Not sure 
Check-in 4.3 
10 
","76.21192932128906","3","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_10_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"48","What is the role of the start variable in generating strings from a context-free grammar (CFG)?"," &&#
class Node(object): 
    def __init__(self, name): 
""""""Assumes name is a string"""""" 
self.name = name 
    def getName(self): 
return self.name 
    def __str__(self): 
return self.name 
Q>KKKMN
LP
","75.96235656738281","4","DPRSearchEngine","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_15_pdf","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3","6.0002","3"
"48","What is the role of the start variable in generating strings from a context-free grammar (CFG)?","DP shows !CFG ∈P
Theorem: !CFG ∈P 
Proof :  Use DP (Dynamic Programming) = recursion + memory.
& = “On input 〈), +, R〉
same as before
S
T
R
+
-
.
1.  For each way to divide + = -. and for each rule R →ST
2.       Use & to test 〈), -, S〉and 〈), ., T〉
3.       Accept if both accept
4.  Reject if none of the above accepted.”
Then decide !CFG by starting from G’s start variable.
Total number of calls is 0(23) so time used is polynomial. 
Alternately, solve all smaller sub-problems first: “bottom up” 
Check-in 14.2
Check-in 14.2
Suppose 5 is a CFL.   
Does that imply that 5 ∈P? 
(a) Yes
(b) No. 
9
","75.91899108886719","5","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_9_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"48","What is the role of the start variable in generating strings from a context-free grammar (CFG)?"," 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
18.404/6.840 Lecture 4 
Last time: 
- Finite automata → regular expressions 
- Proving languages aren’t regular 
- Context free grammars 
Today: (Sipser §2.2) 
- Context free grammars (CFGs) – definition 
- Context free languages (CFLs) 
- Pushdown automata (PDA) 
- Converting CFGs to PDAs 
1 
","75.79042053222656","6","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_1_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"48","What is the role of the start variable in generating strings from a context-free grammar (CFG)?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
18.404/6.840 Lecture 5 
Last time: 
- Context free grammars (CFGs) 
- Context free languages (CFLs) 
- Pushdown automata (PDA) 
- Converting CFGs to PDAs 
Today: (Sipser §2.3, §3.1) 
- Proving languages not Context Free 
- Turing machines 
- T-recognizable and T-decidable languages 
1 
","75.49264526367188","7","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_1_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"48","What is the role of the start variable in generating strings from a context-free grammar (CFG)?","Attempt to show !CFG ∈P
Theorem: !CFG ∈P 
Proof attempt:
Recursive algorithm & tests if ' generates (, starting at any specified variable R. 
& = “On input 〈', (, R〉
1.  For each way to divide ( = -. and for each rule R →ST
2.       Use & to test 〈', -, S〉and 〈', ., T〉
3.       Accept if both accept
4.  Reject if none of the above accepted.”
Then decide !CFG by starting from '’s start variable.
& is a correct algorithm, but it takes non-polynomial time.
(Each recursion makes 0(2) calls and depth is roughly log 2.) 
Fix:  Use recursion + memory called Dynamic Programming (DP)
Observation:  String ( of length 2 has 0(27) substrings (8 ⋯(:
therefore there are only 0(27) possible sub-problems 〈', -, S〉to solve.  
S
T
R
(
-
.
8
","75.47708129882812","8","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_8_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"48","What is the role of the start variable in generating strings from a context-free grammar (CFG)?","is called a derivati 
for so 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
   
 
 
 
 
 
   
 
 
 
 
 
 
 
 
  
  
   
   
 
 
 
 
   
 
 
 
 
 
  
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
!
ution steps in !
on of - from ,. 
me CFG !. 
CFG – Formal Definition 
Defn: A Context Free Grammar (CFG) ! is a 4-tuple (#, Σ, &, ') 
# finite set of variables 
Σ finite set of terminal symbols 
& finite set of rules (rule form: # → # ∪Σ ∗ )
' start variable 
For ,, - ∈ # ∪Σ ∗ write 
Check-in 4.1 
1) , ⇒ ­ if can go from , to - with one substitution step in Which of these are valid CFGs? 
∗ 
2) , ⇒ - if can go from , to - with some number of substit 
90: 
B → 0B1 | ε 
91: 
S → 0S | S1 
, ⇒,0 ⇒,1 ⇒⋯⇒,3 = -
B1 → 1B 
R → RR 
If , = ' then it is a derivation of -. 
0B → 0B 
∗ 
a) 90 only 
5 ! = 6 6 ∈Σ∗ and ' ⇒ 6} 
b) 91 only 
Defn: 8 is a Context Free Language (CFL) if 8 = 5(!) 
c) Both 90 and 91 
d) Neither 
Check-in 4.1 
3 
","75.46045684814453","9","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_3_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"48","What is the role of the start variable in generating strings from a context-free grammar (CFG)?"," 
 
  
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
 
 
 
 
 
 
 
 
 
 
 
Boolean Labeling 
Alternative way to view BP computation 
Show by example: Input is !"" = 0, !# = 1, !$ = 1 
The BP follows its execution path.
!"" 1
Label all nodes and edges on the execution path with 1 
0
1 
1 0 
and off the execution path with 0. 
Output the label of the output node 1. 
1 !# 1
!# 0
0 
Obtain the labeling inductively by using these rules: 
0 
1
0
1 
0
0 
0
1 
' 
0
1 
' ∧!)
' ∧!)
'"" ∨'# ∨'$
!$
!$
!)
1 
'""
'#
'$
1
0 
0 
0
0
1 
0 
0 
1 = output 
0
1 
Label outgoing edges from nodes
Label nodes from incoming edges 
4 
","75.41136169433594","10","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_4_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"49","How do the action and template parts differ in an English sentence compared to a Turing machine when applying the recursion theorem?","if an English description is possible for a Turing machine? Well, you can always write down an English description for any machine. It's-- might be very technical looking, but if you can write it down in a formal way as states and transitions, then you can simply write down an English description, which would just be, follow those states. OK, let's move on. OK, this is going to be our first example of a algorithm that's going to answer a question about automata. And it's a very simple problem. It's a very simple problem to solve, because we want to start out easy. The name of the problem is the acceptance problem for deterministic finite automata, acceptance problem for DFAs. And I'm going to express it, as I always do, as a language.","72.71417236328125","1","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_4_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"49","How do the action and template parts differ in an English sentence compared to a Turing machine when applying the recursion theorem?","And basically it says, so really what we're doing here is called the recursion theorem, as you'll see. We'll actually present the recursion theorem formally on the next slide. But here, in both of these cases, we kind of have a template part and an action part. In both cases, there are two parts to the instructions, the template and the action. OK? So I'm going to leave it to you to try to imagine which of those is which, in each of these two examples. And then, I'm going to ask you to pick. In the Turing machine, which is the action and which is the template, and in the sentence, which is the action and which is the template. The action is the part where there's some interesting sort of instructional stuff happening that you have to carry out. The template is really basically just text or just a string. So let me pull up that poll. See what you think. Because I'm asking you now to indicate where is the action part in both of those cases. What is the upper phrase and lower phrase? I mean, of this sentence here. So write the following twice. This is the upper phrase. And the part in quotations is the lower phrase-- sorry. OK, almost done here? 5 seconds-- a few of you have not answered yet. Answer it. One second to go. OK, here we go, ending polling. So the majority here is correct. I would say, in the English sentence here, the action part is the first part. That's where you actually have been directed to do something. The second half of the sentence, the lower part of the sentence, is just a template written. This is just some string here. There's no action really being directed. It happens to be the same as the top, but this could have been just Hello World. This could have been anything. And then the upper part acts on that. So the upper part is the action part. So it's the upper phrase that's the relevant part. Now, in the Turing machine, in a sense, it's the other way around. The first part is really just the template. The second part, B, is where you're doing some actual work on the template. You're taking that, basically text, which could be anything. A could be anything. And you're looking at that template and reconstructing what A was from that string that appears on the tape. So B is actually the one that's doing the work. So it's B and the upper phrase with part c is correct. So let us continue then. Oh, I want to mention here problem 6 on the Pset. So your job really is to implement this in-- if you have a programming language that you like-- it could be Python or whatever your favorite Java, whatever you like-- you can implement this. If you don't know any programming languages, then just make up some sort of pseudo programming language and implement it there. Let me point out that getting the quoting right is a bit of a pain because you have to kind of escape the quotes and so on. I'm not going to be fussy about that. So you can still get full credit even if you don't get the quoting part quite correct. Do your best. I think it's an interesting problem to try to solve. And if you struggle with it for a while, it's slippery. It's the kind of thing you can easily spend a couple of hours on this problem. Because it's a bit tricky to manage to make a program which prints itself out, which is what the task of problem is on the Pset. But don't fuss about too much on the quoting if that's the only thing that's hanging you up. Try to get the main structure of it, which is fairly simple, actually. And if you can't get the quoting part to work, I'll ask the graders not to penalize you for that part.","72.35418701171875","2","DPRSearchEngine","N-_XmLanPYg.en-j3PyPqV-e1s_6_mp4","N-_XmLanPYg.en-j3PyPqV-e1s","18.404J","11"
"49","How do the action and template parts differ in an English sentence compared to a Turing machine when applying the recursion theorem?"," 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
   
 
 
 
 
Write “Hello World”
Hello World
Write this sentence
Write this sentence
Write the following twice, the second time in quotes “Hello World”
Hello World “Hello World”
Cheating: TMs don’t have this self-reference primitive.
English Implementation 
Check-in 11.1 
Implementations of the Recursion Theorem have two parts, 
a Template and an Action. In the TM and English implementations, 
which is the Action part? 
(a) A and the upper phrase 
(b) A and the lower phrase 
(c) B and the upper phrase 
(d) B and the lower phrase. 
Write the following twice, the second time in quotes 
“Write the following twice, the second time in quotes” 
Write the following twice, the second time in quotes 
“Write the following twice, the second time in quotes” 
& 
% 
' 〈)〉 
Compute & = ' 〈)〉 
from % on tape. 
!""#$ 
Note on Pset Problem 6: Don’t need to worry about quoting. 
5 
Check-in 11.1 
&% 
","71.91461181640625","3","DPRSearchEngine","779043ea724131d008eae652d703938f_MIT18_404f20_lec11_5_pdf","779043ea724131d008eae652d703938f_MIT18_404f20_lec11","18.404J","11"
"49","How do the action and template parts differ in an English sentence compared to a Turing machine when applying the recursion theorem?"," 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Turing Machines (TMs) 
head 
˽ ˽
a
b
a 
. . .
b b
Finite 
read/write input tape 
control 
1) Head can read and write 
2) Head is two way (can move left or right) 
3) Tape is infinite (to the right) 
4) Infinitely many blanks “˽“ follow input 
5) Can accept or reject any time (not only at end of input) 
8 
","71.59223937988281","4","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_8_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"49","How do the action and template parts differ in an English sentence compared to a Turing machine when applying the recursion theorem?","Notation for encodings and TMs
Notation for encoding objects into strings
- If ! is some object (e.g., polynomial, automaton, graph, etc.), 
we write 〈!〉to be an encoding of that object into a string.  
- If !$, !&, … , !( is a list of objects then we write 〈!$, !&, … , !(〉
to be an encoding of them together into a single string. 
Notation for writing Turing machines
We will use high-level English descriptions of algorithms when we describe TMs, 
knowing that we could (in principle) convert those descriptions into states, 
transition function, etc.  Our notation for writing a TM ) is
) = “On input +
[English description of the algorithm]”
Check-in 6.3
If , and - are strings, would ,- be a good choice 
for their encoding 〈,, -〉into a single string?
a)
Yes.
b)
No. 
Check-in 6.3
8
","71.49163818359375","5","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_8_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"49","How do the action and template parts differ in an English sentence compared to a Turing machine when applying the recursion theorem?","§ Problem is exponen<al 
§ Have we overturned the laws of the universe? 
§ Is dynamic programming a miracle? 
§ No, but computa<onal complexity can be subtle 
§ Running <me of fastMaxVal is governed by number of 
dis<nct pairs, <toConsider, avail> 
◦Number of possible values of toConsider bounded 
by len(items)
◦Possible values of avail a bit harder to characterize 
◦Bounded by number of dis<nct sums of weights 
◦Covered in more detail in assigned reading 
How Can This Be? 
6.0002 LECTURE 2 
30 
","71.43891906738281","6","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_30_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"49","How do the action and template parts differ in an English sentence compared to a Turing machine when applying the recursion theorem?","power of a Turing machine. That's a question that I'm going to postpone to later, because you're asking if a Turing machine can simulate itself. And we'll talk about things like that, but that's in a few weeks from now, so I'll hold off on that one. Decidable languages-- somebody's asking me a good question about closure properties of the class of decidable languages. Are they closed under intersection, union, and so on? Yes. And the decidable languages are also closed under complement. That should be something you should think about. But yes, that is true. The recognizable languages, however, are closed under union and intersection, but they are not closed under complement. So that we will prove on Thursday's lecture. So another question is, could we have just run B on w in this-- in solving this problem, instead of using reduced-- converting it to a new Turing machine-- the B prime? Well, yes, we could have just done that. OK. I think we better move on. I don't want to get too bogged down here-- got a lot of questions there, so sorry if I'm not getting to all of the questions. OK. Or you can write to the TAs too, obviously. I'm sure you are.","71.35211181640625","7","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_7_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"49","How do the action and template parts differ in an English sentence compared to a Turing machine when applying the recursion theorem?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 16: Dyn. Prog. Subproblems 
Lecture 16: Dyn. Prog. Subproblems 
Dynamic Programming Review 
• Recursion where subproblem dependencies overlap, forming DAG 
• “Recurse but re-use” (Top down: record and lookup subproblem solutions) 
• “Careful brute force” (Bottom up: do each subproblem in order) 
Dynamic Programming Steps (SRT BOT) 
1. Subproblem deﬁnition 
subproblem x 2 X 
• Describe the meaning of a subproblem in words, in terms of parameters 
• Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence 
• Often multiply possible subsets across multiple inputs 
• Often record partial state: add subproblems by incrementing some auxiliary variables 
2. Relate subproblem solutions recursively 
x(i) =  f(x(j), . . .) for one or more j < i  
• Identify a question about a subproblem solution that, if you knew the answer to, reduces 
the subproblem to smaller subproblem(s) 
• Locally brute-force all possible answers to the question 
3. Topological order to argue relation is acyclic and subproblems form a DAG 
4. Base cases 
• State solutions for all (reachable) independent subproblems where relation breaks down 
5. Original problem 
• Show how to compute solution to original problem from solutions to subproblem(s) 
• Possibly use parent pointers to recover actual solution, not just objective function 
6. Time analysis 
P 
• 
x2X work(x), or if work(x) =  O(W) for all x 2 X, then |X| · O(W) 
• work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time 
","71.24298095703125","8","DPRSearchEngine","28461a74f81101874a13d9679a40584d_MIT6_006S20_lec16_1_pdf","28461a74f81101874a13d9679a40584d_MIT6_006S20_lec16","6.006","16"
"49","How do the action and template parts differ in an English sentence compared to a Turing machine when applying the recursion theorem?","§ Add memo as a third argument 
◦def fastMaxVal(toConsider, avail, memo = {}):
§ Key of memo is a tuple 
◦(items leS to be considered, available weight) 
◦Items leS to be considered represented by 
len(toConsider)
§ First thing body of func<on does is check whether the 
op<mal choice of items given the the available weight 
is already in the memo 
§ Last thing body of func<on does is update the memo 
Modify maxVal to Use a Memo 
6.0002 LECTURE 2 
28 
","71.2327651977539","9","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_28_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"49","How do the action and template parts differ in an English sentence compared to a Turing machine when applying the recursion theorem?","Let's see. Equivalence problem for DFAs-- now we're going to take things to the next level-- ask, are there two-- I'm going to give you two DFAs. And I want to know, do they describe the same language-- do they recognize the same language? OK? So how are we going to do that? So that's a decidable language. Here's the decider. My input now is going to be two DFAs-- again, represented as a string, because that's what Turing machines deal with as their inputs. But they can unpack that string into two DFAs. And there are several different ways to do this problem, and I'm sure I'm going to get suggestions with other ways to go. One thing you could do is just to feed in strings up to a certain length. Just like before, you can't feed in all possible strings and see if the machines ever behave differently on any of them, because that's an infinite operation, and we already decided we can't do that. Now, if you want to talk about this being a recognizer, instead of a decider, then you might be able to do something like that just to make sure your-- you have to be just careful. Let me not say more on that right now. But certainly, for a decider, you can't go forever. You can't have infinite operations. So you would have to have a cut-off. So you can feed in all possible strings up to some length, say, into A and B, and see if there's any difference. Now, we actually had a problem on that in the problem set 1, which said, if two DFAs have unequal languages, then they're going to see a difference. Then there's going to be a string which acts differently on them, which is of length, at most, the product of the number of states of those two machines. So you can either reference that problem-- that would be an adequate solution-- or reprove it or whatever. That would be fine. In fact, you can do even better than that, as the optional problem showed. You only have to go up to the sum of the number of states, not up to the product. But that's actually very difficult to show. I'm not going to prove it that way. I'm going to prove it in an entirely different way, which doesn't require any analysis at all-- no proving something about balance. I'm going to take advantage of something we've already shown, which is I'm going to make a new finite automaton, a new DFAC built out of A and B, which accepts all the strings on which A and B disagree. And I'll show you how to-- that's easy to do. So first of all, let's-- in terms of a picture, let's understand what this is. So here we have-- this is the language of A, this is the language of B written as a Venn diagram. And where are those places where they disagree? Well, they're either in A, but not in B, or in B, but not in A. I'm showing it to you here in terms of the blue region. That actually has a name called the symmetric difference of these two sets. These are the-- all of the members which are in exactly one out of the two, but not both. If you can make a machine C that would accept all of the strings in the blue region, then what do we do with that machine? We test of its length language is empty, which is what we've already shown how to do-- because of the blue region is empty, that means that L of A equals L of B. So I'm going to make a machine, a DFAC where the language of C is exactly that symmetric difference. It's all the strings in A intersected with the strings that are not in B-- so in A and not in B-- or in B and not-- then not an A-- take the union of those two parts. And how do we know we can make C? Well, we have those closure constructions, which we showed several lectures back. Those closure instructions can be implemented on a Turing machine. So a Turing machine can build the DFAC, and then use that test from a few slides back, the emptiness-- the last slide-- the emptiness tester for DFAs on C to see whether its language is empty. And now, if C's language is empty, then we know we can accept, because that means the two-- that L of A equals L of B. Otherwise, we can reject. OK? So here's a note-- I'm going to ask you a check-in. You can also use that time to send me a few more questions, if you want. OK, here's my check-in. OK, now, instead of testing equivalence of finite-- of DFAs, I want to test equivalence of regular expressions. So here are R1, R2. Regular expressions are called the EQ regular expressions","71.06130981445312","10","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_10_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"52","How can non-Boolean assignments be used in an IP protocol to demonstrate coNP problems?"," 
 
  
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
  
  
  
 
18.404/6.840 Lecture 26 
Last time: 
- Interactive Proof Systems 
- The class IP 
- Graph isomorphism problem, !""# ∈ IP 
- #""&' ∈ IP (part 1) 
Today: (Sipser §10.4) 
- Arithmetization of Boolean formulas 
- Finish #""&' ∈ IP and conclude that coNP ⊆ IP 
1 
","74.1243896484375","1","DPRSearchEngine","7ac944716e076209c3964e073929f42e_MIT18_404f20_lec26_1_pdf","7ac944716e076209c3964e073929f42e_MIT18_404f20_lec26","18.404J","26"
"52","How can non-Boolean assignments be used in an IP protocol to demonstrate coNP problems?"," 
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
(
&
&
Constructing the !! graph ! 
Illustrate construction by example 
Say "" = ∃%& ∀%( ∃%) ⋯ ∀%+ [ ( %& ∨%( ∨%) ) ∧(%& ∨%( ∨%1) ∧⋯∧( ⋯) ]
! = 
3( 
3+ 
Endgame 
∀
∃ should win if assignment satisfied all clauses
3+ 
∀ should win if some unsatisfied clause 
Implementation 
∃
∀ picks clause node claimed unsatisfied
∃ picks literal node claimed to satisfy the clause 
liar will be stuck 
TRUE 
FALSE 
∀ 
⋯
3
3
%)
%
%( 
%&
%( %1 
%( 
⋮ 
%5 
%& 
3& 
∃ 
∀ 
∀ 
I = ∃ 
II = ∀ 
∃ 
∀ 
∃
∃ 
∀ 
∃ 
6
∃ 6 
%&
%& 
3& 
3( 
∀ 
5 
","73.99832153320312","2","DPRSearchEngine","fd9c1b8656c7def498dcf662f6750d87_MIT18_404f20_lec19_5_pdf","fd9c1b8656c7def498dcf662f6750d87_MIT18_404f20_lec19","18.404J","19"
"52","How can non-Boolean assignments be used in an IP protocol to demonstrate coNP problems?","Satisfiability Problem
Defn: A Boolean formula ! has Boolean variables (TRUE/FALSE values) 
and Boolean operations AND (∧), OR (∨), and NOT (¬). 
Defn: ! is satisfiable if ! evaluates to TRUE for some assignment to its variables.
Sometimes we use 1 for True and 0 for False.
Example:  Let ! =
& ∨' ∧(& ∨')
(Notation:  & means ¬&)  
Then ! is satisfiable  (x=1, y=0)  
Defn:  *+, =
!
! is a satisfiable Boolean formula}
Theorem (Cook, Levin 1971):    *+, ∈P  →P = NP 
Proof method:  polynomial time (mapping) reducibility
Check-in 14.3
Check-in 14.3
Is  *+, ∈NP?
(a) Yes.
(b) No. 
(c) I don’t know.
(d) No one knows.
11
","73.8177490234375","3","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_11_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"52","How can non-Boolean assignments be used in an IP protocol to demonstrate coNP problems?","Arithmetization Method
Method:  Simulate ∧and ∨with + and ×.
%&
0 1
'
' (1 −%&)
' %&
' ,
' -
' .
' , + ' - + ' .
%,
%-
%-
0 1
0
1
%.
%.
0
1
0
1
0
1
0
1
Replace Boolean labeling with arithmetical labeling
Inductive rules:
Start node labeled 1
' ∧/ →' ×/ = '/
'
→
1 −'
' ∨/ →' + / −'/
Simulate ∨with + because the BP is acyclic.
The execution path can enter a node 
at most one time. 
' ∧%&
' ∧%&
' , ∨' - ∨' .
5
","73.71627044677734","4","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_5_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"52","How can non-Boolean assignments be used in an IP protocol to demonstrate coNP problems?"," 
 
  
 
 
  
 
 
 
 
 
18.404/6.840 Lecture 25 
Last time: 
- Schwartz-Zippel Theorem 
- !""ROBP ∈ BPP 
Today: (Sipser §10.4) 
- Interactive Proof Systems 
- The class IP 
- Graph isomorphism problem 
- coNP ⊆ IP  (part 1) 
1 
","73.65107727050781","5","DPRSearchEngine","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25_1_pdf","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25","18.404J","25"
"52","How can non-Boolean assignments be used in an IP protocol to demonstrate coNP problems?","So just remember, interactive proof systems, there are these two parties, the prover and the verifier. The prover has unlimited computational ability. I kind of model that as an army of students perhaps who can-- where we don't-- they can work all night. They can use computational resources. And the prover, however, we're not going to measure the computational power of the prover. That's unlimited. And so the prover can do things like find certificates. It can test whether things are satisfiable. It can factor numbers. We don't care. It can do whatever we'd like and there is no charge for the prover's computational demands. OK. So the setup we had was the prover and the verifier. Both see the input. The exchange of polynomial number of messages. And then the verifier accepts or rejects. And we had this notion of the probability that the verifier ends up accepting when paired with a particular prover. And what we want is that for strings in a language, that probability should be high for some prover. And for strings not in the language, that probability should be low no matter what the prover does. So there's nothing the prover can do. And the way it kind of suggests that at any prover. But whatever the prover's strategy cannot make the verifier accept with high probability. Just doesn't have enough information or it doesn't-- it's just not able to make the verifier accept with high probability. You might think of the prover as trying to make the verifier accept. So the P tilde is a crooked prover. I don't think that went down very well with everybody. So I have it here. Another way of looking at it, maybe it looks a little bit more like NP here where IP is the collection of languages where there's a verifier, just like we had. You can think of NP as having a verifier which can check certificates. Here the prover is going to be like the certificate so that for strings in the language, there's a prover which can interact with the verifier and make it accept a high probability. And you're not in the language, there is no prover, which can interact with the verifier and make the verifier accept with even more than low probability. What's important is this gap, just like with BPP, between acceptance or rejection. And that gap is there because we want to be able to use the amplification lemma. And if there was no gap, then you wouldn't be able to amplify and make the probability of acceptance extremely high when you want it to be in the language, when you're in the language, and extremely low when you're not in the language. OK. So I hope that refreshes your memory as to how that works.","73.62188720703125","6","DPRSearchEngine","eEXSv0jChO4.en-j3PyPqV-e1s_2_mp4","eEXSv0jChO4.en-j3PyPqV-e1s","18.404J","26"
"52","How can non-Boolean assignments be used in an IP protocol to demonstrate coNP problems?","Arithmetization Method
Method:  Simulate ∧and ∨with + and ×.
%&
0 1
'
' (1 −%&)
' %&
',
'-
'.
', + '- + '.
%,
%-
%-
0 1
0
1
%.
%.
0
1
0
1
0
1
0
1
Replace Boolean labeling with arithmetical labeling
Inductive rules:
Start node labeled 1
' ∧/ →'×/ = '/
'
→
1 −'
' ∨/ →' + / −'/
Works because the BP is acyclic.
The execution path can enter a node 
at most one time. 
' ∧%&
' ∧%&
', ∨'- ∨'.
9
","73.40279388427734","7","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_9_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"52","How can non-Boolean assignments be used in an IP protocol to demonstrate coNP problems?","What's the worst case performance of a hash table? If I have to look up something in a hash table, and I happen to choose a bad hash table-- hash function, what's the worst case here? What? n, right? It's worse than a sorted array, because potentially, I hashed everything that I was storing to the same index in my hash table, and to be able to distinguish between them, I can't do anything more than a linear search. I could store another set's data structure as my chain and do better that way. That's actually how Java does it. They store a data structure we're going to be talking about next week as the chains so that they can get, worst case, log n. But in general, that hash table is only good if we're allowing-- OK, I want this to be expected good, but in the worst case, if I really need that operation to be worst case-- I really can't afford linear time ever for an operation of that kind-- then I don't want to use a hash table. And so on your p set 2, everything we ask you for is worst case, so probably, you don't want to be using hash tables. OK? Yes? AUDIENCE: What does the subscript e mean? JASON KU: What does the subscript e mean? That's great. In this chart, I put a subscript on this is an expected runtime, or an A meaning this is an amortized runtime. At the end, we talked about how, if we had too many things in our hash table, then, as long as we didn't do it too often-- this is a little hand wavey argument, but the same kinds of ideas as the dynamic array-- if, whenever we got a linear-- we are more than a linear factor away from where we are trying-- basically, the fill factor we were trying to be, then we could just completely rebuild the hash table with the new hash function randomly chosen from our hash table with a new size, and we could get amortized bounds. And so that's what Python-- how Python implements dictionaries, or sets, or even objects when it's trying to map keys to different things. So that's hash tables. That's great. The key thing here is, well, actually, if your range of keys is small, or if you as a programmer have the ability to choose the keys that you identify your objects with, you can actually choose that range to be small, to be linear, to be small with respect to your items. And you don't need a hash table. You can just use a direct access array, because if you know your key space is small, that's great. So a lot of C programmers probably would like to do something like that, because they don't have access to-- maybe C++ programmers would have access to their hash table. Any questions on this stuff before we move on? Yeah? AUDIENCE: So why is [INAUDIBLE]? JASON KU: Why is it expected? When I'm building, I could insert-- I'm inserting these things from x 1 by 1 into my hash table. Each of those insert operations-- I'm looking up to see whether that-- an item with that key already exists in my hash table. And so I have to look down the chain to see where it is. However, if I happen to know that all of my keys are unique in my input, all the items I'm trying to store are unique, then I don't have to do that check and I can get worst case linear time. Does that make sense? All right. It's a subtlety, but that's a great question. OK, so today, instead of talking about searching, we're talking about sorting. Last week, we saw a few ways to do sort. Some of them were quadratic-- insertion sort and selection sort-- and then we had one that was n log n. And this thing, n log n, seemed pretty good, but can I do better? Can I do better? Well, what we're going to show at the beginning of this class is, in this comparison model, no. n log n is optimal. And we're going to go through the exact same line of reasoning that we had last week. So in the comparison model, what did we use when we were trying to make this argument that any comparison model algorithm was going to take at least log n time? What we did was we said, OK, I can think of any model in the comparison model-- any algorithm in the comparison model as kind of this-- some comparisons happen. They branch in a binary sense, but you could have it generalized to any constant branching factor. But for our purposes, binary's fine. And what we said was that there were at least n outputs-- really n plus 1, but-- at least order n outputs. And we showed that-- or we argued to you that the height of this tree had to be at least log n-- log the number of leaves. It had to be at least log the number of leaves. That was the height of the decision tree. And if this decision tree represented a search algorithm, I had to walk down and perform these comparisons in order, reach a leaf where I would output something. If the minimum height of any binary tree on a linear number of leaves is log n, then any algorithm in the comparison model also has to take log n time, because it has to do that many comparisons to differentiate between all possible outputs. Does that make sense? All right. So in the sort problem, how many possible outputs are there?","73.2242431640625","8","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_4_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"52","How can non-Boolean assignments be used in an IP protocol to demonstrate coNP problems?"," 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
  
  
 
 
 
 
 
 
 
 
 
  
 
  
 
 
   
 
  
 
 
 
 
 
 
  
   
   
 
 
  
  
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
Interactive Proofs – formal model 
Two interacting parties 
Verifier (V): Probabilistic polynomial time TM 
Prover (P): Unlimited computational power 
Both P and V see input !. 
They exchange a polynomial number of polynomial-size messages. 
Then V accepts or rejects. 
Defn: Pr[ (V ↔ P) accepts ! ] = probability that V accepts when V interacts with P, given input !. 
Defn: IP = $ for some V and P (This P is an “honest” prover) 
! ∈$ → Pr [ (V ↔ P) accepts ! ] ≥ )⁄* 
! ∉$ → for any prover P, Pr [ (V ↔ P) 
, accepts ! ] ≤ .⁄* 
Think of ,P as a “crooked” prover trying to make V accept when it shouldn’t. 
An amplification lemma can improve the error probability from .⁄* to ./)0123 4 
5 
","73.13020324707031","9","DPRSearchEngine","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25_5_pdf","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25","18.404J","25"
"52","How can non-Boolean assignments be used in an IP protocol to demonstrate coNP problems?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","73.12100219726562","10","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"53","What is the significance of the star operation in set operations for languages?","And the last of the regular operations is the so-called star operation, which is a unary operation. It applies to just a single language. And so what you do is now you're going to take-- to get a member of the star language, you're going to take a bunch of strings in the original language, A, you stick them together. Any number of members of A, you stick them together, and that becomes an element of the star language. And we'll do an example in a second if you didn't get that. But one important element is that when you have the star language, you can also allow it to stick zero elements together, and then you get the empty string. So that's always a member of the star language, the empty string. OK, so let's look at some examples. Let's say A is the language-- these are two strings here-- good, bad. And B is the language boy, girl. Now, if we take the union of those two, we get good, bad, boy, girl. That's kind of what you'd expect. And now let's take a look at the concatenation. Now, if you concatenate the A and the B language, you're going to get all possible ways of having an A string followed by all possible ways of having a B string. So you can get goodboy, goodgirl, badboy, badgirl. Now, looking at the star, well, that applies to just one language. So let's say it's the good, bad language from A. And so the A star that you get from that is all possible ways of sticking together the strings from A. So using no strings, you always get the empty string. That's always guaranteed to be a member of A. And then just taking one element of A, you get good, or another element, bad. But now two elements of A, you get goodgood or goodbad, and so on. Or three elements of A, goodgoodgood, goodgoodbad. And so, in fact, A star is going to be an infinite language if A itself contains any non-empty member. So if A is the empty language or if A contains just the language empty string, then A star will be not an infinite language. It'll just be the language empty string. But otherwise, it'll be an infinite language. I'm not even sure-- OK. I'm not-- [LAUGHS] I'm ignoring the chat here. I'm hoping people are getting-- are you guys are getting your questions answered by our TAs? How are we doing, Thomas? AUDIENCE: One question is, are the slides going to be posted? MICHAEL SIPSER: Are the slides going to be posted? Well, the whole lecture is going to be recorded. Is it helpful to have the slides separately? I can post the slides. Sure. Remind me if I don't, but I'll try to do that. Yes, it is helpful. I will do that. Yeah. Yeah, I will post the slides. Just, Thomas, it's your job to remind me. AUDIENCE: OK. MICHAEL SIPSER: All right, good. So we talked about the regular operations. Let's talk about the regular expressions. So regular expressions are-- just like you have the arithmetical operations, then you can get arithmetical expressions, like 1 plus 3 times 7. So now we're going to make expressions out of these operations. First of all, you have, the more atomic things, the building blocks of the expressions, which are going to be like elements of sigma, elements of the alphabet or the sigma itself as an alphabet symbol, or the empty language or the empty string. These are going to be the building blocks for the regular expressions. We'll do an example in a second. And then you combine those basic elements using the regular operations of union, concatenation, and star. So these are the atomic expressions, these are the composite expressions. So, for example, if you look at the expression 0 union 1 star-- so we can also write that as sigma star. Because if sigma is 0 and 1, then sigma star is the same thing as 0 union 1-- sigma is the same as 0 union 1. And that just gives all possible strings over sigma. So this is something you're going to see frequently. Sigma star means this is the language of all strings over the alphabet we're working with at that moment. Now, if you take sigma star 1, you just concatenate 1 onto all of the elements of sigma star, and that's going to give you all strings that end with a 1. Technically, you might imagine writing this with braces around the 1, but generally, we don't do that. We just-- single element sets, single element strings, we write without the braces, because it's clear enough without them, and it gets messy with them. So sigma star 1 is all strings that end with 1. Or, for example, you take sigma star 11 sigma star, that is all strings that contain 11. And we already saw that language once before. That's the language of that other machine that we presented one or two slides back. OK? Right. Yeah, but in terms of readings-- by the way, sorry, I don't know if it's helpful to you for me to do these interjections-- but the readings are listed also on the homework. So if you look at the posted homework 1, it tells you which chapters you should be reading now. And also, if you look at the course schedule, which is also on the home page, it has the whole course plan and which readings are for which dates. So it's all there for you. And so our goal here-- this is not an accident that sigma star 11 sigma star happens to be the same language as we saw before from the language of that finite automaton M1. In fact, that's a general phenomenon. Anything you can do with a regular expression, you can also do with a finite automaton and vice versa. They are equivalent in power with respect to the class of languages they describe. And we'll prove that. OK? So if you step back for a second and just let yourself appreciate this, it's kind of an amazing thing. Because finite automata, with the states and transitions, and the regular expressions, with these operations of union, concatenation, and star, they look totally different from one another. They look like they have nothing to do with one another. But, in fact, they both describe exactly the regular languages, the same class of languages. And so it's kind of a cool fact that you can prove, that these two very different looking systems actually are equivalent to one another. Can we get empty string from empty set? Yeah. There are a bunch of exotic cases, by the way. So empty language star is the language which has just the empty string. If you don't get that, chew on that one. But that is true.","71.96074676513672","1","DPRSearchEngine","9syvZr-9xwk.en-j3PyPqV-e1s_10_mp4","9syvZr-9xwk.en-j3PyPqV-e1s","18.404J","1"
"53","What is the significance of the star operation in set operations for languages?","So first, we're going to introduce this concept of regular expressions-- which, again, these are things you may have run into in one way or another before. So we're going to introduce something called the regular operations. Now, I'm sure you're familiar with the arithmetical operations, like plus and times. Those apply to numbers. The operations we're going to talk about are operations that apply to languages. So they're going to take, let's say, two languages, you apply an operation, you're going to get back another language. Like the union operation, for example, that's one you probably have seen before. The union of two languages here is a collection of strings that are in either one or the other. But there are other operations, which you may not have seen before, that we're going to look at-- the concatenation operation, for example. So that says you're going to take a string from the first language and another string from the second language and stick them together. And it's called concatenating them. And you do that in all possible ways, and you're going to get the concatenation language from these two languages that you're starting with, A and B. The symbol we use for concatenation is this little circle. But often, we don't. We just suppress that and we write the two languages next to one another with the little circle implied.","70.77437591552734","2","DPRSearchEngine","9syvZr-9xwk.en-j3PyPqV-e1s_9_mp4","9syvZr-9xwk.en-j3PyPqV-e1s","18.404J","1"
"53","What is the significance of the star operation in set operations for languages?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","69.56944274902344","3","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"53","What is the significance of the star operation in set operations for languages?","We're given a sequence of symbols. And so the natural thing is to try prefixes, suffixes, and substrings. I'm going to jump ahead and think about the relation first. I want to identify some question about a subproblem or its solution that would let me reduce to smaller subproblems. This is a little trickier. This is very different. We're not always doing something on the left or on the right, or we can't assume there's something happening on the left, because maybe we take a product in the middle first. If I take a product in the middle first, then I have some result here, but I still have three things. I have the thing to the left, I have the thing in the middle, and I have the thing on the right. It turns out to be very messy to think about what the first operation is. Because we can think of this as a tree, where we take a product here-- we take a sum of 7 and 4 and 3 and 5 over here and then take the product at the root. But I don't know what the tree is, right? I only know these numbers and these operators, but I don't know how to organize this tree. The idea is, if you think of this tree, what is the one thing that's easiest to identify? It's the root. The root corresponds to the last operation I do in this computation. The last thing I did was take a product. And that's a lot easier, because if I guess who is at the root-- which operator is at the root-- that naturally decomposes into the left subtree and the right subtree. And those will always be substrings. We kind of know this. This node corresponds to everything left of this operator, and this substring or this subtree corresponds to everything to the right of the operator. So this is our idea, is we're going to guess which operation, star i, is evaluated last-- or, in other words, at the root. So this is the question. It has n possible answers-- I guess, actually, n minus 1 from operator 1, operator n minus 1. And so we'll just brute force all of those choices. I wanted to start here because-- to realize that if, I choose some star i in the middle, which might be the right thing, like in this example. Star i is the middle one-- middle operator. I naturally decompose into everything to the left of that operator and everything to the right of that operator. This is a prefix. This is a suffix. So you might think, oh, my subproblems are all prefixes and all suffixes. But that would be wrong, because if you have a bunch of operators-- and say you choose this one to be last. So I have a prefix here and a suffix here. And then there will be some-- within this suffix, I'll choose some operator to be the root of that one, and I have a prefix and a suffix of this suffix. But in particular, I will have to evaluate this subproblem, which is a prefix of a suffix-- in other words, a substring. So never use a mixture of prefixes and suffixes. If you need both, you probably need all substrings. So our subproblems are going to be substrings. OK. I'm not going to write the subproblems quite yet, because there's another idea we need. So what do I need to do with the substring? I'm going to guess the middle operator and then evaluate the left substring, evaluate the right substring. What am I trying to do with those substring? I guess I'm trying to solve this problem, which is, place parentheses in order to maximize the result, and then return what the result is. And I can use paren pointers to reconstruct what the parentheses actually are. Once I guess what the last operator is, it enough to maximize the part to the right and maximize the part to the left? Will that always maximize my sum or product according to what this operator is? And if you think about it for a while. Yeah. If I want to maximize the sum, I should maximize the two parts. And if I want to maximize a product, I should maximize the two parts. That seems right. Except, I didn't say that my integers are positive. That's true if your integers are positive. But to make this problem more interesting, we're going to allow the integers to be negative. For example, 7 plus minus 4 times 3 plus minus 5. So I just added a couple of minuses to a couple of the numbers here. Then it's no longer best to pair them this way. If I pair them this way, like this, or if I add parentheses this way, I get 3 here, and I get minus 2 here. So I get-- the product of that is negative 6, which i probably not the maximum. In fact, I can do better, I believe, by doing the left operator last. So this, I claim, the best parenthisization, if I remembered it correctly. This is, minus 2 times minus 4 is 8, plus 7 is 15. So I got a positive number-- definitely better than the negative number I got. I claim this is the best. And the key property here is, when we take a product of two negative numbers, we get a positive number. Sometimes, you actually want to make things small, because small might mean very negative. You take two very big negative numbers-- very small negative numbers, in other words. You take their product, you get a very big product, positively, because the signs cancel. OK. So this seems tricky. We want to work on substrings, but we don't know whether we're trying to maximize, or you might think, well, maybe I'm trying to maximize the absolute value. But that's not good. Maybe overall, on this entire expression, I get negative 1 million. And that's not what I wanted. I wanted to maximize the sum. So I still need to solve the max evaluation that I can get, the max parenthesization, but I also need to solve the min parenthesization. If I can solve max and min, I'll know the entire range that I could get. And I really only-- I'll care about min especially when it lets me go negative. But let's just solve, in all cases, the min and the max, and then just brute force the rest. That's what I'm going to write down. So that was some motivation and why we are going to define subproblems this way. I'm going to define x of i, comma j, comma opt to be-- opt, here, is going to be either min or max. And this is my subproblem expansion. I really just care about max at the very end, but I'm going to care about min along the way. And i, j is going to specify my substring. So this is going to be the opt value-- opt stands for ""optimum"" here, or ""optimization."" The opt value I can get for the substring a i star plus 1, a i plus 1, and so on to star j minus 1, a j minus 1. OK. Being careful to get my indices correct here. And I want 0 less than or equal to i, less than j, less than equal to n. I claim and opt like this. OK. I'm going to get the min value and the max value separately. Those are two different subproblems. This is my expansion. This is the constraint I'm adding. And I'm only focusing on this substring from i inclusive to j exclusive. OK. So I claim those are good subproblems. Let's write down a recurrence relation. OK. Relate. I want to write x of i, j, opt on the left. And I want to optimize-- so this will be min or max-- on a set of choices. What is my set of choices? Well, like I said, I want to guess what is the last operation evaluated. I wrote star i here, but star i is already defined, so I'm going to use star k. So I'm going to guess which of my operations between i plus 1 and j minus 1 is the last one, and I evaluate. And that decomposes everything left of k. So that would be x of i, comma k, comma something. And then we will do operator star k on the part after k, which is from k to j, something. And I'm choosing between-- I think it's i less than k less than j. k is some operator in between, because I started i plus 1 and I ended j minus 1. So those are the possible choices for k. I tried them all. That's my local brute force. And then I take what I can get on the left, what I can get on the right, and multiply or add them according to whether the operator is plus or times. Now, should I maximize or minimize this one? Should I maximize or minimize this one? I don't know. So I'm just going to do more local brute force. Well, let's just say opt prime for the left-- or maybe I'll call it opt L for the left and opt R for the right part. And I'll just add this to my four-loop. Let's just try opt L and opt R. Just take all possible choices among min and max. Now, you could think hard-- and for addition, for example, if you're maximizing, you really only need to maximize the two parts. And if you're minimizing, you can prove you all need to minimize the two parts. But for multiplication, it's messy. It could be, really, any of the options. Because sometimes, when you minimize, you get a negative term. Sometimes, you don't. And so it depends what you're trying to do. You have to consider all the signs. But we don't need to think hard. We can just try all options. There's only four choices for opt L and opt R among min and max. You could do min-min, min-max, max-min, and max-max. So try-- it's just a multiplication by 4 in this four-loop. The big cost is actually this one, because there are j minus i choices for k. There's a constant number of choices for opt L and opt R. And you need to prove that this is correct. I won't do it here. But the idea is, if you're trying to minimize or maximize your sum or product, it's enough to know what ranges these could come in. And the optimal choice will always be an extreme in that range. We consider all of them here. And so we get this recurrence. Now, it needs a base case, and we need to check that it's acyclic. But topological order is just increasing j minus i. This is the usual order for substring problems, because this is increasing length of the substring. So start with very tiny substrings. Here, we'll start with length 1 substrings. We just have an a, i there. So that's going to be our base case. And you grow up to the entire string. And it doesn't matter how we order relative to opt as long as we are increasing in j minus i, because i to k and k to j will always be strictly smaller than i to j, and so this will be acyclic. The base case is x of i, i plus 1, opt. This is always a i. Doesn't matter what opt is, because there's nothing-- there's no choice. You just have a single number in that substring, because we're exclusive on i plus 1. And then the original problem we want to solve is x of 0, n, max. You could also solve min and see how small you can get it. So if you wanted to maximize the absolute value, you could solve the max problem and the min problem and take the largest of those two options. And how much time does this take? Well, how many subproblems are there? For substring problems, we have n squared subproblems. Now, we multiply the number of subproblems by 2, but that's still n squared. So we have n squared subproblems. And how much work per subproblem are we doing? Well, as I mentioned, we're doing j minus i choices for k and a constant number of choices for opt L and opt R. So this is theta j minus i, which, if I'll be sloppy, that's at most big O of n. And it turns out to be the right answer anyway. So there's a linear amount of non-recursive work. In fact, it's like a triangular number, but that's still theta n cubed. Same running time as v cubed we just got. But polynomial time. And this is pretty impressive, because we're really brute forcing all possible parenthesizations. There about 4 to the n, exponentially many, parenthesizations of an expression. But we're finding the biggest-- the one that evaluates the largest value and the one that evaluates to the smallest value in just n cubed time-- polynomial. And a key here was subproblem expansion, where we, in addition to solving the max problem, we also solved the min problem, because sometimes, you want to take two very small negative numbers and product them together to get a larger positive number. Cool. Question? AUDIENCE: Would anything go wrong if I added minus or divide? ERIK DEMAINE: So what if I had operators minus and divide? It's a good question. I'm certain that minus should work fine. If we do min and max, this should still evaluate the largest thing for division. I need to think about the cases. I would guess it works, but what we need to prove is that the way to maximize or minimize a division, say, given two numbers in the left and right, is that it either corresponds to maximizing or minimizing the thing on the left and then maximizing or minimizing the thing on the right. So as long as you have this kind of-- it's not exactly monotonicity. It's just that, in order to compute max or min, it suffices to know the max and min of the two parts. It's like interval arithmetic. You know, interval arithmetic? I want to know, what are the extremes I can get on the output of a division if I'm given that a number is in some interval here and some interval here? If the answer is always, use one of the extreme endpoints here and use one of the extreme endpoints here, then this algorithm will work. Otherwise, all bets are off. Cool. So if you negate-- if you put a minus here, that will work fine, because it's negating this range. And then it's just like sum. But-- AUDIENCE: [INAUDIBLE] ERIK DEMAINE: Oh, a divider-- if you're careful about 0, yeah. Actually, it doesn't work, because we care about how close this can get to 0 for division. It might be enough to consider those. It's like, instead of minimizing and-- instead of computing this entire interval, if this interval spans 0, maybe I need to know-- if 0 is here, I need to know how close to 0 I can get on the left side and how close to 0 I can get on the right side. Still just four quantities I need to know. I would guess, for division, that's enough. Yeah. Nice. Solved a little problem. Then, we would be multiplying the subproblem space, instead of by 2, by 4. Hey, maybe we should put this on the final. No, just kidding. Now it's in lecture, so we can't use it. But it's a cool set of problems, right? You can do a lot with dynamic programming. You don't need to be that clever, just brute force anything that seems hard. And when it works, it works great. And this class is all about understanding when it works and when it doesn't work. Of course, we will only give you problems where it works. But it's important to understand when it doesn't work. For example, DAG shortest paths-- that algorithm on a non-DAG, very bad. Infinite time. OK.","69.4666976928711","4","DPRSearchEngine","TDo3r5M1LNo.en-j3PyPqV-e1s_11_mp4","TDo3r5M1LNo.en-j3PyPqV-e1s","6.006","17"
"53","What is the significance of the star operation in set operations for languages?"," 
 
 
    
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Return to Closure Properties 
Recall Theorem: If !"", !$ are regular languages, so is !"" ∪!$ 
(The class of regular languages is closed under union) 
New Proof (sketch): Given DFAs &"" and &$ recognizing !"" and !$ 
&$
&"" 
ε 
ε 
& 
Construct NFA & recognizing !"" ∪!$ 
Nondeterminism 
parallelism 
vs 
guessing 
7 
","69.25138092041016","5","DPRSearchEngine","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_7_pdf","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2","18.404J","2"
"53","What is the significance of the star operation in set operations for languages?","Header for Decision Tree Implementa#on 
6.0002 LECTURE 2 
9 
def maxVal(toConsider, avail): 
    """"""Assumes toConsider a list of items,  
               avail a weight 
       Returns a tuple of the total value of a  
           solution to 0/1 knapsack problem and  
           the items of that solution""""” 
toConsider. Those items that nodes higher up in the tree 
(corresponding to earlier calls in the recursive call stack) 
have not yet considered 
 
avail. The amount of space still available  
","68.37865447998047","6","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_9_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"53","What is the significance of the star operation in set operations for languages?","We're almost done. This will actually work. It's really quite awesome. But for it to work, we need something called subtree augmentation, which I'll talk about generally. And then, we'll apply it to size. So the idea with subtree augmentation is that each node in our binary tree can store a constant number of extra fields. Why not? And in particular, if these fields are of a particular type-- maybe I'll call them properties. I'm going to define a subtree property to be something that can be computed from the properties of the nodes' children. So I should say this is of a node. So children are node.left and node.right. You can also access constant amount of other stuff,","68.29359436035156","7","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_9_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"53","What is the significance of the star operation in set operations for languages?",";
/
def testGreedys(maxUnits):
print('Use greedy by value to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits, Food.getValue)
print('\\nUse greedy by cost to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits,
lambda x: 1/Food.getCost(x))
print('\\nUse greedy by density to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits, Food.density)
testGreedys(800)
	


4
","68.09739685058594","8","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_26_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"53","What is the significance of the star operation in set operations for languages?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","68.09383392333984","9","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"53","What is the significance of the star operation in set operations for languages?","Arithmetization Method
Method:  Simulate ∧and ∨with + and ×.
%&
0 1
'
' (1 −%&)
' %&
',
'-
'.
', + '- + '.
%,
%-
%-
0 1
0
1
%.
%.
0
1
0
1
0
1
0
1
Replace Boolean labeling with arithmetical labeling
Inductive rules:
Start node labeled 1
' ∧/ →'×/ = '/
'
→
1 −'
' ∨/ →' + / −'/
Works because the BP is acyclic.
The execution path can enter a node 
at most one time. 
' ∧%&
' ∧%&
', ∨'- ∨'.
9
","68.07918548583984","10","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_9_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"54","What is the essence of the hierarchy theorems in the context of computational resources?"," 
 
  
  
 
 
 
 
 
 
   
 
 
 
 
  
 
  
 
  
 
 
  
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
   
 
    
   
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
   
  
Time Hierarchy Theorem (1/2) 
Theorem: For any !: ℕ → ℕ where ! is time constructible 
there is a language % where % requires & ! ' 
time, i.e, 
1) % is decidable in & ! ' 
time, and 
2) % is not decidable in ( ! ' / log ! ' 
time 
- .
On other words, TIME (
⊆, TIME ! ' 
/01 - . 
Proof outline:  Give TM 3 where 
1) 3 runs in & ! ' 
time 
2) 3 ensures that 4(3) ≠ 4(8) for every TM 8 that runs in ( ! ' / log ! ' 
time . 
Let % = 4(3). 
10 
","78.64570617675781","1","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_10_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"54","What is the essence of the hierarchy theorems in the context of computational resources?"," 
 
  
  
 
 
 
  
 
 
   
 
 
 
  
 
  
 
  
 
 
  
 
  
 
 
 
 
  
 
 
 
  
 
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
Space Hierarchy Theorem (1/2) 
Theorem: For any !: ℕ → ℕ (where ! satisfies a technical condition) 
there is a language % where % requires & ! ' 
space, i.e, 
1) % is decidable in & ! ' 
space, and 
2) % is not decidable in ( ! ' 
space 
On other words, SPACE ( ! ' 
⊆, SPACE ! ' 
Notation: SPACE ( ! ' 
= {,| some TM . decides , in space ( ! ' } 
Proof outline:  (Diagonalization) 
Give TM 0 where 
% 
1) 0 runs in & ! ' 
space 
2) 0 ensures that 1(0) ≠ 1(.) for 
SPACE ! ' 
every TM . that runs in ( ! ' 
space. 
SPACE ( ! ' 
Let % = 1(0). 
8 
","76.66795349121094","2","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_8_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"54","What is the essence of the hierarchy theorems in the context of computational resources?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","74.97608184814453","3","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"54","What is the essence of the hierarchy theorems in the context of computational resources?","[SQUEAKING] [RUSTLING] [CLICKING] MICHAEL SIPSER: Welcome, everyone. Welcome back to theory of computation. And just to recap where we are, we have been looking at time complexity and space complexity. And we just finished proving what are called the hierarchy theorems, which, in a nutshell, basically say that, if you allow the computational model to have a little bit more resource, a little bit more time, a little bit more space, then you can do more things with certain conditions. So we proved that last time. It was a proof, basically, by a diagonalization. I don't know if you recognized the diagonalization there, but when you're encoding a machine by an input and then basically running all possible different machines, that's essentially a diagonalization. So today, we're going to build on that work to give an example of what we call a natural intractable problem. We'll say a bit more about what that means. And then, we're going to talk about something which is a different topic, but nevertheless related, having to do with oracles and methods which may or may not work to solve the P versus NP problem, which, of course, is","74.28633880615234","4","DPRSearchEngine","N32bnUliSzo.en-j3PyPqV-e1s_1_mp4","N32bnUliSzo.en-j3PyPqV-e1s","18.404J","22"
"54","What is the essence of the hierarchy theorems in the context of computational resources?","§ Time based on number of nodes generated 
§ Number of levels is number of items to choose from 
§ Number of nodes at level i is 2i 
§ So, if there are n items the number of nodes is 
◦ ∑𝑖=0↑𝑖=𝑛▒​2↑𝑖   
◦ I.e., O(​2↑𝑛+1 ) 
§ An obvious op<miza<on: don’t explore parts of tree 
that violate constraint (e.g., too many calories) 
◦ Doesn’t change complexity 
§ Does this mean that brute force is never useful? 
◦ Let’s give it a try 
Computa#onal Complexity 
6.0002 LECTURE 2 
8 
","73.96605682373047","5","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_8_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"54","What is the essence of the hierarchy theorems in the context of computational resources?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","73.87974548339844","6","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"54","What is the essence of the hierarchy theorems in the context of computational resources?"," 
 
 
 
  
 
 
  
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Intro to Complexity Theory 
Computability theory (1930s - 1950s): 
Is A decidable? 
Complexity theory (1960s - present): 
Is A decidable with restricted resources? 
(time/memory/…) 
Example: Let ! = a#b# $ ≥0 . 
Q: How many steps are needed to decide !? 
Depends on the input. 
We give an upper bound for all inputs of length '. 
Called “worst-case complexity”. 
2 
","73.1084213256836","7","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_2_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"54","What is the essence of the hierarchy theorems in the context of computational resources?","The Pros and Cons of Greedy 
§ Easy to implement 
§ Computa<onally eﬃcient 
§ But does not always yield the best solu<on 
◦ Don’t even know how good the approxima<on is 
6.0002 LECTURE 2 
3 
Ques<on 1 
","72.96695709228516","8","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_3_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"54","What is the essence of the hierarchy theorems in the context of computational resources?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","72.70296478271484","9","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"54","What is the essence of the hierarchy theorems in the context of computational resources?"," 
 
  
  
 
 
 
 
 
 
 
  
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Review: Major Complexity Classes 
L ⊆ NL ⊆ P ⊆ NP ⊆ PSPACE 
≠ 
Today 
The time and space hierarchy theorems show that 
if a TM is given more time (or space) then it can do more.* 
* certain restrictions apply. 
For example: 
TIME #$ ⊆, TIME #% 
[ ⊆, means proper subset ] 
SPACE #$ ⊆, SPACE #% 
7 
","72.68083953857422","10","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_7_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"55","What is computability theory concerned with?","power of a Turing machine. That's a question that I'm going to postpone to later, because you're asking if a Turing machine can simulate itself. And we'll talk about things like that, but that's in a few weeks from now, so I'll hold off on that one. Decidable languages-- somebody's asking me a good question about closure properties of the class of decidable languages. Are they closed under intersection, union, and so on? Yes. And the decidable languages are also closed under complement. That should be something you should think about. But yes, that is true. The recognizable languages, however, are closed under union and intersection, but they are not closed under complement. So that we will prove on Thursday's lecture. So another question is, could we have just run B on w in this-- in solving this problem, instead of using reduced-- converting it to a new Turing machine-- the B prime? Well, yes, we could have just done that. OK. I think we better move on. I don't want to get too bogged down here-- got a lot of questions there, so sorry if I'm not getting to all of the questions. OK. Or you can write to the TAs too, obviously. I'm sure you are.","74.53401947021484","1","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_7_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"55","What is computability theory concerned with?","§ Problem is exponen<al 
§ Have we overturned the laws of the universe? 
§ Is dynamic programming a miracle? 
§ No, but computa<onal complexity can be subtle 
§ Running <me of fastMaxVal is governed by number of 
dis<nct pairs, <toConsider, avail> 
◦Number of possible values of toConsider bounded 
by len(items)
◦Possible values of avail a bit harder to characterize 
◦Bounded by number of dis<nct sums of weights 
◦Covered in more detail in assigned reading 
How Can This Be? 
6.0002 LECTURE 2 
30 
","74.24101257324219","2","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_30_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"55","What is computability theory concerned with?"," 
 
 
 
 
 
 
 
  
 
 
 
Role of Theory in Computer Science 
1. Applications 
2. Basic Research 
3. Connections to other fields 
4. What is the nature of computation? 
5 
","73.84505462646484","3","DPRSearchEngine","b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1_5_pdf","b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1","18.404J","1"
"55","What is computability theory concerned with?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
18.404/6.840 Lecture 5 
Last time: 
- Context free grammars (CFGs) 
- Context free languages (CFLs) 
- Pushdown automata (PDA) 
- Converting CFGs to PDAs 
Today: (Sipser §2.3, §3.1) 
- Proving languages not Context Free 
- Turing machines 
- T-recognizable and T-decidable languages 
1 
","73.66829681396484","4","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_1_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"55","What is computability theory concerned with?"," 
  
 
  
  
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
18.404 Course Outline 
Computability Theory 1930s – 1950s 
-
What is computable… or not? 
-
Examples: 
program verification, mathematical truth 
-
Models of Computation: 
Finite automata, Turing machines, … 
2 
Complexity Theory 1960s – present 
-
What is computable in practice? 
-
Example: factoring problem 
-
P versus NP problem 
-
Measures of complexity: Time and Space 
-
Models: Probabilistic and Interactive computation 
","73.6528091430664","5","DPRSearchEngine","b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1_2_pdf","b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1","18.404J","1"
"55","What is computability theory concerned with?"," 
 
 
 
  
 
 
  
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Intro to Complexity Theory 
Computability theory (1930s - 1950s): 
Is A decidable? 
Complexity theory (1960s - present): 
Is A decidable with restricted resources? 
(time/memory/…) 
Example: Let ! = a#b# $ ≥0 . 
Q: How many steps are needed to decide !? 
Depends on the input. 
We give an upper bound for all inputs of length '. 
Called “worst-case complexity”. 
2 
","73.3212661743164","6","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_2_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"55","What is computability theory concerned with?"," 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
 
  
 
  
 
 
 
18.404/6.840 Lecture 6 
Last time: 
- Proving languages not Context Free
- Turing machines
- Recognizers and deciders
- T-recognizable and T-decidable languages
Today: (Sipser §3.2 – §3.3) 
- Equivalence of variants of the Turing machine model
a. Multi-tape TMs
b. Nondeterministic TMs
c. Enumerators
- Church-Turing Thesis
- Notation for encodings and TMs
1 
","73.31236267089844","7","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_1_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"55","What is computability theory concerned with?"," 
 
 
 
 
 
 
 
 
  
 
  
 
   
 
 
 
 
  
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Model Dependence 
Number of steps to decide ! = a#b# $ ≥0 depends on the model. 
• 1-tape TM: '() log )) 
• Multi-tape TM: '()) 
Computability theory: model independence (Church-Turing Thesis) 
Therefore model choice doesn’t matter. Mathematically nice. 
Complexity Theory: model dependence 
But dependence is low (polynomial) for reasonable deterministic models. 
We will focus on questions that do not depend on the model choice. 
So… we will continue to use the 1-tape TM as the basic model for complexity. 
6 
","72.97216796875","8","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_6_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"55","What is computability theory concerned with?"," 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Relationships among models 
Informal Defn: Two models of computation are polynomially related 
if each can simulate the other with a polynomial overhead: 
So ! "" time → !$("") time on the other model, for some '. 
All reasonable deterministic models are polynomially related. 
• 1-tape TMs 
• multi-tape TMs 
• multi-dimensional TMs 
• random access machine (RAM) 
• cellular automata 
9 
","72.81057739257812","9","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_9_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"55","What is computability theory concerned with?"," 
 
 
 
 
 
 
 
 
Machine  Learning Paradigm  
§Observe set of examples: training data 
§Infer something about process that generated that 
data 
§Use inference to make predictions about previously 
unseen data: test data 
§Supervised: given a set of feature/label pairs, find a 
rule that predicts the label associated with a previously 
unseen input 
§Unsupervised: given a set of feature vectors (without 
labels) group them into “natural clusters” 
6.0002  LECTURE 12 
3 
","72.42108154296875","10","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_3_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"56","Why is it impossible to determine whether a machine is looping or just taking a long time?","Given a computer program, does it ever halt? Does it ever terminate? This would be a great thing if we knew how to solve. It's basically an infinite loop detector. If your problem doesn't halt, then it has an infinite loop of some sort. And you'd like to tell your user, hey, you have a bug in your program. So this is one part of bug detection. And it's impossible. There is no algorithm that always-- that solves all inputs to this problem. Maybe given one program that, say, has 0 lines of code, it could solve that. It says, yeah, that one terminates. And maybe you can detect simple kinds of infinite loops. So there's some inputs, some computer programs that you could detect. But there's no one algorithm that solves all inputs. This is kind of sad news.","74.22752380371094","1","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_3_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"56","Why is it impossible to determine whether a machine is looping or just taking a long time?","A pretty small number. But the probability of 26 consecutive reds when the previous 25 rolls were red is what? No, that. AUDIENCE: Oh, I thought you meant it had been 26 times again. JOHN GUTTAG: No, if you had 25 reds and then you spun the wheel once more, the probability of it having 26 reds is now 0.5, because these are independent events. Unless of course the wheel is rigged, and we're assuming it's not. People have a hard time accepting this, and I know it seems funny. But I guarantee there will be some point in the next month or so when you will find yourself thinking this way, that something has to even out. I did so badly on the midterm, I will have to do better on the final. That was mean, I'm sorry. All right, speaking of means-- see? Professor Grimson not the only one who can make bad jokes. There is something-- it's not the gambler's fallacy-- that's often confused with it, and that's called regression to the mean. This term was coined in 1885 by Francis Galton in a paper, of which I've shown you a page from it here.","68.98458862304688","2","DPRSearchEngine","OgO1gpXSUzU.en-j3PyPqV-e1s_8_mp4","OgO1gpXSUzU.en-j3PyPqV-e1s","6.0002","6"
"56","Why is it impossible to determine whether a machine is looping or just taking a long time?"," 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
   
 
    
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
Linearly Bounded Automata 
Defn: A linearly bounded automaton (LBA) is a 1-tape TM 
that cannot move its head off the input portion of the tape. 
LBA 
a a b a a b a 
Tape size adjusts to length of input. 
Let !LBA = &, ( LBA & accepts ( } 
Theorem:  !LBA is decidable 
Proof: (idea) If & on ( runs for long, it must be cycling. 
Decider for !LBA: 
Claim: For inputs of length ), an LBA can have 
.A−LBA = “On input &, ( 
only * ×)× Γ - different configurations. 
1.  Let ) = |(|. 
Therefore, if an LBA runs for longer, it must repeat some 
2. Run & on ( for * ×)× Γ - steps. 
configuration and thus will never halt. 
3. If has accepted, accept. 
4. If it has rejected or is still running, reject.” 
must be looping 
7 
","68.75465393066406","3","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_7_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"56","Why is it impossible to determine whether a machine is looping or just taking a long time?","tell if the machine is looping or if it's really just taking a very long time? You can't. That's what we're going to prove not in today's lecture, but going to prove that on Thursday. You just can't tell. So if that's in reference to problem 5, you're going to have to find some other way of doing-- solving that problem without knowing whether the machine is actually ever going to halt.","68.44259643554688","4","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_3_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"56","Why is it impossible to determine whether a machine is looping or just taking a long time?","Many problems of practical importance can be formulated as optimization problems. Greedy algorithms often provide an adequate though often not optimal solution. Even though finding an optimal solution is, in theory, exponentially hard, dynamic programming really often yields great results. It always gives you a correct result and it's sometimes, in fact, most of the times gives it to you very quickly. Finally, in the PowerPoint, you'll find an interesting optimization problem","67.43818664550781","5","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_15_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"56","Why is it impossible to determine whether a machine is looping or just taking a long time?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","67.30109405517578","6","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"56","Why is it impossible to determine whether a machine is looping or just taking a long time?","OK, so today's topic is about self-reference, self-reproducing machines, and the broader topic called the recursion theorem. So let me introduce it with what I would call the self-reproduction paradox. And that is, suppose you have a factory, like a Tesla effect or a car manufacturing factory. See, there's a picture of the factory, and it's producing cars. All right? So we have a factory that makes cars. And what can we say about the relative complexity of the cars compared with the factory, in some informal sense? So I would argue that you would be reasonable to say that the complexity of the factory is going to have to be greater than the complexity of the cars that it makes. Because not only does the factory have to know how to make the cars, so it has to have all the instructions and whatever things that go into a car, it has to be included in at least some kind of-- it has to be, in some sense, represented in the factory. But the factory also has to have other stuff-- the robots, and the other manufacturing items, tools, and so on-- for making the cars. So the factory has to have all the complexity of a car incorporated plus other things as well. And for that reason, one could imagine that the factory's complexity is more than the car's complexity. But now, suppose you want to have a factory that makes factories-- so imagine here's the picture-- or in general, a machine that makes copies of itself. Well, that seems, at first glance, to be impossible. Because not only does the factory obviously have to have all of the instructions for what a factory is like, but it needs to have all of the extra things that it would need to do the manufacturing. And so for that reason, it seems like it's not possible to have a machine make copies of itself. I mean, you would run into the very same problem if I asked you to produce a program in your favorite language that prints out itself-- an exact copy of the same code. You can always write a program which is going to print out some string, like Hello, world. That's easy because you just put Hello, world into some kind of a variable or some sort of a table into the program and say print that table. But if you want the program to print out a copy of itself, you can't take the whole program and stick that into a table because the program is going to have to be bigger than the table. And so, you're going to end up with something impossible happening. Because the program-- an entire copy of the program can't fit inside the program. You just get the program inside itself, inside itself, inside itself, forever. And so, you end up with an infinite program that way. So if you just kind of naively approach the problem for how to make a program which is going to print out a copy of itself, it's not so easy to do. But hopefully, after today's lecture, you will see that it is possible and in fact, how to do it. And not only that is an idle bit of curiosity, but there are actually applications for why you might want to do that, mainly within mathematics and in computer science theory. But there's even a kind of a real-world application, if you will, in a way too. So we'll get to that at the end. So it seems, as I'm saying, impossible to have a self-reproducing machine. But we know that in the world, there are things that make copies of themselves-- living things. So it seems like a paradox. Cells can make copies exactly of themselves. All living things can make copies of themselves. So how do they manage to get around this paradox? Well, in fact, it is no paradox because it is possible to make a machine that self-reproduces, that makes copies of itself. And this has been known for many years. Probably, it goes back to Von Neumann who wrote a famous paper on self-reproducing machines. OK, so self-reproducing machines are, in fact, possible.","66.81692504882812","7","DPRSearchEngine","N-_XmLanPYg.en-j3PyPqV-e1s_2_mp4","N-_XmLanPYg.en-j3PyPqV-e1s","18.404J","11"
"56","Why is it impossible to determine whether a machine is looping or just taking a long time?","Why did Bellman call dynamic programming dynamic programming? Mostly because it sounded cool, and he was trying to impress government agencies giving him grants. I mean, how can you argue with something as cool-sounding as dynamic programming? But there is some logic to it. Programming is a reference to an old form of this word, which means optimization. And generally, we're trying to optimize things. And instead of optimizing according to some static kind of approach or program, we're doing it dynamically. This is a reference to the local brute force we're doing to optimize at each stage. You can't tell, at the top, what you're going to do in the middle. And so it's kind of-- each subproblem is behaving differently. And so, in that sense, dynamic. And it sounds cool. All right. Then we'll go to all-pairs shortest paths. We'll see a new algorithm for that that's not asymptotically any better, but it's nice and simple, and another way to-- a cool way to see subproblem expansion. And then we'll look at a couple of sort of practical problems-- parenthesizing arithmetic expressions and a real-world problem, piano and guitar fingering, so assigning a fingering how to play a piece. And we're going to do that with our SRTBOT framework. Quick recollection of what that is. We define subproblems. And we saw how to do that for sequences. We try either prefixes, suffixes, or substrings. We prefer prefixes and suffixes because there's fewer of them. If there's more than one sequence, we take the product of those spaces. And then the idea we're going to stress today is, we can always add subproblems","66.6675796508789","8","DPRSearchEngine","TDo3r5M1LNo.en-j3PyPqV-e1s_2_mp4","TDo3r5M1LNo.en-j3PyPqV-e1s","6.006","17"
"56","Why is it impossible to determine whether a machine is looping or just taking a long time?","§ Problem is exponen<al 
§ Have we overturned the laws of the universe? 
§ Is dynamic programming a miracle? 
§ No, but computa<onal complexity can be subtle 
§ Running <me of fastMaxVal is governed by number of 
dis<nct pairs, <toConsider, avail> 
◦Number of possible values of toConsider bounded 
by len(items)
◦Possible values of avail a bit harder to characterize 
◦Bounded by number of dis<nct sums of weights 
◦Covered in more detail in assigned reading 
How Can This Be? 
6.0002 LECTURE 2 
30 
","66.33073425292969","9","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_30_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"56","Why is it impossible to determine whether a machine is looping or just taking a long time?"," 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
Modeling the  World  
§Models  always  inaccurate
◦Provide abstractions of reality
§Deterministic models, e.g., graph theoretic
§Statistical models
◦Simulation models: Monte Carlo simulation
◦Models  based on sampling
◦Characterizing accuracy is critical
◦Central limit theorem
◦Empirical rule
◦Machine learning
◦Unsupervised and supervised
§Presentation of data
◦Plotting
◦Good and bad practices
6.0002  LECTURE 15 
21 
","66.30961608886719","10","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_18_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"57","What is the definition of TIME \\( f(n) \\) and how does it relate to deterministic 1-tape Turing Machines?"," 
 
 
 
 
 
 
 
 
  
 
  
 
   
 
 
 
 
  
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Model Dependence 
Number of steps to decide ! = a#b# $ ≥0 depends on the model. 
• 1-tape TM: '() log )) 
• Multi-tape TM: '()) 
Computability theory: model independence (Church-Turing Thesis) 
Therefore model choice doesn’t matter. Mathematically nice. 
Complexity Theory: model dependence 
But dependence is low (polynomial) for reasonable deterministic models. 
We will focus on questions that do not depend on the model choice. 
So… we will continue to use the 1-tape TM as the basic model for complexity. 
6 
","77.60005187988281","1","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_6_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"57","What is the definition of TIME \\( f(n) \\) and how does it relate to deterministic 1-tape Turing Machines?"," 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Relationships among models 
Informal Defn: Two models of computation are polynomially related 
if each can simulate the other with a polynomial overhead: 
So ! "" time → !$("") time on the other model, for some '. 
All reasonable deterministic models are polynomially related. 
• 1-tape TMs 
• multi-tape TMs 
• multi-dimensional TMs 
• random access machine (RAM) 
• cellular automata 
9 
","77.11853790283203","2","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_9_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"57","What is the definition of TIME \\( f(n) \\) and how does it relate to deterministic 1-tape Turing Machines?"," 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
  
 
Nondeterministic Complexity 
In a nondeterministic TM (NTM) decider, all branches halt on all inputs. 
Defn: An NTM runs in time !(#) if all branches halt within !(#) steps 
on all inputs of length #. 
Defn: NTIME ! # 
= {'| some 1-tape NTM decides ' 
and runs in time ( ! # 
} 
Defn: NP = ⋃* NTIME(#*)
= nondeterministic polynomial time decidable languages 
• Invariant for all reasonable nondeterministic models 
• Corresponds roughly to easily verifiable problems 
3 
Computation tree 
for NTM on input +. 
! # 
all branches halt 
within !(#) steps 
. . . 
","77.04893493652344","3","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_3_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"57","What is the definition of TIME \\( f(n) \\) and how does it relate to deterministic 1-tape Turing Machines?","So now, we're going to start defining things with the one tape model in mind. So first of all, if you have a Turing machine, we're going to say it runs in a certain amount of time. So if t is some sort of time bound function, like n squared, or n log n, we'll say the machine runs in that amount of time, like n squared or n log n. if that machine M always halts within that number of steps on all inputs of length n. So it always halts within t of n steps on inputs of length n. Then we'll say that the machine runs in t of n time. So in other words, if the machine runs in n squared time, then the machine, when you give it an input of length 10, it's got to be guaranteed to halt within 100 steps, 10 squared, 100 steps, on every input of length 10. That's what it means for the machine to be running in that much time.","76.59480285644531","4","DPRSearchEngine","asjAc90L8rE.en-j3PyPqV-e1s_6_mp4","asjAc90L8rE.en-j3PyPqV-e1s","18.404J","12"
"57","What is the definition of TIME \\( f(n) \\) and how does it relate to deterministic 1-tape Turing Machines?","n cubed time on a one tape Turing machine, and so on, 2 exponential time, 2 to the n time on a one tape Turing machine. These are all collections of languages getting larger and larger as we increase the bound. So someone is asking kind of-- let's see, let me get to some of these questions here. I'll try to get to them in order. So somebody says if you have-- a good question, if you have a regular computer, so an ordinary sort of random access computer, which we'll talk about that in a second, can do it in order n, can you do it on a multi-tape Turing machine also in order n time? Actually, I don't know the answer to that offhand. I suspect the answer is no. That ordinary computers have a random access capability that Turing machines do not. And so that there are going to be some examples of problems that you can do with a random-- with a regular computer that you cannot do with the multi-tape Turing machine in order n time. I'd have to double check that, though, so we can-- it's also a question what we believe is true and what we can prove to be true. As we'll see, there are a lot of things that we believe to be true in this subject that we don't know how to prove. Somebody is asking kind of an interesting sort of more advanced question. Is there some function f, some function t where it's so big that so that time t of n gives you all of the decidable problems? It would be a very big t. But the answer actually to that question is yes. But that's a little bit exotic. So let's not spend a lot of time on that right here. But happy to talk about that offline. It's a good question here. Somebody's asking me does it mean that there are no languages between order n and order n log n, because I pointed out that anything below n log n is going to be regular. And so, as soon as you get below n log n, you can do it in order n. And yes, there is what's called a gap between order n and order n log n on a one tape Turing machine. You don't get anything new from order n until you jump up. So from order n to order n log log n, nothing new shows up. So we'll talk about those kinds of things a little bit down the road, when we look at actually the relationship among these various classes, and what we call a hierarchy theorem, which shows-- how much bigger do you have to make the bound in order to be sure you'll get something new? All right, somebody's asking is there a model which has the same time complexity as a normal computer? Well, I mean, there's the random access model, which is supposed to capture a normal computer. So let me-- these are all great questions, kind of more riffing off of this into more advanced directions. Let's move on. Here's another check-in. Suppose we take-- this is a little bit of a check to see how well-- how comfortable you are with the notions we've just presented and whether you can think about some of the arguments that we've made and apply them to a new language. So take the language ww reverse, strings followed by their-- followed by themselves backwards. This language B are the even length palindromes, if you will. What's the smallest bound that you need to be able to solve that language B? And I'll pose it as a-- pose that as a question for you. So which time complexity class is that language B in? Is it time order n, order n log n, n squared, so on? What do you think? So we're about to come to the coffee break. So why don't we-- I'll answer any questions that come up. I think we're got everybody answered. So I'm going to end the polling. OK, make sure you're in if you want to be in. So the correct answer is, in fact, order n squared. It would be hard-- reasonable guess here would be order n log n. I mean, you can come up with the same procedure as the one we showed at the beginning, the order n squared procedure for a to the k, b to the k works for ww reverse as well. You can just cross off, sweep back and forth, crossing off a symbol from w, and going across to the other side, crossing off a symbol from w reverse. And that procedure will give you an n squared and order n squared algorithm. You might imagine you can improve it to order n log n. But you cannot. You can prove that order n squared is the best possible. I'm a little unhappy that a lot of you came up with order n, frankly. Because I already told you that order n is-- these are just regular languages. Anything that you can do in less than-- a little o of n log n is going to be regular. And we know this language is not regular. So this was not a good answer. So please pay attention. And OK, so let us stop sharing.","76.04055786132812","5","DPRSearchEngine","asjAc90L8rE.en-j3PyPqV-e1s_8_mp4","asjAc90L8rE.en-j3PyPqV-e1s","18.404J","12"
"57","What is the definition of TIME \\( f(n) \\) and how does it relate to deterministic 1-tape Turing Machines?","of the reasonable models, they're all what are called polynomially related if each can simulate the other with, at most, a polynomial overhead. So if one of the machines can use this t of n time, the other machine that's simulating it would use t to the k of n time for some k. That's what it means for the two machines to be polynomially related. And all reasonable deterministic models are polynomially related. So as we've already seen, one tape and multi-tape Turing machines are polynomially related, because converting multi-tape to one tape blows you up by, at most, squaring. So k equals 2 in this case. Multidimensional Turing machines, again, polynomially related, the random access machine, which I'm not going to define, but it's the machine that you might imagine-- you would, I'm sure they must define in some form in the algorithms classes, polynomially related. Cellular automata, which are just arrays of finite automata that can communicate with each other, similarly. All the reasonable deterministic models, again, classical models, I'm not talking about quantum computing, are polynomially related. So we are-- that kind of justifies our choice in picking one of them, as long as we're going to ask questions which don't depend upon the polynomial.","75.59952545166016","6","DPRSearchEngine","asjAc90L8rE.en-j3PyPqV-e1s_10_mp4","asjAc90L8rE.en-j3PyPqV-e1s","18.404J","12"
"57","What is the definition of TIME \\( f(n) \\) and how does it relate to deterministic 1-tape Turing Machines?","So let's begin, then, by looking at this in more detail and taking as our starting point the theorem that says that on a one tape Turing machine, which is deciding this language A, a to the k, b to the k, you can do this on a one tape Turing machine, M, we're calling it. In at most some constant times n squared steps, for any input of length n, where the constant is going to be fixed independent of it. So this is going to be-- having a constant in-- factor in the complexity is going to come up often. And so instead of saying this over and over again, we're going to use a notation that m uses order n squared steps. I'm sure many of you seen that terminology as well. But just for the purposes of making sure we're all together on that, there is this big O and little o notation. I'm expecting you to be familiar with that. Big O is when you apply to functions, as it's done. You say f is big O of g, as for two functions f and g. It's basically if f is less than or equal to g, if you're ignoring constant factors. And you say f is little o of g if f is strictly less than g if you're ignoring constant factors. That's kind of one sort of informal way of looking at it. The precise definition is given up there on the slide. And if you haven't seen it before, make sure you look at it in the book, where it's all carefully described and defined. So that you're comfortable with these notions. Because it's really-- we're going to be using this without any further discussion from here on.","75.43074035644531","7","DPRSearchEngine","asjAc90L8rE.en-j3PyPqV-e1s_3_mp4","asjAc90L8rE.en-j3PyPqV-e1s","18.404J","12"
"57","What is the definition of TIME \\( f(n) \\) and how does it relate to deterministic 1-tape Turing Machines?","Quick review of today
1. We showed that various TM variants 
(multi-tape, nondeterministic, enumerator) 
are all equivalent to the single-tape model.
2. Concluded that all “reasonable” models with 
unrestricted memory access are equivalent.
3. Discussed the Church-Turing Thesis:
Turing machines are equivalent to “algorithms”.
4. Notation for encoding objects and describing 
TMs.
5. Discussed Pset 2 Problem 5. 
11
","75.3043441772461","8","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_11_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"57","What is the definition of TIME \\( f(n) \\) and how does it relate to deterministic 1-tape Turing Machines?","All right. So let me define a new automaton that we're going to mainly use as just to provide an example for us today. I'm going to call this a linearly bounded automaton. And all it is is a Turing machine where the Turing machine is going to be restricted in where it can-- the tape is not going to be infinite anymore. The tape is just going to be big enough to hold the input. So the machine no longer has the ability to move into the portion of the tape to the right of the input because there is no tape out there. It just has the tape sitting here that contains the input, which the tape itself can vary in size. However big the input is, that's how big the tape is. So the tape adjusts to the length of the input. But once you've started the machine with some particular input, that's as big as the tape is. There's no more. The reason why it's called linearly bounded is because the amount of memory is a linear function of the size of the input because you can effectively get somewhat more memory by enlarging the tape alphabet, but that's going to be fixed for any given machine, so that's where the linearly comes from, if that's helpful. But if you don't get that, it's sort of a side remark. But what's important to me is that you understand what I mean by a Linearly Bounded Automaton, or an LBA. It's just like a Turing machine, but that portion of the tape that originally had blanks is just not there. As the machine tries to move its head off the right end of the input, it just sticks there just as if it tried to move its head off the left end of the input. Doesn't go anywhere. So now, we're going to ask the same kinds of questions about LBAs that we ask for other automa. So the acceptance problem. If I give you an input and some particular LBA and I want to know, does the LBA accept that input? Well, and now the question is, is that the decidable or not? So at first glance, you might think, well, an LBA is like a Turing machine, and the ATM problem is undecidable, so that might be a good first guess. And also, if you try to simulate them, if you try to figure out how you would go about simulating the machine, if given b and w, if you actually tried to simulate the machine to get the answer, so you run b on w, well, of course, if you run it for a while, and it eventually halts, either accepting or rejecting, then you know the answer and you're finished. But this machine might get into a loop. You know, nothing to prevent the machine from looping on that finite amount of-- on that limited amount of tape that it has. And then you might be in trouble. But in fact, that's not the case because when you start out with a limited amount of tape, if you run the machine for a long time and it's not halting, it's going and going and going, inevitably, it's going to have to repeat, get into exactly the same configuration that it did before because there's only a limited number of configurations that the machine has. And once it repeats a configuration, it's going to be repeating that configuration forever, and it's going to be in a loop. So this problem, in fact, is decidable because the idea is if b on w runs for a very long time and an amount that you can calculate, then you know it's got to be cycling. More than just looping. It's got to be repeating itself. And so therefore, once it starts repeating itself, it's going to be going forever. So and here is the actual calculation, which is something I'm sure you could do on your own, but just to spell it out. So if you have an input of length n that you're providing to b, so if w is of length n, the LBA can only go for this number of different-- it can only have this number of different configurations. The number of states times the number of head positions, which is n, the number of head positions on the tape, times the number of different tape contents. If the tape was only one long, this is the-- this is the size of the tape alphabet. So if the tape were two long, the tape had two cells on it, the number of possible tape contents would be the square of the alphabet. And if the tape is going to be n symbols long, it's going to be the tape alphabet size to the nth power. So therefore, if a Turing machine runs for longer, it's got to repeat some configuration, and it'll never hold. So the decider is going to be hopefully clear at this point. You're given b and w, so this is the decider for a LBA. It's going to run b on w for this number of steps. If it's accepted by then, then you accept, and if it hasn't, if it's rejected or it's still running, then you can reject. And you know, if it's still running at this point, it's never going to accept. All right. Any questions on this? OK, let's move on.","75.29806518554688","9","DPRSearchEngine","MGqoLm2aAgc.en-j3PyPqV-e1s_7_mp4","MGqoLm2aAgc.en-j3PyPqV-e1s","18.404J","10"
"57","What is the definition of TIME \\( f(n) \\) and how does it relate to deterministic 1-tape Turing Machines?"," 
 
 
 
  
 
 
  
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Intro to Complexity Theory 
Computability theory (1930s - 1950s): 
Is A decidable? 
Complexity theory (1960s - present): 
Is A decidable with restricted resources? 
(time/memory/…) 
Example: Let ! = a#b# $ ≥0 . 
Q: How many steps are needed to decide !? 
Depends on the input. 
We give an upper bound for all inputs of length '. 
Called “worst-case complexity”. 
2 
","75.29117584228516","10","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_2_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"59","What prevents Savitch's theorem from working with less than log n space?"," 
 
 
  
 
   
   
  
   
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
  
 
   
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
Relationships between 
Time and SPACE Complexity 
Theorem: For ! "" ≥"" 
1) TIME ! "" 
⊆ SPACE ! "" 
2) SPACE ! "" 
⊆ TIME 2& ' ( 
= ⋃+ TIME ,' ( 
Proof: 
1) A TM that runs in !("") steps cannot use more than !("") tape cells. 
2) A TM that uses !("") tape cells cannot use more than ,' ( time 
without repeating a configuration and looping (for some ,). 
Corollary: P ⊆ PSPACE 
Theorem: NP ⊆ PSPACE [next slide] 
3 
","72.57643127441406","1","DPRSearchEngine","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17_3_pdf","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17","18.404J","17"
"59","What prevents Savitch's theorem from working with less than log n space?","Another thing we mentioned kind of quickly in passing, but still an important fact, is that Savitch's theorem works down to the level of log space-- same exact proof. So that means that nondeterministic log space is contained in deterministic log squared space, because that's what Savitch's theorem does for you. It converts nondeterministic machines to deterministic machines at the cost of a squaring in the amount of space you need. And so I'm not going to go through this in detail. But the same picture that I copied off an earlier slide with a simple modification is that instead of-- that I'm right down-- the size of the configuration is going to be now log n, because that's how big the configurations are when you have a nondeterministic log space machine. And so simulating that-- so this would be what the tableau would look like for an NL machine. And then you can simulate that in the same way by trying all possible intermediates and then splitting it, doing the top half and then the bottom half. We're using the space, of course, recursively. The amount of space you're going to need is going to be enough to store, for one level of the recursion, one configuration. And that's order log space. And then the number of levels of recursion is going to be another factor of log n, because that's log to the running time, which is going to be exponential in log n, which is polynomial. So the total amount of space that you would need would be log squared space. Again, this is sort of saying the proof of Savitch's theorem, just over again. So if it's coming too fast for you, just review the proof of Savitch's theorem and observe that it works, even if the amount of space that the machine-- that the nondeterministic machine starts off with is log space. All right.","72.23612976074219","2","DPRSearchEngine","q3xvno_KgRY.en-j3PyPqV-e1s_4_mp4","q3xvno_KgRY.en-j3PyPqV-e1s","18.404J","20"
"59","What prevents Savitch's theorem from working with less than log n space?","Why does Savitch's theorem work for log n? You have to look back and see what you needed. And all you needed to be able to do was to write down the configurations. And if you look back at how Savitch's film works, you're just needing to write down the configuration. So the deterministic machine can write down the configurations for the nondeterministic machine. They take exactly the same size. And then you look at the recursion. And the depth of the recursion is going to be exponential in the size of the configurations. And so you're going to end up with a squaring again. You have to go back and just rethink that proof. And you'll see nowhere did it need a linear amount of space. It works down to-- it actually does not work for less than log n. Log n is sort of the lower threshold there. And the reason for that is because you also need to store the input location, and that already takes log space. The tape heads-- the tape heads already kind have kind of a log space aspect to them. And so if you're going to use less than log space, then funky things happen with storing the tape heads. And so less than log space usually turns out not to be interesting, very specific to Turing machines and not general models. Yeah, so somebody's asking, suppose in the reduction to generalized geography from TQBF, if the formula had two Exists in a row, then you would do kind of the natural thing in the graph. Instead of having that spacer edge between the two diamonds, you could just have one diamond connecting directly to the other diamond without a spacer edge. And that would give you the effect of not switching whose turn it is. Somebody is asking me just a general question, are people thinking about these open problems? I don't know. People don't say. There was a lot of work on problems related, that seemed to be related to those many open questions, like P versus NP, L versus NL or L versus P and so on, P versus PSPACE. We'll talk a little bit more about some of that. There's some very interesting things that have been developed. I think there's a sense within the community that people are stuck, and you're going to need some sort of major new idea in order to push the thing forward. So I don't know how many people are still thinking about them. I hope people are because I would like to see the answer at some point, or get the answer. I think about them sometimes myself, but one has to acknowledge chances of success are not high. So we're a little after past the end of the hour here. Unless there's any other questions, if I didn't answer your question, I may have missed it, so you can ask again. But otherwise, I'm going to close this, close the session here. OK, bye-bye all. Have a good weekend. See you next week. Take care.","71.36032104492188","3","DPRSearchEngine","4dFPVJrNLDs.en-j3PyPqV-e1s_12_mp4","4dFPVJrNLDs.en-j3PyPqV-e1s","18.404J","19"
"59","What prevents Savitch's theorem from working with less than log n space?","0.5 times 0.4. You guys can figure that out. I think that's 0.2. So you'd expect that, that it should be much smaller than either of the first two probabilities. This is the most common rule, it's something we use all the time in probabilities, the so-called multiplicative law. We have to be careful about it, however, in that it only holds if the events are actually","71.20066833496094","4","DPRSearchEngine","-1BnXEwHUok.en-qlPKC2UN_YU_5_mp4","-1BnXEwHUok.en-qlPKC2UN_YU","6.0002","4"
"59","What prevents Savitch's theorem from working with less than log n space?"," 
 
 
  
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
   
 
  
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
  
Log space properties 
Theorem: L ⊆ P 
Proof: Say "" decides # in space $ log ( . 
Defn: A configuration for "" on ) is *, ,-, ,., / where * is a state, 
,- and ,. are the tape head positions, and / is the tape contents. 
The number of such configurations is 0 ×(×$ log ( ×23 456 7 = $((:) for some <. 
Therefore "" runs in polynomial time. 
,­
Conclusion: # ∈ P 
* 
,. 
Theorem: NL ⊆ SPACE log. ( 
/
Proof: Savitch’s theorem works for log space 
7 
","70.99651336669922","5","DPRSearchEngine","fd9c1b8656c7def498dcf662f6750d87_MIT18_404f20_lec19_7_pdf","fd9c1b8656c7def498dcf662f6750d87_MIT18_404f20_lec19","18.404J","19"
"59","What prevents Savitch's theorem from working with less than log n space?"," 
 
 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) 
General Unweighted 
BFS 
|V | + |E|
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Non-negative Dijkstra 
Bellman-Ford 
|V | log |V | + |E|
General Any 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 14: Johnson’s Algorithm 
Lecture 14: Johnson’s Algorithm 
Previously 
|V | · |E| 
All-Pairs Shortest Paths (APSP) 
• Input: directed graph G = (V, E) with weights w : E → Z 
• Output: δ(u, v) for all u, v ∈ V , or abort if G contains negative-weight cycle 
• Useful when understanding whole network, e.g., transportation, circuit layout, supply chains... 
• Just doing a SSSP algorithm |V | times is actually pretty good, since output has size O(|V |2) 
– |V | · O(|V | + |E|) with BFS if weights positive and bounded by O(|V | + |E|) 
– |V | · O(|V | + |E|) with DAG Relaxation if acyclic 
– |V | · O(|V | log |V | + |E|) with Dijkstra if weights non-negative or graph undirected 
– |V | · O(|V | · |E|) with Bellman-Ford (general) 
• Today: Solve APSP in any weighted graph in |V | · O(|V | log |V | + |E|) time 
","70.93382263183594","6","DPRSearchEngine","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14_1_pdf","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14","6.006","14"
"59","What prevents Savitch's theorem from working with less than log n space?","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","70.61580657958984","7","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"59","What prevents Savitch's theorem from working with less than log n space?"," 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
18.404/6.840 Lecture 9 
Last time: 
- !TM is undecidable 
- The diagonalization method 
- !TM is T-unrecognizable 
- The Reducibility Method, preview 
Today: (Sipser §5.1, §5.3) 
- The Reducibility Method for proving undecidability 
and T-unrecognizability. 
- General reducibility 
- Mapping reducibility 
1 
","70.5096206665039","8","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_1_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"59","What prevents Savitch's theorem from working with less than log n space?","A pretty small number. But the probability of 26 consecutive reds when the previous 25 rolls were red is what? No, that. AUDIENCE: Oh, I thought you meant it had been 26 times again. JOHN GUTTAG: No, if you had 25 reds and then you spun the wheel once more, the probability of it having 26 reds is now 0.5, because these are independent events. Unless of course the wheel is rigged, and we're assuming it's not. People have a hard time accepting this, and I know it seems funny. But I guarantee there will be some point in the next month or so when you will find yourself thinking this way, that something has to even out. I did so badly on the midterm, I will have to do better on the final. That was mean, I'm sorry. All right, speaking of means-- see? Professor Grimson not the only one who can make bad jokes. There is something-- it's not the gambler's fallacy-- that's often confused with it, and that's called regression to the mean. This term was coined in 1885 by Francis Galton in a paper, of which I've shown you a page from it here.","70.45315551757812","9","DPRSearchEngine","OgO1gpXSUzU.en-j3PyPqV-e1s_8_mp4","OgO1gpXSUzU.en-j3PyPqV-e1s","6.0002","6"
"59","What prevents Savitch's theorem from working with less than log n space?","So unless, I guess-- or abort if G contains a negative weight cycle. So we're not actually going to worry about negative weight cycles in today's class. If we have a graph, it could have negative weights. These are any integers. It could include negative weight edges. But as long as all of our path distances are bounded from below, none of them are negative infinity, we don't have any negative weight cycles, then I want you to output all of these shortest path distances. Now, in particular, this output could-- any of these outputs needs to have size theta of V squared. Because for every pair of vertices, I need to return to you a number, or infinity, or minus infinity or something like that. But we are not dealing with a case with minus infinity. The output could have size-- this is a theta here. It does have size V squared. But in particular, it's at least V squared because I need to give a number for each pair of vertices. And so we couldn't hope for linear time in the size of this graph for this problem, right? Single source shortest paths, for certain versions of the problem, we need to read the graph. And so we need to use linear time. But in this problem, our output has quadratic size in the number of vertices. So in a sense, we can't do better than this. We can't do better than quadratic. And actually, what's one way we could solve all-pairs shortest paths by using stuff we've already done in this class? That's why I put this slide up here. Yeah, we could just solve a single source shortest paths algorithm from every vertex in my graph. That seems like a stupid thing to do. It's almost brute force on the vertices. But it's certainly a way we could solve this problem, in polynomial time. And we could definitely solve it in order V squared E time, using Bellman-Ford. We just take V steps of Bellman-Ford and deal with a graph on any set of vertices. We can do better than this. We can do better than this for graphs that are special in some way. We can do V times V plus E, V times linear. If our weights are positive and bounded, we can use BFS V times. Or if our graph doesn't have cycles, we could use DAG relaxation V times. Or if our graph had non-negative edge weights, we could get, basically, V squared log V plus V times E. And that's actually not bad. In sparse graphs, this is what Bellman-Ford would give us. But if we had Dijkstra's, for example, if we had all positive edge weights-- or non-negative, sorry, we could get V squared log V plus V, E time. This is V times Dijkstra. OK, so how do these running times compare? This is V times Bellman-Ford. This is V times Dijkstra. Let's just get a feel for this separation here. If we had a sparse graph where V is upper-bounded by the number of vertices, this one looks like V squared log V. This one looks like V cubed. And we need to spend at least V squared time. So actually, this is really close to linear in the size of the graph, just off by a log factor, just like sorting would entail. And this one would have a linear factor. In the sparse graph, this would be a linear factor worse than this, instead of a logarithmic factor-- again, this linear to log separation. We don't want to have to do this running time if we don't have to. That's the name of the game. And really, all we're going to do in this lecture is try to solve how we can make this running time faster by doing something a little bit more intelligent than running a single source shortest path algorithm from every vertex. How are we going to do that? Well, we could-- let's see. What are we doing? Right. The idea here, if we had a graph-- should my graph be directed or undirected? I'm not sure. Let's see if we can make a directed graph. OK, so here's a directed graph. Why do I not care about undirected graphs? Can anyone tell me? Yeah, it's because-- I don't care about undirected graphs because, if I had an undirected graph, I could detect whether I had negative weight cycles in constant time-- I'm sorry, in linear time. I could just check each edge, see if it has negative weight, because a negative weight edge, an undirected edge is a cycle of negative weight. So I could just-- if it has any negative edge weights, I could return in linear time that it does, and I can abort. Or it has only positive weights, and I can still use Dijkstra. So that's all good. So we're only concerned about needing to run Bellman-Ford on directed graphs that potentially have negative edge weight. OK, so here's a graph. Let's see. Is this a graph that I want? Sure. Let's say we've got that direction and this direction. Say we have a directed graph like this. And let's say this is s. This is our source. And we have weights being 2-- sorry, weights being 4, 1, 1, 2, 2, 2, 2. So this is an example of a graph we might want to run all-pairs shortest paths on. Maybe we also have negative weights in this graph. In particular, this has a negative weight cycle. I don't want negative weight cycles, so I'm going to make this 0. So this graph doesn't have negative weight cycles. Great. That's true, great. All right, so here's an example that we might want to compute shortest paths on. There's no s in all-pairs shortest paths. But I'm going to be talking about a couple of shortest paths from s in my next argument, so I'm just labeling that vertex as s. OK, the claim-- the approach we're going to do, we're going to try to take a graph that has negative edge weights, directed graph. We don't know if it has negative cycles or not yet. But we want to compute all-pairs shortest paths, not in this running time, but in this running time. How could we do that? Well, maybe it's possible that we can change the weight of every edge so that they're all positive, but shortest paths are preserved. So basically, if a particular path-- like OK, the shortest path from s to t here is 1, 2, 3. I could change edge weights in this graph. Say, for example, if I changed 1 to 0 here, that would still make this a shortest path. I haven't done-- I've reweighted the graph. Shortest paths have to be the same in this graph. But now-- sorry. Yeah, this is not a shortest path. OK, I'll make that minus 2, and then these both 2, and I think this 4. Man, I really should have done my example beforehand. OK, so this still doesn't have negative weight cycles. It has a negative weight edge. But this path is longer than this path. So when this was 1, this had length of 3, which was shorter than this path. That is length 4. OK, cool. So this is the shortest path from s to t. I could change weights in this graph,","70.4168701171875","10","DPRSearchEngine","EmSmaW-ud6A.en-j3PyPqV-e1s_3_mp4","EmSmaW-ud6A.en-j3PyPqV-e1s","6.006","14"
"60","What is a Generalized Nondeterministic Finite Automaton (GNFA) and how does it differ from a standard NFA in terms of transition labels?","a Generalized Nondeterministic Finite Automaton, or a Generalized NFA, or just simply a GNFA. So this is yet another variant of the finite automaton model. And conceptually, it's very simple. It's similar to the NFAs. I'll give you-- here's a picture of a GNFA named G, G1. Very similar to the NFAs. But if you look at it for a second, you'll see that the transitions have more complicated labels. For the NFAs, we're only allowing just single symbols, or the empty string, to appear on the labels. Now I'm actually allowing you to put full regular expressions on the labels for the automaton. Now, we have to understand how a GNFA processes its input. And the way it works is not complicated to understand. When you're getting an input string feeding-- when a GNFA is processing an input string, it starts at the start state, just like you would imagine. But now, to go along a transition, instead of reading just a single symbol, or the empty string, as in the case for the nondeterministic machine, it actually gets to read a whole string at one step, kind of, at one bite. It can read an entire string and go along that transition arrow, provided that chunk of the input that it read is in the regular expression that that transition has as its label. So for example, this-- you can go from q1 to q2 in one step in this GNFA by reading a, a, b, b off the input. So it reads all of those four symbols all at once. It just swoops them up and then moves from q1 to q2 in one step. And then, when it's in q2 it can read aab and move to q3. And q3 happens, there's nowhere to go. So this is going to be a nondeterministic machine. There might be several different ways of processing the input. And if any one of them gets to an accepting state at the end of the input, we say the GNFA accepts. So it's similar to nondeterministic-- to NFAs in the way the acceptance criterion works. So you could do an example. But hopefully the concept of how this works is reasonably-- you can at least buy it, that it processes the input in chunks at a time. And those chunks have to be described by the regular expressions on the transition arrows, as it moves along those transitions. So what we're going to do now is to convert not DFAs to regular expressions, we're going to convert GNFAs to regular expression. That's even harder, because GNFAs are-- allow you to do all sorts of other things besides just ordinary DFAs. So that's a harder job. Why am I making my life harder? Well, you'll see in a minute that it's going to actually turn out to be helpful to be working with a more powerful model in the way this construction is going to work. Now, before I dive in and do the construction from GNFAs to regular expressions, I'm going to make a simplifying assumption about the GNFAs. I'm going to put them in a special form that's going to make it easier to do the conversion. And that simpler form is, first of all, I'm going to assume the GNFA has just a single accepting state. And that accepting state is not allowed to be the start state. So it has to have just a single accepting state. I've already violated that convenient assumption in this GNFA, because I have here two accepting states. That's not what I want. I want to have just one. Well, the thing is, it's easy to obtain just one, just to modify the machine so that I have just one by adding a new accepting state which is branched to from the former accepting states by empty transitions. So I can always jump from q2 to q4 at any time without even reading any input, just going along this empty transition. And then I declassify the former accepting states as accepting. And now I have here just a single accepting state. And because it's going to be a new state that I added, it won't be the start state. And I have accomplished that one aspect of my assumption about the form of the GNFA. But there's another thing that I want to do, too. I want to assume-- as you will see, which is going to be convenient in my construction-- that we will have transition arrows going from every state to every other state. In fact, I want transition arrows going from every state even back to themselves. I want there to be-- all possible transition arrows should be present, with two exceptions. For the start state, there should be only transition arrows exiting the start state. And for the accepting state-- there's just one now-- there should be only transition arrows coming into the start state. So it's kind of what you would imagine as being reasonable. For the other states, which are not accepting or starting, there should be transition arrows leaving and coming from everywhere else. But for the start states, just leaving. And from the accept state, just coming in. And you could easily modify the machine to achieve that. Let's just see how to do that in one example. So from-- notice that from q3 to q2 there is no transition right now. And that's not good. That's not what I want. I want there to be a transition from q3 to q2. Well, I'll just add that transition in. But I'm going to label it with the empty language regular expression. So that means, yeah, the transition is there, but you never can take it. So it doesn't change the language that the machine is going to be recognizing. But it fulfills my assumption, my convenient assumption, that we have all of these transition arrows being present in the machine. So anyway, I hope you will buy it. It's not going to be-- if you don't quite get this, don't worry. It's not totally critical that you're following all these little adjustments and modifications to the GNFA. But it will be helpful to understand what GNFAs themselves-- how they work. So as I mentioned, we can easily modify","77.08187866210938","1","DPRSearchEngine","KAySmSEGc9U.en-j3PyPqV-e1s_3_mp4","KAySmSEGc9U.en-j3PyPqV-e1s","18.404J","3"
"60","What is a Generalized Nondeterministic Finite Automaton (GNFA) and how does it differ from a standard NFA in terms of transition labels?"," 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Generalized NFA 
Defn: A Generalized Nondeterministic Finite Automaton (GNFA) is 
similar to an NFA, but allows regular expressions as transition labels 
a
a ∗ b ∗ 
ab
!1 
#1 
#2 
For convenience we will assume: 
b 
ε 
- One accept state, separate from the start state 
∅ 
- One arrow from each state to each state, except 
a ∪ b 
aab 
a) only exiting the start state 
#3 
#4 
b) only entering the accept state 
ε 
We can easily modify a GNFA to have this special form. 
3 
","76.94490814208984","2","DPRSearchEngine","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3_3_pdf","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3","18.404J","3"
"60","What is a Generalized Nondeterministic Finite Automaton (GNFA) and how does it differ from a standard NFA in terms of transition labels?"," 
 
 
 
  
 
 
 
 
  
   
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
          
 
 
  
  
   
 
 
 
 
  
 
 
 
  
 
 
Nondeterminism doesn’t
correspond to a physical machine
we can build. However, it is useful
mathematically.
accept
reject
accept
reject
Nondeterministic Finite Automata 
a 
a
!1 
b 
a,ε 
#1
#2 
#3 
#4 
b 
New features of nondeterminism: 
- multiple paths possible (0, 1 or many at each step) 
- ε-transition is a “free” move without reading input 
- Accept input if some path leads to 
accept 
Check-in 2.1 
Example inputs: 
What does !' do on input aab ? 
- ab 
- aa 
(a) Accept 
- aba 
(b) Reject 
- abb 
(c) Both Accept and Reject 
Check-in 2.1 
4 
","76.21490478515625","3","DPRSearchEngine","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_4_pdf","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2","18.404J","2"
"60","What is a Generalized Nondeterministic Finite Automaton (GNFA) and how does it differ from a standard NFA in terms of transition labels?"," 
 
 
 
 
  
 
 
 
 
 
 
  
 
   
 
 
 
 
 
 
    
       
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Nondeterministic Turing machines 
A Nondeterministic TM (NTM) is similar to a Deterministic TM 
except for its transition function !: Q×Γ → '( )×Γ× {L, R} ). 
Theorem: + is T-recognizable iff some NTM recognizes + 
Proof: (→) immediate. 
(←) convert NTM to Deterministic TM. 
Deterministic TM 
NTM 
. 
a a b a ˽ ˽ 
-
02 a a b a # 01 c b # 03 b c b ˽ ˽ 
Nondeterministic computation tree 
- simulates . by storing each thread’s tape in a 
for . on input /. 
separate “block” on its tape. 
Also need to store the head location, 
and the state for each thread, in the block. 
If a thread forks, then - copies the block. 
If a thread accepts then - accepts. 
accept 
4 
. . . 
","73.75114440917969","4","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_4_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"60","What is a Generalized Nondeterministic Finite Automaton (GNFA) and how does it differ from a standard NFA in terms of transition labels?","the acceptance problems for NFAs looked very similar, except B is going to be an NFA. That's going to be a decidable language too. And now we have Turing machine A-- DANFA, the decider for ANFA that decides ANFA. OK? So now, as promised, here's our new form for writing our Turing machine. On input B, w, we're assuming that B-- based on the context, sometimes you may want to say at this point, what B and w are. But from the context, we know what they are. They're going to be an NFA and an input w for that NFA. I do want to jump into the solution. First, before we actually look at the solution of this, we-- the Turing machine could simulate the NFA on input w. And you have to be careful on that simulation that you don't end up looping, because don't forget, an NFA could have epsilon moves, and could be looping on those epsilon moves. And so that would be a problem, if you're not careful about how you do that simulation. Now, I think, if you were going to simulate an NFA, you would be-- wouldn't follow loop around loops forever. And I think you can-- without getting-- because this is not the way I'm going to solve the problem-- you could find a way to avoid getting caught and getting stuck in loops for an NFA. So even though that looks like it could be a problem, in terms of looping forever, it turns out that it won't be a problem-- it wouldn't be a problem if you're careful. But I'm not going to solve it that way anyway, because I'm going to illustrate a different method for solving this problem. And that is we have exhibited before a way of converting NFAs to DFAs. So my Turing machine is going to solve the ANFA problem by converting its input, which is an NFA, to an equivalent DFA. I'm calling the NFA B and the DFA that I got-- converting it into B prime. And what's nice about that is that, first of all, we already know how to do that conversion, because we essentially went over that in lecture a few lectures back, and it's spelled out in full detail in the textbook. So that is a conversion we know how to do-- we'll assume we know how to do. And we can implement that Turing-- that conversion on a Turing machine. Then, once we have the equivalent DFA, what do we do with that? In the previous slide, we showed how to solve the problem for DFAs. So if we can convert the NFA to a DFA, and then we already know how to solve the problem for DFAs, then we're done. So that's how I'm going to say. We're going to convert the NFA to a DFA, and then I'm going to run that DADFA problem on the new machine that I produced. So remember that the-- this machine here decides the ADFA problem. And now I'm going to accept, if that new machine-- if that previous Turing machine accepts the DADFA problem the machine accepts, and I'm going to basically do whatever it does. If it accepts, I'll accept. If it rejects, then I'll reject. So I guess the thing that this illustrates is this idea of using a conversion construction inside a Turing machine, and then a previously constructed Turing machine basically as a subroutine. All this is perfectly legal, and it's the kind of thing we're going to be doing a lot of, and that you should be used to doing that-- get ready to be doing that on your homework too. And in fact, I'll give you another a little extra hint that problem 6 can be solved in this way. OK. All right, so here, let's pause briefly. OK, got some interesting questions here coming up-- somebody asked me, do we need to be explicit about how we're going to simulate that NFA or the DFA? Because we don't know how many states it has. You do know how many states it has. Once it's presented to you on the input, you can see, oh, this is a machine that has 12 states-- because you're given the machine, and then you can do the simulation. Let's see.","72.40489959716797","5","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_6_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"60","What is a Generalized Nondeterministic Finite Automaton (GNFA) and how does it differ from a standard NFA in terms of transition labels?"," 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
   
 
    
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
Linearly Bounded Automata 
Defn: A linearly bounded automaton (LBA) is a 1-tape TM 
that cannot move its head off the input portion of the tape. 
LBA 
a a b a a b a 
Tape size adjusts to length of input. 
Let !LBA = &, ( LBA & accepts ( } 
Theorem:  !LBA is decidable 
Proof: (idea) If & on ( runs for long, it must be cycling. 
Decider for !LBA: 
Claim: For inputs of length ), an LBA can have 
.A−LBA = “On input &, ( 
only * ×)× Γ - different configurations. 
1.  Let ) = |(|. 
Therefore, if an LBA runs for longer, it must repeat some 
2. Run & on ( for * ×)× Γ - steps. 
configuration and thus will never halt. 
3. If has accepted, accept. 
4. If it has rejected or is still running, reject.” 
must be looping 
7 
","72.25357055664062","6","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_7_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"60","What is a Generalized Nondeterministic Finite Automaton (GNFA) and how does it differ from a standard NFA in terms of transition labels?"," 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
   
 
 
 
 
   
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
  
 
 
  
 
  
 
  
Turing machine model – review 
head 
˽ ˽ . . .
a
b
a
b
b
Finite 
read/write input tape 
control 
On input ! a TM "" may halt (enter #acc or #rej) 
) is T-recognizable if ) = +("") for some TM "". 
or loop (run forever). 
) is T-decidable if ) = +("") for some TM decider "". 
So "" has 3 possible outcomes for each input !: 
halts on all inputs 
1. Accept ! (enter #acc ) 
Turing machines model general-purpose computation. 
2. Reject ! by halting (enter #rej ) 
Q: Why pick this model? 
3. Reject ! by looping (running forever) 
A: Choice of model doesn't matter. 
All reasonable models are equivalent in power. 
Virtues of TMs: simplicity, familiarity. 
2 
","72.11194610595703","7","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_2_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"60","What is a Generalized Nondeterministic Finite Automaton (GNFA) and how does it differ from a standard NFA in terms of transition labels?","All right. So let me define a new automaton that we're going to mainly use as just to provide an example for us today. I'm going to call this a linearly bounded automaton. And all it is is a Turing machine where the Turing machine is going to be restricted in where it can-- the tape is not going to be infinite anymore. The tape is just going to be big enough to hold the input. So the machine no longer has the ability to move into the portion of the tape to the right of the input because there is no tape out there. It just has the tape sitting here that contains the input, which the tape itself can vary in size. However big the input is, that's how big the tape is. So the tape adjusts to the length of the input. But once you've started the machine with some particular input, that's as big as the tape is. There's no more. The reason why it's called linearly bounded is because the amount of memory is a linear function of the size of the input because you can effectively get somewhat more memory by enlarging the tape alphabet, but that's going to be fixed for any given machine, so that's where the linearly comes from, if that's helpful. But if you don't get that, it's sort of a side remark. But what's important to me is that you understand what I mean by a Linearly Bounded Automaton, or an LBA. It's just like a Turing machine, but that portion of the tape that originally had blanks is just not there. As the machine tries to move its head off the right end of the input, it just sticks there just as if it tried to move its head off the left end of the input. Doesn't go anywhere. So now, we're going to ask the same kinds of questions about LBAs that we ask for other automa. So the acceptance problem. If I give you an input and some particular LBA and I want to know, does the LBA accept that input? Well, and now the question is, is that the decidable or not? So at first glance, you might think, well, an LBA is like a Turing machine, and the ATM problem is undecidable, so that might be a good first guess. And also, if you try to simulate them, if you try to figure out how you would go about simulating the machine, if given b and w, if you actually tried to simulate the machine to get the answer, so you run b on w, well, of course, if you run it for a while, and it eventually halts, either accepting or rejecting, then you know the answer and you're finished. But this machine might get into a loop. You know, nothing to prevent the machine from looping on that finite amount of-- on that limited amount of tape that it has. And then you might be in trouble. But in fact, that's not the case because when you start out with a limited amount of tape, if you run the machine for a long time and it's not halting, it's going and going and going, inevitably, it's going to have to repeat, get into exactly the same configuration that it did before because there's only a limited number of configurations that the machine has. And once it repeats a configuration, it's going to be repeating that configuration forever, and it's going to be in a loop. So this problem, in fact, is decidable because the idea is if b on w runs for a very long time and an amount that you can calculate, then you know it's got to be cycling. More than just looping. It's got to be repeating itself. And so therefore, once it starts repeating itself, it's going to be going forever. So and here is the actual calculation, which is something I'm sure you could do on your own, but just to spell it out. So if you have an input of length n that you're providing to b, so if w is of length n, the LBA can only go for this number of different-- it can only have this number of different configurations. The number of states times the number of head positions, which is n, the number of head positions on the tape, times the number of different tape contents. If the tape was only one long, this is the-- this is the size of the tape alphabet. So if the tape were two long, the tape had two cells on it, the number of possible tape contents would be the square of the alphabet. And if the tape is going to be n symbols long, it's going to be the tape alphabet size to the nth power. So therefore, if a Turing machine runs for longer, it's got to repeat some configuration, and it'll never hold. So the decider is going to be hopefully clear at this point. You're given b and w, so this is the decider for a LBA. It's going to run b on w for this number of steps. If it's accepted by then, then you accept, and if it hasn't, if it's rejected or it's still running, then you can reject. And you know, if it's still running at this point, it's never going to accept. All right. Any questions on this? OK, let's move on.","71.80567932128906","8","DPRSearchEngine","MGqoLm2aAgc.en-j3PyPqV-e1s_7_mp4","MGqoLm2aAgc.en-j3PyPqV-e1s","18.404J","10"
"60","What is a Generalized Nondeterministic Finite Automaton (GNFA) and how does it differ from a standard NFA in terms of transition labels?"," 
 
 
 
 
 
 
 
  
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
    
   
   
 
  
  
  
 
 
 
 
  
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
a b a a b a a a a b a b
a b a a b a a a a b a b
Problem:  Given !, is there a match?
Theorem:  Undecidable!
Let !1! =
!
! has a match }
Proof: Show 3TM is reducible to !1!.
First: the Computation History Method.
Post Correspondence Problem 
Given a collection of pairs of strings as dominoes: 
! = 
#$ , 
#' , … , #)
%$
%' 
%) 
a match is a finite sequence of dominos in ! (repeats allowed) 
where the concatenation of the *’s = the concatenation of the +’s. 
# 
#, 
#,
,
Match = 
$ 
'
…
-
where *.$*.' ⋯ *.- = +.$+.' ⋯ +.­
%,$ 
%, 
%,
' 
-
ab 
baab 
ba 
abab 
Check-in 10.1 
Example: 
! = 
,
,
,
aba 
aba 
aa 
b 
baab 
ba 
ab
Let !6 = 
,
,
aaba 
ab 
ba 
Does !6 have a match? 
Match: 
• 
(a) Yes. 
(b) No. 
Check-in 10.1 
4 
","71.72985076904297","9","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_4_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"60","What is a Generalized Nondeterministic Finite Automaton (GNFA) and how does it differ from a standard NFA in terms of transition labels?","  
 
  
 
 
  
 
  
 
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
  
 
 
   
-
Review: Probabilistic TMs and BPP 
coin flip step 
each choice has 
Defn: A probabilistic Turing machine (PTM) is a variant of a NTM 
where each computation step has 1 or 2 possible choices. 
deterministic 
step 
50% probability 
Defn: For ! ≥0 say PTM $  decides language % with error probability !  
if for every &, Pr[ $  gives the wrong answer about & ∈% ] ≤! . 
Defn: BPP = % some poly-time PTM decides % with error !  = +⁄,  } Check-in 24.1 
Actually using a probabilistic algorithm 
Amplification lemma: 2−. /01 2 
presupposes a source of randomness. 
Can we use a standard pseudo-random 
number generator (PRG) as the source? 
& ∈% 
& ∉% 
(a) Yes, but the result isn’t guaranteed.
(b) Yes, but it will run in exponential time.
Many 
Few 
Few 
Many 
(c) No, a TM cannot implement a PRG. 
accepting 
rejecting 
accepting 
rejecting 
(d) No, because that would show P = BPP.
2 
Check-in 24.1 
","71.43592834472656","10","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_2_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"61","How does a non-deterministic log space machine compute the complement of the path problem?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","80.49220275878906","1","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"61","How does a non-deterministic log space machine compute the complement of the path problem?","And then we'll stop for a break. Let's look at the complementary problem, HAMPATH complement. You're in the language now if you don't have a path. So is that complementary problem in NP? For that to be the case, we would need to have short certificates of when a graph does not have a Hamiltonian path. I leave it to you. There are three choices. OK? Going to stop here, so make sure you get your participation credit here. I'm going to end the polling now. Interesting. [LAUGHS] So the majority is wrong. Well, not wrong, we don't know. I think the only fair answer to this question is C. Because we don't know whether or not we can give short certificates for a graph not to have a Hamiltonian path. If P equaled NP, then you can test in polynomial time whether a graph has a Hamiltonian path. And then the computation itself would be a certificate, whether it has a path or whether it doesn't have a path. Because it would be something that you can check easily. Since we don't know for sure that P is different from NP, P could be equal to NP, then it's possible that we could give a short certificate. Namely, the computation of the polynomial algorithm. So the only really reasonable answer to this question is that we don't know. Just ponder that. Those of you who answered yes, however, need to go back. And I put this here explicitly because I know this is a confusion for, well I can see, for quite a few of you. When we have non-deterministic computation and you have a non-deterministic machine, you can't simply invert the answer and get back a non-deterministic machine. Non-determinism does not work that way. If you remember, the complement of a pushdown automaton is not a pushdown automaton. If you have a non-deterministic machine and you invert all of the responses on each of the branches, it's not going to be recognizing or deciding the complementary language. I think that this is something you-- if you answered yes, you need to go back and make sure you understand why yes is not a reasonable answer to this question. Because that's not how non-determinism works. So you have a not complete understanding of non-determinism. And that's going to be really important for us going forward. I really urge you to figure out and understand why yes is not a good answer to this check-in.","78.08958435058594","2","DPRSearchEngine","1VhnDdQsELo.en-j3PyPqV-e1s_9_mp4","1VhnDdQsELo.en-j3PyPqV-e1s","18.404J","14"
"61","How does a non-deterministic log space machine compute the complement of the path problem?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","76.93182373046875","3","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"61","How does a non-deterministic log space machine compute the complement of the path problem?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","76.68550109863281","4","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"61","How does a non-deterministic log space machine compute the complement of the path problem?","But I'll get to that point. So let's look at Hamiltonian, the hampath problem. And what I'm going to show is the Hamiltonian path problem is in NP. And I'm going to walk you through this one kind of slowly. So the Hamiltonian path problem, remember, we don't know if it's in P. But it is in NP. So it's in one of these. You can solve Hamiltonian path in polynomial time if you're a non-deterministic machine. Why is that? Well, it's because of the parallelism of non-determinism, which allows you to kind of check all of the paths on different branches. So let me first describe how I would write down the algorithm. And then, we'll kind of try to unpack that and understand how that actually looks in terms of the Turing machine's computation. So first of all, taking the Hamiltonian path problem, you are given an input now, which is a graph and the nodes s and t where I'm trying to figure out is that Hamiltonian path-- again, which visits all the nodes, which takes you from s to t. And we're trying to make now a non-deterministic machine, which is going to accept all such inputs which have a path. So the way this non-deterministic machine is going to work is it's basically going to use its non-determinism to try all possible paths on the different branches. And the way I'll specify that is to say, non-deterministically, we're going to write down a candidate path which is just going to be a sequence of m nodes, where we will say that's the total number of nodes of the graph. Remember, a Hamiltonian path, because it visits every node, is going to be a path with exactly m nodes in it. So I'm going to write down a sequence of nodes as a candidate path. And I'm non-deterministically going to choose every possible sequence in this way. If you'd like to think of the guessing metaphor for non-determinism, you can think of the non-deterministic machine as guessing the right path, which is going to be the Hamiltonian path from s to t. But I think for this discussion, it might be more helpful to think about all of the different branches of the non-determinism. Because that's perhaps more useful when we're thinking about it in terms of the time. I think you'll get used to thinking about it. You should be used to thinking about it in many of the different ways. but maybe the computation tree of all branches might be the more helpful one here. So now after we write down a candidate path sequence of nodes, now I have to check that this really is a path. And the way I'm going to do that is to say, well, now if I have just a sequence of nodes written down, what does it mean for it to be a Hamiltonian path from s to t? Well, it better start with s and end with t, first of all. And we have to make sure that every step of the way is actually an edge. So each pair vi to vi plus 1 has to be an edge in the graph. Otherwise, that sequence of nodes is not going to be a legitimate Hamiltonian path from s to t. And it has to be a simple path. You can't be repeating nodes. These four conditions together will guarantee that we have a Hamiltonian path. And once we have written down a candidate sequence, we can just check that the sequence actually works. At this second stage of the algorithm, non-determinism isn't necessary. This is going to be a deterministic phase. But stage one of the algorithm is going to be a non-deterministic phase where it's writing down all possible paths. Now, I'm going to try to unpack that for you so you can actually visualize how the machine is doing this. And then, of course, you know on each branch of the non-determinism, you're going to check to see whether the conditions have been satisfied. And on that branch, if the conditions were not satisfied, that branch is going to reject. Of course, one of the other branches might yet accept, so that's how non-determinism works. OK? So I'd like to visualize this as the tree of the different branches of the computation of m on its input. So here is our non-deterministic Turing machine. Which? This one. And you provide it with the input G, s, and t. And how is the machine actually working? So when I say non-deterministically write down a sequence of m nodes-- look, this is getting into a little bit more detail than I would normally think about it, because we try to tend to think about things at a higher level. But just to get us started, I think it's good to think about this with a bit more detail. So let's think of the m nodes as being numbered, having labels numbered 1 through m. And I'm going to think about them being labeled by their binary sequences. We're going to write down those nodes. That's how the machine is going to have to operate on those numbers for the nodes. We'll think about them as being written in binary. And now, as the machine is going to be writing down, let's say, the node v1. So it's non-deterministically picking the first node of the sequence. What does that actually mean in terms of the step-by-step processing of the Turing machine m? Well, it's going to be guessing via a sequence of non-deterministic moves, the bits that represent the number of the node for v1. For example, v1 might be the node number 5 in the graph. Of course, non-deterministically, the machine is on different branches, picking all different possible choices for v1. Those are going to be the different branches here. But one of the branches might be-- and what I'm really representing here, these are-- I probably could have written this down on the slide here in tiny font. But these are like the 0, 1 choices. That's why it's sort of a binary tree here for writing down the bits of v1. So here maybe this could be 101, representing the number 5, which might be the very first node that I'm writing down in my sequence. Some other branch is going to write down node number 6. Some other branch is going to write down node number 2. Because non-deterministically, we're making all possible choices for v1. That's what I'm trying to show in this little part of the computation of m on this input. So then, after it's finished writing down the description of the node for its choice for v1, it goes down to choose what v2 is. Again, non-deterministically, so there's going to be more branches for each possible choice of v2. And so on, node after node. Then, it's going to finally get to the last node, vm. It's going to write down lots of choices for vm. And at this point here, we have completed the first stage of the algorithm. Now, there's some huge tree of all of the possible choices for the V's that have shown up at this point. OK? And now, we're going to move into the second phase. So following this, there's going to be, here, a bunch of deterministic steps of the machine. So no more branching is needed because here, we've written down-- at this point, we've reached a point in each of those locations, where we've chosen one of the candidates, one of the possible branches-- one of the possible paths through the graph, I'm sorry. So here, we're guessing potential paths in the graph. And now, we're going to check that we actually have picked a path that's a Hamiltonian path from s to t. OK? So each one of these branches is now going to end up accepting or rejecting. And the whole overall computation is going to accept if at least one of them ended up accepting, which means you actually found a Hamiltonian path. OK? I don't know if that's helpful to you or not, but that is-- if there's any questions on this, let's see. Question on is there something-- trying to draw a connection here between this and computation histories. I mean, there is a pattern here that does come up often where you want to check that something starts right, ends right, and that all of the intermediates are right. So I think there is some deeper connection here. Probably too hard to explain but that has something to do with this Hamiltonian path problem. Why are we using binary representation? Well, we're going to talk about-- the algorithm would have worked equally well if we used base three or base five or base 20 as a way of writing down our labels for the nodes. But in a sense, it doesn't matter. The alphabet has to be finite though, so that's true. I mean, that's why it's not just in a single step of the Turing machine that you would pick the node the choice for v1. You really have to go to a sequence of steps. Because each of the branches of the machine only has a fixed number of choices. So you can't, in a single step of the Turing machine, pick all the different possibilities for v1. That has to go through a sequence. OK. Now, let me do a second example, the problem of composites. So the language of all composites are all of the non-primes, written as binary numbers again. So we'll talk about the base and the representation in a second. But just imagine these are all of the numbers that are not prime. And that language is easily seen to be a member of NP. Here is, again, the algorithm for that. Given x, we want to accept x, if it's not a prime number. So it has some non-trivial factor. So first, the way the non-deterministic machine is going to work is it's going to guess that factor. So non-deterministically, it's going to try every possible factor. Y is going to be a number between 1 and x. But not including 1. You have to be an interesting factor, so not including one in the number itself. So something strictly in between. And we're going to then-- after we've non-deterministically chosen y, then we're going to test to see if y is really a factor. So we'll see if y divides evenly into x with a remainder of 0. If that branch successfully picked the right y, it's going to accept. And some other branch where it might have picked the wrong y, will not. And if x is really a composite number, some branch will find the factor. Now, the base doesn't matter. Could have used base 10, because you can convert from one base to another. So this is really in terms of our representation of the number. But I do want to make one point here, that changing-- we don't want to write the number in unary-- writing the number of k as a sequence of k1s. That's not really a base. That's just an exponential representation for the number and that changes the game. Because if you make the input exponentially larger, then it's going to change whether the algorithm relative to that exponentially larger input is polynomial or not. So an algorithm that might have been exponential originally when the number's written in binary might become polynomial if the numbers are written in unary. And I do want to mention as a side note, that the composites language-- or primes, for that matter-- both are NP. But we won't cover that. So whereas the Hamiltonian path problem is not known whether it's NP, the primes and composites problem are NP. So that was known. That was actually a very big result in the field. Solved by folks at one of the Indian Institute of Technology back about almost 20 years ago now.","76.46287536621094","5","DPRSearchEngine","1VhnDdQsELo.en-j3PyPqV-e1s_6_mp4","1VhnDdQsELo.en-j3PyPqV-e1s","18.404J","14"
"61","How does a non-deterministic log space machine compute the complement of the path problem?"," 
 
 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) 
General Unweighted 
BFS 
|V | + |E|
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Non-negative Dijkstra 
Bellman-Ford 
|V | log |V | + |E|
General Any 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 14: Johnson’s Algorithm 
Lecture 14: Johnson’s Algorithm 
Previously 
|V | · |E| 
All-Pairs Shortest Paths (APSP) 
• Input: directed graph G = (V, E) with weights w : E → Z 
• Output: δ(u, v) for all u, v ∈ V , or abort if G contains negative-weight cycle 
• Useful when understanding whole network, e.g., transportation, circuit layout, supply chains... 
• Just doing a SSSP algorithm |V | times is actually pretty good, since output has size O(|V |2) 
– |V | · O(|V | + |E|) with BFS if weights positive and bounded by O(|V | + |E|) 
– |V | · O(|V | + |E|) with DAG Relaxation if acyclic 
– |V | · O(|V | log |V | + |E|) with Dijkstra if weights non-negative or graph undirected 
– |V | · O(|V | · |E|) with Bellman-Ford (general) 
• Today: Solve APSP in any weighted graph in |V | · O(|V | log |V | + |E|) time 
","75.87713623046875","6","DPRSearchEngine","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14_1_pdf","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14","6.006","14"
"61","How does a non-deterministic log space machine compute the complement of the path problem?","[SQUEAKING][RUSTLING][CLICKING] JASON KU: Welcome, everybody, to our lecture 14 of 6.006. This is our last lecture on graph algorithms, in particular, the last lecture we'll have on weighted shortest paths. But we're going to talk about a slightly different problem today, different than single source shortest paths. We're going to be talking about all-pairs shortest paths. But first, let's review our single source shortest paths algorithms. We had BFS, DAG relaxation, Dijkstra, which we saw last time, which gets pretty close to linear. V log V plus E is pretty close to linear. It's much closer to linear than the general algorithm we have for solving single source shortest paths, namely, Bellman-Ford, which is a little bit more like quadratic. This is like the difference between-- for sparse graphs, this is like the difference between sorting, using insertion sort and n squared, and merge sort in N log N, for example. We're going to get actually quite a big bonus for large input sizes by using Dijkstra when we can. Today, we're going to be focusing","75.34339141845703","7","DPRSearchEngine","EmSmaW-ud6A.en-j3PyPqV-e1s_1_mp4","EmSmaW-ud6A.en-j3PyPqV-e1s","6.006","14"
"61","How does a non-deterministic log space machine compute the complement of the path problem?","we can talk about that more over the break. And so we'll return here in five minutes. Somebody's asking about-- can infinite sequences be generated by the machine. When we're talking about, especially in the complexity section of the course, all of the computations are going to be bounded in time. So we're not going to be thinking about infinite runs of the machine. That's not going to be relevant for us. So let's not think about that. How does a Turing machine perform division? How does a Turing machine perform division? Well, how do you perform division? [LAUGHS] Long division is an operation that can run in-- the long division procedure that you learn in grade school, you can implement that on a Turing machine. Yes, a Turing machine can definitely perform-- do long division, or division of one integer by another in polynomial time. Another question. Can we generally say, try dividing y by x? Or do we have to enumerate a string of length y and cross off every-- no. I think that's the same question. I mean, if you have numbers written in binary, how would you do the division? You're not going to use long division. Anything such as the thing that's proposed here by the questioner is going to be an exponential algorithm. So don't do it that way. Why does primes in P-- composites in P not imply primes in P? It does imply. If composites are in P, then primes is in P as well. When you have a deterministic machine, you can flip the answer. When you have a non-deterministic machine, you may not be able to flip the answer. So deterministic machine just having a single branch, you can make another deterministic machine that runs in the same amount of time that does the complementary language. Because for deterministic machines, just like for deciders in the computability section, you can just invert the answer. There is an analogy here between P and decidability, and NP and recognizability. It's not an airtight analogy here, but there is some relationship there. Somebody's asking me, what are the implications of P equal to NP? Lots of implications. Too long to enumerate now. But, for example, you would be able to break basically all cryptosystems that I'm aware of, if P equal to NP. So we would have a lot of consequences. Somebody's asking, so composites-- primality and compositeness testing is solvable in polynomial time. But factoring, interestingly enough, is not known to be solvable in polynomial time. We may talk about this a little bit toward the end of the term if we have time. The algorithms for testing whether a number is prime or composite in polynomial time do not operate by looking for factors. They operate in an entirely different way, basically by showing that a number is prime or composite by looking at certain properties of that number. But without testing whether it has-- testing, but without finding a factor. Another question here about asking when we talk about encodings, do we have to say how we encode numbers, values? No, we don't have to. We usually don't have to get into spelling out encodings, as long as they're reasonable encodings. So you don't have to usually. We're going to be talking about things at a high enough level that the specific encodings are not going to matter. Let's return to the rest of our lecture.","75.2848129272461","8","DPRSearchEngine","1VhnDdQsELo.en-j3PyPqV-e1s_10_mp4","1VhnDdQsELo.en-j3PyPqV-e1s","18.404J","14"
"61","How does a non-deterministic log space machine compute the complement of the path problem?","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","74.9692611694336","9","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"61","How does a non-deterministic log space machine compute the complement of the path problem?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 16: Dyn. Prog. Subproblems 
Lecture 16: Dyn. Prog. Subproblems 
Dynamic Programming Review 
• Recursion where subproblem dependencies overlap, forming DAG 
• “Recurse but re-use” (Top down: record and lookup subproblem solutions) 
• “Careful brute force” (Bottom up: do each subproblem in order) 
Dynamic Programming Steps (SRT BOT) 
1. Subproblem deﬁnition 
subproblem x 2 X 
• Describe the meaning of a subproblem in words, in terms of parameters 
• Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence 
• Often multiply possible subsets across multiple inputs 
• Often record partial state: add subproblems by incrementing some auxiliary variables 
2. Relate subproblem solutions recursively 
x(i) =  f(x(j), . . .) for one or more j < i  
• Identify a question about a subproblem solution that, if you knew the answer to, reduces 
the subproblem to smaller subproblem(s) 
• Locally brute-force all possible answers to the question 
3. Topological order to argue relation is acyclic and subproblems form a DAG 
4. Base cases 
• State solutions for all (reachable) independent subproblems where relation breaks down 
5. Original problem 
• Show how to compute solution to original problem from solutions to subproblem(s) 
• Possibly use parent pointers to recover actual solution, not just objective function 
6. Time analysis 
P 
• 
x2X work(x), or if work(x) =  O(W) for all x 2 X, then |X| · O(W) 
• work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time 
","74.70574951171875","10","DPRSearchEngine","28461a74f81101874a13d9679a40584d_MIT6_006S20_lec16_1_pdf","28461a74f81101874a13d9679a40584d_MIT6_006S20_lec16","6.006","16"
"63","What is the key concept for understanding NP?","§ Time based on number of nodes generated 
§ Number of levels is number of items to choose from 
§ Number of nodes at level i is 2i 
§ So, if there are n items the number of nodes is 
◦ ∑𝑖=0↑𝑖=𝑛▒​2↑𝑖   
◦ I.e., O(​2↑𝑛+1 ) 
§ An obvious op<miza<on: don’t explore parts of tree 
that violate constraint (e.g., too many calories) 
◦ Doesn’t change complexity 
§ Does this mean that brute force is never useful? 
◦ Let’s give it a try 
Computa#onal Complexity 
6.0002 LECTURE 2 
8 
","71.79647064208984","1","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_8_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"63","What is the key concept for understanding NP?","Quick review of today
1.
NTIME ! ""
and NP
2.
#$%&$'# and  ()%&)*+',* ∈NP
3.
P versus NP question
4.
$CFG ∈P via Dynamic Programming
5.
The Satisfiability Problem *$'
6.
Polynomial time reducibility
13
","70.99225616455078","2","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_13_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"63","What is the key concept for understanding NP?"," 
 
 
 
 
 
 
 
  
 
 
  
  
18.404/6.840 Lecture 15 
Last time: 
- NTIME ! "" , NP 
- P vs NP problem 
- Dynamic Programming, #CFG ∈ P 
- Polynomial-time reducibility 
Today: (Sipser §7.5) 
- NP-completeness 
1 
","70.68585968017578","3","DPRSearchEngine","c1aca7046a69c913721e5eb910a5fb21_MIT18_404f20_lec15_1_pdf","c1aca7046a69c913721e5eb910a5fb21_MIT18_404f20_lec15","18.404J","15"
"63","What is the key concept for understanding NP?"," 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
  
 
Nondeterministic Complexity 
In a nondeterministic TM (NTM) decider, all branches halt on all inputs. 
Defn: An NTM runs in time !(#) if all branches halt within !(#) steps 
on all inputs of length #. 
Defn: NTIME ! # 
= {'| some 1-tape NTM decides ' 
and runs in time ( ! # 
} 
Defn: NP = ⋃* NTIME(#*)
= nondeterministic polynomial time decidable languages 
• Invariant for all reasonable nondeterministic models 
• Corresponds roughly to easily verifiable problems 
3 
Computation tree 
for NTM on input +. 
! # 
all branches halt 
within !(#) steps 
. . . 
","70.57412719726562","4","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_3_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"63","What is the key concept for understanding NP?"," 
  
 
  
  
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
18.404 Course Outline 
Computability Theory 1930s – 1950s 
-
What is computable… or not? 
-
Examples: 
program verification, mathematical truth 
-
Models of Computation: 
Finite automata, Turing machines, … 
2 
Complexity Theory 1960s – present 
-
What is computable in practice? 
-
Example: factoring problem 
-
P versus NP problem 
-
Measures of complexity: Time and Space 
-
Models: Probabilistic and Interactive computation 
","70.13963317871094","5","DPRSearchEngine","b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1_2_pdf","b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1","18.404J","1"
"63","What is the key concept for understanding NP?","If you compare these two classes, P and NP. P, first of all, is going to be a subset of NP, both in terms of the way we defined it because, deterministic machines are a special case of non-deterministic machines. But also if you want to think about testing membership, if you can test membership easily then you can certainly verify it in terms of the certificate. You don't even need it. The certificate is irrelevant at that point. Because whatever the certificate is, you can still test yourself whether the input is in the language or not. The big question, as I mentioned, is whether these two classes are the same. So does being able to verify membership quickly, say with one of these certificates, allow you to dispense with the certificate? Not even need a certificate and just test it for yourself whether you're in the language. And do that in polynomial time. That's the question. For a problem like Hamiltonian path, do you need to search for the answer if you're doing it deterministically? Or can you somehow avoid that and just come up with the answer directly with a polynomial time solution? Nobody knows the answer to that. And it goes back, at this point, quite a long time. It's almost 60 years now. That problem has been around 60 years. No, that would be 50 years. No, 50 years, almost 50 years. Most people believe that P is different from NP. In other words, that there are problems in P-- in NP which are not in P. A candidate would be the Hamiltonian path problem. But it seems to be very hard to prove that. And part of the reason is, how do you prove that a problem like Hamiltonian path does not have a polynomial time algorithm. It's very tricky to do that, because the class of polynomial time algorithms is a very rich class. Polynomial time algorithms are very powerful. And to try to prove-- there's no clever way of solving the Hamiltonian path problem. It just seems to be beyond our present day mathematics. I believe someday somebody's going to solve it. But so far, no one has succeeded. So what I thought we would do is-- I think I have a check-in here.","69.68709564208984","6","DPRSearchEngine","1VhnDdQsELo.en-j3PyPqV-e1s_8_mp4","1VhnDdQsELo.en-j3PyPqV-e1s","18.404J","14"
"63","What is the key concept for understanding NP?"," 
 
  
 
  
 
 
  
 
 
 
 
 
 
 
18.404/6.840 Lecture 22 
Last time: 
- Finished NL = coNL 
- Time and Space Hierarchy Theorems 
Today: (Sipser §9.2) 
- A “natural” intractable problem 
- Oracles and P versus NP 
1 
","69.57048797607422","7","DPRSearchEngine","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_1_pdf","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22","18.404J","22"
"63","What is the key concept for understanding NP?"," 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Turing Machines (TMs) 
head 
˽ ˽
a
b
a 
. . .
b b
Finite 
read/write input tape 
control 
1) Head can read and write 
2) Head is two way (can move left or right) 
3) Tape is infinite (to the right) 
4) Infinitely many blanks “˽“ follow input 
5) Can accept or reject any time (not only at end of input) 
8 
","69.00235748291016","8","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_8_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"63","What is the key concept for understanding NP?"," 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
   
 
 
 
 
   
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
  
 
 
  
 
  
 
  
Turing machine model – review 
head 
˽ ˽ . . .
a
b
a
b
b
Finite 
read/write input tape 
control 
On input ! a TM "" may halt (enter #acc or #rej) 
) is T-recognizable if ) = +("") for some TM "". 
or loop (run forever). 
) is T-decidable if ) = +("") for some TM decider "". 
So "" has 3 possible outcomes for each input !: 
halts on all inputs 
1. Accept ! (enter #acc ) 
Turing machines model general-purpose computation. 
2. Reject ! by halting (enter #rej ) 
Q: Why pick this model? 
3. Reject ! by looping (running forever) 
A: Choice of model doesn't matter. 
All reasonable models are equivalent in power. 
Virtues of TMs: simplicity, familiarity. 
2 
","68.89160919189453","9","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_2_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"63","What is the key concept for understanding NP?","[SQEAKING] [RUSTLING] [CLICKING] MICHAEL SIPSER: Welcome, everyone, back to theory of computation. So we are now at lecture number 15. And this is an important lecture. Well, all of our lectures are important, but this is going to introduce one of the major topics that we're going to see going on in various forms through the rest of the semester, which is the notion of a complete problem. In this case, it's going to be an NP complete problem. And I think some of you have probably heard of that concept already. Maybe you've seen it in some courses or other, but we're going to do that in a rather careful and formal way over the next couple of lectures. So we are following up on our previous discussions about complexity, time complexity. We defined the time and not deterministic time complexity classes, as you may remember, the classes P and NP, talked about the P versus NP problem, looked at some interesting algorithms for showing problems in P called dynamic programming. And we started to move toward our discussion of NP completeness with the introduction of polynomial time reducibility, which is related to some of the earlier reducibility notions that we discussed in the computability section.","68.46513366699219","10","DPRSearchEngine","iZPzBHGDsWI.en-j3PyPqV-e1s_1_mp4","iZPzBHGDsWI.en-j3PyPqV-e1s","18.404J","15"
"64","What are some roles of theory in computer science?"," 
 
 
 
 
 
 
 
  
 
 
 
Role of Theory in Computer Science 
1. Applications 
2. Basic Research 
3. Connections to other fields 
4. What is the nature of computation? 
5 
","79.92557525634766","1","DPRSearchEngine","b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1_5_pdf","b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1","18.404J","1"
"64","What are some roles of theory in computer science?"," 
  
 
  
  
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
18.404 Course Outline 
Computability Theory 1930s – 1950s 
-
What is computable… or not? 
-
Examples: 
program verification, mathematical truth 
-
Models of Computation: 
Finite automata, Turing machines, … 
2 
Complexity Theory 1960s – present 
-
What is computable in practice? 
-
Example: factoring problem 
-
P versus NP problem 
-
Measures of complexity: Time and Space 
-
Models: Probabilistic and Interactive computation 
","74.56877899169922","2","DPRSearchEngine","b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1_2_pdf","b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1","18.404J","1"
"64","What are some roles of theory in computer science?"," 
 
 
 
  
 
 
  
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Intro to Complexity Theory 
Computability theory (1930s - 1950s): 
Is A decidable? 
Complexity theory (1960s - present): 
Is A decidable with restricted resources? 
(time/memory/…) 
Example: Let ! = a#b# $ ≥0 . 
Q: How many steps are needed to decide !? 
Depends on the input. 
We give an upper bound for all inputs of length '. 
Called “worst-case complexity”. 
2 
","73.78138732910156","3","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_2_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"64","What are some roles of theory in computer science?","§ In theory, yes 
§ In prac<ce, no! 
§ Dynamic programming to the rescue 
Is It Hopeless? 
6.0002 LECTURE 2 
14 
","72.45359802246094","4","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_14_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"64","What are some roles of theory in computer science?","Why did Bellman call dynamic programming dynamic programming? Mostly because it sounded cool, and he was trying to impress government agencies giving him grants. I mean, how can you argue with something as cool-sounding as dynamic programming? But there is some logic to it. Programming is a reference to an old form of this word, which means optimization. And generally, we're trying to optimize things. And instead of optimizing according to some static kind of approach or program, we're doing it dynamically. This is a reference to the local brute force we're doing to optimize at each stage. You can't tell, at the top, what you're going to do in the middle. And so it's kind of-- each subproblem is behaving differently. And so, in that sense, dynamic. And it sounds cool. All right. Then we'll go to all-pairs shortest paths. We'll see a new algorithm for that that's not asymptotically any better, but it's nice and simple, and another way to-- a cool way to see subproblem expansion. And then we'll look at a couple of sort of practical problems-- parenthesizing arithmetic expressions and a real-world problem, piano and guitar fingering, so assigning a fingering how to play a piece. And we're going to do that with our SRTBOT framework. Quick recollection of what that is. We define subproblems. And we saw how to do that for sequences. We try either prefixes, suffixes, or substrings. We prefer prefixes and suffixes because there's fewer of them. If there's more than one sequence, we take the product of those spaces. And then the idea we're going to stress today is, we can always add subproblems","72.4496078491211","5","DPRSearchEngine","TDo3r5M1LNo.en-j3PyPqV-e1s_2_mp4","TDo3r5M1LNo.en-j3PyPqV-e1s","6.006","17"
"64","What are some roles of theory in computer science?","Talk about the expectations of the course. First of all, prerequisites. There are a bunch of prerequisites listed, 6.042, 18.062 , or maybe some other subject as well. The real thing is that this is a math class. This is a class where-- and it's not a beginning math class, this is a moderate-to-advanced math class. And I'm expecting people to have had some prior experience, of a substantial nature, with mathematical theorems and proofs. We'll start off slow, but we're going to ramp up pretty fast. So if you haven't really got the idea or gotten comfortable with doing proofs, coming up with proofs to mathematical statements, that's going to be a concern. I would just be monitoring yourself and seeing how you're doing. Because the homeworks and the exams are going to count on your being able to produce proofs, and so you're going to be struggling if that's going to be a real-- something that you haven't had experience with. And let me talk a little bit about the role of theory in computer science. This is a theory class, as you know. So before we jump into the material, I just thought it would be worth it for you to give you at least my perspective on the role of theoretical computer science within the field. So I've been in computer science for a long time. I go back-- I'm sure I'm getting to be a dinosaur here-- but I go back to the days when you had punch cards. That's what we did when I was an undergraduate. And, obviously, things are very different now. And you can argue that computer science as a discipline has matured, and sort of the basic stuff has all been solved. Well, I would say there's a certain truth to that, but there's a certain way in which I would say that's not true. I think we're still at the very beginning, at least in certain respects, of computer science as a discipline. For one thing, there are a lot of things that we do, a lot of things relating to computation, that we just don't know the answer to-- very fundamental things. Let's take as an example, how does the brain work? Obviously, the brain computes in a certain fashion. And we've made good progress, you can argue, with machine learning and all of those things that have very-- very powerful and doing very cool things. But I would also say that at some deeper level, the methods that we have so far don't allow us to understand creativity. We're not close to being able to create a computer program that can do mathematics or that can do many of the creative kinds of things that human beings can do. I think machine learning, powerful as it is, is really successful only for a very narrow set of tasks. And so I think there's probably something deeper and more fundamental going on that we're missing. That would be my hunch. Now, whether something like theoretical computer science is going to give you an answer there-- or this kind of theory, or some kind of theory-- I think some kind of theory has at least a decent shot at playing a role in helping us to understand computation in a deeper way. And the fact that we can't understand something as basic as, can you factor a big number quickly or not? You can't really say you understand computation until you can answer questions like that. So I would argue that we have a really very primitive understanding of computation at this stage and that there is a lot that has yet to be discovered, not just on the technological side, but just on the very fundamental theoretical side that has a real shot at playing a role in affecting the practice of how we use computers. And so I think for that reason-- again, I'm not sure what kind of theory is going to be the most useful, but the theory we're going to cover in this course is a particularly elegant theory, and it has already paid off in many applications and in terms of our understanding of computation. And I think, at least as a starting point, it's a good subject to learn. Certainly, I enjoy it, and I've spent a good chunk of my career doing that.","71.95316314697266","6","DPRSearchEngine","9syvZr-9xwk.en-j3PyPqV-e1s_3_mp4","9syvZr-9xwk.en-j3PyPqV-e1s","18.404J","1"
"64","What are some roles of theory in computer science?","The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation, or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. PROFESSOR: Hello, everybody. Before we start the material, a couple of announcements. As usual, there's some reading assignments, and you might be surprised to see something from Chapter 5 suddenly popping up. But this is my relentless attempt to introduce more Python. We'll see one new concept later today, list comprehension. Today we're going to look at classification. And you remember last, on Monday, we looked at unsupervised learning. Today we're looking at supervised learning. It can usually be divided into two categories. Regression, where you try and predict some real number associated with the feature vector, and this is something we've already done really, back when we looked at curve fitting, linear regression in particular. It was exactly building a model that, given some features, would predict a point. In this case, it was pretty simple. It was given x predict y. You can imagine generalizing that to multi dimensions.","71.28177642822266","7","DPRSearchEngine","eg8DJYwdMyg.en-qlPKC2UN_YU_1_mp4","eg8DJYwdMyg.en-qlPKC2UN_YU","6.0002","13"
"64","What are some roles of theory in computer science?","It's basically-- it's a set type thing, where I can make a set of just a single element, I can take two sets, merge them together, make them their union, and then given an object, I say, which set am I part of, essentially by electing a leader within a set and saying, return me a pointer to that one. And so this can be useful in dynamically maintaining, say, the connected components in a dynamically changing graph supporting the query of, am I in the same component as this other guy? That could be a very useful thing to know about a graph as it's changing. So that's an application of this problem. And they get near-constant performance for a lot of these queries. It's not quite, but pretty close. OK, on the graph side, they solve","71.26305389404297","8","DPRSearchEngine","2NMtS1ecb3o.en-j3PyPqV-e1s_6_mp4","2NMtS1ecb3o.en-j3PyPqV-e1s","6.006","20"
"64","What are some roles of theory in computer science?","The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. JOHN GUTTAG: Welcome to Lecture 6. As usual, I want to start by posting some relevant reading. For those who don't know, this lovely picture is of the Casino at Monte Carlo, and shortly you'll see why we're talking about casinos and gambling today. Not because I want to encourage you to gamble your life savings away. A little history about Monte Carlo simulation, which is the topic of today's lecture. The concept was invented by the Polish American mathematician, Stanislaw Ulam. Probably more well known for his work on thermonuclear weapons than on mathematics, but he did do a lot of very important mathematics earlier in his life. The story here starts that he was ill, recovering from some serious illness, and was home and was bored and was playing a lot of games of solitaire, a game I suspect you've all played. Being a mathematician, he naturally wondered, what's the probability of my winning this stupid game which I keep losing? And so he actually spent quite a lot of time trying to work out the combinatorics, so that he could actually compute the probability. And despite being a really amazing mathematician, he failed. The combinatorics were just too complicated. So he thought, well suppose I just play lots of hands and count the number I win, divide by the number of hands I played. Well then he thought about it and said, well, I've already played a lot of hands and I haven't won yet. So it probably will take me years to play enough hands to actually get a good estimate, and I don't want to do that. So he said, well, suppose instead of playing the game, I just simulate the game on a computer. He had no idea how to use a computer, but he had friends in high places. And actually talked to John von Neumann, who is often viewed as the inventor of the stored program computer. And said, John, could you do this on your fancy new ENIAC machine? And on the lower right here, you'll see a picture of the ENIAC. It was a very large machine. It filled a room. And von Neumann said, sure, we could probably do it in only a few hours of computation. Today we would think of a few microseconds, but those machines were slow. Hence was born Monte Carlo simulation, and then they actually used it in the design of the hydrogen bomb. So it turned out to be not just useful for cards. So what is Monte Carlo simulation? It's a method of estimating the values of an unknown quantity using what is called inferential statistics. And we've been using inferential statistics for the last several lectures. The key concepts-- and I want to be careful about these things will be coming back to them-- are the population. So think of the population as the universe of possible examples. So in the case of solitaire, it's a universe of all possible games of solitaire that you could possibly play. I have no idea how big that is, but it's really big, Then we take that universe, that population, and we sample it by drawing a proper subset. Proper means not the whole thing. Usually more than one sample to be useful. Certainly more than 0. And then we make an inference about the population based upon some set of statistics we do on the sample. So the population is typically a very large set of examples, and the sample is a smaller set of examples. And the key fact that makes them work is that if we choose the sample at random, the sample will tend to exhibit the same properties as the population from which it is drawn. And that's exactly what we did with the random walk, right? There were a very large number of different random walks you could take of say, 10,000 steps. We didn't look at all possible random walks of 10,000 steps. We drew a small sample of, say 100 such walks, computed the mean of those 100, and said, we think that's probably a good expectation of what the mean would be of all the possible walks of 10,000 steps. So we were depending upon this principle. And of course the key fact here is that the sample has to be random. If you start drawing the sample and it's not random, then there's no reason to expect it to have the same properties as that of the population. And we'll go on throughout the term, and talk about the various ways you can get fooled and think of a random sample when exactly you don't. All right, let's look at a very simple example. People like to use flipping coins because coins are easy.","71.20539855957031","9","DPRSearchEngine","OgO1gpXSUzU.en-j3PyPqV-e1s_1_mp4","OgO1gpXSUzU.en-j3PyPqV-e1s","6.0002","6"
"64","What are some roles of theory in computer science?","So let me just tell you what the course is about. Basically, it's going to be in two halves. We're going to be talking about what are the capabilities and limitations of computers-- of computer algorithms, really, computation. And the two parts of the course are more or less divided in half. The first half of the course is going to talk about a subject called computability theory, which it really asks what you can compute with an algorithm in principle. That's-- was an active area of research in the earlier part of the 20th century. It's pretty much closed off as a research subject these days, mainly because they answered all of their big questions. And so a mathematical field really only stays vital when it has problems to solve, and they really solved all of their interesting problems-- for the most part, not 100%. But for the most part, it sort of finished off in the 1950s-- just to say a little bit more about what we're going to talk about there. When you're interested to know what kinds of problems you can solve with an algorithm-- there are problems that you might want to solve that you just can't solve. For example, given a specification for a computer problem you want to solve, whatever that specification might be-- say your algorithm actually is a sorting algorithm, for example-- and you want to write down that specification and have an automatic verifier that's going to check whether a program meets the specification. Well, that's just in principle impossible. You cannot make a verifier which is going to answer, in all cases, whether or not a program meets a certain specification. So with things like that, we will prove this semester. Questions about mathematical truth-- if you're given a mathematical statement, is it true or is it false? It'd be great if you can write a computer program that would answer that problem. Well, it would not be great if you were a mathematician, because that would put us all out of business. But you can imagine that might be a nice thing to have, but you can't. I mean, there is no algorithm which can answer that question. Well, along the way, we're going to introduce models of computation, like finite automata, which we'll see today, Turing machines, and some other models that we'll see along the way. The second half of the course, which is going to be after the midterm, we're going to shift gears and talk about complexity theory, which is instead of looking at what's computable in principle, you're going to look at what's computable in practice, so things that you can solve in a reasonable amount of time. And, for example, I'm sure many of you are aware of the factoring problem, which has connections to the RSA cryptosystem, cryptography, and asks whether you can factor big numbers quickly. That's a problem we don't know the answer to. We just don't know how to factor big numbers quickly. But it's possible that there are algorithms out there that we haven't discovered yet that can do so. It's connected with this very famous problem in the intersection of computer science and mathematics called the P versus NP problem, which many of you may have heard of. We'll talk about that. We'll spend a lot of time on that this term. And along the way, we'll talk about different measures of complexity, of computation, time and space, time and memory, theoretical memory, electrical space. That's going to be a big part of the course in the complexity theory part-- introduce other models of computation,","71.19998931884766","10","DPRSearchEngine","9syvZr-9xwk.en-j3PyPqV-e1s_2_mp4","9syvZr-9xwk.en-j3PyPqV-e1s","18.404J","1"
"65","What does it mean for a language to be T-unrecognizable?","How do we know that Mw halts on w, or whatever? We don't. Mw may not halt on w. We don't care. We're never going to run Mw on anything. We're going to take Mw as a machine, and we're going to feed it into R as a description. We are going to take the description of Mw and feed it into R. Then it's R's problem. But R has been assumed to answer emptiness testing. So we just took the original machine, modified it so that the only possible thing it could accept is w. And now feed it into the emptiness tester to see whether its language is empty or not. Now if its language is not empty, it has to be accepting w because it's built not to accept anything else. So we don't care whether Mw might end up looping. We're never going to run Mw. I acknowledge, it's a leap for many of you. So you're going to have to mull it over. So we're going to use R to test whether Mw's language is empty. If yes, that means that M rejects w. So then we're going to reject, if we know that Mw's language is empty, that must have been that M rejected w. So now as an A TM decider, which is what S is, S is supposed to reject, which is what we have here in the description. And if no, that means the language is not empty. So M accepts w, and so therefore we're accepting. So there's a little bit of a twist here also. OK, so let's take some more. I'm expecting some questions here.","73.96283721923828","1","DPRSearchEngine","N28g_YBXY8Y.en-j3PyPqV-e1s_10_mp4","N28g_YBXY8Y.en-j3PyPqV-e1s","18.404J","9"
"65","What does it mean for a language to be T-unrecognizable?","← 
/ 
 
 
 
  
  
 
 
  
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
  
      
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Proof:  (
) Convert
to equivalent TM
.
/ = for input !:
Simulate ' (on blank input).
Whenever ' prints 0, test 0 = !. 
Accept if = and continue otherwise.
Turing Enumerators 
˽ ˽ 
˽ ˽ 
˽ ˽ ˽ . . . 
Finite 
control 
read/write tape – initially blank 
printer 
Defn: A Turing Enumerator is a deterministic TM with a printer. 
It starts on a blank tape and it can print strings !"" , !$ , !% , … possibly going forever. 
Its language is the set of all strings it prints. It is a generator, not a recognizer. 
For enumerator ' we say ( ' = ! ' prints !}. 
Theorem:  A is T-recognizable iff + = ((') for some T-enumerator '. 
' 
Proof: (→) Convert TM / to equivalent enumerator '.
Check-in 6.1 
' = Simulate / on each !2 in Σ∗ = {6, 0,1,00,01,10, … } 
When converting TM / to enumerator ', 
If / accepts !2 then print !2 .
does ' always print the strings in string order? 
Continue with next !2 .
a) Yes. 
Problem: What if / on !2 loops? 
b) No. 
Fix: Simulate / on !"" , !$ , … , !2 for 9 steps, for 9 = 1,2, … 
Print those !2 which are accepted. 
Image of the printer © Source unknown. All rights reserved. This content is excluded from 
our Creative Commons license. For more information, see https://ocw.mit.edu/fairuse. 
Check-in 6.1 
5 
","73.55044555664062","2","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_5_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"65","What does it mean for a language to be T-unrecognizable?","So E TM is the emptiness problem for Turing machines. Is this language empty? I'm just going to give you a machine. I want to know, is this language empty or not? Does it accept something or is this language empty? That's going to be undecidable, no surprise, proof by contradiction. And we're going to show that A TM is reducible to E TM. So these things often take a very similar form. And I'm going to try to use the same form. So if you're feeling shaky on it, at least you'll get the form of the way the solution goes and that will help you maybe plug-in to solve problems, OK.","72.9238052368164","3","DPRSearchEngine","N28g_YBXY8Y.en-j3PyPqV-e1s_7_mp4","N28g_YBXY8Y.en-j3PyPqV-e1s","18.404J","9"
"65","What does it mean for a language to be T-unrecognizable?","Turing machines, as we set them up, they have-- on any input w, they have three possible outcomes. The Turing machine can halt and accept w, can halt and reject w, or it can go forever on w, which is rejecting by looping in our language. A Turing machine can recognize a language, the collection of old strings that it accepts. And if the Turing machine always halts, we say it decides the language, and it's a decider, and so therefore, that language is a decided language, a Turing decider. Often we just say decidable, because we don't really have a notion of deciding in other models, so we often talk about Turing-recognizable or just decidable. Or we'll sometimes just say recognizable, when we understand that we're talking about Turing machines. We briefly talked about encodings. When you write it inside brackets, some objects-- whatever they are-- could be strings, could be machines, could be graphs, could be polynomials-- we're representing them as strings, and maybe a collection of objects together represented as a string in order so that we can present that information as an input to a machine. And we talk about-- our languages our collections of strings. And a notation for writing a Turing machine is going to be simply that English description put inside quotation marks to represent our informal way of talking about the formal object that we could produce, if we wanted to. But we're never going to ask you to do that. OK, so now let me see. Let's just take a quick break, as I promised. If there's any quick questions here, you can ask. Let's see-- got a lot of questions here. All right, why don't we move on? And some of these things are good questions.","72.42703247070312","4","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_2_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"65","What does it mean for a language to be T-unrecognizable?","  
  
 
 
  
 
  
  
 
   
   
  
 
   
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
!TM is T-unrecognizable 
Recall !TM = { & | & is a TM and ( & = ∅} 
Theorem: !TM is T-unrecognizable 
Proof: Show +TM ≤- !TM 
Reduction function: . &, 0 
= &1 
Recall TM &1 = “On input 3 
1.  If 3 ≠0, reject.
Explanation: 
&, 0 ∈ +TM iff &1 ∈!TM 
2. else run & on 0
& rejects 0 iff ( &1 
= ∅ 
3. Accept if & accepts.” 
+TM 
. 
!TM 
9 
","72.05089569091797","5","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_9_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"65","What does it mean for a language to be T-unrecognizable?","Now, the language of the machine is the collection of all strings that it ever prints out. So we're defining language in a somewhat different way here. It's not the strings that it accepts. It's the strings that it prints. So we think of this machine almost a little bit analogous to the regular expression or the grammar in the sense that it's a generative model. It produces the language rather than accepts the strings in the language. It's not really a recognizer. It's a generator. And the language of the machine, as writing over here, for an enumerator here, we say its language is a collection of strings that it prints. Now we will show that a language is Turing recognizable in the previous sense recognized by some ordinary Turing machine if and only if it's the language of some enumerator. And actually this is kind of a little bit of an interesting proof. You have to do some work. It's an if only if. Now neither direction is immediate. You're going to have to do some work in both directions. One direction is a little harder than the other. We'll start off with the easier direction. Let's say we have an enumerator. Hopefully you got this concept of this Turing machine which periodically prints strings when you started it off on the empty tape. So now what I'm going to construct for you is that Turing machine recognizer defined from the enumerator. So this recognizer is going to be simulating the enumerator. So basically that recognizer is going to launch the enumerator. It's going to start off simulating it. Now, if you want, if it's convenient, we could use several tapes. We can use one tape to simulate the recognizer and you have other tapes available for convenience if you want, because we already showed multi-tape and single tape are equivalent. So if you want, you can think of M as having multiple tapes. It's not going to really be that relevant to my conversation. But you're going to simulate E starting on the blank input, as you're supposed to. And then you're going to see whenever E prints in x, you're going to see if x is the same as the input to the recognizer. You get the idea? So we have a recognizer. It has an input string, maybe like 1, 1, 0, 1. And I want to know. I want to accept that string if it's one of the strings that the enumerator E prints out, because that's what the recognizer do. It's supposed to accept all the strings that the enumerator prints out. So I got this 1, 1, 0, 1. What do I do? I fire up that numerator, I get it going, and I start watching the strings it prints out, comparing them with my input string, 1, 1, 0, 1. If I ever see it print out a 1, 1, 0, 1, great. I know I can accept, because I know it's in the enumerator's language. But if I compare and compare and compare, I never see the enumerator ever printing out my input string 1, 1, 0, 1. Well, I just keep simulating. If E halts, well then I can halt and reject if I've never seen that string coming out as an output. If E doesn't halt, well, I'm just not going to halt either. I'm going to go forever. But then I'm going to be rejecting my input by looping. So that's the proof of converting in this backward direction, which is the easier direction. Now let's look at the forward direction, which has a certain wrinkle in it that we're going to have to get to. So now we're going to be building our enumerator to simulate our recognizer. And the way we'll do that is the enumerator has to print out all of the strings that the recognizer would ever accept. So you kind of do the obvious thing. You're going to take-- the enumerator is going to start simulating the recognizer M on all possible strings. Sort of one by one, doing them in parallel, taking turns. Maybe we didn't make this so explicit. But you can sort of timeshare among several different possibilities. Sort of like having different blocks for the machine. The enumerator is going to run the recognizer on-- well, let's just say it does it sequentially. It runs it on the empty string. It runs it on the string 0. It runs it on the string one. Runs it on the string 0, 0. These are all the possible strings of sigma star. You run on all of them. And whenever the enumerator-- uh oh. This is wrong. So whenever M accepts, then print-- I can't write very well. Print w, wi. Oops. OK. So I'm going to just say it in words. I'm want to simulate M on each wi. Whenever you notice M accepting wi, you just print out wi. Because you want to print out all of the strings that M accepts. Now, there is a problem here. So hopefully you're not confused by this typo. Doing it sequentially like I just described doesn't quite work. So let me just back that up here. Doing it sequentially doesn't quite work, because M might get stuck looping on one of the wi's. Like maybe when I feed 0 into M, M goes forever. Because M is rejecting 0 by looping. But maybe it also accepts this next string in the list, the string one. I'll never get to one by just feeding the strings into M one by one like this. What I really have to do is run all of the strings in M in parallel. And the way I'm going to indicate that is I want to simulate M on w1 to wi for i steps for each possible i. So I'm going to run M on more and more strings for more and more steps. And every time I notice that M accepts something, I print it out. So I will fix this in the version of the file that I publish on the website. So if you're still not getting it, you can look there. But just to make things even worse, I have a check in, which is going to be about this one little point here. So I got a question. Where do we get the wi strings? The wi strings are simply the list of all strings in sigma star. So under program control, we can make M go through every possible string. Like if you had an odometer, you're going to first get to the empty string. Then you go to the string 0, then the string one. You can write a program which is going to do that. And the Turing machine can similarly write code to do that, to get to each possible string one by one. And then that's what the enumerator is doing. It's obtaining each of those strings and then feeding them into M, seeing what M does. What I'm trying to get at here is that it's not good to feed them in, run M to completion on each one before going to the next one. You really kind of have to do them all in parallel to avoid the problem of getting stuck on one string that M is looping on. All right. So this is relevant to your homework, in fact. If I convert em to an enumerator in this way, does that enumerator always print the strings out in string order. String order is this order here. Having the shorter strings coming up before the longer strings and within strings of a certain length, just doing them in lexicographical order. So hopefully you follow that. But since these are not correct, this doesn't matter for us. Let me launch that poll. I'll see how random the answer is here. So a fair amount of confusion. If you're confused, obviously you're in good company there. About to shut this down. Five seconds to go. OK, ending it now. All right. So the correct answer, as the majority of you did get, is in fact that the order is not going to be respected here when E prints things out. It might print out some things later in the order before earlier things in the order. What's going to control when E is going to print it out? If M accepts some strings more quickly in fewer steps, then E might end up printing out that string earlier in the list than some other string that might be a shorter string. Because the order in which E is going to now identify that M is accepting those strings depends upon the speed with which M is actually doing the accepting. So this is relevant to one of your homeworks, because what you're going to have to show is that if you start with a decidable language instead of a recognizable language, then you can make an enumerator, which always prints out things in order, in the string order. And vice versa. And if you have an enumerator which prints that things out in string order, then the language is decidable. So need to think about that. One direction is a fairly simple modification of what I just showed. The other direction is a little bit of more work.","71.51966857910156","6","DPRSearchEngine","TTArY7ojshU.en-j3PyPqV-e1s_5_mp4","TTArY7ojshU.en-j3PyPqV-e1s","18.404J","6"
"65","What does it mean for a language to be T-unrecognizable?","if an English description is possible for a Turing machine? Well, you can always write down an English description for any machine. It's-- might be very technical looking, but if you can write it down in a formal way as states and transitions, then you can simply write down an English description, which would just be, follow those states. OK, let's move on. OK, this is going to be our first example of a algorithm that's going to answer a question about automata. And it's a very simple problem. It's a very simple problem to solve, because we want to start out easy. The name of the problem is the acceptance problem for deterministic finite automata, acceptance problem for DFAs. And I'm going to express it, as I always do, as a language.","71.50175476074219","7","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_4_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"65","What does it mean for a language to be T-unrecognizable?","we did with Turing machines. And just want to make sure we're all together on that. It's a very important concept for us this term. So the Turing machine model looks like there's going to be this finite control. There's a tape with a head that can read and write on the tape, can move in both directions. The tape is infinite to one side and so on, as I mentioned last time. The output of the Turing machine is either going to be a halt, accepting or rejecting, or loop that the machine may run forever. With three possible outcomes for any particular input. The machine may accept that input by entering q accept. May halt and reject by entering q reject. And it might reject by looping, which means it just never gets to the accept state or it never gets any halting state. It just goes forever. But we still consider that to be rejecting the input, just it's rejecting by looping. And as we defined last time, a language is Turing recognizable, or as we typically write, T recognizable, if it's the language of some Turing machine, the collection of accepted strings from that Turing machine. Again, just as before, the machine may accept 0 strings, one string, many strings, but it always has one language, the collection of all accepted strings. Now, if you have a decider, which is a machine that never loops, which always halts on every input, then we say its language is a decidable language. So we'll say a language is Turing decidable or simply decidable if it's the language of some decider, which is a Turing machine that always halts on all inputs. So we have those two distinct notions, Turing recognizable languages and Turning decidable languages. Now, as we're going to argue this lecture, Turing machines are going to be our model of a general purpose computer. So that's the way we're going to think of computers as Turing machines. And why Turing machines? Why didn't we pick something else? Well, the fact is, it doesn't matter. And that's going to be the point of this lecture. All reasonable models of general purpose computation, unrestricted computation in the sense of not limited memory, are all going to be-- all have been shown, all the models that we've ever encountered have all been shown to be equivalent to one another. And so you're free to pick any one you like. And so for this course, we're going to pick Turing machines because they're very simple to argue about mathematically, and also they have some element of familiarity in that they feel like-- well, they're more familiar than some of the other models that have been proposed that are out there, such as rewriting systems, lambda calculus, and so on. Turing machines feel like a primitive kind of computer. And in that sense, they have a certain familiarity. OK, so let's start talking about variations on the Turing machine model. And we're going to argue that it doesn't make any difference. And then this is going to be kind of a precursor to a discussion of a bit of the history of the subject that we're gonna get to in the second half of the lecture. So a multi-tape Turing machine is a Turing machine, as you might imagine, that has more than one-- well, has one or possibly more tapes. And so a single tape Turing machine would be a special version of a multi-tape Turing machine. That's OK. But you might have more than one tape, as I've shown in this diagram. Now, how do we actually use a multi-tape Turing machine? Well, you present the-- and we're going to see these coming up for convenience. Sometimes it's nice to be working with multiple tapes. So we're going to see these later on in the semester a couple of times as well. But for now, we're setting the model up so that the input is going to be presented on a special input tape. So that's where the input appears, and it's going to be followed by blanks, just as we had before. And now we have these potentially other tapes, possibly other tapes, which we call them work tapes where the machine can write other stuff as it wishes. And those tapes are going to be initially blank. So just all blanks on them. All of the tapes are going to be read and write. So you can write on the input tape. Obviously you can read off on the input tape, and you can read and write on the other tapes as well. So what we want to first establish that by having these additional tapes, you don't get additional power for the machine in the sense that you're not going to have-- you won't have additional languages that you can recognize by virtue of having these additional tapes. I mean, you can imagine that having more tapes will allow you to do more things. For example, if you have a pushdown automaton with two stacks, you can do more languages than you can with one stack. So it's conceivable that by having more tapes, you can do more languages than you could with one tape. But in fact, that's not the case. One tape is as good as having many tapes. And we're going to prove that. We're going to quickly sketch through the proof of that fact. So the theorem is that a language is Turing recognizable. And when we say Turing recognizable, for now we mean just with one tape. So that's the way we've defined it. So a language is Turing recognizable if and only if some multi-tape Turing machine recognizes that language. So really another way of saying that is if you have a language that you can do with a single tape, you can do it with a multi-tape and vice versa. So one direction of that is immediate, because a single tape Turing machine is already a multi-tape Turing machine that just so happens to have one tape. So the forward direction of that is-- there's nothing to say. That's just immediately true. But if we want to prove the reverse, then we're going to have to do some work. And the work is going to be showing how do you convert a multi-tape Turing machine to a single tape Turing machine. So if we have something that's recognized by a multi-tape Turing machine, it's still Turing recognizable. And what that means is that you can do it with a single tape Turing machine. So we have to show how to do the conversion. And I'll show you that I think in a convincing way but without getting into too much detail. So here is an image of a multi-tape Turing machine during the course of its input. So we've already started it off. Initially it starts off with the other tapes, the work tapes being all blank. But now it's processed for a while and the head on the input tape now has moved off from its starting position at the left end. It's somewhere in the middle. It's written stuff on the other tapes. And what we want to do is show how to represent that same information on a single tape Turing machine in a way which allows the single tape Turing machine to carry out the steps of the multi-tape Turing machine but using only a single tape by virtue of some kind of a data structure which allows for the simulation to go forward. So how is the single tape Turing machine going to be simulating, going to be carrying out the same effect of having these multiple tapes on the multi-tape Turing machine? So here's a picture of the single tape Turing machine. It just has one tape. By the way, I should mention that all of the tapes are infinite to the right in the multi-tape Turing machine, just as we had for the single tape Turing machine. And now with this single tape Turing machine, it's going to represent the information that's present on these multiple tapes but using only the single tape. And the way I'm choosing to do that is going to be particularly simple. I'm going to just divide up, so here I'm saying it in words. It's going to simulate m by storing the contents of the multi-tape on the single tape in separate blocks. So I'm basically going to divide up the single tape Turing machines tape into separate regions where each one of those regions is going to have the information that was on one of the tapes in the multi-tape machine. So for example, on the first tape it's got a, a, b, a. Well, that's going to appear here in that first block on the single tape Turing machine. Sort of seeing it float down to suggest that it's coming from this multi-tape Turing machine. But that's really been developed by the simulation that the single tape Turing machine has. Obviously the single tape Turing machine doesn't have any direct access to the multi-tape machine. But it's going to be simulating. So this is how we're showing the data is being stored on the single tape machines tape. So in the second block, it's going to have the contents of the second tape of the Turing multi-tape machine. And the final region of the single tapes, the final block so-called of the single tape's tape is going to have-- the single tape machine's tape-- it's going to have the rest of the contents of the last tape of m. And then it's going to be followed by the same infinitely many blanks that each of these tapes are going to have following the portion that they may have written during the course of their computation. So that's what the single tape Turing machine's tape is going to look like during the course of its computation. It's going to have the information represented in these blocks. Capturing all of the information that the multi-tape Turing machine has in a perhaps somewhat less convenient way, because the multi-tape Turing machine, we didn't really make this explicit. And in part because it doesn't really matter, we didn't say exactly how the multi tape machine operates. What I have in mind is that the multi-tape Turing machine can read and move all of its heads from all of its heads in one step. So in a single step of the multi-tape machine, it can obtain the information that's underneath each of its heads, feed that in through its transition function, and then together with the state of the multi-tape machine decide how to change each of those locations and then how to move each one of those heads. So it's kind of operating on all of the tapes in parallel. So now how does the actual steps of the simulation of the single tape-- by the single tape machine, how does it go? So first of all, besides storing the contents of each of the tapes in S's single tape, there's some additional information that it needs to record. Namely, M has a head for each one of its tapes. But S has just a single head. And each of M's heads could be in some different location. In this case, as I've shown it, on the first tape, its head is in location three. On the second tape, it's in location two. On the third tape, it's on location-- on the last tape, it's in location one. So where were we? We were simulating the multi-tape Turing machine with the single tape Turing machine. And we had to keep track of where the heads are. And so we're going to do that by writing the locations on those blocks. So we're going to have a special dot, as I've shown here, to represent the location of the head in that very first block. So the head's on the b. I'm going to dot the b. And I'm going to do the same thing for the locations of the other heads. And how am I getting that effect? Well, we've seen something like that before, where we just expand the tape alphabet of S to allow for these dotted symbols as well as the irregular symbols. We also have expanded it to include the delimiter markers that separate the blocks from one another, which I'm writing as a pound sign. So we can just get that effect simply by expanding the tape alphabet of S. A few more details of S that are just worth looking at, just to make sure we're kind of all understanding what's happening. So for every time M takes one step, S has actually a lot of work to do. Because one step of M can read and move all of those heads all at one shot. S has to scan the entire tape to see what's underneath those in effect virtual heads, which are the locations of the dotted symbols. It has to see what's underneath each one of those heads to see how to update its state to the next state. And then it has to scan again to change the location, change the contents of those tape locations, and also to move the head left or right by effectively now moving the dot left or right. So that's pretty straightforward. There's one complication that can occur, however, which is that what happens if on one of the tapes, let's say, M starts writing more content than you have room in that block to store that information? So if M, it has 1, 0, 1, suppose M after a few steps moves its head into the originally blank portion of the tape and writes another symbol there. We have to put that symbol somewhere, because we have to record all that information. And the block is full. So what do we do? Well, in that case, S goes to a little interrupt routine and moves, shifts all of the symbols to the right one place to open up a location here where it can write a new symbol for continuing the simulation. So with that in mind, S can maintain the current contents of each of of M's tapes. And let me just note that here. Shift to add room is needed. And that's all that happens during the course of the simulation. And of course, if S as it's simulating M observes that M comes to an accept or reject state, S should do the same. So that's our description of how the single tape","71.32042694091797","8","DPRSearchEngine","TTArY7ojshU.en-j3PyPqV-e1s_2_mp4","TTArY7ojshU.en-j3PyPqV-e1s","18.404J","6"
"65","What does it mean for a language to be T-unrecognizable?","that E TM is decidable, opposite of what we've been trying to show. And then show that A TM is decidable, which you know is false. So we'll say we have a decider for A TM, R, using the same letters on purpose here just to try to get the pattern for you, so R deciding E TM. Construct S deciding A TM, OK. So now, let's think about it together for a minute before I just put it up there. So S, I'm trying to make a decider for A TM, using my decider for the emptiness problem, OK? So we have R, which can tell us whether M's language is empty. So why don't we just, I don't know, stick M into that emptiness tester and see what it says? I'm not saying this is the solution, but this is how one might think about coming up with the solution. So are you with me? We're going to take M, we have an emptiness tester. Let's take M and plug it into R, see what R says. R is going to come back and tell us whether M's language is empty or not. Now, one of those answers will make us happy. Why? Suppose R tells us that M's language is empty. Why is that good? With that, we're done. Because S is trying to figure out, we're trying to figure out exactly, somebody told me the answer which is correct. Because now we can reject. If M's language is empty, it's clearly not accepting w because it's not accepting anything. So if R says M's language is empty, then we're good. The only problem is we also say M's language is not empty. And then what do we know? Well, not much, not much that's useful for testing whether M accepts w. We just know M accepts something. But that something may or may not be w. OK, so what do we do? Well, the problem is that M is possibly accepting all sorts of strings besides w, which are kind of mucking up the works. They're interfering with the solution that we like. We'd like to be able to use R on M to tell us whether M is accepting w. But M is accepting other things. And that's making the picture complicated. So what I propose we do, why don't we modify M so that it never accepts anything besides w? The very first thing M does in the modified form is it looks at its input and sees whether it's different from w. If it's different from w, it immediately rejects.","70.92015075683594","9","DPRSearchEngine","N28g_YBXY8Y.en-j3PyPqV-e1s_8_mp4","N28g_YBXY8Y.en-j3PyPqV-e1s","18.404J","9"
"65","What does it mean for a language to be T-unrecognizable?","So there's a lot of variations on the basics sorting problem and the different algorithms that are out there. Two vocabulary words are going to highlight really quick-- one is if your sort is destructive, what that means is that rather than reserving some new memory for my sorted array B and then putting a sorted version of A into B, a destructive algorithm is one that just overwrites A with a sorted version of A. Certainly the C++ interface does this. I assume the Python one does, too. I always forget this detail. In addition to destructive sorts, some sorts are in place, meaning that not only are they destructive, but they also don't use extra memory in the process of sorting. Really, you could imagine a sorting algorithm that has to reserve a bunch of scratch space to do its work, and then put it back into A. For instance, the world's dumbest destructive sort might be to call your non-destructive and then copy it back into A. But that would require order n space to do. So if my algorithm additionally has the property that it doesn't reserve any extra space, at least up to a constant, then we call that in place. OK. So those are our basic vocabulary words. And they're ways to understand the differences between different sorting algorithms. Yes? AUDIENCE: [INAUDIBLE] JUSTIN: Why do they end up using extra O(1) space? Oh yeah, sure. Any time I just make a temporary variable like a loop counter, that's going to count toward that order 1. But the important thing is that the number of variables I need","70.66156768798828","10","DPRSearchEngine","oS9aPzUNG-s.en-j3PyPqV-e1s_13_mp4","oS9aPzUNG-s.en-j3PyPqV-e1s","6.006","3"
"68","How does the satisfiability problem relate to P and NP, and why is it significant in computational complexity theory?"," 
 
 
 
  
 
 
  
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Intro to Complexity Theory 
Computability theory (1930s - 1950s): 
Is A decidable? 
Complexity theory (1960s - present): 
Is A decidable with restricted resources? 
(time/memory/…) 
Example: Let ! = a#b# $ ≥0 . 
Q: How many steps are needed to decide !? 
Depends on the input. 
We give an upper bound for all inputs of length '. 
Called “worst-case complexity”. 
2 
","74.98139190673828","1","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_2_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"68","How does the satisfiability problem relate to P and NP, and why is it significant in computational complexity theory?","What are oracles? Oracles are a simple thing. But they are a useful concept for a number of reasons. Especially because they're going to tell us something interesting about methods, which may or may not be useful for proving the P versus NP question, when someday somebody hopefully does that. What is an oracle? An oracle is free information you're going to give to a Turing machine, which might affect the difficulty of solving problems. And the way we're going to represent that free information is, we're going to allow the Turing machine to test membership in some specified language, without charging for the work involved. I'm going to allow you have any language at all, some language A. And say a Turing machine with an oracle for A is written this way, M with a superscript A. It's a machine that has a black box that can answer questions. Is some string, which the machine can choose, in A or not? And it gets that answer in one step, effectively for free. So you can imagine, depending upon the language that you're providing to the machine, that may or may not be useful. For example, suppose I give you an oracle for the SAT language. That can be very useful. It could be very useful for deciding SAT, for example. Because now you don't have to go through a brute force search to solve SAT. You just ask the oracle. And the oracle is going to say, yes it's satisfiable, or no it's not satisfiable. But you can use that to solve other languages too, quickly. Because anything that you can do in NP, you can reduce to SAT. So you can convert it to a SAT question, which you can then ship up to the oracle, and the oracle is going to tell you the answer. The word ""oracle"" already sort of conveys something magical. We're not really going to be concerned with the operation of the oracle, so don't ask me how does the oracle work, or what does it correspond to in reality. It doesn't. It's just a mathematical device which provides this free information to the Turing machine, which enables it to compute certain things. It turns out to be a useful concept. It's used in cryptography, where you might imagine the oracle could provide the factors to some number, or the password to some system or something. Free information. And then what can you do with that? So this is a notion that comes up in other places. If we have an oracle, we can think of all of the things that you can compute in polynomial time relative to that oracle. So that's what we-- the terminology that people usually use is sometimes called relativism, or computation relative to having this extra information. So P with an A oracle is all of the language that you can decide in polynomial time if you have an oracle for A. Let's see. Yeah. Somebody's asking me, is it really free or does it cost one unit? Even just setting up the oracle and writing down the question to the oracle is going to take you some number of steps. So you're not going to be able do an infinite number of oracle calls in zero time. So charging one step or zero steps, not going to make a difference. Because you still have to formulate the question. As I pointed out, P with a SAT oracle-- so all the things you do in polynomial time with a SAT oracle includes NP. Does it perhaps include other stuff? Or does it equal NP? Would have been a good check-in question, but I'm not going to ask that. In fact, it seems like it contains other things too. Because co-NP is also contained within P, given a SAT oracle. Because the SAT oracle answer is both yes or no, depending upon the answer. So if the formula is unsatisfiable, the oracle is going to say no, it's not in the language. And now you can do the complement of the SAT problem as well. The unsatisfiability problem. So you can do all of co-NP in the same way. You can also define NP relative to some oracle. So all the things you can do with a non-deterministic Turing machine, where all of the branches have separately access. And they can ask multiple questions, by the way, of the oracle. Independently. Let's do another, a little bit of a more challenging example. The MIN-FORMULA language, which I hope you remember from your homework. So those are all of the formulas that do not have a shorter equivalent formula. They are minimal. You cannot make a smaller formula that's equivalent that gives you the same Boolean function. So you showed, for example, that that language is in P space, as I recall. And there was some other-- you had another two problems about that language. The complement of the MIN-FORMULA problem is in NP with a SAT oracle. So mull that over for a second and then we'll see why. Here's an algorithm, in NP with a SAT oracle algorithm. So in other words, now I want to kind of implement that strategy, which I argued in the homework problem was not legal. But now that I have the SAT oracle, it's going to make it possible where before it was not possible. So let's just understand what I mean by that. If I'm trying to do the non minimal formulas, namely the formulas that do have a shorter equivalent formula. I'm going to guess that shorter formula, called psi. The challenge before was testing whether that shorter formula was actually equivalent to phi. Because that's not obviously doable in polynomial time. But the equivalence problem for formulas is a co-NP problem. Or if you like to think about it the other way, any formula in equivalence is an NP problem, because you just have to-- the witness is the assignment on which they disagree. So two formulas are equivalent if they never disagree. And so that's a co-NP problem. A SAT oracle can solve a co-NP problem. Namely, the equivalence of the two formulas, the input formula and the one that you now deterministically guessed. And if it turns out that they are equivalent, a smaller formula is equivalent to the input formula, you know the input formula is not minimal. And so you can accept. And if it gets the wrong formula, it turns out not to be equivalent, then you reject on that branch of the non-determinism, just like we did before. And if the formula really was minimal, none of the branches is going to find a shorter equivalent formula. So that's why this problem here is in NP with a SAT oracle. So now we're going to try to investigate this on my-- we're getting near the end of the lecture. We're going to look at problems like, well, suppose I compare P with a SAT oracle and NP with a SAT oracle. Could those be the same? Well, there's reasons to believe those are not the same. But could there be any A where P with A oracle is the same as NP with an A oracle? It seems like no, but actually that's wrong. There is a language, there are languages for which NP with that oracle and P with that oracle are exactly the same. And that actually is an interest-- it's not just a curiosity, it actually has relevance to strategies for solving P versus NP. Hopefully I'll be able to have time to get to. Can we think of an oracle like a hash table? I think hashing is somehow different in spirit. I understand there's some similarity there, but I don't see the-- hashing is a way of finding sort of a short name for objects, which has a variety of different purposes why you might want to do that. So I don't really think it's the same. Let's see, an oracle question, OK, let's see. How do we use SAT oracle to solve whether two formulas are equivalent? OK, this is getting back to this point. How can we use a SAT oracle to solve whether two formulas are equivalent? Well, we can use a SAT oracle to solve any NP problem, because it's reducible to SAT. In other words-- P with a SAT oracle contains all of NP, so you have to make sure you understand that part. If you have the clique problem, you can reduce. If I give you a clique problem, which is an NP problem, and I want to use the oracle to test if the formula-- if the graph has a clique, I reduce that problem to a SAT problem using the Cook-Levin theorem. And knowing that a clique of a certain size is going to correspond to having a formula which is satisfiable, now I can ask the oracle. And if I can do NP problems, I can do co-NP problems, because P is a deterministic class. Even though it has an oracle, it's still deterministic. It can invert the answer. Something that non-deterministic machines cannot necessarily do. So I don't know, maybe that's-- let's move on. So there's an oracle where P to the A equals NP to the A, which kind of seems kind of amazing at some level. Because here's an oracle where the non-determinism-- if I give you that oracle, non-determinism doesn't help. And it's actually a language we've seen. It's TQBF. Why is that? Well, here's the whole proof. If I have NP with a TQBF oracle. Let's just check each of these steps. I claim I can do that with a non-deterministic polynomial space machine, which no longer has an oracle. The reason is that, if I have polynomial space, I can answer questions about TQBF without needing an oracle. I have enough space just to answer the question directly myself. And I use my non-determinism here to simulate the non-determinism of the NP machine. So every time the NP machine branches non-deterministically, so do I. Every time one of those branches asks the oracle a TQBF question, I just do my polynomial space algorithm to solve that question myself. But now NPSPACE equals PSPACE by Savitch's theorem. And because TQBF is PSPACE complete, for the very same reason that a SAT oracle allows me to do every NP problem, a TQBF problem allows me to do every PSPACE problem. And so I get NP contained within P for a TQBF oracle. And of course, you get the containment the other way immediately. So they're equal. What does that have to do with-- somebody said-- well, I'll just-- I don't want to run out of time. So I'll take any questions at the end. What does this got to do with the P versus NP problem? OK, so this is a very interesting connection. Remember, we just showed through a combination of today's lecture and yesterday's lecture, and I guess Thursday's lecture, that this problem, this equivalence problem, is not in PSPACE, and therefore it's not in P, and therefore it's intractable. That's what we just did. We showed it's complete for a class, which is provably outside of P, provably bigger than P. That's the kind of thing we would like to be able to do to separate P and NP. We would like to show that some other problem is not in P. Some other problem is intractable. Namely, SAT. If we could do SAT, then we're good. We've solved P and NP. So we already have an example of being able to do that. Could we use the same method? Which is something people did try to do many years ago, to show that SAT is not in P. So what is that method really? The guts of that method really comes from the hierarchy there. That's where you were actually proving problems that are hard. You're getting this problem with through the hierarchy construction that's provably outside of PSPACE. And outside of P. That's a diagonalization. And if you look carefully at what's going on there-- so we're going to say, no, we're not going to be able to solve SAT, show SAT's outside of P in the same way. And the reason is, suppose we could. Well the hierarchy theorems are proved by diagonalization. What I mean by that is that in the hierarchy theorem, there's a machine D, which is simulating some other machine, M. To remember what's going on there, remember that we made a machine which is going to make its language different from the language of every machine that's running with less space or with less time. That's how D was defined. It wants to make sure its language cannot be done in less space. So it makes sure that its language is different. It simulates the machines that use less space, and does something different from what they do. Well, that simulation-- if we had an oracle, if we're trying to show that if we provide both a simulator and the machine being simulated with the same oracle, the simulation still works. Every time the machine you're simulating asks a question, the simulator has the same oracle so it can also ask the same question, and can still do the simulation. So in other words, if you could prove P different from NP using basically a simulation, which is what a diagonalization is, then you would be able to prove that P is different from NP for every oracle. So if you can prove P different from NP by a diagonalization, that would also immediately prove that P is different from NP for every oracle. Because the argument is transparent to the oracle. If you just put the oracle down, everything still works. But-- here is the big but, it can't be that-- we know that P A is-- we know this is false. We just exhibit an oracle for which they're equal. It's not the case that P is different from NP for every oracle. Sometimes they're equal, for some oracles. So something that's just basically a very straightforward diagonalization, something that's at its core is a diagonalization, is not going to be enough to solve P and NP. Because otherwise it would prove that they're different for every oracle. And sometimes they're not different, for some oracles. That's an important insight for what kind of a method will not be adequate to prove P different from NP. And this comes up all the time. People who propose hypothetical solutions that they're trying to show P different from NP. One of the very first things people ask is, well, would that argument still work if you put an oracle there. Often it does, which points out there was a flaw. Anyway, last check in. So this is just a little test of your knowledge about oracles. Why don't we-- in our remaining minute here. Let's say 30 seconds. And then we'll do a wrap on this, and I'll point out which ones are right. Oh boy, we're all over the place on this one. You're liking them all. Well, I guess the ones that are false are lagging slightly. OK, let's conclude. Did I give you enough time there? Share results. So, in fact-- Yeah, so having an oracle for the complement is the same as having an oracle. So this is certainly true. NP SAT equal coNP SAT, we have no reason to believe that would be true, and we don't know it to be true. So B is not a good choice and that's the laggard here. MIN-FORMULA, well, is in PSPACE, and anything in PSPACE is reducible to TQBF, so this is certainly true. And same thing for NP with TQBF and coNP with TQBF. Once you have TQBF, you're going to get all of PSPACE. And as we pointed out, this is going to be equal as well. So why don't we end here. And I think that's my last slide. Oh no, there's my summary here. This is what we've done. And I will send you all off on your way. How does the interaction between the Turing machine and the oracle look? Yeah, I didn't define exactly how the machine interacts with an oracle. You can imagine having a separate tape where it writes the oracle question and then goes into a special query state. You can formalize it however you like. They're all going to be-- any reasonable way of formalizing it is going to come up with the same notion in the end. It does show that P with a TQBF oracle equals PSPACE. Yes, that is correct. Good point. Why do we need the oracle to be TQBF? Wouldn't SAT also work because it could solve any NP problem? So you're asking, does P with a SAT oracle equal NP with a SAT oracle? Not known. And believed not to be true, but we don't have a compelling reason for that. No one has any idea how to do that. Because, for example, we showed the complement of MIN-FORMULA is in NP with a SAT oracle. But no one knows how to do-- because there's sort of two levels of non-determinism there. There's guessing the smaller formula, and then guessing again to check the equivalence. And they really can't be combined, because one of them is sort of an exist type guessing, the other one is kind of a for all type guessing. No one knows how to do that in polynomial time with a SAT oracle. Generally believed that they're not the same. In the check-in, why was B false? B is the same question. Does NP with a SAT oracle equal coNP with a SAT oracle? I'm not saying it's false, it's just not known to be true. It doesn't follow from anything that we've shown so far. And I think that would be something that-- well, I guess it doesn't immediately imply any famous open problem. I wouldn't necessarily expect you to know that it's an unsolved problem, but it is. Could we have oracles for undecidable language? Absolutely. Would it be helpful? Well, if you're trying to solve an undecidable problem, it would be helpful. But people do study that. In fact, the original concept of oracles was presented, was derived in the computability theory. And a side note, you can talk about reducibility. No, I don't want to even go there. Too complicated. What is not known to be true? What is not known to be true is that NP with a SAT oracle equals coNP with a SAT oracle, or equals P with a SAT oracle. Nothing is known except the obvious relations among those. Those are all unknown, and just not known to be true or false. Is NP with a SAT oracle equal to NP? Probably not. NP with a SAT oracle, for one thing, contains coNP. Because it's even more powerful. We pointed out that P with a SAT oracle contains coNP. And so NP with a SAT oracle is going to be at least as good. And so it's going to contain coNP. And so, probably not going to be equal to NP unless shockingly unexpected things happen in our complexity world.","74.8623275756836","2","DPRSearchEngine","N32bnUliSzo.en-j3PyPqV-e1s_9_mp4","N32bnUliSzo.en-j3PyPqV-e1s","18.404J","22"
"68","How does the satisfiability problem relate to P and NP, and why is it significant in computational complexity theory?","If you compare these two classes, P and NP. P, first of all, is going to be a subset of NP, both in terms of the way we defined it because, deterministic machines are a special case of non-deterministic machines. But also if you want to think about testing membership, if you can test membership easily then you can certainly verify it in terms of the certificate. You don't even need it. The certificate is irrelevant at that point. Because whatever the certificate is, you can still test yourself whether the input is in the language or not. The big question, as I mentioned, is whether these two classes are the same. So does being able to verify membership quickly, say with one of these certificates, allow you to dispense with the certificate? Not even need a certificate and just test it for yourself whether you're in the language. And do that in polynomial time. That's the question. For a problem like Hamiltonian path, do you need to search for the answer if you're doing it deterministically? Or can you somehow avoid that and just come up with the answer directly with a polynomial time solution? Nobody knows the answer to that. And it goes back, at this point, quite a long time. It's almost 60 years now. That problem has been around 60 years. No, that would be 50 years. No, 50 years, almost 50 years. Most people believe that P is different from NP. In other words, that there are problems in P-- in NP which are not in P. A candidate would be the Hamiltonian path problem. But it seems to be very hard to prove that. And part of the reason is, how do you prove that a problem like Hamiltonian path does not have a polynomial time algorithm. It's very tricky to do that, because the class of polynomial time algorithms is a very rich class. Polynomial time algorithms are very powerful. And to try to prove-- there's no clever way of solving the Hamiltonian path problem. It just seems to be beyond our present day mathematics. I believe someday somebody's going to solve it. But so far, no one has succeeded. So what I thought we would do is-- I think I have a check-in here.","73.77827453613281","3","DPRSearchEngine","1VhnDdQsELo.en-j3PyPqV-e1s_8_mp4","1VhnDdQsELo.en-j3PyPqV-e1s","18.404J","14"
"68","How does the satisfiability problem relate to P and NP, and why is it significant in computational complexity theory?","OK, so now let's talk about NP completeness, because we've kind of set things up. We're not going to prove that the basic theorem, the Cook-Levin theorem about NP completeness, but at least we'll be able to make the definition. OK, here is our definition of what it means for a problem to be NP complete. So a language B is called the NP complete if it has two properties. Number one is that it has to be a member of NP, and number two-- every language in NP has the polynomial time reduce to that language-- to that NP complete language in order for it to be NP complete. So simple picture-- has to be in NP and everything an NP reduces to it. And so that's kind of the magical property that we claim that SAT has. sat, for one thing, is obviously in NP. And as we-- the Cook-Levin theorem shows-- or will show-- everything in NP is reducible to SAT, so SAT's going to be our first example of an NP complete problem. And we're going to get what we claimed also for SAT-- that, if SAT or any other NP complete problem turns out to be solvable in polynomial time, then every NP problem is solvable in polynomial time. And that's immediate, because everything is reducible in polynomial time to the NP complete problem. So if you can do it easily, you can do everything easily just by going through the reduction. OK. So the Cook-Levin theorem, as I mentioned, is that SAT is NP complete. And we're going to actually prove it next lecture, but let's assume for the remainder of this lecture that we know it to be true. So I'll use the terminology of problems being NP complete, assuming that we know-- that we have SAT as NP complete. OK? So we're going to be using some of the things that we're proving next lecture just in the terminology that we're going to be talking today. OK, so here's the picture. Here's the class NP. And everything in NP is polynomial time reducible to SAT. SAT itself is a member of NP, but I didn't want to show it that way because it makes the picture kind of hard to display. So just from the perspective of the reduction, everything in NP is polynomial time reducible to SAT. We'll show that next lecture. Another thing that we'll show next lecture is that SAT, in turn, is polynomial time reducible to 3SAT. So 3SAT, as you remember, are just those problems that are in conjunct-- are in 3CNF. And then what we show today is that 3SAT is polynomial time reducible to clique. So now, taking the assumption that SAT is NP complete-- so everything is polynomial time reduce both the SAT, which is, in turn, polynomial time reducible to 3SAT, and in turn, reducible to clique. These reductions, as we've seen before, composed. You can just apply one reduction function after the next. If each one individually is polynomial, the whole thing as a combination is going to be polynomial. So now we know that 3SAT is going to be also NP complete, because we can reduce anything in NP to SAT, and then to 3SAT, and then we get a reduction directly to 3SAT by composing those two reductions-- and then, furthermore, at the clique. So now we're-- have several NP complete problems. And moving beyond that, we have the HAMPATH problem, which we are going to talk about next. And we'll show another reduction in addition to the one we just showed to clique, now one going from 3SAT to HAMPATH. OK. So in general, I think the takeaway message is that, to show some language is NP complete, you want to show that 3SAT is polynomial time reducible to it. OK, some good questions coming in-- I'll try to answer those. So you're going to take 3SAT and reduce to C. That's the most typical case. There's going to be other examples too, we might start with another problem that you've already shown to be in NP complete, and reduce it to your language. So it doesn't have to start with 3SAT, though often, it does.","73.02937316894531","4","DPRSearchEngine","iZPzBHGDsWI.en-j3PyPqV-e1s_9_mp4","iZPzBHGDsWI.en-j3PyPqV-e1s","18.404J","15"
"68","How does the satisfiability problem relate to P and NP, and why is it significant in computational complexity theory?"," 
 
  
 
  
 
 
  
 
 
 
 
 
 
 
18.404/6.840 Lecture 22 
Last time: 
- Finished NL = coNL 
- Time and Space Hierarchy Theorems 
Today: (Sipser §9.2) 
- A “natural” intractable problem 
- Oracles and P versus NP 
1 
","72.63047790527344","5","DPRSearchEngine","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_1_pdf","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22","18.404J","22"
"68","How does the satisfiability problem relate to P and NP, and why is it significant in computational complexity theory?"," 
 
 
  
 
   
   
  
   
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
  
 
   
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
Relationships between 
Time and SPACE Complexity 
Theorem: For ! "" ≥"" 
1) TIME ! "" 
⊆ SPACE ! "" 
2) SPACE ! "" 
⊆ TIME 2& ' ( 
= ⋃+ TIME ,' ( 
Proof: 
1) A TM that runs in !("") steps cannot use more than !("") tape cells. 
2) A TM that uses !("") tape cells cannot use more than ,' ( time 
without repeating a configuration and looping (for some ,). 
Corollary: P ⊆ PSPACE 
Theorem: NP ⊆ PSPACE [next slide] 
3 
","72.38082885742188","6","DPRSearchEngine","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17_3_pdf","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17","18.404J","17"
"68","How does the satisfiability problem relate to P and NP, and why is it significant in computational complexity theory?"," 
 
  
  
 
 
 
 
 
 
 
 
 
 
   
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Recap: Separating Complexity Classes 
L ⊆ NL 
≠
⊆ P ⊆ NP ⊆ PSPACE 
Space Hierarchy Theorem 
NL ⊆ SPACE log& ' ⊆, SPACE ' ⊆ PSPACE 
12 
Check-in 21.3 
Consider these two famous unsolved questions: 
1. 
Does L = P? 
2. 
Does P = PSPACE? 
What do the hierarchy theorems tell us about 
these questions? 
a) Nothing 
b) At least one of these has answer “NO” 
c) 
At least one of these has answer “YES” 
Check-in 21.3 
","72.14794921875","7","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_12_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"68","How does the satisfiability problem relate to P and NP, and why is it significant in computational complexity theory?","[SQUEAKING] [RUSTLING] [CLICKING] MICHAEL SIPSER: OK, everybody. Let's begin. Welcome back. Good to see you all here on Zoom. So we're going to pick up with what we had been discussing last week, which was an introduction to NP-completeness. So we're following on our description of time complexity. We started talking about the time complexity classes, the class P, the nondeterministic classes, the class NP, P versus NP problem, and then leading to this discussion of NP-completeness. And today we're going to prove the big theorem in the field, which really kind of got things going back in the early 1970s by Cook and Levin that there was actually an NP-complete problem, that SAT in particular is an NP-complete problem. And then we'll also talk about 3SAT, which is a useful tool. Just to remember, we had this notion of NP-completeness. A language is NP-complete if it's in NP. And everything else in NP is polynomial time reducible to it. And if an NP-complete problem turns out to have a polynomial time solution, then every NP-problem has a polynomial time solution. And that's part of the importance of NP-completeness, because since we consider it unlikely that P equals NP, and that there probably are some problems that are an NP, but are not solvable in polynomial time. That would imply that an NP-complete problem would have that property. And so proving a problem being NP-complete is evidence, very strong evidence, that it doesn't have a polynomial time solution. And so therefore it's called intractable. It's a very difficult problem. So the way we are going to typically show problems NP-complete is by reducing a known-- a previously known NP-complete problem to that problem. Often it's 3SAT, as we've seen in several examples already, or it could be some other example. So let's just survey briefly the things that we've already-- languages that we've already seen, which are NP-complete.","71.97638702392578","8","DPRSearchEngine","6Az1gtDRaAU.en-j3PyPqV-e1s_1_mp4","6Az1gtDRaAU.en-j3PyPqV-e1s","18.404J","16"
"68","How does the satisfiability problem relate to P and NP, and why is it significant in computational complexity theory?","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","71.87055206298828","9","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"68","How does the satisfiability problem relate to P and NP, and why is it significant in computational complexity theory?"," 
 
  
  
 
 
 
 
 
 
 
  
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Review: Major Complexity Classes 
L ⊆ NL ⊆ P ⊆ NP ⊆ PSPACE 
≠ 
Today 
The time and space hierarchy theorems show that 
if a TM is given more time (or space) then it can do more.* 
* certain restrictions apply. 
For example: 
TIME #$ ⊆, TIME #% 
[ ⊆, means proper subset ] 
SPACE #$ ⊆, SPACE #% 
7 
","71.6873779296875","10","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_7_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"69","How can branching programs be used to evaluate Boolean functions probabilistically?","  
 
  
 
 
  
 
  
 
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
  
 
 
   
-
Review: Probabilistic TMs and BPP 
coin flip step 
each choice has 
Defn: A probabilistic Turing machine (PTM) is a variant of a NTM 
where each computation step has 1 or 2 possible choices. 
deterministic 
step 
50% probability 
Defn: For ! ≥0 say PTM $  decides language % with error probability !  
if for every &, Pr[ $  gives the wrong answer about & ∈% ] ≤! . 
Defn: BPP = % some poly-time PTM decides % with error !  = +⁄,  } Check-in 24.1 
Actually using a probabilistic algorithm 
Amplification lemma: 2−. /01 2 
presupposes a source of randomness. 
Can we use a standard pseudo-random 
number generator (PRG) as the source? 
& ∈% 
& ∉% 
(a) Yes, but the result isn’t guaranteed.
(b) Yes, but it will run in exponential time.
Many 
Few 
Few 
Many 
(c) No, a TM cannot implement a PRG. 
accepting 
rejecting 
accepting 
rejecting 
(d) No, because that would show P = BPP.
2 
Check-in 24.1 
","74.83380889892578","1","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_2_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"69","How can branching programs be used to evaluate Boolean functions probabilistically?"," 
  
 
 
  
  
 
 
 
 
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Probabilistic TMs 
Defn: A probabilistic Turing machine (PTM) is a variant of a NTM 
where each computation step has 1 or 2 possible choices. 
deterministic 
coin flip step ­
step 
each choice has 50% probability 
Pr[ branch ! ] = 2&' where ! has ( coin flips 
Pr[ "" accepts # ] = + Pr[ branch ! ] 
Pr[ "" rejects # ] = 1 − Pr[ "" accepts # ] 
b accepts 
computation tree 
for "" on # 
branch ! 
Defn: For 7 ≥0 say PTM "" decides language : with error probability 7 
if for every #, Pr[ "" gives the wrong answer about # ∈: ] ≤7 
i.e., # ∈: → Pr[ "" rejects # ] ≤7 
# ∉: → Pr[ "" accepts # ] ≤7. 
2 
","74.06937408447266","2","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_2_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"69","How can branching programs be used to evaluate Boolean functions probabilistically?","Quick review of today
1. Defined probabilistic Turing machines
2. Defined the class BPP
3. Sketched the amplification lemma
4. Introduced branching programs and read-once branching programs
5. Started the proof that !""ROBP ∈BPP 
6. Introduced the arithmetization method
11
","73.680908203125","3","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_11_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"69","How can branching programs be used to evaluate Boolean functions probabilistically?"," 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Turing Machines (TMs) 
head 
˽ ˽
a
b
a 
. . .
b b
Finite 
read/write input tape 
control 
1) Head can read and write 
2) Head is two way (can move left or right) 
3) Tape is infinite (to the right) 
4) Infinitely many blanks “˽“ follow input 
5) Can accept or reject any time (not only at end of input) 
8 
","73.57757568359375","4","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_8_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"69","How can branching programs be used to evaluate Boolean functions probabilistically?","Review:  Branching Programs
","73.15704345703125","5","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_3_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"69","How can branching programs be used to evaluate Boolean functions probabilistically?","Turing machines, as we set them up, they have-- on any input w, they have three possible outcomes. The Turing machine can halt and accept w, can halt and reject w, or it can go forever on w, which is rejecting by looping in our language. A Turing machine can recognize a language, the collection of old strings that it accepts. And if the Turing machine always halts, we say it decides the language, and it's a decider, and so therefore, that language is a decided language, a Turing decider. Often we just say decidable, because we don't really have a notion of deciding in other models, so we often talk about Turing-recognizable or just decidable. Or we'll sometimes just say recognizable, when we understand that we're talking about Turing machines. We briefly talked about encodings. When you write it inside brackets, some objects-- whatever they are-- could be strings, could be machines, could be graphs, could be polynomials-- we're representing them as strings, and maybe a collection of objects together represented as a string in order so that we can present that information as an input to a machine. And we talk about-- our languages our collections of strings. And a notation for writing a Turing machine is going to be simply that English description put inside quotation marks to represent our informal way of talking about the formal object that we could produce, if we wanted to. But we're never going to ask you to do that. OK, so now let me see. Let's just take a quick break, as I promised. If there's any quick questions here, you can ask. Let's see-- got a lot of questions here. All right, why don't we move on? And some of these things are good questions.","72.81605529785156","6","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_2_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"69","How can branching programs be used to evaluate Boolean functions probabilistically?"," 
 
 
   
 
 
 
   
   
      
 
 
 
 
 
 
  
 
Stochastic Processes  
An ongoing process where the next state might depend on 
both the previous states and some random element 
def rollDie(): 
"""""" returns an int between 1 and 6"""""" 
def rollDie(): 
"""""" returns a randomly chosen int 
between 1 and 6"""""" 
6.0002 LECTURE 4 
8
","72.64544677734375","7","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_8_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"69","How can branching programs be used to evaluate Boolean functions probabilistically?","Second half, Church-Turing thesis. So Church, this is going back into the bit of the history of the subject back to the 1930s. Back then people were interested in formulating the notion of what do we mean by algorithm. They didn't even call it algorithm. Some people call it procedure. Some people called it effective procedure. Some people called it effective calculation. But people had in their minds-- mathematicians have been dealing for centuries, thousands of years, with procedures for doing things. That's a very natural thing. And mathematical logicians, in particular Church and Turing, Turing somebody surely obviously you've heard of, Church maybe not. Church was Turing's thesis advisor, in fact. And they both were coming out of the mathematical logic field of mathematics and trying to use mathematical logic to formalize this intuitive notion of what we have had for centuries about what a procedure is, what is an algorithm. And back in those days, they came up with different ways of formalizing it. So here we had this notion of algorithm, which is kind of intuitive concept. Turing proposed Turing machine as a way of capturing that in a formal way, a mathematically precise way. Other people came up with other ways of doing it. And back then, it wasn't obvious that all of those different formulations would end up giving you equivalent concepts, equivalent notions. And in fact, they proved in fairly elaborate detail that the different methods that people came up with, there was the lambda calculus, there was rewriting systems, there were several methods that were proposed for formalizing this notion, and they all turned out to be equivalent to one another. Today that seems kind of obvious, even though I went to some effort to prove that just to give you a feeling for how those things go. If you have programs, if you have Pascal and Java, say, and thinking about what you can do mathematically in those-- I'm not talking about their ability to interface with Windows and so on, but just the mathematical capabilities. The capability of doing mathematical calculations or functions with a Pascal program or a Java program. It would be absurd to think there's some program that you can write in Java that you can't write in Pascal or Python. And the reason is we know you can compile Python into Java and you can compile Java back into Python. That tells you that the two systems, two programming languages are equivalent in power. That wasn't obvious from the get go to these folks. So they observed that all of the different efforts that came at formalizing algorithm, all were equivalent to one another. That was kind of a breakthrough moment when they realized that all of the ways that they've come up with, and once they got the idea, they realized all reasonable ways of doing it are always going to be equivalent. And so that suggested that they've really captured this notion of algorithm by any one of those methods, say a Turing machine. And that's what they took. You can't prove that, because algorithms are an intuitive notion. But the fact that we're able to capture that in a formal way, that's what we call today the Church-Turing thesis.","72.49847412109375","8","DPRSearchEngine","TTArY7ojshU.en-j3PyPqV-e1s_7_mp4","TTArY7ojshU.en-j3PyPqV-e1s","18.404J","6"
"69","How can branching programs be used to evaluate Boolean functions probabilistically?","Example:  Branching Programs
Defn: A branching program (BP) is a directed, acyclic (no cycles) graph that has
1.  Query nodes labeled !"" and having two outgoing edges labeled 0 and 1.
2.  Two output nodes labeled 0 and 1 and having no outgoing edges.
3.  A designated start node.
BP # with query nodes !$, … , !' describes a Boolean function (: 0,1 ' →{0,1}:
Follow the path designated by the query nodes’ outgoing edges 
from the start note until reach an output node.
Example:  For !$ = 1, !/ = 0, !0 = 1 we have ( 101 = 0 = output.
BPs are equivalent if they describe the same Boolean function.
Defn:  12BP =
#$, #/
#$ and #/ are equivalent BPs (written #$ ≡#/) } 
Theorem:  12BP is coNP-complete  (on pset 6)
12BP ∈BPP ?  Unknown. That would imply NP ⊆BPP and would be surprising!
Instead, consider a restricted problem.
!$
!0
!$
!/
!/
!0
0
1
0
1
0
1
0
1
0
1
0
1
0
1
5
","72.1373291015625","9","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_5_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"69","How can branching programs be used to evaluate Boolean functions probabilistically?","we can talk about that more over the break. And so we'll return here in five minutes. Somebody's asking about-- can infinite sequences be generated by the machine. When we're talking about, especially in the complexity section of the course, all of the computations are going to be bounded in time. So we're not going to be thinking about infinite runs of the machine. That's not going to be relevant for us. So let's not think about that. How does a Turing machine perform division? How does a Turing machine perform division? Well, how do you perform division? [LAUGHS] Long division is an operation that can run in-- the long division procedure that you learn in grade school, you can implement that on a Turing machine. Yes, a Turing machine can definitely perform-- do long division, or division of one integer by another in polynomial time. Another question. Can we generally say, try dividing y by x? Or do we have to enumerate a string of length y and cross off every-- no. I think that's the same question. I mean, if you have numbers written in binary, how would you do the division? You're not going to use long division. Anything such as the thing that's proposed here by the questioner is going to be an exponential algorithm. So don't do it that way. Why does primes in P-- composites in P not imply primes in P? It does imply. If composites are in P, then primes is in P as well. When you have a deterministic machine, you can flip the answer. When you have a non-deterministic machine, you may not be able to flip the answer. So deterministic machine just having a single branch, you can make another deterministic machine that runs in the same amount of time that does the complementary language. Because for deterministic machines, just like for deciders in the computability section, you can just invert the answer. There is an analogy here between P and decidability, and NP and recognizability. It's not an airtight analogy here, but there is some relationship there. Somebody's asking me, what are the implications of P equal to NP? Lots of implications. Too long to enumerate now. But, for example, you would be able to break basically all cryptosystems that I'm aware of, if P equal to NP. So we would have a lot of consequences. Somebody's asking, so composites-- primality and compositeness testing is solvable in polynomial time. But factoring, interestingly enough, is not known to be solvable in polynomial time. We may talk about this a little bit toward the end of the term if we have time. The algorithms for testing whether a number is prime or composite in polynomial time do not operate by looking for factors. They operate in an entirely different way, basically by showing that a number is prime or composite by looking at certain properties of that number. But without testing whether it has-- testing, but without finding a factor. Another question here about asking when we talk about encodings, do we have to say how we encode numbers, values? No, we don't have to. We usually don't have to get into spelling out encodings, as long as they're reasonable encodings. So you don't have to usually. We're going to be talking about things at a high enough level that the specific encodings are not going to matter. Let's return to the rest of our lecture.","72.05522918701172","10","DPRSearchEngine","1VhnDdQsELo.en-j3PyPqV-e1s_10_mp4","1VhnDdQsELo.en-j3PyPqV-e1s","18.404J","14"
"70","What is the condition for a TM to accept an input consisting of strings of 'a', 'b', and 'c'?"," 
 
 
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
  
 
  
 
  
 
 
  
 
 
   
 
 
   
 
 
 
 
TMs and Encodings – review 
A TM has 3 possible outcomes for each input !: 
1. Accept ! (enter ""acc ) 
2. Reject ! by halting (enter ""rej ) 
3. Reject ! by looping (running forever) 
( is T-recognizable if ( = *(,) for some TM ,. 
( is T-decidable if ( = *(,) for some TM decider ,. 
halts on all inputs 
〈/0, /2, … , /4〉 encodes objects /0, /2, … , /4 as a single string. 
Notation for writing a TM , is 
, = “On input ! 
[English description of the algorithm]” 
2 
","73.34124755859375","1","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_2_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"70","What is the condition for a TM to accept an input consisting of strings of 'a', 'b', and 'c'?"," 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
   
 
    
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
Linearly Bounded Automata 
Defn: A linearly bounded automaton (LBA) is a 1-tape TM 
that cannot move its head off the input portion of the tape. 
LBA 
a a b a a b a 
Tape size adjusts to length of input. 
Let !LBA = &, ( LBA & accepts ( } 
Theorem:  !LBA is decidable 
Proof: (idea) If & on ( runs for long, it must be cycling. 
Decider for !LBA: 
Claim: For inputs of length ), an LBA can have 
.A−LBA = “On input &, ( 
only * ×)× Γ - different configurations. 
1.  Let ) = |(|. 
Therefore, if an LBA runs for longer, it must repeat some 
2. Run & on ( for * ×)× Γ - steps. 
configuration and thus will never halt. 
3. If has accepted, accept. 
4. If it has rejected or is still running, reject.” 
must be looping 
7 
","71.92143249511719","2","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_7_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"70","What is the condition for a TM to accept an input consisting of strings of 'a', 'b', and 'c'?","  
 
  
 
 
  
 
  
 
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
  
 
 
   
-
Review: Probabilistic TMs and BPP 
coin flip step 
each choice has 
Defn: A probabilistic Turing machine (PTM) is a variant of a NTM 
where each computation step has 1 or 2 possible choices. 
deterministic 
step 
50% probability 
Defn: For ! ≥0 say PTM $  decides language % with error probability !  
if for every &, Pr[ $  gives the wrong answer about & ∈% ] ≤! . 
Defn: BPP = % some poly-time PTM decides % with error !  = +⁄,  } Check-in 24.1 
Actually using a probabilistic algorithm 
Amplification lemma: 2−. /01 2 
presupposes a source of randomness. 
Can we use a standard pseudo-random 
number generator (PRG) as the source? 
& ∈% 
& ∉% 
(a) Yes, but the result isn’t guaranteed.
(b) Yes, but it will run in exponential time.
Many 
Few 
Few 
Many 
(c) No, a TM cannot implement a PRG. 
accepting 
rejecting 
accepting 
rejecting 
(d) No, because that would show P = BPP.
2 
Check-in 24.1 
","71.46928405761719","3","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_2_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"70","What is the condition for a TM to accept an input consisting of strings of 'a', 'b', and 'c'?"," 
 
  
  
  
 
 
  
       
   
 
 
 
 
 
 
  
 
 
 
  
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
  
 
 
 
  
 
 
   
 
 
   
 
 
 
 
   
 
 
 
 
 
 
 
 
    
 
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
  
 
TM – Formal Definition 
Defn: A Turing Machine (TM) is a 7-tuple ("", Σ, Γ, &, '(, 'acc , 'rej)
Σ input alphabet 
Γ tape alphabet (Σ ⊆Γ)
&: Q×Γ → ""×Γ× {L, R} 
(L = Left, R = Right) 
& ', a = (5, b, R) 
On input 6 a TM 7 may halt (enter 'acc or 'rej) 
Check-in 5.3 
or 7 may run forever (“loop”). 
This Turing machine model is deterministic. 
So 7 has 3 possible outcomes for each input 6: 
How would we change it to be nondeterministic? 
1. Accept 6 (enter 'acc ) 
a) Add a second transition function. 
2. Reject 6 by halting (enter 'rej ) 
b) Change & to be &: Q×Γ → 8( ""×Γ× {L, R} ) 
3. Reject 6 by looping (running forever) 
c) Change the tape alphabet Γ to be infinite. 
10 
Check-in 5.3 
","71.05744934082031","4","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_10_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"70","What is the condition for a TM to accept an input consisting of strings of 'a', 'b', and 'c'?"," 
  
   
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
 
 
 
 
  
 
 
 
 
  
 
  
  
 
   
 
 
 
 
  
 
 
 
 
   
 
 
 
 
TM Configurations 
Defn: A configuration of a TM is a triple ("", $, %) where 
"" = the state, 
$ = the head position, 
% = tape contents 
representing a snapshot of the TM at a point in time. 
6 
˽ ˽ … 
""* 
a a a a a a b b b b b  
Configuration: (""*, 6, aaaaaabbbbb) 
%' 
%( 
Encoding as a string: aaaaa""*abbbbb 
Encode configuration ("", $, %) as the string %'""%( where 
% = %'%( and the head position is on the first symbol of %(. 
5 
","71.0301513671875","5","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_5_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"70","What is the condition for a TM to accept an input consisting of strings of 'a', 'b', and 'c'?"," 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Finite Automata – Formal Definition 
Defn: A finite automaton ! is a 5-tuple (#, Σ, &, '0, )) 
# finite set of states 
Σ finite set of alphabet symbols 
Example: 
& transition function &: #×Σ → # 
a
& (', .) = 0 means 
'
0 
0
'0 start state 
!1 
1 
0,1 
1
) set of accept states 
'1
'2 
'3 
0 
!1 = (#, Σ, &, '1, )) 
& = 
0
1
# = {'1, '2, '3} 
'1
'1 '2
Σ = {0, 1} 
'2 '1 '3 
) = {'3} 
'3 '3 '3 
7 
","70.64567565917969","6","DPRSearchEngine","b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1_7_pdf","b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1","18.404J","1"
"70","What is the condition for a TM to accept an input consisting of strings of 'a', 'b', and 'c'?"," 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
a
-
)
⋯
Tableau for ! on "" 
Defn: An (accepting) tableau for NTM ! on "" is an #$×#$ table 
representing an computation history for ! on "" on an accepting branch 
of the nondeterministic computation. 
#$
#$
""* ⋯"", ˽ … ˽
&'
&
""( "")
← Start configuration for ! on "" 
Construct 45,7 to “say” ! accepts "".
⋮ 
45,7 “says” a tableau for ! on "" exists. 
45,7 = 4cell ∧ 4start ∧ 4move ∧ 4accept
⋯ &accept ⋯
← Accepting configuration 
4 
","70.5548095703125","7","DPRSearchEngine","8212b19fc5a34f500ca6acf03a3a7d74_MIT18_404f20_lec16_4_pdf","8212b19fc5a34f500ca6acf03a3a7d74_MIT18_404f20_lec16","18.404J","16"
"70","What is the condition for a TM to accept an input consisting of strings of 'a', 'b', and 'c'?"," 
 
 
 
 
 
 
 
 
  
 
 
   
 
 
  
 
 
 
  
 
 
   
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
'
a
a
a
b
b
b
˽
b
b
b
a
a
a
a
a
a
˽
a
a
a
˽
˽
˽
˽
˽
˽
˽
˽
˽
˽
˽
˽
Deciding ! = a#b# $ ≥0 even faster 
Theorem: A multi-tape TM ' can decide ! using ((*) steps. 
' = “On input , 
Analysis: 
1. Scan input to check if , ∈ a ∗ b ∗ , reject if not. 
( * steps 
2. Copy a’s to second tape. 
+((*) steps 
3. Match b’s with a’s on second tape. 
+((*) steps 
4. Accept if match, else reject. ” 
-----------------­
= ((*) steps 
5 
","70.35905456542969","8","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_5_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"70","What is the condition for a TM to accept an input consisting of strings of 'a', 'b', and 'c'?"," 
 
 
 
  
 
 
 
 
  
   
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
          
 
 
  
  
   
 
 
 
 
  
 
 
 
  
 
 
Nondeterminism doesn’t
correspond to a physical machine
we can build. However, it is useful
mathematically.
accept
reject
accept
reject
Nondeterministic Finite Automata 
a 
a
!1 
b 
a,ε 
#1
#2 
#3 
#4 
b 
New features of nondeterminism: 
- multiple paths possible (0, 1 or many at each step) 
- ε-transition is a “free” move without reading input 
- Accept input if some path leads to 
accept 
Check-in 2.1 
Example inputs: 
What does !' do on input aab ? 
- ab 
- aa 
(a) Accept 
- aba 
(b) Reject 
- abb 
(c) Both Accept and Reject 
Check-in 2.1 
4 
","70.2591552734375","9","DPRSearchEngine","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_4_pdf","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2","18.404J","2"
"70","What is the condition for a TM to accept an input consisting of strings of 'a', 'b', and 'c'?"," 
 
 
 
 
 
 
 
  
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
    
   
   
 
  
  
  
 
 
 
 
  
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
a b a a b a a a a b a b
a b a a b a a a a b a b
Problem:  Given !, is there a match?
Theorem:  Undecidable!
Let !1! =
!
! has a match }
Proof: Show 3TM is reducible to !1!.
First: the Computation History Method.
Post Correspondence Problem 
Given a collection of pairs of strings as dominoes: 
! = 
#$ , 
#' , … , #)
%$
%' 
%) 
a match is a finite sequence of dominos in ! (repeats allowed) 
where the concatenation of the *’s = the concatenation of the +’s. 
# 
#, 
#,
,
Match = 
$ 
'
…
-
where *.$*.' ⋯ *.- = +.$+.' ⋯ +.­
%,$ 
%, 
%,
' 
-
ab 
baab 
ba 
abab 
Check-in 10.1 
Example: 
! = 
,
,
,
aba 
aba 
aa 
b 
baab 
ba 
ab
Let !6 = 
,
,
aaba 
ab 
ba 
Does !6 have a match? 
Match: 
• 
(a) Yes. 
(b) No. 
Check-in 10.1 
4 
","70.06636810302734","10","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_4_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"71","Why is model independence less applicable in complexity theory compared to computability theory?"," 
 
 
 
 
 
 
 
 
  
 
  
 
   
 
 
 
 
  
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Model Dependence 
Number of steps to decide ! = a#b# $ ≥0 depends on the model. 
• 1-tape TM: '() log )) 
• Multi-tape TM: '()) 
Computability theory: model independence (Church-Turing Thesis) 
Therefore model choice doesn’t matter. Mathematically nice. 
Complexity Theory: model dependence 
But dependence is low (polynomial) for reasonable deterministic models. 
We will focus on questions that do not depend on the model choice. 
So… we will continue to use the 1-tape TM as the basic model for complexity. 
6 
","76.656005859375","1","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_6_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"71","Why is model independence less applicable in complexity theory compared to computability theory?"," 
 
 
 
  
 
 
  
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Intro to Complexity Theory 
Computability theory (1930s - 1950s): 
Is A decidable? 
Complexity theory (1960s - present): 
Is A decidable with restricted resources? 
(time/memory/…) 
Example: Let ! = a#b# $ ≥0 . 
Q: How many steps are needed to decide !? 
Depends on the input. 
We give an upper bound for all inputs of length '. 
Called “worst-case complexity”. 
2 
","73.30352783203125","2","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_2_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"71","Why is model independence less applicable in complexity theory compared to computability theory?"," 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
   
 
    
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
Linearly Bounded Automata 
Defn: A linearly bounded automaton (LBA) is a 1-tape TM 
that cannot move its head off the input portion of the tape. 
LBA 
a a b a a b a 
Tape size adjusts to length of input. 
Let !LBA = &, ( LBA & accepts ( } 
Theorem:  !LBA is decidable 
Proof: (idea) If & on ( runs for long, it must be cycling. 
Decider for !LBA: 
Claim: For inputs of length ), an LBA can have 
.A−LBA = “On input &, ( 
only * ×)× Γ - different configurations. 
1.  Let ) = |(|. 
Therefore, if an LBA runs for longer, it must repeat some 
2. Run & on ( for * ×)× Γ - steps. 
configuration and thus will never halt. 
3. If has accepted, accept. 
4. If it has rejected or is still running, reject.” 
must be looping 
7 
","71.73397064208984","3","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_7_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"71","Why is model independence less applicable in complexity theory compared to computability theory?","§ Problem is exponen<al 
§ Have we overturned the laws of the universe? 
§ Is dynamic programming a miracle? 
§ No, but computa<onal complexity can be subtle 
§ Running <me of fastMaxVal is governed by number of 
dis<nct pairs, <toConsider, avail> 
◦Number of possible values of toConsider bounded 
by len(items)
◦Possible values of avail a bit harder to characterize 
◦Bounded by number of dis<nct sums of weights 
◦Covered in more detail in assigned reading 
How Can This Be? 
6.0002 LECTURE 2 
30 
","71.60836791992188","4","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_30_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"71","Why is model independence less applicable in complexity theory compared to computability theory?"," 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
Law of Large Numbers  
In repeated independent tests with the same actual 
probability p of a particular outcome in each test, the 
chance that the fraction of times that outcome occurs 
differs from p converges to zero as the number of trials 
goes to infinity 
Does this imply that if 
deviations from expected 
behavior occur, these 
deviations are likely to be 
evened out by opposite 
deviations in the future? 
6.0002 LECTURE 6 
14
","71.32984924316406","5","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_14_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"71","Why is model independence less applicable in complexity theory compared to computability theory?"," 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
   
 
 
 
 
   
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
  
 
 
  
 
  
 
  
Turing machine model – review 
head 
˽ ˽ . . .
a
b
a
b
b
Finite 
read/write input tape 
control 
On input ! a TM "" may halt (enter #acc or #rej) 
) is T-recognizable if ) = +("") for some TM "". 
or loop (run forever). 
) is T-decidable if ) = +("") for some TM decider "". 
So "" has 3 possible outcomes for each input !: 
halts on all inputs 
1. Accept ! (enter #acc ) 
Turing machines model general-purpose computation. 
2. Reject ! by halting (enter #rej ) 
Q: Why pick this model? 
3. Reject ! by looping (running forever) 
A: Choice of model doesn't matter. 
All reasonable models are equivalent in power. 
Virtues of TMs: simplicity, familiarity. 
2 
","71.29501342773438","6","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_2_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"71","Why is model independence less applicable in complexity theory compared to computability theory?"," 
 
 
 
 
 
 
 
 
 
  
 
  
 
  
 
 
 
  
 
 
 
 
18.404/6.840 Lecture 7 
Last time: 
- Equivalence of variants of the Turing machine model 
a. Multi-tape TMs 
b. Nondeterministic TMs 
c. Enumerators 
- Church-Turing Thesis 
- Notation for encodings and TMs 
Today: (Sipser §4.1) 
- Decision procedures for automata and grammars 
1 
","70.88219451904297","7","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_1_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"71","Why is model independence less applicable in complexity theory compared to computability theory?"," 
 
  
  
 
 
 
 
 
 
 
  
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Review: Major Complexity Classes 
L ⊆ NL ⊆ P ⊆ NP ⊆ PSPACE 
≠ 
Today 
The time and space hierarchy theorems show that 
if a TM is given more time (or space) then it can do more.* 
* certain restrictions apply. 
For example: 
TIME #$ ⊆, TIME #% 
[ ⊆, means proper subset ] 
SPACE #$ ⊆, SPACE #% 
7 
","70.40748596191406","8","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_7_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"71","Why is model independence less applicable in complexity theory compared to computability theory?","  
 
  
 
 
  
 
  
 
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
  
 
 
   
-
Review: Probabilistic TMs and BPP 
coin flip step 
each choice has 
Defn: A probabilistic Turing machine (PTM) is a variant of a NTM 
where each computation step has 1 or 2 possible choices. 
deterministic 
step 
50% probability 
Defn: For ! ≥0 say PTM $  decides language % with error probability !  
if for every &, Pr[ $  gives the wrong answer about & ∈% ] ≤! . 
Defn: BPP = % some poly-time PTM decides % with error !  = +⁄,  } Check-in 24.1 
Actually using a probabilistic algorithm 
Amplification lemma: 2−. /01 2 
presupposes a source of randomness. 
Can we use a standard pseudo-random 
number generator (PRG) as the source? 
& ∈% 
& ∉% 
(a) Yes, but the result isn’t guaranteed.
(b) Yes, but it will run in exponential time.
Many 
Few 
Few 
Many 
(c) No, a TM cannot implement a PRG. 
accepting 
rejecting 
accepting 
rejecting 
(d) No, because that would show P = BPP.
2 
Check-in 24.1 
","70.20657348632812","9","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_2_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"71","Why is model independence less applicable in complexity theory compared to computability theory?","we had model independence. The choice of the model didn't matter. And that was nice for us. Because the theory of the decidability didn't depend upon whether you had a one tape Turing machine, or a multi-tape Turing machine, it was all the same set of decidable and recognizable languages. So we didn't have to worry about which model we're actually going to work with. We could work with any model, even just an informal model of algorithm would be good enough. Because we're going to end up with the same notion in the end. Now that goes away in complexity theory. Now, we have a difference, depending upon the model. And from a mathematical standpoint, that's a little less nice. Because which model do you work with? If you want to understand the complexity of some problem that you have at hand, now you have to make a choice. You're going to work with a Turing machine, or how many tapes, or you're going to look at some other model, and you're going to get different results. So it's somewhat less natural from a mathematical standpoint just to talk about the complexity of some problem. But we're going to kind of bring back something close enough to model independence by observing that even though we don't have model independence, as we did in computability theory, we can limit how much dependence there is. So the amount of dependence is going to be low, as we will see, provided you stick with a reasonable class of deterministic models. So the dependence, though it does exist, is not going to be that much. It's going to be polynomial dependence. And we'll say exactly what that means in a second. And from our standpoint, that's going to be a small difference, a negligible difference that we're going to ignore. So we're going to focus on questions that do not depend on the model choice among these reasonable deterministic models. Now, you may say, well, that's not interesting from a practical standpoint, because polynomial differences, say the difference between n squared and n cubed certainly make a difference in practice. But it really depends on what kinds of questions you're focusing on. So if you want to look at something that's a very precise distinction, say between n squared and n cubed, then you might want to focus in on which model you want to be working with. And that's going to be more the domain of an algorithms class. But from our standpoint, we're going to be looking at other, still important, questions. But they are questions that don't depend upon exactly which polynomial you're going to have. We're going to be looking more at distinctions between polynomial and exponential. And still, there are important practical questions that arise in that somewhat different setting. So with that in mind, we're going to continue to use the one tape Turing machine as our basic model of complexity. Since the model among the reasonable deterministic models in the end is not going to matter from the perspective of the kinds of questions we're going to be asking. So with that, so we are going to continue, then, it's important to remember that from going forward, we're going to stick with the one tape Turing machine model. Maybe that's something you would have expected us to do anyway. But I'm trying to justify that through this little discussion","70.0218505859375","10","DPRSearchEngine","asjAc90L8rE.en-j3PyPqV-e1s_5_mp4","asjAc90L8rE.en-j3PyPqV-e1s","18.404J","12"
"72","Why does the choice of a Turing machine model become significant when comparing complexities like n squared and n cubed?","A pretty small number. But the probability of 26 consecutive reds when the previous 25 rolls were red is what? No, that. AUDIENCE: Oh, I thought you meant it had been 26 times again. JOHN GUTTAG: No, if you had 25 reds and then you spun the wheel once more, the probability of it having 26 reds is now 0.5, because these are independent events. Unless of course the wheel is rigged, and we're assuming it's not. People have a hard time accepting this, and I know it seems funny. But I guarantee there will be some point in the next month or so when you will find yourself thinking this way, that something has to even out. I did so badly on the midterm, I will have to do better on the final. That was mean, I'm sorry. All right, speaking of means-- see? Professor Grimson not the only one who can make bad jokes. There is something-- it's not the gambler's fallacy-- that's often confused with it, and that's called regression to the mean. This term was coined in 1885 by Francis Galton in a paper, of which I've shown you a page from it here.","71.2647705078125","1","DPRSearchEngine","OgO1gpXSUzU.en-j3PyPqV-e1s_8_mp4","OgO1gpXSUzU.en-j3PyPqV-e1s","6.0002","6"
"72","Why does the choice of a Turing machine model become significant when comparing complexities like n squared and n cubed?","And a comparison model means-- is that the items, the objects I'm storing-- I can kind of think of them as black boxes. I don't get to touch these things, except the only way that I can distinguish between them is to say, given a key and an item, or two items, I can do a comparison on those keys. Are these keys the same? Is this key bigger than this one? Is it smaller than this one? Those are the only operations I get to do with them. Say, if the keys are numbers, I don't get to look at what number that is. I just get to take two keys and compare them. And actually, all of the search algorithms that we saw on Tuesday we're comparison sort algorithms. What you did was stepped through the program. At some point, you came to a branch and you looked at two keys, and you branched based on whether one key was bigger than another. That was a comparison. And then you move some stuff around, but that was the general paradigm. Those three sorting operations lived in this comparison model.","71.24948120117188","2","DPRSearchEngine","Nu8YGneFCWE.en-j3PyPqV-e1s_2_mp4","Nu8YGneFCWE.en-j3PyPqV-e1s","6.006","4"
"72","Why does the choice of a Turing machine model become significant when comparing complexities like n squared and n cubed?"," 
 
 
 
 
 
 
 
 
  
 
  
 
   
 
 
 
 
  
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Model Dependence 
Number of steps to decide ! = a#b# $ ≥0 depends on the model. 
• 1-tape TM: '() log )) 
• Multi-tape TM: '()) 
Computability theory: model independence (Church-Turing Thesis) 
Therefore model choice doesn’t matter. Mathematically nice. 
Complexity Theory: model dependence 
But dependence is low (polynomial) for reasonable deterministic models. 
We will focus on questions that do not depend on the model choice. 
So… we will continue to use the 1-tape TM as the basic model for complexity. 
6 
","71.15182495117188","3","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_6_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"72","Why does the choice of a Turing machine model become significant when comparing complexities like n squared and n cubed?","of the reasonable models, they're all what are called polynomially related if each can simulate the other with, at most, a polynomial overhead. So if one of the machines can use this t of n time, the other machine that's simulating it would use t to the k of n time for some k. That's what it means for the two machines to be polynomially related. And all reasonable deterministic models are polynomially related. So as we've already seen, one tape and multi-tape Turing machines are polynomially related, because converting multi-tape to one tape blows you up by, at most, squaring. So k equals 2 in this case. Multidimensional Turing machines, again, polynomially related, the random access machine, which I'm not going to define, but it's the machine that you might imagine-- you would, I'm sure they must define in some form in the algorithms classes, polynomially related. Cellular automata, which are just arrays of finite automata that can communicate with each other, similarly. All the reasonable deterministic models, again, classical models, I'm not talking about quantum computing, are polynomially related. So we are-- that kind of justifies our choice in picking one of them, as long as we're going to ask questions which don't depend upon the polynomial.","71.0248031616211","4","DPRSearchEngine","asjAc90L8rE.en-j3PyPqV-e1s_10_mp4","asjAc90L8rE.en-j3PyPqV-e1s","18.404J","12"
"72","Why does the choice of a Turing machine model become significant when comparing complexities like n squared and n cubed?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 4: Hashing 
Lecture 4: Hashing 
Review 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
• Idea! Want faster search and dynamic operations. Can we find(k) faster than Θ(log n)? 
• Answer is no (lower bound)! (But actually, yes...!?) 
Comparison Model 
• In this model, assume algorithm can only differentiate items via comparisons 
• Comparable items: black boxes only supporting comparisons between pairs 
• Comparisons are <, ≤, >, ≥, =, =6 , outputs are binary: True or False 
• Goal: Store a set of n comparable items, support find(k) operation 
• Running time is lower bounded by # comparisons performed, so count comparisons! 
Decision Tree 
• Any algorithm can be viewed as a decision tree of operations performed 
• An internal node represents a binary comparison, branching either True or False 
• For a comparison algorithm, the decision tree is binary (draw example) 
• A leaf represents algorithm termination, resulting in an algorithm output 
• A root-to-leaf path represents an execution of the algorithm on some input 
• Need at least one leaf for each algorithm output, so search requires ≥ n + 1 leaves 
","70.9039077758789","5","DPRSearchEngine","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_1_pdf","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4","6.006","4"
"72","Why does the choice of a Turing machine model become significant when comparing complexities like n squared and n cubed?","equivalents of regular expressions. Can we now conclude that this problem is also decidable, either immediately from stuff we've already shown; or yes, but would take some significant extra work; or no, because intersection is not a regular operation? So let's see if I can pull that out here-- launch the polling. Here we go. OK, I think we're just about done here. Five seconds more-- OK, ready, set, end. All right. Yes, the correct answer is A. We have basically already shown this fact, because-- why is that? Because we have shown that we can convert-- if you're given two regular expressions, and we want to test whether they're equivalent, they generate the same language, we can convert them both to find out automata. We can convert them to NFAs, and then the NFAs to DFAs. And then we can apply what we've just showed about testing equivalence of DFAs. So yes, it really follows immediately from stuff we've already shown-- the conversion, number one, and then the testing of equivalence for DFAs. So there's not really any work to do here. And in fact, what I'm trying to illustrate with this check-in-- that, once you've shown how to do some kind of a test for one model, it-- going to apply for all of the equivalent models that we've shown to be equivalent, because the Turing machine can do the constructions which show the equivalence. OK, so let's move on. Somebody didn't get the poll. Did most people not get the poll? Well, I think most of you have gotten it. Did you? I'm not seeing a lot of complaints. So if you didn't get the poll, something is wrong with your setup, and you're going to have to take the recorded check-ins that are going to launch right after this lecture's over. Sorry. But you should figure out what's wrong with the setup there, because I think most people are getting these. OK, and with that, we're going to take a little break, and then we'll continue on afterward. Let me know how this is-- should I be speed a little speedier about the little mini breaks that we're taking, or is this good for you? Feedback is always-- I'm trying to make this as good as I can for all of you. OK, I think there's a mixture of between people saying that these breaks are good. Someone says they're a little overlong, so I'll try to tighten them up a little. Some folks are saying what-- more people should be asking the TAs. I don't know how the TAs are doing, in terms of their-- I'll check with them afterward-- how well this is going for them, in terms of the questions. But I think some amount of break is good so that we don't-- so there's time to be asking questions. Otherwise, what's the point of having a live lecture? So we will start promptly when this timer runs down. So be ready to go in 55 seconds from now. Just to confirm, to show the decidability of the equivalence of two regular expressions, do we need to show that we can use a Turing machine to convert them to two DFAs first? If you want to test whether two regular expressions are equivalent, you can give any procedure for doing that deciding you want. I'm just offering one simple way to do it that takes advantage of stuff we've already shown. But if you want to dig down and do some analysis of those regular expressions to show that they describe the same language, they generate the same language, be my guest. I think that's-- actually would be complicated to do that that way. OK, so we're just about ready to go here, so let's continue. And let me take this timer off here. All right. Now, we are going to talk a little about context-free grammars. So we talked about decision problems for finite automata. Let's talk about some for grammars. OK, now I'm going to give us an analogous problem. I'm going to give you a-- I'm calling it the acceptance problem, but-- just for consistency with everything else, but it's really the generating problem. So I'm giving you a grammar-- context-free grammar G and a string that's in a string. And I want to know, is it in the language of G? So does G generate w? I'm calling that the ACFG problem. So that's going to be a decidable again. These are getting slightly harder as we're moving along, so I'm giving you a grammar and a string, and I want to know, does the grammar generate that string? Well, it's not totally trivial to solve that. One thing you might try doing is looking at all possible things, all possible derivations from that grammar and see if any one of them leads to w-- leads you to generate w. Well, you have to be careful, because as I've-- as we've shown in some of our examples, you actually could have-- because you're allowed to have variables that can get converted to empty string, you might have very long intermediate strings being generated from a, grammar which then ultimately give you a small string of terminals that get generated, a small string in the language that gets produced. You certainly don't want to try every possible derivation, because there's infinitely many different derivations-- most of them generating, of course, things that are irrelevant to the string w. But you have to know how to cut things off, and it's not immediately obvious how you do that-- unless you have done the homework problems that I asked you to do, which I'm sure very many of you have not done-- the zero point X problems, because they're-- that's going to come in handy right now. And so I'll help you through that. Remember-- you should remember, but you may not have looked at it-- something called Chomsky normal form, which is for context-free grammars, but only allows the rules to be of a special kind. And they have to look like this. They can be a variable that goes to two variables, on the right-hand side, or a variable that goes to a terminal. Those are the only kinds of rules that you're allowed. This is a special case for the empty string, but let's ignore that for-- the start variable can also work to the empty string, if you want to have a-- the empty string in a language. But that's a special case. Let's ignore that. These are the only two kinds of rules that you can have in a Chomsky normal form grammar. Once you have a Chomsky normal form grammar-- well, first of all, there's two things. First of all, you can always convert any context-free grammar into Chomsky normal form. So that's given in the textbook. You do the obvious thing. I'm not going to spend time on it. And you don't have to know it. It's just a little bit tedious, but it's straightforward and it's there, if you're curious. But the second lemma's the thing that's important to us, which is that, if you have a grammar which is in Chomsky normal form and a string that's generated, every derivation of that string has exactly 2 times the length of the string minus 1 steps. If you think about it, this is a lemma-- very easy to prove. I think the homework problem asks you to prove that in the 0.2 or whatever it was in problem set 1-- or problem set 2-- I don't remember. Rules of this kind allow you to make the string one longer, and rules of this kind allow you to produce a new terminal symbol. If the length w is n, you're going to have n minus 1 of these and n of. Those that's why you get 2n minus 1 steps. But the point is that I don't really care exactly how many. It's just that we have a bound. And once you have that bound, life is good from the point of view of giving a Turing machine which is going to decide this language-- because here's the Turing machine. What it's going to do-- the first thing is it's going to convert G into Chomsky normal form. That we assume we know how to do. Now, we're going to try all derivations, but only those of length 2-- twice the length of the string minus 1, because if any derivation is going to generate w, it has to be this many steps, now that we know the grammar is in Chomsky normal form. OK, so we have converted this problem of one that might be a very unboundedly lengthy problem and to one where it's going to terminate after some fixed number of steps. And so therefore, we can accept, if any of those generate w, and reject if not. OK? Before moving on, so this answers the problem-- shows that this language is decidable, the ACFG language. So that's something that-- make sure you understand. We're basically trying old derivations of up to-- of a certain length, because that's all that's needed when the grammar is in that form. Now we're going to use that to prove a corollary, which is important for understanding how everything fits together. And that corollary states that every context-free language is a decidable language. Every context-free language is decidable. Now, why does that follow from this? Well, suppose you have a context-free language. We know that language is generated by some context-free grammar G. That's what it means. So then you can take that grammar G and you can build it into a Turing machine. So there's going to be a term machine which is constructed with the knowledge of G. And that Turing machine is going to take its w and run the ACFG algorithm with w combined with a G that's already built into it. So it's just going to stick that grammar G in front of w, and now we run the ACFG decider. It's going to say, does degenerate w? Well, that's going to be yes every time w is in A. And so this machine here now is going to end up accepting every string that's in A, because it's every string that G generates. So that is, I think, what I wanted to say about this. Now, I feel that this corollary here throws a little bit of a curveball. And we can just pause for a moment here just to make sure you're understanding this. The tricky thing about this corollary is-- that I often get-- a question I often get where-- is when we start off with a context-free language, who gives-- how do we get G? Because we need G to build a Turing machine M sub G. So we know A is a context-free language, but how do we know what G is? Well, the point is that we may not know what G is, but we know G exists, because that's a definition of A being a context-free language. It must have a context-free grammar, by definition. And so because G exists, I now know my Turing machine, M sub G, exists. And that's enough to know that A is decidable, because it has a decider that exists. Now, if you're not going to tell me the grammar for G, I'm not going to tell you the Turing machine which decides A. But both of them exist. So if you tell me G, then I can tell you the Turing machine. So it's a subtle, tricky issue there. A certain little element maybe of-- sometimes people call it non-constructive, because we're just, in a sense, showing just that something is existing. It does the job for us, because it shows that A is a decidable language. OK, so not so many questions here-- maybe the TAs are getting them. So let's move on. Here's another check-in. So now, can we conclude that A-- instead of ACFG, APDA is decidable? People are getting this one pretty fast. Another 10 seconds-- three seconds-- OK, going to shut it down-- end polling, share results. Yeah. So this problem here is APDA is decidable. I was almost wondering whether or not to give this poll, because it has-- it's true for the same reason as poll number 1, because we know how to convert PDAs-- or we stated we can convert PDAs to CFGs. And that conversion has given in the book. We didn't do in lecture, but I just stated you have to know that fact, but not necessarily know how to do it. That's OK. But the fact is true. The conversion is in the book, and it could be implemented on a Turing machine. So if you want to know whether a PDA's language is empty, you convert it to a context-free grammar and then use this procedure here to test whether it's a language--","70.67568969726562","6","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_11_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"72","Why does the choice of a Turing machine model become significant when comparing complexities like n squared and n cubed?","The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. JOHN GUTTAG: Welcome to Lecture 6. As usual, I want to start by posting some relevant reading. For those who don't know, this lovely picture is of the Casino at Monte Carlo, and shortly you'll see why we're talking about casinos and gambling today. Not because I want to encourage you to gamble your life savings away. A little history about Monte Carlo simulation, which is the topic of today's lecture. The concept was invented by the Polish American mathematician, Stanislaw Ulam. Probably more well known for his work on thermonuclear weapons than on mathematics, but he did do a lot of very important mathematics earlier in his life. The story here starts that he was ill, recovering from some serious illness, and was home and was bored and was playing a lot of games of solitaire, a game I suspect you've all played. Being a mathematician, he naturally wondered, what's the probability of my winning this stupid game which I keep losing? And so he actually spent quite a lot of time trying to work out the combinatorics, so that he could actually compute the probability. And despite being a really amazing mathematician, he failed. The combinatorics were just too complicated. So he thought, well suppose I just play lots of hands and count the number I win, divide by the number of hands I played. Well then he thought about it and said, well, I've already played a lot of hands and I haven't won yet. So it probably will take me years to play enough hands to actually get a good estimate, and I don't want to do that. So he said, well, suppose instead of playing the game, I just simulate the game on a computer. He had no idea how to use a computer, but he had friends in high places. And actually talked to John von Neumann, who is often viewed as the inventor of the stored program computer. And said, John, could you do this on your fancy new ENIAC machine? And on the lower right here, you'll see a picture of the ENIAC. It was a very large machine. It filled a room. And von Neumann said, sure, we could probably do it in only a few hours of computation. Today we would think of a few microseconds, but those machines were slow. Hence was born Monte Carlo simulation, and then they actually used it in the design of the hydrogen bomb. So it turned out to be not just useful for cards. So what is Monte Carlo simulation? It's a method of estimating the values of an unknown quantity using what is called inferential statistics. And we've been using inferential statistics for the last several lectures. The key concepts-- and I want to be careful about these things will be coming back to them-- are the population. So think of the population as the universe of possible examples. So in the case of solitaire, it's a universe of all possible games of solitaire that you could possibly play. I have no idea how big that is, but it's really big, Then we take that universe, that population, and we sample it by drawing a proper subset. Proper means not the whole thing. Usually more than one sample to be useful. Certainly more than 0. And then we make an inference about the population based upon some set of statistics we do on the sample. So the population is typically a very large set of examples, and the sample is a smaller set of examples. And the key fact that makes them work is that if we choose the sample at random, the sample will tend to exhibit the same properties as the population from which it is drawn. And that's exactly what we did with the random walk, right? There were a very large number of different random walks you could take of say, 10,000 steps. We didn't look at all possible random walks of 10,000 steps. We drew a small sample of, say 100 such walks, computed the mean of those 100, and said, we think that's probably a good expectation of what the mean would be of all the possible walks of 10,000 steps. So we were depending upon this principle. And of course the key fact here is that the sample has to be random. If you start drawing the sample and it's not random, then there's no reason to expect it to have the same properties as that of the population. And we'll go on throughout the term, and talk about the various ways you can get fooled and think of a random sample when exactly you don't. All right, let's look at a very simple example. People like to use flipping coins because coins are easy.","70.50402069091797","7","DPRSearchEngine","OgO1gpXSUzU.en-j3PyPqV-e1s_1_mp4","OgO1gpXSUzU.en-j3PyPqV-e1s","6.0002","6"
"72","Why does the choice of a Turing machine model become significant when comparing complexities like n squared and n cubed?","All right, acceptance problem for Turing Machines. So just as I mentioned, we showed that A,TM, which is the language of Turing machines and inputs where the machine accepts the input. We showed that was recognizable. We claimed it was decidable. Today, we're going to prove it's not decidable. All right, now the method that we're going to use, which is really the only method out there for proving a problem as undecidable is called the diagonalization method. I mean, ultimately, we're going to show the reducibility method as well. But it really depends on having already shown some other problem undecidable via the diagonalization method. So ultimately, everything hinges on the diagonalization method, which is really what we have.","70.4421157836914","8","DPRSearchEngine","3PzuSPQPEU4.en-j3PyPqV-e1s_3_mp4","3PzuSPQPEU4.en-j3PyPqV-e1s","18.404J","8"
"72","Why does the choice of a Turing machine model become significant when comparing complexities like n squared and n cubed?","power of a Turing machine. That's a question that I'm going to postpone to later, because you're asking if a Turing machine can simulate itself. And we'll talk about things like that, but that's in a few weeks from now, so I'll hold off on that one. Decidable languages-- somebody's asking me a good question about closure properties of the class of decidable languages. Are they closed under intersection, union, and so on? Yes. And the decidable languages are also closed under complement. That should be something you should think about. But yes, that is true. The recognizable languages, however, are closed under union and intersection, but they are not closed under complement. So that we will prove on Thursday's lecture. So another question is, could we have just run B on w in this-- in solving this problem, instead of using reduced-- converting it to a new Turing machine-- the B prime? Well, yes, we could have just done that. OK. I think we better move on. I don't want to get too bogged down here-- got a lot of questions there, so sorry if I'm not getting to all of the questions. OK. Or you can write to the TAs too, obviously. I'm sure you are.","70.32107543945312","9","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_7_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"72","Why does the choice of a Turing machine model become significant when comparing complexities like n squared and n cubed?","§ Problem is exponen<al 
§ Have we overturned the laws of the universe? 
§ Is dynamic programming a miracle? 
§ No, but computa<onal complexity can be subtle 
§ Running <me of fastMaxVal is governed by number of 
dis<nct pairs, <toConsider, avail> 
◦Number of possible values of toConsider bounded 
by len(items)
◦Possible values of avail a bit harder to characterize 
◦Bounded by number of dis<nct sums of weights 
◦Covered in more detail in assigned reading 
How Can This Be? 
6.0002 LECTURE 2 
30 
","70.099365234375","10","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_30_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"73","Why is the proof that the language !TM is undecidable a diagonalization proof?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
Use our knowledge that !TM is undecidable to show other 
problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
10 
","84.1872329711914","1","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_10_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"73","Why is the proof that the language !TM is undecidable a diagonalization proof?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
If we know that some problem (say !TM) is undecidable, 
we can use that to show other problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Recall Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
2 
","84.01739501953125","2","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_2_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"73","Why is the proof that the language !TM is undecidable a diagonalization proof?","So E TM is the emptiness problem for Turing machines. Is this language empty? I'm just going to give you a machine. I want to know, is this language empty or not? Does it accept something or is this language empty? That's going to be undecidable, no surprise, proof by contradiction. And we're going to show that A TM is reducible to E TM. So these things often take a very similar form. And I'm going to try to use the same form. So if you're feeling shaky on it, at least you'll get the form of the way the solution goes and that will help you maybe plug-in to solve problems, OK.","83.18722534179688","3","DPRSearchEngine","N28g_YBXY8Y.en-j3PyPqV-e1s_7_mp4","N28g_YBXY8Y.en-j3PyPqV-e1s","18.404J","9"
"73","Why is the proof that the language !TM is undecidable a diagonalization proof?"," 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
18.404/6.840 Lecture 9 
Last time: 
- !TM is undecidable 
- The diagonalization method 
- !TM is T-unrecognizable 
- The Reducibility Method, preview 
Today: (Sipser §5.1, §5.3) 
- The Reducibility Method for proving undecidability 
and T-unrecognizability. 
- General reducibility 
- Mapping reducibility 
1 
","82.93241119384766","4","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_1_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"73","Why is the proof that the language !TM is undecidable a diagonalization proof?","All right, acceptance problem for Turing Machines. So just as I mentioned, we showed that A,TM, which is the language of Turing machines and inputs where the machine accepts the input. We showed that was recognizable. We claimed it was decidable. Today, we're going to prove it's not decidable. All right, now the method that we're going to use, which is really the only method out there for proving a problem as undecidable is called the diagonalization method. I mean, ultimately, we're going to show the reducibility method as well. But it really depends on having already shown some other problem undecidable via the diagonalization method. So ultimately, everything hinges on the diagonalization method, which is really what we have.","81.46847534179688","5","DPRSearchEngine","3PzuSPQPEU4.en-j3PyPqV-e1s_3_mp4","3PzuSPQPEU4.en-j3PyPqV-e1s","18.404J","8"
"73","Why is the proof that the language !TM is undecidable a diagonalization proof?"," 
  
  
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
  
 
 
 
  
!TM is undecidable 
Let !TM = { & | & is a TM and ( & = ∅} 
Theorem: !TM is undecidable 
Proof by contradiction. Show that +TM is reducible to !TM. 
Assume that !TM is decidable and show that +TM is decidable (false!). 
Let TM , decide !TM. 
Construct TM - deciding +TM. 
- = “On input &, / 
1. Transform & to new TM &0 = “On input 1 
1.  If 1 ≠/, reject. 
2. else run & on / 
3. Accept if & accepts.” 
2.  Use , to test whether ((&0) = ∅ 
3.  If YES [so & rejects /] then reject. 
If NO [so & accepts /] then accept. 
&0 works like & except that it 
always rejects strings 1 where 1 ≠/. 
if & accepts / 
So ( &0 = 5 /
∅ 
if & rejects / 
4 
","81.39643859863281","6","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_4_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"73","Why is the proof that the language !TM is undecidable a diagonalization proof?"," 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
18.404/6.840 Lecture 8 
Last time: 
- Decision procedures for automata and grammars
!DFA , !NFA , &DFA , &'DFA , !CFG , &CFG are decidable 
!TM is T-recognizable 
Today: (Sipser §4.2) 
- !TM is undecidable 
- The diagonalization method 
- !TM is T-unrecognizable 
- The reducibility method 
- Other undecidable languages 
1 
","81.06742858886719","7","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_1_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"73","Why is the proof that the language !TM is undecidable a diagonalization proof?","  
 
 
 
  
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Recall: Acceptance Problem for TMs 
Let !TM = { &, ( | & is a TM and & accepts (} 
Today’s Theorem: !TM is not decidable 
Proof uses the diagonalization method, 
so we will introduce that first. 
2 
","79.7148208618164","8","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_2_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"73","Why is the proof that the language !TM is undecidable a diagonalization proof?","  
  
 
 
  
 
  
  
 
   
   
  
 
   
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
!TM is T-unrecognizable 
Recall !TM = { & | & is a TM and ( & = ∅} 
Theorem: !TM is T-unrecognizable 
Proof: Show +TM ≤- !TM 
Reduction function: . &, 0 
= &1 
Recall TM &1 = “On input 3 
1.  If 3 ≠0, reject.
Explanation: 
&, 0 ∈ +TM iff &1 ∈!TM 
2. else run & on 0
& rejects 0 iff ( &1 
= ∅ 
3. Accept if & accepts.” 
+TM 
. 
!TM 
9 
","79.44168853759766","9","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_9_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"73","Why is the proof that the language !TM is undecidable a diagonalization proof?"," 
 
 
 
  
 
 
 
 
  
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
  
!""TM and !""TM are T-unrecognizable 
!""TM = &', &) &' and &) are TMs and * &' = *(&)) } 
Theorem: Both !""TM and !""TM are T-unrecognizable 
Proof: (1) .TM ≤0 !""TM 
(2) .TM ≤0 !""TM 
For any 1 let 23 = “On input 4 
23 acts on all inputs the way & acts on 1. 
1. Ignore 4. 
2. Simulate & on 1.” 
(1) Here we give 5 which maps .TM problems (of the form &, 1 ) 
to !""TM problems (of the form 2', 2) ).
5 &, 1 
= 〈23, 2reject〉
2reject is a TM that always rejects. 
(2) Similarly 5 &, 1 
= 〈23, 2accept 〉
2accept always accepts. 
10 
","78.78734588623047","10","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_10_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"74","What is a tableau in the context of nondeterministic computation, and how does it relate to an accepting branch and computation history?","So first of all, let me describe what my computation history is going to look like. And the situation is a little bit different than what we had before because when we were talking about the Post correspondence problem we had a deterministic machine. And now our machine is nondeterministic. So we're going to call the object-- instead of an accepting computation or a computation history, we're just going to-- we're going to call it a tableau, or sometimes an accepting tableau if you want to emphasize the accepting nature of it. But generally, we're just going to call it a tableau. So a tableau is really an accepting computation history for the machine on an accepting branch of its nondeterministic computation. So if M accepts w, it's got to have some accepting branch, and the tableau is going to be the sequence of configurations that the machine goes through on that accepting branch. If there are several accepting branches, there may be several tableaus. There will be several tableaus. So there's going to be one tableau for each accepting branch of the machine's computation on w. If the machine does not accept w, there won't be any tableaus. And so the whole point is that we're going to make our formula represent the statement that there is a tableau. And satisfying that formula is going to correspond to filling out the symbols in the tableau to make it a tableau. So here is a tableau. So a tableau is just, again, an accepting computation history on some branch, some accepting branch of the machine's computation. The rows are the-- instead of writing the computation history out linearly, we're going to represent it in a table form where each configuration is going to be on a separate row. Now, the dimensions of that table are going to be n to the k by n to the k, because the machine runs for n to the k steps. So there's going to-- if there's an accepting branch, it's going to accept within that number of steps. And we'll have enough rows here to write down all of the configurations that the machine goes through one after the next, row by row, each one having a configuration in it. And then at the bottom, there'll be an accept. Minor detail, if the machine accepts earlier, we'll just say the machine stays in the-- once it enters an accept, the machine does not change from that point on. So the rule of the machine is nothing changes. And it just remains in the same configuration from that point on.","74.74949645996094","1","DPRSearchEngine","6Az1gtDRaAU.en-j3PyPqV-e1s_4_mp4","6Az1gtDRaAU.en-j3PyPqV-e1s","18.404J","16"
"74","What is a tableau in the context of nondeterministic computation, and how does it relate to an accepting branch and computation history?","  
 
  
 
 
  
 
  
 
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
  
 
 
   
-
Review: Probabilistic TMs and BPP 
coin flip step 
each choice has 
Defn: A probabilistic Turing machine (PTM) is a variant of a NTM 
where each computation step has 1 or 2 possible choices. 
deterministic 
step 
50% probability 
Defn: For ! ≥0 say PTM $  decides language % with error probability !  
if for every &, Pr[ $  gives the wrong answer about & ∈% ] ≤! . 
Defn: BPP = % some poly-time PTM decides % with error !  = +⁄,  } Check-in 24.1 
Actually using a probabilistic algorithm 
Amplification lemma: 2−. /01 2 
presupposes a source of randomness. 
Can we use a standard pseudo-random 
number generator (PRG) as the source? 
& ∈% 
& ∉% 
(a) Yes, but the result isn’t guaranteed.
(b) Yes, but it will run in exponential time.
Many 
Few 
Few 
Many 
(c) No, a TM cannot implement a PRG. 
accepting 
rejecting 
accepting 
rejecting 
(d) No, because that would show P = BPP.
2 
Check-in 24.1 
","73.85397338867188","2","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_2_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"74","What is a tableau in the context of nondeterministic computation, and how does it relate to an accepting branch and computation history?"," 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
Computation History Method - recap 
Computation History Method is useful for showing the undecidability 
of problems involving testing for the existence of some object. 
!
Is there an integral solution (to the polynomial equation)?
""LBA 
Is there some accepted string (for the LBA)?
&'& 
Is there a match (for the given dominos)?
())CFG Is there some rejected string (for the CFG)?
In each case, the object is the computation history in some form.
12
","73.64720916748047","3","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_12_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"74","What is a tableau in the context of nondeterministic computation, and how does it relate to an accepting branch and computation history?"," 
 
  
 
 
 
 
 
 
  
 
 
 
 
 
 
  
18.404/6.840 Lecture 23 
Last time: 
- !""#$%↑ is EXPSPACE-complete 
- Thus !""#$%↑ ∉ PSPACE 
- Oracles and P versus NP 
Today: (Sipser §10.2) 
- Probabilistic computation 
- The class BPP 
- Branching programs 
1 
","72.51220703125","4","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_1_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"74","What is a tableau in the context of nondeterministic computation, and how does it relate to an accepting branch and computation history?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","72.49097442626953","5","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"74","What is a tableau in the context of nondeterministic computation, and how does it relate to an accepting branch and computation history?","Turing machines, as we set them up, they have-- on any input w, they have three possible outcomes. The Turing machine can halt and accept w, can halt and reject w, or it can go forever on w, which is rejecting by looping in our language. A Turing machine can recognize a language, the collection of old strings that it accepts. And if the Turing machine always halts, we say it decides the language, and it's a decider, and so therefore, that language is a decided language, a Turing decider. Often we just say decidable, because we don't really have a notion of deciding in other models, so we often talk about Turing-recognizable or just decidable. Or we'll sometimes just say recognizable, when we understand that we're talking about Turing machines. We briefly talked about encodings. When you write it inside brackets, some objects-- whatever they are-- could be strings, could be machines, could be graphs, could be polynomials-- we're representing them as strings, and maybe a collection of objects together represented as a string in order so that we can present that information as an input to a machine. And we talk about-- our languages our collections of strings. And a notation for writing a Turing machine is going to be simply that English description put inside quotation marks to represent our informal way of talking about the formal object that we could produce, if we wanted to. But we're never going to ask you to do that. OK, so now let me see. Let's just take a quick break, as I promised. If there's any quick questions here, you can ask. Let's see-- got a lot of questions here. All right, why don't we move on? And some of these things are good questions.","72.1875","6","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_2_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"74","What is a tableau in the context of nondeterministic computation, and how does it relate to an accepting branch and computation history?","All right, acceptance problem for Turing Machines. So just as I mentioned, we showed that A,TM, which is the language of Turing machines and inputs where the machine accepts the input. We showed that was recognizable. We claimed it was decidable. Today, we're going to prove it's not decidable. All right, now the method that we're going to use, which is really the only method out there for proving a problem as undecidable is called the diagonalization method. I mean, ultimately, we're going to show the reducibility method as well. But it really depends on having already shown some other problem undecidable via the diagonalization method. So ultimately, everything hinges on the diagonalization method, which is really what we have.","72.17625427246094","7","DPRSearchEngine","3PzuSPQPEU4.en-j3PyPqV-e1s_3_mp4","3PzuSPQPEU4.en-j3PyPqV-e1s","18.404J","8"
"74","What is a tableau in the context of nondeterministic computation, and how does it relate to an accepting branch and computation history?","What are oracles? Oracles are a simple thing. But they are a useful concept for a number of reasons. Especially because they're going to tell us something interesting about methods, which may or may not be useful for proving the P versus NP question, when someday somebody hopefully does that. What is an oracle? An oracle is free information you're going to give to a Turing machine, which might affect the difficulty of solving problems. And the way we're going to represent that free information is, we're going to allow the Turing machine to test membership in some specified language, without charging for the work involved. I'm going to allow you have any language at all, some language A. And say a Turing machine with an oracle for A is written this way, M with a superscript A. It's a machine that has a black box that can answer questions. Is some string, which the machine can choose, in A or not? And it gets that answer in one step, effectively for free. So you can imagine, depending upon the language that you're providing to the machine, that may or may not be useful. For example, suppose I give you an oracle for the SAT language. That can be very useful. It could be very useful for deciding SAT, for example. Because now you don't have to go through a brute force search to solve SAT. You just ask the oracle. And the oracle is going to say, yes it's satisfiable, or no it's not satisfiable. But you can use that to solve other languages too, quickly. Because anything that you can do in NP, you can reduce to SAT. So you can convert it to a SAT question, which you can then ship up to the oracle, and the oracle is going to tell you the answer. The word ""oracle"" already sort of conveys something magical. We're not really going to be concerned with the operation of the oracle, so don't ask me how does the oracle work, or what does it correspond to in reality. It doesn't. It's just a mathematical device which provides this free information to the Turing machine, which enables it to compute certain things. It turns out to be a useful concept. It's used in cryptography, where you might imagine the oracle could provide the factors to some number, or the password to some system or something. Free information. And then what can you do with that? So this is a notion that comes up in other places. If we have an oracle, we can think of all of the things that you can compute in polynomial time relative to that oracle. So that's what we-- the terminology that people usually use is sometimes called relativism, or computation relative to having this extra information. So P with an A oracle is all of the language that you can decide in polynomial time if you have an oracle for A. Let's see. Yeah. Somebody's asking me, is it really free or does it cost one unit? Even just setting up the oracle and writing down the question to the oracle is going to take you some number of steps. So you're not going to be able do an infinite number of oracle calls in zero time. So charging one step or zero steps, not going to make a difference. Because you still have to formulate the question. As I pointed out, P with a SAT oracle-- so all the things you do in polynomial time with a SAT oracle includes NP. Does it perhaps include other stuff? Or does it equal NP? Would have been a good check-in question, but I'm not going to ask that. In fact, it seems like it contains other things too. Because co-NP is also contained within P, given a SAT oracle. Because the SAT oracle answer is both yes or no, depending upon the answer. So if the formula is unsatisfiable, the oracle is going to say no, it's not in the language. And now you can do the complement of the SAT problem as well. The unsatisfiability problem. So you can do all of co-NP in the same way. You can also define NP relative to some oracle. So all the things you can do with a non-deterministic Turing machine, where all of the branches have separately access. And they can ask multiple questions, by the way, of the oracle. Independently. Let's do another, a little bit of a more challenging example. The MIN-FORMULA language, which I hope you remember from your homework. So those are all of the formulas that do not have a shorter equivalent formula. They are minimal. You cannot make a smaller formula that's equivalent that gives you the same Boolean function. So you showed, for example, that that language is in P space, as I recall. And there was some other-- you had another two problems about that language. The complement of the MIN-FORMULA problem is in NP with a SAT oracle. So mull that over for a second and then we'll see why. Here's an algorithm, in NP with a SAT oracle algorithm. So in other words, now I want to kind of implement that strategy, which I argued in the homework problem was not legal. But now that I have the SAT oracle, it's going to make it possible where before it was not possible. So let's just understand what I mean by that. If I'm trying to do the non minimal formulas, namely the formulas that do have a shorter equivalent formula. I'm going to guess that shorter formula, called psi. The challenge before was testing whether that shorter formula was actually equivalent to phi. Because that's not obviously doable in polynomial time. But the equivalence problem for formulas is a co-NP problem. Or if you like to think about it the other way, any formula in equivalence is an NP problem, because you just have to-- the witness is the assignment on which they disagree. So two formulas are equivalent if they never disagree. And so that's a co-NP problem. A SAT oracle can solve a co-NP problem. Namely, the equivalence of the two formulas, the input formula and the one that you now deterministically guessed. And if it turns out that they are equivalent, a smaller formula is equivalent to the input formula, you know the input formula is not minimal. And so you can accept. And if it gets the wrong formula, it turns out not to be equivalent, then you reject on that branch of the non-determinism, just like we did before. And if the formula really was minimal, none of the branches is going to find a shorter equivalent formula. So that's why this problem here is in NP with a SAT oracle. So now we're going to try to investigate this on my-- we're getting near the end of the lecture. We're going to look at problems like, well, suppose I compare P with a SAT oracle and NP with a SAT oracle. Could those be the same? Well, there's reasons to believe those are not the same. But could there be any A where P with A oracle is the same as NP with an A oracle? It seems like no, but actually that's wrong. There is a language, there are languages for which NP with that oracle and P with that oracle are exactly the same. And that actually is an interest-- it's not just a curiosity, it actually has relevance to strategies for solving P versus NP. Hopefully I'll be able to have time to get to. Can we think of an oracle like a hash table? I think hashing is somehow different in spirit. I understand there's some similarity there, but I don't see the-- hashing is a way of finding sort of a short name for objects, which has a variety of different purposes why you might want to do that. So I don't really think it's the same. Let's see, an oracle question, OK, let's see. How do we use SAT oracle to solve whether two formulas are equivalent? OK, this is getting back to this point. How can we use a SAT oracle to solve whether two formulas are equivalent? Well, we can use a SAT oracle to solve any NP problem, because it's reducible to SAT. In other words-- P with a SAT oracle contains all of NP, so you have to make sure you understand that part. If you have the clique problem, you can reduce. If I give you a clique problem, which is an NP problem, and I want to use the oracle to test if the formula-- if the graph has a clique, I reduce that problem to a SAT problem using the Cook-Levin theorem. And knowing that a clique of a certain size is going to correspond to having a formula which is satisfiable, now I can ask the oracle. And if I can do NP problems, I can do co-NP problems, because P is a deterministic class. Even though it has an oracle, it's still deterministic. It can invert the answer. Something that non-deterministic machines cannot necessarily do. So I don't know, maybe that's-- let's move on. So there's an oracle where P to the A equals NP to the A, which kind of seems kind of amazing at some level. Because here's an oracle where the non-determinism-- if I give you that oracle, non-determinism doesn't help. And it's actually a language we've seen. It's TQBF. Why is that? Well, here's the whole proof. If I have NP with a TQBF oracle. Let's just check each of these steps. I claim I can do that with a non-deterministic polynomial space machine, which no longer has an oracle. The reason is that, if I have polynomial space, I can answer questions about TQBF without needing an oracle. I have enough space just to answer the question directly myself. And I use my non-determinism here to simulate the non-determinism of the NP machine. So every time the NP machine branches non-deterministically, so do I. Every time one of those branches asks the oracle a TQBF question, I just do my polynomial space algorithm to solve that question myself. But now NPSPACE equals PSPACE by Savitch's theorem. And because TQBF is PSPACE complete, for the very same reason that a SAT oracle allows me to do every NP problem, a TQBF problem allows me to do every PSPACE problem. And so I get NP contained within P for a TQBF oracle. And of course, you get the containment the other way immediately. So they're equal. What does that have to do with-- somebody said-- well, I'll just-- I don't want to run out of time. So I'll take any questions at the end. What does this got to do with the P versus NP problem? OK, so this is a very interesting connection. Remember, we just showed through a combination of today's lecture and yesterday's lecture, and I guess Thursday's lecture, that this problem, this equivalence problem, is not in PSPACE, and therefore it's not in P, and therefore it's intractable. That's what we just did. We showed it's complete for a class, which is provably outside of P, provably bigger than P. That's the kind of thing we would like to be able to do to separate P and NP. We would like to show that some other problem is not in P. Some other problem is intractable. Namely, SAT. If we could do SAT, then we're good. We've solved P and NP. So we already have an example of being able to do that. Could we use the same method? Which is something people did try to do many years ago, to show that SAT is not in P. So what is that method really? The guts of that method really comes from the hierarchy there. That's where you were actually proving problems that are hard. You're getting this problem with through the hierarchy construction that's provably outside of PSPACE. And outside of P. That's a diagonalization. And if you look carefully at what's going on there-- so we're going to say, no, we're not going to be able to solve SAT, show SAT's outside of P in the same way. And the reason is, suppose we could. Well the hierarchy theorems are proved by diagonalization. What I mean by that is that in the hierarchy theorem, there's a machine D, which is simulating some other machine, M. To remember what's going on there, remember that we made a machine which is going to make its language different from the language of every machine that's running with less space or with less time. That's how D was defined. It wants to make sure its language cannot be done in less space. So it makes sure that its language is different. It simulates the machines that use less space, and does something different from what they do. Well, that simulation-- if we had an oracle, if we're trying to show that if we provide both a simulator and the machine being simulated with the same oracle, the simulation still works. Every time the machine you're simulating asks a question, the simulator has the same oracle so it can also ask the same question, and can still do the simulation. So in other words, if you could prove P different from NP using basically a simulation, which is what a diagonalization is, then you would be able to prove that P is different from NP for every oracle. So if you can prove P different from NP by a diagonalization, that would also immediately prove that P is different from NP for every oracle. Because the argument is transparent to the oracle. If you just put the oracle down, everything still works. But-- here is the big but, it can't be that-- we know that P A is-- we know this is false. We just exhibit an oracle for which they're equal. It's not the case that P is different from NP for every oracle. Sometimes they're equal, for some oracles. So something that's just basically a very straightforward diagonalization, something that's at its core is a diagonalization, is not going to be enough to solve P and NP. Because otherwise it would prove that they're different for every oracle. And sometimes they're not different, for some oracles. That's an important insight for what kind of a method will not be adequate to prove P different from NP. And this comes up all the time. People who propose hypothetical solutions that they're trying to show P different from NP. One of the very first things people ask is, well, would that argument still work if you put an oracle there. Often it does, which points out there was a flaw. Anyway, last check in. So this is just a little test of your knowledge about oracles. Why don't we-- in our remaining minute here. Let's say 30 seconds. And then we'll do a wrap on this, and I'll point out which ones are right. Oh boy, we're all over the place on this one. You're liking them all. Well, I guess the ones that are false are lagging slightly. OK, let's conclude. Did I give you enough time there? Share results. So, in fact-- Yeah, so having an oracle for the complement is the same as having an oracle. So this is certainly true. NP SAT equal coNP SAT, we have no reason to believe that would be true, and we don't know it to be true. So B is not a good choice and that's the laggard here. MIN-FORMULA, well, is in PSPACE, and anything in PSPACE is reducible to TQBF, so this is certainly true. And same thing for NP with TQBF and coNP with TQBF. Once you have TQBF, you're going to get all of PSPACE. And as we pointed out, this is going to be equal as well. So why don't we end here. And I think that's my last slide. Oh no, there's my summary here. This is what we've done. And I will send you all off on your way. How does the interaction between the Turing machine and the oracle look? Yeah, I didn't define exactly how the machine interacts with an oracle. You can imagine having a separate tape where it writes the oracle question and then goes into a special query state. You can formalize it however you like. They're all going to be-- any reasonable way of formalizing it is going to come up with the same notion in the end. It does show that P with a TQBF oracle equals PSPACE. Yes, that is correct. Good point. Why do we need the oracle to be TQBF? Wouldn't SAT also work because it could solve any NP problem? So you're asking, does P with a SAT oracle equal NP with a SAT oracle? Not known. And believed not to be true, but we don't have a compelling reason for that. No one has any idea how to do that. Because, for example, we showed the complement of MIN-FORMULA is in NP with a SAT oracle. But no one knows how to do-- because there's sort of two levels of non-determinism there. There's guessing the smaller formula, and then guessing again to check the equivalence. And they really can't be combined, because one of them is sort of an exist type guessing, the other one is kind of a for all type guessing. No one knows how to do that in polynomial time with a SAT oracle. Generally believed that they're not the same. In the check-in, why was B false? B is the same question. Does NP with a SAT oracle equal coNP with a SAT oracle? I'm not saying it's false, it's just not known to be true. It doesn't follow from anything that we've shown so far. And I think that would be something that-- well, I guess it doesn't immediately imply any famous open problem. I wouldn't necessarily expect you to know that it's an unsolved problem, but it is. Could we have oracles for undecidable language? Absolutely. Would it be helpful? Well, if you're trying to solve an undecidable problem, it would be helpful. But people do study that. In fact, the original concept of oracles was presented, was derived in the computability theory. And a side note, you can talk about reducibility. No, I don't want to even go there. Too complicated. What is not known to be true? What is not known to be true is that NP with a SAT oracle equals coNP with a SAT oracle, or equals P with a SAT oracle. Nothing is known except the obvious relations among those. Those are all unknown, and just not known to be true or false. Is NP with a SAT oracle equal to NP? Probably not. NP with a SAT oracle, for one thing, contains coNP. Because it's even more powerful. We pointed out that P with a SAT oracle contains coNP. And so NP with a SAT oracle is going to be at least as good. And so it's going to contain coNP. And so, probably not going to be equal to NP unless shockingly unexpected things happen in our complexity world.","71.92152404785156","8","DPRSearchEngine","N32bnUliSzo.en-j3PyPqV-e1s_9_mp4","N32bnUliSzo.en-j3PyPqV-e1s","18.404J","22"
"74","What is a tableau in the context of nondeterministic computation, and how does it relate to an accepting branch and computation history?"," 
 
 
  
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
Computation with Oracles 
Let ! be any language. 
Defn: A TM "" with oracle for !, written ""#, is a TM equipped 
with a “black box” that can answer queries “is $ ∈!?” for free. 
Example: A TM with an oracle for &!' can decide all ( ∈ NP in polynomial time. 
Defn: P# = ( ( is decidable in polynomial time with an oracle for !} 
Thus NP ⊆ P+#, 
NP = P+#,? Probably No because coNP ⊆ P+#, 
Defn: NP# = ( ( is decidable in nondeterministic polynomial time with an oracle for !} 
Recall MIN-FORMULA = 7 7 is a minimal Boolean formula } 
Example: MIN−FORMULA ∈ NP+#, 
“On input 7 
1. Guess shorter formula 9 
2.  Use &!' oracle to solve the coNP problem: 7 and 9 are equivalent 
3. Accept if 7 and 9 are equivalent. Reject if not.” 
8 
","71.9010009765625","9","DPRSearchEngine","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_8_pdf","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22","18.404J","22"
"74","What is a tableau in the context of nondeterministic computation, and how does it relate to an accepting branch and computation history?"," 
 
 
 
 
 
   
  
 
  
 
 
   
 
 
  
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
  
 
 
 
 
 
 
Check-in 8.2 
Recall the Queue Automaton (QA) defined in Pset 2. 
It is similar to a PDA except that it is deterministic 
and it has a queue instead of a stack. 
Let !QA = { &, ( | & is a QA and & accepts (} 
Is !QA decidable? 
(a) Yes, because QA are similar to PDA and !PDA is decidable. 
(b) No, because “yes” would contradict results we now know. 
(c) We don’t have enough information to answer this question. 
8 
Check-in 8.2 
","71.70523071289062","10","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_8_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"75","What is one of the conditions of the Pumping Lemma for context-free languages (CFLs) concerning the substring x of a string s?"," 
 
 
 
 
   
 
 
 
 
  
 
 
   
 
 
 
   
 
   
  
  
  
 
 
  
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Proving languages not Context Free 
Let ! = 0$1$2$ ' ≥0}. We will show that ! isn’t a CFL. 
Pumping Lemma for CFLs: For every CFL *, there is a + 
such that if , ∈* and , ≥+ then , = ./012 where 
1) ./30132 ∈ * for all 4 ≥0 
2) /1 ≠ ε 
3) /01 ≤+ 
, = 
≥+ 
. 
/
0 
1
2 
∈* 
Informally: All long strings in * are pumpable and stay in *. 
∈* 
1 
2
. 
/ 
/
≤+ 
0 
1 
3 
","76.80545806884766","1","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_3_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"75","What is one of the conditions of the Pumping Lemma for context-free languages (CFLs) concerning the substring x of a string s?"," 
 
 
 
 
 
   
   
 
 
  
 
 
  
  
 
 
  
  
 
 
 
 
 
 
 
 
  
  
 
   
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Pumping Lemma – Proof 
Pumping Lemma for CFLs:   For every CFL !, there is a "" 
such that if # ∈! and # ≥ "" then # = '()*+ where 
1) '(,)*,+ ∈ ! for all - ≥0 
2) (* ≠ ε 
E
3) ()* ≤ "" 
Proof by picture: 
R
R
E 
R 
E 
R 
'
( 
*
+ 
R
R 
)
(
) 
* 
Generates '(()**+ 
' 
Generates ')+ 
+ 
= '(1)*1+ 
= '(2)*2+
# = 
' 
(
) 
*
+ 
Long # → 
“cutting and pasting” argument 
tall parse tree 
4 
","76.31746673583984","2","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_4_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"75","What is one of the conditions of the Pumping Lemma for context-free languages (CFLs) concerning the substring x of a string s?","Satisfiability Problem
Defn: A Boolean formula ! has Boolean variables (TRUE/FALSE values) 
and Boolean operations AND (∧), OR (∨), and NOT (¬). 
Defn: ! is satisfiable if ! evaluates to TRUE for some assignment to its variables.
Sometimes we use 1 for True and 0 for False.
Example:  Let ! =
& ∨' ∧(& ∨')
(Notation:  & means ¬&)  
Then ! is satisfiable  (x=1, y=0)  
Defn:  *+, =
!
! is a satisfiable Boolean formula}
Theorem (Cook, Levin 1971):    *+, ∈P  →P = NP 
Proof method:  polynomial time (mapping) reducibility
Check-in 14.3
Check-in 14.3
Is  *+, ∈NP?
(a) Yes.
(b) No. 
(c) I don’t know.
(d) No one knows.
11
","74.95507049560547","3","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_11_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"75","What is one of the conditions of the Pumping Lemma for context-free languages (CFLs) concerning the substring x of a string s?","And proving languages not regular. The way we're going to prove languages are not regular is by introducing a method called the pumping lemma. And the overarching plan at the pumping lemma, without getting into the specifics of it, is to say-- show that-- that lemma says all regular languages have a certain property, which we will describe. And so to show a language is not regular you simply show the language doesn't have that property, because all regular languages have to have that property. And so by showing a language fails to have the property, it could not be regular. That's the plan. Now, the property itself is a little complicated to describe, but not too bad. I'll try to unpack it for you. But first, let's look at the statement of the lemma, which says that whenever you have a regular language-- let's call it A. So for every regular language A there's always a special value called the pump-- a number. p, we'll call it-- called the pumping length. It's a special number. And it's-- and that length tells you that whenever a string is in that language and it's longer than that length, then something special happens. You can take that string and you can modify it, and you still stay in the language. So anything that's longer than that special length can be modified in a certain way, and you still stay in the language. So let's look at the actual statement of the lemma. So there is a number p such that if s is a string in the language and it's longer than p, or at least of length p, then you can take s and you can cut it up into three pieces-- x, y, and z-- so that's just breaking s into three pieces-- where you can take that middle piece, repeat it as many times as you like, and you still stay in the language. That's the-- what the pumping lemma is saying. And there's a bunch of other conditions here too. But the spirit of the pumping lemma says, whenever you have a regular language there's some cutoff such that all strings longer than that cutoff can be what we call pumped. You can take that string, you can find a section somewhere in the middle of that string or somewhere-- you cut it up in three pieces, you take that center piece, and you can repeat it. You can pump it up. And by repeating that string and repeating that piece, the string gets longer and longer. But you still stay in the language. That's the special property that all regular languages have. So in an informal way-- and we'll do-- I'll try to help you get the feeling for this. Informally, it says that if you have a regular language, then every long string-- so a long is by-- informal way of saying bigger than this value p. Every long string in the language can be pumped. And this result still stays in the language. And by ""pumped"" means I can cut the string into three pieces and repeat that middle piece as many times as I want. That's what I mean by pumping a string.","74.55380249023438","4","DPRSearchEngine","KAySmSEGc9U.en-j3PyPqV-e1s_9_mp4","KAySmSEGc9U.en-j3PyPqV-e1s","18.404J","3"
"75","What is one of the conditions of the Pumping Lemma for context-free languages (CFLs) concerning the substring x of a string s?","  
  
  
  
 
 
 
  
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Equivalence of CFGs and PDAs 
Theorem: ! is a CFL iff* some PDA recognizes ! 
Done. 
In book.  You are responsible for knowing 
it is true, but not for knowing the proof. 
* “iff” = “if an only if” means the implication goes both ways. 
So we need to prove both directions: forward (→) and reverse (←). 
Check-in 4.3 
Is every Regular Language also 
a Context Free Language? 
(a) Yes 
(b) No 
(c) Not sure 
Check-in 4.3 
10 
","74.26649475097656","5","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_10_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"75","What is one of the conditions of the Pumping Lemma for context-free languages (CFLs) concerning the substring x of a string s?","   
 
  
 
 
 
 
 
 
 
  
 
 
 
 
 
  
  
 
   
  
  
 
  
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
 
  
 
  
 
TRUE
FALSE
Example: !""#$ 
Defn: A quantified Boolean formula (QBF) is a Boolean formula 
with leading exists (∃&) and for all (∀&) quantifiers. All variables 
must lie within the scope of a quantifier. 
A QBF is TRUE or FALSE. 
Check-in 17.2 
Examples: () = ∀& ∃+ & ∨+ ∧ & ∨+ 
(. = ∃+ ∀& & ∨+ ∧ & ∨+ 
How is 23! a special case of !""#$? 
(a) Remove all quantifiers. 
Defn: !""#$ = ( ( is a QBF that is TRUE} 
(b) Add ∃ and ∀ quantifiers. 
Thus () ∈ !""#$ and (. ∉ !""#$. 
(c) Add only ∃ quantifiers. 
Theorem: !""#$ ∈ PSPACE 
(d) Add only ∀ quantifiers. 
5 
Check-in 17.2 
","74.2100830078125","6","DPRSearchEngine","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17_5_pdf","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17","18.404J","17"
"75","What is one of the conditions of the Pumping Lemma for context-free languages (CFLs) concerning the substring x of a string s?","Often, the challenge in applying the pumping lemma in either case that we've seen involves choosing that string that you need to pump, that you're going to pump. So you have to choose s in F, which is longer than p, which s to go with. So you might try this one, first glance. Here is a string that's in the language, because it's two copies of the string 0 to the p1 0 to-- and then 0 to the p1. So that's in the language, but it's a bad choice. Before I get ahead of myself, let's draw a picture of s, which I think is always helpful to see. So here is runs of 0's and then a 1, runs of 0's and then a 1. Why is this a bad choice? Because you can pump that string and you remain in the language. There is a way to cut that string up and you'll stay in the language. And the way to cut it up is to let the x be just that substring which is just the 1. And the v and y can be a couple of 0's or a single 0 on either side of that 1. And now that's going to be a small vxy. But if you repeat v and y, you're going to stay in the language, because you'll just be adding 0's here. You'll be adding same number of 0's there. And then you're going to have a string which still looks like ww. And you'll still be in the language. So that means that cutting it up doesn't get you out of the language under pumping. And the fact is that that's a bad choice for s, because there is that way of cutting it up. So you have to show there's no way-- you don't get to pick the way to cut it up. You have to show that there is no way to cut it up in order to violate the pumping lemma. So if instead you use the string 0 to the p, 1 to the p, 0 to the p, 1 to the p-- so this is 0's followed by 1's followed by 0's followed by 1's, all the same number of them-- that can't be pumped satisfying the three conditions. And just going through that-- now if you try to break it up, you're going to lose. Or the lemma is going to lose. You're going to be happy, but the lemma is not going to be happy, because it's not going-- it's going to violate the condition. Condition three says vxy is not-- doesn't span too much, and in fact, can't span two runs of 0's or two runs of 1's. It's just not big enough, because they're more than p things-- they're p things apart. And this one string, this string vxy is only p long. And so therefore, if you repeat v and y, you're going to have two runs of 0's or two 1's that have unequal length. And now that's not going to be the form ww. You're going to be out of the language. So I hope that's-- you've got a little practice with that. I think we're at our break. And I will see you back here in five minutes, if I can get my timer launched here. OK, so see you soon. This is a good time, by the way, to message me or the TAs. And I'll try to be looking for if you have any questions. In the pumping lemma, can x-- yeah, x can be epsilon in the pumping lemma. x can be epsilon. y can be epsilon, but x and y cannot both be epsilon, because then, when you pump, you'll get nothing new. Technically, v and y can include both 0's and 1's. Yeah, v and y can include both 0's and 1's. So let me try to put that back, if that's will-- so v and y can have both 0's and 1's, but they can't have 0's from two different blocks. And you can't have 1's from two different blocks. So what's going to happen is either you're going to get things out of order when you repeat-- like, a v has both 0's and 1's in it. When you repeat v, you're going to have 0's and 1's, and 0's and 1's, and 0's and 1's. That's clearly out of the language, so that's no good. Your only hope is to have v to be sticking only inside the 0's and y to be sticking only inside 0's or only inside 1's. But now, if you repeat that and just look at what you're going to get, you're going to have a string which is going to be-- if you try to cut that string in half, it's not going to be of the right form. It's not going to be two copies of the same string, because it's going to have a run of 0's followed by a longer or shorter run of 0's, or a run of 1's followed by another run of 1's of unequal length. So there is no way this can be two strings, two copies of the same string, because that's what you required. F has to be two copies of the same string to be in the language. OK, let me just see where-- we're running out of time here. Let me just put my timer here. We've only got 30 seconds. And I'm sorry I'm not getting to answer all the questions here. OK, we are done with our break. It's going to come back. And now we're shifting gears in a major way, because in a sense, everything we've","74.11277770996094","7","DPRSearchEngine","IycOPFmEQk8.en-j3PyPqV-e1s_11_mp4","IycOPFmEQk8.en-j3PyPqV-e1s","18.404J","5"
"75","What is one of the conditions of the Pumping Lemma for context-free languages (CFLs) concerning the substring x of a string s?"," 
 
 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) 
General Unweighted 
BFS 
|V | + |E|
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Non-negative Dijkstra 
Bellman-Ford 
|V | log |V | + |E|
General Any 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 14: Johnson’s Algorithm 
Lecture 14: Johnson’s Algorithm 
Previously 
|V | · |E| 
All-Pairs Shortest Paths (APSP) 
• Input: directed graph G = (V, E) with weights w : E → Z 
• Output: δ(u, v) for all u, v ∈ V , or abort if G contains negative-weight cycle 
• Useful when understanding whole network, e.g., transportation, circuit layout, supply chains... 
• Just doing a SSSP algorithm |V | times is actually pretty good, since output has size O(|V |2) 
– |V | · O(|V | + |E|) with BFS if weights positive and bounded by O(|V | + |E|) 
– |V | · O(|V | + |E|) with DAG Relaxation if acyclic 
– |V | · O(|V | log |V | + |E|) with Dijkstra if weights non-negative or graph undirected 
– |V | · O(|V | · |E|) with Bellman-Ford (general) 
• Today: Solve APSP in any weighted graph in |V | · O(|V | log |V | + |E|) time 
","73.81563568115234","8","DPRSearchEngine","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14_1_pdf","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14","6.006","14"
"75","What is one of the conditions of the Pumping Lemma for context-free languages (CFLs) concerning the substring x of a string s?"," 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Generalized NFA 
Defn: A Generalized Nondeterministic Finite Automaton (GNFA) is 
similar to an NFA, but allows regular expressions as transition labels 
a
a ∗ b ∗ 
ab
!1 
#1 
#2 
For convenience we will assume: 
b 
ε 
- One accept state, separate from the start state 
∅ 
- One arrow from each state to each state, except 
a ∪ b 
aab 
a) only exiting the start state 
#3 
#4 
b) only entering the accept state 
ε 
We can easily modify a GNFA to have this special form. 
3 
","73.8003921508789","9","DPRSearchEngine","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3_3_pdf","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3","18.404J","3"
"75","What is one of the conditions of the Pumping Lemma for context-free languages (CFLs) concerning the substring x of a string s?",";
/
def testGreedy(items, constraint, keyFunction):
taken, val = greedy(items, constraint, keyFunction)
print('Total value of items taken =', val)
for item in taken:
print('   ', item)
	

'
","73.42523193359375","10","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_25_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"76","What is an unprovable mathematical statement mentioned in the content?","What are oracles? Oracles are a simple thing. But they are a useful concept for a number of reasons. Especially because they're going to tell us something interesting about methods, which may or may not be useful for proving the P versus NP question, when someday somebody hopefully does that. What is an oracle? An oracle is free information you're going to give to a Turing machine, which might affect the difficulty of solving problems. And the way we're going to represent that free information is, we're going to allow the Turing machine to test membership in some specified language, without charging for the work involved. I'm going to allow you have any language at all, some language A. And say a Turing machine with an oracle for A is written this way, M with a superscript A. It's a machine that has a black box that can answer questions. Is some string, which the machine can choose, in A or not? And it gets that answer in one step, effectively for free. So you can imagine, depending upon the language that you're providing to the machine, that may or may not be useful. For example, suppose I give you an oracle for the SAT language. That can be very useful. It could be very useful for deciding SAT, for example. Because now you don't have to go through a brute force search to solve SAT. You just ask the oracle. And the oracle is going to say, yes it's satisfiable, or no it's not satisfiable. But you can use that to solve other languages too, quickly. Because anything that you can do in NP, you can reduce to SAT. So you can convert it to a SAT question, which you can then ship up to the oracle, and the oracle is going to tell you the answer. The word ""oracle"" already sort of conveys something magical. We're not really going to be concerned with the operation of the oracle, so don't ask me how does the oracle work, or what does it correspond to in reality. It doesn't. It's just a mathematical device which provides this free information to the Turing machine, which enables it to compute certain things. It turns out to be a useful concept. It's used in cryptography, where you might imagine the oracle could provide the factors to some number, or the password to some system or something. Free information. And then what can you do with that? So this is a notion that comes up in other places. If we have an oracle, we can think of all of the things that you can compute in polynomial time relative to that oracle. So that's what we-- the terminology that people usually use is sometimes called relativism, or computation relative to having this extra information. So P with an A oracle is all of the language that you can decide in polynomial time if you have an oracle for A. Let's see. Yeah. Somebody's asking me, is it really free or does it cost one unit? Even just setting up the oracle and writing down the question to the oracle is going to take you some number of steps. So you're not going to be able do an infinite number of oracle calls in zero time. So charging one step or zero steps, not going to make a difference. Because you still have to formulate the question. As I pointed out, P with a SAT oracle-- so all the things you do in polynomial time with a SAT oracle includes NP. Does it perhaps include other stuff? Or does it equal NP? Would have been a good check-in question, but I'm not going to ask that. In fact, it seems like it contains other things too. Because co-NP is also contained within P, given a SAT oracle. Because the SAT oracle answer is both yes or no, depending upon the answer. So if the formula is unsatisfiable, the oracle is going to say no, it's not in the language. And now you can do the complement of the SAT problem as well. The unsatisfiability problem. So you can do all of co-NP in the same way. You can also define NP relative to some oracle. So all the things you can do with a non-deterministic Turing machine, where all of the branches have separately access. And they can ask multiple questions, by the way, of the oracle. Independently. Let's do another, a little bit of a more challenging example. The MIN-FORMULA language, which I hope you remember from your homework. So those are all of the formulas that do not have a shorter equivalent formula. They are minimal. You cannot make a smaller formula that's equivalent that gives you the same Boolean function. So you showed, for example, that that language is in P space, as I recall. And there was some other-- you had another two problems about that language. The complement of the MIN-FORMULA problem is in NP with a SAT oracle. So mull that over for a second and then we'll see why. Here's an algorithm, in NP with a SAT oracle algorithm. So in other words, now I want to kind of implement that strategy, which I argued in the homework problem was not legal. But now that I have the SAT oracle, it's going to make it possible where before it was not possible. So let's just understand what I mean by that. If I'm trying to do the non minimal formulas, namely the formulas that do have a shorter equivalent formula. I'm going to guess that shorter formula, called psi. The challenge before was testing whether that shorter formula was actually equivalent to phi. Because that's not obviously doable in polynomial time. But the equivalence problem for formulas is a co-NP problem. Or if you like to think about it the other way, any formula in equivalence is an NP problem, because you just have to-- the witness is the assignment on which they disagree. So two formulas are equivalent if they never disagree. And so that's a co-NP problem. A SAT oracle can solve a co-NP problem. Namely, the equivalence of the two formulas, the input formula and the one that you now deterministically guessed. And if it turns out that they are equivalent, a smaller formula is equivalent to the input formula, you know the input formula is not minimal. And so you can accept. And if it gets the wrong formula, it turns out not to be equivalent, then you reject on that branch of the non-determinism, just like we did before. And if the formula really was minimal, none of the branches is going to find a shorter equivalent formula. So that's why this problem here is in NP with a SAT oracle. So now we're going to try to investigate this on my-- we're getting near the end of the lecture. We're going to look at problems like, well, suppose I compare P with a SAT oracle and NP with a SAT oracle. Could those be the same? Well, there's reasons to believe those are not the same. But could there be any A where P with A oracle is the same as NP with an A oracle? It seems like no, but actually that's wrong. There is a language, there are languages for which NP with that oracle and P with that oracle are exactly the same. And that actually is an interest-- it's not just a curiosity, it actually has relevance to strategies for solving P versus NP. Hopefully I'll be able to have time to get to. Can we think of an oracle like a hash table? I think hashing is somehow different in spirit. I understand there's some similarity there, but I don't see the-- hashing is a way of finding sort of a short name for objects, which has a variety of different purposes why you might want to do that. So I don't really think it's the same. Let's see, an oracle question, OK, let's see. How do we use SAT oracle to solve whether two formulas are equivalent? OK, this is getting back to this point. How can we use a SAT oracle to solve whether two formulas are equivalent? Well, we can use a SAT oracle to solve any NP problem, because it's reducible to SAT. In other words-- P with a SAT oracle contains all of NP, so you have to make sure you understand that part. If you have the clique problem, you can reduce. If I give you a clique problem, which is an NP problem, and I want to use the oracle to test if the formula-- if the graph has a clique, I reduce that problem to a SAT problem using the Cook-Levin theorem. And knowing that a clique of a certain size is going to correspond to having a formula which is satisfiable, now I can ask the oracle. And if I can do NP problems, I can do co-NP problems, because P is a deterministic class. Even though it has an oracle, it's still deterministic. It can invert the answer. Something that non-deterministic machines cannot necessarily do. So I don't know, maybe that's-- let's move on. So there's an oracle where P to the A equals NP to the A, which kind of seems kind of amazing at some level. Because here's an oracle where the non-determinism-- if I give you that oracle, non-determinism doesn't help. And it's actually a language we've seen. It's TQBF. Why is that? Well, here's the whole proof. If I have NP with a TQBF oracle. Let's just check each of these steps. I claim I can do that with a non-deterministic polynomial space machine, which no longer has an oracle. The reason is that, if I have polynomial space, I can answer questions about TQBF without needing an oracle. I have enough space just to answer the question directly myself. And I use my non-determinism here to simulate the non-determinism of the NP machine. So every time the NP machine branches non-deterministically, so do I. Every time one of those branches asks the oracle a TQBF question, I just do my polynomial space algorithm to solve that question myself. But now NPSPACE equals PSPACE by Savitch's theorem. And because TQBF is PSPACE complete, for the very same reason that a SAT oracle allows me to do every NP problem, a TQBF problem allows me to do every PSPACE problem. And so I get NP contained within P for a TQBF oracle. And of course, you get the containment the other way immediately. So they're equal. What does that have to do with-- somebody said-- well, I'll just-- I don't want to run out of time. So I'll take any questions at the end. What does this got to do with the P versus NP problem? OK, so this is a very interesting connection. Remember, we just showed through a combination of today's lecture and yesterday's lecture, and I guess Thursday's lecture, that this problem, this equivalence problem, is not in PSPACE, and therefore it's not in P, and therefore it's intractable. That's what we just did. We showed it's complete for a class, which is provably outside of P, provably bigger than P. That's the kind of thing we would like to be able to do to separate P and NP. We would like to show that some other problem is not in P. Some other problem is intractable. Namely, SAT. If we could do SAT, then we're good. We've solved P and NP. So we already have an example of being able to do that. Could we use the same method? Which is something people did try to do many years ago, to show that SAT is not in P. So what is that method really? The guts of that method really comes from the hierarchy there. That's where you were actually proving problems that are hard. You're getting this problem with through the hierarchy construction that's provably outside of PSPACE. And outside of P. That's a diagonalization. And if you look carefully at what's going on there-- so we're going to say, no, we're not going to be able to solve SAT, show SAT's outside of P in the same way. And the reason is, suppose we could. Well the hierarchy theorems are proved by diagonalization. What I mean by that is that in the hierarchy theorem, there's a machine D, which is simulating some other machine, M. To remember what's going on there, remember that we made a machine which is going to make its language different from the language of every machine that's running with less space or with less time. That's how D was defined. It wants to make sure its language cannot be done in less space. So it makes sure that its language is different. It simulates the machines that use less space, and does something different from what they do. Well, that simulation-- if we had an oracle, if we're trying to show that if we provide both a simulator and the machine being simulated with the same oracle, the simulation still works. Every time the machine you're simulating asks a question, the simulator has the same oracle so it can also ask the same question, and can still do the simulation. So in other words, if you could prove P different from NP using basically a simulation, which is what a diagonalization is, then you would be able to prove that P is different from NP for every oracle. So if you can prove P different from NP by a diagonalization, that would also immediately prove that P is different from NP for every oracle. Because the argument is transparent to the oracle. If you just put the oracle down, everything still works. But-- here is the big but, it can't be that-- we know that P A is-- we know this is false. We just exhibit an oracle for which they're equal. It's not the case that P is different from NP for every oracle. Sometimes they're equal, for some oracles. So something that's just basically a very straightforward diagonalization, something that's at its core is a diagonalization, is not going to be enough to solve P and NP. Because otherwise it would prove that they're different for every oracle. And sometimes they're not different, for some oracles. That's an important insight for what kind of a method will not be adequate to prove P different from NP. And this comes up all the time. People who propose hypothetical solutions that they're trying to show P different from NP. One of the very first things people ask is, well, would that argument still work if you put an oracle there. Often it does, which points out there was a flaw. Anyway, last check in. So this is just a little test of your knowledge about oracles. Why don't we-- in our remaining minute here. Let's say 30 seconds. And then we'll do a wrap on this, and I'll point out which ones are right. Oh boy, we're all over the place on this one. You're liking them all. Well, I guess the ones that are false are lagging slightly. OK, let's conclude. Did I give you enough time there? Share results. So, in fact-- Yeah, so having an oracle for the complement is the same as having an oracle. So this is certainly true. NP SAT equal coNP SAT, we have no reason to believe that would be true, and we don't know it to be true. So B is not a good choice and that's the laggard here. MIN-FORMULA, well, is in PSPACE, and anything in PSPACE is reducible to TQBF, so this is certainly true. And same thing for NP with TQBF and coNP with TQBF. Once you have TQBF, you're going to get all of PSPACE. And as we pointed out, this is going to be equal as well. So why don't we end here. And I think that's my last slide. Oh no, there's my summary here. This is what we've done. And I will send you all off on your way. How does the interaction between the Turing machine and the oracle look? Yeah, I didn't define exactly how the machine interacts with an oracle. You can imagine having a separate tape where it writes the oracle question and then goes into a special query state. You can formalize it however you like. They're all going to be-- any reasonable way of formalizing it is going to come up with the same notion in the end. It does show that P with a TQBF oracle equals PSPACE. Yes, that is correct. Good point. Why do we need the oracle to be TQBF? Wouldn't SAT also work because it could solve any NP problem? So you're asking, does P with a SAT oracle equal NP with a SAT oracle? Not known. And believed not to be true, but we don't have a compelling reason for that. No one has any idea how to do that. Because, for example, we showed the complement of MIN-FORMULA is in NP with a SAT oracle. But no one knows how to do-- because there's sort of two levels of non-determinism there. There's guessing the smaller formula, and then guessing again to check the equivalence. And they really can't be combined, because one of them is sort of an exist type guessing, the other one is kind of a for all type guessing. No one knows how to do that in polynomial time with a SAT oracle. Generally believed that they're not the same. In the check-in, why was B false? B is the same question. Does NP with a SAT oracle equal coNP with a SAT oracle? I'm not saying it's false, it's just not known to be true. It doesn't follow from anything that we've shown so far. And I think that would be something that-- well, I guess it doesn't immediately imply any famous open problem. I wouldn't necessarily expect you to know that it's an unsolved problem, but it is. Could we have oracles for undecidable language? Absolutely. Would it be helpful? Well, if you're trying to solve an undecidable problem, it would be helpful. But people do study that. In fact, the original concept of oracles was presented, was derived in the computability theory. And a side note, you can talk about reducibility. No, I don't want to even go there. Too complicated. What is not known to be true? What is not known to be true is that NP with a SAT oracle equals coNP with a SAT oracle, or equals P with a SAT oracle. Nothing is known except the obvious relations among those. Those are all unknown, and just not known to be true or false. Is NP with a SAT oracle equal to NP? Probably not. NP with a SAT oracle, for one thing, contains coNP. Because it's even more powerful. We pointed out that P with a SAT oracle contains coNP. And so NP with a SAT oracle is going to be at least as good. And so it's going to contain coNP. And so, probably not going to be equal to NP unless shockingly unexpected things happen in our complexity world.","73.52137756347656","1","DPRSearchEngine","N32bnUliSzo.en-j3PyPqV-e1s_9_mp4","N32bnUliSzo.en-j3PyPqV-e1s","18.404J","22"
"76","What is an unprovable mathematical statement mentioned in the content?","Satisfiability Problem
Defn: A Boolean formula ! has Boolean variables (TRUE/FALSE values) 
and Boolean operations AND (∧), OR (∨), and NOT (¬). 
Defn: ! is satisfiable if ! evaluates to TRUE for some assignment to its variables.
Sometimes we use 1 for True and 0 for False.
Example:  Let ! =
& ∨' ∧(& ∨')
(Notation:  & means ¬&)  
Then ! is satisfiable  (x=1, y=0)  
Defn:  *+, =
!
! is a satisfiable Boolean formula}
Theorem (Cook, Levin 1971):    *+, ∈P  →P = NP 
Proof method:  polynomial time (mapping) reducibility
Check-in 14.3
Check-in 14.3
Is  *+, ∈NP?
(a) Yes.
(b) No. 
(c) I don’t know.
(d) No one knows.
11
","73.27529907226562","2","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_11_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"76","What is an unprovable mathematical statement mentioned in the content?"," 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
  
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
18.404/6.840 Lecture 12 
Last time: 
- Self-reproducing machines and The Recursion Theorem 
- Applications: 
a) New proof that !TM is undecidable 
b) $%&TM is T-unrecognizable (and so is any infinite subset of $%&TM) 
c) True but unprovable statements 
Today: (Sipser §7.1) 
- Introduction to Complexity Theory 
- Complexity classes; the Class P 
1 
","72.23577117919922","3","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_1_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"76","What is an unprovable mathematical statement mentioned in the content?","So E TM is the emptiness problem for Turing machines. Is this language empty? I'm just going to give you a machine. I want to know, is this language empty or not? Does it accept something or is this language empty? That's going to be undecidable, no surprise, proof by contradiction. And we're going to show that A TM is reducible to E TM. So these things often take a very similar form. And I'm going to try to use the same form. So if you're feeling shaky on it, at least you'll get the form of the way the solution goes and that will help you maybe plug-in to solve problems, OK.","72.23566436767578","4","DPRSearchEngine","N28g_YBXY8Y.en-j3PyPqV-e1s_7_mp4","N28g_YBXY8Y.en-j3PyPqV-e1s","18.404J","9"
"76","What is an unprovable mathematical statement mentioned in the content?","This is just another word for being not in R. OK, and next thing I'd like to do is prove to you that most decision problems are uncomputable, or sketcher proof. So remember, decision problems are problems where the answer is just yes or no. This is a very special kind of problem. And even those, almost all of them, cannot be solved. So halting is an example of a problem we want-- we can't solve. This whole class, this 006, is about problems we can solve. But today I'm going to show you that, actually, those are in the minority. Most problems cannot be computed. This is very strange and also a little depressing. So we'll talk more about that in a moment. First let me argue why this is the case. So I'm going to be a little informal about what exactly is a computer program and what exactly is a decision problem. But roughly, all I need to do, the only level of precision I need is just to count how many are there. What is a computer program? Well, it's usually a file. What's a file? It's like a string of characters. What's a character? It's a string of bits. So a program is just, in the end, a string of bits, finite string of bits. We all understand that. Whatever language you define, in the end, every program is just a string of bits. And a string of bits we can translate into a number. So we can convert between strings of bits and numbers. When I say number, I mean what's usually called a natural number or a non-negative integer. This is usually represented by bold board bold-- blackboard bold capital N. So this is just 0, 1, 2, and so on. Now, what about decision problems? Decision problem is a specification of what we want to solve. So we can think of it as saying, for every input, is the answer yes or no? That's literally what a decision problem is. The only question is, what is an input? And we've talked about inputs and the size of inputs. And there's lots of different ways to measure them. But in the end, we can think of an input as a string of bits also. It's just a file. So a decision problem is a function from inputs to yes or no. And inputs we're going to say, well, that's a string of bits, which we can associate with a number in N. So here we can start to tie things together. So in other words, a program is a finite string of bits, and a problem is, in some sense, an infinite string of bits because there are infinitely many possible inputs. And for each of them, we specify yes or no. So this is basically an infinite string of bits. So we can imagine 011010001110, infinitely. Just some-- for every string of bits, we can say, OK, if your input is the number 0, here's the answer-- no. If your input is the number 1, then the answer is yes. If your input is the number 2, your answer is yes, and so on down this line. Every infinite string of bits corresponds to exactly one decision problem, which specifies for every possible input integer, which corresponds to a string of bits, what is the answer, yes or no? So this may seem subtle, or it may seem like not a big deal. This is a finite string of bits. This is an infinite string of bits. But mathematics has well studied this problem. And infinite strings of bits, there are very many of them, infinitely many. It's not surprising. There are also infinitely many integers. So maybe it doesn't seem that deep. But there's a difference in infinitude. Programs and integers are countably infinite. And infinite strings of bits are what's called uncountable. I think the most intuitive way to see this is, an infinite string of bits, if I put a decimal or a binary point in front, this encodes a real number between 0 and 1. So this is roughly a real number in 01. And when I'm writing approximately equal here, this really goes in both directions. Given a decision problem, I can define a string of bits, of course giving me the answer for all inputs. And I can convert that into a real number between 0 and 1. But also the other direction, if I take any real number, that is a corresponding decision problem. These are 1 to 1 bijection between them. And the bad news is, real numbers are uncountable, and natural numbers are countable, which means there's a lot more of these than there are these. So one way you might phrase this is, informally, the number of natural numbers is way smaller than the number of real numbers. And so from that, we derive that most problems are unsolvable, because every program solves exactly one decision problem. We can also run a program, conceptually, on all possible inputs, and we will figure out what function at solving. And if we don't allow random numbers in our program, which I'm not here, then every program solves exactly one decision problem. Possibly, it's even worse for us because multiple programs probably solve the same decision problem. They're just-- they add irrelevant lines of code or they don't do anything different. Or you run Bellman-Ford versus running Bellman-Ford five times, you'll get the same result. And that's actually the bad direction for us. We'd like to know whether there is a program that solves every decision problem. And because there are only this many programs and this many decision problems, it just-- there aren't enough to go around.","72.20260620117188","5","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_4_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"76","What is an unprovable mathematical statement mentioned in the content?"," 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
  
 
 
 
 
 
 
   
  
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
  
  
 
 
 
  
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
Intro to Mathematical Logic 
Goal: A mathematical study of mathematical reasoning itself. 
Formally defines the language of mathematics, mathematical truth, and provability. 
Gödel’s First Incompleteness Theorem: 
In any reasonable formal system, some true statements are not provable. 
Proof: We use two properties of formal proofs: 
1) Soundness: If ! has a proof "" then ! is true. 
2) Checkability: The language "", ! "" is a proof of statement !} is decidable. 
Checkability implies the set of provable statements {〈!〉| ! has a proof} is T-recognizable. 
SImilarly, if we can always prove ', ( ∈ *TM when it is true, then *TM is T-recognizable (false!). 
Therefore, some true statements of the form ', ( ∈ *TM are unprovable. 
Next, we use the Recursion Theorem to give a specific example of a true but unprovable statement. 
11 
","71.52886962890625","6","DPRSearchEngine","779043ea724131d008eae652d703938f_MIT18_404f20_lec11_11_pdf","779043ea724131d008eae652d703938f_MIT18_404f20_lec11","18.404J","11"
"76","What is an unprovable mathematical statement mentioned in the content?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
Use our knowledge that !TM is undecidable to show other 
problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
10 
","71.15953826904297","7","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_10_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"76","What is an unprovable mathematical statement mentioned in the content?","! ""
! #
! #
0
1
0 
1
0
1
0
1
Symbolic Execution
Leave the ! $ as variables and obtain an expression in the ! $
for the output of the BP. 
1
1 −! ""
! ""
1 −! ""
1 −! #
+ (! "" ) ! #
(1 −! "" ) 1 −! #
1 −! "" (x#)
(! "" ) ! #
(! "" ) 1 −! #
1 −! ""
x#
+ (! "" ) 1 −! #
! $
0 1
+
+(1 −! $)
+! $
+""
+#
+,
+"" + +# + +,
Recall 
labeling rules:
1 −! ""
! ""
= output
=
1 −! ""
x#
,
1 −! ,
! .
⋯(1 −! 0 )
+
! ""
! #
! ,
1 −! .
⋯
! 0
+
! ""
1 −! #
1 −! ,
! .
⋯
(! 0 )
⋮
+
! ""
! #
1 −! ,
! .
⋯
(! 0 )
form of 
output
Corresponds to the TRUE rows in the 
truth table of the Boolean function
Exponents ≤1
due to “read-once”
Assume read exactly once so that for each 3
(! $) or (1 −! $) appears in every row 
8
","70.52639770507812","8","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_8_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"76","What is an unprovable mathematical statement mentioned in the content?","So just remember, interactive proof systems, there are these two parties, the prover and the verifier. The prover has unlimited computational ability. I kind of model that as an army of students perhaps who can-- where we don't-- they can work all night. They can use computational resources. And the prover, however, we're not going to measure the computational power of the prover. That's unlimited. And so the prover can do things like find certificates. It can test whether things are satisfiable. It can factor numbers. We don't care. It can do whatever we'd like and there is no charge for the prover's computational demands. OK. So the setup we had was the prover and the verifier. Both see the input. The exchange of polynomial number of messages. And then the verifier accepts or rejects. And we had this notion of the probability that the verifier ends up accepting when paired with a particular prover. And what we want is that for strings in a language, that probability should be high for some prover. And for strings not in the language, that probability should be low no matter what the prover does. So there's nothing the prover can do. And the way it kind of suggests that at any prover. But whatever the prover's strategy cannot make the verifier accept with high probability. Just doesn't have enough information or it doesn't-- it's just not able to make the verifier accept with high probability. You might think of the prover as trying to make the verifier accept. So the P tilde is a crooked prover. I don't think that went down very well with everybody. So I have it here. Another way of looking at it, maybe it looks a little bit more like NP here where IP is the collection of languages where there's a verifier, just like we had. You can think of NP as having a verifier which can check certificates. Here the prover is going to be like the certificate so that for strings in the language, there's a prover which can interact with the verifier and make it accept a high probability. And you're not in the language, there is no prover, which can interact with the verifier and make the verifier accept with even more than low probability. What's important is this gap, just like with BPP, between acceptance or rejection. And that gap is there because we want to be able to use the amplification lemma. And if there was no gap, then you wouldn't be able to amplify and make the probability of acceptance extremely high when you want it to be in the language, when you're in the language, and extremely low when you're not in the language. OK. So I hope that refreshes your memory as to how that works.","70.43681335449219","9","DPRSearchEngine","eEXSv0jChO4.en-j3PyPqV-e1s_2_mp4","eEXSv0jChO4.en-j3PyPqV-e1s","18.404J","26"
"76","What is an unprovable mathematical statement mentioned in the content?","!""#$""%! is NP-complete
Theorem:  !""#$""%! is NP-complete
Proof:  Show 3'""% ≤) !""#$""%! (assumes 3'""% is NP-complete)
Idea:  “Simulate” variables and clauses with “gadgets” 
* =
,- ∨,/ ∨,0
∧
,- ∨,/ ∨,2
∧⋯∧
variable gadget
. . .
Zig-zag
clause gadget
4
〈6, 8, 9〉
,-
8
Zag-zig
Corresponds to setting ,- TRUE
Corresponds to setting ,- FALSE
7
","70.37215423583984","10","DPRSearchEngine","c1aca7046a69c913721e5eb910a5fb21_MIT18_404f20_lec15_7_pdf","c1aca7046a69c913721e5eb910a5fb21_MIT18_404f20_lec15","18.404J","15"
"77","What does the GNFA conversion process involve with respect to the states?","which stands for the acceptance problem for DFAs-- is the collection of pairs. B and w-- B is a DFA. w is considered to be some other string, which will be an input to B. We're going to be thinking of it as an input to B. I put the two of them in brackets to represent the pair of them as a single string. We're not going to make explicit what the form of the encoding is. The only important thing is that the encoding should be something simple, but that the Turing machine can decode back into the DFA and this input string to that DFA. So anything reasonable is going to be a satisfactory encoding from us-- for us. So this is an encoding of the two of them into a string, and where B is a DFA, and B accepts w. So now, if you want to test if something's a member of ADFA, then, first of all, you want to make sure that the string itself that you're getting really encodes a DFA and a string. So it has to be the right form. And once you know that, then you have the DFA, you have the string w, and you're then going to do the obvious thing, which would be to simulate B on w and see if it's actually accepting w. So that's what the content of this slide is. I'm just going to write it down for you. So I'm going to give a Turing machine, which I'm going to call-- the name of that Turing machine is going to be D A DFA. To help you remember the function of this machine. This is a decider for the language below, the ADFA language. This is just a name, but-- so nothing fancy going on here, but just to help us remember, because I'm going to refer to some of these Turing machines later on. So this is the decider for ADFA. And I'm going to describe that machine for you, and that machine decides the ADFA language. So what does that mean? So that machine-- I'm describing it now in English, as I promised. We're going to take an input string s, and first, it's going to check that s has the right form, as I mentioned-- has the form which is the encoding of a DFA and a w. If it's not of that form, the Turing machine should reject that input right away. Now, I'm not going to go through the details of how that Turing machine is going to work, though I'll say a little bit more this time only just to give you a sense of how it actually might carry that out. If you don't believe that you can do it with a Turing machine, believe you could do it with your favorite programming language. That's good enough, because that's going to be-- that's equivalent to a Turing machine. So first, you check that the input's of the right form. Then you're going to simulate the computation of B on w. And then, if B ends up in an accept state, then we know B is accepting the input, and we should accept, and we do. If B does not end up in an accept state at the end of w, then we should reject, because B is not accepting w. OK? That's my description of this machine. Let's just turn to a little bit of details just to make sure we're comfortable with this. So here is our Turing machine-- D, the decider for ADFA. The input to that Turing machine, as I mentioned, is going to be B and w, provided it's of the right form. So that's what this string S is supposed to be of that form. And what does that mean? It's just an encoding of the machine w and the string-- the machine B and the string w. Let me just write it down. Here is B written down in some just completely explicit way, where you're just listing the states of B, the alphabet of B, the transition function as a table, the start state, and the set of accepting states-- just writing it down explicitly, as you might do it if you would just want to describe that machine in a completely formal way, and then writing down with the string is-- whatever it is. Once DADFA has that as its input, it can then go ahead and do that computation. And just to try to make it a little bit more explicit, I'm going to capture that here by saying, let's give that Turing machine an extra tape, because we already know that the multi-tape model is equivalent to the single tape model-- make our life perhaps a little easier. And in the course of doing that simulation, what do we want to keep track of? Well, what is the current state of B, the DFA, as we're reading the symbols of w? And where in w are we at right now? So I'll call that k, which is the input head location on w. How many symbols of w have we read? OK? And that's all I'm going to say about what this Turing machine D looks like. Oh, there's one more thing I do want to say for the-- that's coming up, because pretty much all of the Turing machines that we're going to talk about today and going forward are going to often want to check that their input is of the correct form. I don't want to repeat this every time, because that's going to be assumed. So my shorthand for that is to say my input is of the form I'm looking for, and that has built into it the check that the string-- the input string is of that form, and we're going to reject if it is not. So all of our Turing machines are going to start out, on input, the string is of a certain form, and then go out and do something with it. OK? OK, so let me try to answer a few of the questions that I've gotten here, because I think this is important as a way of getting us all started. Now, somebody asked me, can we use arguments of this form? Somebody asking, can we use-- can we give our description of a procedure, if I'm understanding this correctly, as using some other programming language? Well, typically, you just want to make sure you're understood. If you want to do that on a homework, I wouldn't advocate writing your algorithm in Java, because it's going to be hard to read. But write it down in some pseudo programming language if you want, just to make sure it's clear that-- what you're doing. Probably English is going to be the easiest for you-- even though this person says-- feels it would be easier to do it in terms of a formal language. Well, whatever's easier-- as long as we can understand it. This is a good question here I got to ask. What if B-- here's our B-- gets into a loop on w? Well, that's not going to happen. B is a DFA. DFAs-- they move from state to state every time they read a symbol of w. When they get to the end of w, it's the end of the story. There's no more computation to be done. So we know in exactly how many steps B is ever going to take on-- it's going to take the same number of steps as the length of the input. That's how many moves it gets to make. B as a DFA never loops. So that would be a problem if it did loop, but it doesn't. That input never does loop. So have we verified that D is a decider? Well, I think I just did. From my standpoint, we've said enough to be sure that D is a decider. There's never any reason for D to be-- for that DADFA Turing machine to be getting into a loop. The input head location is referring to where we are on the string w? Yes. And somebody's asking me, is this the level of detail for the homework? Yes. That's all I want. It's all I'm looking for. OK? Let us move on. I'm going to have to-- otherwise we'll never get anywhere. There are a lot of questions here. They're good questions. So why don't we go on? Some of these may get resolved as we're going to look at additional examples, because that's all of today is pretty much examples. Let's talk about the similar problem, the acceptance problem, but now for NFAs. So now, actually, NFAs can loop, so we have to think about what that possibly could look at.","64.88318634033203","1","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_5_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"77","What does the GNFA conversion process involve with respect to the states?","which is about the reciprocal of 0.046 if you can figure that out. And you can see, it's not a bad fit to a line through that data. Again, there's still something funky going on over here that we're going to come back to. But it's a pretty good fit to the data. Great. So now I've got a fit. I'm going to show you a variation of this that we're going to use in a second.","64.82313537597656","2","DPRSearchEngine","vIFKGFl1Cn8.en-qlPKC2UN_YU_10_mp4","vIFKGFl1Cn8.en-qlPKC2UN_YU","6.0002","9"
"77","What does the GNFA conversion process involve with respect to the states?","a Generalized Nondeterministic Finite Automaton, or a Generalized NFA, or just simply a GNFA. So this is yet another variant of the finite automaton model. And conceptually, it's very simple. It's similar to the NFAs. I'll give you-- here's a picture of a GNFA named G, G1. Very similar to the NFAs. But if you look at it for a second, you'll see that the transitions have more complicated labels. For the NFAs, we're only allowing just single symbols, or the empty string, to appear on the labels. Now I'm actually allowing you to put full regular expressions on the labels for the automaton. Now, we have to understand how a GNFA processes its input. And the way it works is not complicated to understand. When you're getting an input string feeding-- when a GNFA is processing an input string, it starts at the start state, just like you would imagine. But now, to go along a transition, instead of reading just a single symbol, or the empty string, as in the case for the nondeterministic machine, it actually gets to read a whole string at one step, kind of, at one bite. It can read an entire string and go along that transition arrow, provided that chunk of the input that it read is in the regular expression that that transition has as its label. So for example, this-- you can go from q1 to q2 in one step in this GNFA by reading a, a, b, b off the input. So it reads all of those four symbols all at once. It just swoops them up and then moves from q1 to q2 in one step. And then, when it's in q2 it can read aab and move to q3. And q3 happens, there's nowhere to go. So this is going to be a nondeterministic machine. There might be several different ways of processing the input. And if any one of them gets to an accepting state at the end of the input, we say the GNFA accepts. So it's similar to nondeterministic-- to NFAs in the way the acceptance criterion works. So you could do an example. But hopefully the concept of how this works is reasonably-- you can at least buy it, that it processes the input in chunks at a time. And those chunks have to be described by the regular expressions on the transition arrows, as it moves along those transitions. So what we're going to do now is to convert not DFAs to regular expressions, we're going to convert GNFAs to regular expression. That's even harder, because GNFAs are-- allow you to do all sorts of other things besides just ordinary DFAs. So that's a harder job. Why am I making my life harder? Well, you'll see in a minute that it's going to actually turn out to be helpful to be working with a more powerful model in the way this construction is going to work. Now, before I dive in and do the construction from GNFAs to regular expressions, I'm going to make a simplifying assumption about the GNFAs. I'm going to put them in a special form that's going to make it easier to do the conversion. And that simpler form is, first of all, I'm going to assume the GNFA has just a single accepting state. And that accepting state is not allowed to be the start state. So it has to have just a single accepting state. I've already violated that convenient assumption in this GNFA, because I have here two accepting states. That's not what I want. I want to have just one. Well, the thing is, it's easy to obtain just one, just to modify the machine so that I have just one by adding a new accepting state which is branched to from the former accepting states by empty transitions. So I can always jump from q2 to q4 at any time without even reading any input, just going along this empty transition. And then I declassify the former accepting states as accepting. And now I have here just a single accepting state. And because it's going to be a new state that I added, it won't be the start state. And I have accomplished that one aspect of my assumption about the form of the GNFA. But there's another thing that I want to do, too. I want to assume-- as you will see, which is going to be convenient in my construction-- that we will have transition arrows going from every state to every other state. In fact, I want transition arrows going from every state even back to themselves. I want there to be-- all possible transition arrows should be present, with two exceptions. For the start state, there should be only transition arrows exiting the start state. And for the accepting state-- there's just one now-- there should be only transition arrows coming into the start state. So it's kind of what you would imagine as being reasonable. For the other states, which are not accepting or starting, there should be transition arrows leaving and coming from everywhere else. But for the start states, just leaving. And from the accept state, just coming in. And you could easily modify the machine to achieve that. Let's just see how to do that in one example. So from-- notice that from q3 to q2 there is no transition right now. And that's not good. That's not what I want. I want there to be a transition from q3 to q2. Well, I'll just add that transition in. But I'm going to label it with the empty language regular expression. So that means, yeah, the transition is there, but you never can take it. So it doesn't change the language that the machine is going to be recognizing. But it fulfills my assumption, my convenient assumption, that we have all of these transition arrows being present in the machine. So anyway, I hope you will buy it. It's not going to be-- if you don't quite get this, don't worry. It's not totally critical that you're following all these little adjustments and modifications to the GNFA. But it will be helpful to understand what GNFAs themselves-- how they work. So as I mentioned, we can easily modify","64.53446960449219","3","DPRSearchEngine","KAySmSEGc9U.en-j3PyPqV-e1s_3_mp4","KAySmSEGc9U.en-j3PyPqV-e1s","18.404J","3"
"77","What does the GNFA conversion process involve with respect to the states?"," 
  
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
! −1 states
! states
$
$
%&
%'
%&
%'
()
(*
(+
(,
() (*
∗(+ ∪(,
!-state GNFA → (!—1)-state GNFA 
Check-in 3.1 
We just showed how to convert GNFAs to regular expressions 
but our goal was to show that how to convert DFAs to 
regular expressions. How do we finish our goal? 
(a) Show how to convert DFAs to GNFAs 
(b) Show how to convert GNFAs to DFAs 
(c) We are already done. DFAs are a type of GNFAs. 
Thus DFAs and regular expressions are equivalent. 
1. Pick any state $ except 
the start and accept states. 
2. Remove $. 
3. Repair the damage by 
recovering all paths that 
went through $. 
4. Make the indicated change 
for each pair of states %&, %' . 
Check-in 3.1 
5 
","64.0077896118164","4","DPRSearchEngine","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3_5_pdf","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3","18.404J","3"
"77","What does the GNFA conversion process involve with respect to the states?","So the file is in the zip file I uploaded. It looks more or less like this. Right? So it's very straightforward. The outcomes are binary. 1 is a positive outcome. Strangely enough in the medical jargon, a death is a positive outcome. I guess maybe if you're responsible for the medical bills, it's positive. If you're the patient, it's hard to think of it as a good thing. Nevertheless, that's the way that they talk. And the others are all there, right?","63.83793640136719","5","DPRSearchEngine","esmzYhuFnds.en-qlPKC2UN_YU_8_mp4","esmzYhuFnds.en-qlPKC2UN_YU","6.0002","12"
"77","What does the GNFA conversion process involve with respect to the states?"," 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Generalized NFA 
Defn: A Generalized Nondeterministic Finite Automaton (GNFA) is 
similar to an NFA, but allows regular expressions as transition labels 
a
a ∗ b ∗ 
ab
!1 
#1 
#2 
For convenience we will assume: 
b 
ε 
- One accept state, separate from the start state 
∅ 
- One arrow from each state to each state, except 
a ∪ b 
aab 
a) only exiting the start state 
#3 
#4 
b) only entering the accept state 
ε 
We can easily modify a GNFA to have this special form. 
3 
","63.53770065307617","6","DPRSearchEngine","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3_3_pdf","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3","18.404J","3"
"77","What does the GNFA conversion process involve with respect to the states?","I hope you're all refreshed and ready for the second half. So now that we have nondeterminism, we're going to use that as a tool to prove the closure properties that we were aiming for, starting from last lecture. OK. So remember, let's look at closure under a union. Now, we already did that, but I'm going to do it again, but this time, using nondeterminism. And you'll see how powerful nondeterminism is. Because it's going to allow us to do it almost with no effort. We'll start off the way we did before. I'm going to start off with two DFAs. But actually, these could be NFAs even. But let's say we started with the two DFAs for the two languages A1 and A2. And now we're going to construct an NFA, recognizing the union. And that's good enough, because we already know that we can convert NFAs to DFAs. And therefore, they do regular languages, too. OK. So now here are the two DFAs that do the languages A1 and A2. And what I'm going to do is I'm going to put them together into a bag of states, which is going to be M, the NFA that's going to do the union language. So remember-- what does M supposed to do? M is supposed to accept its input, if either M1 or M2 accept. So how is it going to do that? What it's going to do, we're going to add a new state to M, which is going to branch under epsilon transitions. And now you can start to see how useful these epsilon transitions are going to be for us. Going to branch under epsilon transitions to the two original start states of M1 and M2. And we're done. Why? Well, now, nondeterministically, as we get an input, w coming in to M-- and at the very beginning, even just right after it gets going, the very first thing that happens is it's going to branch to M1 and also branch to M2 nondeterministically as two possibilities. And then inside M1 and M2, it's going to actually start reading the input. And each one is going to be now following along as it would have originally the states corresponding to reading those input symbols. And M, as a combination of M1 and M2, is going to have a possibility for one state in M1 and one state in M2. And so M is going to have those combined into one package. And now at the end of the input, if either of these end up at an accepting state, then M is going to accept as a nondeterministic finite automaton. Because that's how nondeterminism works. You accept if either-- if any one of the branches ended up accepting-- which is just what you need for union. So when we're doing union, you want either one of these to be accepting. And the nondeterminism just is built conveniently to allow us to do the union almost for free. So you can again, thinking about nondeterminism as terms of parallelism, you could think of the nondeterministic machine as running in parallel M1 and M2 on the input. And if either one of them ends up accepting, M will accept. Or you can think about it in terms of that guessing that I referred to before, which means that as M is getting-- when it's just about to read the first symbols of its input, it guesses whether that's going to be an input accepted by M1 or an input accepted by M2. And the magic of nondeterminism is that it always guesses right. So that input happens to be an input that's going to be accepted by M2. M is going to guess that M2 is the right way to follow. And it's going to go in the M2 direction. Because nondeterminism, the magic is you always guess right. I wish that was true in real life. It would make exams a lot easier.","63.338768005371094","7","DPRSearchEngine","oNsscmUwjMU.en-j3PyPqV-e1s_6_mp4","oNsscmUwjMU.en-j3PyPqV-e1s","18.404J","2"
"77","What does the GNFA conversion process involve with respect to the states?"," 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Quick review of today 
1. Conversion of DFAs to regular expressions 
Summary: DFAs, NFAs, regular expressions are all equivalent 
2. Proving languages not regular by using the pumping lemma 
and closure properties 
3. Context Free Grammars 
12 
","63.19474792480469","8","DPRSearchEngine","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3_12_pdf","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3","18.404J","3"
"77","What does the GNFA conversion process involve with respect to the states?","  
 
 
   
 
 
 
 
 
 
 
 
   
 
 
  
 
 
 
 
 
 
  
  
 
 
 
 
 
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
   
GNFA → Regular Expressions 
Lemma: Every GNFA ! has an equivalent regular expression "" 
Proof: By induction on the number of states # of ! 
Basis (# = 2): 
(
! = 
Remember: ! is in special form 
Let "" = ( 
GNFA 
GNFA 
# states 
# −1 states 
4 
-state GNFA 
Induction step (# > 2): Assume Lemma true for # − 1 states and prove for # states 
IDEA: Convert #-state GNFA to equivalent # − 1 
","63.061500549316406","9","DPRSearchEngine","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3_4_pdf","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3","18.404J","3"
"77","What does the GNFA conversion process involve with respect to the states?"," 
 
 
 
 
 
 
 
 
 
 
Regular 
language 
Context Free 
language 
Regular 
languages 
Recap 
Recognizer 
DFA or NFA 
PDA 
Context Free 
languages 
Generator 
Regular 
expression 
Context Free 
Grammar 
11 
","62.504825592041016","10","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_11_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"78","What is a branching program (BP)?","Example:  Branching Programs
Defn: A branching program (BP) is a directed, acyclic (no cycles) graph that has
1.  Query nodes labeled !"" and having two outgoing edges labeled 0 and 1.
2.  Two output nodes labeled 0 and 1 and having no outgoing edges.
3.  A designated start node.
BP # with query nodes !$, … , !' describes a Boolean function (: 0,1 ' →{0,1}:
Follow the path designated by the query nodes’ outgoing edges 
from the start note until reach an output node.
Example:  For !$ = 1, !/ = 0, !0 = 1 we have ( 101 = 0 = output.
BPs are equivalent if they describe the same Boolean function.
Defn:  12BP =
#$, #/
#$ and #/ are equivalent BPs (written #$ ≡#/) } 
Theorem:  12BP is coNP-complete  (on pset 6)
12BP ∈BPP ?  Unknown. That would imply NP ⊆BPP and would be surprising!
Instead, consider a restricted problem.
!$
!0
!$
!/
!/
!0
0
1
0
1
0
1
0
1
0
1
0
1
0
1
5
","85.40731811523438","1","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_5_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"78","What is a branching program (BP)?"," 
 
  
 
 
 
 
 
 
  
 
 
 
 
  
  
  
  
18.404/6.840 Lecture 24 
Last time: 
- Probabilistic computation
- The class BPP
- Branching programs
- Arithmetization
- Started showing !""
ROBP ∈ BPP
Today: (Sipser §10.2)
- Finish !""
ROBP ∈ BPP
1 
","76.6058578491211","2","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_1_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"78","What is a branching program (BP)?"," 
 
  
 
 
 
 
 
 
  
 
 
 
 
 
 
  
18.404/6.840 Lecture 23 
Last time: 
- !""#$%↑ is EXPSPACE-complete 
- Thus !""#$%↑ ∉ PSPACE 
- Oracles and P versus NP 
Today: (Sipser §10.2) 
- Probabilistic computation 
- The class BPP 
- Branching programs 
1 
","76.23623657226562","3","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_1_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"78","What is a branching program (BP)?","  
 
  
 
 
 
  
 
 
 
 
 
   
 
 
 
 
  
 
 
 
  
 
  
   
 
  
 
 
  
  
  
 
 
 
 
 
 
  
  
 
 
 
 
 
 
 
  
 
 
 
 
   
 
 
 
 
 
  
 
 
Example: Ladder Problem 
A ladder is a sequence of strings of a common length where 
WORK
consecutive strings differ in a single symbol. 
PORK 
A word ladder for English is a ladder of English words. 
PORT 
SORT
Let ! be a language. A ladder in ! is a ladder of strings in !. 
SOOT 
Defn: ""!##$%DFA = *, ,, ­
* is a DFA and ""(*) contains 
SLOT 
a ladder 01, 02, … , 04 where 01 = , and 04 = -}. 
PLOT 
Theorem: ""!##$%DFA ∈ NPSPACE 
PLOY 
PLAY
PLAY 
7 
","74.60786437988281","4","DPRSearchEngine","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17_7_pdf","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17","18.404J","17"
"78","What is a branching program (BP)?","  
 
  
 
 
  
 
  
 
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
  
 
 
   
-
Review: Probabilistic TMs and BPP 
coin flip step 
each choice has 
Defn: A probabilistic Turing machine (PTM) is a variant of a NTM 
where each computation step has 1 or 2 possible choices. 
deterministic 
step 
50% probability 
Defn: For ! ≥0 say PTM $  decides language % with error probability !  
if for every &, Pr[ $  gives the wrong answer about & ∈% ] ≤! . 
Defn: BPP = % some poly-time PTM decides % with error !  = +⁄,  } Check-in 24.1 
Actually using a probabilistic algorithm 
Amplification lemma: 2−. /01 2 
presupposes a source of randomness. 
Can we use a standard pseudo-random 
number generator (PRG) as the source? 
& ∈% 
& ∉% 
(a) Yes, but the result isn’t guaranteed.
(b) Yes, but it will run in exponential time.
Many 
Few 
Few 
Many 
(c) No, a TM cannot implement a PRG. 
accepting 
rejecting 
accepting 
rejecting 
(d) No, because that would show P = BPP.
2 
Check-in 24.1 
","74.41390991210938","5","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_2_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"78","What is a branching program (BP)?","Quick review of today
1. Defined probabilistic Turing machines
2. Defined the class BPP
3. Sketched the amplification lemma
4. Introduced branching programs and read-once branching programs
5. Started the proof that !""ROBP ∈BPP 
6. Introduced the arithmetization method
11
","73.87596893310547","6","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_11_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"78","What is a branching program (BP)?"," 
 
  
 
 
  
 
 
 
 
 
18.404/6.840 Lecture 25 
Last time: 
- Schwartz-Zippel Theorem 
- !""ROBP ∈ BPP 
Today: (Sipser §10.4) 
- Interactive Proof Systems 
- The class IP 
- Graph isomorphism problem 
- coNP ⊆ IP  (part 1) 
1 
","73.21788787841797","7","DPRSearchEngine","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25_1_pdf","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25","18.404J","25"
"78","What is a branching program (BP)?","Review:  Branching Programs
","72.75346374511719","8","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_3_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"78","What is a branching program (BP)?","Read-once Branching Programs
Defn: A BP is read-once if it never queries a variable more than once 
on any path from the start node to an output. 
Defn:  !""ROBP =
(), (+
() and (+ are equivalent read-once BPs}
Theorem:   !""ROBP ∈BPP 
.)
./
.)
.+
.+
./
0
1
0
1
0
1
0
1
0
1
0
1
0
1
Not read-once
Check-in 23.2
Check-in 23.2
Assuming (as we will show) that !""ROBP ∈BPP, 
can we use that to show !""BP ∈BPP by converting 
branching programs to read-once branching programs?
(a) Yes, there is no need to re-read inputs.
(b) No, we cannot do that conversion in general.
(c) No, the conversion is possible but not in polynomial-time.
6
","72.39246368408203","9","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_6_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"78","What is a branching program (BP)?","we can talk about that more over the break. And so we'll return here in five minutes. Somebody's asking about-- can infinite sequences be generated by the machine. When we're talking about, especially in the complexity section of the course, all of the computations are going to be bounded in time. So we're not going to be thinking about infinite runs of the machine. That's not going to be relevant for us. So let's not think about that. How does a Turing machine perform division? How does a Turing machine perform division? Well, how do you perform division? [LAUGHS] Long division is an operation that can run in-- the long division procedure that you learn in grade school, you can implement that on a Turing machine. Yes, a Turing machine can definitely perform-- do long division, or division of one integer by another in polynomial time. Another question. Can we generally say, try dividing y by x? Or do we have to enumerate a string of length y and cross off every-- no. I think that's the same question. I mean, if you have numbers written in binary, how would you do the division? You're not going to use long division. Anything such as the thing that's proposed here by the questioner is going to be an exponential algorithm. So don't do it that way. Why does primes in P-- composites in P not imply primes in P? It does imply. If composites are in P, then primes is in P as well. When you have a deterministic machine, you can flip the answer. When you have a non-deterministic machine, you may not be able to flip the answer. So deterministic machine just having a single branch, you can make another deterministic machine that runs in the same amount of time that does the complementary language. Because for deterministic machines, just like for deciders in the computability section, you can just invert the answer. There is an analogy here between P and decidability, and NP and recognizability. It's not an airtight analogy here, but there is some relationship there. Somebody's asking me, what are the implications of P equal to NP? Lots of implications. Too long to enumerate now. But, for example, you would be able to break basically all cryptosystems that I'm aware of, if P equal to NP. So we would have a lot of consequences. Somebody's asking, so composites-- primality and compositeness testing is solvable in polynomial time. But factoring, interestingly enough, is not known to be solvable in polynomial time. We may talk about this a little bit toward the end of the term if we have time. The algorithms for testing whether a number is prime or composite in polynomial time do not operate by looking for factors. They operate in an entirely different way, basically by showing that a number is prime or composite by looking at certain properties of that number. But without testing whether it has-- testing, but without finding a factor. Another question here about asking when we talk about encodings, do we have to say how we encode numbers, values? No, we don't have to. We usually don't have to get into spelling out encodings, as long as they're reasonable encodings. So you don't have to usually. We're going to be talking about things at a high enough level that the specific encodings are not going to matter. Let's return to the rest of our lecture.","72.24017333984375","10","DPRSearchEngine","1VhnDdQsELo.en-j3PyPqV-e1s_10_mp4","1VhnDdQsELo.en-j3PyPqV-e1s","18.404J","14"
"79","How can the equivalence of two regular expressions be determined using automata?","equivalents of regular expressions. Can we now conclude that this problem is also decidable, either immediately from stuff we've already shown; or yes, but would take some significant extra work; or no, because intersection is not a regular operation? So let's see if I can pull that out here-- launch the polling. Here we go. OK, I think we're just about done here. Five seconds more-- OK, ready, set, end. All right. Yes, the correct answer is A. We have basically already shown this fact, because-- why is that? Because we have shown that we can convert-- if you're given two regular expressions, and we want to test whether they're equivalent, they generate the same language, we can convert them both to find out automata. We can convert them to NFAs, and then the NFAs to DFAs. And then we can apply what we've just showed about testing equivalence of DFAs. So yes, it really follows immediately from stuff we've already shown-- the conversion, number one, and then the testing of equivalence for DFAs. So there's not really any work to do here. And in fact, what I'm trying to illustrate with this check-in-- that, once you've shown how to do some kind of a test for one model, it-- going to apply for all of the equivalent models that we've shown to be equivalent, because the Turing machine can do the constructions which show the equivalence. OK, so let's move on. Somebody didn't get the poll. Did most people not get the poll? Well, I think most of you have gotten it. Did you? I'm not seeing a lot of complaints. So if you didn't get the poll, something is wrong with your setup, and you're going to have to take the recorded check-ins that are going to launch right after this lecture's over. Sorry. But you should figure out what's wrong with the setup there, because I think most people are getting these. OK, and with that, we're going to take a little break, and then we'll continue on afterward. Let me know how this is-- should I be speed a little speedier about the little mini breaks that we're taking, or is this good for you? Feedback is always-- I'm trying to make this as good as I can for all of you. OK, I think there's a mixture of between people saying that these breaks are good. Someone says they're a little overlong, so I'll try to tighten them up a little. Some folks are saying what-- more people should be asking the TAs. I don't know how the TAs are doing, in terms of their-- I'll check with them afterward-- how well this is going for them, in terms of the questions. But I think some amount of break is good so that we don't-- so there's time to be asking questions. Otherwise, what's the point of having a live lecture? So we will start promptly when this timer runs down. So be ready to go in 55 seconds from now. Just to confirm, to show the decidability of the equivalence of two regular expressions, do we need to show that we can use a Turing machine to convert them to two DFAs first? If you want to test whether two regular expressions are equivalent, you can give any procedure for doing that deciding you want. I'm just offering one simple way to do it that takes advantage of stuff we've already shown. But if you want to dig down and do some analysis of those regular expressions to show that they describe the same language, they generate the same language, be my guest. I think that's-- actually would be complicated to do that that way. OK, so we're just about ready to go here, so let's continue. And let me take this timer off here. All right. Now, we are going to talk a little about context-free grammars. So we talked about decision problems for finite automata. Let's talk about some for grammars. OK, now I'm going to give us an analogous problem. I'm going to give you a-- I'm calling it the acceptance problem, but-- just for consistency with everything else, but it's really the generating problem. So I'm giving you a grammar-- context-free grammar G and a string that's in a string. And I want to know, is it in the language of G? So does G generate w? I'm calling that the ACFG problem. So that's going to be a decidable again. These are getting slightly harder as we're moving along, so I'm giving you a grammar and a string, and I want to know, does the grammar generate that string? Well, it's not totally trivial to solve that. One thing you might try doing is looking at all possible things, all possible derivations from that grammar and see if any one of them leads to w-- leads you to generate w. Well, you have to be careful, because as I've-- as we've shown in some of our examples, you actually could have-- because you're allowed to have variables that can get converted to empty string, you might have very long intermediate strings being generated from a, grammar which then ultimately give you a small string of terminals that get generated, a small string in the language that gets produced. You certainly don't want to try every possible derivation, because there's infinitely many different derivations-- most of them generating, of course, things that are irrelevant to the string w. But you have to know how to cut things off, and it's not immediately obvious how you do that-- unless you have done the homework problems that I asked you to do, which I'm sure very many of you have not done-- the zero point X problems, because they're-- that's going to come in handy right now. And so I'll help you through that. Remember-- you should remember, but you may not have looked at it-- something called Chomsky normal form, which is for context-free grammars, but only allows the rules to be of a special kind. And they have to look like this. They can be a variable that goes to two variables, on the right-hand side, or a variable that goes to a terminal. Those are the only kinds of rules that you're allowed. This is a special case for the empty string, but let's ignore that for-- the start variable can also work to the empty string, if you want to have a-- the empty string in a language. But that's a special case. Let's ignore that. These are the only two kinds of rules that you can have in a Chomsky normal form grammar. Once you have a Chomsky normal form grammar-- well, first of all, there's two things. First of all, you can always convert any context-free grammar into Chomsky normal form. So that's given in the textbook. You do the obvious thing. I'm not going to spend time on it. And you don't have to know it. It's just a little bit tedious, but it's straightforward and it's there, if you're curious. But the second lemma's the thing that's important to us, which is that, if you have a grammar which is in Chomsky normal form and a string that's generated, every derivation of that string has exactly 2 times the length of the string minus 1 steps. If you think about it, this is a lemma-- very easy to prove. I think the homework problem asks you to prove that in the 0.2 or whatever it was in problem set 1-- or problem set 2-- I don't remember. Rules of this kind allow you to make the string one longer, and rules of this kind allow you to produce a new terminal symbol. If the length w is n, you're going to have n minus 1 of these and n of. Those that's why you get 2n minus 1 steps. But the point is that I don't really care exactly how many. It's just that we have a bound. And once you have that bound, life is good from the point of view of giving a Turing machine which is going to decide this language-- because here's the Turing machine. What it's going to do-- the first thing is it's going to convert G into Chomsky normal form. That we assume we know how to do. Now, we're going to try all derivations, but only those of length 2-- twice the length of the string minus 1, because if any derivation is going to generate w, it has to be this many steps, now that we know the grammar is in Chomsky normal form. OK, so we have converted this problem of one that might be a very unboundedly lengthy problem and to one where it's going to terminate after some fixed number of steps. And so therefore, we can accept, if any of those generate w, and reject if not. OK? Before moving on, so this answers the problem-- shows that this language is decidable, the ACFG language. So that's something that-- make sure you understand. We're basically trying old derivations of up to-- of a certain length, because that's all that's needed when the grammar is in that form. Now we're going to use that to prove a corollary, which is important for understanding how everything fits together. And that corollary states that every context-free language is a decidable language. Every context-free language is decidable. Now, why does that follow from this? Well, suppose you have a context-free language. We know that language is generated by some context-free grammar G. That's what it means. So then you can take that grammar G and you can build it into a Turing machine. So there's going to be a term machine which is constructed with the knowledge of G. And that Turing machine is going to take its w and run the ACFG algorithm with w combined with a G that's already built into it. So it's just going to stick that grammar G in front of w, and now we run the ACFG decider. It's going to say, does degenerate w? Well, that's going to be yes every time w is in A. And so this machine here now is going to end up accepting every string that's in A, because it's every string that G generates. So that is, I think, what I wanted to say about this. Now, I feel that this corollary here throws a little bit of a curveball. And we can just pause for a moment here just to make sure you're understanding this. The tricky thing about this corollary is-- that I often get-- a question I often get where-- is when we start off with a context-free language, who gives-- how do we get G? Because we need G to build a Turing machine M sub G. So we know A is a context-free language, but how do we know what G is? Well, the point is that we may not know what G is, but we know G exists, because that's a definition of A being a context-free language. It must have a context-free grammar, by definition. And so because G exists, I now know my Turing machine, M sub G, exists. And that's enough to know that A is decidable, because it has a decider that exists. Now, if you're not going to tell me the grammar for G, I'm not going to tell you the Turing machine which decides A. But both of them exist. So if you tell me G, then I can tell you the Turing machine. So it's a subtle, tricky issue there. A certain little element maybe of-- sometimes people call it non-constructive, because we're just, in a sense, showing just that something is existing. It does the job for us, because it shows that A is a decidable language. OK, so not so many questions here-- maybe the TAs are getting them. So let's move on. Here's another check-in. So now, can we conclude that A-- instead of ACFG, APDA is decidable? People are getting this one pretty fast. Another 10 seconds-- three seconds-- OK, going to shut it down-- end polling, share results. Yeah. So this problem here is APDA is decidable. I was almost wondering whether or not to give this poll, because it has-- it's true for the same reason as poll number 1, because we know how to convert PDAs-- or we stated we can convert PDAs to CFGs. And that conversion has given in the book. We didn't do in lecture, but I just stated you have to know that fact, but not necessarily know how to do it. That's OK. But the fact is true. The conversion is in the book, and it could be implemented on a Turing machine. So if you want to know whether a PDA's language is empty, you convert it to a context-free grammar and then use this procedure here to test whether it's a language--","76.19867706298828","1","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_11_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"79","How can the equivalence of two regular expressions be determined using automata?","power of a Turing machine. That's a question that I'm going to postpone to later, because you're asking if a Turing machine can simulate itself. And we'll talk about things like that, but that's in a few weeks from now, so I'll hold off on that one. Decidable languages-- somebody's asking me a good question about closure properties of the class of decidable languages. Are they closed under intersection, union, and so on? Yes. And the decidable languages are also closed under complement. That should be something you should think about. But yes, that is true. The recognizable languages, however, are closed under union and intersection, but they are not closed under complement. So that we will prove on Thursday's lecture. So another question is, could we have just run B on w in this-- in solving this problem, instead of using reduced-- converting it to a new Turing machine-- the B prime? Well, yes, we could have just done that. OK. I think we better move on. I don't want to get too bogged down here-- got a lot of questions there, so sorry if I'm not getting to all of the questions. OK. Or you can write to the TAs too, obviously. I'm sure you are.","73.53228759765625","2","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_7_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"79","How can the equivalence of two regular expressions be determined using automata?","free and regular, why do we know that's still context free? Because the pushdown automaton for A can be simulating the finite automaton for B inside its finite control, inside its finite memory. The problem is, if you have two context-free languages, you have two pushdown automata, you can't simulate that with one pushdown automaton, because it has only a single stack. So if you're trying to take the intersection of two context-free languages with only a single stack, you're going to be in trouble, because it's hard to-- anyway, that's not a proof, but at least it shows you what goes wrong if you try to do the obvious thing. OK, so if-- and just, here is an important point that was trying to make before. If A and B are both context free and you're taking the intersection, the result may not necessarily be a context-free language. So the class of context-free languages is not closed under its intersection. We'll comment on that in a bit. The context-free languages are closed under the regular operations, however, union, intersection-- union, concatenation, and star. So you should feel comfortable that you know how to prove that. Again, it's one of the-- I think it's problem 0.2. And I think the solution is even given in the book for it. So you just should know how to prove that. It's pretty straightforward. OK, so let's move on then to basically conclude our work on context-free languages, to understand the limitations of context-free grammars, and what kinds of languages may not be context free. And how do you prove that? So how do you prove that, for some language, there is no grammar? Again, you know, it's not enough just to, say, give an informal comment that, I couldn't think of a grammar, or some-- things of that kind. That's not going to be good enough. We need to have a proof. So if we take the language here, 0 to the k, 1 to the k, 2 to the k, so those are strings which are runs of 0's followed by an equal number of 1's followed by an equal number of 2's, so just 0's, then 1's, then 2's, all the same length. That's a language which is not going to be a context-free language. And we'll give a method for proving that. If you had a stack, you can match the 1's with the 0's, but then once you're done with that, the stack is empty. And how do you now make sure that the number of 2's corresponds to the number of 1's that you had? So again, that's an informal argument that's not good enough to be a proof, but it sort of gives an intuition. So we're going to give a method for proving non-context-free-- languages are not context free using, again, a pumping lemma. But this is going to be a pumping lemma that applies to context-free language, not to regular languages. It looks very similar, but it has some extra wrinkles thrown in, because the other older pumping lemma was specific to the regular languages. And this is going to be something that applies to the context-free languages. OK, so now let's just read it. And then we'll try to interpret it again. It's very similar in spirit. Basically, it says that, whenever you have a context-free language, all long strings in the language can be pumped in some kind of way. So it's going to be a little different kind of pumping than we had before. And you stay in the language. OK, so before, we broke the string into three pieces where we could repeat that centerpiece as many times as you like. And you stay in the language. Here, we're going to end up breaking the string into five pieces. So s is going to be broken up into uvxyz. And the way it's going to work here-- so here is a picture. So all long strings-- again, there is going to be a threshold. So whenever you have a language, there is going to be some cut-off length. So all the longer strings in that language can be pumped. And you stay in the language. But the shorter strings, there is no guarantee. So if you have a long string in the language of length at least this pumping length p, then you can break it up into five pieces. But now it's that second and fourth string that are going to play that special pumping role, which means that, what you can do is you can repeat those and you stay in the language. And it's important that you repeat them both, that v and that y, the same number of times. So you're going to have a picture that looks something like this. And that is going to you repeat. If you repeat the v and you repeat the y, you get uvvxyyz. Or if you look at over here, it would be uv squared xy squared z. And that's going to still be in the language. And then we have-- so that's one condition. We'll have to look at all of these conditions when we do the proof, but we just want to understand what the statement is right now. So the second condition is that v and y together cannot be empty. And really, that's another way of saying, they can't both be the empty string, because if they were both the empty string, then repeating them wouldn't change s. And then of course it would stay in the language. So it would be kind of meaningless if they were allowed to be empty. And the last thing is, again, going to be there as a matter of convenience for proving languages are not context free, because you have to make sure there is no possible way of cutting up the string. When you're trying to prove a language is not context free, you have to show the pumping fails. It's going to be helpful sometimes to limit the ways in which the string can be cut up, because then you have-- it's an easier job for you to work with it. So here, it's a little different than before, but sort of similar, that vxy combine as a substring. So I show that over here. vxy together is not too long. So the vxy-- maybe it's better seen up here-- is going to be, at most, p. We'll do an example in a minute of using this. OK, so again, here is our pumping lemma. I've just restated it. So we have it in front of us. And we're going to do a proof. I'm just going to give you the idea of the proof first. And then we'll go through some of the details.","73.39060974121094","3","DPRSearchEngine","IycOPFmEQk8.en-j3PyPqV-e1s_7_mp4","IycOPFmEQk8.en-j3PyPqV-e1s","18.404J","5"
"79","How can the equivalence of two regular expressions be determined using automata?","Let's see. Equivalence problem for DFAs-- now we're going to take things to the next level-- ask, are there two-- I'm going to give you two DFAs. And I want to know, do they describe the same language-- do they recognize the same language? OK? So how are we going to do that? So that's a decidable language. Here's the decider. My input now is going to be two DFAs-- again, represented as a string, because that's what Turing machines deal with as their inputs. But they can unpack that string into two DFAs. And there are several different ways to do this problem, and I'm sure I'm going to get suggestions with other ways to go. One thing you could do is just to feed in strings up to a certain length. Just like before, you can't feed in all possible strings and see if the machines ever behave differently on any of them, because that's an infinite operation, and we already decided we can't do that. Now, if you want to talk about this being a recognizer, instead of a decider, then you might be able to do something like that just to make sure your-- you have to be just careful. Let me not say more on that right now. But certainly, for a decider, you can't go forever. You can't have infinite operations. So you would have to have a cut-off. So you can feed in all possible strings up to some length, say, into A and B, and see if there's any difference. Now, we actually had a problem on that in the problem set 1, which said, if two DFAs have unequal languages, then they're going to see a difference. Then there's going to be a string which acts differently on them, which is of length, at most, the product of the number of states of those two machines. So you can either reference that problem-- that would be an adequate solution-- or reprove it or whatever. That would be fine. In fact, you can do even better than that, as the optional problem showed. You only have to go up to the sum of the number of states, not up to the product. But that's actually very difficult to show. I'm not going to prove it that way. I'm going to prove it in an entirely different way, which doesn't require any analysis at all-- no proving something about balance. I'm going to take advantage of something we've already shown, which is I'm going to make a new finite automaton, a new DFAC built out of A and B, which accepts all the strings on which A and B disagree. And I'll show you how to-- that's easy to do. So first of all, let's-- in terms of a picture, let's understand what this is. So here we have-- this is the language of A, this is the language of B written as a Venn diagram. And where are those places where they disagree? Well, they're either in A, but not in B, or in B, but not in A. I'm showing it to you here in terms of the blue region. That actually has a name called the symmetric difference of these two sets. These are the-- all of the members which are in exactly one out of the two, but not both. If you can make a machine C that would accept all of the strings in the blue region, then what do we do with that machine? We test of its length language is empty, which is what we've already shown how to do-- because of the blue region is empty, that means that L of A equals L of B. So I'm going to make a machine, a DFAC where the language of C is exactly that symmetric difference. It's all the strings in A intersected with the strings that are not in B-- so in A and not in B-- or in B and not-- then not an A-- take the union of those two parts. And how do we know we can make C? Well, we have those closure constructions, which we showed several lectures back. Those closure instructions can be implemented on a Turing machine. So a Turing machine can build the DFAC, and then use that test from a few slides back, the emptiness-- the last slide-- the emptiness tester for DFAs on C to see whether its language is empty. And now, if C's language is empty, then we know we can accept, because that means the two-- that L of A equals L of B. Otherwise, we can reject. OK? So here's a note-- I'm going to ask you a check-in. You can also use that time to send me a few more questions, if you want. OK, here's my check-in. OK, now, instead of testing equivalence of finite-- of DFAs, I want to test equivalence of regular expressions. So here are R1, R2. Regular expressions are called the EQ regular expressions","73.2655258178711","4","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_10_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"79","How can the equivalence of two regular expressions be determined using automata?"," 
 
  
 
 
  
 
 
 
 
 
 
  
 
 
 
Interactive Proofs – Introduction 
Illustration: Graph isomorphism testing 
Defn: Undirected graphs ! and "" are isomorphic if they are identical except 
for a permutation (rearrangement) of the nodes. 
2 
","72.87602233886719","5","DPRSearchEngine","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25_2_pdf","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25","18.404J","25"
"79","How can the equivalence of two regular expressions be determined using automata?","OK, let's move on. OK, let's talk about closure properties now. We're going to start doing something that has a little bit more meat to it, in terms of we're going to have our first theorem of the course coming here. And this is not a baby theorem. This is actually-- there's going to be some meat to this. And you're going to have to not totally-- this is not a toy. We're proving something that has real substance. And the statement of this theorem says that the regular languages are closed, that really, the class of regular languages are closed under union, closed under the union operation. So what do I mean by that? So when you say a collection of objects is closed under some operation, that means applying that operation to those objects leaves you in the same class of objects. Like the positive integers, the natural numbers, that's closed under addition. Because when you add two positive integers, you get back a positive integer. But they're not closed under subtraction. Because 2 minus 4, you get something which is not a positive integer. So closed means you leave yourself in the collection. And the fact is that if you look at all the regular languages-- these are the languages that the finite automata can recognize-- they are closed under the union operation. So if you start off with two regular languages and you apply the union, you get back another regular language. And that's what the statement of this theorem is. I hope that's clear enough in the way I've written it. If A1 and A2 are regular, then A1 union A2 is also regular. That's what the statement of this is. And it's just simply that-- that's proving that the class of regular language is closed under union. So we're going to prove that. So how do you prove such a thing? So the way we're going to prove that is you start off with what we're assuming. So our hypothesis is that we have two regular languages. And we have to prove our conclusion, that the union is also regular. Now, the hypothesis that they're regular, you have to unpack that and understand, what does that get you? And them being regular means that there are finite automata that recognize those languages. So let's give those two finite automata names. So M1 and M2 are the two final automata that recognize those two languages, A1 and A2. That's what it means, that they're regular, that these automata exist. So let's have those two automata, M1 and M2, using the components as we've described, the respective state sets, input alphabet, transition functions, the two starting states and the two collections of accepting states. Here I'm assuming that they're over the same alphabet. You could have automata which operate over different alphabets. It's not interesting to do that. It doesn't add anything. The proof would be exactly the same. So let's just not overcomplicate our lives and focus on the more interesting case, so assuming that the two input alphabets are going to be the same. And from these two automata, we have to show that this language here, the union, is also a regular language. And we're going to do that by constructing the automaton which recognizes the union. That's really the only thing that we can do. So we're going to build an automaton out of M1 and M2 which recognizes the union language A1 union A2. And the task of M is that it should accept its input if either M1 or M2 accept. And now what I'd like you to think about doing that, how in the world are we going to come up with this finite automaton M? And the way we do that is to think about, how would you do that union language? If I ask you-- I give you two automata, M1 and M2, and I say, here's an input, w. Is w in the union language? That's the job that M is supposed to solve. And I suggest you try to figure out how you would solve it first. I mean, this is a good strategy for solving a lot of the problems in this course. Put yourself in the place of the machine you're trying to build. And so if you want to try to figure out how to do that, a natural thing is, well, you take w, you feed it into M1, and then you feed it into M2. And if M1 accepts it, great, then you know it's in the union. And if not, you try it out in M2 and see if M2 accepts it. Now, you have to be a little careful, because you want to have a strategy that you can also implement in a finite automaton. And a finite automaton only gets one shot at looking at the input. You can't sort of rewind the input. You feed it first into M1 and then you feed it into M2 and operate in a sequential way like that. That's not going to be allowed in the way finite automata work. So you're going to have to take it to the next level, be a little bit more clever. And instead of feeding it first into M1 and then and then into M2, you feed them into both in parallel. So you take M1 and M2, and you run them both in parallel on the input w, keeping track of which state each of those two automata are in. And then at the end, you see if either one of those machines is in an accepting state, and then you accept. So that's the strategy we're going to employ in building the finite automaton M out of M1 and M2.","72.2269515991211","6","DPRSearchEngine","9syvZr-9xwk.en-j3PyPqV-e1s_11_mp4","9syvZr-9xwk.en-j3PyPqV-e1s","18.404J","1"
"79","How can the equivalence of two regular expressions be determined using automata?","we can talk about that more over the break. And so we'll return here in five minutes. Somebody's asking about-- can infinite sequences be generated by the machine. When we're talking about, especially in the complexity section of the course, all of the computations are going to be bounded in time. So we're not going to be thinking about infinite runs of the machine. That's not going to be relevant for us. So let's not think about that. How does a Turing machine perform division? How does a Turing machine perform division? Well, how do you perform division? [LAUGHS] Long division is an operation that can run in-- the long division procedure that you learn in grade school, you can implement that on a Turing machine. Yes, a Turing machine can definitely perform-- do long division, or division of one integer by another in polynomial time. Another question. Can we generally say, try dividing y by x? Or do we have to enumerate a string of length y and cross off every-- no. I think that's the same question. I mean, if you have numbers written in binary, how would you do the division? You're not going to use long division. Anything such as the thing that's proposed here by the questioner is going to be an exponential algorithm. So don't do it that way. Why does primes in P-- composites in P not imply primes in P? It does imply. If composites are in P, then primes is in P as well. When you have a deterministic machine, you can flip the answer. When you have a non-deterministic machine, you may not be able to flip the answer. So deterministic machine just having a single branch, you can make another deterministic machine that runs in the same amount of time that does the complementary language. Because for deterministic machines, just like for deciders in the computability section, you can just invert the answer. There is an analogy here between P and decidability, and NP and recognizability. It's not an airtight analogy here, but there is some relationship there. Somebody's asking me, what are the implications of P equal to NP? Lots of implications. Too long to enumerate now. But, for example, you would be able to break basically all cryptosystems that I'm aware of, if P equal to NP. So we would have a lot of consequences. Somebody's asking, so composites-- primality and compositeness testing is solvable in polynomial time. But factoring, interestingly enough, is not known to be solvable in polynomial time. We may talk about this a little bit toward the end of the term if we have time. The algorithms for testing whether a number is prime or composite in polynomial time do not operate by looking for factors. They operate in an entirely different way, basically by showing that a number is prime or composite by looking at certain properties of that number. But without testing whether it has-- testing, but without finding a factor. Another question here about asking when we talk about encodings, do we have to say how we encode numbers, values? No, we don't have to. We usually don't have to get into spelling out encodings, as long as they're reasonable encodings. So you don't have to usually. We're going to be talking about things at a high enough level that the specific encodings are not going to matter. Let's return to the rest of our lecture.","72.1573486328125","7","DPRSearchEngine","1VhnDdQsELo.en-j3PyPqV-e1s_10_mp4","1VhnDdQsELo.en-j3PyPqV-e1s","18.404J","14"
"79","How can the equivalence of two regular expressions be determined using automata?","And proving languages not regular. The way we're going to prove languages are not regular is by introducing a method called the pumping lemma. And the overarching plan at the pumping lemma, without getting into the specifics of it, is to say-- show that-- that lemma says all regular languages have a certain property, which we will describe. And so to show a language is not regular you simply show the language doesn't have that property, because all regular languages have to have that property. And so by showing a language fails to have the property, it could not be regular. That's the plan. Now, the property itself is a little complicated to describe, but not too bad. I'll try to unpack it for you. But first, let's look at the statement of the lemma, which says that whenever you have a regular language-- let's call it A. So for every regular language A there's always a special value called the pump-- a number. p, we'll call it-- called the pumping length. It's a special number. And it's-- and that length tells you that whenever a string is in that language and it's longer than that length, then something special happens. You can take that string and you can modify it, and you still stay in the language. So anything that's longer than that special length can be modified in a certain way, and you still stay in the language. So let's look at the actual statement of the lemma. So there is a number p such that if s is a string in the language and it's longer than p, or at least of length p, then you can take s and you can cut it up into three pieces-- x, y, and z-- so that's just breaking s into three pieces-- where you can take that middle piece, repeat it as many times as you like, and you still stay in the language. That's the-- what the pumping lemma is saying. And there's a bunch of other conditions here too. But the spirit of the pumping lemma says, whenever you have a regular language there's some cutoff such that all strings longer than that cutoff can be what we call pumped. You can take that string, you can find a section somewhere in the middle of that string or somewhere-- you cut it up in three pieces, you take that center piece, and you can repeat it. You can pump it up. And by repeating that string and repeating that piece, the string gets longer and longer. But you still stay in the language. That's the special property that all regular languages have. So in an informal way-- and we'll do-- I'll try to help you get the feeling for this. Informally, it says that if you have a regular language, then every long string-- so a long is by-- informal way of saying bigger than this value p. Every long string in the language can be pumped. And this result still stays in the language. And by ""pumped"" means I can cut the string into three pieces and repeat that middle piece as many times as I want. That's what I mean by pumping a string.","72.05013275146484","8","DPRSearchEngine","KAySmSEGc9U.en-j3PyPqV-e1s_9_mp4","KAySmSEGc9U.en-j3PyPqV-e1s","18.404J","3"
"79","How can the equivalence of two regular expressions be determined using automata?"," 
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
  
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
  
 
 
 
 
 
 
 
 
 
  
Finite Automata – Computation 
Strings and languages 
-
A string is a finite sequence of symbols in Σ 
-
A language is a set of strings (finite or infinite) 
-
The empty string ε is the string of length 0 
Recognizing languages 
-
The empty language ø is the set with no strings 
- :(#) = {$| # accepts $} 
- :(#) is the language of # 
Defn:  # accepts string $ = $1$2 … $) each $* + Σ 
- # recognizes :(#) 
if there is a sequence of states ,0, ,1, ,2, , … , ,) + / 
where: 
- ,0 = 00 
- ,* = 1(,345, $*) for 1 ≤ * ≤) 
Defn: A language is regular if some 
- ,) + 8 
finite automaton recognizes it. 
8 
","71.16551971435547","9","DPRSearchEngine","b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1_8_pdf","b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1","18.404J","1"
"79","How can the equivalence of two regular expressions be determined using automata?"," 
 
   
 
 
 
 
 
 
   
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Regular Expressions → NFA 
Theorem: If "" is a regular expr and # = % "" then # is regular 
Proof: Convert "" to equivalent NFA &: 
If "" is atomic: 
Equivalent & is: 
) 
Example:  
"" = ) for ) ∈Σ 
Convert a ∪ ab ∗ to equivalent NFA 
"" = ε 
a
a:
"" = ∅ 
b
b: 
a 
ε 
b 
If "" is composite: 
ab: 
a 
"" = "". ∪""/ 
a ∪ ab: 
ε 
a 
ε 
b
"" = "". ∘""/ 
Use closure constructions 
ε
}
∗ 
a ∪ ab ∗ : 
ε
"" = "". 
a
ε
ε 
a 
ε 
b
ε 
10 
ε 
","71.06338500976562","10","DPRSearchEngine","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_10_pdf","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2","18.404J","2"
"83","What does BPP stand for?"," 
 
  
 
 
  
 
 
 
 
 
18.404/6.840 Lecture 25 
Last time: 
- Schwartz-Zippel Theorem 
- !""ROBP ∈ BPP 
Today: (Sipser §10.4) 
- Interactive Proof Systems 
- The class IP 
- Graph isomorphism problem 
- coNP ⊆ IP  (part 1) 
1 
","71.07643127441406","1","DPRSearchEngine","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25_1_pdf","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25","18.404J","25"
"83","What does BPP stand for?","Example:  Branching Programs
Defn: A branching program (BP) is a directed, acyclic (no cycles) graph that has
1.  Query nodes labeled !"" and having two outgoing edges labeled 0 and 1.
2.  Two output nodes labeled 0 and 1 and having no outgoing edges.
3.  A designated start node.
BP # with query nodes !$, … , !' describes a Boolean function (: 0,1 ' →{0,1}:
Follow the path designated by the query nodes’ outgoing edges 
from the start note until reach an output node.
Example:  For !$ = 1, !/ = 0, !0 = 1 we have ( 101 = 0 = output.
BPs are equivalent if they describe the same Boolean function.
Defn:  12BP =
#$, #/
#$ and #/ are equivalent BPs (written #$ ≡#/) } 
Theorem:  12BP is coNP-complete  (on pset 6)
12BP ∈BPP ?  Unknown. That would imply NP ⊆BPP and would be surprising!
Instead, consider a restricted problem.
!$
!0
!$
!/
!/
!0
0
1
0
1
0
1
0
1
0
1
0
1
0
1
5
","69.89476776123047","2","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_5_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"83","What does BPP stand for?"," 
 
  
 
 
 
 
 
 
  
 
 
 
 
  
  
  
  
18.404/6.840 Lecture 24 
Last time: 
- Probabilistic computation
- The class BPP
- Branching programs
- Arithmetization
- Started showing !""
ROBP ∈ BPP
Today: (Sipser §10.2)
- Finish !""
ROBP ∈ BPP
1 
","67.9439468383789","3","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_1_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"83","What does BPP stand for?","  
 
  
 
 
  
 
  
 
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
  
 
 
   
-
Review: Probabilistic TMs and BPP 
coin flip step 
each choice has 
Defn: A probabilistic Turing machine (PTM) is a variant of a NTM 
where each computation step has 1 or 2 possible choices. 
deterministic 
step 
50% probability 
Defn: For ! ≥0 say PTM $  decides language % with error probability !  
if for every &, Pr[ $  gives the wrong answer about & ∈% ] ≤! . 
Defn: BPP = % some poly-time PTM decides % with error !  = +⁄,  } Check-in 24.1 
Actually using a probabilistic algorithm 
Amplification lemma: 2−. /01 2 
presupposes a source of randomness. 
Can we use a standard pseudo-random 
number generator (PRG) as the source? 
& ∈% 
& ∉% 
(a) Yes, but the result isn’t guaranteed.
(b) Yes, but it will run in exponential time.
Many 
Few 
Few 
Many 
(c) No, a TM cannot implement a PRG. 
accepting 
rejecting 
accepting 
rejecting 
(d) No, because that would show P = BPP.
2 
Check-in 24.1 
","66.8796157836914","4","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_2_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"83","What does BPP stand for?","Defn:  BPP = "" some poly-time PTM decides "" with error # = ⁄
% & }
Amplification lemma: If '% is a poly-time PTM with error #% < ⁄
% ) then, 
for any 0 < #) < ⁄
% ), there is an equivalent poly-time PTM ') with error #).  
Can strengthen to make #) < 2−,-./ 0 . 
Proof idea:  ') = “On input 1
1.  Run '% on 1 for 2 times and output the majority response.”
Details:  Calculation to obtain 2 and the improved error probability. 
Significance:  Can make the error probability so small it is negligible.
The Class BPP
3
","66.63101196289062","5","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_3_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"83","What does BPP stand for?"," 
 
  
 
 
 
 
 
 
  
 
 
 
 
 
 
  
18.404/6.840 Lecture 23 
Last time: 
- !""#$%↑ is EXPSPACE-complete 
- Thus !""#$%↑ ∉ PSPACE 
- Oracles and P versus NP 
Today: (Sipser §10.2) 
- Probabilistic computation 
- The class BPP 
- Branching programs 
1 
","66.56846618652344","6","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_1_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"83","What does BPP stand for?","!""
!#
!#
0
1
0
1
!$
!$
0
1
0
1
0
1
0
1
1
1
1
1
1
1
1
0
0
0
0
0
0
0
0
0
0
Boolean Labeling
Show by example:  Input is  !"" = 0, !# = 1, !$ = 1
The BP follows its execution path.
Label all nodes and edges on the execution path with 1
and off the execution path with 0.
Output the label of the output node 1.
Alternative way to view BP computation
Obtain the labeling inductively by using these rules:
'
' ∧!)
' ∧!)
'""
'#
'$
'"" ∨'# ∨'$
!)
0 1
Label edges from nodes
Label nodes from incoming edges
8
","65.33370971679688","7","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_8_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"83","What does BPP stand for?"," 
 
Looking at  Distributions 
def plotDistributions():  
uniform, normal, exp = [], [], []  
for i in range(100000):  
uniform.append(random.random())  
normal.append(random.gauss(0, 1))  
exp.append(random.expovariate(0.5))  
makeHist(uniform, 'Uniform', 'Value', 'Frequency')  
pylab.figure()  
makeHist(normal, 'Gaussian', 'Value', 'Frequency')  
pylab.figure()  
makeHist(exp, 'Exponential', 'Value', 'Frequency')  
6.0002  LECTURE 8 
 
27
","63.58665084838867","8","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_27_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"83","What does BPP stand for?"," 
 
  
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
 
 
 
 
 
 
 
 
 
 
 
Boolean Labeling 
Alternative way to view BP computation 
Show by example: Input is !"" = 0, !# = 1, !$ = 1 
The BP follows its execution path.
!"" 1
Label all nodes and edges on the execution path with 1 
0
1 
1 0 
and off the execution path with 0. 
Output the label of the output node 1. 
1 !# 1
!# 0
0 
Obtain the labeling inductively by using these rules: 
0 
1
0
1 
0
0 
0
1 
' 
0
1 
' ∧!)
' ∧!)
'"" ∨'# ∨'$
!$
!$
!)
1 
'""
'#
'$
1
0 
0 
0
0
1 
0 
0 
1 = output 
0
1 
Label outgoing edges from nodes
Label nodes from incoming edges 
4 
","63.05036926269531","9","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_4_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"83","What does BPP stand for?"," 
 
 
Testing the SEM  
sampleSizes = (25, 50, 100, 200, 300, 400, 500, 600)  
numTrials = 50  
population = getHighs()  
popSD = numpy.std(population)  
sems = []  
sampleSDs = []  
for size in sampleSizes:  
sems.append(sem(popSD, size))  
means = []  
for t in range(numTrials):  
sample = random.sample(population, size)  
means.append(sum(sample)/len(sample))  
sampleSDs.append(numpy.std(means))  
pylab.plot(sampleSizes, sampleSDs,  
label = 'Std of ' + str(numTrials) + ' means')  
pylab.plot(sampleSizes, sems, 'r--', label = 'SEM')  
pylab.xlabel('Sample Size')  
pylab.ylabel('Std and SEM')  
pylab.title('SD for ' + str(numTrials) + ' Means and SEM')  
6.0002  LECTURE 8 
 
pylab.legend() 
23
","62.72148132324219","10","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_23_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"85","What is the opinion about the possibility of proving P = NP or P ≠ NP within 20 years?","Quick review of today
1.
NTIME ! ""
and NP
2.
#$%&$'# and  ()%&)*+',* ∈NP
3.
P versus NP question
4.
$CFG ∈P via Dynamic Programming
5.
The Satisfiability Problem *$'
6.
Polynomial time reducibility
13
","73.40336608886719","1","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_13_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"85","What is the opinion about the possibility of proving P = NP or P ≠ NP within 20 years?"," 
 
  
 
  
 
 
  
 
 
 
 
 
 
 
18.404/6.840 Lecture 22 
Last time: 
- Finished NL = coNL 
- Time and Space Hierarchy Theorems 
Today: (Sipser §9.2) 
- A “natural” intractable problem 
- Oracles and P versus NP 
1 
","72.95639038085938","2","DPRSearchEngine","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_1_pdf","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22","18.404J","22"
"85","What is the opinion about the possibility of proving P = NP or P ≠ NP within 20 years?"," 
 
    
 
 
 
 
 
 
 
 
 
     
 
 
 
 
 
     
 
 
  
 
 
 
     
 
 
  
 
     
 
 
  
 
     
 
 
  
 
 
 
  
  
 
 
   
 
 
 
   
 
 
Check-in 26.3 
P = NP ? 
a) YES. Deep learning will do !""# ∈ P, but we won’t understand how. 
b) NO. 
But we will never prove it.
c) NO. 
We will prove it but only after 100 years
d) NO. 
We will prove it in ' years, 20 ≤ ' ≤ 100
e) NO. 
We will prove it in ' years, 1 ≤ ' < 20
f) NO. 
One of us is writing up the proof now…
9 
Check-in 26.3 
","71.19418334960938","3","DPRSearchEngine","7ac944716e076209c3964e073929f42e_MIT18_404f20_lec26_9_pdf","7ac944716e076209c3964e073929f42e_MIT18_404f20_lec26","18.404J","26"
"85","What is the opinion about the possibility of proving P = NP or P ≠ NP within 20 years?"," 
  
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
  
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
today
Or:
P = NP
previously
≤% *#+ ≤% 3*#+ ≤% (,-./0
NP
≤% */!*0+-*/1
≤% 2#13#+2
≤% /2#13#+2
NP
NP-complete
P
recitation
Quick Review 
Defn: ! is NP-complete if 
1) ! ∈ NP 
2) For all # ∈ NP, # ≤% ! 
If ! is NP-complete and ! ∈ P then P = NP. 
Importance of NP-completeness 
1) Evidence of computational intractability. 
2) Gives a good candidate for proving P ≠ NP. 
To show some language ( is NP-complete, 
show 3*#+ ≤% (. 
or some other previously shown 
NP-complete language 
2 
Check-in 16.1 
The big sigma notation means summing over some set. 
4 9 = 1 + 2 + ⋯+ > 
56768 
The big AND (or OR) notation has a similar meaning. 
For example, if ? = ?5 ⋯?8 and @ = @5 ⋯@8 are two 
strings of length >, when does the following hold? 
A ?7 = @7 
= TRUE 
56768 
(a) Whenever ? and @ agree on some symbol. 
(b) Whenever ? = @. 
Check-in 16.1 
","70.4921646118164","4","DPRSearchEngine","8212b19fc5a34f500ca6acf03a3a7d74_MIT18_404f20_lec16_2_pdf","8212b19fc5a34f500ca6acf03a3a7d74_MIT18_404f20_lec16","18.404J","16"
"85","What is the opinion about the possibility of proving P = NP or P ≠ NP within 20 years?"," 
 
  
  
 
 
 
 
 
 
 
 
 
 
   
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Recap: Separating Complexity Classes 
L ⊆ NL 
≠
⊆ P ⊆ NP ⊆ PSPACE 
Space Hierarchy Theorem 
NL ⊆ SPACE log& ' ⊆, SPACE ' ⊆ PSPACE 
12 
Check-in 21.3 
Consider these two famous unsolved questions: 
1. 
Does L = P? 
2. 
Does P = PSPACE? 
What do the hierarchy theorems tell us about 
these questions? 
a) Nothing 
b) At least one of these has answer “NO” 
c) 
At least one of these has answer “YES” 
Check-in 21.3 
","70.34091186523438","5","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_12_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"85","What is the opinion about the possibility of proving P = NP or P ≠ NP within 20 years?"," 
 
 
  
 
 
 
  
 
 
  
 
 
  
 
 
  
 
 
 
 
  
 
  
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
  
   
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
NO.
Oracles and P versus NP 
Theorem: There is an oracle ! where P "" = NP "" 
Proof: Let ! = $%&' 
NP()*+ ⊆ NPSPACE = PSPACE ⊆ P()*+ 
Relevance to the P versus NP question 
Recall: We showed -%./0↑ ∉ PSPACE. 
Could we show 3!$ ∉ P using a similar method? 
Reason: Suppose YES. 
The Hierarchy Theorems are proved by a diagonalization. 
In this diagonalization, the TM 4 simulates some TM 5. 
If both TMs were oracle TMs 4"" and 5"" with the same oracle !, 
the simulation and the diagonalization would still work. 
Therefore, if we could prove P ≠ NP by a diagonalization, 
we would also prove that P "" ≠ NP "" for every oracle !. 
But that is false! 
9 
Check-in 22.3 
Which of these are known to be true? 
Check all that apply. 
P7""( 
P7""( 
(a) 
= 
(b) NP7""( = coNP7""( 
(c) MIN-FORMULA ∈ P()*+ 
NP()*+ = coNP()*+ 
(d) 
Check-in 22.3 
","70.19450378417969","6","DPRSearchEngine","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_9_pdf","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22","18.404J","22"
"85","What is the opinion about the possibility of proving P = NP or P ≠ NP within 20 years?"," 
 
 
 
 
 
 
 
 
 
 
Quick review of today 
1. Log-space reducibility 
2. L = NL? question 
3. !""#$ is NL-complete 
4. 2&""# is NL-complete 
5. NL = coNL 
13 
","70.1430892944336","7","DPRSearchEngine","c9b742bd624556b45ac75ea2fb133b32_MIT18_404f20_lec20_13_pdf","c9b742bd624556b45ac75ea2fb133b32_MIT18_404f20_lec20","18.404J","20"
"85","What is the opinion about the possibility of proving P = NP or P ≠ NP within 20 years?"," 
 
 
 
 
 
 
 
  
 
 
  
  
18.404/6.840 Lecture 15 
Last time: 
- NTIME ! "" , NP 
- P vs NP problem 
- Dynamic Programming, #CFG ∈ P 
- Polynomial-time reducibility 
Today: (Sipser §7.5) 
- NP-completeness 
1 
","70.00773620605469","8","DPRSearchEngine","c1aca7046a69c913721e5eb910a5fb21_MIT18_404f20_lec15_1_pdf","c1aca7046a69c913721e5eb910a5fb21_MIT18_404f20_lec15","18.404J","15"
"85","What is the opinion about the possibility of proving P = NP or P ≠ NP within 20 years?","   
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
  
 
  
 
  
 
   
 
 
 
 
 
 
 
  
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
Review: NL ⊆ P 
Theorem: NL ⊆ P 
Proof: Say NTM "" decides # in space $ log ( . 
Defn: The configuration graph )*,, for "" on - has 
nodes: all configurations for "" on ­
edges: edge from ./ → .1 if ./ can yield .1 in 1 step. 
Claim: "" accepts - iff the configuration graph )*,, 
configuration graph )*,, 
.23453 
.466783 
iff "" accepts ­
has a path from .23453 to .466783 
Polynomial time algorithm 9 for #:
9 = “On input ­
1. Construct )*,,. [polynomial size] 
2. Accept if there is a path from .23453 to .466783. 
./ 
.1 
NL 
P 
Reject if not.” 
L = P? Unsolved 
L 
5 
","69.97779083251953","9","DPRSearchEngine","c9b742bd624556b45ac75ea2fb133b32_MIT18_404f20_lec20_5_pdf","c9b742bd624556b45ac75ea2fb133b32_MIT18_404f20_lec20","18.404J","20"
"85","What is the opinion about the possibility of proving P = NP or P ≠ NP within 20 years?","!""#$""%&'(% ∈NP
Defn:  !""#$""%&'(% = + + is not prime and + is written in binary} 
= + + = ,- for integers ,, - > 1,  + in binary} 
Theorem:  !""#$""%&'(% ∈NP
Proof:   “On input +
1.  Nondeterministically write , where 1 < , < +.
2.  Accept if , divides + with remainder 0.
Reject if not.”
Note:  Using base 10 instead of base 2 wouldn’t matter because can convert in 
polynomial time.
Bad encoding:  write number 3 in unary:  14 = 111 ⋯1
4
, exponentially longer.
Theorem (2002):  !""#$""%&'(% ∈P
We won’t cover this proof.
5
","69.86489868164062","10","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_5_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"86","What principle explains why if an FA with p states runs for more than p steps, it must enter some state twice?"," 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Generalized NFA 
Defn: A Generalized Nondeterministic Finite Automaton (GNFA) is 
similar to an NFA, but allows regular expressions as transition labels 
a
a ∗ b ∗ 
ab
!1 
#1 
#2 
For convenience we will assume: 
b 
ε 
- One accept state, separate from the start state 
∅ 
- One arrow from each state to each state, except 
a ∪ b 
aab 
a) only exiting the start state 
#3 
#4 
b) only entering the accept state 
ε 
We can easily modify a GNFA to have this special form. 
3 
","71.37281799316406","1","DPRSearchEngine","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3_3_pdf","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3","18.404J","3"
"86","What principle explains why if an FA with p states runs for more than p steps, it must enter some state twice?"," 
  
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
! −1 states
! states
$
$
%&
%'
%&
%'
()
(*
(+
(,
() (*
∗(+ ∪(,
!-state GNFA → (!—1)-state GNFA 
Check-in 3.1 
We just showed how to convert GNFAs to regular expressions 
but our goal was to show that how to convert DFAs to 
regular expressions. How do we finish our goal? 
(a) Show how to convert DFAs to GNFAs 
(b) Show how to convert GNFAs to DFAs 
(c) We are already done. DFAs are a type of GNFAs. 
Thus DFAs and regular expressions are equivalent. 
1. Pick any state $ except 
the start and accept states. 
2. Remove $. 
3. Repair the damage by 
recovering all paths that 
went through $. 
4. Make the indicated change 
for each pair of states %&, %' . 
Check-in 3.1 
5 
","69.90267181396484","2","DPRSearchEngine","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3_5_pdf","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3","18.404J","3"
"86","What principle explains why if an FA with p states runs for more than p steps, it must enter some state twice?"," 
 
 
 
  
 
 
 
 
  
   
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
          
 
 
  
  
   
 
 
 
 
  
 
 
 
  
 
 
Nondeterminism doesn’t
correspond to a physical machine
we can build. However, it is useful
mathematically.
accept
reject
accept
reject
Nondeterministic Finite Automata 
a 
a
!1 
b 
a,ε 
#1
#2 
#3 
#4 
b 
New features of nondeterminism: 
- multiple paths possible (0, 1 or many at each step) 
- ε-transition is a “free” move without reading input 
- Accept input if some path leads to 
accept 
Check-in 2.1 
Example inputs: 
What does !' do on input aab ? 
- ab 
- aa 
(a) Accept 
- aba 
(b) Reject 
- abb 
(c) Both Accept and Reject 
Check-in 2.1 
4 
","68.55593872070312","3","DPRSearchEngine","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_4_pdf","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2","18.404J","2"
"86","What principle explains why if an FA with p states runs for more than p steps, it must enter some state twice?","is regular → every long s 
is also 
 
 
 
 
 
 
   
 
 
 
 
  
 
 
  
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
  
  
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
tring in ! can be pumped and the result stays in !.
be the number of states in 0. Pick # ∈! where # ≥"".
'
(
)
0
12
#
The path that 0 foll
when reading #.
accepted
Method for Proving Non-regularity 
Pumping Lemma:   For every regular language !, 
there is a number "" (the “pumping length”) such that 
if # ∈! and # ≥ "" then # = '() where 
1) '(*) ∈ ! for all + ≥0
(* = (( ⋯( 
2) ( ≠ ε
'( ≤ ""
3) 
+
}
Informally: ! 
Proof:  Let DFA 0 recognize !. Let "" 
'
( 
)
# = 
12
12
0 will repeat a state 12 when reading 
because # is so long. 
'
(
( 
) 
12
12
12
Check-in 3.2 
The Pumping Lemma depends on the fact that 
if 0 has "" states and it runs for more than "" steps 
then 0 will enter some state at least twice. 
We call that fact: 
(a) The Pigeonhole Principle
(b) Burnside's Counting Theorem
(c) The Coronavirus Calculation
Check-in 3.2 
7 
","68.38162231445312","4","DPRSearchEngine","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3_7_pdf","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3","18.404J","3"
"86","What principle explains why if an FA with p states runs for more than p steps, it must enter some state twice?"," 
 
 
  
  
 
 
  
 
  
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Emptiness Problem for DFAs 
Let !DFA = & & is a DFA and ' & = ∅} 
Theorem: !DFA is decidable 
Proof: Give TM *E−DFA that decides !DFA . 
*E−DFA = “On input & 
[IDEA: Check for a path from start to accept.] 
1. 
Mark start state. 
2. 
Repeat until no new state is marked: 
Mark every state that has an incoming arrow 
from a previously marked state. 
3. 
Accept if no accept state is marked. 
Reject if some accept state is marked.” 
5 
","68.32002258300781","5","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_5_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"86","What principle explains why if an FA with p states runs for more than p steps, it must enter some state twice?","So the pumping lemma depends on the fact that if M has p states and it runs for more than p steps, then it's going to enter some state twice. So you may have seen that before. It actually has a name which some of you may have seen. So let's see how to just get a poll here. And I hope not too many of you are going to pick C, as it's-- some of you are. [LAUGHS] Oh well. Yes, I think this one most of you are-- you've seen this before. This is-- I think you pretty much all got it. This is what's known as the Pigeonhole Principle. So here, sharing the results, obviously I was having a little fun with this. I'm sure some of you were having fun back at me. That's OK.","68.22608184814453","6","DPRSearchEngine","KAySmSEGc9U.en-j3PyPqV-e1s_12_mp4","KAySmSEGc9U.en-j3PyPqV-e1s","18.404J","3"
"86","What principle explains why if an FA with p states runs for more than p steps, it must enter some state twice?","  
 
  
 
 
  
 
  
 
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
  
 
 
   
-
Review: Probabilistic TMs and BPP 
coin flip step 
each choice has 
Defn: A probabilistic Turing machine (PTM) is a variant of a NTM 
where each computation step has 1 or 2 possible choices. 
deterministic 
step 
50% probability 
Defn: For ! ≥0 say PTM $  decides language % with error probability !  
if for every &, Pr[ $  gives the wrong answer about & ∈% ] ≤! . 
Defn: BPP = % some poly-time PTM decides % with error !  = +⁄,  } Check-in 24.1 
Actually using a probabilistic algorithm 
Amplification lemma: 2−. /01 2 
presupposes a source of randomness. 
Can we use a standard pseudo-random 
number generator (PRG) as the source? 
& ∈% 
& ∉% 
(a) Yes, but the result isn’t guaranteed.
(b) Yes, but it will run in exponential time.
Many 
Few 
Few 
Many 
(c) No, a TM cannot implement a PRG. 
accepting 
rejecting 
accepting 
rejecting 
(d) No, because that would show P = BPP.
2 
Check-in 24.1 
","68.20191955566406","7","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_2_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"86","What principle explains why if an FA with p states runs for more than p steps, it must enter some state twice?","Defn:  BPP = "" some poly-time PTM decides "" with error # = ⁄
% & }
Amplification lemma: If '% is a poly-time PTM with error #% < ⁄
% ) then, 
for any 0 < #) < ⁄
% ), there is an equivalent poly-time PTM ') with error #).  
Can strengthen to make #) < 2−,-./ 0 . 
Proof idea:  ') = “On input 1
1.  Run '% on 1 for 2 times and output the majority response.”
Details:  Calculation to obtain 2 and the improved error probability. 
Significance:  Can make the error probability so small it is negligible.
The Class BPP
3
","68.1169204711914","8","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_3_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"86","What principle explains why if an FA with p states runs for more than p steps, it must enter some state twice?"," 
 
   
 
 
 
 
 
 
 
    
       
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Multi-tape Turing machines 
input tape 
Finite 
control 
. . .
}work tapes, initially blank 
all tapes read/write 
Theorem: ! is T-recognizable iff some multi-tape TM recognizes ! 
Proof: (→) immediate. 
(←) convert multi-tape to single tape: 
& simulates ' by storing the contents of 
multiple tapes on a single tape in “blocks”. 
a a b b a 
. . .
˽ ˽ 
Record head positions with dotted symbols. 
multi-tape 
' 
˽
1 0 1 
. . . 
˽
c c c a 
. . . 
. . . 
Some details of &: 
1) To simulate each of '’s steps 
a. Scan entire tape to find dotted symbols. 
b. Scan again to update according to '’s (.
single tape 
& 
… 
˽ ˽
a a b b a # 1 0 1 # 
# c c c a 
c. Shift to add room as needed. 
2) Accept/reject if ' does. 
3 
","68.07907104492188","9","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_3_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"86","What principle explains why if an FA with p states runs for more than p steps, it must enter some state twice?","Read-once Branching Programs
Defn: A BP is read-once if it never queries a variable more than once 
on any path from the start node to an output. 
Defn:  !""ROBP =
(), (+
() and (+ are equivalent read-once BPs}
Theorem:   !""ROBP ∈BPP 
.)
./
.)
.+
.+
./
0
1
0
1
0
1
0
1
0
1
0
1
0
1
Not read-once
Check-in 23.2
Check-in 23.2
Assuming (as we will show) that !""ROBP ∈BPP, 
can we use that to show !""BP ∈BPP by converting 
branching programs to read-once branching programs?
(a) Yes, there is no need to re-read inputs.
(b) No, we cannot do that conversion in general.
(c) No, the conversion is possible but not in polynomial-time.
6
","68.05809020996094","10","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_6_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"88","Why do we need a 2 by 3 neighborhood to ensure a legitimate tableau in a computation history?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","72.25481414794922","1","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"88","Why do we need a 2 by 3 neighborhood to ensure a legitimate tableau in a computation history?","we're not going to put the drunk in. We're going to raise a value error, ""Duplicate drunk."" Otherwise we're going to set the value of drunkenness mapping to loc. Now you see, by the way, why I wanted drunks to be immutable. Because they have to be hashable so I can use them as a key in a dictionary. So it was not an idle question whether they were immutable. It was an important question. I can get the location of a drunk. If the drunk is not in there, then I'll raise a different value error, ""Drunk not in field."" Otherwise I'll return the location associated with that drunk. And finally, we're going to have moveDrunk.","71.51206970214844","2","DPRSearchEngine","6wUD_gp5WeE.en-qlPKC2UN_YU_9_mp4","6wUD_gp5WeE.en-qlPKC2UN_YU","6.0002","5"
"88","Why do we need a 2 by 3 neighborhood to ensure a legitimate tableau in a computation history?","And here is another kind of a weird legal neighborhood. If you have a, b, c, and then the a changes to a d, that could also be a legal neighborhood if the machine transition function allows an a to get converted to a d when there is some machine-- when there is some state reading that a, and that state also moves its head left. So it doesn't move into this picture. So those are examples of legal neighborhoods. Let me show you some illegal neighborhoods. Just I'm doing this-- this is kind of a proof by example now. This is perhaps the most intuitive part. But I claim that this is easy to turn this into something airtight and formal. So this would be clearly illegal. If you have a piece of the tape in the previous step where it's a, b, c, and then suddenly the b changes to a d. The symbol on the tape changes out of nowhere without having a head nearby to a different-- to something else. That could never happen. So that would be illegal. Another thing that would be illegal is if a state appears from nowhere. That could never happen. Or if it just disappears. That could never happen. And here's another-- here's an interesting one. If a state becomes two states. Don't forget the machine is nondeterministic. So the machine in principle could move its head left on one branch and move its head right on a different branch, but those would have to be in different tableaus. They can't be in the same tableau, because that doesn't correspond to any of the threads of the computation, those with multiple threads. And I say this because if you think about my claim, which is going to put down over here, that if every 2 by 3 neighborhood is legal, then the tableau overall corresponds to a computation history. This illustrates why it's not enough to have a 2 by 2 neighborhood, where you really need the 2 by 3. Because if this was a 2 by 2 neighborhood, if you just look at these four-- this leftmost 2 by 2, that could be a legal neighborhood if it was a 2 by 2, if the rules of the machine allowed for that. And the right four box-- right four cells could also be a legal neighborhood. So you could have something that looks OK from the perspective of 2 by 2 neighborhoods, but globally, in terms of the overall tableau, it's completely nonsensical because it has multiple hits. But if you have a 2 by 3 neighborhood, it's big enough to prevent this situation from occurring. And then you can check the details. And I think it's very plausible that it guarantees that the overall tableau is legitimate if all of the 2 by 3 neighborhoods are legal. And so that's what we're going to turn into a Boolean expression. We're going to say for each cell that the set-- for each neighborhood-- so here's a neighborhood at the i, j location. I'm calling this position here sort of the home location for that neighborhood. For each neighborhood, it has to be set to one of the legal possibilities. And there's, again, only a fixed number of those because there's a fixed number of possible symbols that can appear in those cells. So this is that fixed number to the sixth power at most. And I'm going to say that the cell in the upper left, which would be this one, is in r. And this one here is an s. And this one is a t. And this one is a v, if you just trace down what the indices are telling you. It says that that piece of the tape, that piece of the tableau here is set according to one of the possible legal settings. And we're just going to OR over all of those possible fixed number of legal settings. And then I take an AND over all possible tape cells, over all possible neighborhoods. And so that's going to be my phi move. And that's it. OK. Let's see. Can I explain again the third example of illegal? So this one over here, I presume, I'm being asked about. Well, if the machine is in a state q7 reading a c, the head has to move either left or right. So at the next configuration, there's got to be a state symbol appearing either in this cell or in this cell. And here the tape-- the head has basically just vanished with nowhere to-- it's gone. That could not happen according to the rules of the machine the way we talk about Turing machines. So that's not possible. So this would be an illegal neighborhood. You want to prevent any of the bad stuff from happening anywhere in here. So only good stuff can be happening locally. And that guarantees the overall picture is OK. Do we have to check that the head doesn't leave the tableau from the left most to right right? Yeah, there are some little details here like that. So the question is, do I have to make sure that the-- yeah, you probably need to mark. I think the book probably does this correctly. You may have to mark the left and right ends to make sure that-- I mean, the right end is not a problem, because the machine can never go off the right end. And if you design the machine so that it never moves its head off the left end either, which you can do, then you wouldn't have to worry about that possibility. But otherwise, you would have to put some sort of delimiter here to enforce the head not moving off the left end. So there are some details like that, too. There will be two heads in the same row. No, this can-- I don't know what you-- somebody says, there will be two heads in the same row. Please elaborate, because this is designed not to allow two heads in the same row. Could I go over the OR for legal again? OK. The OR, the big OR here, what I have in mind is I take-- there's going to be-- first of all, I look at the machine and I look at the transition function. And based on that, I write down the list of all the legal 2 by 3 neighborhoods. So all the settings which correspond to legal 2 by 3 neighborhoods. There's going to be some fixed number of those. 100. There's 100 possible legal neighborhoods of which I've written down here four. But maybe there's some number, say 100. So now there's going to be an OR over those 100 different possibilities. It's either going to be this legal neighborhood, or some other legal neighborhood, or some other legal neighborhood. And for each one of those legal neighborhoods, I'm going to say, well, the variables are set according to that legal neighborhood, or the variables are set according to the next legal neighborhood, or the variables are set according to the next legal neighborhood, and do that 100 times. One of those has got to end up-- I mean it's an OR, so one of them has to work. Otherwise, the formula fails. And it will be false, because you're going to AND that over all of the neighborhoods in the picture. Is it possible to have a head on the far left of the configuration and one on the far right? You mean a head over here and a head over there? I mean, how'd the head get there? It can't happen. You know, the head has to come from a head above it. If you're going to be worrying about the details of the boundaries here, all that's fixable. So let's not lose sight of the main idea. I mean, if you understand the main idea, you can fix the little details. So I want to make sure you understand the main idea of what's happening. So let's finish up this proof. So in summary, we gave a reduction from 8 to SAT. This is what we needed. It was in those four pieces. And you really just need to argue that that formula we're building is not too big. And it's going to be basically the size of the tableau if you look at what we constructed. The number of variables is roughly the size of the tableau. And the amount of logic that we're putting into the formula is also going to be a fixed amount of logic independent of n for each of the variables in that tableau. And somebody asked me about the size-- how big the indices are. The indices for the x i value, the i and j values, technically, they're going to be numbers between 1 and n to the k. So you're going to have to write those down. And so that's going to be a slight additional logarithmic cost to write those things down. It's not really that interesting a point. And so the overall f is going to be computable in polynomial time because the output is not very big. And it's also not complicated to write the output down. So that's the end of the proof. I can take a couple of questions. Why can't we just check that the whole-- this is a good question. Why can't we just check that the whole row is legal? You can check that a row actually is a configuration. But to check that the row follows from the previous row, ultimately, the operation of a Turing machine is a local thing. I mean, the way it moves from one configuration to the next depends locally on how where the head is. And so really, that's just another way of-- the way I'm saying it is just really checking the whole configuration, but just doing it locally. I don't know if that's satisfying to you. Why don't I move on because I just want to make sure we have enough time to get to the very last part, which is a little bit-- I'm afraid, a little technical. So we're going to kind of shift gears now and talk about reducing SAT to 3SAT. And let's see how it goes. I don't always have the most success with presenting this little piece, because it's slightly a technical argument. But if you don't get it, don't worry. Just you have to accept that it's true. But I'd like to show it to you just to make the whole presentation complete in that sense. So I'm going to give a reduction that maps general formulas to 3CNF formulas. So that's how we map SAT to 3SAT. If you remember 3SAT is satisfiability but for three CNFs. So a conjunctive normal form in the form of those clauses, which are ANDed together. And each clause is an OR of a bunch of literals, which are variables or negated variables. So I want to convert phi to phi prime, which is 3CNF formula, but preserve the satisfiability. And phi prime is not going to be logically equivalent to phi, because I could do that, too. I can convert any formula to a logically equivalent CNF formula. Maybe not even a 3CNF, but yeah, you won't be able to get a 3CNF, but you can get a CNF. But it might be exponentially larger. And that's not good enough. I have to do the reduction in polynomial time. So I can't generate a much larger formula that's exponentially larger. And so I'm going to do that by adding additional variables. So it won't be logically equivalent because the new formula is going to have additional variables in it. I'm going to kind of do it by example. And we'll see how that goes. So here's phi, which is not in 3CNF. It's not even in CNF, because it's got ORs of ANDs appearing, which is not allowed to happen in a CNF. So how are we going to convert that into a 3CNF formula preserving the satisfiability? And just working it through with this example, I hope to at least give you some idea of how you do the conversion in general. So first of all, I'm going to represent this formula as a tree using its natural tree structure. So you understand. So a AND B becomes a AND b written as a tree. And then I OR that with c. So I get the tree structure here in sort of the natural way. And I'm going to label all of these intermediate nodes, which are associated now with operations. And I'm assuming also that the formula is fully parenthesized so that each operation I'm only thinking about is applying just the two-- it's a binary operation. And let's ignore negations for the minute, because negations, you can always push those through down to the leaves. But it's just going to make it too complicated. So negations turn out not to be a problem. So there's only going to be negations at the level of the inputs, not at the negation operations in the middle. So we have this tree structure here. And now I'm going to use these two logical facts. And I don't know if-- you've probably all seen ANDs and ORs, I hope. Otherwise, it's going to be really tough. But there's also other logical operators, such as the implication operator, where you have A implies B sort of as a logical operation. And so this requires that if A is true, then B is true. However, if A is false, B can be anything. And similarly if B is true, A can be anything. The only thing that's prohibited is that if A is true and B is false. That's the only thing that would be invalid. And so if you think about it, that's going to be equivalent to saying that either A is false or B is true. One of those has to be. And that's going to be logically equivalent to saying that A implies B. Another logical equivalence may be more familiar to you. It's just simply De Morgan's law, which says that if you have the not of A AND B, that's equivalent to saying the not of A or the not of B. I'm going to make use of both of these. Now, here, I want to-- I ran out of room on this slide. So I'm going to take myself out of the picture here for a minute. I had no place else to put this. So here we have-- if you're going to think of the AND in terms of its truth table, so here's a and b in terms of a and b. So 1 and 1 is 1, but all other settings of a and b yield 0 for the AND. And I'm going to represent those-- if you imagine a and b is going to be called c. I'm going to represent this information with four small formulas, which taken together, you AND them together, are going to force c to have the correct behavior associated with a AND b. So if a AND b are both 1, then c is 1. If a is 0 and b is 1, then it forces c to be 0. And similarly, every other setting besides a AND b being true, for C to be false, which is what you want when you have AND. So I'm going to write this expression here down with z1 being in the place of c by just taking those four expressions and ANDing them together. So this is exactly those same four expressions written out linearly. Now I want to do the same thing for z2, but now that's written in terms of an OR. So there's a slightly different truth table here up in this corner. So now if either one is 1, we get a 1 result. And so now if a AND b are true, you get c is true. However, if a is true and b is false, that still implies c is true. So I'm going to write down those rules for specifying how z2 must be set. And each one of these things is going to get converted into clauses, three clauses with three literals, using these rules over here. So I'm going to do that for each zi. And lastly, to make sure the whole thing is satisfied, which means there's an output of one here, I'm going to have one clause associated, which says that z4, the output, is 1. Now, I can convert all of those when I have a AND b implies c. That's logically equivalent to not a OR not b OR c. And the way you can see that is really by repeated application of these rules here. We're running a little low on time. So maybe you'll just have to check this offline. But quickly, a AND b implies c using the first equivalence is the not of this part, OR C. And then I can use De Morgan to convert that not of an AND to an OR of the nots. And then I can remove the parentheses because OR is associative. And so I get a clause, which is what I need. So each one of these guys is really equivalent to a clause. And so I just get a bunch of clauses. And actually, technically, this needs to be three, a copy of three things here. It should be z4 OR z4 OR z4, which is a lot. So check-in-- [INAUDIBLE] I realize my check-in is broken, because I only realized that last point just now as I was talking. So the actual value that you get in terms of-- oh, no, the number of clauses is correct. No, I take it back. This is fine. So if you understood what I was saying, hopefully, you can see how big the formula phi prime is in terms of the number of operations in phi. So let's see how many people get that. I acknowledge this may be a little on the technical side. OK. I'm going to close it, close it down. Please enter your value. OK. Yeah, the correct answer is 4k plus 1, because each one of these operations is going to end up being a row in this picture. Each operation is going to have a variable associated to it. It's going to become a row in this picture. And so then each row is going to have four clauses, which define what you need-- set what you need in order to force that variable to have the right value corresponding to that operation. And so then you need-- and you need one extra clause here for saying that this whole thing evaluates to true. So that's all I wanted to do today. We proved those two main theorems. And now we know that there are NP-complete problems. And all of the other problems that we can get from-- by reductions from these problems are also going to be NP-complete as long as they're in NP. So that's it. Feel free to put some questions into the chat, or move on to whatever else you're going to be doing next. So a good question here is, why is phi prime not logically equivalent with this construction? It can't be logically equivalent. Logically equivalent means that it gives you exactly the same function. If you set the variables in the same way, you get the same result coming out. Well, phi prime has more variables than phi does. So it wouldn't even make sense to talk about logical equivalence because they're two functions on different numbers of variables. So in that sense, it doesn't really make sense. What you could say is that for every setting of the overlapping variables, so the variables that appear in both phi and phi prime-- so those are the original variables of phi-- there's going to exist some setting of new variables, which is going to make the-- there's going to be-- there will exist some setting of the new variables which will make the two formulas agree, but that's not the definition of logical equivalence. So why-- going back to the proof, the satisfiability proof and the legal neighborhoods, could I go over why the number of legal neighborhoods is polynomial. The number of legal neighborhoods is not only polynomial. It's constant. It depends only on the machine. It does not depend on M. Because each cell can have at most some fixed number of-- can have the number of tape symbols plus the number of state symbols. That depends on the machine only. So now we have six tape cells for the six cells in a 2 by 3 neighborhood. So you're going to have that number to the sixth power. But still, it's a constant to the sixth power. It's still a constant. It doesn't depend on M. So it's not a question of even being polynomial. It's a constant value. It's a constant multiplier if you want to think about it in terms of the size of the formula that's going to result. Don't forget we're trying to make a formula which is-- the reduction has to be polynomial. It's a polynomial time reduction. So that means that as n increases, the time to calculate the reduction increases as a polynomial. But we're fixing M. So M does not change. So therefore anything that depends on M only is just going to be a constant impact on the formula. It's not going to be-- it doesn't depend on M. OK, everybody. Bye bye. See you.","71.16699981689453","3","DPRSearchEngine","6Az1gtDRaAU.en-j3PyPqV-e1s_11_mp4","6Az1gtDRaAU.en-j3PyPqV-e1s","18.404J","16"
"88","Why do we need a 2 by 3 neighborhood to ensure a legitimate tableau in a computation history?","2 
Lecture 20: Course Review 
Next Steps 
• (U) 6.046: Design & Analysis of Algorithms 
• (G) 6.851: Advanced Data Structures 
• (G) 6.854: Advanced Algorithms 
6.046 
• Extension of 6.006 
– Data Structures: Union-Find, Amortization via potential analysis 
– Graphs: Minimum Spanning Trees, Network Flows/Cuts 
– Algorithm Design (Paradigms): Divide & Conquer, Dynamic Programming, Greedy 
– Complexity: Reductions 
• Relax Problem (change deﬁnition of correct/efﬁcient) 
– Randomized Algorithms 
∗ 6.006 mostly deterministic (hashing) 
∗ Las Vegas: always correct, probably fast (like hashing) 
∗ Monte Carlo: always fast, probably correct 
∗ Can generally get faster randomized algorithms on structured data 
– Numerical Algorithms/Continuous Optimization 
∗ 6.006 only deals with integers 
∗ Approximate real numbers! Pay time for precision 
– Approximation Algorithms 
∗ Input optimization problem (min/max over weighted outputs) 
∗ Many optimization problems NP-hard 
∗ How close can we get to an optimal solution in polynomial time? 
• Change Model of Computation 
– Cache Models (memory hierarchy cost model) 
– Quantum Computer (exploiting quantum properties) 
– Parallel Processors (use multiple CPUs instead of just one) 
∗ Multicore, large shared memory 
∗ Distributed cores, message passing 
","70.86772918701172","4","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_2_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"88","Why do we need a 2 by 3 neighborhood to ensure a legitimate tableau in a computation history?","which, I think, most of us would agree was not a very big number. And let's look what's going on here. If you look at this, what in some sense seems really stupid about it? What is it doing that a rational person would not want to do if they could avoid it? It's bad enough to do something once. But to do the same thing over and over again is really wasteful. And if we look at this, we'll see, for example, that fib 4 is being computed here, and fib 4 is being computed here. Fib 3 is being considered here, and here, and here. And do you think we'll get a different answer for fib 3 in one place when we get it in the other place? You sure hope not. So you think, well, what should we do about this? How would we go about avoiding doing the same work over and over again? And there's kind of an obvious answer, and that answer is at the heart of dynamic programming. What's the answer? AUDIENCE: [INAUDIBLE] JOHN GUTTAG: Exactly. And I'm really happy that someone in the front row answered the question because I can throw it that far. You store the answer and then look it up when you need it. Because we know that we can look things up very quickly. Dictionary, despite what Eric said in his lecture, almost all the time works in constant time if you make it big enough, and it usually is in Python. We'll see later in the term how to do that trick. So you store it and then you'd never have to compute it again. And that's the basic trick behind dynamic programming. And it's something called memoization, as in you create a memo and you store it in the memo. So we see this here. Notice that what we're doing is trading time for space. It takes some space to store the old results, but negligible related to the time we save. So here's the trick. We're going to create a table to record what we've done. And then before computing fib of x, we'll check if the value has already been computed. If so, we just look it up and return it. Otherwise, we'll compute it-- it's the first time-- and store it in the table. Here is a fast implementation of Fibonacci that does that. It looks like the old one, except it's got an extra argument-- memo-- which is a dictionary. The first time we call it, the memo will be empty. It tries to return the value in the memo. If it's not there, an exception will get raised, we know that.","70.7728271484375","5","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_9_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"88","Why do we need a 2 by 3 neighborhood to ensure a legitimate tableau in a computation history?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","70.24703216552734","6","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"88","Why do we need a 2 by 3 neighborhood to ensure a legitimate tableau in a computation history?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 16: Dyn. Prog. Subproblems 
Lecture 16: Dyn. Prog. Subproblems 
Dynamic Programming Review 
• Recursion where subproblem dependencies overlap, forming DAG 
• “Recurse but re-use” (Top down: record and lookup subproblem solutions) 
• “Careful brute force” (Bottom up: do each subproblem in order) 
Dynamic Programming Steps (SRT BOT) 
1. Subproblem deﬁnition 
subproblem x 2 X 
• Describe the meaning of a subproblem in words, in terms of parameters 
• Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence 
• Often multiply possible subsets across multiple inputs 
• Often record partial state: add subproblems by incrementing some auxiliary variables 
2. Relate subproblem solutions recursively 
x(i) =  f(x(j), . . .) for one or more j < i  
• Identify a question about a subproblem solution that, if you knew the answer to, reduces 
the subproblem to smaller subproblem(s) 
• Locally brute-force all possible answers to the question 
3. Topological order to argue relation is acyclic and subproblems form a DAG 
4. Base cases 
• State solutions for all (reachable) independent subproblems where relation breaks down 
5. Original problem 
• Show how to compute solution to original problem from solutions to subproblem(s) 
• Possibly use parent pointers to recover actual solution, not just objective function 
6. Time analysis 
P 
• 
x2X work(x), or if work(x) =  O(W) for all x 2 X, then |X| · O(W) 
• work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time 
","70.03013610839844","7","DPRSearchEngine","28461a74f81101874a13d9679a40584d_MIT6_006S20_lec16_1_pdf","28461a74f81101874a13d9679a40584d_MIT6_006S20_lec16","6.006","16"
"88","Why do we need a 2 by 3 neighborhood to ensure a legitimate tableau in a computation history?","The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high-quality educational resources for free. To make a donation, or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. JOHN GUTTAG: I'm a little reluctant to say good afternoon, given the weather, but I'll say it anyway. I guess now we all do know that we live in Boston. And I should say, I hope none of you were affected too much by the fire yesterday in Cambridge, but that seems to have been a pretty disastrous event for some. Anyway, here's the reading. This is a chapter in the book on clustering, a topic that Professor Grimson introduced last week. And I'm going to try and finish up with respect to this course today, though not with respect to everything there is to know about clustering. Quickly just reviewing where we were. We're in the unit of a course on machine learning, and we always follow the same paradigm. We observe some set of examples, which we call the training data. We try and infer something about the process that created those examples. And then we use inference techniques, different kinds of techniques, to make predictions about previously unseen data. We call that the test data. As Professor Grimson said, you can think of two broad classes. Supervised, where we have a set of examples and some label associated with the example-- Democrat, Republican, smart, dumb, whatever you want to associate with them-- and then we try and infer the labels. Or unsupervised, where we're given a set of feature vectors without labels, and then we attempt to group them into natural clusters. That's going to be today's topic, clustering. So clustering is an optimization problem. As we'll see later, supervised machine learning is also an optimization problem. Clustering's a rather simple one. We're going to start first with the notion of variability. So this little c is a single cluster, and we're going to talk about the variability in that cluster of the sum of the distance between the mean of the cluster and each example in the cluster. And then we square it. OK? Pretty straightforward. For the moment, we can just assume that we're using Euclidean distance as our distance metric. Minkowski with p equals two. So variability should look pretty similar to something we've seen before, right? It's not quite variance, right, but it's very close. In a minute, we'll look at why it's different. And then we can look at the dissimilarity of a set of clusters, a group of clusters, which I'm writing as capital C, and that's just the sum of all the variabilities. Now, if I had divided variability by the size of the cluster, what would I have? Something we've seen before. What would that be? Somebody? Isn't that just the variance? So the question is, why am I not doing that? If up til now, we always wanted to talk about variance, why suddenly am I not doing it? Why do I define this notion of variability instead of good old variance? Any thoughts? What am I accomplishing by not dividing by the size of the cluster? Or what would happen if I did divide by the size of the cluster? Yes. AUDIENCE: You normalize it? JOHN GUTTAG: Absolutely. I'd normalize it. That's exactly what it would be doing. And what might be good or bad about normalizing it? What does it essentially mean to normalize? It means that the penalty for a big cluster with a lot of variance in it is no higher than the penalty of a tiny little cluster with a lot of variance in it. By not normalizing, what I'm saying is I want to penalize big, highly-diverse clusters more than small, highly-diverse clusters. OK? And if you think about it, that probably makes sense. Big and bad is worse than small and bad. All right, so now we define the objective function. And can we say that the optimization problem we want to solve by clustering is simply finding a capital C that minimizes dissimilarity? Is that a reasonable definition? Well, hint-- no. What foolish thing could we do that would optimize that objective function? Yeah. AUDIENCE: You could have the same number of clusters as points? JOHN GUTTAG: Yeah. I can have the same number of clusters as points, assign each point to its own cluster, whoops. Ooh, almost a relay. The dissimilarity of each cluster would be 0. The variability would be 0, so the dissimilarity would be 0, and I just solved the problem. Well, that's clearly not a very useful thing to do. So, well, what do you think we do to get around that? Yeah. AUDIENCE: We apply a constraint? JOHN GUTTAG: We apply a constraint. Exactly. And so we have to pick some constraint. What would be a suitable constraint, for example? Well, maybe we'd say, OK, the clusters have to have some minimum distance between them. Or-- and this is the constraint we'll be using today-- we could constrain the number of clusters. Say, all right, I only want to have at most five clusters. Do the best you can to minimize dissimilarity, but you're not allowed to use more than five clusters. That's the most common constraint that gets placed in the problem. All right, we're going to look at two algorithms. Maybe I should say two methods, because there are multiple implementations of these methods. The first is called hierarchical clustering, and the second is called k-means. There should be an S on the word mean there. Sorry about that. All right, let's look at hierarchical clustering first.","69.90992736816406","8","DPRSearchEngine","esmzYhuFnds.en-qlPKC2UN_YU_1_mp4","esmzYhuFnds.en-qlPKC2UN_YU","6.0002","12"
"88","Why do we need a 2 by 3 neighborhood to ensure a legitimate tableau in a computation history?"," 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
18.404/6.840 Lecture 8 
Last time: 
- Decision procedures for automata and grammars
!DFA , !NFA , &DFA , &'DFA , !CFG , &CFG are decidable 
!TM is T-recognizable 
Today: (Sipser §4.2) 
- !TM is undecidable 
- The diagonalization method 
- !TM is T-unrecognizable 
- The reducibility method 
- Other undecidable languages 
1 
","69.86322784423828","9","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_1_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"88","Why do we need a 2 by 3 neighborhood to ensure a legitimate tableau in a computation history?"," 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 18: Pseudopolynomial 
Lecture 18: Pseudopolynomial 
Dynamic Programming Steps (SRT BOT) 
1. Subproblem deﬁnition 
subproblem x ∈ X 
• Describe the meaning of a subproblem in words, in terms of parameters 
• Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence 
• Often multiply possible subsets across multiple inputs 
• Often record partial state: add subproblems by incrementing some auxiliary variables 
• Often smaller integers than a given integer (today’s focus) 
2. Relate subproblem solutions recursively 
x(i) = f(x(j), . . .) for one or more j < i 
• Identify a question about a subproblem solution that, if you knew the answer to, reduces 
the subproblem to smaller subproblem(s) 
• Locally brute-force all possible answers to the question 
3. Topological order to argue relation is acyclic and subproblems form a DAG 
4. Base cases 
• State solutions for all (reachable) independent subproblems where relation breaks down 
5. Original problem 
• Show how to compute solution to original problem from solutions to subproblem(s) 
• Possibly use parent pointers to recover actual solution, not just objective function 
6. Time analysis 
P 
• 
work(x), or if work(x) = O(W ) for all x ∈ X, then |X| · O(W )
x∈X 
• work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time 
","69.85332489013672","10","DPRSearchEngine","mit6_006s20_lec18_1_pdf","mit6_006s20_lec18","6.006","18"
"89","What are the five components of a finite automaton as defined by a 5-tuple, and what does each component represent?","OK, so now we gave it this informal idea of a finite automaton. We're going to have to try to get a formal definition now, which is going to be a more mathematical way of saying the same thing that I just said. And the reason for having a formal definition is, for one thing, it allows us to be very precise. Then we'll know exactly what we mean by a finite automaton, and it should answer any questions about what counts and what doesn't count. It also is a way of providing notation. So it'll help us describe finite automata. And sometimes there might be an automaton where the picture is just too big, so you might want to be able to describe it in some mathematical terminology rather than by giving a picture. Or maybe you're going to be asked to give a family of automata, where there is going to be a parameter, N, associated with the class of languages you're trying to describe with the automaton. And then it'll be more helpful to describe it in this formal notation rather than as a kind of a picture, because it might be infinitely many pictures that are being needed. So maybe examples of that will come up now. So a finite automaton, we call it a 5-tuple. Don't be put off by that. A 5-tuple is just a list of five things. So a finite automaton, in our definition, is going to have five components. It's going to have Q, which is going to be a finite set of states, so it's going to be a finite set, which we'll designate as the states of the automaton. Sigma is the alphabet symbols of the automaton, another finite set. Delta is the transition function. That tells us how the automaton moves from state to state. Those describes how those transition arrows-- those arrows which connected the states with each other-- it describes them in a mathematical way instead in terms of a picture. And the way I'm doing that is with a function. So delta is a function which takes two things. So I'm hoping you've seen this notation before. I'll help you through it once, but this is the kind of thing I would expect you to have seen already. So we have Q cross sigma. So I'm going to give delta a state and an alphabet symbol. So Q is states, sigma is alphabet symbols. So you're going to get a state and an alphabet symbol, and it's going to give you back a state. So describing it kind of a little bit more detail, delta, if you give it state q and symbol a equals r, that means q, when you read an a, you go to r. So that's the way this picture gets translated into a mathematical function, which describes those transitions. And then now q0 is going to be the starting state. That's the one with the arrow coming in from nowhere. And F is the set of accepting states. So there's only going to be one starting state, but there might be several different-- or possibly even 0-- accepting states. That's all legal when we have a finite automaton. And so in terms of using the notation-- going back to the machine that we just had from the previous slide, which I've given you here again-- let me show you how I would describe this using this notation that comes out of the definition. So here is M1 again. It's this 5-tuple where Q now is the set-- q1, q2, q3-- that's the set of states. The input alphabet is 0, 1. It might vary in other automata. And f is the set q3, which has only the element q3, because this has just one accept state, q3. So I hope that's helpful. Oh, of course, I forgot the transition function, which here I'm describing as a table. So the transition function says if you have a state and an input alphabet, you can look up in the table where you're supposed to go under the transition function according to the state and the alphabet symbol that you're given. So, for example, if we were in state q2 here getting a 0, then q2 goes back to q1 so that q2 on 0 is q1. But q2 on 1 here is q3. OK? So that's how that table captures this picture. OK? And it's just a function. It's a way of representing a function, a finite function, in terms of this table here. So I realize, for some of you, this may be slow. We will ramp up in speed, but I'm trying to get us all together in terms","74.06471252441406","1","DPRSearchEngine","9syvZr-9xwk.en-j3PyPqV-e1s_6_mp4","9syvZr-9xwk.en-j3PyPqV-e1s","18.404J","1"
"89","What are the five components of a finite automaton as defined by a 5-tuple, and what does each component represent?","So we're going to talk about models of computation, as I mentioned. We want to try to understand computers, and we want to understand what computers can do. But computers in the real world are pretty complicated objects, and they're really not nice to talk about mathematically. So we're going to talk about abstract models of computers that are much simpler but really capture-- just like models in general-- capture the important aspects of the thing we're trying to understand. And so we're going to look at several different kinds of models that vary in their capabilities and the way they approximate the real computers that we deal with every day. And for starters, we're going to look at a very simple model called the finite automaton. And that's going to represent-- you can think of it as representing a computer that has a very small amount of memory and a very limited and small amount of memory. And we're going to look at the capabilities of those kinds of machines. And what's nice about them is that you can understand them very well. And so more powerful models that we're going to look at later are going to be harder to understand in as deep a way. But for these, we can develop a very comprehensive theory. And so that's what we're going to do for the next lecture and a half. So I'm starting off with an example. I'm presenting a finite automaton as a diagram-- we call it a state diagram. It has these circles and lines and labels on the lines and also on these circles. So what's going on here? So this is a finite automaton. I'm giving it the name M1.","72.47590637207031","2","DPRSearchEngine","9syvZr-9xwk.en-j3PyPqV-e1s_4_mp4","9syvZr-9xwk.en-j3PyPqV-e1s","18.404J","1"
"89","What are the five components of a finite automaton as defined by a 5-tuple, and what does each component represent?","We're given a sequence of symbols. And so the natural thing is to try prefixes, suffixes, and substrings. I'm going to jump ahead and think about the relation first. I want to identify some question about a subproblem or its solution that would let me reduce to smaller subproblems. This is a little trickier. This is very different. We're not always doing something on the left or on the right, or we can't assume there's something happening on the left, because maybe we take a product in the middle first. If I take a product in the middle first, then I have some result here, but I still have three things. I have the thing to the left, I have the thing in the middle, and I have the thing on the right. It turns out to be very messy to think about what the first operation is. Because we can think of this as a tree, where we take a product here-- we take a sum of 7 and 4 and 3 and 5 over here and then take the product at the root. But I don't know what the tree is, right? I only know these numbers and these operators, but I don't know how to organize this tree. The idea is, if you think of this tree, what is the one thing that's easiest to identify? It's the root. The root corresponds to the last operation I do in this computation. The last thing I did was take a product. And that's a lot easier, because if I guess who is at the root-- which operator is at the root-- that naturally decomposes into the left subtree and the right subtree. And those will always be substrings. We kind of know this. This node corresponds to everything left of this operator, and this substring or this subtree corresponds to everything to the right of the operator. So this is our idea, is we're going to guess which operation, star i, is evaluated last-- or, in other words, at the root. So this is the question. It has n possible answers-- I guess, actually, n minus 1 from operator 1, operator n minus 1. And so we'll just brute force all of those choices. I wanted to start here because-- to realize that if, I choose some star i in the middle, which might be the right thing, like in this example. Star i is the middle one-- middle operator. I naturally decompose into everything to the left of that operator and everything to the right of that operator. This is a prefix. This is a suffix. So you might think, oh, my subproblems are all prefixes and all suffixes. But that would be wrong, because if you have a bunch of operators-- and say you choose this one to be last. So I have a prefix here and a suffix here. And then there will be some-- within this suffix, I'll choose some operator to be the root of that one, and I have a prefix and a suffix of this suffix. But in particular, I will have to evaluate this subproblem, which is a prefix of a suffix-- in other words, a substring. So never use a mixture of prefixes and suffixes. If you need both, you probably need all substrings. So our subproblems are going to be substrings. OK. I'm not going to write the subproblems quite yet, because there's another idea we need. So what do I need to do with the substring? I'm going to guess the middle operator and then evaluate the left substring, evaluate the right substring. What am I trying to do with those substring? I guess I'm trying to solve this problem, which is, place parentheses in order to maximize the result, and then return what the result is. And I can use paren pointers to reconstruct what the parentheses actually are. Once I guess what the last operator is, it enough to maximize the part to the right and maximize the part to the left? Will that always maximize my sum or product according to what this operator is? And if you think about it for a while. Yeah. If I want to maximize the sum, I should maximize the two parts. And if I want to maximize a product, I should maximize the two parts. That seems right. Except, I didn't say that my integers are positive. That's true if your integers are positive. But to make this problem more interesting, we're going to allow the integers to be negative. For example, 7 plus minus 4 times 3 plus minus 5. So I just added a couple of minuses to a couple of the numbers here. Then it's no longer best to pair them this way. If I pair them this way, like this, or if I add parentheses this way, I get 3 here, and I get minus 2 here. So I get-- the product of that is negative 6, which i probably not the maximum. In fact, I can do better, I believe, by doing the left operator last. So this, I claim, the best parenthisization, if I remembered it correctly. This is, minus 2 times minus 4 is 8, plus 7 is 15. So I got a positive number-- definitely better than the negative number I got. I claim this is the best. And the key property here is, when we take a product of two negative numbers, we get a positive number. Sometimes, you actually want to make things small, because small might mean very negative. You take two very big negative numbers-- very small negative numbers, in other words. You take their product, you get a very big product, positively, because the signs cancel. OK. So this seems tricky. We want to work on substrings, but we don't know whether we're trying to maximize, or you might think, well, maybe I'm trying to maximize the absolute value. But that's not good. Maybe overall, on this entire expression, I get negative 1 million. And that's not what I wanted. I wanted to maximize the sum. So I still need to solve the max evaluation that I can get, the max parenthesization, but I also need to solve the min parenthesization. If I can solve max and min, I'll know the entire range that I could get. And I really only-- I'll care about min especially when it lets me go negative. But let's just solve, in all cases, the min and the max, and then just brute force the rest. That's what I'm going to write down. So that was some motivation and why we are going to define subproblems this way. I'm going to define x of i, comma j, comma opt to be-- opt, here, is going to be either min or max. And this is my subproblem expansion. I really just care about max at the very end, but I'm going to care about min along the way. And i, j is going to specify my substring. So this is going to be the opt value-- opt stands for ""optimum"" here, or ""optimization."" The opt value I can get for the substring a i star plus 1, a i plus 1, and so on to star j minus 1, a j minus 1. OK. Being careful to get my indices correct here. And I want 0 less than or equal to i, less than j, less than equal to n. I claim and opt like this. OK. I'm going to get the min value and the max value separately. Those are two different subproblems. This is my expansion. This is the constraint I'm adding. And I'm only focusing on this substring from i inclusive to j exclusive. OK. So I claim those are good subproblems. Let's write down a recurrence relation. OK. Relate. I want to write x of i, j, opt on the left. And I want to optimize-- so this will be min or max-- on a set of choices. What is my set of choices? Well, like I said, I want to guess what is the last operation evaluated. I wrote star i here, but star i is already defined, so I'm going to use star k. So I'm going to guess which of my operations between i plus 1 and j minus 1 is the last one, and I evaluate. And that decomposes everything left of k. So that would be x of i, comma k, comma something. And then we will do operator star k on the part after k, which is from k to j, something. And I'm choosing between-- I think it's i less than k less than j. k is some operator in between, because I started i plus 1 and I ended j minus 1. So those are the possible choices for k. I tried them all. That's my local brute force. And then I take what I can get on the left, what I can get on the right, and multiply or add them according to whether the operator is plus or times. Now, should I maximize or minimize this one? Should I maximize or minimize this one? I don't know. So I'm just going to do more local brute force. Well, let's just say opt prime for the left-- or maybe I'll call it opt L for the left and opt R for the right part. And I'll just add this to my four-loop. Let's just try opt L and opt R. Just take all possible choices among min and max. Now, you could think hard-- and for addition, for example, if you're maximizing, you really only need to maximize the two parts. And if you're minimizing, you can prove you all need to minimize the two parts. But for multiplication, it's messy. It could be, really, any of the options. Because sometimes, when you minimize, you get a negative term. Sometimes, you don't. And so it depends what you're trying to do. You have to consider all the signs. But we don't need to think hard. We can just try all options. There's only four choices for opt L and opt R among min and max. You could do min-min, min-max, max-min, and max-max. So try-- it's just a multiplication by 4 in this four-loop. The big cost is actually this one, because there are j minus i choices for k. There's a constant number of choices for opt L and opt R. And you need to prove that this is correct. I won't do it here. But the idea is, if you're trying to minimize or maximize your sum or product, it's enough to know what ranges these could come in. And the optimal choice will always be an extreme in that range. We consider all of them here. And so we get this recurrence. Now, it needs a base case, and we need to check that it's acyclic. But topological order is just increasing j minus i. This is the usual order for substring problems, because this is increasing length of the substring. So start with very tiny substrings. Here, we'll start with length 1 substrings. We just have an a, i there. So that's going to be our base case. And you grow up to the entire string. And it doesn't matter how we order relative to opt as long as we are increasing in j minus i, because i to k and k to j will always be strictly smaller than i to j, and so this will be acyclic. The base case is x of i, i plus 1, opt. This is always a i. Doesn't matter what opt is, because there's nothing-- there's no choice. You just have a single number in that substring, because we're exclusive on i plus 1. And then the original problem we want to solve is x of 0, n, max. You could also solve min and see how small you can get it. So if you wanted to maximize the absolute value, you could solve the max problem and the min problem and take the largest of those two options. And how much time does this take? Well, how many subproblems are there? For substring problems, we have n squared subproblems. Now, we multiply the number of subproblems by 2, but that's still n squared. So we have n squared subproblems. And how much work per subproblem are we doing? Well, as I mentioned, we're doing j minus i choices for k and a constant number of choices for opt L and opt R. So this is theta j minus i, which, if I'll be sloppy, that's at most big O of n. And it turns out to be the right answer anyway. So there's a linear amount of non-recursive work. In fact, it's like a triangular number, but that's still theta n cubed. Same running time as v cubed we just got. But polynomial time. And this is pretty impressive, because we're really brute forcing all possible parenthesizations. There about 4 to the n, exponentially many, parenthesizations of an expression. But we're finding the biggest-- the one that evaluates the largest value and the one that evaluates to the smallest value in just n cubed time-- polynomial. And a key here was subproblem expansion, where we, in addition to solving the max problem, we also solved the min problem, because sometimes, you want to take two very small negative numbers and product them together to get a larger positive number. Cool. Question? AUDIENCE: Would anything go wrong if I added minus or divide? ERIK DEMAINE: So what if I had operators minus and divide? It's a good question. I'm certain that minus should work fine. If we do min and max, this should still evaluate the largest thing for division. I need to think about the cases. I would guess it works, but what we need to prove is that the way to maximize or minimize a division, say, given two numbers in the left and right, is that it either corresponds to maximizing or minimizing the thing on the left and then maximizing or minimizing the thing on the right. So as long as you have this kind of-- it's not exactly monotonicity. It's just that, in order to compute max or min, it suffices to know the max and min of the two parts. It's like interval arithmetic. You know, interval arithmetic? I want to know, what are the extremes I can get on the output of a division if I'm given that a number is in some interval here and some interval here? If the answer is always, use one of the extreme endpoints here and use one of the extreme endpoints here, then this algorithm will work. Otherwise, all bets are off. Cool. So if you negate-- if you put a minus here, that will work fine, because it's negating this range. And then it's just like sum. But-- AUDIENCE: [INAUDIBLE] ERIK DEMAINE: Oh, a divider-- if you're careful about 0, yeah. Actually, it doesn't work, because we care about how close this can get to 0 for division. It might be enough to consider those. It's like, instead of minimizing and-- instead of computing this entire interval, if this interval spans 0, maybe I need to know-- if 0 is here, I need to know how close to 0 I can get on the left side and how close to 0 I can get on the right side. Still just four quantities I need to know. I would guess, for division, that's enough. Yeah. Nice. Solved a little problem. Then, we would be multiplying the subproblem space, instead of by 2, by 4. Hey, maybe we should put this on the final. No, just kidding. Now it's in lecture, so we can't use it. But it's a cool set of problems, right? You can do a lot with dynamic programming. You don't need to be that clever, just brute force anything that seems hard. And when it works, it works great. And this class is all about understanding when it works and when it doesn't work. Of course, we will only give you problems where it works. But it's important to understand when it doesn't work. For example, DAG shortest paths-- that algorithm on a non-DAG, very bad. Infinite time. OK.","71.79977416992188","3","DPRSearchEngine","TDo3r5M1LNo.en-j3PyPqV-e1s_11_mp4","TDo3r5M1LNo.en-j3PyPqV-e1s","6.006","17"
"89","What are the five components of a finite automaton as defined by a 5-tuple, and what does each component represent?"," 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Finite Automata – Formal Definition 
Defn: A finite automaton ! is a 5-tuple (#, Σ, &, '0, )) 
# finite set of states 
Σ finite set of alphabet symbols 
Example: 
& transition function &: #×Σ → # 
a
& (', .) = 0 means 
'
0 
0
'0 start state 
!1 
1 
0,1 
1
) set of accept states 
'1
'2 
'3 
0 
!1 = (#, Σ, &, '1, )) 
& = 
0
1
# = {'1, '2, '3} 
'1
'1 '2
Σ = {0, 1} 
'2 '1 '3 
) = {'3} 
'3 '3 '3 
7 
","71.53439331054688","4","DPRSearchEngine","b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1_7_pdf","b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1","18.404J","1"
"89","What are the five components of a finite automaton as defined by a 5-tuple, and what does each component represent?","OK, let's move on. OK, let's talk about closure properties now. We're going to start doing something that has a little bit more meat to it, in terms of we're going to have our first theorem of the course coming here. And this is not a baby theorem. This is actually-- there's going to be some meat to this. And you're going to have to not totally-- this is not a toy. We're proving something that has real substance. And the statement of this theorem says that the regular languages are closed, that really, the class of regular languages are closed under union, closed under the union operation. So what do I mean by that? So when you say a collection of objects is closed under some operation, that means applying that operation to those objects leaves you in the same class of objects. Like the positive integers, the natural numbers, that's closed under addition. Because when you add two positive integers, you get back a positive integer. But they're not closed under subtraction. Because 2 minus 4, you get something which is not a positive integer. So closed means you leave yourself in the collection. And the fact is that if you look at all the regular languages-- these are the languages that the finite automata can recognize-- they are closed under the union operation. So if you start off with two regular languages and you apply the union, you get back another regular language. And that's what the statement of this theorem is. I hope that's clear enough in the way I've written it. If A1 and A2 are regular, then A1 union A2 is also regular. That's what the statement of this is. And it's just simply that-- that's proving that the class of regular language is closed under union. So we're going to prove that. So how do you prove such a thing? So the way we're going to prove that is you start off with what we're assuming. So our hypothesis is that we have two regular languages. And we have to prove our conclusion, that the union is also regular. Now, the hypothesis that they're regular, you have to unpack that and understand, what does that get you? And them being regular means that there are finite automata that recognize those languages. So let's give those two finite automata names. So M1 and M2 are the two final automata that recognize those two languages, A1 and A2. That's what it means, that they're regular, that these automata exist. So let's have those two automata, M1 and M2, using the components as we've described, the respective state sets, input alphabet, transition functions, the two starting states and the two collections of accepting states. Here I'm assuming that they're over the same alphabet. You could have automata which operate over different alphabets. It's not interesting to do that. It doesn't add anything. The proof would be exactly the same. So let's just not overcomplicate our lives and focus on the more interesting case, so assuming that the two input alphabets are going to be the same. And from these two automata, we have to show that this language here, the union, is also a regular language. And we're going to do that by constructing the automaton which recognizes the union. That's really the only thing that we can do. So we're going to build an automaton out of M1 and M2 which recognizes the union language A1 union A2. And the task of M is that it should accept its input if either M1 or M2 accept. And now what I'd like you to think about doing that, how in the world are we going to come up with this finite automaton M? And the way we do that is to think about, how would you do that union language? If I ask you-- I give you two automata, M1 and M2, and I say, here's an input, w. Is w in the union language? That's the job that M is supposed to solve. And I suggest you try to figure out how you would solve it first. I mean, this is a good strategy for solving a lot of the problems in this course. Put yourself in the place of the machine you're trying to build. And so if you want to try to figure out how to do that, a natural thing is, well, you take w, you feed it into M1, and then you feed it into M2. And if M1 accepts it, great, then you know it's in the union. And if not, you try it out in M2 and see if M2 accepts it. Now, you have to be a little careful, because you want to have a strategy that you can also implement in a finite automaton. And a finite automaton only gets one shot at looking at the input. You can't sort of rewind the input. You feed it first into M1 and then you feed it into M2 and operate in a sequential way like that. That's not going to be allowed in the way finite automata work. So you're going to have to take it to the next level, be a little bit more clever. And instead of feeding it first into M1 and then and then into M2, you feed them into both in parallel. So you take M1 and M2, and you run them both in parallel on the input w, keeping track of which state each of those two automata are in. And then at the end, you see if either one of those machines is in an accepting state, and then you accept. So that's the strategy we're going to employ in building the finite automaton M out of M1 and M2.","71.42697143554688","5","DPRSearchEngine","9syvZr-9xwk.en-j3PyPqV-e1s_11_mp4","9syvZr-9xwk.en-j3PyPqV-e1s","18.404J","1"
"89","What are the five components of a finite automaton as defined by a 5-tuple, and what does each component represent?"," 
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
  
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
  
 
 
 
 
 
 
 
 
 
  
Finite Automata – Computation 
Strings and languages 
-
A string is a finite sequence of symbols in Σ 
-
A language is a set of strings (finite or infinite) 
-
The empty string ε is the string of length 0 
Recognizing languages 
-
The empty language ø is the set with no strings 
- :(#) = {$| # accepts $} 
- :(#) is the language of # 
Defn:  # accepts string $ = $1$2 … $) each $* + Σ 
- # recognizes :(#) 
if there is a sequence of states ,0, ,1, ,2, , … , ,) + / 
where: 
- ,0 = 00 
- ,* = 1(,345, $*) for 1 ≤ * ≤) 
Defn: A language is regular if some 
- ,) + 8 
finite automaton recognizes it. 
8 
","70.5480728149414","6","DPRSearchEngine","b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1_8_pdf","b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1","18.404J","1"
"89","What are the five components of a finite automaton as defined by a 5-tuple, and what does each component represent?","Here, we're given a sequence of notes t 0, t 1-- t for note-- up to t n minus 1. These are single notes. And all of the single notes-- all of the single notes, right? And we have fingers on our hands. This is not like two-finger algorithm. This is the five-finger algorithm. So in general, I'm going to assume an arbitrary anthropomorphic object. So this is 5 for humans-- most humans. Some humans-- I think the maximum on each hand is 7. Could be smaller. Maybe you've had an accident.","70.2987289428711","7","DPRSearchEngine","TDo3r5M1LNo.en-j3PyPqV-e1s_12_mp4","TDo3r5M1LNo.en-j3PyPqV-e1s","6.006","17"
"89","What are the five components of a finite automaton as defined by a 5-tuple, and what does each component represent?","So just as we did last time, we can formally define a nondeterministic finite automata. Here's the picture again. OK. So it looks a lot like the case we had before, the Deterministic Finite Automata, or DFA, as we'll call them. It's a 5 tuple. So I've written down little reminders for what those components of that 5 tuple are, that list of five components. So they're all the same as before-- states, alphabet, transition function, start state, and accepting states. So that the formal definition looks exactly the same except the structure of the transition function. So now, before, if you remember, you had a state and an input symbol, and you got back a state. Now we have something more complicated-looking. We have a state and an input symbol, but instead of just sigma, it's sigma sub epsilon. And that that's a shorthand for sigma union epsilon. And that's a way-- my way of saying that you're allowed to have on your transition arrows either an input symbol or an empty string. So the transition function has to tell you what to do when you have an empty string coming in as well. So that would be part of your table for the transition function. Now, over here, what's going on over here? Well, now, instead of just producing a single state, when you've read, for example, an a from q1, there's a whole set of possibilities. So here we have what's called a power set. That's the set of subsets of the collection Q. So here we're going to produce an entire subset of states. Instead of just one state coming out, there might be a subset of possible states that you can go to. So the power set of Q is a set of subsets of Q. So that's what this notation means. Again, this is something that I'm, hopefully, presenting to you as a bit of a reminder. You've seen this somewhere else before. But please make sure you understand the notation, going forward, because we'll be doing less hand-holding as we start moving forward. OK. So just let's take a look. In the N1 example here, just to illustrate what's going on, when you're in state q1 reading an a, now you get a whole set of possibilities, which, in this case, is q1 and q2. Whereas, if you're reading a b, what would be that set? Coming out of q1, what's the set of possible successor states? Well, there are none. So it's the empty set. OK? So hopefully, you're understanding the notation here. So now here's, I think, really important. How do we understand nondeterminism, intuitively speaking? And there are multiple different ways, which each has their value under different circumstances. So one way is thinking about nondeterminism as a kind of parallelism. So every time the machine has a nondeterministic choice to make, where there's more than one outcome, you think of the machine as a branching, forking, new threads of the parallel computation at that stage, where it makes an entire copy of itself when there's a choice of possibilities. And then each of those independently proceeds to read the rest of the input as separate threads of the computation. So if you're familiar with parallel computing, this should be reasonably familiar to you. The only key thing to remember is that as this thing forks a number of possibilities, the acceptance rule is, that if any one of those possibilities gets to an accept at the end of the input, it raises a flag and says, accept. And that overrules everybody else. So acceptance dominates. So another way of looking at it is the mathematical view, where you can imagine-- and we're going to use all these. So you really need to understand them all. The mathematical view is you can think of the computation as kind of a tree of possibilities. So you start off at the very beginning at the root of the computation, which is when it really begins. But every time there's a nondeterministic branching that occurs, that node of the tree has multiple children coming out of that node. And so the different threads of the computation correspond to different branches of that tree. And now you're going to accept if any one of those branches leads to an accepting state-- OK, obviously, somewhat similar to what we had before. But I think it's a little bit of a different perspective on how to think about nondeterminism. And the last one is going to sound a little weird. But actually, I think for people who are in the business, it's the one they use the most. And that's the magical way of thinking about nondeterminism. And that is, when the machine has nondeterministic choices to make, you think of the machine as magically guessing the correct one at every stage, and the correct one being the one that will eventually lead it to accept. OK? So you can think of the machine as guessing which is the right way to go. And if there is some way right way to go, it always guesses right. Of course, if the machine ends up rejecting, because there is no right way to go, then it doesn't matter. There is no good guess. But if there is some good guess, we'll think of the machine as taking that good guess and going that way. OK. So now here is a very important thing. We introduced this new model, the Nondeterministic Finite Automaton, NFA. It turns out, even though it looks more powerful, because it has this nondeterminism, it isn't any more powerful. It can do exactly the same class of languages, the regular languages. And we'll show that with this theorem here, that if an NFA recognizes a, then a is regular. So we'll prove that by showing how to convert an NFA to an equivalent DFA, which does the same language. So we can take an NFA that has the nondeterminism and find another DFA which doesn't have nondeterminism, but does the same language. It accepts exactly the same strength, even though it lacks that nondeterministic capability. This is going to be extremely useful, by the way, and for example, in showing that closure under concatenation. OK, so in this presentation here, I'm going to ignore the epsilon transitions. Because once you get the idea for how to do this, you could figure out how to incorporate them. They just make things a little more complicated. So let's just focus on the key aspect of nondeterminism, which is that the machine could have several ways to go at any point in time. There could be several next states on an input. OK? Now the idea for the construction-- so we're going to start with a nondeterministic machine M, and we're going to build a deterministic machine M prime, which does exactly the same thing. And the way M prime works is it's going to do what you would do if you were simulating M. What would you do? This is what we were doing as I was explaining it to you. If you were simulating M, every time you get an input symbol, you just keep track of what is the set of possible states at that point in time. That's what the DFA is going to do. it's going to have to keep track of which possible set of states the NFA could be in at the point on that input where we are right now. And then as you get to the next symbol, the DFA is going to have to update things to keep track of the next set of states the NFA could be in at this point, just like you would do. OK? And so here's a kind of a picture. And how do we implement that? So here's the NFA that we're starting with, M, and we're going to make here the DFA. But in order to remember which set of states that DFA could be in at a given point-- so maybe it's in the set of states that M could be in. Did I say it wrong? Which set of states the NFA could be in a given time-- so maybe M, the NFA, could be in, at some point, state q3 and q7. The way the DFA keeps track of that, it's going to have a state for every possible subset of states of the NFA. That's how it remembers which subset of states the NFA is in. That's the way DFAs work. They have a separate state for each possibility that they need to keep track of. And the possibilities here are the different subsets of states that the NFA could be in at a given point. OK? So corresponding to this subset, to these two possibilities q3, q7, the DFA is going to have a state with the subset q3, q7. And it's going to, for every possible subset here, there's going to be a different state of M prime. So M prime is going to be bigger. OK. So quickly, the construction of M, the states of M prime now, q prime, are going to be the power set, the set of subsets of states from the original machine M. And now we have to look at how the transition function of the DFA, when you made the primed machines of the DFAs, the DFA machine. So these are the deterministic components. So delta prime, when it has a subset, something like this, has one of its states, which corresponds to a subset of states of M, and it reads an input symbol, you just have to do the updating the way you would naturally do. You're going to look at every state in R, look at where that can go under a-- so there's a bunch of sets there. And look at all the possible states that could be in one of those subsets, and that's the set of states that you could be. That's going to be the new set of states, and that's going to be in the new state of M prime. OK? So it's going to be the subset corresponding to all of the states that could be in, when you apply the transition function of the nondeterministic machine, to one of the states in the subset of states that the nondeterministic machine could be in. OK? It's a little bit of a mouthful. I suggest you look at this, if you didn't quite get it, after the fact. Good to understand. The starting stage for the NFA-- for the DFA-- I'm sorry-- is going to be which subset now we're going to start off with. It's going to be the subset corresponding to just the start state of M. And the accepting states are going to be-- of the deterministic machine are going to be all of the subsets that have at least one accepting state from the NFA. OK? So I hope you got that. Because I'm going to give you another little check-in here. Which is I'm going to ask you, how big is M prime? How many states does M prime have? I told you what those states are. So just go think about that. So check-in two-- if M has n states, how many states does M prime have by this construction? OK, so let's launch the next poll. OK, five seconds-- and I think we're almost done here. good. All right, share results-- I don't know if sharing results is a good thing. I'm not trying to make you, if you didn't get the right answer-- because most of the people did get the right answer-- but if you didn't get the right answer, trying to make you feel bad. But it's a little bit of suggestion that you need to review some basic concepts. So the basic concept here is if you have a collection-- you have a set of states, how many subsets are there? And the number of subsets is going to be exponential. So if you have a collection of n elements, the number of subsets of those n elements is 2 to the n. That's the fact we're using here. And that's why M prime has 2 to the n states, if M had n states. And you should make sure you understand why that is. All right, so with that, as requested, we're going to have a little break. And that break is going to last us exactly five minutes. So we will return in five minutes. I'm going to be prompt. So I gave you a little timer here. So please, I'm going to begin it right when this is over. OK, almost ready.","70.08670806884766","8","DPRSearchEngine","oNsscmUwjMU.en-j3PyPqV-e1s_5_mp4","oNsscmUwjMU.en-j3PyPqV-e1s","18.404J","2"
"89","What are the five components of a finite automaton as defined by a 5-tuple, and what does each component represent?","to this interface problem-- the natural solution-- is what I'll call a static array. Jason mentioned these in lecture one. It's a little tricky because there are no static arrays in Python. There are only dynamic arrays, which is something we will get to. But I want to talk about, what is a static array, really? And this relates to our notion of-- our model of computation, Jason also talked about, which we call the word RAM, remember? The idea, in word RAM, is that your memory is an array of w-bit words. This is a bit circular. I'm going to define an array in terms of the word RAM, which is defined in terms of arrays. But I think you know the idea. So we have a big memory which goes off to infinity, maybe. It's divided into words. Each word here is w bits long. This is word 0, word 1, word 2. And you can access this array randomly-- random access memory. So I can give you the number 5 and get 0 1, 2, 3, 4, 5, the fifth word in this RAM. That's how actual memories work. You can access any of them equally quickly. OK, so that's memory. And so what we want to do is, when we say an array, we want this to be a consecutive chunk of memory. Let me get color. Let's say I have an array of size 4 and it lives here. Jason can't spell, but I can't count. So I think that's four. We've got-- so the array starts here and it ends over here. It's of size 4. And it's consecutive, which means, if I want to access the array at position-- at index i, then this is the same thing as accessing my memory array at position-- wherever the array starts, which I'll call the address of the array-- in Python, this is ID of array-- plus i. OK. This is just simple offset arithmetic. If I want to know the 0th item of the array, it's right here, where it starts. The first item is one after that. The second item is one after that. So as long as I store my array consecutively in memory, I can access the array in constant time. I can do get_at and set_at as quickly as I can randomly access the memory and get value-- or set a value-- which we're assuming is constant time. My array access is constant time. This is what allows a static array to actually solve this problem in constant time per get_at and set_at operation. This may seem simple, but we're really going to need this model and really rely on this model increasingly as we get to more interesting data structures. This is the first time we're actually needing it. Let's see. Length is also constant time. We're just going to store that number n, along with its address. And build is going to take linear time. Iteration will take linear time. Pretty straightforward. I guess one thing here, when defining build, I need to introduce a little bit more of our model of computation, which is, how do you create an array in the beginning? I claim I could do it in linear time, but that's just part of the model. This is called the memory allocation model. There are a few possible choices here, but the cleanest one is just to assume that you can allocate an array of size n in theta n time. So it takes linear time to make an array of size n. You could imagine this being constant. It doesn't really matter much. But it does take work. And in particular, if you just allocate some chunk of memory, you have no idea whether it's initialized. So initializing that array to 0s will cost linear time. It won't really matter, constant versus linear, but a nice side effect of this model is that space-- if you're just allocating arrays, the amount of space you use is, at most, the amount of time you use. Or, I guess, big O of that. So that's a nice feature. It's pretty weird if you imagine-- it's unrealistic to imagine you can allocate an array that's infinite size and then just use a few items out of it. That won't give you a good data structure. So we'll assume it costs to allocate memory. OK, great. We solved the sequence problem. Very simple, kind of boring. These are optimal running times. Now, let's make it interesting-- make sure I didn't miss anything--","70.07878112792969","9","DPRSearchEngine","CHhwJjR0mZA.en-j3PyPqV-e1s_3_mp4","CHhwJjR0mZA.en-j3PyPqV-e1s","6.006","2"
"89","What are the five components of a finite automaton as defined by a 5-tuple, and what does each component represent?","free and regular, why do we know that's still context free? Because the pushdown automaton for A can be simulating the finite automaton for B inside its finite control, inside its finite memory. The problem is, if you have two context-free languages, you have two pushdown automata, you can't simulate that with one pushdown automaton, because it has only a single stack. So if you're trying to take the intersection of two context-free languages with only a single stack, you're going to be in trouble, because it's hard to-- anyway, that's not a proof, but at least it shows you what goes wrong if you try to do the obvious thing. OK, so if-- and just, here is an important point that was trying to make before. If A and B are both context free and you're taking the intersection, the result may not necessarily be a context-free language. So the class of context-free languages is not closed under its intersection. We'll comment on that in a bit. The context-free languages are closed under the regular operations, however, union, intersection-- union, concatenation, and star. So you should feel comfortable that you know how to prove that. Again, it's one of the-- I think it's problem 0.2. And I think the solution is even given in the book for it. So you just should know how to prove that. It's pretty straightforward. OK, so let's move on then to basically conclude our work on context-free languages, to understand the limitations of context-free grammars, and what kinds of languages may not be context free. And how do you prove that? So how do you prove that, for some language, there is no grammar? Again, you know, it's not enough just to, say, give an informal comment that, I couldn't think of a grammar, or some-- things of that kind. That's not going to be good enough. We need to have a proof. So if we take the language here, 0 to the k, 1 to the k, 2 to the k, so those are strings which are runs of 0's followed by an equal number of 1's followed by an equal number of 2's, so just 0's, then 1's, then 2's, all the same length. That's a language which is not going to be a context-free language. And we'll give a method for proving that. If you had a stack, you can match the 1's with the 0's, but then once you're done with that, the stack is empty. And how do you now make sure that the number of 2's corresponds to the number of 1's that you had? So again, that's an informal argument that's not good enough to be a proof, but it sort of gives an intuition. So we're going to give a method for proving non-context-free-- languages are not context free using, again, a pumping lemma. But this is going to be a pumping lemma that applies to context-free language, not to regular languages. It looks very similar, but it has some extra wrinkles thrown in, because the other older pumping lemma was specific to the regular languages. And this is going to be something that applies to the context-free languages. OK, so now let's just read it. And then we'll try to interpret it again. It's very similar in spirit. Basically, it says that, whenever you have a context-free language, all long strings in the language can be pumped in some kind of way. So it's going to be a little different kind of pumping than we had before. And you stay in the language. OK, so before, we broke the string into three pieces where we could repeat that centerpiece as many times as you like. And you stay in the language. Here, we're going to end up breaking the string into five pieces. So s is going to be broken up into uvxyz. And the way it's going to work here-- so here is a picture. So all long strings-- again, there is going to be a threshold. So whenever you have a language, there is going to be some cut-off length. So all the longer strings in that language can be pumped. And you stay in the language. But the shorter strings, there is no guarantee. So if you have a long string in the language of length at least this pumping length p, then you can break it up into five pieces. But now it's that second and fourth string that are going to play that special pumping role, which means that, what you can do is you can repeat those and you stay in the language. And it's important that you repeat them both, that v and that y, the same number of times. So you're going to have a picture that looks something like this. And that is going to you repeat. If you repeat the v and you repeat the y, you get uvvxyyz. Or if you look at over here, it would be uv squared xy squared z. And that's going to still be in the language. And then we have-- so that's one condition. We'll have to look at all of these conditions when we do the proof, but we just want to understand what the statement is right now. So the second condition is that v and y together cannot be empty. And really, that's another way of saying, they can't both be the empty string, because if they were both the empty string, then repeating them wouldn't change s. And then of course it would stay in the language. So it would be kind of meaningless if they were allowed to be empty. And the last thing is, again, going to be there as a matter of convenience for proving languages are not context free, because you have to make sure there is no possible way of cutting up the string. When you're trying to prove a language is not context free, you have to show the pumping fails. It's going to be helpful sometimes to limit the ways in which the string can be cut up, because then you have-- it's an easier job for you to work with it. So here, it's a little different than before, but sort of similar, that vxy combine as a substring. So I show that over here. vxy together is not too long. So the vxy-- maybe it's better seen up here-- is going to be, at most, p. We'll do an example in a minute of using this. OK, so again, here is our pumping lemma. I've just restated it. So we have it in front of us. And we're going to do a proof. I'm just going to give you the idea of the proof first. And then we'll go through some of the details.","70.02342224121094","10","DPRSearchEngine","IycOPFmEQk8.en-j3PyPqV-e1s_7_mp4","IycOPFmEQk8.en-j3PyPqV-e1s","18.404J","5"
"93","What does the space hierarchy theorem state about space-bound functions?"," 
 
  
  
 
 
 
  
 
 
   
 
 
 
  
 
  
 
  
 
 
  
 
  
 
 
 
 
  
 
 
 
  
 
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
Space Hierarchy Theorem (1/2) 
Theorem: For any !: ℕ → ℕ (where ! satisfies a technical condition) 
there is a language % where % requires & ! ' 
space, i.e, 
1) % is decidable in & ! ' 
space, and 
2) % is not decidable in ( ! ' 
space 
On other words, SPACE ( ! ' 
⊆, SPACE ! ' 
Notation: SPACE ( ! ' 
= {,| some TM . decides , in space ( ! ' } 
Proof outline:  (Diagonalization) 
Give TM 0 where 
% 
1) 0 runs in & ! ' 
space 
2) 0 ensures that 1(0) ≠ 1(.) for 
SPACE ! ' 
every TM . that runs in ( ! ' 
space. 
SPACE ( ! ' 
Let % = 1(0). 
8 
","81.85521697998047","1","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_8_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"93","What does the space hierarchy theorem state about space-bound functions?"," 
 
  
  
 
 
 
 
 
 
   
 
 
 
 
  
 
  
 
  
 
 
  
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
   
 
    
   
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
   
  
Time Hierarchy Theorem (1/2) 
Theorem: For any !: ℕ → ℕ where ! is time constructible 
there is a language % where % requires & ! ' 
time, i.e, 
1) % is decidable in & ! ' 
time, and 
2) % is not decidable in ( ! ' / log ! ' 
time 
- .
On other words, TIME (
⊆, TIME ! ' 
/01 - . 
Proof outline:  Give TM 3 where 
1) 3 runs in & ! ' 
time 
2) 3 ensures that 4(3) ≠ 4(8) for every TM 8 that runs in ( ! ' / log ! ' 
time . 
Let % = 4(3). 
10 
","79.31224822998047","2","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_10_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"93","What does the space hierarchy theorem state about space-bound functions?","I'm going to make a bit of a digression into a branch of mathematics called set theory or it's a part of mathematical logic, where the method of diagonalization was first conceived of back in the late 19th century by a mathematician called Georg Cantor. And Cantor was considering the problem of, how do you compare the relative sizes of infinite sets? For finite sets, the problem of comparing-- somebody said that Cantor went crazy. That is true. And maybe I don't know why he went crazy. But he did go-- he had some mental problems, unfortunately. And so how do we compare the sizes of sets in general? If they're finite sets, we can just count them up. We can say, whoa, this set has 11 elements, and the other set has 10 elements. So the one with 11 is bigger. Or if they both have 11, they're the same size. Well, that's not going to work for infinite sets because you can't count them up. And so he had-- Cantor had the following idea for comparing the sizes of infinite sets. And that was, basically, to see whether you can have a function that would map from one set to the other set with certain properties. And those properties are called, traditionally, well, I mean, in the past, have been called the one-to-one and onto properties for the function. I'll tell you what that means. But the concept is very simple. So a one-to-one function is a function that's mapping from A to B. Those are the two sets whose sizes we're trying to compare. And the function being one-to-one just means that there are no collisions. If you have two different elements of A, they're never going to map onto the same element of B. So two different elements of A always map onto two different elements of B. So that's the one-to-one property. It's also called injective. And the other property is called onto or surjective, which is that the range of f has to be all of B. So you're not allowed to miss any elements, but you have to hit everything. And when you have both of those properties, the function is called a one-to-one correspondence or a bijection also, OK? Now another way of looking at it-- I don't want to make this more complicated than it needs to be. It just simply means that two sets are considered to be the same size if we can match up the elements with one set with elements of the other set. You just pair them up. For example, well, if you have finite sets, that idea, that informal idea just works exactly as you would expect. For example, if we have two sets-- here's a set of puppies. Here's a set of kittens. Now we want to show that those two sets have the same size. We could count them up, as I mentioned, and see that there are six elements in both. But counting up does not work for infinite sets. So we can just match up the elements of the puppies with the kittens, and then we know we have the same number of puppies as kittens. OK, now that has the advantage of it making sense when you have infinite sets. So we're just going to extend that idea and apply it to infinite sets too. And then we'll have a notion of what it means for two infinite sets to have the same size. And you might wonder, what do you get? Are all infinite sets of the same size when you use this notion or not? What happens? Well, some strange things do happen. But there actually are quite some interesting structure there that emerges. So anyway, I don't want to rush on. Questions on any of this? If you want to-- quick question. This, hopefully, was not too hard, but I want to make sure everybody's together with me on it, so we can pop in-- I'll give a few seconds for a chat if you have any questions. The range of the set is all of the elements that you hit as you look at the different possible elements of A. So all of the things that f hits, the standard notion of a range of a function. So the range of f has to be equal to B. You have to hit everything. All right, can you think of a one-to-one correspondence as a relabeling? Yeah, I'm not sure that's helpful. But, yes, you can think of as a relabeling of the elements in a sense, but yeah. I just think of it as a matching up.","75.9486083984375","3","DPRSearchEngine","3PzuSPQPEU4.en-j3PyPqV-e1s_4_mp4","3PzuSPQPEU4.en-j3PyPqV-e1s","18.404J","8"
"93","What does the space hierarchy theorem state about space-bound functions?"," 
 
 
  
 
   
   
  
   
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
  
 
   
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
Relationships between 
Time and SPACE Complexity 
Theorem: For ! "" ≥"" 
1) TIME ! "" 
⊆ SPACE ! "" 
2) SPACE ! "" 
⊆ TIME 2& ' ( 
= ⋃+ TIME ,' ( 
Proof: 
1) A TM that runs in !("") steps cannot use more than !("") tape cells. 
2) A TM that uses !("") tape cells cannot use more than ,' ( time 
without repeating a configuration and looping (for some ,). 
Corollary: P ⊆ PSPACE 
Theorem: NP ⊆ PSPACE [next slide] 
3 
","75.84011840820312","4","DPRSearchEngine","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17_3_pdf","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17","18.404J","17"
"93","What does the space hierarchy theorem state about space-bound functions?"," 
 
  
  
 
 
 
 
 
 
 
  
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Review: Major Complexity Classes 
L ⊆ NL ⊆ P ⊆ NP ⊆ PSPACE 
≠ 
Today 
The time and space hierarchy theorems show that 
if a TM is given more time (or space) then it can do more.* 
* certain restrictions apply. 
For example: 
TIME #$ ⊆, TIME #% 
[ ⊆, means proper subset ] 
SPACE #$ ⊆, SPACE #% 
7 
","75.73887634277344","5","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_7_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"93","What does the space hierarchy theorem state about space-bound functions?"," 
 
 
    
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Return to Closure Properties 
Recall Theorem: If !"", !$ are regular languages, so is !"" ∪!$ 
(The class of regular languages is closed under union) 
New Proof (sketch): Given DFAs &"" and &$ recognizing !"" and !$ 
&$
&"" 
ε 
ε 
& 
Construct NFA & recognizing !"" ∪!$ 
Nondeterminism 
parallelism 
vs 
guessing 
7 
","75.1609115600586","6","DPRSearchEngine","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_7_pdf","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2","18.404J","2"
"93","What does the space hierarchy theorem state about space-bound functions?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","75.09254455566406","7","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"93","What does the space hierarchy theorem state about space-bound functions?"," 
 
 
  
 
  
 
 
 
 
Quick review of today 
1. !""##$%DFA ∈ PSPACE 
2. Savitch’s Theorem: NSPACE * + 
⊆ SPACE *- + 
3. ./01 is PSPACE-complete 
10 
","75.02898406982422","8","DPRSearchEngine","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18_10_pdf","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18","18.404J","18"
"93","What does the space hierarchy theorem state about space-bound functions?","≤ 
≤ 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
   
 
 
 
  
  
 
 
 
  
 
 
 
 
Why
% and not
%'%()* when defining PSPACE-complete?
- Reductions should be “weaker” than the class. Otherwise all
problems in the class would be reducible to each other, and then 
all problems in the class would be complete.
Theorem: +,!- is PSPACE-complete
PSPACE-completeness 
Defn: ! is PSPACE-complete if 
1) ! ∈ PSPACE 
2) For all # ∈ PSPACE, # ≤% ! 
If ! is PSPACE-complete and ! ∈ P then P = PSPACE. 
Check-in 18.1 
Knowing that +,!- is PSPACE-complete, 
what can we conclude if +,!- ∈ NP? 
Check all that apply. 
(a) P = PSPACE 
(b) NP = PSPACE 
(c) P = NP 
(d) NP = coNP 
5 
PSPACE-complete 
NP-complete 
PSPACE = 
NPSPACE 
NP
P 
Think of complete problems as the “hardest” 
in their associated class. 
Check-in 18.1 
","74.76754760742188","9","DPRSearchEngine","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18_5_pdf","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18","18.404J","18"
"93","What does the space hierarchy theorem state about space-bound functions?"," 
 
  
 
 
 
 
 
  
 
 
  
 
 
 
 
 
  
 
 
 
 
 
18.404/6.840 Lecture 18 
Last time: 
- Space complexity 
- SPACE ! "" , NSPACE ! "" , PSPACE, NPSPACE 
- Relationship with TIME classes 
Today: (Sipser §8.3) 
- Review $%&&'(DFA ∈ PSPACE 
- Savitch’s Theorem: NSPACE ! "" 
⊆ SPACE !. "" 
- PSPACE-completeness 
- /012 is PSPACE-complete 
1 
","74.6284408569336","10","DPRSearchEngine","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18_1_pdf","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18","18.404J","18"
"94","What are the terminals in the given context-free grammar?"," 
 
 
 
 
 
 
 
 
 
 
Regular 
language 
Context Free 
language 
Regular 
languages 
Recap 
Recognizer 
DFA or NFA 
PDA 
Context Free 
languages 
Generator 
Regular 
expression 
Context Free 
Grammar 
11 
","78.94390106201172","1","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_11_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"94","What are the terminals in the given context-free grammar?","Notation for encodings and TMs
Notation for encoding objects into strings
- If ! is some object (e.g., polynomial, automaton, graph, etc.), 
we write 〈!〉to be an encoding of that object into a string.  
- If !$, !&, … , !( is a list of objects then we write 〈!$, !&, … , !(〉
to be an encoding of them together into a single string. 
Notation for writing Turing machines
We will use high-level English descriptions of algorithms when we describe TMs, 
knowing that we could (in principle) convert those descriptions into states, 
transition function, etc.  Our notation for writing a TM ) is
) = “On input +
[English description of the algorithm]”
Check-in 6.3
If , and - are strings, would ,- be a good choice 
for their encoding 〈,, -〉into a single string?
a)
Yes.
b)
No. 
Check-in 6.3
8
","74.37113189697266","2","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_8_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"94","What are the terminals in the given context-free grammar?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
18.404/6.840 Lecture 5 
Last time: 
- Context free grammars (CFGs) 
- Context free languages (CFLs) 
- Pushdown automata (PDA) 
- Converting CFGs to PDAs 
Today: (Sipser §2.3, §3.1) 
- Proving languages not Context Free 
- Turing machines 
- T-recognizable and T-decidable languages 
1 
","74.02558135986328","3","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_1_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"94","What are the terminals in the given context-free grammar?","Turing machines, as we set them up, they have-- on any input w, they have three possible outcomes. The Turing machine can halt and accept w, can halt and reject w, or it can go forever on w, which is rejecting by looping in our language. A Turing machine can recognize a language, the collection of old strings that it accepts. And if the Turing machine always halts, we say it decides the language, and it's a decider, and so therefore, that language is a decided language, a Turing decider. Often we just say decidable, because we don't really have a notion of deciding in other models, so we often talk about Turing-recognizable or just decidable. Or we'll sometimes just say recognizable, when we understand that we're talking about Turing machines. We briefly talked about encodings. When you write it inside brackets, some objects-- whatever they are-- could be strings, could be machines, could be graphs, could be polynomials-- we're representing them as strings, and maybe a collection of objects together represented as a string in order so that we can present that information as an input to a machine. And we talk about-- our languages our collections of strings. And a notation for writing a Turing machine is going to be simply that English description put inside quotation marks to represent our informal way of talking about the formal object that we could produce, if we wanted to. But we're never going to ask you to do that. OK, so now let me see. Let's just take a quick break, as I promised. If there's any quick questions here, you can ask. Let's see-- got a lot of questions here. All right, why don't we move on? And some of these things are good questions.","74.02474212646484","4","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_2_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"94","What are the terminals in the given context-free grammar?","if an English description is possible for a Turing machine? Well, you can always write down an English description for any machine. It's-- might be very technical looking, but if you can write it down in a formal way as states and transitions, then you can simply write down an English description, which would just be, follow those states. OK, let's move on. OK, this is going to be our first example of a algorithm that's going to answer a question about automata. And it's a very simple problem. It's a very simple problem to solve, because we want to start out easy. The name of the problem is the acceptance problem for deterministic finite automata, acceptance problem for DFAs. And I'm going to express it, as I always do, as a language.","73.71356964111328","5","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_4_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"94","What are the terminals in the given context-free grammar?","OK, so now let's talk about some more the computation, so strings and languages. A string is just a finite sequence of symbols from the alphabet. This class is not going to talk about infinite strings. All of our strings are going to be finite. There's other mathematical theories of automata and so on that talk about infinite inputs and infinite strings. We're not going to talk about that. Maybe rarely, we'll make it very clear, we'll talk about an infinite string, but that's going to be an exception. And a language is a set of strings. That's the traditional way that people in this subject refer to a set of strings. They call it a language-- really because the subject had its roots in linguistics, actually. And they were talking about-- they're trying to understand languages, human languages. So this is just a historical fact, and that's the terminology that's stuck. OK, so two special string-- a special string and a special language. The empty string is the string of length 0. This is a totally legitimate string that you are going to run into now and then. And there's the empty language, which is the set with no strings. These are not the same. They're not even of the same type of object. So don't confuse them with one another. I mean, you can have a set, a language, which has just one element, which is the empty string. That is not the empty set. That is a set-- that is not the empty language. That is a language that has one element in it, namely, the empty string. So those are separate things. OK, so here's a little bit of a mouthful here on the slide, defining what it means for an automaton to accept its input-- accepts its input string w. And we can define that formally. And it's a little technical looking, it's really not that bad. So if you have your input string w, which you can write as a sequence of symbols in the alphabet-- w1, w2, dot dot dot, wn, so like 01001. I'm just writing it out symbol by symbol here. So what does it mean for the machine to accept that input? So that means that there's a sequence of states in the machine, sequence of states of members of Q. So a sequence from Q, these are the states of the machine that satisfy these three properties down here. First of all-- and I'm thinking about the sequence that the machine goes through as it's processing the input w. So when does it accept w? If that sequence has the feature that it starts at the start state, each state legally follows the previous state according to the transition function. So that says the i-th member of the sequence is obtained by looking at the previous one-- the i minus first member of that sequence, the i minus first state in that sequence-- and then looking at what happens when you take the i-th input symbol. So as you look at the previous state and the next input symbol, you should get the next state. That's all that this is saying. And this should happen for each one of these guys. And lastly, for this to be accepted, the very last member here, where we ended up at the end of the input-- so you only care about this at the end of the input-- you have to be in an accepting state. So you can mathematically capture this notion of going along this path. And that's what-- I'm just trying to illustrate that we could describe all this very formally-- I'm not saying that's the best way to think about it all the time-- but that it can be done. And I think that's something worth appreciating. OK. So now in terms of, again, getting back-- we've said this once already, but in terms of the languages that the machine recognizes, it's the collection of strings that the machine accepts. Every machine accepts-- it might accept many strings, but it always recognizes one particular language, even if the machine accepts no strings-- then it recognizes the empty language. So a machine always recognizes one language, but it may have many, many strings that it's accepting. And we call that language the language of the machine. And we say that M recognizes that language. These three things mean the same thing. OK? And now important definition-- I try to reserve the most important things or the highlighted things to be in this light blue color, if you can see that. We say a language is a regular language if there's some finite automaton that recognizes it. OK? So there are going to be some languages that have associated to them finite automata that actually solve those languages, that recognize those languages. But there might be other languages-- and we'll see examples-- where you just can't solve them. You can't recognize them with a finite automaton. Those languages will not be regular languages. The regular ones are the ones that you can do with a finite automaton. That's the traditional terminology.","73.52998352050781","6","DPRSearchEngine","9syvZr-9xwk.en-j3PyPqV-e1s_7_mp4","9syvZr-9xwk.en-j3PyPqV-e1s","18.404J","1"
"94","What are the terminals in the given context-free grammar?","This is just another word for being not in R. OK, and next thing I'd like to do is prove to you that most decision problems are uncomputable, or sketcher proof. So remember, decision problems are problems where the answer is just yes or no. This is a very special kind of problem. And even those, almost all of them, cannot be solved. So halting is an example of a problem we want-- we can't solve. This whole class, this 006, is about problems we can solve. But today I'm going to show you that, actually, those are in the minority. Most problems cannot be computed. This is very strange and also a little depressing. So we'll talk more about that in a moment. First let me argue why this is the case. So I'm going to be a little informal about what exactly is a computer program and what exactly is a decision problem. But roughly, all I need to do, the only level of precision I need is just to count how many are there. What is a computer program? Well, it's usually a file. What's a file? It's like a string of characters. What's a character? It's a string of bits. So a program is just, in the end, a string of bits, finite string of bits. We all understand that. Whatever language you define, in the end, every program is just a string of bits. And a string of bits we can translate into a number. So we can convert between strings of bits and numbers. When I say number, I mean what's usually called a natural number or a non-negative integer. This is usually represented by bold board bold-- blackboard bold capital N. So this is just 0, 1, 2, and so on. Now, what about decision problems? Decision problem is a specification of what we want to solve. So we can think of it as saying, for every input, is the answer yes or no? That's literally what a decision problem is. The only question is, what is an input? And we've talked about inputs and the size of inputs. And there's lots of different ways to measure them. But in the end, we can think of an input as a string of bits also. It's just a file. So a decision problem is a function from inputs to yes or no. And inputs we're going to say, well, that's a string of bits, which we can associate with a number in N. So here we can start to tie things together. So in other words, a program is a finite string of bits, and a problem is, in some sense, an infinite string of bits because there are infinitely many possible inputs. And for each of them, we specify yes or no. So this is basically an infinite string of bits. So we can imagine 011010001110, infinitely. Just some-- for every string of bits, we can say, OK, if your input is the number 0, here's the answer-- no. If your input is the number 1, then the answer is yes. If your input is the number 2, your answer is yes, and so on down this line. Every infinite string of bits corresponds to exactly one decision problem, which specifies for every possible input integer, which corresponds to a string of bits, what is the answer, yes or no? So this may seem subtle, or it may seem like not a big deal. This is a finite string of bits. This is an infinite string of bits. But mathematics has well studied this problem. And infinite strings of bits, there are very many of them, infinitely many. It's not surprising. There are also infinitely many integers. So maybe it doesn't seem that deep. But there's a difference in infinitude. Programs and integers are countably infinite. And infinite strings of bits are what's called uncountable. I think the most intuitive way to see this is, an infinite string of bits, if I put a decimal or a binary point in front, this encodes a real number between 0 and 1. So this is roughly a real number in 01. And when I'm writing approximately equal here, this really goes in both directions. Given a decision problem, I can define a string of bits, of course giving me the answer for all inputs. And I can convert that into a real number between 0 and 1. But also the other direction, if I take any real number, that is a corresponding decision problem. These are 1 to 1 bijection between them. And the bad news is, real numbers are uncountable, and natural numbers are countable, which means there's a lot more of these than there are these. So one way you might phrase this is, informally, the number of natural numbers is way smaller than the number of real numbers. And so from that, we derive that most problems are unsolvable, because every program solves exactly one decision problem. We can also run a program, conceptually, on all possible inputs, and we will figure out what function at solving. And if we don't allow random numbers in our program, which I'm not here, then every program solves exactly one decision problem. Possibly, it's even worse for us because multiple programs probably solve the same decision problem. They're just-- they add irrelevant lines of code or they don't do anything different. Or you run Bellman-Ford versus running Bellman-Ford five times, you'll get the same result. And that's actually the bad direction for us. We'd like to know whether there is a program that solves every decision problem. And because there are only this many programs and this many decision problems, it just-- there aren't enough to go around.","73.21653747558594","7","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_4_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"94","What are the terminals in the given context-free grammar?","I touched on that briefly in lecture. It's enough to solve the problem. The book has a little bit more detail about ambiguous languages, ambiguous grammars-- ambiguous grammars, I should say. And so this is a grammar that's supposed to represent a fragment of a programming language with if thens and if then elses. I'm sure you're all familiar with those kinds of constructs","72.88961791992188","8","DPRSearchEngine","IycOPFmEQk8.en-j3PyPqV-e1s_4_mp4","IycOPFmEQk8.en-j3PyPqV-e1s","18.404J","5"
"94","What are the terminals in the given context-free grammar?","So there's a lot of variations on the basics sorting problem and the different algorithms that are out there. Two vocabulary words are going to highlight really quick-- one is if your sort is destructive, what that means is that rather than reserving some new memory for my sorted array B and then putting a sorted version of A into B, a destructive algorithm is one that just overwrites A with a sorted version of A. Certainly the C++ interface does this. I assume the Python one does, too. I always forget this detail. In addition to destructive sorts, some sorts are in place, meaning that not only are they destructive, but they also don't use extra memory in the process of sorting. Really, you could imagine a sorting algorithm that has to reserve a bunch of scratch space to do its work, and then put it back into A. For instance, the world's dumbest destructive sort might be to call your non-destructive and then copy it back into A. But that would require order n space to do. So if my algorithm additionally has the property that it doesn't reserve any extra space, at least up to a constant, then we call that in place. OK. So those are our basic vocabulary words. And they're ways to understand the differences between different sorting algorithms. Yes? AUDIENCE: [INAUDIBLE] JUSTIN: Why do they end up using extra O(1) space? Oh yeah, sure. Any time I just make a temporary variable like a loop counter, that's going to count toward that order 1. But the important thing is that the number of variables I need","72.3242416381836","9","DPRSearchEngine","oS9aPzUNG-s.en-j3PyPqV-e1s_13_mp4","oS9aPzUNG-s.en-j3PyPqV-e1s","6.006","3"
"94","What are the terminals in the given context-free grammar?","free and regular, why do we know that's still context free? Because the pushdown automaton for A can be simulating the finite automaton for B inside its finite control, inside its finite memory. The problem is, if you have two context-free languages, you have two pushdown automata, you can't simulate that with one pushdown automaton, because it has only a single stack. So if you're trying to take the intersection of two context-free languages with only a single stack, you're going to be in trouble, because it's hard to-- anyway, that's not a proof, but at least it shows you what goes wrong if you try to do the obvious thing. OK, so if-- and just, here is an important point that was trying to make before. If A and B are both context free and you're taking the intersection, the result may not necessarily be a context-free language. So the class of context-free languages is not closed under its intersection. We'll comment on that in a bit. The context-free languages are closed under the regular operations, however, union, intersection-- union, concatenation, and star. So you should feel comfortable that you know how to prove that. Again, it's one of the-- I think it's problem 0.2. And I think the solution is even given in the book for it. So you just should know how to prove that. It's pretty straightforward. OK, so let's move on then to basically conclude our work on context-free languages, to understand the limitations of context-free grammars, and what kinds of languages may not be context free. And how do you prove that? So how do you prove that, for some language, there is no grammar? Again, you know, it's not enough just to, say, give an informal comment that, I couldn't think of a grammar, or some-- things of that kind. That's not going to be good enough. We need to have a proof. So if we take the language here, 0 to the k, 1 to the k, 2 to the k, so those are strings which are runs of 0's followed by an equal number of 1's followed by an equal number of 2's, so just 0's, then 1's, then 2's, all the same length. That's a language which is not going to be a context-free language. And we'll give a method for proving that. If you had a stack, you can match the 1's with the 0's, but then once you're done with that, the stack is empty. And how do you now make sure that the number of 2's corresponds to the number of 1's that you had? So again, that's an informal argument that's not good enough to be a proof, but it sort of gives an intuition. So we're going to give a method for proving non-context-free-- languages are not context free using, again, a pumping lemma. But this is going to be a pumping lemma that applies to context-free language, not to regular languages. It looks very similar, but it has some extra wrinkles thrown in, because the other older pumping lemma was specific to the regular languages. And this is going to be something that applies to the context-free languages. OK, so now let's just read it. And then we'll try to interpret it again. It's very similar in spirit. Basically, it says that, whenever you have a context-free language, all long strings in the language can be pumped in some kind of way. So it's going to be a little different kind of pumping than we had before. And you stay in the language. OK, so before, we broke the string into three pieces where we could repeat that centerpiece as many times as you like. And you stay in the language. Here, we're going to end up breaking the string into five pieces. So s is going to be broken up into uvxyz. And the way it's going to work here-- so here is a picture. So all long strings-- again, there is going to be a threshold. So whenever you have a language, there is going to be some cut-off length. So all the longer strings in that language can be pumped. And you stay in the language. But the shorter strings, there is no guarantee. So if you have a long string in the language of length at least this pumping length p, then you can break it up into five pieces. But now it's that second and fourth string that are going to play that special pumping role, which means that, what you can do is you can repeat those and you stay in the language. And it's important that you repeat them both, that v and that y, the same number of times. So you're going to have a picture that looks something like this. And that is going to you repeat. If you repeat the v and you repeat the y, you get uvvxyyz. Or if you look at over here, it would be uv squared xy squared z. And that's going to still be in the language. And then we have-- so that's one condition. We'll have to look at all of these conditions when we do the proof, but we just want to understand what the statement is right now. So the second condition is that v and y together cannot be empty. And really, that's another way of saying, they can't both be the empty string, because if they were both the empty string, then repeating them wouldn't change s. And then of course it would stay in the language. So it would be kind of meaningless if they were allowed to be empty. And the last thing is, again, going to be there as a matter of convenience for proving languages are not context free, because you have to make sure there is no possible way of cutting up the string. When you're trying to prove a language is not context free, you have to show the pumping fails. It's going to be helpful sometimes to limit the ways in which the string can be cut up, because then you have-- it's an easier job for you to work with it. So here, it's a little different than before, but sort of similar, that vxy combine as a substring. So I show that over here. vxy together is not too long. So the vxy-- maybe it's better seen up here-- is going to be, at most, p. We'll do an example in a minute of using this. OK, so again, here is our pumping lemma. I've just restated it. So we have it in front of us. And we're going to do a proof. I'm just going to give you the idea of the proof first. And then we'll go through some of the details.","72.10945129394531","10","DPRSearchEngine","IycOPFmEQk8.en-j3PyPqV-e1s_7_mp4","IycOPFmEQk8.en-j3PyPqV-e1s","18.404J","5"
"96","What are the terminal symbols in the given context-free grammar for arithmetical expressions?","let's do another somewhat interesting example of a context-free grammar um this is a grammar that is um can generate arithmetical expressions involving pluses and times so here it is it has how many rules well there are six rules here each line represents two rules so e goes to e plus t or t t goes to t times f or f and f goes to uh parenthesis e parenthesis or a um now so the variables are going to be the symbols that appear on the left hand side et and f the terminal symbols which are going to be the symbols of the language that you're going to be generating um is going to be the plus the time symbols the parentheses are just terminal symbols here so they're nothing not playing any special role besides that and then you have the a which is representing kind of the um operand on which those operators uh would be working if there was actually an expression you would use but they're just symbols from the perspective of the of the grammar and lastly the start variable is going to be as normally appears on the upper left hand side of the grammar in terms of the way you write it down so sometimes you might specify a different start variable but","80.56720733642578","1","DPRSearchEngine","m9eHViDPAJQ.en_4_mp4","m9eHViDPAJQ.en","18.404J","4"
"96","What are the terminal symbols in the given context-free grammar for arithmetical expressions?","OK, so now let's talk about some more the computation, so strings and languages. A string is just a finite sequence of symbols from the alphabet. This class is not going to talk about infinite strings. All of our strings are going to be finite. There's other mathematical theories of automata and so on that talk about infinite inputs and infinite strings. We're not going to talk about that. Maybe rarely, we'll make it very clear, we'll talk about an infinite string, but that's going to be an exception. And a language is a set of strings. That's the traditional way that people in this subject refer to a set of strings. They call it a language-- really because the subject had its roots in linguistics, actually. And they were talking about-- they're trying to understand languages, human languages. So this is just a historical fact, and that's the terminology that's stuck. OK, so two special string-- a special string and a special language. The empty string is the string of length 0. This is a totally legitimate string that you are going to run into now and then. And there's the empty language, which is the set with no strings. These are not the same. They're not even of the same type of object. So don't confuse them with one another. I mean, you can have a set, a language, which has just one element, which is the empty string. That is not the empty set. That is a set-- that is not the empty language. That is a language that has one element in it, namely, the empty string. So those are separate things. OK, so here's a little bit of a mouthful here on the slide, defining what it means for an automaton to accept its input-- accepts its input string w. And we can define that formally. And it's a little technical looking, it's really not that bad. So if you have your input string w, which you can write as a sequence of symbols in the alphabet-- w1, w2, dot dot dot, wn, so like 01001. I'm just writing it out symbol by symbol here. So what does it mean for the machine to accept that input? So that means that there's a sequence of states in the machine, sequence of states of members of Q. So a sequence from Q, these are the states of the machine that satisfy these three properties down here. First of all-- and I'm thinking about the sequence that the machine goes through as it's processing the input w. So when does it accept w? If that sequence has the feature that it starts at the start state, each state legally follows the previous state according to the transition function. So that says the i-th member of the sequence is obtained by looking at the previous one-- the i minus first member of that sequence, the i minus first state in that sequence-- and then looking at what happens when you take the i-th input symbol. So as you look at the previous state and the next input symbol, you should get the next state. That's all that this is saying. And this should happen for each one of these guys. And lastly, for this to be accepted, the very last member here, where we ended up at the end of the input-- so you only care about this at the end of the input-- you have to be in an accepting state. So you can mathematically capture this notion of going along this path. And that's what-- I'm just trying to illustrate that we could describe all this very formally-- I'm not saying that's the best way to think about it all the time-- but that it can be done. And I think that's something worth appreciating. OK. So now in terms of, again, getting back-- we've said this once already, but in terms of the languages that the machine recognizes, it's the collection of strings that the machine accepts. Every machine accepts-- it might accept many strings, but it always recognizes one particular language, even if the machine accepts no strings-- then it recognizes the empty language. So a machine always recognizes one language, but it may have many, many strings that it's accepting. And we call that language the language of the machine. And we say that M recognizes that language. These three things mean the same thing. OK? And now important definition-- I try to reserve the most important things or the highlighted things to be in this light blue color, if you can see that. We say a language is a regular language if there's some finite automaton that recognizes it. OK? So there are going to be some languages that have associated to them finite automata that actually solve those languages, that recognize those languages. But there might be other languages-- and we'll see examples-- where you just can't solve them. You can't recognize them with a finite automaton. Those languages will not be regular languages. The regular ones are the ones that you can do with a finite automaton. That's the traditional terminology.","79.48268127441406","2","DPRSearchEngine","9syvZr-9xwk.en-j3PyPqV-e1s_7_mp4","9syvZr-9xwk.en-j3PyPqV-e1s","18.404J","1"
"96","What are the terminal symbols in the given context-free grammar for arithmetical expressions?","Notation for encodings and TMs
Notation for encoding objects into strings
- If ! is some object (e.g., polynomial, automaton, graph, etc.), 
we write 〈!〉to be an encoding of that object into a string.  
- If !$, !&, … , !( is a list of objects then we write 〈!$, !&, … , !(〉
to be an encoding of them together into a single string. 
Notation for writing Turing machines
We will use high-level English descriptions of algorithms when we describe TMs, 
knowing that we could (in principle) convert those descriptions into states, 
transition function, etc.  Our notation for writing a TM ) is
) = “On input +
[English description of the algorithm]”
Check-in 6.3
If , and - are strings, would ,- be a good choice 
for their encoding 〈,, -〉into a single string?
a)
Yes.
b)
No. 
Check-in 6.3
8
","79.40503692626953","3","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_8_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"96","What are the terminal symbols in the given context-free grammar for arithmetical expressions?","So first, we're going to introduce this concept of regular expressions-- which, again, these are things you may have run into in one way or another before. So we're going to introduce something called the regular operations. Now, I'm sure you're familiar with the arithmetical operations, like plus and times. Those apply to numbers. The operations we're going to talk about are operations that apply to languages. So they're going to take, let's say, two languages, you apply an operation, you're going to get back another language. Like the union operation, for example, that's one you probably have seen before. The union of two languages here is a collection of strings that are in either one or the other. But there are other operations, which you may not have seen before, that we're going to look at-- the concatenation operation, for example. So that says you're going to take a string from the first language and another string from the second language and stick them together. And it's called concatenating them. And you do that in all possible ways, and you're going to get the concatenation language from these two languages that you're starting with, A and B. The symbol we use for concatenation is this little circle. But often, we don't. We just suppress that and we write the two languages next to one another with the little circle implied.","79.28758239746094","4","DPRSearchEngine","9syvZr-9xwk.en-j3PyPqV-e1s_9_mp4","9syvZr-9xwk.en-j3PyPqV-e1s","18.404J","1"
"96","What are the terminal symbols in the given context-free grammar for arithmetical expressions?"," 
 
 
 
 
 
 
 
 
 
 
Regular 
language 
Context Free 
language 
Regular 
languages 
Recap 
Recognizer 
DFA or NFA 
PDA 
Context Free 
languages 
Generator 
Regular 
expression 
Context Free 
Grammar 
11 
","78.98690795898438","5","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_11_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"96","What are the terminal symbols in the given context-free grammar for arithmetical expressions?","And proving languages not regular. The way we're going to prove languages are not regular is by introducing a method called the pumping lemma. And the overarching plan at the pumping lemma, without getting into the specifics of it, is to say-- show that-- that lemma says all regular languages have a certain property, which we will describe. And so to show a language is not regular you simply show the language doesn't have that property, because all regular languages have to have that property. And so by showing a language fails to have the property, it could not be regular. That's the plan. Now, the property itself is a little complicated to describe, but not too bad. I'll try to unpack it for you. But first, let's look at the statement of the lemma, which says that whenever you have a regular language-- let's call it A. So for every regular language A there's always a special value called the pump-- a number. p, we'll call it-- called the pumping length. It's a special number. And it's-- and that length tells you that whenever a string is in that language and it's longer than that length, then something special happens. You can take that string and you can modify it, and you still stay in the language. So anything that's longer than that special length can be modified in a certain way, and you still stay in the language. So let's look at the actual statement of the lemma. So there is a number p such that if s is a string in the language and it's longer than p, or at least of length p, then you can take s and you can cut it up into three pieces-- x, y, and z-- so that's just breaking s into three pieces-- where you can take that middle piece, repeat it as many times as you like, and you still stay in the language. That's the-- what the pumping lemma is saying. And there's a bunch of other conditions here too. But the spirit of the pumping lemma says, whenever you have a regular language there's some cutoff such that all strings longer than that cutoff can be what we call pumped. You can take that string, you can find a section somewhere in the middle of that string or somewhere-- you cut it up in three pieces, you take that center piece, and you can repeat it. You can pump it up. And by repeating that string and repeating that piece, the string gets longer and longer. But you still stay in the language. That's the special property that all regular languages have. So in an informal way-- and we'll do-- I'll try to help you get the feeling for this. Informally, it says that if you have a regular language, then every long string-- so a long is by-- informal way of saying bigger than this value p. Every long string in the language can be pumped. And this result still stays in the language. And by ""pumped"" means I can cut the string into three pieces and repeat that middle piece as many times as I want. That's what I mean by pumping a string.","77.89070129394531","6","DPRSearchEngine","KAySmSEGc9U.en-j3PyPqV-e1s_9_mp4","KAySmSEGc9U.en-j3PyPqV-e1s","18.404J","3"
"96","What are the terminal symbols in the given context-free grammar for arithmetical expressions?","So remembering, again, about Boolean formulas, we're going to consider a special class of Boolean formulas, restricted form of Boolean form formulas called conjunctive normal form. And so this formula here in particular is in that conjunctive normal form. So just remember-- I was explaining some of this to someone else earlier this morning, showing some of these slides, and it was pointed out that not all of you may be familiar with these the Boolean operations of and and or. So this is the or symbol here. This is the and symbol here. Hopefully you've seen just the concept of Booelan and and or. Or is, in a sense, a little bit like a union. And it's like an intersection. And the symbols here are a little bit similar to the union and the intersection-- union and intersection symbols themselves. The V shape is a little bit like a pointy union symbol an the upside down V shape is a little like a pointy intersection symbol. If you haven't seen those-- seen that connection before, maybe it's interesting to observe that. But anyway, what makes this formula be in conjunctive normal form? Well, conjunctive normal formulas are organized in a certain way. They have these groups called clauses within the parentheses that are anded together, that are connected by these and operations. And within those groups, which are called clauses, the elements are ORed together. Those elements are going to be either variables","77.78367614746094","7","DPRSearchEngine","iZPzBHGDsWI.en-j3PyPqV-e1s_3_mp4","iZPzBHGDsWI.en-j3PyPqV-e1s","18.404J","15"
"96","What are the terminal symbols in the given context-free grammar for arithmetical expressions?","And this is going to use subproblem expansion. So the subproblems are going to be x of i, comma f-- this is the minimum total difficulty to play suffix-- because I like suffixes-- t i up to t n minus 1, starting with finger f on note t i. The obvious subproblems would be without this constraint.","77.16172790527344","8","DPRSearchEngine","TDo3r5M1LNo.en-j3PyPqV-e1s_14_mp4","TDo3r5M1LNo.en-j3PyPqV-e1s","6.006","17"
"96","What are the terminal symbols in the given context-free grammar for arithmetical expressions?",") 
/ 
} 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
3 rules
R,S
0,1
S
Example of ') generating a string
S
0 S 1
0 S 1
R
ε
S
0S1
00S11
00R11
0011
% '
= 0-1-
≥0
In '):
Tree of
substitutions
Resulting
string
∈% ')
Context Free Grammars 
') S → 0S1 
S → R }
(Substitution) Rules 
R →ε 
Rule: Variable → string of variables and terminals 
Variables: Symbols appearing on left-hand side of rule 
Terminals: Symbols appearing only on right-hand side 
Start Variable: Top left symbol 
Grammars generate strings 
1. 
Write down start variable 
2. 
Replace any variable according to a rule 
Repeat until only terminals remain 
3. 
Result is the generated string 
4. 
%(') is the language of all generated strings. 
11 
Check-in 3.3 
(a) 001101 
(b) 000111 
(c) 1010 
(d) ε 
'3 
S → RR 
R → 0R1 
R →ε 
Check all of the strings that are in %('3): 
Check-in 3.3 
","77.13124084472656","9","DPRSearchEngine","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3_11_pdf","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3","18.404J","3"
"96","What are the terminal symbols in the given context-free grammar for arithmetical expressions?","Turing machines, as we set them up, they have-- on any input w, they have three possible outcomes. The Turing machine can halt and accept w, can halt and reject w, or it can go forever on w, which is rejecting by looping in our language. A Turing machine can recognize a language, the collection of old strings that it accepts. And if the Turing machine always halts, we say it decides the language, and it's a decider, and so therefore, that language is a decided language, a Turing decider. Often we just say decidable, because we don't really have a notion of deciding in other models, so we often talk about Turing-recognizable or just decidable. Or we'll sometimes just say recognizable, when we understand that we're talking about Turing machines. We briefly talked about encodings. When you write it inside brackets, some objects-- whatever they are-- could be strings, could be machines, could be graphs, could be polynomials-- we're representing them as strings, and maybe a collection of objects together represented as a string in order so that we can present that information as an input to a machine. And we talk about-- our languages our collections of strings. And a notation for writing a Turing machine is going to be simply that English description put inside quotation marks to represent our informal way of talking about the formal object that we could produce, if we wanted to. But we're never going to ask you to do that. OK, so now let me see. Let's just take a quick break, as I promised. If there's any quick questions here, you can ask. Let's see-- got a lot of questions here. All right, why don't we move on? And some of these things are good questions.","76.99845886230469","10","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_2_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"103","What is the problem with initially attempting to connect the accepting states of M1 to the start state of M2 when constructing a finite automaton for the concatenation of two regular languages?","return to the material of the course. As you remember, we were looking at the closure properties for the class of regular languages. We started doing that. And if you recall, hopefully, we did closure under union. And then we tried to do closure under concatenation, which I have shown here on this slide, the proof attempt that we tried to do last time. And let's just review that quickly, because I think that's going to be helpful to see how to fix the problem that came up. So if you remember, we're given two regular languages, A1 and A2. And we're trying to show that the concatenation language A1A2 is also regular. And so the way we go about all of these things is we assume that A1 and A2 are regular. So that means we have machines, finite automata, for A1 and A2. We'll call them M1 and M2, that recognize A1 and A2, respectively. And then what we need to do in order to show the concatenation is regular is to make a finite automaton which recognizes the concatenation. And we tried to do that last time. So if you remember, that concatenation machine-- M, we're calling it-- what is it supposed to do? It's supposed to accept its input if it's in the concatenation language. And that means that the input can be split into two parts, x and y, where x is in the A language, and y is in the B lang-- y is accepted by M1-- and x is accepted by M1, and y is accepted by M2. Sorry I garbled that up. So x should be in A1, and y should be in A2. if you can split w that way, then M should accept it. So M has to figure out if there's some way to split the input so that the first machine accepts the first part, the second machine accepts the second part. And the idea that we came up with for doing that was to take these two machines, build them in to a new machine M, and then connect the accepting states for M to the start state-- connect the accepting states for M1 to the start state for M2. Because the idea would be that if M1 has accepted an initial part, well, then you want to pass control to M2 to accept the rest. But as we observed, that doesn't quite work. Because the first place to split w after you found an initial part that's accepted by M1 may not be the right place. Because the remainder may not be accepted by M2. You might have been better off waiting until you found another place that M1 accepted, later on in the string, say, over here. And then by splitting it over there, then maybe you do get successfully find that the remainder is accepted by M2. Whereas if you tried to split it in the first place, the remainder wouldn't have been accepted by M2. So all you need to do-- M has to know, is there some place to split the input so that you can get both parts accepted by the respective machines? The problem is that M might need to know the future in order to know where to make the split. And it doesn't have access to the future. So what do we do? So what we're going to do is introduce a new concept that will allow us to basically get the effect of M1-- and the-- sort of being able to see the future. And that new concept is going to be very important for us throughout the term.","74.16531372070312","1","DPRSearchEngine","oNsscmUwjMU.en-j3PyPqV-e1s_3_mp4","oNsscmUwjMU.en-j3PyPqV-e1s","18.404J","2"
"103","What is the problem with initially attempting to connect the accepting states of M1 to the start state of M2 when constructing a finite automaton for the concatenation of two regular languages?","All right, acceptance problem for Turing Machines. So just as I mentioned, we showed that A,TM, which is the language of Turing machines and inputs where the machine accepts the input. We showed that was recognizable. We claimed it was decidable. Today, we're going to prove it's not decidable. All right, now the method that we're going to use, which is really the only method out there for proving a problem as undecidable is called the diagonalization method. I mean, ultimately, we're going to show the reducibility method as well. But it really depends on having already shown some other problem undecidable via the diagonalization method. So ultimately, everything hinges on the diagonalization method, which is really what we have.","73.27938842773438","2","DPRSearchEngine","3PzuSPQPEU4.en-j3PyPqV-e1s_3_mp4","3PzuSPQPEU4.en-j3PyPqV-e1s","18.404J","8"
"103","What is the problem with initially attempting to connect the accepting states of M1 to the start state of M2 when constructing a finite automaton for the concatenation of two regular languages?"," 
 
 
 
 
  
 
 
 
 
 
 
  
 
   
 
 
 
 
 
 
    
       
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Nondeterministic Turing machines 
A Nondeterministic TM (NTM) is similar to a Deterministic TM 
except for its transition function !: Q×Γ → '( )×Γ× {L, R} ). 
Theorem: + is T-recognizable iff some NTM recognizes + 
Proof: (→) immediate. 
(←) convert NTM to Deterministic TM. 
Deterministic TM 
NTM 
. 
a a b a ˽ ˽ 
-
02 a a b a # 01 c b # 03 b c b ˽ ˽ 
Nondeterministic computation tree 
- simulates . by storing each thread’s tape in a 
for . on input /. 
separate “block” on its tape. 
Also need to store the head location, 
and the state for each thread, in the block. 
If a thread forks, then - copies the block. 
If a thread accepts then - accepts. 
accept 
4 
. . . 
","72.96820068359375","3","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_4_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"103","What is the problem with initially attempting to connect the accepting states of M1 to the start state of M2 when constructing a finite automaton for the concatenation of two regular languages?","  
 
  
 
 
  
 
  
 
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
  
 
 
   
-
Review: Probabilistic TMs and BPP 
coin flip step 
each choice has 
Defn: A probabilistic Turing machine (PTM) is a variant of a NTM 
where each computation step has 1 or 2 possible choices. 
deterministic 
step 
50% probability 
Defn: For ! ≥0 say PTM $  decides language % with error probability !  
if for every &, Pr[ $  gives the wrong answer about & ∈% ] ≤! . 
Defn: BPP = % some poly-time PTM decides % with error !  = +⁄,  } Check-in 24.1 
Actually using a probabilistic algorithm 
Amplification lemma: 2−. /01 2 
presupposes a source of randomness. 
Can we use a standard pseudo-random 
number generator (PRG) as the source? 
& ∈% 
& ∉% 
(a) Yes, but the result isn’t guaranteed.
(b) Yes, but it will run in exponential time.
Many 
Few 
Few 
Many 
(c) No, a TM cannot implement a PRG. 
accepting 
rejecting 
accepting 
rejecting 
(d) No, because that would show P = BPP.
2 
Check-in 24.1 
","72.45719146728516","4","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_2_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"103","What is the problem with initially attempting to connect the accepting states of M1 to the start state of M2 when constructing a finite automaton for the concatenation of two regular languages?"," 
 
 
  
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
Computation with Oracles 
Let ! be any language. 
Defn: A TM "" with oracle for !, written ""#, is a TM equipped 
with a “black box” that can answer queries “is $ ∈!?” for free. 
Example: A TM with an oracle for &!' can decide all ( ∈ NP in polynomial time. 
Defn: P# = ( ( is decidable in polynomial time with an oracle for !} 
Thus NP ⊆ P+#, 
NP = P+#,? Probably No because coNP ⊆ P+#, 
Defn: NP# = ( ( is decidable in nondeterministic polynomial time with an oracle for !} 
Recall MIN-FORMULA = 7 7 is a minimal Boolean formula } 
Example: MIN−FORMULA ∈ NP+#, 
“On input 7 
1. Guess shorter formula 9 
2.  Use &!' oracle to solve the coNP problem: 7 and 9 are equivalent 
3. Accept if 7 and 9 are equivalent. Reject if not.” 
8 
","72.35929107666016","5","DPRSearchEngine","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_8_pdf","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22","18.404J","22"
"103","What is the problem with initially attempting to connect the accepting states of M1 to the start state of M2 when constructing a finite automaton for the concatenation of two regular languages?","What are oracles? Oracles are a simple thing. But they are a useful concept for a number of reasons. Especially because they're going to tell us something interesting about methods, which may or may not be useful for proving the P versus NP question, when someday somebody hopefully does that. What is an oracle? An oracle is free information you're going to give to a Turing machine, which might affect the difficulty of solving problems. And the way we're going to represent that free information is, we're going to allow the Turing machine to test membership in some specified language, without charging for the work involved. I'm going to allow you have any language at all, some language A. And say a Turing machine with an oracle for A is written this way, M with a superscript A. It's a machine that has a black box that can answer questions. Is some string, which the machine can choose, in A or not? And it gets that answer in one step, effectively for free. So you can imagine, depending upon the language that you're providing to the machine, that may or may not be useful. For example, suppose I give you an oracle for the SAT language. That can be very useful. It could be very useful for deciding SAT, for example. Because now you don't have to go through a brute force search to solve SAT. You just ask the oracle. And the oracle is going to say, yes it's satisfiable, or no it's not satisfiable. But you can use that to solve other languages too, quickly. Because anything that you can do in NP, you can reduce to SAT. So you can convert it to a SAT question, which you can then ship up to the oracle, and the oracle is going to tell you the answer. The word ""oracle"" already sort of conveys something magical. We're not really going to be concerned with the operation of the oracle, so don't ask me how does the oracle work, or what does it correspond to in reality. It doesn't. It's just a mathematical device which provides this free information to the Turing machine, which enables it to compute certain things. It turns out to be a useful concept. It's used in cryptography, where you might imagine the oracle could provide the factors to some number, or the password to some system or something. Free information. And then what can you do with that? So this is a notion that comes up in other places. If we have an oracle, we can think of all of the things that you can compute in polynomial time relative to that oracle. So that's what we-- the terminology that people usually use is sometimes called relativism, or computation relative to having this extra information. So P with an A oracle is all of the language that you can decide in polynomial time if you have an oracle for A. Let's see. Yeah. Somebody's asking me, is it really free or does it cost one unit? Even just setting up the oracle and writing down the question to the oracle is going to take you some number of steps. So you're not going to be able do an infinite number of oracle calls in zero time. So charging one step or zero steps, not going to make a difference. Because you still have to formulate the question. As I pointed out, P with a SAT oracle-- so all the things you do in polynomial time with a SAT oracle includes NP. Does it perhaps include other stuff? Or does it equal NP? Would have been a good check-in question, but I'm not going to ask that. In fact, it seems like it contains other things too. Because co-NP is also contained within P, given a SAT oracle. Because the SAT oracle answer is both yes or no, depending upon the answer. So if the formula is unsatisfiable, the oracle is going to say no, it's not in the language. And now you can do the complement of the SAT problem as well. The unsatisfiability problem. So you can do all of co-NP in the same way. You can also define NP relative to some oracle. So all the things you can do with a non-deterministic Turing machine, where all of the branches have separately access. And they can ask multiple questions, by the way, of the oracle. Independently. Let's do another, a little bit of a more challenging example. The MIN-FORMULA language, which I hope you remember from your homework. So those are all of the formulas that do not have a shorter equivalent formula. They are minimal. You cannot make a smaller formula that's equivalent that gives you the same Boolean function. So you showed, for example, that that language is in P space, as I recall. And there was some other-- you had another two problems about that language. The complement of the MIN-FORMULA problem is in NP with a SAT oracle. So mull that over for a second and then we'll see why. Here's an algorithm, in NP with a SAT oracle algorithm. So in other words, now I want to kind of implement that strategy, which I argued in the homework problem was not legal. But now that I have the SAT oracle, it's going to make it possible where before it was not possible. So let's just understand what I mean by that. If I'm trying to do the non minimal formulas, namely the formulas that do have a shorter equivalent formula. I'm going to guess that shorter formula, called psi. The challenge before was testing whether that shorter formula was actually equivalent to phi. Because that's not obviously doable in polynomial time. But the equivalence problem for formulas is a co-NP problem. Or if you like to think about it the other way, any formula in equivalence is an NP problem, because you just have to-- the witness is the assignment on which they disagree. So two formulas are equivalent if they never disagree. And so that's a co-NP problem. A SAT oracle can solve a co-NP problem. Namely, the equivalence of the two formulas, the input formula and the one that you now deterministically guessed. And if it turns out that they are equivalent, a smaller formula is equivalent to the input formula, you know the input formula is not minimal. And so you can accept. And if it gets the wrong formula, it turns out not to be equivalent, then you reject on that branch of the non-determinism, just like we did before. And if the formula really was minimal, none of the branches is going to find a shorter equivalent formula. So that's why this problem here is in NP with a SAT oracle. So now we're going to try to investigate this on my-- we're getting near the end of the lecture. We're going to look at problems like, well, suppose I compare P with a SAT oracle and NP with a SAT oracle. Could those be the same? Well, there's reasons to believe those are not the same. But could there be any A where P with A oracle is the same as NP with an A oracle? It seems like no, but actually that's wrong. There is a language, there are languages for which NP with that oracle and P with that oracle are exactly the same. And that actually is an interest-- it's not just a curiosity, it actually has relevance to strategies for solving P versus NP. Hopefully I'll be able to have time to get to. Can we think of an oracle like a hash table? I think hashing is somehow different in spirit. I understand there's some similarity there, but I don't see the-- hashing is a way of finding sort of a short name for objects, which has a variety of different purposes why you might want to do that. So I don't really think it's the same. Let's see, an oracle question, OK, let's see. How do we use SAT oracle to solve whether two formulas are equivalent? OK, this is getting back to this point. How can we use a SAT oracle to solve whether two formulas are equivalent? Well, we can use a SAT oracle to solve any NP problem, because it's reducible to SAT. In other words-- P with a SAT oracle contains all of NP, so you have to make sure you understand that part. If you have the clique problem, you can reduce. If I give you a clique problem, which is an NP problem, and I want to use the oracle to test if the formula-- if the graph has a clique, I reduce that problem to a SAT problem using the Cook-Levin theorem. And knowing that a clique of a certain size is going to correspond to having a formula which is satisfiable, now I can ask the oracle. And if I can do NP problems, I can do co-NP problems, because P is a deterministic class. Even though it has an oracle, it's still deterministic. It can invert the answer. Something that non-deterministic machines cannot necessarily do. So I don't know, maybe that's-- let's move on. So there's an oracle where P to the A equals NP to the A, which kind of seems kind of amazing at some level. Because here's an oracle where the non-determinism-- if I give you that oracle, non-determinism doesn't help. And it's actually a language we've seen. It's TQBF. Why is that? Well, here's the whole proof. If I have NP with a TQBF oracle. Let's just check each of these steps. I claim I can do that with a non-deterministic polynomial space machine, which no longer has an oracle. The reason is that, if I have polynomial space, I can answer questions about TQBF without needing an oracle. I have enough space just to answer the question directly myself. And I use my non-determinism here to simulate the non-determinism of the NP machine. So every time the NP machine branches non-deterministically, so do I. Every time one of those branches asks the oracle a TQBF question, I just do my polynomial space algorithm to solve that question myself. But now NPSPACE equals PSPACE by Savitch's theorem. And because TQBF is PSPACE complete, for the very same reason that a SAT oracle allows me to do every NP problem, a TQBF problem allows me to do every PSPACE problem. And so I get NP contained within P for a TQBF oracle. And of course, you get the containment the other way immediately. So they're equal. What does that have to do with-- somebody said-- well, I'll just-- I don't want to run out of time. So I'll take any questions at the end. What does this got to do with the P versus NP problem? OK, so this is a very interesting connection. Remember, we just showed through a combination of today's lecture and yesterday's lecture, and I guess Thursday's lecture, that this problem, this equivalence problem, is not in PSPACE, and therefore it's not in P, and therefore it's intractable. That's what we just did. We showed it's complete for a class, which is provably outside of P, provably bigger than P. That's the kind of thing we would like to be able to do to separate P and NP. We would like to show that some other problem is not in P. Some other problem is intractable. Namely, SAT. If we could do SAT, then we're good. We've solved P and NP. So we already have an example of being able to do that. Could we use the same method? Which is something people did try to do many years ago, to show that SAT is not in P. So what is that method really? The guts of that method really comes from the hierarchy there. That's where you were actually proving problems that are hard. You're getting this problem with through the hierarchy construction that's provably outside of PSPACE. And outside of P. That's a diagonalization. And if you look carefully at what's going on there-- so we're going to say, no, we're not going to be able to solve SAT, show SAT's outside of P in the same way. And the reason is, suppose we could. Well the hierarchy theorems are proved by diagonalization. What I mean by that is that in the hierarchy theorem, there's a machine D, which is simulating some other machine, M. To remember what's going on there, remember that we made a machine which is going to make its language different from the language of every machine that's running with less space or with less time. That's how D was defined. It wants to make sure its language cannot be done in less space. So it makes sure that its language is different. It simulates the machines that use less space, and does something different from what they do. Well, that simulation-- if we had an oracle, if we're trying to show that if we provide both a simulator and the machine being simulated with the same oracle, the simulation still works. Every time the machine you're simulating asks a question, the simulator has the same oracle so it can also ask the same question, and can still do the simulation. So in other words, if you could prove P different from NP using basically a simulation, which is what a diagonalization is, then you would be able to prove that P is different from NP for every oracle. So if you can prove P different from NP by a diagonalization, that would also immediately prove that P is different from NP for every oracle. Because the argument is transparent to the oracle. If you just put the oracle down, everything still works. But-- here is the big but, it can't be that-- we know that P A is-- we know this is false. We just exhibit an oracle for which they're equal. It's not the case that P is different from NP for every oracle. Sometimes they're equal, for some oracles. So something that's just basically a very straightforward diagonalization, something that's at its core is a diagonalization, is not going to be enough to solve P and NP. Because otherwise it would prove that they're different for every oracle. And sometimes they're not different, for some oracles. That's an important insight for what kind of a method will not be adequate to prove P different from NP. And this comes up all the time. People who propose hypothetical solutions that they're trying to show P different from NP. One of the very first things people ask is, well, would that argument still work if you put an oracle there. Often it does, which points out there was a flaw. Anyway, last check in. So this is just a little test of your knowledge about oracles. Why don't we-- in our remaining minute here. Let's say 30 seconds. And then we'll do a wrap on this, and I'll point out which ones are right. Oh boy, we're all over the place on this one. You're liking them all. Well, I guess the ones that are false are lagging slightly. OK, let's conclude. Did I give you enough time there? Share results. So, in fact-- Yeah, so having an oracle for the complement is the same as having an oracle. So this is certainly true. NP SAT equal coNP SAT, we have no reason to believe that would be true, and we don't know it to be true. So B is not a good choice and that's the laggard here. MIN-FORMULA, well, is in PSPACE, and anything in PSPACE is reducible to TQBF, so this is certainly true. And same thing for NP with TQBF and coNP with TQBF. Once you have TQBF, you're going to get all of PSPACE. And as we pointed out, this is going to be equal as well. So why don't we end here. And I think that's my last slide. Oh no, there's my summary here. This is what we've done. And I will send you all off on your way. How does the interaction between the Turing machine and the oracle look? Yeah, I didn't define exactly how the machine interacts with an oracle. You can imagine having a separate tape where it writes the oracle question and then goes into a special query state. You can formalize it however you like. They're all going to be-- any reasonable way of formalizing it is going to come up with the same notion in the end. It does show that P with a TQBF oracle equals PSPACE. Yes, that is correct. Good point. Why do we need the oracle to be TQBF? Wouldn't SAT also work because it could solve any NP problem? So you're asking, does P with a SAT oracle equal NP with a SAT oracle? Not known. And believed not to be true, but we don't have a compelling reason for that. No one has any idea how to do that. Because, for example, we showed the complement of MIN-FORMULA is in NP with a SAT oracle. But no one knows how to do-- because there's sort of two levels of non-determinism there. There's guessing the smaller formula, and then guessing again to check the equivalence. And they really can't be combined, because one of them is sort of an exist type guessing, the other one is kind of a for all type guessing. No one knows how to do that in polynomial time with a SAT oracle. Generally believed that they're not the same. In the check-in, why was B false? B is the same question. Does NP with a SAT oracle equal coNP with a SAT oracle? I'm not saying it's false, it's just not known to be true. It doesn't follow from anything that we've shown so far. And I think that would be something that-- well, I guess it doesn't immediately imply any famous open problem. I wouldn't necessarily expect you to know that it's an unsolved problem, but it is. Could we have oracles for undecidable language? Absolutely. Would it be helpful? Well, if you're trying to solve an undecidable problem, it would be helpful. But people do study that. In fact, the original concept of oracles was presented, was derived in the computability theory. And a side note, you can talk about reducibility. No, I don't want to even go there. Too complicated. What is not known to be true? What is not known to be true is that NP with a SAT oracle equals coNP with a SAT oracle, or equals P with a SAT oracle. Nothing is known except the obvious relations among those. Those are all unknown, and just not known to be true or false. Is NP with a SAT oracle equal to NP? Probably not. NP with a SAT oracle, for one thing, contains coNP. Because it's even more powerful. We pointed out that P with a SAT oracle contains coNP. And so NP with a SAT oracle is going to be at least as good. And so it's going to contain coNP. And so, probably not going to be equal to NP unless shockingly unexpected things happen in our complexity world.","71.89971923828125","6","DPRSearchEngine","N32bnUliSzo.en-j3PyPqV-e1s_9_mp4","N32bnUliSzo.en-j3PyPqV-e1s","18.404J","22"
"103","What is the problem with initially attempting to connect the accepting states of M1 to the start state of M2 when constructing a finite automaton for the concatenation of two regular languages?","OK, so we're going to-- our coffee break is coming, in case you're wondering. So this is my last slide before then. But this is an important slide, so please hold out. So here is our promised theorem of the day. I'm going to show that A,TM is not decidable, the acceptance problem for Turing machines. And it's all going to be contained on this one slide. We're going to give a proof by contradiction using diagonalization. And we're going to assume some Turing machine, H, decides A,TM. And we're going to get a contradiction. So let's, first of all, make sure we understand what H is doing. So H gets an input-- a Turing machine and an input. And H is going to be a decider, so it always halts with an accept or a reject. It's supposed to accept if M accepts w and reject if it doesn't. So in other words, it's going to reject if M rejects w either by halting or by looping. That's the job of H. And we're assuming we can do that. But we will see a contradiction occur. So the way we're going to do that is really kind of just one step here in a way. And we're going to use H to construct another Turing machine D. H is going to be a subroutine to D. We've already seen us doing that in the past. D is going to do something a little strange, just to warn you. D's input is just a Turing machine-- no w. And what D is going to do using its subroutine H is going to simulate H on input M, comma, the description of M. Now what is that? Well, the description of M is just some string. So what H is trying-- what it's asking H to tell, to answer is, does M accept the string representing M's own description? It's as if we're feeding M into itself, which seems like a totally twisted thing to do, you might say. Why would you ever feed a program into itself? Somebody has written cannibalism here-- yeah, kind of. I'd say it's worse [LAUGHS] because it's not eating somebody else. It's eating yourself. OK, but I claim that there are actual cases in practice where we do this. We feed programs into themselves. And the example that I know of where this is done is when you're making a compiler. You might want to make a compiler and then written in the same language that it's compiling. And then you feed the compiler into itself. You may say, why even bother because it's already, obviously, if it, once it's running, you don't need to compile it again. But actually, an example where this was really used was when there was an optimizing compiler, I think, for C written on early Unix machines. And the optimizing compiler for C was written in C. So you would feed the optimizing compiler into the regular compiler, first of all. Now, you had the compiler running, but it was an optimized. So but now that it's the optimizing compiler is running, you can feed the optimizing compiler into that, which is itself. Now you have an optimized optimizing compiler. So it really makes some-- there is at least one case where this has actually been done in practice. Not that we really care. This is a theory class-- but just for fun to observe that. So here, H is trying to say, well, does in a M end up accepting when it's fed the description of itself? You know, at least, mathematically speaking, that's a reasonable thing to ask. And then what D is going to do when it gets the answer back from H-- H is a decider, don't forget-- is D's going to do the opposite of whatever H does. It's going to accept if H rejects and reject if H accepts. So let's, in summary, let's pull this together, so it's easy to understand, in the end, what is D doing? D is going to accept. D is also going to be decider, by the way. So D is always going to either accept or reject-- Just. The opposite of what H tells it to do. So D is going to accept M exactly when M doesn't accept M because when M doesn't accept M, H is going to reject, and so then D is going to accept. So D accepts M if and only if M doesn't accept M. That's exactly the condition in which D accepts M. I think it's important to just step back and make sure you understand this line because we have only one line left to get our contradiction. Right? Are we together? D accepts M if and only if M doesn't accept M. That's just by the way we've defined setup D. Now what we're going to do is feed in, instead of M to D, and not some arbitrary feed, we're going to use feed in D into D. And that is going to be our contradiction because D is now going to accept D if and only if D doesn't accept D, and that's certainly impossible. That's our contradiction which proves that H cannot exist. And therefore, A,TM is undecidable. OK, so we're done, except for the one point, which is that why is this a diagonalization? And I think you can get that from the following picture. If you imagine here writing down all possible times-- I'm going to make a table here. Here is the list of all Turing machines, including D, which is a machine which I built under the assumption that H exists. So D appears here somewhere. But here are all the other Turing machines. And here are all of these descriptions of the Turing machines along the labeling all of the columns. OK, so these are the rows labeled. These are the column labels. And inside, I'm going to tell you the answer for whether a given machine accepts a given input. So for example, M1 accepts its own description but rejects the description of M2, but accepts the description of M3. I don't you know. I'm obviously I'm making this up. I don't know what M1 is. But just hypothetically, that's what the machine M1 does. So I'm just filling out this table. H could get the answer to any of the elements in this table because it can test whether M4 accepts the description of M3. So H could fill out this table. So maybe M2 is a machine that always rejects. It's a very unfriendly, rejecting machine. M3 is a very friendly machine. It accepts all inputs. M4 rejects some and accepts others, dot, dot, dot. Now, I want to look and see, what does D do? Now based on the information that I've already given you, we can understand what D does. So for example, what does D do when I feed it the description of M1? What does D do? Well, we can look here. D accepts M if and only if M doesn't accept M. So D is going to accept M1 if and only if M1 does not accept M1. Well, M1 does accept M1. So D does the opposite. D rejects. So OK, I'm highlighting here. D rejects because D is going to do the opposite of what the machine does on its own it on input. So D on M2, you have to look what M2 does on M2. It rejects, so D does the opposite of that. It accepts. And similarly, each one of these things-- D's answer is going to be the opposite of what the machine does on its own description, just by virtue of the definition of D. OK, and so on-- so far, so good. But the problem is, what happens when D is fed itself? Because, as you can see, we're heading for trouble because this is a diagonal down here. D is just one of the rows. That diagonal is going to intersect that row at this point. And D is defined to be going to be doing the opposite of what that element is, but it can't be the opposite of itself. And so that's the contradiction. So I think we're-- I'm going to call us, give us a little break here. And then you can also text me in the meantime. I'll be happy to answer some questions during that. A little over 4 minutes to go-- so let's see. Let me see if I can answer your questions. OK, what's so special about A,TM that enables us to do this? Why can't we do this on ADFA, for example? That's a good question. And the answer is that, in a sense, we can do this on DFA. I mean, I think this is, perhaps, a bit of a stretch. But DFAs could not answer ADFA. I mean, we could prove that in other ways as well by just-- we could use things like the pumping lemma, and it's not clear, even how you'd formulate ADFA. But what's important here is that it's really the model talking about itself that really is where the problem comes up. So if you try to push this argument through to show that ADFA is not decidable by Turing machines, you're going to fail because we're starting off with a Turing machine. And I think I'm going to confuse myself if I try to just repeat it. But you won't get a contradiction because the Turing machine is not a finite automaton. OK. Will this argument get into self-loops? I don't see why it would-- there is some self-reference, perhaps. We're going to talk about that a little later. So we're going to come back and revisit this argument in a week or so when we talk about the recursion theorem which talks about machines that can refer to themselves. But this is a little bit of a head-- getting ahead of ourselves. So somebody's commenting on this reminding them of the barber paradox, if you remember that, which has some similarity. There is a town in which there was a barber which shaves every man who doesn't shave themselves. It seems he's a very good barber. So there are some people who shave themselves. And all the rest, the barber shaves. The question is, does the barber shave himself? Because he shaves only those men who don't shave themselves. So you've got a same kind of a contradiction. There is a relationship there. So someone wants to know, where did we use the decidability? So we used the decidability to come up with H. Once we know that A,TM is decidable, then we have that H function, and then we can build D. So that's the chain of reason. So you assume A,TM is decidable. Then you have the decider called H, and then you can build D. Somebody wants to see the previous slide. What part of the slide do you want? So I'll leave that up there. Why can we apply the proof that all Turing machines are accountable to all languages? Well, because Turing machines have descriptions. General languages don't have descriptions. And so that's why. OK, the candle has burnt to the bottom, and it's time to move on. So now, let's look at the acceptance problem for queue automata. I'll give you a queue automaton on input, and I want to know, does it accept the input? Is that going to be decidable? And you have your choices. It's either yes, it is decidable because these are similar to pushdown automata and APDA is decidable, or no because yes contradicts results that we know at this point, or we don't have enough information to answer the question. OK, let's put that up. One second-- [LAUGHS] all right, that's it. Ready, going, gone. So yes, the answer is, well, no. [LAUGHS] The answer is, indeed, the answer is B. True, that queue automata are similar to pushdown automata, but all these automata are similar to each other, and that's not going to be good enough. What the homework has asked you to do is to show that you can simulate Turing machines with queue automata. So if you can answer the question about whether the queue automata will accept their input, that would allow you to be able to answer questions about whether Turing machines accept their input. And we just proved that's not possible. So it would be a contradiction if we could answer-- if we could decide A, queue, A. Now, we have an example of an undecidable language. Let's look at an example of an unrecognizable language. Now A,TM is not going to serve that purpose because A,TM is Turing-recognizable, as we pointed out by the universal Turing machine. So A,TM is undecidable, however. How about an unrecognizable language? For that, we will see that the complement of A,TM will serve. So the complement of A,TM is neither decidable nor even recognizable. Now it's not Turing-recognizable. And that's going to follow from a pretty basic theorem that connects recognizability and decidability that I've put up here on the screen, which is that if you have a language where it and its complement are both recognizable, then the language turnout turns out to be decidable. In fact, a language and its complement are decidable. But being decidable is closed under complement, so that's something you should be aware. But being-- OK. We'll get to that in a minute. But if-- so anyway, so if you have a language and it's complement both recognizable, how do we know the language is decidable? So first of all, let's take the two Turing machines, M1 and M2 that recognizes A and A-complement. And we're going to put those together to get a decider for A. And that's going to work like this. It's going to be called T. So T says, on input w, what it's going to do, it's going to feed w into M1 and M2 both. A is the language, by the way, yes. A is-- when I say it's Turing-recognizable, you know, Turing-recognizable only applies to languages. So yes, A is often this symbol I'm going to use for languages, sometimes for an automaton. But A is typically going to be a language. So now, I'm trying to make T be a decider for A from the recognizers for A and A-complement. So I'm going to take an input to T and feed it into both recognizers, M1 and M2. OK, I'm going to run them in parallel. What's nice is that because M2 recognizes the complement of what M1 recognizes, every string is going to be accepted either by M1 or by M2 because every string is either an A or an A-complement. So if I run M1 and M2 on w until one of the halts or one of them accepts, I know I'm not going to run forever because, eventually, one or the other one have to accept. So and then I got my answer because if M1 accepts, then I know I'm in the language. But if M2 accepts, I know I'm in the complement of the language, so I'm out of the language. So if M1 accepts, then T should accept. But if M2 accepts, then T should reject. , So that proves that nice little theorem written at the top in blue. So I got my decider for A built out of the recognizers for A and A-complement. Now immediately, it follows that the complement of A,TM is not Turing-recognizable because we know that A,TM itself is recognizable, but it's undecidable. If the complement was also recognizable, then A,TM would be decidable, but it isn't. So when something is decidable, either it or its complement have to be unrecognizable. And in the case for A,TM, it has to be the complement because we already showed that it is itself is recognizable. So that's the proof of that. So here is a little picture of the way the world looks right now if you have here, in the middle are the decidable languages-- so these are all languages, this Venn diagram of languages. We showed earlier, the regular, the context-free, decidable, recognizable. Here, I've got the recognizable and what I'm calling the co-Turing recognizable. This is the collection of all complements of recognizable languages. So A,TM bar, A,TM complement is the complement of a recognizable language. This region here are all the complements of the recognizable languages or the so-called co-Turing recognizable languages-- complement of. So A,TM is on this side. A,TM-complement is on that side. But if something's in both, by virtue of this theorem here, then it's decidable. OK, last check-in for the day. From what we learned so far, which closure properties can we prove for the class of deterring recognizable languages? Choose all that apply. Well, as I say, you don't have to get it right. Let's not spend too much more time on this because we'll talk a little bit about it. Almost all-- its closed under almost all of them, but not all of them. Because-- are we done here? I think we're done-- 5 seconds. OK, here we go, ending polling. I'm not sure what the meaning of [LAUGHS] deleting your answer is here. Everybody likes union, I guess. They're closed under all of these operations except complement. But we just proved it's not closed under complement, so I'm a little puzzled by why we have so many votes for closure under complement. We have here, A,TM is Turing-recognizable, but A,TM-complement is not Turing-recognizable. it's right here on the slide. I'm not trying to make you feel bad, but I'm trying to just point out that you think, please. So now closure under union and intersection, I mean, you could kind of get those answers just by running things in parallel the way we did the proof here. You just run both machines. And if they both give-- I mean, it's a little tricky, I suppose. If either one of them accept, then you can accept. Or if they both accept, you just wait until they both have accepted. Otherwise, you just keep running. So the first two are pretty straightforward. Closure under concatenation-- this is also going to be similar. You just try every possible way of cutting the string up into two pieces and run in parallel on. And if you ever find a way of cutting it up, and you run those two, and put those two sides in parallel, and if they both accept, then you can accept. And star is, again, very similar. So these are not too bad. But I admit, you know, it's not a whole lot of time to have to contend with something that you're just getting used to. So let's talk about the very last topic of the day, which is really going to be setting ourselves up for Tuesday's lecture next week. And that's how we are going to be showing other languages are undecidable, which is something that I'm going to be expecting you guys to be able to do. This is the standard procedure for showing languages are undecidable using what's called the reducibility method. And what that does is it takes, as a starting point, a language that we already know is undecidable-- typically, A,TM-- or it could be another one that you've previously shown to be undecidable-- and leverages that information to show other languages are undecidable. And it's using what's called reducibility. We're going to go into this more carefully next time. But basically, reducibility is a way of using one problem to solve another problem. And so we are going to show, for example, let's take a look at the problem called the halting problem, which is like the famous problem for Turing machines. You just want to know whether it halts, not necessarily whether it accepts. So it's very similar, but not exactly the same. And we're going to show that this halting problem is similarly undecidable. Now we could go back and do the whole diagonalization, but that seems like-- well, that's more work than necessary now that we already know A,TM is undecidable because we're going to show that we can reduce the A,TM problem to the halting problem. And we'll explain what that means again later. But the idea is-- and as we'll show in an illustration shortly-- that by proving by contradiction if the if HALT,TM were decidable, then A,TM would be decided. And we know A,TM is not decidable. And so that's our contradiction. Now the way we're going to show that if HALT,TM is decidable, then A,TM is decidable is use a decider for HALT,TM to decide A,TM with a suitable modification. So basically, we want to turn a HALT,TM decider into an A,TM decider. And that's how we're going to reduce the problem of solving A,TM to the problem of solving HALT,TM. Let's just do an example. If you've seen it before, obviously, this is not going to be hard. But for the many of you who have not seen it before, I'm partly doing it this time just so we can do it again next time. And maybe it'll sink in by virtue of repetition. So again, so as I just said, we're going to assume the HALT,TM problem is decidable and use that to show that A,TM is decidable, which we know is false. We showed it just earlier that it's not. So assume we have a decider for HALT,TM. We'll call it R. And we're going to construct from R a decider for A,TM we'll call S. OK? So we're, again, typical proof by contradiction. We're assuming the opposite of what we're trying to prove. And then we're going to get something crazy. OK, so here, my job now, is I'm assuming I have R, which is a HALT,TM decider. So now, I'm assuming I know how to decide if a Turing machine and an input eventually halts-- Not. Necessarily would it accept, just whether it halts. It's conceivable. You have to bear with me here. It's conceivable that you could find a way to test whether Turing machines halt on their input, even though we now know that testing whether they accept their input is not decidable. So you have to be open-minded to the possibility that the HALT problem is decidable, and we're going to show that that's can't be. So we're going to show that if we could decide the halting problem, then we can use that to decide the acceptance problem. OK, so how are we going to do that? So imagine how we can solve the halting problem. So to solve the A,TM, which is what my job is to do, so S is supposed to solve A,TM. I'm constructing a Turing machine as decide A,TM. I'm going to use first-- I'm giving it M and w. I'm going to feed it into R since that's really all I got. See if R tells me what happens. Does M on w at least halt? Well, if R says, no, it doesn't halt, well then I'm actually done because if M doesn't even halt on w, then it couldn't be accepting w. So at that point, I know that M doesn't accept w, and I can reject right off. So R, you can see how it could potentially be helpful. But it's going to be helpful in either way because if R says M does hold, well, then, I'm also good because I don't know the answer yet, but what I do know is I can now simulate M on w until it halts because R has told me it halts. So I don't have to worry about getting into a loop. So S can be confident in being a decider for whatever it's doing because I'm running now M on w with a guarantee that it halts. And now, that's going to tell me-- now eventually, the simulation of M on w is going to end up at an accept or reject. And that's going to be the answer I need. So if M is accepted, then accept. And if M is rejected, then reject. And that's how S solves A,TM using R, which solves HALT,TM. But S can't exist. And so therefore, R can't exist. And therefore, HALT,TM can't be decidable. OK? So that quickly-- OK, I'm not sure which diagram you wanted me to show. But anyway, maybe we can do that. We're basically at the end of the hour or end of the 90 minutes. So let's do a quick review. And if you stick around, I'm happy to go back and look at any of the other slides that you might have missed something on. OK, so just to recap, we showed that the natural numbers and the real numbers are not the same size using that definition of one-to-one correspondence to introduce the diagonalization method. We used the diagonalization method to show that A,TM is undecidable. We also showed that little theorem that if the language and its complement are recognizable, then the language is decidable. And from that, we concluded that A,TM complement is not recognizable. And then we showed, at least by virtue of an introduction to the method, the reducibility method to show that HALT,TM is undecidable. And that was today's lecture. And we're and we're at the end of the hour. So why don't I-- we are finished. You can log out. And if you want, I will stick around. OK, OK, this is kind of a good question here. So I'm getting a question about the A,TM-complement, which is-- since we have a recognizer for A,TM, if I'm doing justice to this question, we have a recogniser for A,TM, so why can't we just invert the answer? Flip the answer around, and now, we have a recognizer for the complement of A,TM, A,TM-complement. So why doesn't that work? Well, the reason that doesn't work is because the recognizer for A,TM might be rejecting some things by looping. And now, if you just flip the accepting and rejecting, when it hits one of those halting states, it's going to give the reverse answer. But when it rejects by looping, it'll continue to reject by looping. So you won't get the complementary language coming out. So if it would be helpful, I can go back to that slide here, which proves that A,TM-complement is unrecognizable because maybe we should start with the bottom. We know that A,TM is recognizable and undecidable, right? We already proved those two facts. A,TM is recognizable from the universal Turing machine, and it's undecidable by the diagonalization argument. Those two things together tell us that the complement has to be unrecognizable because if a language and its complement are both recognizable-- and we already know the language itself is recognizable. So now, if the complement is also recognizable, the language is going to be decidable by the upper theorem. So it must be the case had either the language itself is unrecognizable, or its complement is unrecognizable. We know the language is recognizable. That's what the universal Turing machine told us. So the only thing left is for the complement to be unrecognizable. You should review that if you didn't get it because this is the kind of reasoning we're going to be building on things like that. So I think it's good to make sure you understand. OK. OK, the diagram on the right-- so this is just a Venn diagram here. I threw this in at the last minute here. I was worried about it being confusing. That part is-- I'm trying to show that the three classes that we've already talked about-- the languages which are decidable, the languages which are Turing-recognizable, and the languages whose complements are Turing-recognizable. Those are three separate classes of languages. And those come up here in those three regions. These are the decidable ones. Here are the recognizable ones. And here are the ones whose complements are recognizable. Now if a language is in both the recognizable, and its complement is recognizable-- so it's in both of these bigger regions here-- then this theorem tells you it's decidable. So that's why the intersection of these two regions is marked as being decidable because that means you're in both. OK? But we know that A,TM is sitting out here as recognizable but not decidable. So A,TM is in the recognizable side, but it's not on the complement of recognizable, A,TM itself. The complement of A,TM is the complement of a recognizable but itself is not recognizable and not decidable. So you got this side of nice, you know-- I hope you think it's nice, but it's sort of a try to summarize things in this little Venn diagram. So I think I'm going to then sign off. And I'll see you all on Tuesday. And have a good weekend. Bye bye.","70.54334259033203","7","DPRSearchEngine","3PzuSPQPEU4.en-j3PyPqV-e1s_8_mp4","3PzuSPQPEU4.en-j3PyPqV-e1s","18.404J","8"
"103","What is the problem with initially attempting to connect the accepting states of M1 to the start state of M2 when constructing a finite automaton for the concatenation of two regular languages?","we can talk about that more over the break. And so we'll return here in five minutes. Somebody's asking about-- can infinite sequences be generated by the machine. When we're talking about, especially in the complexity section of the course, all of the computations are going to be bounded in time. So we're not going to be thinking about infinite runs of the machine. That's not going to be relevant for us. So let's not think about that. How does a Turing machine perform division? How does a Turing machine perform division? Well, how do you perform division? [LAUGHS] Long division is an operation that can run in-- the long division procedure that you learn in grade school, you can implement that on a Turing machine. Yes, a Turing machine can definitely perform-- do long division, or division of one integer by another in polynomial time. Another question. Can we generally say, try dividing y by x? Or do we have to enumerate a string of length y and cross off every-- no. I think that's the same question. I mean, if you have numbers written in binary, how would you do the division? You're not going to use long division. Anything such as the thing that's proposed here by the questioner is going to be an exponential algorithm. So don't do it that way. Why does primes in P-- composites in P not imply primes in P? It does imply. If composites are in P, then primes is in P as well. When you have a deterministic machine, you can flip the answer. When you have a non-deterministic machine, you may not be able to flip the answer. So deterministic machine just having a single branch, you can make another deterministic machine that runs in the same amount of time that does the complementary language. Because for deterministic machines, just like for deciders in the computability section, you can just invert the answer. There is an analogy here between P and decidability, and NP and recognizability. It's not an airtight analogy here, but there is some relationship there. Somebody's asking me, what are the implications of P equal to NP? Lots of implications. Too long to enumerate now. But, for example, you would be able to break basically all cryptosystems that I'm aware of, if P equal to NP. So we would have a lot of consequences. Somebody's asking, so composites-- primality and compositeness testing is solvable in polynomial time. But factoring, interestingly enough, is not known to be solvable in polynomial time. We may talk about this a little bit toward the end of the term if we have time. The algorithms for testing whether a number is prime or composite in polynomial time do not operate by looking for factors. They operate in an entirely different way, basically by showing that a number is prime or composite by looking at certain properties of that number. But without testing whether it has-- testing, but without finding a factor. Another question here about asking when we talk about encodings, do we have to say how we encode numbers, values? No, we don't have to. We usually don't have to get into spelling out encodings, as long as they're reasonable encodings. So you don't have to usually. We're going to be talking about things at a high enough level that the specific encodings are not going to matter. Let's return to the rest of our lecture.","70.47979736328125","8","DPRSearchEngine","1VhnDdQsELo.en-j3PyPqV-e1s_10_mp4","1VhnDdQsELo.en-j3PyPqV-e1s","18.404J","14"
"103","What is the problem with initially attempting to connect the accepting states of M1 to the start state of M2 when constructing a finite automaton for the concatenation of two regular languages?"," 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Finite Automata – Formal Definition 
Defn: A finite automaton ! is a 5-tuple (#, Σ, &, '0, )) 
# finite set of states 
Σ finite set of alphabet symbols 
Example: 
& transition function &: #×Σ → # 
a
& (', .) = 0 means 
'
0 
0
'0 start state 
!1 
1 
0,1 
1
) set of accept states 
'1
'2 
'3 
0 
!1 = (#, Σ, &, '1, )) 
& = 
0
1
# = {'1, '2, '3} 
'1
'1 '2
Σ = {0, 1} 
'2 '1 '3 
) = {'3} 
'3 '3 '3 
7 
","70.47428894042969","9","DPRSearchEngine","b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1_7_pdf","b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1","18.404J","1"
"103","What is the problem with initially attempting to connect the accepting states of M1 to the start state of M2 when constructing a finite automaton for the concatenation of two regular languages?","Here is the automaton we're trying to build. We don't know how it's going to look like yet. And yeah, so kind of getting ahead of myself, but here is a strategy, as I just described, for M. M is going to keep track of which state that M1 is in and which state M2 is in at any given moment. As we're reading the symbols of w, we're going to feed that into M1 and also into M2. And so the possibilities we have to keep track of in M are all the pairs of states that are in M1 and M2, because you're going to really be tracking M1 and M2 simultaneously. So you have to remember which state M1 is in and also which state M2 is in. And so that really corresponds to what pair of states to remember, one from M1 and one from M2, and that's why I've indicated it like that. So M1 is in state q, M2 is in state r at some given point in time. And that's going to correspond to M being in the pair q comma r. That's just the label of this particular state of m that we're going to apply here. OK? And then M is going to accept if either M1 and M2 is an accepting state. So it's going to be if either q or r is an accepting state, we're going to make this into an accepting state too. OK? Whoops. There we go. So let's describe this formally instead of by a picture, because we can do it both ways. And sometimes it's better to do it one way and sometimes the other way. So now if we take-- the components of M now are the pairs of states from M1 and M2. Again, I'm writing this out literally, explicitly here, but you should make sure you're comfortable with this cross product notation. So this is the collection of pairs of states, q1 and q2, where q1 is in the state of the first machine, q2 is the state of the second machine. The start state is you start at the two start states of the two machines. So this is q1, q2-- probably I should have not reused the Q notation. I should have called these r's-- now that I'm looking at that. But, anyway, I hope you're not confused by reusing this. q1 and q2 here are the specific start states of the two machines. These are just two other states, representative states of those machines. Now, the transition function for the new machine is going to be built out of the transition functions from the previous machines. So when I have a pair, q, r, and I have the symbol a, where do we go? Which new pair do we get? Well, we just update the state from M1 and update the state from M2 according to their respective transition functions, and that's what's shown over here. Now let's take a look at the accepting states for M. The natural thing to do is look at the set of pairs of states, where we have a pair of states-- a pair of accepting states, one from the first machine and one from the second machine. But if you're thinking with me, you realize that this is not the right thing. What is DFAs? Did I would call them DFA somewhere? Oh, somebody else is probably doing that in the chat. The DFA-- careful what notation you're using. We haven't introduced DFAs yet. We'll do that next on Thursday. But these are DFAs. These are just finite automata, Deterministic Finite Automata. That's why the D. Anyway, so this is actually not right, because if you think about what this is saying, it says that both components have to be accepting. And you want either one to be accepting. So this is not good. This would be the wrong way of defining it. That actually gives the intersection language. And really, kind of along the way, it's proving closure under intersection, which we don't care about but might be useful to have in our back pocket sometime in the future. In order to get closure under a union, we have to write it this slightly more complicated looking way, which says the pair, what you want to have is either the first state is an accepting state and then any state for the second element, or any state for the first element and an accepting state for the second element. That's what it means to have the union, to be doing the union. OK? So let's do-- oh, here's a quick check-in. So let's do another poll here. We thought we were done with these. Again-- oh, here we go. So it was too complicated to write it out in the polls, so I actually put it up on the slide for you. So all I'm asking is that if M1 has k1 states and M2 has k2 states, how many states does M have? Is it the sum, the sum of the squares, or the product? OK, you have to think about the states of M, what do they look like? And come on, guys. All right, ending the poll, sharing results. Yes, indeed, it is-- most of you got it correct. It is C, the product. Because when you look at the number of pairs of states from M1 and M2, you need all possible pairs. And so it's the number of states in M1 times the number of states in M2. So make sure you understand that and think about that so that you're following and get this.","70.25818634033203","10","DPRSearchEngine","9syvZr-9xwk.en-j3PyPqV-e1s_12_mp4","9syvZr-9xwk.en-j3PyPqV-e1s","18.404J","1"
"104","What is a rejecting computation history?","It's going to help me in the coming slides because they're a little bit dense. When I'm going to draw this sort of reddish, pinkish box around something, that means that I'm going to try to describe all strings except for that one. I want to avoid describing that one, because that's the rejecting computation history, but I want to describe everything else. That's my wish. So here's a check in before we move forward. But we can also-- maybe we should just take some questions, even before we launch the check in. How are we doing here? So, is our one describing-- well, R1 is a regular expression. Over here, we're talking about a-- this is just an ordinary computation history, but it ends with a reject. That's all. A rejecting computation history is just one that's a little different at the end. The machine just ended up rejecting instead of accepting. Otherwise everything has to be spelled out in accordance with the rules of the machine and the start configuration. Yeah, we were assuming one rejecting state. Yeah, that's the way we actually define Turing machines in the first place. But, who's arguing. Yeah, there's one reject state. We're all deterministic, correct. Why do we need the padding? Because I want to make these all the same size, all of these configurations. That's going to help me later in terms of describing the invalid configurations, the ones that are not legal configurations, legal rejecting configurations. So just simply a matter of convenience, but just accept it for now. I just want all of those configurations to be the same length in my rejecting computation history. Otherwise I'm not going to-- I'm just coding that rejecting computation history in this particular way. So people are asking about the details of bad start. That's yet to come. I have two more slides on this. So I'll tell you about how we're going to do those. So R bad-start-- that's a good question-- is R bad-start all-- these are all the strings that don't start this way. We'll see it in a second. But R bad-start are all the things that don't start with the-- they start bad. They're not starting with the start configuration. They're starting with some other junk. Do we need only one rejecting computation history? What about the other ones? This is a deterministic machine, so there's only going to be-- if I prescribe the lengths as I've done, there's going to be only one rejecting computation history. Because it's deterministic, everything is going to be forced from the beginning. Should R1 be the not of those three? No. R1 is describing all of the strings except, except this one string. So I'm capturing all the different possible ways a string could fail to be the string. It could start wrong. Could be wrong along the middle somewhere. So I have to union them together. Because I'm describing-- as I always believe, negations are the most confusing thing to everybody, including me. So we're describing all the things that are not this string. We're trying to stay away from that one. We want to describe everything else. All right, I think I'd better move on here. We've got a lot of questions. Talk to the TAs. All right, check in. How big is this rejecting computation history anyway? Interesting. There's a lesson here. I got a big burst of answers right at the very beginning. All wrong. But then the bright-- the people who took a little bit more time to think started getting the right answer, which is-- let's look. We've got a close election here folks, so now I have to report. Hope we don't have to do a recount. OK, come on guys. Answer up. 10 seconds. This is not super hard. Stop the count. Yeah, I think we'd better stop at this, we're on the edge. OK, 3 seconds. End polling. Share results. The correct answer is, in fact, c. Why is that? Because each configuration is 2 to the n to the k. So that's how much space the machine has, exponential space. But the amount of time, which is each one-- the number of configurations is going to be the amount of time that's used. It's going to be exponentially more even than that. So it's going to be 2 to the 2 to the n of the k, is how many steps the machine can run. And that's going to be how long the computation history could be. So it's a very long thing. And when you think about it, the regular expression we are generating, how big is that? The regular expression-- again, a lot of people playing off my comments here. Were the votes legal or not? OK. Let's focus here. So this is doubly exponentially large. How big is the regular expression that we're generating? Well that has to be produced in polynomial time, so it's only polynomially big. So we have this little teensy weensy, relatively speaking, regular expression, which is only n to the k. It's having to describe all strings except for this particular string, which is 2 to the 2 to the n to the k. So in a sense, this string that is related to that regular expression is doubly exponentially larger than that. And that kind of presents some of the challenge in doing the reduction, in constructing that regular expression.","72.85456848144531","1","DPRSearchEngine","N32bnUliSzo.en-j3PyPqV-e1s_6_mp4","N32bnUliSzo.en-j3PyPqV-e1s","18.404J","22"
"104","What is a rejecting computation history?"," 
 
 
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
  
 
  
 
  
 
 
  
 
 
   
 
 
   
 
 
 
 
TMs and Encodings – review 
A TM has 3 possible outcomes for each input !: 
1. Accept ! (enter ""acc ) 
2. Reject ! by halting (enter ""rej ) 
3. Reject ! by looping (running forever) 
( is T-recognizable if ( = *(,) for some TM ,. 
( is T-decidable if ( = *(,) for some TM decider ,. 
halts on all inputs 
〈/0, /2, … , /4〉 encodes objects /0, /2, … , /4 as a single string. 
Notation for writing a TM , is 
, = “On input ! 
[English description of the algorithm]” 
2 
","72.16239166259766","2","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_2_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"104","What is a rejecting computation history?"," 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
   
 
 
 
 
   
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
  
 
 
  
 
  
 
  
Turing machine model – review 
head 
˽ ˽ . . .
a
b
a
b
b
Finite 
read/write input tape 
control 
On input ! a TM "" may halt (enter #acc or #rej) 
) is T-recognizable if ) = +("") for some TM "". 
or loop (run forever). 
) is T-decidable if ) = +("") for some TM decider "". 
So "" has 3 possible outcomes for each input !: 
halts on all inputs 
1. Accept ! (enter #acc ) 
Turing machines model general-purpose computation. 
2. Reject ! by halting (enter #rej ) 
Q: Why pick this model? 
3. Reject ! by looping (running forever) 
A: Choice of model doesn't matter. 
All reasonable models are equivalent in power. 
Virtues of TMs: simplicity, familiarity. 
2 
","71.30604553222656","3","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_2_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"104","What is a rejecting computation history?","Now let's look at what the transition function, how that operates. So the transition function, remember, tells how the machine is actually doing its computation. And it says that, if you're in a certain state and the head is looking at a certain tape symbol, then you can go to a new state. You write a new symbol at that location on the tape. And you can move the head either left or right. So that's how we get the effect of the head being able to be bi-directional. And here is the writing on the tape. It comes up right here. So just an example here which says that, if we're in state two and the head is looking at an a currently on the tape, then we can move the state r. We change that a to a b. And we move the head right 1 square. Now, this is important. When you give a certain input here to the Turing machine, it may compute around for a while, moving its head back and forth, as we were showing. And it may eventually halt by either entering the q accept state or the q reject state, which I didn't bring out here, but that's important. These are the accepting, rejecting, special states of the machine. Or the machine may never enter one of those. It may just go on, and on, and on and never halt. We call that looping, a little bit of a misnomer, because looping implies some sort of a repetition. For us, looping just means not halting. And so therefore, M has three possible outcomes for each input, this w. It might accept w by entering the accept state. It could reject w by entering the reject state, which means it's going to reject it by halting. Or we also say we can reject by looping. You can reject the string by running forever. That's just the terminology that's common in the subject. So you either accept it by halting and accepting or rejecting it by either halting and rejecting or by just going forever. That's also considered to be rejecting, sort of rejecting in a sense by default. If you never actually have accepted it, then it's going to be rejected. OK, check in three here-- all right, so now our last check in for the day, we say, this Turing machine model is deterministic. I'm just saying that. But if you look at the way we set it up, if you've been following the formal definition so far, you would understand why it's deterministic. So let's just, as a way of checking that, how would we change this definition? Because we will look at the next lecture at non-deterministic Turing machines. So a little bit of a lead in to that, how would we change this definition to make it a non-deterministic Turing machine? Which of those three options would we use? So here, I'll launch that poll. I've got about 10 people left. Let's give them another 10 seconds. OK, I think that's everybody who has answered it from before. So here, I think you pretty much almost all of you got the right idea. It is B, in fact, because when we have the power set symbol here, that means there might be several-- there is a subset of possibilities. So that indicates several different ways to go. And that's the essence of non-determinism. OK, so I think we're-- whoops. All right, so look, this is also kind of setting us up for next lecture and where we're going to be going with this. So these are basically two in a-- well, two or three important definitions here. One is-- we talked about the regular languages from finite automata. We talked about the context-free languages from the grammars and the pushdown automata. What are the languages that the Turing machines can do? Those are called, in this course, anyway, Turing-recognizable languages, or T recognizable. Those are the languages that the Turing machine can recognize. And so just to make sure we were on the same page on this, the language of the machine is the collection of strings that the machine accepts. So the things that are not in the language are the things that are rejected either by looping or by halting and rejecting. So only the ones that are accepted is the language. Every machine has just a single language. It's the language of all strings that that machine accepts. And we'll say that and recognize that language, if that language is the collection of such strings that are accepted. And we will call that language a Turing-recognizable language, if there is some Turing machine that can recognize it. Now, this feature of being able to reject by running forever is a little bit weird, perhaps. And from the standpoint of practicality, it's more convenient if the machine always makes a decision to accept or reject in finite time and doesn't just reject by going forever. And so we're going to bring out a special class of Turing machines that have that feature, that they always halt. The halting states, by the way-- maybe it didn't say this explicitly-- are the q accept and the q reject states. The accept and reject states are the halting states. So if the machine halts, that means it ends up in one of those two. So it has made a decision of accepting or rejecting at the point at which it has halted. So we'll say a machine is a decider if it always halts on every input. So for every w fed in, the machine is eventually going to come to a q accept or a q reject. We call such a machine a decider. And now we're going to say, a language is-- so we'll say that the machine decides a language if it's the language of the machine, so the collection of accepted strings, and the machine is the decider. We'll say that, instead of just recognizing the language, we'll say that it decides the language. And the Turing-decidable language is a language that the machine-- of all strings the machine accepts for some Turing machine which is a decider, which is a Turing machine that always halts. So if a Turing machine may sometimes reject by looping, then it's only recognizing its language. If the Turing machine is always halting, so it's always rejecting by explicitly coming to a reject state and halting, then we'll say it's actually deciding the language. So then, in a sense, that's better. And we're going to distinguish between those two, because they're not the same. There are some languages which can be recognized, but not decided. And so in fact, we're going to get the following picture here, that the Turing-recognizable languages are a proper subset. They include all of-- everything that's decidable, certainly is going to be recognizable, because being a decider is an additional restriction to impose, an additional requirement. So everything that's decidable is going to be automatically recognizable. But there are things which are recognizable which are not decidable, as we'll see. I'll actually give an example of that, but not prove it next lecture. And just for, just to complete out this picture, I'm going to also point out-- we haven't proven this yet, but we will prove it-- that the decidable languages also include all the context-free languages, which, in turn, include the regular languages, as was already seen. So we haven't shown this inclusion yet. But actually, this is the picture that we get. So there is actually a hierarchy of containments here. Regular languages are a subset of the context-free languages, which are, in turn, a subset of the decidable languages, which in turn, are a subset of the Turing-recognizable languages.","71.19535064697266","4","DPRSearchEngine","IycOPFmEQk8.en-j3PyPqV-e1s_15_mp4","IycOPFmEQk8.en-j3PyPqV-e1s","18.404J","5"
"104","What is a rejecting computation history?"," 
 
 
  
  
 
 
  
 
  
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Emptiness Problem for DFAs 
Let !DFA = & & is a DFA and ' & = ∅} 
Theorem: !DFA is decidable 
Proof: Give TM *E−DFA that decides !DFA . 
*E−DFA = “On input & 
[IDEA: Check for a path from start to accept.] 
1. 
Mark start state. 
2. 
Repeat until no new state is marked: 
Mark every state that has an incoming arrow 
from a previously marked state. 
3. 
Accept if no accept state is marked. 
Reject if some accept state is marked.” 
5 
","70.70451354980469","5","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_5_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"104","What is a rejecting computation history?"," 
 
 
  
  
 
 
 
  
 
 
  
  
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
Acceptance Problem for TMs 
Let !TM = { &, ( | & is a TM and & accepts (} 
Theorem: !TM is not decidable 
Proof: Thursday. 
Theorem: !TM is T-recognizable 
Proof: The following TM + recognizes !TM 
+ = “On input &, ( 
Turing’s original “Universal Computing Machine” 
1. 
Simulate & on input (. 
2. 
Accept if & halts and accepts. 
Description of &, input ( 
3. 
Reject if & halts and rejects. 
+ 
4. 
Reject if & never halts.” 
Not a legal TM action. 
Von Neumann said + inspired the concept of a stored program computer. 
10 
","70.1468505859375","6","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_10_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"104","What is a rejecting computation history?","  
 
  
 
 
  
 
  
 
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
  
 
 
   
-
Review: Probabilistic TMs and BPP 
coin flip step 
each choice has 
Defn: A probabilistic Turing machine (PTM) is a variant of a NTM 
where each computation step has 1 or 2 possible choices. 
deterministic 
step 
50% probability 
Defn: For ! ≥0 say PTM $  decides language % with error probability !  
if for every &, Pr[ $  gives the wrong answer about & ∈% ] ≤! . 
Defn: BPP = % some poly-time PTM decides % with error !  = +⁄,  } Check-in 24.1 
Actually using a probabilistic algorithm 
Amplification lemma: 2−. /01 2 
presupposes a source of randomness. 
Can we use a standard pseudo-random 
number generator (PRG) as the source? 
& ∈% 
& ∉% 
(a) Yes, but the result isn’t guaranteed.
(b) Yes, but it will run in exponential time.
Many 
Few 
Few 
Many 
(c) No, a TM cannot implement a PRG. 
accepting 
rejecting 
accepting 
rejecting 
(d) No, because that would show P = BPP.
2 
Check-in 24.1 
","70.06214141845703","7","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_2_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"104","What is a rejecting computation history?"," 
 
 
 
  
 
 
 
 
  
   
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
          
 
 
  
  
   
 
 
 
 
  
 
 
 
  
 
 
Nondeterminism doesn’t
correspond to a physical machine
we can build. However, it is useful
mathematically.
accept
reject
accept
reject
Nondeterministic Finite Automata 
a 
a
!1 
b 
a,ε 
#1
#2 
#3 
#4 
b 
New features of nondeterminism: 
- multiple paths possible (0, 1 or many at each step) 
- ε-transition is a “free” move without reading input 
- Accept input if some path leads to 
accept 
Check-in 2.1 
Example inputs: 
What does !' do on input aab ? 
- ab 
- aa 
(a) Accept 
- aba 
(b) Reject 
- abb 
(c) Both Accept and Reject 
Check-in 2.1 
4 
","69.31443786621094","8","DPRSearchEngine","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_4_pdf","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2","18.404J","2"
"104","What is a rejecting computation history?"," 
 
 
 
 
 
  
  
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
  
Acceptance Problem for DFAs 
Let $DFA = !, # ! is a DFA and ! accepts #} 
Theorem: $DFA is decidable 
Proof: Give TM *A−DFA that decides $DFA . 
*A−DFA = “On input , 
Shorthand: 
1. 
Check that , has the form !, # where 
if not. 
On input !, # 
! is a DFA and # is a string; reject 
2. 
Simulate the computation of ! on #. 
3. 
If ! ends in an accept state then accept. 
If not then reject.” 
input tape contains !, # 
- = ./, … , .1 , Σ = 0,1 , 5 = ⋯, ./, 7 = ⋯ , # = 01101
*A−DFA 
! 
# 
.8 , 9 
work tape with current state and input head location 
3 
","69.30538940429688","9","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_3_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"104","What is a rejecting computation history?","All right, acceptance problem for Turing Machines. So just as I mentioned, we showed that A,TM, which is the language of Turing machines and inputs where the machine accepts the input. We showed that was recognizable. We claimed it was decidable. Today, we're going to prove it's not decidable. All right, now the method that we're going to use, which is really the only method out there for proving a problem as undecidable is called the diagonalization method. I mean, ultimately, we're going to show the reducibility method as well. But it really depends on having already shown some other problem undecidable via the diagonalization method. So ultimately, everything hinges on the diagonalization method, which is really what we have.","69.26631927490234","10","DPRSearchEngine","3PzuSPQPEU4.en-j3PyPqV-e1s_3_mp4","3PzuSPQPEU4.en-j3PyPqV-e1s","18.404J","8"
"105","Why is padding needed in rejecting computation histories?"," 
 
 
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
  
 
  
 
  
 
 
  
 
 
   
 
 
   
 
 
 
 
TMs and Encodings – review 
A TM has 3 possible outcomes for each input !: 
1. Accept ! (enter ""acc ) 
2. Reject ! by halting (enter ""rej ) 
3. Reject ! by looping (running forever) 
( is T-recognizable if ( = *(,) for some TM ,. 
( is T-decidable if ( = *(,) for some TM decider ,. 
halts on all inputs 
〈/0, /2, … , /4〉 encodes objects /0, /2, … , /4 as a single string. 
Notation for writing a TM , is 
, = “On input ! 
[English description of the algorithm]” 
2 
","71.58274841308594","1","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_2_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"105","Why is padding needed in rejecting computation histories?"," 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
   
 
    
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
Linearly Bounded Automata 
Defn: A linearly bounded automaton (LBA) is a 1-tape TM 
that cannot move its head off the input portion of the tape. 
LBA 
a a b a a b a 
Tape size adjusts to length of input. 
Let !LBA = &, ( LBA & accepts ( } 
Theorem:  !LBA is decidable 
Proof: (idea) If & on ( runs for long, it must be cycling. 
Decider for !LBA: 
Claim: For inputs of length ), an LBA can have 
.A−LBA = “On input &, ( 
only * ×)× Γ - different configurations. 
1.  Let ) = |(|. 
Therefore, if an LBA runs for longer, it must repeat some 
2. Run & on ( for * ×)× Γ - steps. 
configuration and thus will never halt. 
3. If has accepted, accept. 
4. If it has rejected or is still running, reject.” 
must be looping 
7 
","69.41604614257812","2","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_7_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"105","Why is padding needed in rejecting computation histories?","It's going to help me in the coming slides because they're a little bit dense. When I'm going to draw this sort of reddish, pinkish box around something, that means that I'm going to try to describe all strings except for that one. I want to avoid describing that one, because that's the rejecting computation history, but I want to describe everything else. That's my wish. So here's a check in before we move forward. But we can also-- maybe we should just take some questions, even before we launch the check in. How are we doing here? So, is our one describing-- well, R1 is a regular expression. Over here, we're talking about a-- this is just an ordinary computation history, but it ends with a reject. That's all. A rejecting computation history is just one that's a little different at the end. The machine just ended up rejecting instead of accepting. Otherwise everything has to be spelled out in accordance with the rules of the machine and the start configuration. Yeah, we were assuming one rejecting state. Yeah, that's the way we actually define Turing machines in the first place. But, who's arguing. Yeah, there's one reject state. We're all deterministic, correct. Why do we need the padding? Because I want to make these all the same size, all of these configurations. That's going to help me later in terms of describing the invalid configurations, the ones that are not legal configurations, legal rejecting configurations. So just simply a matter of convenience, but just accept it for now. I just want all of those configurations to be the same length in my rejecting computation history. Otherwise I'm not going to-- I'm just coding that rejecting computation history in this particular way. So people are asking about the details of bad start. That's yet to come. I have two more slides on this. So I'll tell you about how we're going to do those. So R bad-start-- that's a good question-- is R bad-start all-- these are all the strings that don't start this way. We'll see it in a second. But R bad-start are all the things that don't start with the-- they start bad. They're not starting with the start configuration. They're starting with some other junk. Do we need only one rejecting computation history? What about the other ones? This is a deterministic machine, so there's only going to be-- if I prescribe the lengths as I've done, there's going to be only one rejecting computation history. Because it's deterministic, everything is going to be forced from the beginning. Should R1 be the not of those three? No. R1 is describing all of the strings except, except this one string. So I'm capturing all the different possible ways a string could fail to be the string. It could start wrong. Could be wrong along the middle somewhere. So I have to union them together. Because I'm describing-- as I always believe, negations are the most confusing thing to everybody, including me. So we're describing all the things that are not this string. We're trying to stay away from that one. We want to describe everything else. All right, I think I'd better move on here. We've got a lot of questions. Talk to the TAs. All right, check in. How big is this rejecting computation history anyway? Interesting. There's a lesson here. I got a big burst of answers right at the very beginning. All wrong. But then the bright-- the people who took a little bit more time to think started getting the right answer, which is-- let's look. We've got a close election here folks, so now I have to report. Hope we don't have to do a recount. OK, come on guys. Answer up. 10 seconds. This is not super hard. Stop the count. Yeah, I think we'd better stop at this, we're on the edge. OK, 3 seconds. End polling. Share results. The correct answer is, in fact, c. Why is that? Because each configuration is 2 to the n to the k. So that's how much space the machine has, exponential space. But the amount of time, which is each one-- the number of configurations is going to be the amount of time that's used. It's going to be exponentially more even than that. So it's going to be 2 to the 2 to the n of the k, is how many steps the machine can run. And that's going to be how long the computation history could be. So it's a very long thing. And when you think about it, the regular expression we are generating, how big is that? The regular expression-- again, a lot of people playing off my comments here. Were the votes legal or not? OK. Let's focus here. So this is doubly exponentially large. How big is the regular expression that we're generating? Well that has to be produced in polynomial time, so it's only polynomially big. So we have this little teensy weensy, relatively speaking, regular expression, which is only n to the k. It's having to describe all strings except for this particular string, which is 2 to the 2 to the n to the k. So in a sense, this string that is related to that regular expression is doubly exponentially larger than that. And that kind of presents some of the challenge in doing the reduction, in constructing that regular expression.","69.21617126464844","3","DPRSearchEngine","N32bnUliSzo.en-j3PyPqV-e1s_6_mp4","N32bnUliSzo.en-j3PyPqV-e1s","18.404J","22"
"105","Why is padding needed in rejecting computation histories?"," 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
   
 
 
 
 
   
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
  
 
 
  
 
  
 
  
Turing machine model – review 
head 
˽ ˽ . . .
a
b
a
b
b
Finite 
read/write input tape 
control 
On input ! a TM "" may halt (enter #acc or #rej) 
) is T-recognizable if ) = +("") for some TM "". 
or loop (run forever). 
) is T-decidable if ) = +("") for some TM decider "". 
So "" has 3 possible outcomes for each input !: 
halts on all inputs 
1. Accept ! (enter #acc ) 
Turing machines model general-purpose computation. 
2. Reject ! by halting (enter #rej ) 
Q: Why pick this model? 
3. Reject ! by looping (running forever) 
A: Choice of model doesn't matter. 
All reasonable models are equivalent in power. 
Virtues of TMs: simplicity, familiarity. 
2 
","68.06632995605469","4","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_2_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"105","Why is padding needed in rejecting computation histories?"," 
 
  
  
  
 
 
  
       
   
 
 
 
 
 
 
  
 
 
 
  
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
  
 
 
 
  
 
 
   
 
 
   
 
 
 
 
   
 
 
 
 
 
 
 
 
    
 
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
  
 
TM – Formal Definition 
Defn: A Turing Machine (TM) is a 7-tuple ("", Σ, Γ, &, '(, 'acc , 'rej)
Σ input alphabet 
Γ tape alphabet (Σ ⊆Γ)
&: Q×Γ → ""×Γ× {L, R} 
(L = Left, R = Right) 
& ', a = (5, b, R) 
On input 6 a TM 7 may halt (enter 'acc or 'rej) 
Check-in 5.3 
or 7 may run forever (“loop”). 
This Turing machine model is deterministic. 
So 7 has 3 possible outcomes for each input 6: 
How would we change it to be nondeterministic? 
1. Accept 6 (enter 'acc ) 
a) Add a second transition function. 
2. Reject 6 by halting (enter 'rej ) 
b) Change & to be &: Q×Γ → 8( ""×Γ× {L, R} ) 
3. Reject 6 by looping (running forever) 
c) Change the tape alphabet Γ to be infinite. 
10 
Check-in 5.3 
","67.04441833496094","5","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_10_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"105","Why is padding needed in rejecting computation histories?","TM – example revisited 
TM ! recognizing  "" = a$b$c$
% ≥0
! = “On input (
1.  Check if ( ∈a∗b∗c∗,  reject if not.
2.  Count the number of a’s, b’s, and c’s in (.
3.  Accept if all counts are equal; reject if not.”
High-level description is ok.  
You do not need to manage tapes, states, etc… 
9
","66.98715209960938","6","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_9_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"105","Why is padding needed in rejecting computation histories?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","66.91967010498047","7","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"105","Why is padding needed in rejecting computation histories?"," 
 
 
 
  
 
 
 
 
  
   
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
          
 
 
  
  
   
 
 
 
 
  
 
 
 
  
 
 
Nondeterminism doesn’t
correspond to a physical machine
we can build. However, it is useful
mathematically.
accept
reject
accept
reject
Nondeterministic Finite Automata 
a 
a
!1 
b 
a,ε 
#1
#2 
#3 
#4 
b 
New features of nondeterminism: 
- multiple paths possible (0, 1 or many at each step) 
- ε-transition is a “free” move without reading input 
- Accept input if some path leads to 
accept 
Check-in 2.1 
Example inputs: 
What does !' do on input aab ? 
- ab 
- aa 
(a) Accept 
- aba 
(b) Reject 
- abb 
(c) Both Accept and Reject 
Check-in 2.1 
4 
","66.75086212158203","8","DPRSearchEngine","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_4_pdf","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2","18.404J","2"
"105","Why is padding needed in rejecting computation histories?","Now let's look at what the transition function, how that operates. So the transition function, remember, tells how the machine is actually doing its computation. And it says that, if you're in a certain state and the head is looking at a certain tape symbol, then you can go to a new state. You write a new symbol at that location on the tape. And you can move the head either left or right. So that's how we get the effect of the head being able to be bi-directional. And here is the writing on the tape. It comes up right here. So just an example here which says that, if we're in state two and the head is looking at an a currently on the tape, then we can move the state r. We change that a to a b. And we move the head right 1 square. Now, this is important. When you give a certain input here to the Turing machine, it may compute around for a while, moving its head back and forth, as we were showing. And it may eventually halt by either entering the q accept state or the q reject state, which I didn't bring out here, but that's important. These are the accepting, rejecting, special states of the machine. Or the machine may never enter one of those. It may just go on, and on, and on and never halt. We call that looping, a little bit of a misnomer, because looping implies some sort of a repetition. For us, looping just means not halting. And so therefore, M has three possible outcomes for each input, this w. It might accept w by entering the accept state. It could reject w by entering the reject state, which means it's going to reject it by halting. Or we also say we can reject by looping. You can reject the string by running forever. That's just the terminology that's common in the subject. So you either accept it by halting and accepting or rejecting it by either halting and rejecting or by just going forever. That's also considered to be rejecting, sort of rejecting in a sense by default. If you never actually have accepted it, then it's going to be rejected. OK, check in three here-- all right, so now our last check in for the day, we say, this Turing machine model is deterministic. I'm just saying that. But if you look at the way we set it up, if you've been following the formal definition so far, you would understand why it's deterministic. So let's just, as a way of checking that, how would we change this definition? Because we will look at the next lecture at non-deterministic Turing machines. So a little bit of a lead in to that, how would we change this definition to make it a non-deterministic Turing machine? Which of those three options would we use? So here, I'll launch that poll. I've got about 10 people left. Let's give them another 10 seconds. OK, I think that's everybody who has answered it from before. So here, I think you pretty much almost all of you got the right idea. It is B, in fact, because when we have the power set symbol here, that means there might be several-- there is a subset of possibilities. So that indicates several different ways to go. And that's the essence of non-determinism. OK, so I think we're-- whoops. All right, so look, this is also kind of setting us up for next lecture and where we're going to be going with this. So these are basically two in a-- well, two or three important definitions here. One is-- we talked about the regular languages from finite automata. We talked about the context-free languages from the grammars and the pushdown automata. What are the languages that the Turing machines can do? Those are called, in this course, anyway, Turing-recognizable languages, or T recognizable. Those are the languages that the Turing machine can recognize. And so just to make sure we were on the same page on this, the language of the machine is the collection of strings that the machine accepts. So the things that are not in the language are the things that are rejected either by looping or by halting and rejecting. So only the ones that are accepted is the language. Every machine has just a single language. It's the language of all strings that that machine accepts. And we'll say that and recognize that language, if that language is the collection of such strings that are accepted. And we will call that language a Turing-recognizable language, if there is some Turing machine that can recognize it. Now, this feature of being able to reject by running forever is a little bit weird, perhaps. And from the standpoint of practicality, it's more convenient if the machine always makes a decision to accept or reject in finite time and doesn't just reject by going forever. And so we're going to bring out a special class of Turing machines that have that feature, that they always halt. The halting states, by the way-- maybe it didn't say this explicitly-- are the q accept and the q reject states. The accept and reject states are the halting states. So if the machine halts, that means it ends up in one of those two. So it has made a decision of accepting or rejecting at the point at which it has halted. So we'll say a machine is a decider if it always halts on every input. So for every w fed in, the machine is eventually going to come to a q accept or a q reject. We call such a machine a decider. And now we're going to say, a language is-- so we'll say that the machine decides a language if it's the language of the machine, so the collection of accepted strings, and the machine is the decider. We'll say that, instead of just recognizing the language, we'll say that it decides the language. And the Turing-decidable language is a language that the machine-- of all strings the machine accepts for some Turing machine which is a decider, which is a Turing machine that always halts. So if a Turing machine may sometimes reject by looping, then it's only recognizing its language. If the Turing machine is always halting, so it's always rejecting by explicitly coming to a reject state and halting, then we'll say it's actually deciding the language. So then, in a sense, that's better. And we're going to distinguish between those two, because they're not the same. There are some languages which can be recognized, but not decided. And so in fact, we're going to get the following picture here, that the Turing-recognizable languages are a proper subset. They include all of-- everything that's decidable, certainly is going to be recognizable, because being a decider is an additional restriction to impose, an additional requirement. So everything that's decidable is going to be automatically recognizable. But there are things which are recognizable which are not decidable, as we'll see. I'll actually give an example of that, but not prove it next lecture. And just for, just to complete out this picture, I'm going to also point out-- we haven't proven this yet, but we will prove it-- that the decidable languages also include all the context-free languages, which, in turn, include the regular languages, as was already seen. So we haven't shown this inclusion yet. But actually, this is the picture that we get. So there is actually a hierarchy of containments here. Regular languages are a subset of the context-free languages, which are, in turn, a subset of the decidable languages, which in turn, are a subset of the Turing-recognizable languages.","66.70352935791016","9","DPRSearchEngine","IycOPFmEQk8.en-j3PyPqV-e1s_15_mp4","IycOPFmEQk8.en-j3PyPqV-e1s","18.404J","5"
"105","Why is padding needed in rejecting computation histories?","All right, acceptance problem for Turing Machines. So just as I mentioned, we showed that A,TM, which is the language of Turing machines and inputs where the machine accepts the input. We showed that was recognizable. We claimed it was decidable. Today, we're going to prove it's not decidable. All right, now the method that we're going to use, which is really the only method out there for proving a problem as undecidable is called the diagonalization method. I mean, ultimately, we're going to show the reducibility method as well. But it really depends on having already shown some other problem undecidable via the diagonalization method. So ultimately, everything hinges on the diagonalization method, which is really what we have.","66.69896697998047","10","DPRSearchEngine","3PzuSPQPEU4.en-j3PyPqV-e1s_3_mp4","3PzuSPQPEU4.en-j3PyPqV-e1s","18.404J","8"
"106","What is R bad-start?",")%%%$
""
!1%%)$""$
""
%%""
+%%$""""%)
""%%""
&(""""!
""+%)""%
87	&

	

'
","64.15089416503906","1","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_15_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"106","What is R bad-start?"," L.)&
M&)-'
! 0&'&7):

! 0&''-&7)P:

!  ('
! A0-'""'P* )

 +5
! D  2.;O
! D'&'O
! D)&O
.	
	 
	

RU
","63.054840087890625","2","DPRSearchEngine","4c4fc506075a8502ccc5191583d22882_MIT6_0002F16_lec11_46_pdf","4c4fc506075a8502ccc5191583d22882_MIT6_0002F16_lec11","6.0002","11"
"106","What is R bad-start?"," ' *&)
'&&'
! 6 )""
.('*0
!  & ))*
-')*
 	&&^
 	&'')-'
^
 L'-'&'""
02'
 L'-'&.""0
)'
) 
	

9S
","62.91079330444336","3","DPRSearchEngine","4c4fc506075a8502ccc5191583d22882_MIT6_0002F16_lec11_55_pdf","4c4fc506075a8502ccc5191583d22882_MIT6_0002F16_lec11","6.0002","11"
"106","What is R bad-start?","/3112&('
""CD'DC
	

#
","62.07836151123047","4","DPRSearchEngine","3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7_23_pdf","3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7","6.0002","7"
"106","What is R bad-start?","
!$ !""("""",&""%$&
 3$'$)"""".,#/
W */
W ""/
W 10#$)""0*""0#.0*(&"".,#/
 /$)"""".,#/
W .#$)""*.,0#/05))*/
W .#$)""*.*,1(',0#/05))*/
Q>KKKMN
LO
","61.52861022949219","5","DPRSearchEngine","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_14_pdf","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3","6.0002","3"
"106","What is R bad-start?","7*5.(89
def getEst(numNeedles, numTrials):
estimates = []
for t in range(numTrials):
piGuess = throwNeedles(numNeedles)
estimates.append(piGuess)
sDev = stdDev(estimates)
curEst = sum(estimates)/len(estimates)
print('Est. = ' + str(curEst) +\\
', Std. dev. = ' + str(round(sDev, 6))\\
+ ', Needles = ' + str(numNeedles))
return (curEst, sDev)
	

9
","61.247779846191406","6","DPRSearchEngine","3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7_28_pdf","3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7","6.0002","7"
"106","What is R bad-start?","""!1

"",,""%
""$""
/+11$%""
1""$
+%%""%$""+

/+11$%""
1)""""
,*$1 ,
*$1 ,
#5*3	-67

	

&
","61.15150451660156","7","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_13_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"106","What is R bad-start?","	$
	&$	!	 	
	

9
","60.949806213378906","8","DPRSearchEngine","20a7e184a1a2b3c34a5055dc1f1dc066_MIT6_0002F16_lec9_9_pdf","20a7e184a1a2b3c34a5055dc1f1dc066_MIT6_0002F16_lec9","6.0002","9"
"106","What is R bad-start?","	
 
	








	 
	 
!
!
""
""
# $
# $
#%&
'(
'(
'	 
	 '!(""
!'""(
# $'
""'
","60.91664123535156","9","DPRSearchEngine","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_23_pdf","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3","6.0002","3"
"106","What is R bad-start?","	%$6'#%(# &
%	%!&#""

$%'!""' '% """"%""""
#!$,'%""
Q>KKKMN
L
","60.60293197631836","10","DPRSearchEngine","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_1_pdf","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3","6.0002","3"
"107","Why can a deterministic Turing machine only have one rejecting computation history?"," 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
   
 
 
 
 
   
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
  
 
 
  
 
  
 
  
Turing machine model – review 
head 
˽ ˽ . . .
a
b
a
b
b
Finite 
read/write input tape 
control 
On input ! a TM "" may halt (enter #acc or #rej) 
) is T-recognizable if ) = +("") for some TM "". 
or loop (run forever). 
) is T-decidable if ) = +("") for some TM decider "". 
So "" has 3 possible outcomes for each input !: 
halts on all inputs 
1. Accept ! (enter #acc ) 
Turing machines model general-purpose computation. 
2. Reject ! by halting (enter #rej ) 
Q: Why pick this model? 
3. Reject ! by looping (running forever) 
A: Choice of model doesn't matter. 
All reasonable models are equivalent in power. 
Virtues of TMs: simplicity, familiarity. 
2 
","81.76285552978516","1","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_2_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"107","Why can a deterministic Turing machine only have one rejecting computation history?"," 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Turing Machines (TMs) 
head 
˽ ˽
a
b
a 
. . .
b b
Finite 
read/write input tape 
control 
1) Head can read and write 
2) Head is two way (can move left or right) 
3) Tape is infinite (to the right) 
4) Infinitely many blanks “˽“ follow input 
5) Can accept or reject any time (not only at end of input) 
8 
","79.8115234375","2","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_8_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"107","Why can a deterministic Turing machine only have one rejecting computation history?"," 
 
 
 
 
  
 
 
 
 
 
 
  
 
   
 
 
 
 
 
 
    
       
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Nondeterministic Turing machines 
A Nondeterministic TM (NTM) is similar to a Deterministic TM 
except for its transition function !: Q×Γ → '( )×Γ× {L, R} ). 
Theorem: + is T-recognizable iff some NTM recognizes + 
Proof: (→) immediate. 
(←) convert NTM to Deterministic TM. 
Deterministic TM 
NTM 
. 
a a b a ˽ ˽ 
-
02 a a b a # 01 c b # 03 b c b ˽ ˽ 
Nondeterministic computation tree 
- simulates . by storing each thread’s tape in a 
for . on input /. 
separate “block” on its tape. 
Also need to store the head location, 
and the state for each thread, in the block. 
If a thread forks, then - copies the block. 
If a thread accepts then - accepts. 
accept 
4 
. . . 
","79.80597686767578","3","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_4_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"107","Why can a deterministic Turing machine only have one rejecting computation history?","  
 
  
 
 
  
 
  
 
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
  
 
 
   
-
Review: Probabilistic TMs and BPP 
coin flip step 
each choice has 
Defn: A probabilistic Turing machine (PTM) is a variant of a NTM 
where each computation step has 1 or 2 possible choices. 
deterministic 
step 
50% probability 
Defn: For ! ≥0 say PTM $  decides language % with error probability !  
if for every &, Pr[ $  gives the wrong answer about & ∈% ] ≤! . 
Defn: BPP = % some poly-time PTM decides % with error !  = +⁄,  } Check-in 24.1 
Actually using a probabilistic algorithm 
Amplification lemma: 2−. /01 2 
presupposes a source of randomness. 
Can we use a standard pseudo-random 
number generator (PRG) as the source? 
& ∈% 
& ∉% 
(a) Yes, but the result isn’t guaranteed.
(b) Yes, but it will run in exponential time.
Many 
Few 
Few 
Many 
(c) No, a TM cannot implement a PRG. 
accepting 
rejecting 
accepting 
rejecting 
(d) No, because that would show P = BPP.
2 
Check-in 24.1 
","78.43372344970703","4","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_2_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"107","Why can a deterministic Turing machine only have one rejecting computation history?"," 
 
 
  
  
 
 
 
  
 
 
  
  
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
Acceptance Problem for TMs 
Let !TM = { &, ( | & is a TM and & accepts (} 
Theorem: !TM is not decidable 
Proof: Thursday. 
Theorem: !TM is T-recognizable 
Proof: The following TM + recognizes !TM 
+ = “On input &, ( 
Turing’s original “Universal Computing Machine” 
1. 
Simulate & on input (. 
2. 
Accept if & halts and accepts. 
Description of &, input ( 
3. 
Reject if & halts and rejects. 
+ 
4. 
Reject if & never halts.” 
Not a legal TM action. 
Von Neumann said + inspired the concept of a stored program computer. 
10 
","76.93802642822266","5","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_10_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"107","Why can a deterministic Turing machine only have one rejecting computation history?","we did with Turing machines. And just want to make sure we're all together on that. It's a very important concept for us this term. So the Turing machine model looks like there's going to be this finite control. There's a tape with a head that can read and write on the tape, can move in both directions. The tape is infinite to one side and so on, as I mentioned last time. The output of the Turing machine is either going to be a halt, accepting or rejecting, or loop that the machine may run forever. With three possible outcomes for any particular input. The machine may accept that input by entering q accept. May halt and reject by entering q reject. And it might reject by looping, which means it just never gets to the accept state or it never gets any halting state. It just goes forever. But we still consider that to be rejecting the input, just it's rejecting by looping. And as we defined last time, a language is Turing recognizable, or as we typically write, T recognizable, if it's the language of some Turing machine, the collection of accepted strings from that Turing machine. Again, just as before, the machine may accept 0 strings, one string, many strings, but it always has one language, the collection of all accepted strings. Now, if you have a decider, which is a machine that never loops, which always halts on every input, then we say its language is a decidable language. So we'll say a language is Turing decidable or simply decidable if it's the language of some decider, which is a Turing machine that always halts on all inputs. So we have those two distinct notions, Turing recognizable languages and Turning decidable languages. Now, as we're going to argue this lecture, Turing machines are going to be our model of a general purpose computer. So that's the way we're going to think of computers as Turing machines. And why Turing machines? Why didn't we pick something else? Well, the fact is, it doesn't matter. And that's going to be the point of this lecture. All reasonable models of general purpose computation, unrestricted computation in the sense of not limited memory, are all going to be-- all have been shown, all the models that we've ever encountered have all been shown to be equivalent to one another. And so you're free to pick any one you like. And so for this course, we're going to pick Turing machines because they're very simple to argue about mathematically, and also they have some element of familiarity in that they feel like-- well, they're more familiar than some of the other models that have been proposed that are out there, such as rewriting systems, lambda calculus, and so on. Turing machines feel like a primitive kind of computer. And in that sense, they have a certain familiarity. OK, so let's start talking about variations on the Turing machine model. And we're going to argue that it doesn't make any difference. And then this is going to be kind of a precursor to a discussion of a bit of the history of the subject that we're gonna get to in the second half of the lecture. So a multi-tape Turing machine is a Turing machine, as you might imagine, that has more than one-- well, has one or possibly more tapes. And so a single tape Turing machine would be a special version of a multi-tape Turing machine. That's OK. But you might have more than one tape, as I've shown in this diagram. Now, how do we actually use a multi-tape Turing machine? Well, you present the-- and we're going to see these coming up for convenience. Sometimes it's nice to be working with multiple tapes. So we're going to see these later on in the semester a couple of times as well. But for now, we're setting the model up so that the input is going to be presented on a special input tape. So that's where the input appears, and it's going to be followed by blanks, just as we had before. And now we have these potentially other tapes, possibly other tapes, which we call them work tapes where the machine can write other stuff as it wishes. And those tapes are going to be initially blank. So just all blanks on them. All of the tapes are going to be read and write. So you can write on the input tape. Obviously you can read off on the input tape, and you can read and write on the other tapes as well. So what we want to first establish that by having these additional tapes, you don't get additional power for the machine in the sense that you're not going to have-- you won't have additional languages that you can recognize by virtue of having these additional tapes. I mean, you can imagine that having more tapes will allow you to do more things. For example, if you have a pushdown automaton with two stacks, you can do more languages than you can with one stack. So it's conceivable that by having more tapes, you can do more languages than you could with one tape. But in fact, that's not the case. One tape is as good as having many tapes. And we're going to prove that. We're going to quickly sketch through the proof of that fact. So the theorem is that a language is Turing recognizable. And when we say Turing recognizable, for now we mean just with one tape. So that's the way we've defined it. So a language is Turing recognizable if and only if some multi-tape Turing machine recognizes that language. So really another way of saying that is if you have a language that you can do with a single tape, you can do it with a multi-tape and vice versa. So one direction of that is immediate, because a single tape Turing machine is already a multi-tape Turing machine that just so happens to have one tape. So the forward direction of that is-- there's nothing to say. That's just immediately true. But if we want to prove the reverse, then we're going to have to do some work. And the work is going to be showing how do you convert a multi-tape Turing machine to a single tape Turing machine. So if we have something that's recognized by a multi-tape Turing machine, it's still Turing recognizable. And what that means is that you can do it with a single tape Turing machine. So we have to show how to do the conversion. And I'll show you that I think in a convincing way but without getting into too much detail. So here is an image of a multi-tape Turing machine during the course of its input. So we've already started it off. Initially it starts off with the other tapes, the work tapes being all blank. But now it's processed for a while and the head on the input tape now has moved off from its starting position at the left end. It's somewhere in the middle. It's written stuff on the other tapes. And what we want to do is show how to represent that same information on a single tape Turing machine in a way which allows the single tape Turing machine to carry out the steps of the multi-tape Turing machine but using only a single tape by virtue of some kind of a data structure which allows for the simulation to go forward. So how is the single tape Turing machine going to be simulating, going to be carrying out the same effect of having these multiple tapes on the multi-tape Turing machine? So here's a picture of the single tape Turing machine. It just has one tape. By the way, I should mention that all of the tapes are infinite to the right in the multi-tape Turing machine, just as we had for the single tape Turing machine. And now with this single tape Turing machine, it's going to represent the information that's present on these multiple tapes but using only the single tape. And the way I'm choosing to do that is going to be particularly simple. I'm going to just divide up, so here I'm saying it in words. It's going to simulate m by storing the contents of the multi-tape on the single tape in separate blocks. So I'm basically going to divide up the single tape Turing machines tape into separate regions where each one of those regions is going to have the information that was on one of the tapes in the multi-tape machine. So for example, on the first tape it's got a, a, b, a. Well, that's going to appear here in that first block on the single tape Turing machine. Sort of seeing it float down to suggest that it's coming from this multi-tape Turing machine. But that's really been developed by the simulation that the single tape Turing machine has. Obviously the single tape Turing machine doesn't have any direct access to the multi-tape machine. But it's going to be simulating. So this is how we're showing the data is being stored on the single tape machines tape. So in the second block, it's going to have the contents of the second tape of the Turing multi-tape machine. And the final region of the single tapes, the final block so-called of the single tape's tape is going to have-- the single tape machine's tape-- it's going to have the rest of the contents of the last tape of m. And then it's going to be followed by the same infinitely many blanks that each of these tapes are going to have following the portion that they may have written during the course of their computation. So that's what the single tape Turing machine's tape is going to look like during the course of its computation. It's going to have the information represented in these blocks. Capturing all of the information that the multi-tape Turing machine has in a perhaps somewhat less convenient way, because the multi-tape Turing machine, we didn't really make this explicit. And in part because it doesn't really matter, we didn't say exactly how the multi tape machine operates. What I have in mind is that the multi-tape Turing machine can read and move all of its heads from all of its heads in one step. So in a single step of the multi-tape machine, it can obtain the information that's underneath each of its heads, feed that in through its transition function, and then together with the state of the multi-tape machine decide how to change each of those locations and then how to move each one of those heads. So it's kind of operating on all of the tapes in parallel. So now how does the actual steps of the simulation of the single tape-- by the single tape machine, how does it go? So first of all, besides storing the contents of each of the tapes in S's single tape, there's some additional information that it needs to record. Namely, M has a head for each one of its tapes. But S has just a single head. And each of M's heads could be in some different location. In this case, as I've shown it, on the first tape, its head is in location three. On the second tape, it's in location two. On the third tape, it's on location-- on the last tape, it's in location one. So where were we? We were simulating the multi-tape Turing machine with the single tape Turing machine. And we had to keep track of where the heads are. And so we're going to do that by writing the locations on those blocks. So we're going to have a special dot, as I've shown here, to represent the location of the head in that very first block. So the head's on the b. I'm going to dot the b. And I'm going to do the same thing for the locations of the other heads. And how am I getting that effect? Well, we've seen something like that before, where we just expand the tape alphabet of S to allow for these dotted symbols as well as the irregular symbols. We also have expanded it to include the delimiter markers that separate the blocks from one another, which I'm writing as a pound sign. So we can just get that effect simply by expanding the tape alphabet of S. A few more details of S that are just worth looking at, just to make sure we're kind of all understanding what's happening. So for every time M takes one step, S has actually a lot of work to do. Because one step of M can read and move all of those heads all at one shot. S has to scan the entire tape to see what's underneath those in effect virtual heads, which are the locations of the dotted symbols. It has to see what's underneath each one of those heads to see how to update its state to the next state. And then it has to scan again to change the location, change the contents of those tape locations, and also to move the head left or right by effectively now moving the dot left or right. So that's pretty straightforward. There's one complication that can occur, however, which is that what happens if on one of the tapes, let's say, M starts writing more content than you have room in that block to store that information? So if M, it has 1, 0, 1, suppose M after a few steps moves its head into the originally blank portion of the tape and writes another symbol there. We have to put that symbol somewhere, because we have to record all that information. And the block is full. So what do we do? Well, in that case, S goes to a little interrupt routine and moves, shifts all of the symbols to the right one place to open up a location here where it can write a new symbol for continuing the simulation. So with that in mind, S can maintain the current contents of each of of M's tapes. And let me just note that here. Shift to add room is needed. And that's all that happens during the course of the simulation. And of course, if S as it's simulating M observes that M comes to an accept or reject state, S should do the same. So that's our description of how the single tape","76.33304595947266","6","DPRSearchEngine","TTArY7ojshU.en-j3PyPqV-e1s_2_mp4","TTArY7ojshU.en-j3PyPqV-e1s","18.404J","6"
"107","Why can a deterministic Turing machine only have one rejecting computation history?"," 
  
 
 
  
  
 
 
 
 
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Probabilistic TMs 
Defn: A probabilistic Turing machine (PTM) is a variant of a NTM 
where each computation step has 1 or 2 possible choices. 
deterministic 
coin flip step ­
step 
each choice has 50% probability 
Pr[ branch ! ] = 2&' where ! has ( coin flips 
Pr[ "" accepts # ] = + Pr[ branch ! ] 
Pr[ "" rejects # ] = 1 − Pr[ "" accepts # ] 
b accepts 
computation tree 
for "" on # 
branch ! 
Defn: For 7 ≥0 say PTM "" decides language : with error probability 7 
if for every #, Pr[ "" gives the wrong answer about # ∈: ] ≤7 
i.e., # ∈: → Pr[ "" rejects # ] ≤7 
# ∉: → Pr[ "" accepts # ] ≤7. 
2 
","76.2980728149414","7","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_2_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"107","Why can a deterministic Turing machine only have one rejecting computation history?","Turing machines, as we set them up, they have-- on any input w, they have three possible outcomes. The Turing machine can halt and accept w, can halt and reject w, or it can go forever on w, which is rejecting by looping in our language. A Turing machine can recognize a language, the collection of old strings that it accepts. And if the Turing machine always halts, we say it decides the language, and it's a decider, and so therefore, that language is a decided language, a Turing decider. Often we just say decidable, because we don't really have a notion of deciding in other models, so we often talk about Turing-recognizable or just decidable. Or we'll sometimes just say recognizable, when we understand that we're talking about Turing machines. We briefly talked about encodings. When you write it inside brackets, some objects-- whatever they are-- could be strings, could be machines, could be graphs, could be polynomials-- we're representing them as strings, and maybe a collection of objects together represented as a string in order so that we can present that information as an input to a machine. And we talk about-- our languages our collections of strings. And a notation for writing a Turing machine is going to be simply that English description put inside quotation marks to represent our informal way of talking about the formal object that we could produce, if we wanted to. But we're never going to ask you to do that. OK, so now let me see. Let's just take a quick break, as I promised. If there's any quick questions here, you can ask. Let's see-- got a lot of questions here. All right, why don't we move on? And some of these things are good questions.","76.05741882324219","8","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_2_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"107","Why can a deterministic Turing machine only have one rejecting computation history?"," 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
   
 
    
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
Linearly Bounded Automata 
Defn: A linearly bounded automaton (LBA) is a 1-tape TM 
that cannot move its head off the input portion of the tape. 
LBA 
a a b a a b a 
Tape size adjusts to length of input. 
Let !LBA = &, ( LBA & accepts ( } 
Theorem:  !LBA is decidable 
Proof: (idea) If & on ( runs for long, it must be cycling. 
Decider for !LBA: 
Claim: For inputs of length ), an LBA can have 
.A−LBA = “On input &, ( 
only * ×)× Γ - different configurations. 
1.  Let ) = |(|. 
Therefore, if an LBA runs for longer, it must repeat some 
2. Run & on ( for * ×)× Γ - steps. 
configuration and thus will never halt. 
3. If has accepted, accept. 
4. If it has rejected or is still running, reject.” 
must be looping 
7 
","75.06402587890625","9","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_7_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"107","Why can a deterministic Turing machine only have one rejecting computation history?"," 
 
  
  
  
 
 
  
       
   
 
 
 
 
 
 
  
 
 
 
  
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
  
 
 
 
  
 
 
   
 
 
   
 
 
 
 
   
 
 
 
 
 
 
 
 
    
 
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
  
 
TM – Formal Definition 
Defn: A Turing Machine (TM) is a 7-tuple ("", Σ, Γ, &, '(, 'acc , 'rej)
Σ input alphabet 
Γ tape alphabet (Σ ⊆Γ)
&: Q×Γ → ""×Γ× {L, R} 
(L = Left, R = Right) 
& ', a = (5, b, R) 
On input 6 a TM 7 may halt (enter 'acc or 'rej) 
Check-in 5.3 
or 7 may run forever (“loop”). 
This Turing machine model is deterministic. 
So 7 has 3 possible outcomes for each input 6: 
How would we change it to be nondeterministic? 
1. Accept 6 (enter 'acc ) 
a) Add a second transition function. 
2. Reject 6 by halting (enter 'rej ) 
b) Change & to be &: Q×Γ → 8( ""×Γ× {L, R} ) 
3. Reject 6 by looping (running forever) 
c) Change the tape alphabet Γ to be infinite. 
10 
Check-in 5.3 
","74.83231353759766","10","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_10_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"108","How large can the computation history be for a Turing machine using exponential space?"," 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Turing Machines (TMs) 
head 
˽ ˽
a
b
a 
. . .
b b
Finite 
read/write input tape 
control 
1) Head can read and write 
2) Head is two way (can move left or right) 
3) Tape is infinite (to the right) 
4) Infinitely many blanks “˽“ follow input 
5) Can accept or reject any time (not only at end of input) 
8 
","77.43582153320312","1","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_8_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"108","How large can the computation history be for a Turing machine using exponential space?","we can talk about that more over the break. And so we'll return here in five minutes. Somebody's asking about-- can infinite sequences be generated by the machine. When we're talking about, especially in the complexity section of the course, all of the computations are going to be bounded in time. So we're not going to be thinking about infinite runs of the machine. That's not going to be relevant for us. So let's not think about that. How does a Turing machine perform division? How does a Turing machine perform division? Well, how do you perform division? [LAUGHS] Long division is an operation that can run in-- the long division procedure that you learn in grade school, you can implement that on a Turing machine. Yes, a Turing machine can definitely perform-- do long division, or division of one integer by another in polynomial time. Another question. Can we generally say, try dividing y by x? Or do we have to enumerate a string of length y and cross off every-- no. I think that's the same question. I mean, if you have numbers written in binary, how would you do the division? You're not going to use long division. Anything such as the thing that's proposed here by the questioner is going to be an exponential algorithm. So don't do it that way. Why does primes in P-- composites in P not imply primes in P? It does imply. If composites are in P, then primes is in P as well. When you have a deterministic machine, you can flip the answer. When you have a non-deterministic machine, you may not be able to flip the answer. So deterministic machine just having a single branch, you can make another deterministic machine that runs in the same amount of time that does the complementary language. Because for deterministic machines, just like for deciders in the computability section, you can just invert the answer. There is an analogy here between P and decidability, and NP and recognizability. It's not an airtight analogy here, but there is some relationship there. Somebody's asking me, what are the implications of P equal to NP? Lots of implications. Too long to enumerate now. But, for example, you would be able to break basically all cryptosystems that I'm aware of, if P equal to NP. So we would have a lot of consequences. Somebody's asking, so composites-- primality and compositeness testing is solvable in polynomial time. But factoring, interestingly enough, is not known to be solvable in polynomial time. We may talk about this a little bit toward the end of the term if we have time. The algorithms for testing whether a number is prime or composite in polynomial time do not operate by looking for factors. They operate in an entirely different way, basically by showing that a number is prime or composite by looking at certain properties of that number. But without testing whether it has-- testing, but without finding a factor. Another question here about asking when we talk about encodings, do we have to say how we encode numbers, values? No, we don't have to. We usually don't have to get into spelling out encodings, as long as they're reasonable encodings. So you don't have to usually. We're going to be talking about things at a high enough level that the specific encodings are not going to matter. Let's return to the rest of our lecture.","76.81575775146484","2","DPRSearchEngine","1VhnDdQsELo.en-j3PyPqV-e1s_10_mp4","1VhnDdQsELo.en-j3PyPqV-e1s","18.404J","14"
"108","How large can the computation history be for a Turing machine using exponential space?","n cubed time on a one tape Turing machine, and so on, 2 exponential time, 2 to the n time on a one tape Turing machine. These are all collections of languages getting larger and larger as we increase the bound. So someone is asking kind of-- let's see, let me get to some of these questions here. I'll try to get to them in order. So somebody says if you have-- a good question, if you have a regular computer, so an ordinary sort of random access computer, which we'll talk about that in a second, can do it in order n, can you do it on a multi-tape Turing machine also in order n time? Actually, I don't know the answer to that offhand. I suspect the answer is no. That ordinary computers have a random access capability that Turing machines do not. And so that there are going to be some examples of problems that you can do with a random-- with a regular computer that you cannot do with the multi-tape Turing machine in order n time. I'd have to double check that, though, so we can-- it's also a question what we believe is true and what we can prove to be true. As we'll see, there are a lot of things that we believe to be true in this subject that we don't know how to prove. Somebody is asking kind of an interesting sort of more advanced question. Is there some function f, some function t where it's so big that so that time t of n gives you all of the decidable problems? It would be a very big t. But the answer actually to that question is yes. But that's a little bit exotic. So let's not spend a lot of time on that right here. But happy to talk about that offline. It's a good question here. Somebody's asking me does it mean that there are no languages between order n and order n log n, because I pointed out that anything below n log n is going to be regular. And so, as soon as you get below n log n, you can do it in order n. And yes, there is what's called a gap between order n and order n log n on a one tape Turing machine. You don't get anything new from order n until you jump up. So from order n to order n log log n, nothing new shows up. So we'll talk about those kinds of things a little bit down the road, when we look at actually the relationship among these various classes, and what we call a hierarchy theorem, which shows-- how much bigger do you have to make the bound in order to be sure you'll get something new? All right, somebody's asking is there a model which has the same time complexity as a normal computer? Well, I mean, there's the random access model, which is supposed to capture a normal computer. So let me-- these are all great questions, kind of more riffing off of this into more advanced directions. Let's move on. Here's another check-in. Suppose we take-- this is a little bit of a check to see how well-- how comfortable you are with the notions we've just presented and whether you can think about some of the arguments that we've made and apply them to a new language. So take the language ww reverse, strings followed by their-- followed by themselves backwards. This language B are the even length palindromes, if you will. What's the smallest bound that you need to be able to solve that language B? And I'll pose it as a-- pose that as a question for you. So which time complexity class is that language B in? Is it time order n, order n log n, n squared, so on? What do you think? So we're about to come to the coffee break. So why don't we-- I'll answer any questions that come up. I think we're got everybody answered. So I'm going to end the polling. OK, make sure you're in if you want to be in. So the correct answer is, in fact, order n squared. It would be hard-- reasonable guess here would be order n log n. I mean, you can come up with the same procedure as the one we showed at the beginning, the order n squared procedure for a to the k, b to the k works for ww reverse as well. You can just cross off, sweep back and forth, crossing off a symbol from w, and going across to the other side, crossing off a symbol from w reverse. And that procedure will give you an n squared and order n squared algorithm. You might imagine you can improve it to order n log n. But you cannot. You can prove that order n squared is the best possible. I'm a little unhappy that a lot of you came up with order n, frankly. Because I already told you that order n is-- these are just regular languages. Anything that you can do in less than-- a little o of n log n is going to be regular. And we know this language is not regular. So this was not a good answer. So please pay attention. And OK, so let us stop sharing.","75.9339828491211","3","DPRSearchEngine","asjAc90L8rE.en-j3PyPqV-e1s_8_mp4","asjAc90L8rE.en-j3PyPqV-e1s","18.404J","12"
"108","How large can the computation history be for a Turing machine using exponential space?","So now, we're going to start defining things with the one tape model in mind. So first of all, if you have a Turing machine, we're going to say it runs in a certain amount of time. So if t is some sort of time bound function, like n squared, or n log n, we'll say the machine runs in that amount of time, like n squared or n log n. if that machine M always halts within that number of steps on all inputs of length n. So it always halts within t of n steps on inputs of length n. Then we'll say that the machine runs in t of n time. So in other words, if the machine runs in n squared time, then the machine, when you give it an input of length 10, it's got to be guaranteed to halt within 100 steps, 10 squared, 100 steps, on every input of length 10. That's what it means for the machine to be running in that much time.","75.786376953125","4","DPRSearchEngine","asjAc90L8rE.en-j3PyPqV-e1s_6_mp4","asjAc90L8rE.en-j3PyPqV-e1s","18.404J","12"
"108","How large can the computation history be for a Turing machine using exponential space?","Oh yeah. This is somehow related. And feel free to ask questions too, while you're thinking about this check-in. But the check-in says here, we've solved the A CFG problem in polynomial time. Does that tell us that every context-free language itself is also solvable in polynomial time? Just mull that over, and please give me an answer to it. I hope you do better on this check-in than you did on the last one. But anyway, why don't you go ahead and think about that. I can take some questions in the meantime. Somebody is asking here-- actually, I'm getting several questions on this. Why isn't it order n cubed or something greater than order n squared because of the variables? The variables don't depend on n. When you're given-- well, actually that's not true. No. You are right. Because the grammar is part of the input. So you might have as many as n different variables in the given grammar. So you are right. There is potentially-- the grammar might be half the size of the input, and the input to the grammar w might be half the size of the input. So I didn't think about that, but you're correct. There are potentially different numbers of variables in different grammars, so you have to add an extra factor, which would be at most the size of the input, because that's as many variables as you could possibly have. So it really should be, I think, order n cubed to take that into account as well. Plus all of the work that needs to happen in terms of dividing things up. On a one-tape Turing machine, there's going to be some extra work just to carry out some of these individual steps, because with a single tape things are sometimes a little awkward. I think the total running time is going to end up being something like n to the 4th or into the 5th on a one-tape Turing machine. But that's a good point. Somebody's saying, how can we be storing n squared strings in finite time? I'm not saying finite time. We have polynomial time. Every stage of this algorithm is allowed to run for polynomially many steps. As long as it's clearly polynomial, we can just write that down as a single stage. Part two should say-- oh. There's a typo here. So use D. Thank you. That is a typo. I'm afraid if I change it on my original slide here, things will break in some horrible way. Let's just see. Did I completely wreck my slide? No, that's good. Yeah, thank you. Good point. Oops. OK, how's our check-in doing? I think you're just about all done. Spent a lot of time on this. End polling. As you may remember from the first half of the course-- so the answer is A, indeed. Remember that we showed A CFG is decidable, and therefore each context-free language itself is decidable, just because you can plug in a specific grammar into the A CFG problem. The very same reasoning works here. If you have a context-free language, it has a grammar. You can plug that grammar into the A CFG problem. And then, that's polynomial time, you're going to get a polynomial time algorithm for that language. Good to review that. It's the same thing, same argument we used before. I don't want to spend a lot of time on this. There's another way of looking at dynamic programming. We'll talk about this again maybe in a lecture, probably next lecture, just because I you have a homework problem on it. If you've seen dynamic programming before, this is going to be easy. If you haven't seen it before, it's going to be, I think, probably a little challenging. Another way of looking at dynamic programming is the so-called bottom-up version of dynamic programming. And what that would mean is, you solve all of the subproblems first. You solve all the smaller subproblems before you solve the larger subproblems. It's here on the slide. I'm not sure I want to talk it through. But basically, you solve the subproblems here where, start with strings of length 1, and then from that you build up to subproblems with the substrings are of length 2, and then 3, and so on. And each of those only relies on the smaller previously solved subproblems. So you can, kind of in a systematic way, solve all the larger and larger subproblems for larger and larger substrings. That gives kind of a different perspective on dynamic programming. And for different problems, sometimes it's better to think about either this sort of top-down recursion based process, or the bottom-up process that I'm describing here. They're really completely equivalent. The version that's described for this particular algorithm, which appears in the textbook, is actually the bottom-up algorithm. So you shouldn't be confused if you see something there which looks somewhat different. You basically solve all possible subproblems, basically filling out a table. Let me not say anything more about that here, since we're running a little short on time. There are really two perspectives on dynamic programming. So moving on from there, let's shift gears. Leave context-free languages and dynamic programming behind. And so I'm moving toward understanding P and NP. And for that, we will introduce a new problem called the satisfiability problem. And that's one we're going to spend a lot of time on. If you tuned out a little bit during the dynamic programming discussion, time to get back on board. The satisfiability problem is going to be a computational problem that we're going to be working on. And it has to do with Boolean formula. So these are expressions, like arithmetical formula, like x plus y times z, but instead of using numerical variables, we're going to be using Boolean variables that take on Boolean values, true, false. Or sometimes represented by 1 and 0. The operators that we're going to be using are going to be the and, or, and negation operations. And, or, not. I'm going to say such a formula, such a Boolean formula, we're going to call it satisfiable-- we'll do an example in a second-- if that formula value evaluates to true if you make some assignment of values to its variables. So just like arithmetical formula will have some value if you plug in values for the variables, Boolean formula is going to have some value if you plug in Boolean values for its variables. And I want to know, is there some way to plug in values which makes the whole thing evaluate to true. The formula itself is going to evaluate to either true or false, and I wanted to evaluate to true. Here is our example. Let's take the formula, phi, which is x or y, and x complement-- or, not x or not y. So the notation x with a bar over it, x complement, is just x bar, not x. It's just the way if you're familiar with the other notation, the not operation, which just inverts 1s and 0s. We're going to write it with a bar instead of the negation symbol. I'm assuming that you've all seen Boolean algebra, Boolean arithmetic before, where the and operation is only true if both inputs are true. These are going to be binary and operations and binary or operations. Or is going to be true if either input is true. And not is true if its single input is false. Oops, just looked at the answer. Here I want to know, for this Boolean formula, here is it satisfiable. Is there some way to assign values to the variables to make this formula evaluate to true? So for example, let's just try things. Let's make x and y both true. So x is true and y is true. So x or y, well that's good, that's true. But now we have to do an and, so we need both sides to be true. So now we have x complement-- well we said we said x is true, so x complement is false, y complement is false. False or false is false. So now we have a true and false. That's going to be false. We did not find a satisfying assignment. But maybe there's another one. And in fact, there is. If you make x true and y false, then both of these parts will evaluate to true, and then you'll have true and true. So we found a satisfying assignment to this formula. It is, in fact, satisfiable. So if you say x is 1 and y is 0, yes. This is satisfiable. Now the problem of testing for a Boolean formula, if it is satisfiable, is going to be the SAT language. It's a set. It's a collection of satisfiable Boolean formula. And testing whether you're in SAT or not is going to be an important computational problem. There was an amazing theorem which really got this whole subject going, discovered independently by Steve Cook in North America and Leonid Levin in the former Soviet Union, almost exactly at the same time, which made a connection between this one problem and all of the problems in NP. By solving this one satisfiability problem in polynomial time, it allows you to solve all of the problems in NP in polynomial time. So if you could solve this problem set in P, then Hamiltonian path is also solvable in P. If you step back and think about that, it's kind of amazing. And the method that we're going to introduce is called polynomial time reducibility. Let's do a quick check-in on this. This should be an easy one. Why don't you just think about, is SAT, the SAT problem that we just described here, is that in NP? Three seconds. You all there? OK. Ending polling. Hopefully you're getting the intuition for NP that these are the problems-- to be in NP means that when you're a member of the language, there's a short proof or a short certificate of membership. And in this case, the short certificate that the formula is satisfiable is the assignment, which makes it true, also called the satisfying assignment. So yes, this is an NP language, language that's in NP. There are a lot of things that we don't know in the subject, but this isn't one of them. We do know that SAT is in NP. So let's talk about our method for showing this remarkable fact that, if you can solve SAT in polynomial time, then all of NP is solvable in polynomial time. And it uses this notion of polynomial time reducibility, which is just like mapping reducibility that I hope you've all grown to know and love in the first half of the course. But now, the reduction has to operate in polynomial time. So it's the same picture that we had before, mapping A to B, transforming A questions to B questions. But now the transformation has to operate quickly. And we get that if A is polynomial time reducible to B, and B is polynomial time, then A is also polynomial time. Same pattern as before. If A is reducible to B and B is easy, then A is easy. Here is kind of the essence of the idea, or at least the outline of the idea of this Cook and Levin theorem. That if satisfiable is in P, then everything in NP can be done in P. Which is because, we will show that all problems in NP are polynomial time reducible to SAT. That's the amazing fact. So therefore, if you can bring SAT down into P by using this reduction, it brings everything else along with it, everything is reducible to SAT. So we just have to show how to do that. There is an analogy that we had in the first half of the course, in one of our homework problems, if you may remember. We showed that A TM has the very special property that all Turing recognizable languages are mapping reducible to it. I think that was problem 2, or 2a, either in problem set 3 or problem set 2. I think problem set 3. That every Turing recognizable language is polynomial time reducible to A TM. And so, very similar picture. And there's a lot of analogies here that you can draw between the computability section and the complexity section. With that, I know we're just about out of time. So let's just quick review of what we've done here. I will stick around for questions for a while. Is there a-- OK, that's a good question. Is there a regular reduction analogy version to mapping reducibility? We had the general reduction for the computability section. And we had the mapping reduction for the computability section. Here, we're only going to be focusing now on the mapping reduction. So polynomial time reduction is, by assumption, going to be a mapping reduction. Yes, there is a general polynomial time reduction notion as well. This is not required, but if you are curious about the general reduction and how to precisely formulate that, it actually appears in chapter 6 under Turing reducibility. That's the general notion of reducibility spelled out in a formal way. And there's polynomial time Turing reducibility as well. We're not going to talk about it in this course. Other questions? Does NP correspond exactly to verification in polynomial time? For me to answer that as a precise question, we have to have a precise definition of verification. But with the right definition, the answer is yes. So you can define a verifier as a polynomial time algorithm that gives a certificate, that takes a certificate and an input to the language, and will accept if that certificate is a valid certificate for that input. This is actually discussed in chapter, I think, 9 of the text. Now I'm forgetting already, what's where in the book. But yeah, you can think of NP in terms of verification as the definition. Is proving P equal NP the same as proving that a polynom-- actually, I can even make the-- if you want, you can post public comments too. I should have done that in other cases. Is proving P equal NP the same as proving that a polynomial time non-deterministic Turing machine N has a polynomial time deterministic? Yeah. Suppose we prove that P equals NP, which is the minority view, I would say, the small minority view. There are some people who believe that that is entirely possible, and might even be the case. But that's a very small group. But yeah, if you prove P equal NP, that's the same as saying that every non-deterministic polynomial time Turing machine is going to have a companion deterministic polynomial time Turing machine which does the same language. That's exactly what it means. Bye bye, everybody.","75.6877212524414","5","DPRSearchEngine","1VhnDdQsELo.en-j3PyPqV-e1s_12_mp4","1VhnDdQsELo.en-j3PyPqV-e1s","18.404J","14"
"108","How large can the computation history be for a Turing machine using exponential space?","Actually, what a modern computer is addressed in is bytes, collections of 8 bits. So there's an address I have for every 8 bits in memory-- consecutive 8 bits in memory. And so if I want to pull something in into the CPU, I give it an address. It'll take some chunk, and bring it into the CPU, operate on it, and spit it back. How big is that chunk? This goes to the answer that you were asking, which-- or saying, which is it's some sequence of some fixed number of bits, which we call a word. A word is how big of a chunk that the CPU can take in from memory at a time and operate on. In your computers, how big is that word size? 64 bits-- that's how much I can operate on at a time. When I was growing up, when I was your age, my word size was 32 bits. And that actually was a problem for my computer, because in order for me to be able to read to address in memory, I need to be able to store that address in my CPU, in a word. But if I have 32 bits, how many different addresses can I address? I have a limitation on the memory addresses I can address, right? So how many different memory addresses can I address with 32 bits? 2 to the 32, right? That makes sense. Well, if you do that calculation out, how big of a hard disk can I have to access? It's about 4 gigabytes. So in my day, all the hard drives were limited to being partitioned-- even if you had a bigger than 4 gigabyte hard drive, I had to partition it into these 4 gigabyte chunks, which","75.65203857421875","6","DPRSearchEngine","ZA-tUyM_y7s.en-j3PyPqV-e1s_8_mp4","ZA-tUyM_y7s.en-j3PyPqV-e1s","6.006","1"
"108","How large can the computation history be for a Turing machine using exponential space?"," 
 
 
 
  
 
 
  
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Intro to Complexity Theory 
Computability theory (1930s - 1950s): 
Is A decidable? 
Complexity theory (1960s - present): 
Is A decidable with restricted resources? 
(time/memory/…) 
Example: Let ! = a#b# $ ≥0 . 
Q: How many steps are needed to decide !? 
Depends on the input. 
We give an upper bound for all inputs of length '. 
Called “worst-case complexity”. 
2 
","74.2967529296875","7","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_2_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"108","How large can the computation history be for a Turing machine using exponential space?"," 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Relationships among models 
Informal Defn: Two models of computation are polynomially related 
if each can simulate the other with a polynomial overhead: 
So ! "" time → !$("") time on the other model, for some '. 
All reasonable deterministic models are polynomially related. 
• 1-tape TMs 
• multi-tape TMs 
• multi-dimensional TMs 
• random access machine (RAM) 
• cellular automata 
9 
","74.22450256347656","8","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_9_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"108","How large can the computation history be for a Turing machine using exponential space?","So first, let's understand what we mean by the time used by a non-deterministic machine. And what we mean by the time used is, we're looking at each individual branch individually, separately. So a non-deterministic machine, we'll say, runs in a certain amount of time if all of the branches halt within that amount of time. So what we do not mean that the total amount of usage, the total amount of effort by adding up all the branches is at most T of n. It's just that each branch individually uses at most T of n. That's just going to be our definition. And it's going to turn out to be the right way to look at this to get something useful. So now we're going to define the analogous complexity class associated to non-deterministic computation, which we'll call non-deterministic time. So non-deterministic time T of n is the set of all languages that you can do with a non-deterministic machine that runs in order T of n time. Just think back to the definition we had for deterministic complexity, the time class-- or sometimes people call it dtime to emphasize the difference. But let's just say we're calling it in this course time versus ntime. So TIME[T(n)] is all of the language that you can do with the one-tape Turing machine that's deterministic. But this here is a non-deterministic Turing machine for non-deterministic time. So the picture that is good to have in your head here would be if you think of non-determinism in terms of a computation tree thinking of all the different branches of the non-determinism. All of those branches have to halt and they have to halt within the time bound. So imagine, here, this is T of n time. All of the branches have to halt within T of n steps for this, a non-deterministic Turing machine to be running in T of n time and to be doing a language in the NTIME[T(n)] class. And by analogy with what we did before, the class NP is the collection of all languages that you can do non-deterministically in polynomial time. So it's the union over all of the ntime classes where the bound is polynomial. OK, so a lot of this should look very familiar, but we've just added a bunch of non-deterministic and a bunch of Ns in place. But the definitions are very similar. And one of the motivations we had for looking at the class P was that it did not depend on the choice of model, as long as the model was deterministic and reasonable. And the class NP is also going to not depend on the choice of model, as long as it's a reasonable non-deterministic model. So it's again a very natural class to look at from a mathematical standpoint. And it also captures something interesting, kind of, from a practical standpoint - which we're going to talk about over the next couple of slides - which is that it captures the problems where you can easily verify when you're a member of the language. OK, so we'll talk about that. But if you take, for example, the Hamiltonian path problem. When you find a member of the language, so that is a graph that does have a Hamiltonian path from s to t, you can easily verify that's true by simply exhibiting the path. Not all problems can be verified in that way. But the problems that are in NP have that special feature-- that when you have a member of the language, there's a way to verify that you're a member. So we're going to talk about that, because that's really the key to understanding NP-- this notion of verification. OK, so let me go-- there was a good question here. Let me just see if I want to answer that. Yeah, I mean, this is a little bit of a longer question than I want to fully respond to but-- well, let's turn to my next slide, which maybe sort bringing that out anyway.","74.0125961303711","9","DPRSearchEngine","1VhnDdQsELo.en-j3PyPqV-e1s_5_mp4","1VhnDdQsELo.en-j3PyPqV-e1s","18.404J","14"
"108","How large can the computation history be for a Turing machine using exponential space?","And I'm happy to try to take questions along the way as we're waiting for the time to end. So let's see, let me put this up here. Let me try to take some of your questions. So someone is asking me about quantum computers as reasonable models of-- you may say a quantum computer is a reasonable model of computation. And that's fine. I would not say it's a reasonable model of deterministic computation, at least from our standpoint. Let's not quibble about the words. I'm not including quantum computers in the collection of machines that I have in mind right now when I'm talking about the reasonable models of deterministic computation that we're going to be discussing. Let's see. Oh, because a bunch of people apparently are asking the TAs why all regular languages can be done in order n. So if you think about a DFA, which processes an input of length n with n steps, and a DFA is I'm going to be a type of Turing machine that never writes on its tape, so if a DFA can do it in n steps, the Turing machine can do it in n steps. And so therefore, every regular language can be done in order n steps on a Turing machine. Not sure where the confusion is. So please message me if you're still not getting it. OK, somebody saying why are we using one tape Turing machines instead of random access? Wouldn't it be better to use the random access machines? If you were using-- if you're trying to do algorithms, yes. That's a more reasonable model. We're trying to prove things about the computation. And from that standpoint, we want to use as simple a model as possible. Trying to prove things using random access computers is possible. It'd be very messy. So that's why we don't use random access machines to prove the kinds of things we're going to be proving about computation that are really the meat and potatoes of this course. So I mean, there's compelling reasons why you would want to use a simple model like a Turing machine, but not a powerful model like a random access computer. So somebody's asking me, does the class time order n log log n have any elements? Yes, it has all the regular languages, but nothing else. Order n log log is it's only the regular languages. You have to go all the way up to n log n before you get something non-regular. Someone's asking me are we going to talk about how the random access model works? No. That's beyond the scope of this course, outside of what we're going to be doing. We're going to talk about Turing machines. Not because we care so much about Turing machines. But I'm trying to prove things about computation. And the Turing machines are a convenient vehicle for doing that. Our candle has burned out. Why don't we return, then, to the next slide. So everybody come back. So this answers one of the questions I got on the chat. What actually is the dependency between multi-tape Turing machines and one tape Turing machines? Can we bound that in general? Yes, we can. We're going to show that converting a multi-tape Turing machine to a one tape Turing machine can, at most, blow up the amount of time that's necessary by squaring. No, I acknowledge it's a lot. But it still allows you-- but it's still small compared with an exponential increase. And we're going to be focusing, in this course, on things like the difference between polynomial and exponential, not between the different-- not between the difference of-- not the difference between n squared and n cubed. That's going to be less of a factor, less of an issue for us. So the way I'm showing this theorem is that if you have a multi-tape Turing machine that can do a language in a certain amount of time, then it's in the time complexity class of that time bound squared. And the way I'm just saying that is because this is the bound that's utilizing the one tape model. So another way of saying that is converting multi-tape to one tape squares the amount of time you need at most. So the way we're going to prove that is simply by going back and remembering the conversion that we already presented from multi-tape to one tape. And observe that if we analyze that conversion, it just ends up squaring the amount of time that the multi-tape used. So why is that? So if you remember, let's just make sure we're all together on this, the way the single tape machine S simulates the multi tape Turing machine M is that it takes the contents of each of M's tapes, up to the place where there's infinitely many blanks. Obviously you don't store the infinite part. But the active portion of each of M's tapes, you're going to store them consecutively in separate blocks on S's tape, on S's only tape. And now every time M makes one move, S has to scan its entire tape to see what's under each of the heads and to do all the updating. So to simulate one step of M's computation, S is going to use order of t of n steps, where t of n is the total running time that M is going to use. So why is t of m steps coming up here? Well, that's because you have to measure how-- S is going to make a scan across its tape. How big can its tape be? Well M, if it's trying to use as much tape as possible, can use, at most, t of n tape on each of-- t of n cells on each of its tapes. So altogether, they're just going to be some constant number of times t of n cells on S's tape. Do you see that? So each one of these is going to be, at most, t of n long. So this all together is going to be order t of n long. Because what can M do? It could send its head out, say the head on this tape here, moving as fast as possible to the right, using as much tape as it can. But you can only use t of n cells in t of n time. So this is going to be order t of n. So one step of computation is going to be t of n steps on S's computation. But M itself has t of n steps. So it's going to be t of n times t of n for the total number of steps that S is going to end up using. And that's where the squaring comes from. Similar results, I'm not going to do lots of simulations of one model by another. I think that you'll get the idea. And you can, if you're interested, you can study those on your own. But you can convert multidimensional Turing machines to one tape Turing machines, one tape ordinary linear-- one tape, one dimensional machines.","73.23577880859375","10","DPRSearchEngine","asjAc90L8rE.en-j3PyPqV-e1s_9_mp4","asjAc90L8rE.en-j3PyPqV-e1s","18.404J","12"
"109","What is the process to convert a DFA into a regular expression?"," 
 
 
 
 
 
 
 
 
 
 
Regular 
language 
Context Free 
language 
Regular 
languages 
Recap 
Recognizer 
DFA or NFA 
PDA 
Context Free 
languages 
Generator 
Regular 
expression 
Context Free 
Grammar 
11 
","70.93045806884766","1","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_11_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"109","What is the process to convert a DFA into a regular expression?"," 
 
 
   
 
 
 
 
 
   
  
 
   
 
 
 
 
 
   
   
  
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
DFAs → Regular Expressions 
Recall Theorem: If "" is a regular expressipn and # = % "" then # is regular 
Proof: Conversion "" → NFA & → DFA &′ 
& 
Regular 
Finite 
expression "" 
automaton 
Recall: we did a ∪ ab ∗ as an example 
Today’s Theorem: If # is regular then # = % "" for some regular expr "" 
Proof: Give conversion DFA & → "" 
WAIT! Need new concept first. 
2 
","70.47451782226562","2","DPRSearchEngine","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3_2_pdf","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3","18.404J","3"
"109","What is the process to convert a DFA into a regular expression?","of this regular expression, and then combine them, using our closure instructions, to be NFAs for larger and larger subexpressions, until I get the NFA that's the equivalent of the entire expression. So let's just see how that goes. So the very most primitive parts, the smallest subexpressions here, are just the expressions for a and for b. So here's the one just for a. So this is the NFA which recognizes the language, which is just the one string a. Here is the NFA whose language is just the one string b. And now I want an NFA which accepts only the string ab. Now, of course, you could just do that by hand yourself. It's simple enough. But what I'm arguing is that we can do this automatically, using the closure construction for concatenation. Because really there's a hidden concatenation symbol. This is a concatenate b. So now for ab, I'm going to take the thing from a and the part from b-- so these two things that I had from before, and use the concatenation construction to combine them. You see that? So now I have automatically an NFA which does the language whose string is just ab, just the ab string. And it's not the simplest NFA. You can make a simpler one, but the virtue of this one is that I got it automatically just by following the closure construction. So now I'm going to do a more complex one, just the inside here, a union ab. So the way I'm going to build that is from the two parts, the a part and the ab part, the a part and the ab part. So here is the a part. Here's the ab part. I've already got those from before. It's really kind of a proof by induction here. But I think it's simple enough, we don't have to use that language. So we have the a part, the ab part. And now we are going to apply the closure under union construction to combine those into one machine. And remember how that worked. We had a new symbol here, which branches under empty string to the previous-- we're adding a new start state, which branches to the original start states under empty transition. And now this is an NFA for this language, a union ab. And lastly, now we're one step away from getting the star of this. And how are we going to do that? We're going to take this thing here and apply the construction for the star closure. And that's going to be an NFA which does a union ab star, which is what we wanted in the first place. So first, we're going to bring that one down. Because we've already built that one. And now remember how we built the closure under star. We made the accepting states return back to the start state, and we added a new start state to make sure we got the empty string in there that transitioned to the original start state under epsilon. OK? So that's all I wanted to say for today's lecture. Let's do a quick review. Very important concept, nondeterminism and nondeterministic finite automata-- we proved they were equivalent in power, showed the class of regular languages closed under concatenation in star. We showed how to do conversion of regular expressions to NFAs. So I think that is it for today's lecture. And thank you, all, for being here. I'll try to answer a few of these. ""Why does concatenation have order?"" Well, because it's an ordered construction. Is there a simple way to prove closure under concatenation without using nondeterminism? No. ""Why are the empty strings at the accept state? Can't they be at any state? Doesn't star make copies of any part of the input?"" No, it's only-- you have to think about what's going on. You have to branch back to the beginning only on an accept. Because that means you found a piece that's in the original language. ""Is there an automaton that can add some or subtract memory automata?"" Well, depends on what you mean by all that. But certainly, there are more powerful machines that we're going to study than finite automata. But yes, there is. And even finite automata can add and subtract, if you present the input in the right way. I would refer you to the first problem on the homework. So I think I'm going to check out then. Take care, everybody. Bye-bye.","68.72206115722656","3","DPRSearchEngine","oNsscmUwjMU.en-j3PyPqV-e1s_9_mp4","oNsscmUwjMU.en-j3PyPqV-e1s","18.404J","2"
"109","What is the process to convert a DFA into a regular expression?"," 
 
   
 
 
 
 
 
 
 
    
       
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Multi-tape Turing machines 
input tape 
Finite 
control 
. . .
}work tapes, initially blank 
all tapes read/write 
Theorem: ! is T-recognizable iff some multi-tape TM recognizes ! 
Proof: (→) immediate. 
(←) convert multi-tape to single tape: 
& simulates ' by storing the contents of 
multiple tapes on a single tape in “blocks”. 
a a b b a 
. . .
˽ ˽ 
Record head positions with dotted symbols. 
multi-tape 
' 
˽
1 0 1 
. . . 
˽
c c c a 
. . . 
. . . 
Some details of &: 
1) To simulate each of '’s steps 
a. Scan entire tape to find dotted symbols. 
b. Scan again to update according to '’s (.
single tape 
& 
… 
˽ ˽
a a b b a # 1 0 1 # 
# c c c a 
c. Shift to add room as needed. 
2) Accept/reject if ' does. 
3 
","68.34941101074219","4","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_3_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"109","What is the process to convert a DFA into a regular expression?"," 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
              
 
 
 
 
 
 
 
 
 
 
 
Pushdown Automata (PDA) 
“head” 
a
b
a
b
a 
… 
a
Finite 
input appears on a “tape” 
control 
c 
Schematic diagram for DFA or NFA
(pushdown) 
d 
stack 
Schematic diagram for PDA 
d 
Operates like an NFA except can write-add or read-remove symbols 
from the top of stack. 
push 
pop 
Example: PDA for ! = 0$1$ & ≥0 
1) Read 0s from input, push onto stack until read 1. 
2) Read 1s from input, while popping 0s from stack. 
3) Enter accept state if stack is empty. (note: acceptance only at end of input) 
6 
","68.21955871582031","5","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_6_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"109","What is the process to convert a DFA into a regular expression?"," 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Generalized NFA 
Defn: A Generalized Nondeterministic Finite Automaton (GNFA) is 
similar to an NFA, but allows regular expressions as transition labels 
a
a ∗ b ∗ 
ab
!1 
#1 
#2 
For convenience we will assume: 
b 
ε 
- One accept state, separate from the start state 
∅ 
- One arrow from each state to each state, except 
a ∪ b 
aab 
a) only exiting the start state 
#3 
#4 
b) only entering the accept state 
ε 
We can easily modify a GNFA to have this special form. 
3 
","68.05926513671875","6","DPRSearchEngine","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3_3_pdf","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3","18.404J","3"
"109","What is the process to convert a DFA into a regular expression?","a Generalized Nondeterministic Finite Automaton, or a Generalized NFA, or just simply a GNFA. So this is yet another variant of the finite automaton model. And conceptually, it's very simple. It's similar to the NFAs. I'll give you-- here's a picture of a GNFA named G, G1. Very similar to the NFAs. But if you look at it for a second, you'll see that the transitions have more complicated labels. For the NFAs, we're only allowing just single symbols, or the empty string, to appear on the labels. Now I'm actually allowing you to put full regular expressions on the labels for the automaton. Now, we have to understand how a GNFA processes its input. And the way it works is not complicated to understand. When you're getting an input string feeding-- when a GNFA is processing an input string, it starts at the start state, just like you would imagine. But now, to go along a transition, instead of reading just a single symbol, or the empty string, as in the case for the nondeterministic machine, it actually gets to read a whole string at one step, kind of, at one bite. It can read an entire string and go along that transition arrow, provided that chunk of the input that it read is in the regular expression that that transition has as its label. So for example, this-- you can go from q1 to q2 in one step in this GNFA by reading a, a, b, b off the input. So it reads all of those four symbols all at once. It just swoops them up and then moves from q1 to q2 in one step. And then, when it's in q2 it can read aab and move to q3. And q3 happens, there's nowhere to go. So this is going to be a nondeterministic machine. There might be several different ways of processing the input. And if any one of them gets to an accepting state at the end of the input, we say the GNFA accepts. So it's similar to nondeterministic-- to NFAs in the way the acceptance criterion works. So you could do an example. But hopefully the concept of how this works is reasonably-- you can at least buy it, that it processes the input in chunks at a time. And those chunks have to be described by the regular expressions on the transition arrows, as it moves along those transitions. So what we're going to do now is to convert not DFAs to regular expressions, we're going to convert GNFAs to regular expression. That's even harder, because GNFAs are-- allow you to do all sorts of other things besides just ordinary DFAs. So that's a harder job. Why am I making my life harder? Well, you'll see in a minute that it's going to actually turn out to be helpful to be working with a more powerful model in the way this construction is going to work. Now, before I dive in and do the construction from GNFAs to regular expressions, I'm going to make a simplifying assumption about the GNFAs. I'm going to put them in a special form that's going to make it easier to do the conversion. And that simpler form is, first of all, I'm going to assume the GNFA has just a single accepting state. And that accepting state is not allowed to be the start state. So it has to have just a single accepting state. I've already violated that convenient assumption in this GNFA, because I have here two accepting states. That's not what I want. I want to have just one. Well, the thing is, it's easy to obtain just one, just to modify the machine so that I have just one by adding a new accepting state which is branched to from the former accepting states by empty transitions. So I can always jump from q2 to q4 at any time without even reading any input, just going along this empty transition. And then I declassify the former accepting states as accepting. And now I have here just a single accepting state. And because it's going to be a new state that I added, it won't be the start state. And I have accomplished that one aspect of my assumption about the form of the GNFA. But there's another thing that I want to do, too. I want to assume-- as you will see, which is going to be convenient in my construction-- that we will have transition arrows going from every state to every other state. In fact, I want transition arrows going from every state even back to themselves. I want there to be-- all possible transition arrows should be present, with two exceptions. For the start state, there should be only transition arrows exiting the start state. And for the accepting state-- there's just one now-- there should be only transition arrows coming into the start state. So it's kind of what you would imagine as being reasonable. For the other states, which are not accepting or starting, there should be transition arrows leaving and coming from everywhere else. But for the start states, just leaving. And from the accept state, just coming in. And you could easily modify the machine to achieve that. Let's just see how to do that in one example. So from-- notice that from q3 to q2 there is no transition right now. And that's not good. That's not what I want. I want there to be a transition from q3 to q2. Well, I'll just add that transition in. But I'm going to label it with the empty language regular expression. So that means, yeah, the transition is there, but you never can take it. So it doesn't change the language that the machine is going to be recognizing. But it fulfills my assumption, my convenient assumption, that we have all of these transition arrows being present in the machine. So anyway, I hope you will buy it. It's not going to be-- if you don't quite get this, don't worry. It's not totally critical that you're following all these little adjustments and modifications to the GNFA. But it will be helpful to understand what GNFAs themselves-- how they work. So as I mentioned, we can easily modify","67.96195983886719","7","DPRSearchEngine","KAySmSEGc9U.en-j3PyPqV-e1s_3_mp4","KAySmSEGc9U.en-j3PyPqV-e1s","18.404J","3"
"109","What is the process to convert a DFA into a regular expression?","Now let's do closure under star. And closure under star works very similarly, but now we're just going to have a single language. If A is regular, so is A star. So they're not a pair of languages, because a star is a unary operation applying to just a single language. So if we have a DFA recognizing A, in order to show that A star is regular, we have to construct a machine that recognizes A star. And the machine we're going to construct is as before and then an NFA. OK? So here is M, the DFA for A. And we're going to build an NFA M prime that recognizes A star. And let's think now, what does it mean to recognize A star? So if I'm going to give you an input, when is it in the star language? What does M prime have to do? So remember what star is. Star means you can take as many copies of you lot as you like of strings in the original language, and that's in the star language. So to determine if something is in the star language, you have to see, can I break it up into pieces which are all in the original language? So you want to see, can I take my input w and cut it up into a bunch of pieces-- four, in this case-- where each of those pieces are members of A, the members of the original language? So that's what M prime's job is. It has its input and wants to know, can I cut that input up into pieces, each of which are accepted by the original machine M? That's what M prime does. And if you think about it a little bit, really what's happening is that as soon as M-- so M prime is going to be simulating M. That's the way I like to think about this, as having M inside. So if you were going to be doing this yourself, you're going to take w. You're going to run it for a while. You'll see, oh, M is accepted. Now I have to start him over again to see if it accepts the next segment. So every time M accepts, you're going to restart M to see if it accepts another segment. And so by doing that, you're going to be cutting w up into different segments, each of which is accepted by M. Of course, it's never totally clear whether you should, for any given segment, you should cut it there or you should wait a little longer and find another, a later place to cut. But that's exactly the same problem that we had before with concatenation. And we solved it using nondeterminism, and we're going to solve it again using nondeterminism. So the way we're going to get that effect of starting the machine over again, once it's accepted, is by adding in epsilon transitions that go from the start states back to-- from the accept state back to the start state. So now every time M has accepted, it has an option-- not a requirement, but has an option. It can either stay continuing to process, or it could restart, making a cut at that point and trying to see if there's yet a second, another segment of the input that it's going to accept. And this is basically the whole thing, with one little problem that we need to deal with. And that is we need to make sure that M prime accepts the empty string. Because remember, the empty string is always a member of the star language. And as it's written right now, we're going to be requiring there to be at least one copy of at least one segment. We're not taking into account the possibility of no segments, which is the empty string. And the way we're going to get that is-- well, I mean, one thing, one way to get to add-- so we're missing the empty string right now. So how do we fix it? Basically, we're just going to take the construction we have on the screen, and we're going to adjust it to add in the empty string. Because it's possibly missing. One way to do that, which is tempting, but wrong, is to make the start state of M an accepting state for M prime. So we could have made this an accepting state, too. And now M prime is also going to accept the empty string. That's the good news. The problem is that the start date might be playing some other role in M besides just being the start. There might be times when M comes back to the start state later on. And if we make the start state the an accept state, it's going to suddenly start accepting a bunch of other things too, which might not be intended. So it's a bad idea to make the start state an accept state. Instead, we'll take the simple solution alternative of adding a new start state, which will never be returned to under any circumstances, and make that a new start-- an accept state as well. So here, we'll have to make this additional modification. So as I'm saying, this is what we need to do. And the way we'll do that is by adding a new start state, which is also an accept state, to make sure it accepts the empty string. And then that also can branch to start off M as before, if the string that's input is not the empty string. And so then M prime is actually going to have to do some work to see if it can be cut off, as it was doing before. So that's the proof of closure under star. I'm not going to do it anything beyond what I've just described. These proofs by picture are convincing enough, I hope. And if not, they are explained in somewhat more detail, somewhat more formally, in the textbook. But for the lecture, this is where I'm going to stop, with these two arguments. And so now-- oh, we have one quick check-in on this. So if M has n states, how many states does M prime have by this construction? So I'm not intending these to be very hard, more just to keep you awake. So how many states does M prime have? OK, maybe a little too easy even for a check-in. Yeah, everybody is getting this one. Because all you did was-- we added one new state. So the answer is as you have-- I think pretty much everybody is observing that it's number b. So I'm going to end the polling, and I'm going to share the results. And everybody got that one. And so let's continue on. And so the very last thing we're going to do today is show you how to convert regular expressions to NFAs, thereby showing that every language that you can describe with a regular expression is a regular language. On Tuesday, we'll show how to do the conversion in the other direction and so thereby showing that these two methods of describing languages are equivalent to one another. So here's our theorem. If R is a regular expression, and A is the language-- a set of strings that that regular expression describes, then A is regular. OK? So we're going to show how to convert. The strategy is to convert R to an equivalent NFA M. And so we have to think about, remember, these regular expressions that we introduced last time. These are these expressions that look like ab union b star, something like that-- so built up out of the regular operations from the primitive regular expressions that don't have any operations, that we're calling atomic. So if R is an atomic regular expression, it just looks like either just a single symbol or an empty string symbol or an empty language symbol. Or R can be a composite regular expression-- whoops. We're having a little-- yeah, so we have two possibilities here. R is either atomic or composite. And so let's look at what the equivalent expression is in each case. So if R is just the single letter regular expression-- that's a totally legitimate regular expression, just a regular expression 1. So that just describes the language of the string 1. So we have to make an NFA which accepts-- which recognizes just that language, accepts only the string 1. So it's a very simple NFA. It just starts in the start state. And on that single symbol, it branches to an accept state. And there were no other transitions allowed. So if you get anything else coming in besides that one, that string, which is just that one symbol, the NFA is going to reject it. If it's too long, if it gets aa coming in, well, there's nowhere to go from this accepting state on an A. So the machine is just going to die. It has to be in an accept state at the end of the input. Now, I want you think for yourself for a minute, how do we make an NFA which accepts only the empty string and no other strings? You can do that with just one state with an NFA, just this one here. The machine is going to start off in the start state, which is also immediately an accept state. So it accepts the empty string. But if anything else comes in, there's nowhere to go when the machine dies. So this machine accepts just the empty string. Or its language is the language with one element, the empty string. How about the empty language? Well, here's an NFA which has no accepting state, so it can't be accepting anything. Now, if we have a composite regular expression, we're already finished. Because we showed how to build up-- we showed constructions which give us closure under union, concatenation, and star. And those constructions are going to enable us to build up the NFAs that do the language of these more complex regular expressions built up out of the NFAs that do the individual parts. So if we already have NFAs that do R1 and R2, then the closure under union construction gives us an NFA that does R1 union R2 as a language. So I hope that's clear, but I'm going to do an example which will hopefully illustrate it. And it's going to show you-- basically, what I'm giving you is an automatic procedure for converting a regular expression into an equivalent NFA. So let's just see that procedure in action, which is really just following this recipe that I described for you. So here is a regular expression a union ab star. So this is a regular expression. It's some language. Whatever it is, I don't care. But I want to make an NFA which recognizes that same language. And the way I'm going to do that is first build","67.77867889404297","8","DPRSearchEngine","oNsscmUwjMU.en-j3PyPqV-e1s_8_mp4","oNsscmUwjMU.en-j3PyPqV-e1s","18.404J","2"
"109","What is the process to convert a DFA into a regular expression?"," 
  
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
! −1 states
! states
$
$
%&
%'
%&
%'
()
(*
(+
(,
() (*
∗(+ ∪(,
!-state GNFA → (!—1)-state GNFA 
Check-in 3.1 
We just showed how to convert GNFAs to regular expressions 
but our goal was to show that how to convert DFAs to 
regular expressions. How do we finish our goal? 
(a) Show how to convert DFAs to GNFAs 
(b) Show how to convert GNFAs to DFAs 
(c) We are already done. DFAs are a type of GNFAs. 
Thus DFAs and regular expressions are equivalent. 
1. Pick any state $ except 
the start and accept states. 
2. Remove $. 
3. Repair the damage by 
recovering all paths that 
went through $. 
4. Make the indicated change 
for each pair of states %&, %' . 
Check-in 3.1 
5 
","67.20263671875","9","DPRSearchEngine","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3_5_pdf","a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3","18.404J","3"
"109","What is the process to convert a DFA into a regular expression?"," 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
18.404/6.840 Lecture 8 
Last time: 
- Decision procedures for automata and grammars
!DFA , !NFA , &DFA , &'DFA , !CFG , &CFG are decidable 
!TM is T-recognizable 
Today: (Sipser §4.2) 
- !TM is undecidable 
- The diagonalization method 
- !TM is T-unrecognizable 
- The reducibility method 
- Other undecidable languages 
1 
","66.74864196777344","10","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_1_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"110","What is the significance of using the big O notation in analyzing the time complexity of algorithms, particularly for a one tape Turing machine deciding a language like a^k b^k?"," 
 
 
 
  
 
 
  
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Intro to Complexity Theory 
Computability theory (1930s - 1950s): 
Is A decidable? 
Complexity theory (1960s - present): 
Is A decidable with restricted resources? 
(time/memory/…) 
Example: Let ! = a#b# $ ≥0 . 
Q: How many steps are needed to decide !? 
Depends on the input. 
We give an upper bound for all inputs of length '. 
Called “worst-case complexity”. 
2 
","74.47689819335938","1","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_2_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"110","What is the significance of using the big O notation in analyzing the time complexity of algorithms, particularly for a one tape Turing machine deciding a language like a^k b^k?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","74.25943756103516","2","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"110","What is the significance of using the big O notation in analyzing the time complexity of algorithms, particularly for a one tape Turing machine deciding a language like a^k b^k?","All right. So let me define a new automaton that we're going to mainly use as just to provide an example for us today. I'm going to call this a linearly bounded automaton. And all it is is a Turing machine where the Turing machine is going to be restricted in where it can-- the tape is not going to be infinite anymore. The tape is just going to be big enough to hold the input. So the machine no longer has the ability to move into the portion of the tape to the right of the input because there is no tape out there. It just has the tape sitting here that contains the input, which the tape itself can vary in size. However big the input is, that's how big the tape is. So the tape adjusts to the length of the input. But once you've started the machine with some particular input, that's as big as the tape is. There's no more. The reason why it's called linearly bounded is because the amount of memory is a linear function of the size of the input because you can effectively get somewhat more memory by enlarging the tape alphabet, but that's going to be fixed for any given machine, so that's where the linearly comes from, if that's helpful. But if you don't get that, it's sort of a side remark. But what's important to me is that you understand what I mean by a Linearly Bounded Automaton, or an LBA. It's just like a Turing machine, but that portion of the tape that originally had blanks is just not there. As the machine tries to move its head off the right end of the input, it just sticks there just as if it tried to move its head off the left end of the input. Doesn't go anywhere. So now, we're going to ask the same kinds of questions about LBAs that we ask for other automa. So the acceptance problem. If I give you an input and some particular LBA and I want to know, does the LBA accept that input? Well, and now the question is, is that the decidable or not? So at first glance, you might think, well, an LBA is like a Turing machine, and the ATM problem is undecidable, so that might be a good first guess. And also, if you try to simulate them, if you try to figure out how you would go about simulating the machine, if given b and w, if you actually tried to simulate the machine to get the answer, so you run b on w, well, of course, if you run it for a while, and it eventually halts, either accepting or rejecting, then you know the answer and you're finished. But this machine might get into a loop. You know, nothing to prevent the machine from looping on that finite amount of-- on that limited amount of tape that it has. And then you might be in trouble. But in fact, that's not the case because when you start out with a limited amount of tape, if you run the machine for a long time and it's not halting, it's going and going and going, inevitably, it's going to have to repeat, get into exactly the same configuration that it did before because there's only a limited number of configurations that the machine has. And once it repeats a configuration, it's going to be repeating that configuration forever, and it's going to be in a loop. So this problem, in fact, is decidable because the idea is if b on w runs for a very long time and an amount that you can calculate, then you know it's got to be cycling. More than just looping. It's got to be repeating itself. And so therefore, once it starts repeating itself, it's going to be going forever. So and here is the actual calculation, which is something I'm sure you could do on your own, but just to spell it out. So if you have an input of length n that you're providing to b, so if w is of length n, the LBA can only go for this number of different-- it can only have this number of different configurations. The number of states times the number of head positions, which is n, the number of head positions on the tape, times the number of different tape contents. If the tape was only one long, this is the-- this is the size of the tape alphabet. So if the tape were two long, the tape had two cells on it, the number of possible tape contents would be the square of the alphabet. And if the tape is going to be n symbols long, it's going to be the tape alphabet size to the nth power. So therefore, if a Turing machine runs for longer, it's got to repeat some configuration, and it'll never hold. So the decider is going to be hopefully clear at this point. You're given b and w, so this is the decider for a LBA. It's going to run b on w for this number of steps. If it's accepted by then, then you accept, and if it hasn't, if it's rejected or it's still running, then you can reject. And you know, if it's still running at this point, it's never going to accept. All right. Any questions on this? OK, let's move on.","73.32987976074219","3","DPRSearchEngine","MGqoLm2aAgc.en-j3PyPqV-e1s_7_mp4","MGqoLm2aAgc.en-j3PyPqV-e1s","18.404J","10"
"110","What is the significance of using the big O notation in analyzing the time complexity of algorithms, particularly for a one tape Turing machine deciding a language like a^k b^k?"," 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
   
 
    
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
Linearly Bounded Automata 
Defn: A linearly bounded automaton (LBA) is a 1-tape TM 
that cannot move its head off the input portion of the tape. 
LBA 
a a b a a b a 
Tape size adjusts to length of input. 
Let !LBA = &, ( LBA & accepts ( } 
Theorem:  !LBA is decidable 
Proof: (idea) If & on ( runs for long, it must be cycling. 
Decider for !LBA: 
Claim: For inputs of length ), an LBA can have 
.A−LBA = “On input &, ( 
only * ×)× Γ - different configurations. 
1.  Let ) = |(|. 
Therefore, if an LBA runs for longer, it must repeat some 
2. Run & on ( for * ×)× Γ - steps. 
configuration and thus will never halt. 
3. If has accepted, accept. 
4. If it has rejected or is still running, reject.” 
must be looping 
7 
","73.32666015625","4","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_7_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"110","What is the significance of using the big O notation in analyzing the time complexity of algorithms, particularly for a one tape Turing machine deciding a language like a^k b^k?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","72.93182373046875","5","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"110","What is the significance of using the big O notation in analyzing the time complexity of algorithms, particularly for a one tape Turing machine deciding a language like a^k b^k?","which, I think, most of us would agree was not a very big number. And let's look what's going on here. If you look at this, what in some sense seems really stupid about it? What is it doing that a rational person would not want to do if they could avoid it? It's bad enough to do something once. But to do the same thing over and over again is really wasteful. And if we look at this, we'll see, for example, that fib 4 is being computed here, and fib 4 is being computed here. Fib 3 is being considered here, and here, and here. And do you think we'll get a different answer for fib 3 in one place when we get it in the other place? You sure hope not. So you think, well, what should we do about this? How would we go about avoiding doing the same work over and over again? And there's kind of an obvious answer, and that answer is at the heart of dynamic programming. What's the answer? AUDIENCE: [INAUDIBLE] JOHN GUTTAG: Exactly. And I'm really happy that someone in the front row answered the question because I can throw it that far. You store the answer and then look it up when you need it. Because we know that we can look things up very quickly. Dictionary, despite what Eric said in his lecture, almost all the time works in constant time if you make it big enough, and it usually is in Python. We'll see later in the term how to do that trick. So you store it and then you'd never have to compute it again. And that's the basic trick behind dynamic programming. And it's something called memoization, as in you create a memo and you store it in the memo. So we see this here. Notice that what we're doing is trading time for space. It takes some space to store the old results, but negligible related to the time we save. So here's the trick. We're going to create a table to record what we've done. And then before computing fib of x, we'll check if the value has already been computed. If so, we just look it up and return it. Otherwise, we'll compute it-- it's the first time-- and store it in the table. Here is a fast implementation of Fibonacci that does that. It looks like the old one, except it's got an extra argument-- memo-- which is a dictionary. The first time we call it, the memo will be empty. It tries to return the value in the memo. If it's not there, an exception will get raised, we know that.","72.82262420654297","6","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_9_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"110","What is the significance of using the big O notation in analyzing the time complexity of algorithms, particularly for a one tape Turing machine deciding a language like a^k b^k?","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","72.56385040283203","7","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"110","What is the significance of using the big O notation in analyzing the time complexity of algorithms, particularly for a one tape Turing machine deciding a language like a^k b^k?"," 
 
 
 
 
 
 
 
 
  
 
  
 
   
 
 
 
 
  
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Model Dependence 
Number of steps to decide ! = a#b# $ ≥0 depends on the model. 
• 1-tape TM: '() log )) 
• Multi-tape TM: '()) 
Computability theory: model independence (Church-Turing Thesis) 
Therefore model choice doesn’t matter. Mathematically nice. 
Complexity Theory: model dependence 
But dependence is low (polynomial) for reasonable deterministic models. 
We will focus on questions that do not depend on the model choice. 
So… we will continue to use the 1-tape TM as the basic model for complexity. 
6 
","72.52049255371094","8","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_6_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"110","What is the significance of using the big O notation in analyzing the time complexity of algorithms, particularly for a one tape Turing machine deciding a language like a^k b^k?","What's the worst case performance of a hash table? If I have to look up something in a hash table, and I happen to choose a bad hash table-- hash function, what's the worst case here? What? n, right? It's worse than a sorted array, because potentially, I hashed everything that I was storing to the same index in my hash table, and to be able to distinguish between them, I can't do anything more than a linear search. I could store another set's data structure as my chain and do better that way. That's actually how Java does it. They store a data structure we're going to be talking about next week as the chains so that they can get, worst case, log n. But in general, that hash table is only good if we're allowing-- OK, I want this to be expected good, but in the worst case, if I really need that operation to be worst case-- I really can't afford linear time ever for an operation of that kind-- then I don't want to use a hash table. And so on your p set 2, everything we ask you for is worst case, so probably, you don't want to be using hash tables. OK? Yes? AUDIENCE: What does the subscript e mean? JASON KU: What does the subscript e mean? That's great. In this chart, I put a subscript on this is an expected runtime, or an A meaning this is an amortized runtime. At the end, we talked about how, if we had too many things in our hash table, then, as long as we didn't do it too often-- this is a little hand wavey argument, but the same kinds of ideas as the dynamic array-- if, whenever we got a linear-- we are more than a linear factor away from where we are trying-- basically, the fill factor we were trying to be, then we could just completely rebuild the hash table with the new hash function randomly chosen from our hash table with a new size, and we could get amortized bounds. And so that's what Python-- how Python implements dictionaries, or sets, or even objects when it's trying to map keys to different things. So that's hash tables. That's great. The key thing here is, well, actually, if your range of keys is small, or if you as a programmer have the ability to choose the keys that you identify your objects with, you can actually choose that range to be small, to be linear, to be small with respect to your items. And you don't need a hash table. You can just use a direct access array, because if you know your key space is small, that's great. So a lot of C programmers probably would like to do something like that, because they don't have access to-- maybe C++ programmers would have access to their hash table. Any questions on this stuff before we move on? Yeah? AUDIENCE: So why is [INAUDIBLE]? JASON KU: Why is it expected? When I'm building, I could insert-- I'm inserting these things from x 1 by 1 into my hash table. Each of those insert operations-- I'm looking up to see whether that-- an item with that key already exists in my hash table. And so I have to look down the chain to see where it is. However, if I happen to know that all of my keys are unique in my input, all the items I'm trying to store are unique, then I don't have to do that check and I can get worst case linear time. Does that make sense? All right. It's a subtlety, but that's a great question. OK, so today, instead of talking about searching, we're talking about sorting. Last week, we saw a few ways to do sort. Some of them were quadratic-- insertion sort and selection sort-- and then we had one that was n log n. And this thing, n log n, seemed pretty good, but can I do better? Can I do better? Well, what we're going to show at the beginning of this class is, in this comparison model, no. n log n is optimal. And we're going to go through the exact same line of reasoning that we had last week. So in the comparison model, what did we use when we were trying to make this argument that any comparison model algorithm was going to take at least log n time? What we did was we said, OK, I can think of any model in the comparison model-- any algorithm in the comparison model as kind of this-- some comparisons happen. They branch in a binary sense, but you could have it generalized to any constant branching factor. But for our purposes, binary's fine. And what we said was that there were at least n outputs-- really n plus 1, but-- at least order n outputs. And we showed that-- or we argued to you that the height of this tree had to be at least log n-- log the number of leaves. It had to be at least log the number of leaves. That was the height of the decision tree. And if this decision tree represented a search algorithm, I had to walk down and perform these comparisons in order, reach a leaf where I would output something. If the minimum height of any binary tree on a linear number of leaves is log n, then any algorithm in the comparison model also has to take log n time, because it has to do that many comparisons to differentiate between all possible outputs. Does that make sense? All right. So in the sort problem, how many possible outputs are there?","72.50464630126953","9","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_4_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"110","What is the significance of using the big O notation in analyzing the time complexity of algorithms, particularly for a one tape Turing machine deciding a language like a^k b^k?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","72.2685775756836","10","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"112","What happens to the size of the QBF at each recursive level?","§ Problem is exponen<al 
§ Have we overturned the laws of the universe? 
§ Is dynamic programming a miracle? 
§ No, but computa<onal complexity can be subtle 
§ Running <me of fastMaxVal is governed by number of 
dis<nct pairs, <toConsider, avail> 
◦Number of possible values of toConsider bounded 
by len(items)
◦Possible values of avail a bit harder to characterize 
◦Bounded by number of dis<nct sums of weights 
◦Covered in more detail in assigned reading 
How Can This Be? 
6.0002 LECTURE 2 
30 
","74.53414916992188","1","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_30_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"112","What happens to the size of the QBF at each recursive level?","As we see in this tree, for the example we just saw, the box is around a place where we're actually solving the same problem, even though we've made different decisions about what to take, A versus B. And in fact, we have different amounts of value in the knapsack-- 6 versus 7. What matters is we still have C and D to consider and we have two units left. It's a small and easy step. I'm not going to walk you through the code because it's kind of boring to do so. How do you modify the maxVal we looked at before to use a memo? First, you have to add the third argument, which is initially going to be set to the empty dictionary. The key of the memo will be a tuple-- the items left to be considered and the available weight. Because the items left to be considered are in a list, we can represent the items left to be considered by how long the list is. Because we'll start at the front item and just work our way to the end. And then the function works, essentially, exactly the same way fastFib worked. I'm not going to run it for you because we're running out of time. You might want to run it yourself because it is kind of fun to see how really fast it is.","73.63325500488281","2","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_13_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"112","What happens to the size of the QBF at each recursive level?","Header for Decision Tree Implementa#on 
6.0002 LECTURE 2 
9 
def maxVal(toConsider, avail): 
    """"""Assumes toConsider a list of items,  
               avail a weight 
       Returns a tuple of the total value of a  
           solution to 0/1 knapsack problem and  
           the items of that solution""""” 
toConsider. Those items that nodes higher up in the tree 
(corresponding to earlier calls in the recursive call stack) 
have not yet considered 
 
avail. The amount of space still available  
","73.33504486083984","3","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_9_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"112","What happens to the size of the QBF at each recursive level?"," 
 
 
 
 
 
Class Field, continued  
def moveDrunk(self, drunk):  
if drunk not in self.drunks:  
raise ValueError('Drunk not in field')  
xDist, yDist = drunk.takeStep()  
#use move method of Location to get new location  
self.drunks[drunk] =\\  
self.drunks[drunk].move(xDist, yDist)  
Immutable or not? 
6.0002  LECTURE 5 
19 
","73.15514373779297","4","DPRSearchEngine","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_19_pdf","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5","6.0002","5"
"112","What happens to the size of the QBF at each recursive level?","3F)$%%%!G%H""?%!
!%%%%!%%)
*!!!%!4
# 
!I!7$18
2/
&)+
	

;
","73.0687255859375","5","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_29_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"112","What happens to the size of the QBF at each recursive level?"," 
 
 
 
 
 
 
 
 
   
 
 
  
 
 
 
 
 
 
 
  
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
Constructing !"",$: 3rd try 
!34, 35, 6 = ∃89:; !34, 3<=>, 6/2 ∧ !3<=>, 35, 6/2 
, , J
Check-in 18.3 
Would this construction still work if N were 
nondeterministic? 
(a) Yes. 
(b) No. 
∀(K ∈L) M
∀ 8B, 8C ∈ 
8E, 89:; , 89:;, 8F 
!3G, 3H, 6/2 
is equivalent to 
⋮ 
∀K K ∈L 
M
!"",$ = !3OPQRP, 3QSSTUP, V 
! 
defined as in Cook-Levin 
/
W = - . 
Size analysis: 
Each recursive level adds %('() to the QBF. 
Number of levels is log - ./ = % '( . 
→ Size is % 
'2( 
•
'(×'( = % 
9 
Check-in 18.3 
","72.9889144897461","6","DPRSearchEngine","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18_9_pdf","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18","18.404J","18"
"112","What happens to the size of the QBF at each recursive level?","to this interface problem-- the natural solution-- is what I'll call a static array. Jason mentioned these in lecture one. It's a little tricky because there are no static arrays in Python. There are only dynamic arrays, which is something we will get to. But I want to talk about, what is a static array, really? And this relates to our notion of-- our model of computation, Jason also talked about, which we call the word RAM, remember? The idea, in word RAM, is that your memory is an array of w-bit words. This is a bit circular. I'm going to define an array in terms of the word RAM, which is defined in terms of arrays. But I think you know the idea. So we have a big memory which goes off to infinity, maybe. It's divided into words. Each word here is w bits long. This is word 0, word 1, word 2. And you can access this array randomly-- random access memory. So I can give you the number 5 and get 0 1, 2, 3, 4, 5, the fifth word in this RAM. That's how actual memories work. You can access any of them equally quickly. OK, so that's memory. And so what we want to do is, when we say an array, we want this to be a consecutive chunk of memory. Let me get color. Let's say I have an array of size 4 and it lives here. Jason can't spell, but I can't count. So I think that's four. We've got-- so the array starts here and it ends over here. It's of size 4. And it's consecutive, which means, if I want to access the array at position-- at index i, then this is the same thing as accessing my memory array at position-- wherever the array starts, which I'll call the address of the array-- in Python, this is ID of array-- plus i. OK. This is just simple offset arithmetic. If I want to know the 0th item of the array, it's right here, where it starts. The first item is one after that. The second item is one after that. So as long as I store my array consecutively in memory, I can access the array in constant time. I can do get_at and set_at as quickly as I can randomly access the memory and get value-- or set a value-- which we're assuming is constant time. My array access is constant time. This is what allows a static array to actually solve this problem in constant time per get_at and set_at operation. This may seem simple, but we're really going to need this model and really rely on this model increasingly as we get to more interesting data structures. This is the first time we're actually needing it. Let's see. Length is also constant time. We're just going to store that number n, along with its address. And build is going to take linear time. Iteration will take linear time. Pretty straightforward. I guess one thing here, when defining build, I need to introduce a little bit more of our model of computation, which is, how do you create an array in the beginning? I claim I could do it in linear time, but that's just part of the model. This is called the memory allocation model. There are a few possible choices here, but the cleanest one is just to assume that you can allocate an array of size n in theta n time. So it takes linear time to make an array of size n. You could imagine this being constant. It doesn't really matter much. But it does take work. And in particular, if you just allocate some chunk of memory, you have no idea whether it's initialized. So initializing that array to 0s will cost linear time. It won't really matter, constant versus linear, but a nice side effect of this model is that space-- if you're just allocating arrays, the amount of space you use is, at most, the amount of time you use. Or, I guess, big O of that. So that's a nice feature. It's pretty weird if you imagine-- it's unrealistic to imagine you can allocate an array that's infinite size and then just use a few items out of it. That won't give you a good data structure. So we'll assume it costs to allocate memory. OK, great. We solved the sequence problem. Very simple, kind of boring. These are optimal running times. Now, let's make it interesting-- make sure I didn't miss anything--","72.83428192138672","7","DPRSearchEngine","CHhwJjR0mZA.en-j3PyPqV-e1s_3_mp4","CHhwJjR0mZA.en-j3PyPqV-e1s","6.006","2"
"112","What happens to the size of the QBF at each recursive level?","§ 1. Enumerate all possible combina<ons of items. 
§ 2. Remove all of the combina<ons whose total units 
exceeds the allowed weight. 
§ 3. From the remaining combina<ons choose any one 
whose value is the largest. 
Brute Force Algorithm 
6.0002 LECTURE 2 
4 
","72.72921752929688","8","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_4_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"112","What happens to the size of the QBF at each recursive level?"," 
  
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
New in  Code  
§numpy.std is function in the numpy module that
returns the standard deviation
§random.sample(population, sampleSize) returns a list
containing sampleSize randomly chosen distinct
elements of population
◦Sampling without replacement
6.0002  LECTURE 8 
 
8
","72.68058013916016","9","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_8_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"112","What happens to the size of the QBF at each recursive level?","
0	
@)
 
numSubsets = 10 
dimensions = (1, 2, 3, 4) 
rSquares = {} 
for d in dimensions: 
    rSquares[d] = [] 
	

?@
","72.47723388671875","10","DPRSearchEngine","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10_45_pdf","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10","6.0002","10"
"114","Why is the language A_CFG decidable?"," 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
18.404/6.840 Lecture 4 
Last time: 
- Finite automata → regular expressions 
- Proving languages aren’t regular 
- Context free grammars 
Today: (Sipser §2.2) 
- Context free grammars (CFGs) – definition 
- Context free languages (CFLs) 
- Pushdown automata (PDA) 
- Converting CFGs to PDAs 
1 
","73.08748626708984","1","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_1_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"114","Why is the language A_CFG decidable?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
18.404/6.840 Lecture 5 
Last time: 
- Context free grammars (CFGs) 
- Context free languages (CFLs) 
- Pushdown automata (PDA) 
- Converting CFGs to PDAs 
Today: (Sipser §2.3, §3.1) 
- Proving languages not Context Free 
- Turing machines 
- T-recognizable and T-decidable languages 
1 
","72.50691986083984","2","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_1_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"114","Why is the language A_CFG decidable?"," 
 
 
  
 
 
 
  
 
 
   
 
 
 
 
 
 
  
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
Theorem: 0123(CFG is NOT decidable
Proof: Homework.
Equivalence Problem for CFGs 
Let !""CFG = { (, * | (, * are CFGs and , ( = ,(*) } 
Theorem: !""CFG is NOT decidable 
Proof: Next week. 
Let 0123(CFG = { ( | ( is an ambiguous CFG } 
Check-in 7.3 
Why can’t we use the same technique we used to show !""DFA is decidable 
to show that !""CFG is decidable? 
a) Because CFGs are generators and DFAs are recognizers. 
b) Because CFLs are closed under union. 
c) 
Because CFLs are not closed under complementation and intersection. 
Check-in 7.3 
9 
","71.22491455078125","3","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_9_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"114","Why is the language A_CFG decidable?"," 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
18.404/6.840 Lecture 8 
Last time: 
- Decision procedures for automata and grammars
!DFA , !NFA , &DFA , &'DFA , !CFG , &CFG are decidable 
!TM is T-recognizable 
Today: (Sipser §4.2) 
- !TM is undecidable 
- The diagonalization method 
- !TM is T-unrecognizable 
- The reducibility method 
- Other undecidable languages 
1 
","71.15373229980469","4","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_1_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"114","Why is the language A_CFG decidable?","   
  
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
  
    
 
 
 
  
 
 
 
 
 
 
 
 
Converting CFGs to PDAs (contd) 
Theorem: If ! is a CFL then some PDA recognizes ! 
Proof construction:  Convert the CFG for ! to the following PDA. 
1) Push the start symbol on the stack. 
2) If the top of stack is 
Variable: replace with right hand side of rule (nondet choice). 
Terminal: pop it and match with next input symbol. 
3) If the stack is empty, accept. 
a
+
a
×
a
Example: 
E
E
F
T
a 
+ 
T
T 
+
+
+
+
T 
× 
T
T
T
T 
F 
9 
#$ 
E → E+T | T 
T → T×F | F 
F → ( E ) | a 
E
E 
E+T 
E + T  
T+T×F 
T T × F 
F+F×a 
F 
F
a 
a+a×a 
a
a
a 
","70.76873779296875","5","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_9_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"114","Why is the language A_CFG decidable?"," 
 
 
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
  
 
  
 
  
 
 
  
 
 
   
 
 
   
 
 
 
 
TMs and Encodings – review 
A TM has 3 possible outcomes for each input !: 
1. Accept ! (enter ""acc ) 
2. Reject ! by halting (enter ""rej ) 
3. Reject ! by looping (running forever) 
( is T-recognizable if ( = *(,) for some TM ,. 
( is T-decidable if ( = *(,) for some TM decider ,. 
halts on all inputs 
〈/0, /2, … , /4〉 encodes objects /0, /2, … , /4 as a single string. 
Notation for writing a TM , is 
, = “On input ! 
[English description of the algorithm]” 
2 
","70.20823669433594","6","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_2_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"114","Why is the language A_CFG decidable?"," 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
18.404/6.840 Lecture 10 
Last time: 
- The Reducibility Method for proving undecidability 
and T-unrecognizability 
- General reducibility 
- Mapping reducibility 
Today: (Sipser §5.2) 
- The Computation History Method for proving undecidability 
- The Post Correspondence Problem is undecidable 
- Linearly bounded automata 
- Undecidable problems about LBAs and CFGs 
1 
","70.16960144042969","7","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_1_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"114","Why is the language A_CFG decidable?"," 
 
 
   
  
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
  
 
 
 
 
  
 
  
 
 
 
 
  
 
 
 
 
 
 
  
  
 
 
 
 
  
  
 
  
    
 
 
 
 
 
 
 
 
 
 
 
Converting CFGs to PDAs 
Theorem: If ! is a CFL then some PDA recognizes ! 
Proof: Convert !’s CFG to a PDA 
…
E → E+T | T 
PDA 
T → … 
F → … 
CFG 
$% 
E → E+T | T 
IDEA: PDA begins with starting variable and guesses substitutions. 
T → T×F | F
It keeps intermediate generated strings on stack. When done, compare with input. 
F → ( E ) | a
E
E 
T 
T 
Input: 
a
+
a
×
a
+
+ 
+ 
E 
E
T
T 
T 
× 
E+T 
E +  T  
F 
T+T×F 
T T × F 
Problem! Access below the top of stack is cheating! 
F+F×a 
F 
F
a
Instead, only substitute variables when on the top of stack. 
a+a×a 
a
a
a
If a terminal is on the top of stack, pop it and compare with input. Reject if ≠. 
8 
","70.08101654052734","8","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_8_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"114","Why is the language A_CFG decidable?"," 
 
 
  
  
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
    
  
 
 
 
 
 
  
 
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
S 
a
R 
T 
a
Emptiness Problem for CFGs 
Let !CFG = { ' | ' is a CFG and ) ' = ∅} 
Theorem: !CFG is decidable 
Proof: 
,E−CFG = “On input ' 
[IDEA: work backwards from terminals] 
1. Mark all occurrences of terminals in '. 
S → RTa
2. Repeat until no new variables are marked 
R → 
R
Tb
Tb
Mark all occurrences of variable A if 
A → B1B2 ⋯ B4 is a rule and all B5 were already marked. 
T → a 
3. 
Reject if the start variable is marked. 
Accept if not.” 
8 
","69.41590881347656","9","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_8_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"114","Why is the language A_CFG decidable?"," 
 
 
 
 
 
  
  
 
 
 
 
  
 
 
 
 
 
 
    
 
 
 
 
 
 
 
 
 
 
 
 
Ambiguity 
!"" E → E+T | T 
T → T×F | F 
F → ( E ) | a 
!# E → E+E | E×E | ( E ) | a 
E 
E 
E
Both !"" and !# recognize the same language, i.e., $ !"" = $ !# . 
However !"" is an unambiguous CFG and !# is ambiguous. 
E 
E 
a + a × a 
E
E 
E
E 
E 
5 
","69.35198974609375","10","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_5_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"115","Explain why a negative weight cycle in a graph could result in no finite shortest path between two vertices connected to the cycle."," 
 
 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) 
General Unweighted 
BFS 
|V | + |E|
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Non-negative Dijkstra 
Bellman-Ford 
|V | log |V | + |E|
General Any 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 14: Johnson’s Algorithm 
Lecture 14: Johnson’s Algorithm 
Previously 
|V | · |E| 
All-Pairs Shortest Paths (APSP) 
• Input: directed graph G = (V, E) with weights w : E → Z 
• Output: δ(u, v) for all u, v ∈ V , or abort if G contains negative-weight cycle 
• Useful when understanding whole network, e.g., transportation, circuit layout, supply chains... 
• Just doing a SSSP algorithm |V | times is actually pretty good, since output has size O(|V |2) 
– |V | · O(|V | + |E|) with BFS if weights positive and bounded by O(|V | + |E|) 
– |V | · O(|V | + |E|) with DAG Relaxation if acyclic 
– |V | · O(|V | log |V | + |E|) with Dijkstra if weights non-negative or graph undirected 
– |V | · O(|V | · |E|) with Bellman-Ford (general) 
• Today: Solve APSP in any weighted graph in |V | · O(|V | log |V | + |E|) time 
","77.83842468261719","1","DPRSearchEngine","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14_1_pdf","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14","6.006","14"
"115","Explain why a negative weight cycle in a graph could result in no finite shortest path between two vertices connected to the cycle.","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","76.75337219238281","2","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"115","Explain why a negative weight cycle in a graph could result in no finite shortest path between two vertices connected to the cycle."," 
 
 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) Lecture 
General Unweighted 
BFS 
|V | + |E| L09 
L11 
L12 
L13 (Today!) 
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Any 
Bellman-Ford 
Dijkstra 
|V | · |E|
General Non-negative 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 13: Dijkstra’s Algorithm 
Lecture 13: Dijkstra’s Algorithm 
Review 
• Single-Source Shortest Paths on weighted graphs 
• Previously: O(|V | + |E|)-time algorithms for small positive weights or DAGs 
• Last time: Bellman-Ford, O(|V ||E|)-time algorithm for general graphs with negative weights 
• Today: faster for general graphs with non-negative edge weights, i.e., for e ∈ E, w(e) ≥ 0 
|V | log |V | + |E| 
Non-negative Edge Weights 
• Idea! Generalize BFS approach to weighted graphs: 
– Grow a sphere centered at source s 
– Repeatedly explore closer vertices before further ones 
– But how to explore closer vertices if you don’t know distances beforehand? 
:( 
• Observation 1: If weights non-negative, monotonic distance increase along shortest paths 
– i.e., if vertex u appears on a shortest path from s to v, then δ(s, u) ≤ δ(s, v) 
– Let Vx ⊂ V be the subset of vertices reachable within distance ≤ x from s 
– If v ∈ Vx, then any shortest path from s to v only contains vertices from Vx 
– Perhaps grow Vx one vertex at a time! (but growing for every x is slow if weights large) 
• Observation 2: Can solve SSSP fast if given order of vertices in increasing distance from s 
– Remove edges that go against this order (since cannot participate in shortest paths) 
– May still have cycles if zero-weight edges: repeatedly collapse into single vertices 
– Compute δ(s, v) for each v ∈ V using DAG relaxation in O(|V | + |E|) time 
","74.87640380859375","3","DPRSearchEngine","d819e7f4568aced8d5b59e03db6c7b67_MIT6_006S20_lec13_1_pdf","d819e7f4568aced8d5b59e03db6c7b67_MIT6_006S20_lec13","6.006","13"
"115","Explain why a negative weight cycle in a graph could result in no finite shortest path between two vertices connected to the cycle."," 
 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) Lecture 
General Unweighted 
BFS 
|V | + |E| L09 
L11 
L12 (Today!) 
L13 
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Any 
Bellman-Ford 
Dijkstra 
|V | · |E|
General Non-negative 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 12: Bellman-Ford 
Lecture 12: Bellman-Ford 
Previously 
• Weighted graphs, shortest-path weight, negative-weight cycles 
• Finding shortest-path tree from shortest-path weights in O(|V | + |E|) time 
• DAG Relaxation: algorithm to solve SSSP on a weighted DAG in O(|V | + |E|) time 
• SSSP for graph with negative weights 
– Compute δ(s, v) for all v ∈ V (−∞ if v reachable via negative-weight cycle) 
– If a negative-weight cycle reachable from s, return one 
Warmups 
• Exercise 1: Given undirected graph G, return whether G contains a negative-weight cycle 
• Solution: Return Yes if there is an edge with negative weight in G in O(|E|) time 
:O 
• So for this lecture, we restrict our discussion to directed graphs 
• Exercise 2: Given SSSP algorithm A that runs in O(|V |(|V | + |E|) time, 
show how to use it to solve SSSP in O(|V ||E|) time 
• Solution: Run BFS or DFS to ﬁnd the vertices reachable from s in O(|E|) time 
– Mark each vertex v not reachable from s with δ(s, v) = ∞ in O(|V |) time 
– Make graph G0 = (V 0, E0) with only vertices reachable from s in O(|V | + |E|) time 
– Run A from s in G0 . 
– G0 is connected, so |V 0| = O(|E0|) = O(|E|) so A runs in O(|V ||E|) time 
• Today, we will ﬁnd a SSSP algorithm with this running time that works for general graphs! 
|V | log |V | + |E| 
","74.74506378173828","4","DPRSearchEngine","2430d7903a5529451d80c17f89a41fe8_MIT6_006S20_lec12_1_pdf","2430d7903a5529451d80c17f89a41fe8_MIT6_006S20_lec12","6.006","12"
"115","Explain why a negative weight cycle in a graph could result in no finite shortest path between two vertices connected to the cycle.","And that's cycle detection. So there's a bit of an exercise left to the reader here. So the problem that we're looking for now is that we're given a directed graph. There's a G in graph, in case you're wondering. But now, we don't know if it's a DAG or not. And so the question that we're trying to ask is, does there exist a cycle in our directed acyclic graph? So we're just given our graph, and we want to know, can we do this? Let's think through the logic of this a bit. So what do we know? We know that if our graph were a DAG, then I could call DGS, get the ordering out, and then I guess flip its ordering backwards. So I could compute the reverse finishing order. And it would give me a topological order of my graph. So if I were a DAG, I would get a topological order when I call DFS. So let's say that I ran DFS. I got whatever ordering I got. And now I found an edge the points in the wrong direction. I can just double check my list of edges, and I find one that does not respect the relationship that I see in the second bullet point here. Can my graph be a DAG? No. Because if my graph were a DAG, the algorithm would work. I just proved it to you. Right? So if my graph were a DAG, then I could do reverse finishing order. And what I would get back is a topological order. So if I found a certificate that my order wasn't topological, something went wrong, and the only thing that could go wrong is that my graph isn't a DAG. Yeah. Isn't a DAG. In fact, sort of an exercise left to the reader and/or to your section-- do we still have section? I think we do, as of now-- is that this is an if and only if, meaning that the only time that you even have a topological ordering in your graph is if your graph is a DAG. This is a really easy fact to sanity check, by the way. This is not like, a particularly challenging problem. But you should think through it because it's a good exercise to make sure you understand the definitions, which is to say that if you have a topological order, your graph is a DAG. If you don't have a topological order, your graph isn't a DAG. So in other words, we secretly gave you an algorithm for checking if a graph is a DAG at all. Right? What could I do? I could compute reverse finishing order. Check if it obeys the relationship on the second bullet point here for every edge. And if it does, then we're in good shape. My graph is a DAG. If it doesn't, something went wrong. And the only thing that could have gone wrong is not being a DAG. OK. So in other words, secretly we just solved-- well, I guess the way that I've written it here, we've solved the cycle detection problem here, which is to say that, well, I have a cycle if and only if I'm not a DAG, which I can check using this technique. Of course, the word ""detection"" here probably means that I actually want to find that cycle, and I haven't told you how to do that yet. All we know how to do so far is say, like, somewhere in this graph there's a cycle. And that's not so good. So we can do one additional piece of information in the two minutes we have remaining to sort of complete our story here, which is to modify our algorithm ever so slightly to not only say thumbs up, thumbs down, is there a cycle in this graph, but also to actually return the vertices as a cycle. And here's the property that we're going to do that, which is following, which is that if G contains a cycle, right, then full DFS will traverse an edge from a vertex v to some ancestor of v. I guess we haven't carefully defined the term ""ancestor"" here. Essentially, if you think of the sort of the running of the DFS algorithm, then an ancestor is like something that appears in the recursive call tree before I got to v. OK. So how could we prove that? Well, let's take a cycle. And we'll give it a name. In particular, we'll say that it's a cycle from v0 v1 to vk. And then it's a cycle, so it goes back to v0. OK. And I can order this cycle any way I want. Notice that if I permute the vertices in this list in a cyclical way, meaning that I take the last few of them and stick them at the beginning of the list, it's still a cycle. That's the nice thing about cycles. So in particular, without loss of generality, we're going to assume that v0 is the first vertex visited by DFS. What does that mean? That means, like, when I do my DFS algorithm making all these recursive calls, the very first vertex to be touched by this technique is v0. OK. Well, now what's going to end up happening? Well, think about the recursive call tree starting at v0. By the time that completes, anything that's reachable from v0 is also going to be complete. Do you see that? So for instance, v0 somewhere in its call tree might call v2. And notice that v2 was not already visited. So in fact, it will. For v1 I got to call v2 and so on. And in particular, we're going to get all the way to vertex k. Right? So in other words, we're going to visit a vertex vk. And notice what's going to happen. So remember our algorithm. In fact, we should probably just put it up on the screen would be easier than talking about it a bunch. Well, vk is now going to iterate over every one of the neighbors of vk. And in particular, it's going to see vertex v0. Right? So we're going to see the edge from vk to v0, which is an edge kind of by definition because we took this to be a cycle here. But notice that's exactly the thing we set out to prove, namely that full DFS traverses an edge from a vertex to one of its ancestors. Here's a vertex k. Here's the ancestor v0. Why do we know that it's an ancestor? Well, because v0 was called in our call tree before any of these other guys. Right? So we wanted an algorithm that not only did cycle detection, but also actually gave me the cycle. What could I do? Well, it's essentially a small modification of what we already have. Right. So-- whoops. Right. If I want to compute topological order or whatever, I can just do DFS. And that'll tell me like, yay or nay, does there exist a cycle. If I want to actually find that cycle, all I have to do is check that topological order property at the same time that it traversed the graph during DFS. And the second that I find an edge that loops back, I'm done. And so that's our basic algorithm here. And this is a technique for actually just finding the cycle in a graph using the DFS algorithm.","73.51725769042969","5","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_20_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"115","Explain why a negative weight cycle in a graph could result in no finite shortest path between two vertices connected to the cycle.","There's not a bound on the number of edges for a shortest path, because I could just keep going around that cycle as many times as I want and get a shorter path. And so we assign those distances to be minus infinity. So that's what we're going to do today in Bellman-Ford. In particular, what we're going to do is compute our shortest path distances, the shortest path waits for every vertex in our graph, setting the ones that are not reachable to infinity, and the ones that are reachable through a negative weight cycle to minus infinity, and all other ones we're going to set to a finite weight. And another thing that we might want is if there's a negative weight cycle in the graph, let's return one. So those are the two kinds of things that we're trying to solve in today's lecture. But before we do that, let's warm up with two short exercises. The first one, exercise 1, given an undirected graph, given undirected graph G, return whether G contains a negative weight cycle. Anyone have an idea of how we can solve this in linear time, actually? In fact, we can do it in order E. No-- yes, yes. Reachable from S. I guess-- let's just say a negative weight cycle at all. Not in the context of single-source shortest paths.","73.5140380859375","6","DPRSearchEngine","f9cVS_URPc0.en-j3PyPqV-e1s_3_mp4","f9cVS_URPc0.en-j3PyPqV-e1s","6.006","12"
"115","Explain why a negative weight cycle in a graph could result in no finite shortest path between two vertices connected to the cycle.","single source shortest paths in linear time. Last time we discussed another linear time algorithm, DAG relaxation. And today we're going to be talking about Bellman-Ford, which isn't limited to asymptotic graphs. In particular, there could be negative weight cycles in our graph. If it has cycles, if it has negative weights, the worry is that we could have negative weight cycles, in which case there-- if a negative weight cycle is reachable from our source, then the vertices in that cycle and anything reachable from that cycle will potentially","73.50672149658203","7","DPRSearchEngine","f9cVS_URPc0.en-j3PyPqV-e1s_2_mp4","f9cVS_URPc0.en-j3PyPqV-e1s","6.006","12"
"115","Explain why a negative weight cycle in a graph could result in no finite shortest path between two vertices connected to the cycle.","2 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) Lecture 
General Unweighted 
BFS 
|V | + |E| L09 
L11 (Today!) 
L12 
L13 
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Any 
Bellman-Ford 
Dijkstra 
|V | · |E|
General Non-negative 
Lecture 11: Weighted Shortest Paths 
Weighted Paths 
• The weight w(π) of a path π in a weighted graph is the sum of weights of edges in the path 
• The (weighted) shortest path from s ∈ V to t ∈ V is path of minimum weight from s to t 
• δ(s, t) = inf{w(π) | path π from s to t} is the shortest-path weight from s to t 
• (Often use “distance” for shortest-path weight in weighted graphs, not number of edges) 
• As with unweighted graphs: 
– δ(s, t) = ∞ if no path from s to t 
– Subpaths of shortest paths are shortest paths (or else could splice in a shorter path) 
• Why inﬁmum not minimum? Possible that no ﬁnite-length minimum-weight path exists 
• When? Can occur if there is a negative-weight cycle in the graph, Ex: (b, f, g, c, b) in G1 
• A negative-weight cycle is a path π starting and ending at same vertex with w(π) < 0 
• δ(s, t) = −∞ if there is a path from s to t through a vertex on a negative-weight cycle 
• If this occurs, don’t want a shortest path, but may want the negative-weight cycle 
Weighted Shortest Paths Algorithms 
• Next four lectures: algorithms to ﬁnd shortest-path weights in weighted graphs 
• (No parent pointers: can reconstruct shortest paths tree in linear time after. Next page!) 
• Already know one algorithm: Breadth-First Search! Runs in O(|V | + |E|) time when, e.g.: 
– graph has positive weights, and all weights are the same 
– graph has positive weights, and sum of all weights at most O(|V | + |E|) 
• For general weighted graphs, we don’t know how to solve SSSP in O(|V | + |E|) time 
• But if your graph is a Directed Acyclic Graph you can! 
|V | log |V | + |E| 
","73.19770050048828","8","DPRSearchEngine","aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11_2_pdf","aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11","6.006","11"
"115","Explain why a negative weight cycle in a graph could result in no finite shortest path between two vertices connected to the cycle.","It's not really complicated. Instead of having a single source, we are essentially wanting to, given an input-- this is our weighted graph, where we've got a graph V, E, and we've got a weight function from the edges to the integers. This is our general weighted graph. We want our output to be something like, the shortest path distance from u to v for every u and v in our vortex set. That's what we want to return. Now, there's one caveat here that, if there's a negative weight cycle in our graph-- in other words, if any of these delta u, v's is minus infinity,","73.18199157714844","9","DPRSearchEngine","EmSmaW-ud6A.en-j3PyPqV-e1s_2_mp4","EmSmaW-ud6A.en-j3PyPqV-e1s","6.006","14"
"115","Explain why a negative weight cycle in a graph could result in no finite shortest path between two vertices connected to the cycle."," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 11: Weighted Shortest Paths 
Lecture 11: Weighted Shortest Paths 
Review 
• Single-Source Shortest Paths with BFS in O(|V | + |E|) time (return distance per vertex) 
• Single-Source Reachability with BFS or DFS in O(|E|) time (return only reachable vertices) 
• Connected components with Full-BFS or Full-DFS in O(|V | + |E|) time 
• Topological Sort of a DAG with Full-DFS in O(|V | + |E|) time 
• Previously: distance = number of edges in path Today: generalize meaning of distance 
Weighted Graphs 
• A weighted graph is a graph G = (V, E) together with a weight function w : E → Z 
• i.e., assigns each edge e = (u, v) ∈ E an integer weight: w(e) = w(u, v) 
• Many applications for edge weights in a graph: 
– distances in road network 
– latency in network connections 
– strength of a relationship in a social network 
• Two common ways to represent weights computationally: 
– Inside graph representation: store edge weight with each vertex in adjacency lists 
– Store separate Set data structure mapping each edge to its weight 
• We assume a representation that allows querying the weight of an edge in O(1) time 
Examples 
G1 
G2 
a 
e 
b 
f 
c 
g 
d 
h 
6 
8 
−2 
5 
9 
−5 
7 
3 
2 
−1 
−4 
1 
4 
a 
e 
b 
f 
c 
g 
d 
h 
6 
8 
−2 
5 
9 
−5 
7 
3 
2 
−1 
−4 
1 
4 
","73.1812515258789","10","DPRSearchEngine","aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11_1_pdf","aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11","6.006","11"
"116","What is the purpose of right and left rotations in binary trees, and why is it important to maintain traversal order during these operations?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","72.84654235839844","1","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"116","What is the purpose of right and left rotations in binary trees, and why is it important to maintain traversal order during these operations?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","72.40665435791016","2","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"116","What is the purpose of right and left rotations in binary trees, and why is it important to maintain traversal order during these operations?","namely, random accessing. And if we stored the things that we're looking for, we have unique keys, and those keys are integers. Then, if I have an item with key K, if I store it at index K in my array, then I can find it and manipulate it in constant time.","70.43247985839844","3","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_2_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"116","What is the purpose of right and left rotations in binary trees, and why is it important to maintain traversal order during these operations?","If you think about it a little bit, this is exactly binary search on an array. It just happens to be on a tree instead. If you think of an array like this, what does binary search do? It first looks at the key in the middle. I'm going to draw that as the root. And then, it recurses either on the left chunk, which I will draw recursively, or on the right chunk. And so if you happen to have a perfect binary tree like this one, it is simulating exactly binary search in this array. But this we're going to be able to maintain dynamically-- not perfect any more, but close. Whereas this we could not maintain in sorted order. So this is like a generalization of binary search to work on trees instead of on arrays. And for this reason, set binary trees are called binary search trees, because they're the tree version of binary search. So there's many equivalent names. So binary search tree is another name for set binary tree. And the key thing that makes this algorithm work is the so-called binary search tree property, which is all the keys in the left subtree of a node are less than the root, or of that node, and that key is less than all the keys in the right subtree. And this is true recursively all the way down. And so that's how you prove that this algorithm is correct by this property. Why is this true? Because if we can maintain traversal order to be increasing key, then that's exactly what traversal order means. It tells you all the things in the left subtree come before the root, which come before all the things in the right subtree.","70.15641021728516","4","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_4_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"116","What is the purpose of right and left rotations in binary trees, and why is it important to maintain traversal order during these operations?","I'll call them left justified. And these two properties together is what I call a complete binary tree. Why is this interesting? Because I claim I can represent a tree like this as an array. I've narrowed things down enough that I can draw an array down here. And what I'm going to do is write these nodes in depth order. So I write A first, because that's step 0. Then B, C, that's step 1. Then, well, they're alphabetical. I made it that way. D, E, F, G is depth 2. And then H, I, J is step 3. This is very different from traversal order of a tree. Traversal order would have been H, D, I, B, J, E, A, F, C, G, OK? But this is what we might call depth order, do the lowest depth nodes first-- very different way to lay things out or to linearize our data. And this is what a heap is going to look like. So the cool thing is, between complete binary trees and arrays is a bijection. For every array, there's a unique complete binary tree. And for every complete binary tree, there's a unique array. Why? Because the complete constraint forces everything-- forces my hand. There's only-- if I give you a number n, there is one tree shape of size n, right? You just fill in the nodes top down until you get to the last level. And then you have to fill them in left to right. It's what you might call reading order for writing down nodes. And the array is telling you which keys go where. This is the first node you write down at the root, this is the next node you write down at the left child of the root, and so on. So here we have a binary tree represented as an array, or array representing a binary tree. The very specific binary tree, it has a clear advantage, which is it is guaranteed balance. No rotations necessary in heaps, because complete binary trees are always balanced. In fact, they have the best height they possibly could, which is ceiling of log n. Balanced, remember, just meant you were big O of log n. This is 1 times log n. So it's the best level of balance you could hope for. So somehow, I claim, we can maintain a complete binary tree for solving priority queues. This would not be possible if you were trying to solve the whole set interface. And that's kind of the cool thing about heaps, is that by just focusing on the subset of the set interface, we can do more. We can maintain this very strong property. And because we have this very strong property, we don't even need to store this tree. We're not going to store left and right pointers and parent pointers, we're just going to store the array.","69.63552856445312","5","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_8_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"116","What is the purpose of right and left rotations in binary trees, and why is it important to maintain traversal order during these operations?"," 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 7: Binary Trees II: AVL 
Lecture 7: Binary Trees II: AVL 
Last Time and Today’s Goal 
Sequence 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
build(X) 
get at(i) 
set at(i,x) 
insert first(x) 
delete first() 
insert last(x) 
delete last() 
insert at(i, x) 
delete at(i) 
Binary Tree 
n 
h 
h 
h 
h 
AVL Tree 
n 
log n 
log n 
log n 
log n 
Set 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Binary Tree 
n log n 
h 
h 
h 
h 
AVL Tree 
n log n 
log n 
log n 
log n 
log n 
Height Balance 
• How to maintain height h = O(log n) where n is number of nodes in tree? 
• A binary tree that maintains O(log n) height under dynamic operations is called balanced 
– There are many balancing schemes (Red-Black Trees, Splay Trees, 2-3 Trees, . . . ) 
– First proposed balancing scheme was the AVL Tree (Adelson-Velsky and Landis, 1962) 
Rotations 
• Need to reduce height of tree without changing its traversal order, so that we represent the 
same sequence of items 
• How to change the structure of a tree, while preserving traversal order? Rotations! 
1 
_____<D>__ 
rotate_right(<D>) 
__<B>_____ 
2 
__<B>__ 
<E> 
=> 
<A> 
__<D>__ 
3 
<A> 
<C> 
/ \\ 
/ \\ 
<C> 
<E> 
4 
/ \\ 
/ \\ 
/___\\ 
<= 
/___\\ 
/ \\ 
/ \\ 
5 
/___\\ /___\\ 
rotate_left(<B>) 
/___\\ /___\\ 
• A rotation relinks O(1) pointers to modify tree structure and maintains traversal order 
","69.6037368774414","6","DPRSearchEngine","a2c80596cf4a2b5fbc854afdd2f23dcb_MIT6_006S20_lec7_1_pdf","a2c80596cf4a2b5fbc854afdd2f23dcb_MIT6_006S20_lec7","6.006","7"
"116","What is the purpose of right and left rotations in binary trees, and why is it important to maintain traversal order during these operations?","changing the traversal sequence so these are insert and delete operations these will correspond roughly to insert at or delete at but they're not quite we're not quite in","69.20219421386719","7","DPRSearchEngine","76dhtgZt38A.en_8_mp4","76dhtgZt38A.en","6.006","6"
"116","What is the purpose of right and left rotations in binary trees, and why is it important to maintain traversal order during these operations?","We're almost done. This will actually work. It's really quite awesome. But for it to work, we need something called subtree augmentation, which I'll talk about generally. And then, we'll apply it to size. So the idea with subtree augmentation is that each node in our binary tree can store a constant number of extra fields. Why not? And in particular, if these fields are of a particular type-- maybe I'll call them properties. I'm going to define a subtree property to be something that can be computed from the properties of the nodes' children. So I should say this is of a node. So children are node.left and node.right. You can also access constant amount of other stuff,","68.8028564453125","8","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_9_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"116","What is the purpose of right and left rotations in binary trees, and why is it important to maintain traversal order during these operations?","So first, we're going to introduce this concept of regular expressions-- which, again, these are things you may have run into in one way or another before. So we're going to introduce something called the regular operations. Now, I'm sure you're familiar with the arithmetical operations, like plus and times. Those apply to numbers. The operations we're going to talk about are operations that apply to languages. So they're going to take, let's say, two languages, you apply an operation, you're going to get back another language. Like the union operation, for example, that's one you probably have seen before. The union of two languages here is a collection of strings that are in either one or the other. But there are other operations, which you may not have seen before, that we're going to look at-- the concatenation operation, for example. So that says you're going to take a string from the first language and another string from the second language and stick them together. And it's called concatenating them. And you do that in all possible ways, and you're going to get the concatenation language from these two languages that you're starting with, A and B. The symbol we use for concatenation is this little circle. But often, we don't. We just suppress that and we write the two languages next to one another with the little circle implied.","68.59404754638672","9","DPRSearchEngine","9syvZr-9xwk.en-j3PyPqV-e1s_9_mp4","9syvZr-9xwk.en-j3PyPqV-e1s","18.404J","1"
"116","What is the purpose of right and left rotations in binary trees, and why is it important to maintain traversal order during these operations?","free and regular, why do we know that's still context free? Because the pushdown automaton for A can be simulating the finite automaton for B inside its finite control, inside its finite memory. The problem is, if you have two context-free languages, you have two pushdown automata, you can't simulate that with one pushdown automaton, because it has only a single stack. So if you're trying to take the intersection of two context-free languages with only a single stack, you're going to be in trouble, because it's hard to-- anyway, that's not a proof, but at least it shows you what goes wrong if you try to do the obvious thing. OK, so if-- and just, here is an important point that was trying to make before. If A and B are both context free and you're taking the intersection, the result may not necessarily be a context-free language. So the class of context-free languages is not closed under its intersection. We'll comment on that in a bit. The context-free languages are closed under the regular operations, however, union, intersection-- union, concatenation, and star. So you should feel comfortable that you know how to prove that. Again, it's one of the-- I think it's problem 0.2. And I think the solution is even given in the book for it. So you just should know how to prove that. It's pretty straightforward. OK, so let's move on then to basically conclude our work on context-free languages, to understand the limitations of context-free grammars, and what kinds of languages may not be context free. And how do you prove that? So how do you prove that, for some language, there is no grammar? Again, you know, it's not enough just to, say, give an informal comment that, I couldn't think of a grammar, or some-- things of that kind. That's not going to be good enough. We need to have a proof. So if we take the language here, 0 to the k, 1 to the k, 2 to the k, so those are strings which are runs of 0's followed by an equal number of 1's followed by an equal number of 2's, so just 0's, then 1's, then 2's, all the same length. That's a language which is not going to be a context-free language. And we'll give a method for proving that. If you had a stack, you can match the 1's with the 0's, but then once you're done with that, the stack is empty. And how do you now make sure that the number of 2's corresponds to the number of 1's that you had? So again, that's an informal argument that's not good enough to be a proof, but it sort of gives an intuition. So we're going to give a method for proving non-context-free-- languages are not context free using, again, a pumping lemma. But this is going to be a pumping lemma that applies to context-free language, not to regular languages. It looks very similar, but it has some extra wrinkles thrown in, because the other older pumping lemma was specific to the regular languages. And this is going to be something that applies to the context-free languages. OK, so now let's just read it. And then we'll try to interpret it again. It's very similar in spirit. Basically, it says that, whenever you have a context-free language, all long strings in the language can be pumped in some kind of way. So it's going to be a little different kind of pumping than we had before. And you stay in the language. OK, so before, we broke the string into three pieces where we could repeat that centerpiece as many times as you like. And you stay in the language. Here, we're going to end up breaking the string into five pieces. So s is going to be broken up into uvxyz. And the way it's going to work here-- so here is a picture. So all long strings-- again, there is going to be a threshold. So whenever you have a language, there is going to be some cut-off length. So all the longer strings in that language can be pumped. And you stay in the language. But the shorter strings, there is no guarantee. So if you have a long string in the language of length at least this pumping length p, then you can break it up into five pieces. But now it's that second and fourth string that are going to play that special pumping role, which means that, what you can do is you can repeat those and you stay in the language. And it's important that you repeat them both, that v and that y, the same number of times. So you're going to have a picture that looks something like this. And that is going to you repeat. If you repeat the v and you repeat the y, you get uvvxyyz. Or if you look at over here, it would be uv squared xy squared z. And that's going to still be in the language. And then we have-- so that's one condition. We'll have to look at all of these conditions when we do the proof, but we just want to understand what the statement is right now. So the second condition is that v and y together cannot be empty. And really, that's another way of saying, they can't both be the empty string, because if they were both the empty string, then repeating them wouldn't change s. And then of course it would stay in the language. So it would be kind of meaningless if they were allowed to be empty. And the last thing is, again, going to be there as a matter of convenience for proving languages are not context free, because you have to make sure there is no possible way of cutting up the string. When you're trying to prove a language is not context free, you have to show the pumping fails. It's going to be helpful sometimes to limit the ways in which the string can be cut up, because then you have-- it's an easier job for you to work with it. So here, it's a little different than before, but sort of similar, that vxy combine as a substring. So I show that over here. vxy together is not too long. So the vxy-- maybe it's better seen up here-- is going to be, at most, p. We'll do an example in a minute of using this. OK, so again, here is our pumping lemma. I've just restated it. So we have it in front of us. And we're going to do a proof. I'm just going to give you the idea of the proof first. And then we'll go through some of the details.","68.45929718017578","10","DPRSearchEngine","IycOPFmEQk8.en-j3PyPqV-e1s_7_mp4","IycOPFmEQk8.en-j3PyPqV-e1s","18.404J","5"
"117","What happens when deleting a leaf node in a binary tree?","sorry, delete_max, thank you. You can of course define all of these things for min instead of max. Everything works the same. I just have a hard time remembering which one we're doing. Just don't switch you can't use a max-heap to do delete_min. You can't use a min-heap to do delete_max, but you can use a min-heap to do delete_min. That's fine. So like I said, the only node we really know how to delete is the last leaf on the last level, which is the end of the array. Because that's what arrays can delete efficiently. And what we need to delete is the root item, because that's always the maximum one, which is at the first position in the array. So what do we do? Swap them, our usual trick. I think the cool thing about heaps is we never have to do rotations. We're only going to do swaps, which is something we had to do with trees also-- binary trees. Q[0] with Q of the last item-- great, done. Now we have the last item is the one we want to delete. So we do delete_last, or pop in Python, and boom, we've got-- we've now deleted the maximum item. Of course, we may have also messed up the max-heap property just like we did with insert. So with insert, we were adding a last leaf. Now, what we're doing is swapping the last leaf with the-- I'm pointing at the wrong picture. Let me go back to this tree. What we did is swap item J with A. So the problem is now-- and then we deleted this node. The problem is now that that root node has maybe a very small key. Because the key that's here now is whatever was down here, which is very low in the tree. So intuitively, that's a small value. This is supposed to be the maximum value, and we just put a small value in the root. So what do we do? Heapify down. We're going to take that item and somehow push it down to the tree until the-- down in the tree until max-heap property is satisfied. So this is going to be max_heapify_down. And we will start at position 0, which is the root. And max_heapify_down is going to be a recursive algorithm. So we'll start at some position i. And initially, that's the root. And what we're going to do is look at position i and its two children. So let's say we put a very small value up here, like 0. And let's say we have our children, 5 and 10. We don't know-- maybe I'll swap their order just to be more generic, because that looks like not quite a binary search tree, but we don't know their relative order. But one of them is greater than or equal to the other in some order. And so what would I like to do to fix this local picture? Yeah, I want to swap. And I could swap-- 0 is clearly in the wrong spot. It needs to go lower in the tree. I can swap 0 with 5 or 0 with 10. Which one? 10. I could draw the picture with 5, but it will not be happy. Why 10? We want to do it with the larger one, because then this edge will be happy, and also this edge will be happy. If I swapped 5 up there instead, the 5/10 edge would be unhappy. It wouldn't satisfy the max-heap property. So I can do one swap and fix max-heap property. Except that, again, 0 may be unhappy with its children. 0 was this one item that was in the wrong spot. And so it made it have to go farther down. But 5 will be-- 5 didn't even move. So it's happy. Everything in this subtree is good. What about the parent? Well, if you think about it, because everything was a correct heap before we added 0, or before we put 0 too high, all of these nodes will be greater than or equal to 10 on the ancestor path. And all of these nodes were less than or equal to 10 before, unless you're equal to 5. So that's still true. But you see, this tree is happy. This tree still may be unhappy. 0 still might need to push down farther. That's going to be the recursion. So we check down here. There's a base case, which is if i is a leaf, we're done. Because there's nothing below them. So we satisfy the max-heap property at i because there's no children. Otherwise, let's look at the leaf among the left-- sorry, left not leaf-- among the two children left and right of i. Right if i might not exist. Then ignore it. But among the two children that exist, find the one that has maximum key value, Q[j].key. That was 10 in our example. And then, if these items are out of order, if we do not satisfy-- so greater than would be satisfy. Less than Q[j] would be the opposite of the max-heap property here. If max-heap property is violated, then we fix it by swapping Q[i] with Q[j], and then we recurse on j-- call max_heapify_down of j. That's it. So pretty symmetric. Insert was a little bit simpler, because we only have one parent. Delete_min, because we're pushing down, we have two children. We have to pick one. But there's a clear choice-- the bigger one. And again, this algorithm-- this whole thing-- will take order h time, the height of the tree, which is log n, because our node just sort of bubbles down. At some point, it stops. When it stops, we know the max-heap property was satisfied there. And if you check along the way, by induction, all the other max-heap properties will be satisfied, because they were before. So almost forced what we could do here. The amazing thing is that you can actually maintain a complete binary tree that satisfies the max-heap property. But once you're told that, the algorithm kind of falls out. Because we have an array. The only thing we can do is insert and delete the last item. And so we've got to swap things to there in order-- or out of there in order to make that work. And then, the rest is just checking locally that you can fix the property. Cool. So that's almost it, not quite what we wanted. So we now have log n amortize insert and delete_max in our heap. We did not yet cover linear build. Right now, it's n log n if you insert n times. And we did not yet cover how to make this an in-place sorting algorithm. So let me sketch each of those. I think first is in-place. So how do we make this algorithm in-place? I guess I want that, but I don't need this. So we want to follow priority queue sort. Maybe I do want that. But I don't want to have to grow and shrink my array. I would just like to start with the array itself. So this is in place. So what we're going to do is say, OK, here's my array that I want to sort. That's given to me. That's the input to priority queue sort. And what I'd like is to build a priority queue out of it. Initially, it's empty. And then I want to insert the items one at a time, let's say. So in general, what I'm going to do is maintain that Q is some prefix of A. That's going to be my priority queue. It's going to live in this sub array-- this prefix. So how do I insert a new item? Well, I just increment. So to do an insert, the first step is increment size of Q. Then I will have taken the next item from A and injected into this Q. And conveniently, if we look at our insert code, which is here, the first thing we wanted to do was add an item at the end of the array. So we just did it without any actual work, just conceptual work. We just said, oh, our Q is one bigger. Boom! Now this is at the end of the array. no more amortization, in fact, because we're not ever resizing our array, we're just saying, oh, now Q is a little bit bigger of a prefix. It just absorb the next item of A. Similarly, delete_max is going to, at the end, decrement the size of Q. Why is that OK? Because at the end of our delete_max operation-- not quite at the end, but almost the end-- we deleted the last item from our array. So we just replaced that delete last with a decrement, and that's going to shrink the Q by 1. It has the exact same impact as leading the last item. But now, it's constant time, worst case not amortized. And the result is we never actually build a dynamic array. We just use a portion of A to do it. So what's going to happen is we're going to absorb all the items into the priority queue, and then start kicking them out. As we kick them out, we kick out the largest key item first, and we put it here, then the next largest, then the next largest, and so on. The minimum item is going to be here. And, boom, it's sorted. This is the whole reason I did max-heaps instead of min-heaps, is that in the end, this will be a upward sorted array with the max at the end. Because we always kick out items at the end. We delete the max first. So that is what's normally called heapsort. You can apply this same trick to insertion sort and selection sort, and you actually get the insertion sort and selection sort algorithms that we've seen which operate in prefixes of the array. Cool, so now we have-- we've achieved the y up there, which is n log n sorting algorithm that is in-place. So that was our main goal-- heapsort. Let me very quickly mention you can build a heap in linear time with a clever trick. So if you insert the items one at a time, that would correspond to inserting down the array. And every time I insert an item, I have to walk up the tree. So this would be the sum of the depth of each node. If you do that, you get n log n. This is the sum over i of log i. That turns out to be n log n. It's a log of n factorial. The cool trick is to, instead, imagine adding all the items at once and not heapifying anything, and then heapify up-- sorry, heapify down from the bottom up. So here we're heapifying up. Now, we're going to heapify down. And surprisingly, that's better. Because this is the sum of the heights of the nodes. And that turns out to be linear. It's not obvious. But intuitively, for a depth, this is 0, this is log n, and we've got a whole ton of leaves. So right at the leaf level, you can see, we're paying n log n, right? Because there are n of them, and each one costs log n. Down here, at the leaf level, we're paying constant. Because the height of the leaves are 1. Here, the height of the root is log n. And this is better. Now we're paying a small amount for the thing of which there are many. It's not quite a geometric series, but it turns out this is linear. So that's how you can do linear building heap. To come back to your question about sequence AVL trees, turns out you can get all of the same bounds as heaps, except for the in-place part, by taking a sequence AVL tree, storing the items in an arbitrary order, and augmenting by max, which is a crazy idea. But it also gives you a linear build time. And yeah, there's other fun stuff in your notes. But I'll stop there.","75.32029724121094","1","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_11_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"117","What happens when deleting a leaf node in a binary tree?","next i'm going to do a couple of deletions let's delete f first and then we're going to well this is confusing and then we're going to delete a so where's f we're supposing we're given a pointer to f this node well it's a leaf so if i want to delete it i just erase it easy leaves are easy to delete there's no work to do so what that means is i'm removing the pointer from d","72.98509216308594","2","DPRSearchEngine","76dhtgZt38A.en_11_mp4","76dhtgZt38A.en","6.006","6"
"117","What happens when deleting a leaf node in a binary tree?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","72.62460327148438","3","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"117","What happens when deleting a leaf node in a binary tree?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","72.4776840209961","4","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"117","What happens when deleting a leaf node in a binary tree?","If you think about it a little bit, this is exactly binary search on an array. It just happens to be on a tree instead. If you think of an array like this, what does binary search do? It first looks at the key in the middle. I'm going to draw that as the root. And then, it recurses either on the left chunk, which I will draw recursively, or on the right chunk. And so if you happen to have a perfect binary tree like this one, it is simulating exactly binary search in this array. But this we're going to be able to maintain dynamically-- not perfect any more, but close. Whereas this we could not maintain in sorted order. So this is like a generalization of binary search to work on trees instead of on arrays. And for this reason, set binary trees are called binary search trees, because they're the tree version of binary search. So there's many equivalent names. So binary search tree is another name for set binary tree. And the key thing that makes this algorithm work is the so-called binary search tree property, which is all the keys in the left subtree of a node are less than the root, or of that node, and that key is less than all the keys in the right subtree. And this is true recursively all the way down. And so that's how you prove that this algorithm is correct by this property. Why is this true? Because if we can maintain traversal order to be increasing key, then that's exactly what traversal order means. It tells you all the things in the left subtree come before the root, which come before all the things in the right subtree.","72.38056945800781","5","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_4_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"117","What happens when deleting a leaf node in a binary tree?"," &&%$3$%'9
class Digraph(object): 
 """"""edges is a dict mapping each node to a list of 
    its children""""” 
    def __init__(self): 
self.edges = {} 
    def addNode(self, node): 
if node in self.edges: 
 raise ValueError('Duplicate node') 
else: 
self.edges[node] = [] 
    def addEdge(self, edge): 
src = edge.getSource() 
dest = edge.getDestination() 
if not (src in self.edges and dest in self.edges): 
raise ValueError('Node not in graph') 
self.edges[src].append(dest) 
Q>KKKMN
LS
mapping each node 
list 
","71.70077514648438","6","DPRSearchEngine","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_18_pdf","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3","6.0002","3"
"117","What happens when deleting a leaf node in a binary tree?"," 
 
 
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
  
 
  
 
  
 
 
  
 
 
   
 
 
   
 
 
 
 
TMs and Encodings – review 
A TM has 3 possible outcomes for each input !: 
1. Accept ! (enter ""acc ) 
2. Reject ! by halting (enter ""rej ) 
3. Reject ! by looping (running forever) 
( is T-recognizable if ( = *(,) for some TM ,. 
( is T-decidable if ( = *(,) for some TM decider ,. 
halts on all inputs 
〈/0, /2, … , /4〉 encodes objects /0, /2, … , /4 as a single string. 
Notation for writing a TM , is 
, = “On input ! 
[English description of the algorithm]” 
2 
","71.5077896118164","7","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_2_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"117","What happens when deleting a leaf node in a binary tree?","!""#$""%&'(% ∈NP
Defn:  !""#$""%&'(% = + + is not prime and + is written in binary} 
= + + = ,- for integers ,, - > 1,  + in binary} 
Theorem:  !""#$""%&'(% ∈NP
Proof:   “On input +
1.  Nondeterministically write , where 1 < , < +.
2.  Accept if , divides + with remainder 0.
Reject if not.”
Note:  Using base 10 instead of base 2 wouldn’t matter because can convert in 
polynomial time.
Bad encoding:  write number 3 in unary:  14 = 111 ⋯1
4
, exponentially longer.
Theorem (2002):  !""#$""%&'(% ∈P
We won’t cover this proof.
5
","69.85030364990234","8","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_5_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"117","What happens when deleting a leaf node in a binary tree?","2 
Lecture 8: Binary Heaps 
Priority Queue: Set AVL Tree 
• Set AVL trees support insert(x), find min(), find max(), delete min(), and 
delete max() in O(log n) time per operation 
• So priority queue sort runs in O(n log n) time 
– This is (essentially) AVL sort from Lecture 7 
• Can speed up find min() and find max() to O(1) time via subtree augmentation 
• But this data structure is complicated and resulting sort is not in-place 
• Is there a simpler data structure for just priority queue, and in-place O(n lg n) sort? 
YES, binary heap and heap sort 
• Essentially implement a Set data structure on top of a Sequence data structure (array), using 
what we learned about binary trees 
Priority Queue: Array 
• Store elements in an unordered dynamic array 
• insert(x): append x to end in amortized O(1) time 
• delete max(): ﬁnd max in O(n), swap max to the end and remove 
• insert is quick, but delete max is slow 
• Priority queue sort is selection sort! (plus some copying) 
Priority Queue: Sorted Array 
• Store elements in a sorted dynamic array 
• insert(x): append x to end, swap down to sorted position in O(n) time 
• delete max(): delete from end in O(1) amortized 
• delete max is quick, but insert is slow 
• Priority queue sort is insertion sort! (plus some copying) 
• Can we ﬁnd a compromise between these two array priority queue extremes? 
","69.39358520507812","9","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_2_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"117","What happens when deleting a leaf node in a binary tree?"," 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 6: Binary Trees I 
Lecture 6: Binary Trees I 
Previously and New Goal 
Sequence 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
build(X) 
get at(i) 
set at(i,x) 
insert first(x) 
delete first() 
insert last(x) 
delete last() 
insert at(i, x) 
delete at(i) 
Array 
n 
1 
n 
n 
n 
Linked List 
n 
n 
1 
n 
n 
Dynamic Array 
n 
1 
n 
1(a) 
n 
Goal 
n 
log n 
log n 
log n 
log n 
Set 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
Direct Access Array 
u 
1 
1 
u 
u 
Hash Table 
n(e) 
1(e) 
1(a)(e) 
n 
n 
Goal 
n log n 
log n 
log n 
log n 
log n 
How? Binary Trees! 
• Pointer-based data structures (like Linked List) can achieve worst-case performance 
• Binary tree is pointer-based data structure with three pointers per node 
• Node representation: node.{item, parent, left, right} 
• Example: 
1 
2 
3 
4 
5 
________<A>_____ 
__<B>_____ 
<C> 
__<D> 
<E> 
<F> 
node 
| 
item 
| 
parent | 
left 
| 
right 
| 
<A> | 
A 
| 
-
| 
<B> | 
<C> | 
<B> 
B 
<A> 
<C> 
<D> 
| 
| 
| 
| 
| 
<C> | 
C 
| 
<A> | 
-
| 
-
| 
<D> | 
D 
| 
<B> | 
<F> | 
-
| 
<E> | 
E 
| 
<B> | 
-
| 
-
| 
<F> 
F 
<D> 
-
-
| 
| 
| 
| 
| 
","69.1831283569336","10","DPRSearchEngine","376714cc85c6c784d90eec9c575ec027_MIT6_006S20_lec6_1_pdf","376714cc85c6c784d90eec9c575ec027_MIT6_006S20_lec6","6.006","6"
"118","What is a dynamic array sequence in the context of data structures?","to this interface problem-- the natural solution-- is what I'll call a static array. Jason mentioned these in lecture one. It's a little tricky because there are no static arrays in Python. There are only dynamic arrays, which is something we will get to. But I want to talk about, what is a static array, really? And this relates to our notion of-- our model of computation, Jason also talked about, which we call the word RAM, remember? The idea, in word RAM, is that your memory is an array of w-bit words. This is a bit circular. I'm going to define an array in terms of the word RAM, which is defined in terms of arrays. But I think you know the idea. So we have a big memory which goes off to infinity, maybe. It's divided into words. Each word here is w bits long. This is word 0, word 1, word 2. And you can access this array randomly-- random access memory. So I can give you the number 5 and get 0 1, 2, 3, 4, 5, the fifth word in this RAM. That's how actual memories work. You can access any of them equally quickly. OK, so that's memory. And so what we want to do is, when we say an array, we want this to be a consecutive chunk of memory. Let me get color. Let's say I have an array of size 4 and it lives here. Jason can't spell, but I can't count. So I think that's four. We've got-- so the array starts here and it ends over here. It's of size 4. And it's consecutive, which means, if I want to access the array at position-- at index i, then this is the same thing as accessing my memory array at position-- wherever the array starts, which I'll call the address of the array-- in Python, this is ID of array-- plus i. OK. This is just simple offset arithmetic. If I want to know the 0th item of the array, it's right here, where it starts. The first item is one after that. The second item is one after that. So as long as I store my array consecutively in memory, I can access the array in constant time. I can do get_at and set_at as quickly as I can randomly access the memory and get value-- or set a value-- which we're assuming is constant time. My array access is constant time. This is what allows a static array to actually solve this problem in constant time per get_at and set_at operation. This may seem simple, but we're really going to need this model and really rely on this model increasingly as we get to more interesting data structures. This is the first time we're actually needing it. Let's see. Length is also constant time. We're just going to store that number n, along with its address. And build is going to take linear time. Iteration will take linear time. Pretty straightforward. I guess one thing here, when defining build, I need to introduce a little bit more of our model of computation, which is, how do you create an array in the beginning? I claim I could do it in linear time, but that's just part of the model. This is called the memory allocation model. There are a few possible choices here, but the cleanest one is just to assume that you can allocate an array of size n in theta n time. So it takes linear time to make an array of size n. You could imagine this being constant. It doesn't really matter much. But it does take work. And in particular, if you just allocate some chunk of memory, you have no idea whether it's initialized. So initializing that array to 0s will cost linear time. It won't really matter, constant versus linear, but a nice side effect of this model is that space-- if you're just allocating arrays, the amount of space you use is, at most, the amount of time you use. Or, I guess, big O of that. So that's a nice feature. It's pretty weird if you imagine-- it's unrealistic to imagine you can allocate an array that's infinite size and then just use a few items out of it. That won't give you a good data structure. So we'll assume it costs to allocate memory. OK, great. We solved the sequence problem. Very simple, kind of boring. These are optimal running times. Now, let's make it interesting-- make sure I didn't miss anything--","78.45668029785156","1","DPRSearchEngine","CHhwJjR0mZA.en-j3PyPqV-e1s_3_mp4","CHhwJjR0mZA.en-j3PyPqV-e1s","6.006","2"
"118","What is a dynamic array sequence in the context of data structures?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","77.26506042480469","2","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"118","What is a dynamic array sequence in the context of data structures?","You've taken, probably-- you've probably seen linked lists before at some point. But the main new part here is, we're going to actually analyze them and see how efficiently they implement all of these operations we might care about. First, review. What is a linked list? We store our items in a bunch of nodes. Each node has an item in it and a next field. So you can think of these as class objects with two class variables, the item and the next pointer. And we assemble those into this kind of structure where we store-- in the item fields, we're going to store the actual values that we want to represent in our sequence, x 0 through x n minus 1, in order. And then we're going to use the next pointers to link these all together in that order. So the next pointers are what actually give us the order. And in addition, we're going to keep track of what's called the head of the list. The data structure is going to be represented by a head. If you wanted to, you could also store length. This could be the data structure itself. And it's pointing to all of these types of data structures. Notice, we've just seen an array-based data structure, which is just a static array, and we've seen a pointer-based data structure. And we're relying on the fact that pointers can be stored in a single word, which means we can de-reference them-- we can see what's on the other side of the pointer-- in constant time in our word RAM model. In reality, each of these nodes is stored somewhere in the array of the computer. So maybe each one is two words long, so maybe one node is-- the first node is here. Maybe the second node is here. The third node is here. They're in some arbitrary order. We're using this fact, that we can allocate an array of size n in linear time-- in this case, we're going to have arrays of size 2. We can just say, oh, please give me a new array of size 2. And that will make us one of these nodes. And then we're storing pointers. Pointers are just indices into the giant memory array. They're just, what is the address of this little array? If you've ever wondered how pointers are implemented, they're just numbers that say where, in memory, is this thing over here? And in memory, they're in arbitrary order. This is really nice because it's easy to manipulate the order of a linked list without actually physically moving nodes around, whereas arrays are problematic. Maybe it's worth mentioning. Let's start analyzing things. So we care about these dynamic sequence operations. And we could try to apply it to the static array data structure, or we could try to implement these operations in a static array. It's possible, just not going to be very good. And we can try to implement it with linked lists. And it's also not going to be that great.","75.85808563232422","3","DPRSearchEngine","CHhwJjR0mZA.en-j3PyPqV-e1s_5_mp4","CHhwJjR0mZA.en-j3PyPqV-e1s","6.006","2"
"118","What is a dynamic array sequence in the context of data structures?","And this is a subset of the set interface. And subsets are interesting because, potentially, we can solve them better, faster, simpler, something. And so you'll recognize-- you should recognize all of these operations, except we didn't normally highlight the max operation. So here, we're interested in storing a bunch of items. They have keys which we think of as priorities. And we want to be able to identify the maximum priority item in our set and remove it. And so there's lots of motivations for this. Maybe you have a router, packets going into the router. They have different priorities assigned to them. You want to route the highest priority first. Or you have processes on your computer trying to run on your single threaded-- single core, and you've got to choose which one to run next. And you usually run higher priority processes first. Or you're trying to simulate a system where events happen at different times, and you want to process the next event ordered by time. All of these are examples of the priority queue interface. We'll even see applications within this class when we get to graph algorithms. But the main two things we want to be able to support are inserting an item, which includes a key, and leading the maximum item, and also returning it at the same time. We'll also talk some about being able to build the structure faster than just inserting it. But of course, we could implement build by starting empty and repeatedly inserting. And also the complexity of just finding the max without deleting it, this you could simulate with these two operations by deleting the max and then reinserting it, which works. But often, we can do faster. But the two key, main operations are insert and delete max. And we're going to see a few data structures to do this. Any suggestions among the data structures we've seen in this class? What should we use to solve priority queue interface? Many possible answers.","75.76789855957031","4","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_2_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"118","What is a dynamic array sequence in the context of data structures?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","75.53414916992188","5","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"118","What is a dynamic array sequence in the context of data structures?","That's what we called a direct access array. A direct access array-- really not different than a regular array, except how are you using it when we were talking about sequences is we are giving extrinsic semantics to the slots where we are storing these things. Basically, I could put any item in any slot. Where it was in my array had nothing to do with what those things were. Here we are imposing intrinsic semantics on my array that, if I have an item with key K, it must be at index K. That's the thing that we're taking advantage of here. And then we can use this nice, powerful linear branching random access operation to find that thing in constant time, because that's our model of computation. OK, then what was the problem with this direct access array? Anyone shout it out. Space-- right. So we had to instantiate a direct access array that was the size of the space of our keys. In general, my index location is-- could go from 0 to some positive number. If I a very large positive numbers, if I was sorting-- if I was searching among your MIT IDs, I'd have to have a direct access array that was that spanned that space of possible keys you could have. And that could be much larger than n. And so the rest of the time we talked about how to fix that space problem. We can reduce the space by taking that larger key space from 0 to u, which could be very large, and map it down to a small space. Now, in general, if I give you a fixed hash function there, that's not going to be good in-- for all inputs. If your inputs are very well distributed over the key space, then it is good, but in general, there would be hash functions with some inputs that will be bad. That's what we argued. And so for the rest of the time there, we talked about hash families, choosing a hash function randomly from among a large set of hash functions, which had a property that, if I chose this thing randomly and you, generating your input, didn't know which random numbers I was picking, the expectation over my random choice-- me-- I'm the one running the algorithm, not you giving me the input-- that random choice-- my algorithm actually behaves really well in expectation. In particular, I got constant time for finding, inserting, and deleting into this data structure, in expectation. We did a little proof of-- that the chain links where we stored collisions in our hash function-- in our hash table-- sorry-- those wouldn't be very long, and so if they were constant, then I don't have to search more than a constant number of things when I go to an-- a hashed index location. Does everyone remember what we talked about last week? I didn't show you this chart at the end, but I'm showing it to you now. Essentially, what we had was we have a bunch of different ways to deal with this set interface. And last week, we talked about the sorted array, and then we talked about this direct access array and this hash table, which do better for these dictionary-- the find, and insert, and delete operations--","74.95856475830078","6","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_3_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"118","What is a dynamic array sequence in the context of data structures?","They take linear time for some of the operations. So the sorting algorithms are not efficient. But they're ones we've seen before, so it's neat to see how they fit in here. They had the-- selection sort and insertion sort had the advantage that they were in place. You just needed a constant number of pointers or indices beyond the array itself. So they're very space efficient. So that was a plus for them. But they take n squared time, so you should never use them, except for n, at most, 100 or something. AVL tree sort is great and then it gets n log n time, probably more complicated than merge sort and you could stick to merge sort. But neither merge sort nor set AVL tree sort are in place. And so the goal of today is to get the best of all those worlds in sorting to get n log n comparisons, which is optimal in the comparison model, but get it to be in place. And that's what we're going to get with binary heaps. We're going to design a data structure that happens to build a little bit faster-- as I mentioned, linear time building. So it's not representing a sorted order in the same way that AVL trees are. But it will be kind of tree-based. It will also be array-based. We're going to get logarithmic time for insert and delete_max. It happens to be amortized, because we use arrays. But the key thing is that it's an in-place data structure. It only consists of an array of the items. And so, when we plug it into our sorting algorithm-- priority queue sort or generic sorting algorithm-- not only do we get n log n performance, but we also get an in-place sorting algorithm. This will be our first and only-- to this class-- n log n in-place sorting algorithm. Cool. That's the goal.","74.9539794921875","7","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_5_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"118","What is a dynamic array sequence in the context of data structures?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 2: Data Structures 
Lecture 2: Data Structures 
Data Structure Interfaces 
• A data structure is a way to store data, with algorithms that support operations on the data 
• Collection of supported operations is called an interface (also API or ADT) 
• Interface is a speciﬁcation: what operations are supported (the problem!) 
• Data structure is a representation: how operations are supported (the solution!) 
• In this class, two main interfaces: Sequence and Set 
Sequence Interface (L02, L07) 
• Maintain a sequence of items (order is extrinsic) 
• Ex: (x0, x1, x2, . . . , xn−1) (zero indexing) 
• (use n to denote the number of items stored in the data structure) 
• Supports sequence operations: 
Container 
build(X) 
len() 
given an iterable X, build sequence from items in X 
return the number of stored items 
Static 
iter seq() 
get at(i) 
set at(i, x) 
return the stored items one-by-one in sequence order 
return the ith item 
replace the ith item with x 
Dynamic 
insert at(i, x) 
delete at(i) 
insert first(x) 
delete first() 
insert last(x) 
delete last() 
add x as the ith item 
remove and return the ith item 
add x as the ﬁrst item 
remove and return the ﬁrst item 
add x as the last item 
remove and return the last item 
• Special case interfaces: 
stack 
insert last(x) and delete last() 
queue 
insert last(x) and delete first() 
","74.93356323242188","8","DPRSearchEngine","79a07dc1cb47d76dae2ffedc701e3d2b_MIT6_006S20_lec2_1_pdf","79a07dc1cb47d76dae2ffedc701e3d2b_MIT6_006S20_lec2","6.006","2"
"118","What is a dynamic array sequence in the context of data structures?","What's the worst case performance of a hash table? If I have to look up something in a hash table, and I happen to choose a bad hash table-- hash function, what's the worst case here? What? n, right? It's worse than a sorted array, because potentially, I hashed everything that I was storing to the same index in my hash table, and to be able to distinguish between them, I can't do anything more than a linear search. I could store another set's data structure as my chain and do better that way. That's actually how Java does it. They store a data structure we're going to be talking about next week as the chains so that they can get, worst case, log n. But in general, that hash table is only good if we're allowing-- OK, I want this to be expected good, but in the worst case, if I really need that operation to be worst case-- I really can't afford linear time ever for an operation of that kind-- then I don't want to use a hash table. And so on your p set 2, everything we ask you for is worst case, so probably, you don't want to be using hash tables. OK? Yes? AUDIENCE: What does the subscript e mean? JASON KU: What does the subscript e mean? That's great. In this chart, I put a subscript on this is an expected runtime, or an A meaning this is an amortized runtime. At the end, we talked about how, if we had too many things in our hash table, then, as long as we didn't do it too often-- this is a little hand wavey argument, but the same kinds of ideas as the dynamic array-- if, whenever we got a linear-- we are more than a linear factor away from where we are trying-- basically, the fill factor we were trying to be, then we could just completely rebuild the hash table with the new hash function randomly chosen from our hash table with a new size, and we could get amortized bounds. And so that's what Python-- how Python implements dictionaries, or sets, or even objects when it's trying to map keys to different things. So that's hash tables. That's great. The key thing here is, well, actually, if your range of keys is small, or if you as a programmer have the ability to choose the keys that you identify your objects with, you can actually choose that range to be small, to be linear, to be small with respect to your items. And you don't need a hash table. You can just use a direct access array, because if you know your key space is small, that's great. So a lot of C programmers probably would like to do something like that, because they don't have access to-- maybe C++ programmers would have access to their hash table. Any questions on this stuff before we move on? Yeah? AUDIENCE: So why is [INAUDIBLE]? JASON KU: Why is it expected? When I'm building, I could insert-- I'm inserting these things from x 1 by 1 into my hash table. Each of those insert operations-- I'm looking up to see whether that-- an item with that key already exists in my hash table. And so I have to look down the chain to see where it is. However, if I happen to know that all of my keys are unique in my input, all the items I'm trying to store are unique, then I don't have to do that check and I can get worst case linear time. Does that make sense? All right. It's a subtlety, but that's a great question. OK, so today, instead of talking about searching, we're talking about sorting. Last week, we saw a few ways to do sort. Some of them were quadratic-- insertion sort and selection sort-- and then we had one that was n log n. And this thing, n log n, seemed pretty good, but can I do better? Can I do better? Well, what we're going to show at the beginning of this class is, in this comparison model, no. n log n is optimal. And we're going to go through the exact same line of reasoning that we had last week. So in the comparison model, what did we use when we were trying to make this argument that any comparison model algorithm was going to take at least log n time? What we did was we said, OK, I can think of any model in the comparison model-- any algorithm in the comparison model as kind of this-- some comparisons happen. They branch in a binary sense, but you could have it generalized to any constant branching factor. But for our purposes, binary's fine. And what we said was that there were at least n outputs-- really n plus 1, but-- at least order n outputs. And we showed that-- or we argued to you that the height of this tree had to be at least log n-- log the number of leaves. It had to be at least log the number of leaves. That was the height of the decision tree. And if this decision tree represented a search algorithm, I had to walk down and perform these comparisons in order, reach a leaf where I would output something. If the minimum height of any binary tree on a linear number of leaves is log n, then any algorithm in the comparison model also has to take log n time, because it has to do that many comparisons to differentiate between all possible outputs. Does that make sense? All right. So in the sort problem, how many possible outputs are there?","74.6927719116211","9","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_4_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"118","What is a dynamic array sequence in the context of data structures?","3 
Lecture 4: Hashing 
• Always exists keys a, b such that h(a) = h(b) → Collision! :( 
• Can’t store both items at same index, so where to store? Either: 
– store somewhere else in the array (open addressing) 
∗ complicated analysis, but common and practical 
– store in another data structure supporting dynamic set interface (chaining) 
Chaining 
• Idea! Store collisions in another data structure (a chain) 
• If keys roughly evenly distributed over indices, chain size is n/m = n/Ω(n) = O(1)! 
• If chain has O(1) size, all operations take O(1) time! Yay! 
• If not, many items may map to same location, e.g. h(k) = constant, chain size is Θ(n) :( 
• Need good hash function! So what’s a good hash function? 
Hash Functions 
Division (bad): 
h(k) = (k mod m) 
• Heuristic, good when keys are uniformly distributed! 
• m should avoid symmetries of the stored keys 
• Large primes far from powers of 2 and 10 can be reasonable 
• Python uses a version of this with some additional mixing 
• If u ≫ n, every hash function will have some input set that will a create O(n) size chain 
• Idea! Don’t use a ﬁxed hash function! Choose one randomly (but carefully)! 
","74.37449645996094","10","DPRSearchEngine","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_3_pdf","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4","6.006","4"
"119","How can we prove that the height of a height-balanced tree is logarithmic with respect to the number of nodes?","on how many nodes are over here on the left, which is not in the subtree of that node. So that's where you have to be careful. Don't use global properties of the tree. You can only use subtree properties. Another example is depth. Depth Is annoying to maintain, but it's not obvious why yet. We will see that in a moment. The rest of today is about going from order h order log n, which is what this slide is showing us. So at this point, you should believe that we can do all of the sequence data structure operations in order h time-- except for build and iterate, which take linear time-- and that we can do all of the set operations in order h time, except build and iterate, which take n log n and n respectively. And our goal is to now bound h by log n. We know it's possible at some level, because there are trees that have logarithmic height. That's like this perfect tree here. But we also know we have to be careful, because there are some bad trees, like this chain. So if h equals log n, we call this a balanced binary tree. There are many balanced binary trees in the world, maybe a dozen or two-- a lot of different data structures. Question? AUDIENCE: [INAUDIBLE] you said not to think about things on a global level so we'll think of them [INAUDIBLE]..","71.370361328125","1","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_12_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"119","How can we prove that the height of a height-balanced tree is logarithmic with respect to the number of nodes?","So, the first claim is that if I could maintain height balance, then I will guarantee that h equals log n. So in other words, height balance implies balance. So let's prove that first quickly. And then, the interesting part is how do we actually prove-- or how do we actually maintain the balance property? We're going to do that using rotations. But how is a big question. So why does height balance imply balance? So what this is saying is that all height balanced trees have logarithmic height. So what I'd like to think about is sort of the least balanced height balanced tree. The least balanced one is going to have every node a mismatch. Let's say the left subtree is shallower than the right subtree by 1, and recursively all the way down. So every node has a gap here, a-- what do we call it-- a skew of 1, which I'm going to write-- I'm going to introduce some notation. I'll write a dissenting rightward arrow of this one is higher than the left subtree. So the easy way to think about this is this is sort of our worst case. This is going to be the fewest nodes for the maximum depth. Let's just count how many nodes are in this tree. I'm going to write that as a recurrence, which is the number of nodes in a tree of height h. So if this whole tree has height h, as we said in this picture, if I just subtract 2 from all these numbers, then this one has height h minus 2, and this one has height h minus 1. So how many nodes are in here? Well, this is a recurrence I'm going to write. So this will be N sub h minus 2. This will be N sub h minus 1. And then I just count how many nodes are in this picture. It is Nh minus 1 plus Nh minus 2 plus 1, or this node. Now you might ask, what is Nh a recurrence for? But it is the number of nodes in this sort of worst case if the worst case has total height h. So you can also think of it as what is the minimum number of nodes I could have in an AVL tree, which is a height balanced tree, that has a height h in a height balanced tree? OK, so now I just need to solve this recurrence. This recurrence look familiar-ish? It's like Fibonacci numbers. If I remove the plus 1, it's Fibonacci. And if you happen to know the Fibonacci numbers grow as, like, a golden ratio to the n, then we know that this is exponential, which is what we want. Because if Nh is exponential in h, that means h is logarithmic in N, because log is inverse of exponential. But maybe you don't know about Fibonacci numbers. And so we can still easily show that this is exponential as follows. I want to prove that it's at least an exponential, because that gives me that h is at most logarithmic. So we need a lower bound. And so we have these two terms which are hard to compare-- Nh minus 1 and Nh minus 2. It's kind of ugly. But if we're allowed to be sloppy-- and we'll see if we're not too sloppy-- and still get an exponential answer, let's just make them equal like so. So this is a true statement, in fact, strictly greater than. Why? Because I removed the plus 1. That should only make something smaller. And I replaced Nh minus 1 with Nh minus 2. Here, I'm implicitly using a fact, which is obvious by induction, that this tree on height-- if I take this tree versus this tree, this one has more nodes than this one. If I have larger height, this construction is going to build a bigger tree, at least as big. It doesn't even need to be strictly bigger. So certainly, Nh minus 1 is greater than or equal to Nh minus 2. Now, this is 2 times Nh minus 2. And this is an easy recurrence. This is just powers of 2. I keep multiplying by 2, and subtracting 2 from h. So this solves to 2 to the h over 2, maybe with a floor or something. But I'm using a base case here, which is N sub 0 equals 1. Maybe it's a ceiling then. But the point is this is exponential. So this implies that the height is always, at most, 2 times log n. This 2 corresponds to this 2. If you just invert this formula, this was a number of nodes is going to be at least 2 to the h over 2. And so h is, at most, 2 log n. So it's not log n. That would be perfect. But it's within a factor of 2 of log n. So AVL trees are always quite balanced. Number of levels is at most double what you need to store n nodes. Great. We're left with the main magic-- not domain magic. That's different. And let's see, we're going to use subtree augmentation. Keep that. Big remaining challenge is how do we maintain this high balance property using rotations? We have all the ingredients lined up for us. We have subtree augmentation. What does that let me do? It's relevant to AVL trees. Well, it lets me store height. I need to be able to compute the height of a node. That, in general, takes linear time, because I have to look at all the downward paths-- all the leaves within that subtree. But height is a subtree property-- so, yes-- height. Why? Because-- let me just write it here-- node.height equals 1 plus max of node.left.height and node.right.height and of max. Let me put this in a box. This equation, or I guess it's an assignment operation--","71.30250549316406","2","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_20_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"119","How can we prove that the height of a height-balanced tree is logarithmic with respect to the number of nodes?","And we did adding and removing a leaf. That's not enough. We're going to need something else to let us guarantee logarithmic height. And that something else is called a rotation.","70.35856628417969","3","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_15_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"119","How can we prove that the height of a height-balanced tree is logarithmic with respect to the number of nodes?","I know you don't believe it, but it is because notice what it says, it says the r squared value for the line is horrible. It accounts for less than 0.05% of the data. You could say, OK, I can see that. I look at it. It does a lousy job. On the other hand, the quadratic is really pretty good. It's accounting for about 84% of the variability in the data. This is a nice high value. It's not one, but it's a nice high value. So this is now reinforcing what I already knew, but in a nice way. It's telling me that that r squared value tells me that the quadratic is a much better fit than the linear fit was. But then you say maybe, wait a minute. I could have done this by just comparing the fits themselves. I already saw that. Part of my goal is how do I know if I've got the best fit possible or not. So I'm going to do the same thing, but now I'm going to run it with another set of degrees. I'm going to go over here. I'm going to take exactly the same code. But let's try it with a quadratic, with a quartic, an order eight, and an order 16 fit. So I'm going to take different size polynomials. As a quick aside, this is why I want to use the PyLab kind of code because now I'm simply optimizing over a 16-dimensional space. Every point in that 16-dimensional space defines a 16th-degree polynomial. And I can still use linear regression, meaning walking down the gradient, to find the best solution. I'm going to run this. And I get out a set of values. Looks good. And let's go look at them.","70.30116271972656","4","DPRSearchEngine","vIFKGFl1Cn8.en-qlPKC2UN_YU_18_mp4","vIFKGFl1Cn8.en-qlPKC2UN_YU","6.0002","9"
"119","How can we prove that the height of a height-balanced tree is logarithmic with respect to the number of nodes?","I'll call them left justified. And these two properties together is what I call a complete binary tree. Why is this interesting? Because I claim I can represent a tree like this as an array. I've narrowed things down enough that I can draw an array down here. And what I'm going to do is write these nodes in depth order. So I write A first, because that's step 0. Then B, C, that's step 1. Then, well, they're alphabetical. I made it that way. D, E, F, G is depth 2. And then H, I, J is step 3. This is very different from traversal order of a tree. Traversal order would have been H, D, I, B, J, E, A, F, C, G, OK? But this is what we might call depth order, do the lowest depth nodes first-- very different way to lay things out or to linearize our data. And this is what a heap is going to look like. So the cool thing is, between complete binary trees and arrays is a bijection. For every array, there's a unique complete binary tree. And for every complete binary tree, there's a unique array. Why? Because the complete constraint forces everything-- forces my hand. There's only-- if I give you a number n, there is one tree shape of size n, right? You just fill in the nodes top down until you get to the last level. And then you have to fill them in left to right. It's what you might call reading order for writing down nodes. And the array is telling you which keys go where. This is the first node you write down at the root, this is the next node you write down at the left child of the root, and so on. So here we have a binary tree represented as an array, or array representing a binary tree. The very specific binary tree, it has a clear advantage, which is it is guaranteed balance. No rotations necessary in heaps, because complete binary trees are always balanced. In fact, they have the best height they possibly could, which is ceiling of log n. Balanced, remember, just meant you were big O of log n. This is 1 times log n. So it's the best level of balance you could hope for. So somehow, I claim, we can maintain a complete binary tree for solving priority queues. This would not be possible if you were trying to solve the whole set interface. And that's kind of the cool thing about heaps, is that by just focusing on the subset of the set interface, we can do more. We can maintain this very strong property. And because we have this very strong property, we don't even need to store this tree. We're not going to store left and right pointers and parent pointers, we're just going to store the array.","70.28186798095703","5","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_8_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"119","How can we prove that the height of a height-balanced tree is logarithmic with respect to the number of nodes?","Minimum Spanning Tree-- so I'm trying to find a tree connecting all of the vertices in a connected component of my graph. And I'm trying to find-- in a weighted graph, I'm trying to find the spanning tree that has minimum total weight. So that's a problem-- a fundamental problem in weighted-graph algorithms. They've solved this via a greedy algorithm. And network flows and I guess cuts. So this is-- what is this? This is, I'm given a weighted graph. Basically, each of the weights correspond to a capacity. I could push water through along this edge. And I may be given a source vertex and a sink vertex. And I want to say, I want to shove water through the source vertex along the edges with their various capacities. And I'll get some amount of water on the other end in the source. So the question is, what's the most amount of water that I can push through this? Well, I could build that pipe network with the different things and just do this experimentally. I just stick a bunch of-- maybe-- I'm a mechanical engineer, so that maybe makes sense to me. But you want to be able to just look at those numbers and be able to tell me how much water can I push through. That's what the max flow in a network is talking about.","69.84901428222656","6","DPRSearchEngine","2NMtS1ecb3o.en-j3PyPqV-e1s_7_mp4","2NMtS1ecb3o.en-j3PyPqV-e1s","6.006","20"
"119","How can we prove that the height of a height-balanced tree is logarithmic with respect to the number of nodes?"," 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 7: Binary Trees II: AVL 
Lecture 7: Binary Trees II: AVL 
Last Time and Today’s Goal 
Sequence 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
build(X) 
get at(i) 
set at(i,x) 
insert first(x) 
delete first() 
insert last(x) 
delete last() 
insert at(i, x) 
delete at(i) 
Binary Tree 
n 
h 
h 
h 
h 
AVL Tree 
n 
log n 
log n 
log n 
log n 
Set 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Binary Tree 
n log n 
h 
h 
h 
h 
AVL Tree 
n log n 
log n 
log n 
log n 
log n 
Height Balance 
• How to maintain height h = O(log n) where n is number of nodes in tree? 
• A binary tree that maintains O(log n) height under dynamic operations is called balanced 
– There are many balancing schemes (Red-Black Trees, Splay Trees, 2-3 Trees, . . . ) 
– First proposed balancing scheme was the AVL Tree (Adelson-Velsky and Landis, 1962) 
Rotations 
• Need to reduce height of tree without changing its traversal order, so that we represent the 
same sequence of items 
• How to change the structure of a tree, while preserving traversal order? Rotations! 
1 
_____<D>__ 
rotate_right(<D>) 
__<B>_____ 
2 
__<B>__ 
<E> 
=> 
<A> 
__<D>__ 
3 
<A> 
<C> 
/ \\ 
/ \\ 
<C> 
<E> 
4 
/ \\ 
/ \\ 
/___\\ 
<= 
/___\\ 
/ \\ 
/ \\ 
5 
/___\\ /___\\ 
rotate_left(<B>) 
/___\\ /___\\ 
• A rotation relinks O(1) pointers to modify tree structure and maintains traversal order 
","69.75631713867188","7","DPRSearchEngine","a2c80596cf4a2b5fbc854afdd2f23dcb_MIT6_006S20_lec7_1_pdf","a2c80596cf4a2b5fbc854afdd2f23dcb_MIT6_006S20_lec7","6.006","7"
"119","How can we prove that the height of a height-balanced tree is logarithmic with respect to the number of nodes?","[SQUEAKING][RUSTLING][CLICKING] JASON KU: Welcome, everybody, to our lecture 14 of 6.006. This is our last lecture on graph algorithms, in particular, the last lecture we'll have on weighted shortest paths. But we're going to talk about a slightly different problem today, different than single source shortest paths. We're going to be talking about all-pairs shortest paths. But first, let's review our single source shortest paths algorithms. We had BFS, DAG relaxation, Dijkstra, which we saw last time, which gets pretty close to linear. V log V plus E is pretty close to linear. It's much closer to linear than the general algorithm we have for solving single source shortest paths, namely, Bellman-Ford, which is a little bit more like quadratic. This is like the difference between-- for sparse graphs, this is like the difference between sorting, using insertion sort and n squared, and merge sort in N log N, for example. We're going to get actually quite a big bonus for large input sizes by using Dijkstra when we can. Today, we're going to be focusing","69.2060546875","8","DPRSearchEngine","EmSmaW-ud6A.en-j3PyPqV-e1s_1_mp4","EmSmaW-ud6A.en-j3PyPqV-e1s","6.006","14"
"119","How can we prove that the height of a height-balanced tree is logarithmic with respect to the number of nodes?","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","68.67646789550781","9","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"119","How can we prove that the height of a height-balanced tree is logarithmic with respect to the number of nodes?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","68.65708923339844","10","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"120","What is the relation used in the divide-and-conquer Bowling Algorithm to calculate B(i, j)?","6 
Lecture 15: Recursive Algorithms 
Bowling Algorithms 
• Let’s start with a more familiar divide-and-conquer algorithm: 
– Subproblems: B(i, j) = maximum score starting with just pins i, i + 1, . . . , j − 1, 
for 0 ≤ i ≤ j ≤ n 
– Relation: 
∗ m = b(i + j)/2c 
∗ Either hit m and m + 1 together, or don’t 
∗ B(i, j) = max{vm · vm+1 + B(i, m) + B(m + 2, j), B(i, m + 1) + B(m + 1, j)} 
– Topo. order: 
Increasing j − i 
– Base cases: 
B(i, i) = 0, B(i, i + 1) = max{vi, 0} 
– Original: 
B(0, n) 
– Time: 
T (n) = 4 T (n/2) + O(1) = O(n2) 
• This algorithm works but isn’t very fast, and doesn’t generalize well 
(e.g., to allow for a bigger ball that hits three balls at once) 
• Dynamic programming algorithm: use sufﬁxes 
– Subproblems: B(i) = maximum score starting with just pins i, i + 1, . . . , n − 1, 
for 0 ≤ i ≤ n 
– Relation: 
∗ Locally brute-force what could happen with ﬁrst pin (original pin i): 
skip pin, hit one pin, hit two pins 
∗ Reduce to smaller sufﬁx and recurse, either B(i + 1) or B(i + 2) 
∗ B(i) = max{B(i + 1), vi + B(i + 1), vi · vi+1 + B(i + 2)} 
– Topo. order: 
Decreasing i (for i = n, n − 1, . . . , 0) 
– Base cases: 
B(n) = B(n + 1) = 0 
– Original: 
B(0) 
– Time: 
(assuming memoization) 
∗ Θ(n) subproblems · Θ(1) work in each 
∗ Θ(n) total time 
• Fast and easy to generalize! 
• Equivalent to maximum-weight path in Subproblem DAG: 
B0 
B1 
B2 
B3 
· · · 
Bn 
max{v0, 0} 
max{v1, 0} 
max{v2, 0} 
v0 · v1 
v1 · v2 
v2 · v3 
","69.55054473876953","1","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_6_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"120","What is the relation used in the divide-and-conquer Bowling Algorithm to calculate B(i, j)?","OK, so this is it. We just take these components, plug them into this recursive, memoized algorithm, and we have a linear time algorithm. I want to briefly mention a different way you could plug together those pieces, which is called bottom up dp, which is-- let's do it for this example. So if I have-- let's see. Let me start with the base case, b of n equals 0. But now it's an assignment. And I'm going to do for loop from the topological order for i equals n, n minus 1 to 0. Now I'm going to do the relation, b of i equals max of b of i plus 1 and b of i plus 1 plus bi and b of i plus 2 plus di vi plus 1. Technically this only works if i is strictly less than n minus 1. So I should have an if i is less than minus 1 for that last part because I can only do-- I can only hit two pins if there's at least two pins left. And then return b of 0. So what I just did is a transformation from this SRTBOT template into a non-recursive algorithm, a for loop algorithm, where I wrote my base case first. Then I did my topological order. Then I did my relation. Then at the end, I did my-- not base case. The original problem. And provided you can write your topological order as some for loops. This is actually a great way to write down a dp as code. If I were going to implement this algorithm, I would write it this way, because this is super fast. No recursive calls. Just one for loop. In fact, this is almost a trivial algorithm. It's amazing that this solves the bowling problem. It's in some sense considering every possible strategy I could for bowling these pins. What we're using is what we like to call local brute force, where when we think about pin i, we look at all of the possible things I could do to pin i, here there's really only three options of what I could do. Now, normally, if I tried all the options for pin i and then all the options for i plus 1 and i plus 2 and so on, that would be exponential. It'd be 3 times 3 times 3. That's bad, but because I can reuse these sub problems, it turns out to only be linear time. It's almost like magic. dp-- dp is essentially an idea of using local brute force. And by defining a small number of sub-problems up front-- and as long as I stay within those sub problems, as long as I'm always recursing into this polynomial space, I end up only doing polynomial work, even though I'm in some sense exploring exponentially many options. And it is because what I do to this pin doesn't depend too much to what I do to a pin much later. There's a lot of intuition going on here for what-- when DP works. But we're going to see a lot more examples of that coming up. And I just want to mention the intuition for how to write a recurrence like this is to think about-- in the case of suffixes, you always want to think about the first item, or maybe the first couple of items. The case of prefixes, you always think about the last item. And for substrings, it could be any item-- maybe in the middle. If I remove an item from the middle of a substring, I get two substrings, so I can recurse. Here or in general, what we want to do is identify some feature of the solution that if we knew that feature we would be done. We would reduce to a smaller sub problem. In this case, we just say, well, what are the possible things I could do to the first pin? There are three options. If I knew which option it was, I would be done. I could recurse and do my addition. Now, I don't know which thing I want to do. So I just try them all and take the max. And if you're maximizing, you take the max. If you're minimizing, you take the min. Sometimes you take an or or an and. There might be some combination function. For optimization problems where you're trying to maximize or minimize something, like shortest paths you're trying to minimize, we put them in here. So usually it's min or max. And this is extremely powerful. All you need to do-- the hard part is this inspired design part where you say, what do I need to know that would let me solve my problem? And if you can identify that and the number of choices for what you need to know is polynomial, then you will be able to get a polynomial dynamic program. That's the intuition. You'll see a lot more examples in the next three lectures.","68.80013275146484","2","DPRSearchEngine","r4-cftqTcdI.en-j3PyPqV-e1s_13_mp4","r4-cftqTcdI.en-j3PyPqV-e1s","6.006","15"
"120","What is the relation used in the divide-and-conquer Bowling Algorithm to calculate B(i, j)?","you will just hit that one pin. And if you bowl in the middle between two pins, you will knock down-- that's a ball, sorry-- you will knock down two pins. And this is your model of bowling, model of computation. Now, what makes this interesting is that the pins have values. Pin i has value-- this is obviously a toy problem, though this problem-- this type of bowling does go back to 1908, it was also a toy problem in that setting. So each of these bowling pins has some number on it, let's say 1, 9, 9-- I'll do a slightly more interesting example, maybe another one here and a 2 and a 5 and a 5, something like this. OK. Or maybe make it a little more interesting. Let's put some negative numbers on here. OK. And the model-- so you're at the carnival bowling. Each pin has different-- potentially different values. And the model is if you hit one pin, i, then you get vi points. So that's straight forward. To make it interesting, when you hit two pins, you get the product. So if I hit two pins, it's always i and i plus 1 for some I. You get vi times vi plus 1 points. This is the game you're playing. And it doesn't really matter that this is a product. Product is just some weird function that's hard to imagine. If you stare at this long enough, you should convince yourself that the optimal solution is probably to-- so, for each of these numbers, I could leave it singleton or pair it with its left neighbor or pair it with its right neighbor. But the pairings can't overlap because once I hit a pin, it's gone. It's knocked over. It disappears. So because of these nine, which are a very high value, what I'd probably like to do is hit both of them together, so pair them up, because 9 times 9 is 81. That's really big, much better than hitting them individually or hitting 9 times 1 or 9 times 2. 1 and 1 is kind of funny, because it's actually better to hit them individually. That will give you two points, whereas if I'd pair them up, I only get one point. 2 and minus 5, that seems bad. Negative 10 points. My goal is to maximize score. Do you have to hit all the pins? Let's say no, you don't have to hit all the pins. So I could skip the minus fives. But in fact, here, because they're adjacent, minus 5 times minus 5 is good. That's 25 points. So the optimal solution for this particular instance are to hit all the pins, these positive, these together, these together. If I added, for example, another pin of minus 3 here, I would choose not to hit that pin. Good question. So you just play until you are tired.","68.7201919555664","3","DPRSearchEngine","r4-cftqTcdI.en-j3PyPqV-e1s_10_mp4","r4-cftqTcdI.en-j3PyPqV-e1s","6.006","15"
"120","What is the relation used in the divide-and-conquer Bowling Algorithm to calculate B(i, j)?","But sometimes it's not enough. And we'll have to go to substrings. That won't be for another lecture or two. Today I claim that prefixes or suffixes are enough to solve the bowling problem. So what we're going to do is think about-- I prefer suffixes usually, because I like to work from left to right, from the beginning to the end. So we're going to think of a suffix of the bowling pins. And so what is the sub-problem on a suffix? Well, a natural version is just to solve the original problem, bowling. How do I maximize my score if all I were given were these pins? Suppose the pins to the left of i didn't exist. How would I maximize my score on the remaining pins? Or for this suffix, given these four pins, what would I do? And there's some weird sub problems here. If I just gave you the last pin, what would you do? Nothing. That's clearly different from what I would do globally here. But I claim if I can solve all suffixes I can solve my original problem, because one of the suffixes is the whole sequence. So let's do it. Sort by for bowling. So here is our dynamic program. The sub-problems are suffixes. So I'll write b of i is the maximum score we could get possible with our starting-- if we started a game with pins i, i plus 1, up to n minus 1, which is a suffix of the pins. Very important whenever you write a dynamic program to define what your sub-problems are. Don't just say how to compute them, but first say what is the goal of the sub problem. This is a common mistake to forget to state what you're trying to do. So now I have defined b of i. Now, what is the original thing I'm trying to solve? You also put in SRTBOT-- you could put the O earlier, then it actually spells sort. So why don't I do that for fun. The original problem we're trying to solve is b of 0, because that is all of the pins. The suffix starting at 0 is everything. So if we can solve that, we're done. Next is r for relate. This is the test of, did I get the sub-problems right, is whether I can write a recurrence relation. So let's try to do it. We want to compute b of i. So we have pin i here and then the remaining pins. And the big idea here is to just think about-- the nice thing about suffixes is if I take off something from the beginning, I still have a suffix. Remember, my goal is to take this sub-problem, which is suffix starting at i, and reduce it to a smaller sub problem, which means a smaller suffix. So I'd like to clip off one or two items here. And then the remaining problem will be one of my sub problems. I'll be able to recursively call b of something smaller than i-- or sorry, b of something larger than i will be a smaller subsequence because we're starting later. OK, so what could I do? Well, the idea is to just look at pin i and think, well, what could I do to pin i? I could not hit it ever with a ball. I could skip it. That's one option. What would be my score then? Well, if I skip pin i, that leaves the remaining pins, which is just a smaller suffix. So that is b of i plus 1. I'm going to write a max out here because I'd like to maximize my score. And one of the options is, forget about pin i. Just solve the rest. Another option is I throw a ball. And I exactly hit pin i. That's one thing I could do. And it would leave exactly the same remainder. So another option is b of i plus 1 plus vi. Why would I prefer this over this? Well, if vi is negative, I'd prefer this. But if vi is positive, I'd actually prefer this over that. So you can figure out which is better, just locally. But then there's another thing I can do, which is maybe I hit this pin in a pair with some other pin. Now, there's no pin to the left of this one. We're assuming we only have the suffix. And so the only other thing I can do is throw a ball and hit i together with i plus 1. And then I get the product. Now, what pins remain? i plus 2 on. Still a suffix. So if I remove one or two items, of course, I still get a suffix-- in this case, b of i plus 2-- and then the number of points that I add on are vi times vi plus 1. So this is a max of three things. So how long does it take me to compute it? I claim constant time. If I don't count the time it takes to compute these other sub problems, which are smaller because they are smaller suffixes further to the right, then I'm doing a couple of additions-- product, max. These are all nice numbers and I'll assume that they live in the w-bit word, because we're only doing constant sized products. That's good. So this takes constant, constant non-recursive work. How many sub problems are? Well, it's suffixes, so it's a linear number of sub problems. And so the time I'm going to end up needing is number of sub problems, n, times the non-recursive work I do per sub problem, which is constant. And so this is linear time. Great. And I didn't finish SRTBOT, so there's another t, which is to make sure that there is a topological order and that is in decreasing i order. Or I might write that as a for loop-- for i equals n, n minus 1. This is the order that I would compute my problems because the suffix starting at n is the empty suffix. The suffix starting at 0, that's the one I actually want to compute. That's the final suffix I should be computing. And then we have a b for base case, which is that first case, b of n equals 0, because there's no pins. So I don't get any points. Sad.","67.82552337646484","4","DPRSearchEngine","r4-cftqTcdI.en-j3PyPqV-e1s_12_mp4","r4-cftqTcdI.en-j3PyPqV-e1s","6.006","15"
"120","What is the relation used in the divide-and-conquer Bowling Algorithm to calculate B(i, j)?","which is merge sort, so a divide and conquer algorithm, phrased with this structure of SRTBOT. So for the sub problems-- so our original problem is to sort the elements of A. And some sub-problems that we solve along the way are sorting different sub-arrays of A. So for every-- well, not for every i and j, but for some i and js, we sort the items from i up to j minus 1. So I'm going to define that subproblem to be s of ij. So this is something that I might want to solve. The original problem that I want to solve is s of 0 comma n, where n is the length of the array. So that's what I actually care about in the end. But we're going to solve that by writing it recursively in terms of sorting different sub-arrays as follows. This is the recurrence relation. I've written it very simply here. Of course, there's a merge algorithm, which is somewhat complicated. But as we saw the two finger linear time merge algorithm, given two sorted arrays-- so this is supposed to be the sorted array version of the items i through m. m is the middle element between i and j and the sorted array of the items from m up to j. If we merge those, that gives us the sorted array from i up to j. And that's exactly what merge sort does. So in general, this relation is just some algorithm for if you're given the solutions to some smaller subproblems, how do I solve the subproblem that I want to solve? And so we need to make sure that this problem is bigger than the ones that we recursively call on and that we don't get an infinite cyclic loop of recursions. And here our valid topological order is to say, solve these problems in order where j minus i-- the length of the sub-array-- is increasing. And then you can check because m is strictly between i and j. As long as we're not in a base case, then we know we can-- these subarrays will be smaller than this one. And so this increasing order gives us a valid topological order on all of the problems, all the subproblems. We have a base case, which is if we don't want to sort anything, that's the empty array, or at least in the original problem. And then running time is-- I mean, there's no better way to solve it than the recurrence that we already saw how to solve. So this is just another way to think of n log n","67.68305969238281","5","DPRSearchEngine","r4-cftqTcdI.en-j3PyPqV-e1s_3_mp4","r4-cftqTcdI.en-j3PyPqV-e1s","6.006","15"
"120","What is the relation used in the divide-and-conquer Bowling Algorithm to calculate B(i, j)?","  
 
 
  
 
 
 
    
 
    
 
 
        
 
        
 
            
 
        
 
            
  
    
 
          
 
    
 
 
    
 
          
 
 
 
 
A Simulation of Die Rolling  
def runSim(goal, numTrials, txt): 
total = 0 
for i in range(numTrials): 
result = '' 
for j in range(len(goal)): 
result += str(rollDie()) 
if result == goal: 
total += 1 
print('Actual probability of', txt, '=', 
round(1/(6**len(goal)), 8)) 
estProbability = round(total/numTrials, 8) 
print('Estimated Probability of', txt, '=', 
round(estProbability, 8)) 
runSim('11111', 1000, '11111') 
6.0002 LECTURE 4 
15
","66.52985382080078","6","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_15_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"120","What is the relation used in the divide-and-conquer Bowling Algorithm to calculate B(i, j)?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","66.50345611572266","7","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"120","What is the relation used in the divide-and-conquer Bowling Algorithm to calculate B(i, j)?","7 
Lecture 18: Pseudopolynomial 
Main Features of Dynamic Programs 
• Review of examples from lecture 
• Subproblems: 
– Preﬁx/sufﬁxes: Bowling, LCS, LIS, Floyd–Warshall, Rod Cutting (coincidentally, re­
ally Integer subproblems), Subset Sum 
– Substrings: Alternating Coin Game, Arithmetic Parenthesization 
– Multiple sequences: LCS 
– Integers: Fibonacci, Rod Cutting, Subset Sum 
Pseudopolynomial: Fibonacci, Subset Sum 
* 
– Vertices: DAG shortest paths, Bellman–Ford, Floyd–Warshall 
• Subproblem constraints/expansion: 
– Nonexpansive constraint: LIS (include ﬁrst item) 
– 2× expansion: Alternating Coin Game (who goes ﬁrst?), Arithmetic Parenthesization 
(min/max) 
– Θ(1)× expansion: Piano Fingering (ﬁrst ﬁnger assignment) 
– Θ(n)× expansion: Bellman–Ford (# edges) 
• Relation: 
– Branching = # dependant subproblems in each subproblem 
– Θ(1) branching: Fibonacci, Bowling, LCS, Alternating Coin Game, Floyd–Warshall, 
Subset Sum 
– Θ(degree) branching (source of |E| in running time): DAG shortest paths, Bellman– 
Ford 
– Θ(n) branching: LIS, Arithmetic Parenthesization, Rod Cutting 
– Combine multiple solutions (not path in subproblem DAG): Fibonacci, Floyd– 
Warshall, Arithmetic Parenthesization 
• Original problem: 
– Combine multiple subproblems: DAG shortest paths, Bellman–Ford, Floyd–Warshall, 
LIS, Piano Fingering 
","66.23255920410156","8","DPRSearchEngine","mit6_006s20_lec18_7_pdf","mit6_006s20_lec18","6.006","18"
"120","What is the relation used in the divide-and-conquer Bowling Algorithm to calculate B(i, j)?","-
numTrials = 1000000
numSpins = 200
game = FairRoulette()
means = []
for i in range(numTrials):
means.append(findPocketReturn(game, 1, numSpins,
False)[0])
pylab.hist(means, bins = 19,
weights = [1/len(means)]*len(means))
pylab.xlabel('Mean Return')
pylab.ylabel('Probability')
pylab.title('Expected Return Betting a Pocket 200 Times')
	


","66.22262573242188","9","DPRSearchEngine","3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7_17_pdf","3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7","6.0002","7"
"120","What is the relation used in the divide-and-conquer Bowling Algorithm to calculate B(i, j)?","	
	! 
for f in range(numSubsets): 
    trainX,trainY,testX,testY = splitData(xVals, yVals) 
    for d in dimensions: 
        model = pylab.polyfit(trainX, trainY, d) 
        #estYVals = pylab.polyval(model, trainX) 
        estYVals = pylab.polyval(model, testX) 
        rSquares[d].append(rSquared(testY, estYVals)) 
 
print('Mean R-squares for test data') 
for d in dimensions: 
    mean = round(sum(rSquares[d])/len(rSquares[d]), 4) 
    sd = round(numpy.std(rSquares[d]), 4) 
    print('For dimensionality', d, 'mean =', mean, 
          'Std =', sd) 
	

?F
","66.04595184326172","10","DPRSearchEngine","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10_47_pdf","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10","6.0002","10"
"121","How does the dynamic programming approach for the Bowling Algorithm generalize the problem better compared to the divide-and-conquer method?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","71.97013092041016","1","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"121","How does the dynamic programming approach for the Bowling Algorithm generalize the problem better compared to the divide-and-conquer method?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 4: Hashing 
Lecture 4: Hashing 
Review 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
• Idea! Want faster search and dynamic operations. Can we find(k) faster than Θ(log n)? 
• Answer is no (lower bound)! (But actually, yes...!?) 
Comparison Model 
• In this model, assume algorithm can only differentiate items via comparisons 
• Comparable items: black boxes only supporting comparisons between pairs 
• Comparisons are <, ≤, >, ≥, =, =6 , outputs are binary: True or False 
• Goal: Store a set of n comparable items, support find(k) operation 
• Running time is lower bounded by # comparisons performed, so count comparisons! 
Decision Tree 
• Any algorithm can be viewed as a decision tree of operations performed 
• An internal node represents a binary comparison, branching either True or False 
• For a comparison algorithm, the decision tree is binary (draw example) 
• A leaf represents algorithm termination, resulting in an algorithm output 
• A root-to-leaf path represents an execution of the algorithm on some input 
• Need at least one leaf for each algorithm output, so search requires ≥ n + 1 leaves 
","67.98587799072266","2","DPRSearchEngine","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_1_pdf","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4","6.006","4"
"121","How does the dynamic programming approach for the Bowling Algorithm generalize the problem better compared to the divide-and-conquer method?","6 
Lecture 15: Recursive Algorithms 
Bowling Algorithms 
• Let’s start with a more familiar divide-and-conquer algorithm: 
– Subproblems: B(i, j) = maximum score starting with just pins i, i + 1, . . . , j − 1, 
for 0 ≤ i ≤ j ≤ n 
– Relation: 
∗ m = b(i + j)/2c 
∗ Either hit m and m + 1 together, or don’t 
∗ B(i, j) = max{vm · vm+1 + B(i, m) + B(m + 2, j), B(i, m + 1) + B(m + 1, j)} 
– Topo. order: 
Increasing j − i 
– Base cases: 
B(i, i) = 0, B(i, i + 1) = max{vi, 0} 
– Original: 
B(0, n) 
– Time: 
T (n) = 4 T (n/2) + O(1) = O(n2) 
• This algorithm works but isn’t very fast, and doesn’t generalize well 
(e.g., to allow for a bigger ball that hits three balls at once) 
• Dynamic programming algorithm: use sufﬁxes 
– Subproblems: B(i) = maximum score starting with just pins i, i + 1, . . . , n − 1, 
for 0 ≤ i ≤ n 
– Relation: 
∗ Locally brute-force what could happen with ﬁrst pin (original pin i): 
skip pin, hit one pin, hit two pins 
∗ Reduce to smaller sufﬁx and recurse, either B(i + 1) or B(i + 2) 
∗ B(i) = max{B(i + 1), vi + B(i + 1), vi · vi+1 + B(i + 2)} 
– Topo. order: 
Decreasing i (for i = n, n − 1, . . . , 0) 
– Base cases: 
B(n) = B(n + 1) = 0 
– Original: 
B(0) 
– Time: 
(assuming memoization) 
∗ Θ(n) subproblems · Θ(1) work in each 
∗ Θ(n) total time 
• Fast and easy to generalize! 
• Equivalent to maximum-weight path in Subproblem DAG: 
B0 
B1 
B2 
B3 
· · · 
Bn 
max{v0, 0} 
max{v1, 0} 
max{v2, 0} 
v0 · v1 
v1 · v2 
v2 · v3 
","67.83025360107422","3","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_6_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"121","How does the dynamic programming approach for the Bowling Algorithm generalize the problem better compared to the divide-and-conquer method?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 5: Linear Sorting 
Lecture 5: Linear Sorting 
Review 
• Comparison search lower bound: any decision tree with n nodes has height ≥dlg(n+1)e−1 
• Can do faster using random access indexing: an operation with linear branching factor! 
• Direct access array is fast, but may use a lot of space (Θ(u)) 
• Solve space problem by mapping (hashing) key space u down to m = Θ(n) 
• Hash tables give expected O(1) time operations, amortized if dynamic 
• Expectation input-independent: choose hash function randomly from universal hash family 
• Data structure overview! 
• Last time we achieved faster ﬁnd. Can we also achieve faster sort? 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
Direct Access Array 
u 
1 
1 
u 
u 
Hash Table 
n(e) 
1(e) 
1(a)(e) 
n 
n 
","67.09771728515625","4","DPRSearchEngine","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5_1_pdf","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5","6.006","5"
"121","How does the dynamic programming approach for the Bowling Algorithm generalize the problem better compared to the divide-and-conquer method?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","67.03116607666016","5","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"121","How does the dynamic programming approach for the Bowling Algorithm generalize the problem better compared to the divide-and-conquer method?","7 
Lecture 18: Pseudopolynomial 
Main Features of Dynamic Programs 
• Review of examples from lecture 
• Subproblems: 
– Preﬁx/sufﬁxes: Bowling, LCS, LIS, Floyd–Warshall, Rod Cutting (coincidentally, re­
ally Integer subproblems), Subset Sum 
– Substrings: Alternating Coin Game, Arithmetic Parenthesization 
– Multiple sequences: LCS 
– Integers: Fibonacci, Rod Cutting, Subset Sum 
Pseudopolynomial: Fibonacci, Subset Sum 
* 
– Vertices: DAG shortest paths, Bellman–Ford, Floyd–Warshall 
• Subproblem constraints/expansion: 
– Nonexpansive constraint: LIS (include ﬁrst item) 
– 2× expansion: Alternating Coin Game (who goes ﬁrst?), Arithmetic Parenthesization 
(min/max) 
– Θ(1)× expansion: Piano Fingering (ﬁrst ﬁnger assignment) 
– Θ(n)× expansion: Bellman–Ford (# edges) 
• Relation: 
– Branching = # dependant subproblems in each subproblem 
– Θ(1) branching: Fibonacci, Bowling, LCS, Alternating Coin Game, Floyd–Warshall, 
Subset Sum 
– Θ(degree) branching (source of |E| in running time): DAG shortest paths, Bellman– 
Ford 
– Θ(n) branching: LIS, Arithmetic Parenthesization, Rod Cutting 
– Combine multiple solutions (not path in subproblem DAG): Fibonacci, Floyd– 
Warshall, Arithmetic Parenthesization 
• Original problem: 
– Combine multiple subproblems: DAG shortest paths, Bellman–Ford, Floyd–Warshall, 
LIS, Piano Fingering 
","66.80862426757812","6","DPRSearchEngine","mit6_006s20_lec18_7_pdf","mit6_006s20_lec18","6.006","18"
"121","How does the dynamic programming approach for the Bowling Algorithm generalize the problem better compared to the divide-and-conquer method?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","66.3825912475586","7","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"121","How does the dynamic programming approach for the Bowling Algorithm generalize the problem better compared to the divide-and-conquer method?","OK, so this is it. We just take these components, plug them into this recursive, memoized algorithm, and we have a linear time algorithm. I want to briefly mention a different way you could plug together those pieces, which is called bottom up dp, which is-- let's do it for this example. So if I have-- let's see. Let me start with the base case, b of n equals 0. But now it's an assignment. And I'm going to do for loop from the topological order for i equals n, n minus 1 to 0. Now I'm going to do the relation, b of i equals max of b of i plus 1 and b of i plus 1 plus bi and b of i plus 2 plus di vi plus 1. Technically this only works if i is strictly less than n minus 1. So I should have an if i is less than minus 1 for that last part because I can only do-- I can only hit two pins if there's at least two pins left. And then return b of 0. So what I just did is a transformation from this SRTBOT template into a non-recursive algorithm, a for loop algorithm, where I wrote my base case first. Then I did my topological order. Then I did my relation. Then at the end, I did my-- not base case. The original problem. And provided you can write your topological order as some for loops. This is actually a great way to write down a dp as code. If I were going to implement this algorithm, I would write it this way, because this is super fast. No recursive calls. Just one for loop. In fact, this is almost a trivial algorithm. It's amazing that this solves the bowling problem. It's in some sense considering every possible strategy I could for bowling these pins. What we're using is what we like to call local brute force, where when we think about pin i, we look at all of the possible things I could do to pin i, here there's really only three options of what I could do. Now, normally, if I tried all the options for pin i and then all the options for i plus 1 and i plus 2 and so on, that would be exponential. It'd be 3 times 3 times 3. That's bad, but because I can reuse these sub problems, it turns out to only be linear time. It's almost like magic. dp-- dp is essentially an idea of using local brute force. And by defining a small number of sub-problems up front-- and as long as I stay within those sub problems, as long as I'm always recursing into this polynomial space, I end up only doing polynomial work, even though I'm in some sense exploring exponentially many options. And it is because what I do to this pin doesn't depend too much to what I do to a pin much later. There's a lot of intuition going on here for what-- when DP works. But we're going to see a lot more examples of that coming up. And I just want to mention the intuition for how to write a recurrence like this is to think about-- in the case of suffixes, you always want to think about the first item, or maybe the first couple of items. The case of prefixes, you always think about the last item. And for substrings, it could be any item-- maybe in the middle. If I remove an item from the middle of a substring, I get two substrings, so I can recurse. Here or in general, what we want to do is identify some feature of the solution that if we knew that feature we would be done. We would reduce to a smaller sub problem. In this case, we just say, well, what are the possible things I could do to the first pin? There are three options. If I knew which option it was, I would be done. I could recurse and do my addition. Now, I don't know which thing I want to do. So I just try them all and take the max. And if you're maximizing, you take the max. If you're minimizing, you take the min. Sometimes you take an or or an and. There might be some combination function. For optimization problems where you're trying to maximize or minimize something, like shortest paths you're trying to minimize, we put them in here. So usually it's min or max. And this is extremely powerful. All you need to do-- the hard part is this inspired design part where you say, what do I need to know that would let me solve my problem? And if you can identify that and the number of choices for what you need to know is polynomial, then you will be able to get a polynomial dynamic program. That's the intuition. You'll see a lot more examples in the next three lectures.","66.29910278320312","8","DPRSearchEngine","r4-cftqTcdI.en-j3PyPqV-e1s_13_mp4","r4-cftqTcdI.en-j3PyPqV-e1s","6.006","15"
"121","How does the dynamic programming approach for the Bowling Algorithm generalize the problem better compared to the divide-and-conquer method?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 10: Depth-First Search 
Lecture 10: Depth-First Search 
Previously 
• Graph deﬁnitions (directed/undirected, simple, neighbors, degree) 
• Graph representations (Set mapping vertices to adjacency lists) 
• Paths and simple paths, path length, distance, shortest path 
• Graph Path Problems 
– Single Pair Reachability(G,s,t) 
– Single Source Reachability(G,s) 
– Single Pair Shortest Path(G,s,t) 
– Single Source Shortest Paths(G,s) (SSSP) 
• Breadth-First Search (BFS) 
– algorithm that solves Single Source Shortest Paths 
– with appropriate data structures, runs in O(|V | + |E|) time (linear in input size) 
Examples 
G1 
a 
d 
b 
e 
c 
f 
G2 
a 
d 
b 
e 
c 
f 
","66.15737915039062","9","DPRSearchEngine","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10_1_pdf","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10","6.006","10"
"121","How does the dynamic programming approach for the Bowling Algorithm generalize the problem better compared to the divide-and-conquer method?","2 
Lecture 20: Course Review 
Next Steps 
• (U) 6.046: Design & Analysis of Algorithms 
• (G) 6.851: Advanced Data Structures 
• (G) 6.854: Advanced Algorithms 
6.046 
• Extension of 6.006 
– Data Structures: Union-Find, Amortization via potential analysis 
– Graphs: Minimum Spanning Trees, Network Flows/Cuts 
– Algorithm Design (Paradigms): Divide & Conquer, Dynamic Programming, Greedy 
– Complexity: Reductions 
• Relax Problem (change deﬁnition of correct/efﬁcient) 
– Randomized Algorithms 
∗ 6.006 mostly deterministic (hashing) 
∗ Las Vegas: always correct, probably fast (like hashing) 
∗ Monte Carlo: always fast, probably correct 
∗ Can generally get faster randomized algorithms on structured data 
– Numerical Algorithms/Continuous Optimization 
∗ 6.006 only deals with integers 
∗ Approximate real numbers! Pay time for precision 
– Approximation Algorithms 
∗ Input optimization problem (min/max over weighted outputs) 
∗ Many optimization problems NP-hard 
∗ How close can we get to an optimal solution in polynomial time? 
• Change Model of Computation 
– Cache Models (memory hierarchy cost model) 
– Quantum Computer (exploiting quantum properties) 
– Parallel Processors (use multiple CPUs instead of just one) 
∗ Multicore, large shared memory 
∗ Distributed cores, message passing 
","65.92469787597656","10","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_2_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"122","How is the maximum score obtained in the dynamic programming Bowling Algorithm according to its relation?","6 
Lecture 15: Recursive Algorithms 
Bowling Algorithms 
• Let’s start with a more familiar divide-and-conquer algorithm: 
– Subproblems: B(i, j) = maximum score starting with just pins i, i + 1, . . . , j − 1, 
for 0 ≤ i ≤ j ≤ n 
– Relation: 
∗ m = b(i + j)/2c 
∗ Either hit m and m + 1 together, or don’t 
∗ B(i, j) = max{vm · vm+1 + B(i, m) + B(m + 2, j), B(i, m + 1) + B(m + 1, j)} 
– Topo. order: 
Increasing j − i 
– Base cases: 
B(i, i) = 0, B(i, i + 1) = max{vi, 0} 
– Original: 
B(0, n) 
– Time: 
T (n) = 4 T (n/2) + O(1) = O(n2) 
• This algorithm works but isn’t very fast, and doesn’t generalize well 
(e.g., to allow for a bigger ball that hits three balls at once) 
• Dynamic programming algorithm: use sufﬁxes 
– Subproblems: B(i) = maximum score starting with just pins i, i + 1, . . . , n − 1, 
for 0 ≤ i ≤ n 
– Relation: 
∗ Locally brute-force what could happen with ﬁrst pin (original pin i): 
skip pin, hit one pin, hit two pins 
∗ Reduce to smaller sufﬁx and recurse, either B(i + 1) or B(i + 2) 
∗ B(i) = max{B(i + 1), vi + B(i + 1), vi · vi+1 + B(i + 2)} 
– Topo. order: 
Decreasing i (for i = n, n − 1, . . . , 0) 
– Base cases: 
B(n) = B(n + 1) = 0 
– Original: 
B(0) 
– Time: 
(assuming memoization) 
∗ Θ(n) subproblems · Θ(1) work in each 
∗ Θ(n) total time 
• Fast and easy to generalize! 
• Equivalent to maximum-weight path in Subproblem DAG: 
B0 
B1 
B2 
B3 
· · · 
Bn 
max{v0, 0} 
max{v1, 0} 
max{v2, 0} 
v0 · v1 
v1 · v2 
v2 · v3 
","69.33363342285156","1","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_6_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"122","How is the maximum score obtained in the dynamic programming Bowling Algorithm according to its relation?",";
/
def testGreedys(maxUnits):
print('Use greedy by value to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits, Food.getValue)
print('\\nUse greedy by cost to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits,
lambda x: 1/Food.getCost(x))
print('\\nUse greedy by density to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits, Food.density)
testGreedys(800)
	


4
","68.7877426147461","2","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_26_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"122","How is the maximum score obtained in the dynamic programming Bowling Algorithm according to its relation?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
Regression to the Mean  
Following an extreme random event, the next random 
event is likely to be less extreme 
If you spin a fair roulette wheel 10 times and get 100% 
reds, that is an extreme event (probability = 1/1024) 
It is likely that in the next 10 spins, you will get fewer 
than 10 reds 
◦ But the expected number is only 5 
So, if you look at the average of the 20 spins, it will be 
closer to the expected mean of 50% reds than to the 
100% of the first 10 spins 
6.0002 LECTURE 6 
16
","68.00691223144531","3","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_16_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"122","How is the maximum score obtained in the dynamic programming Bowling Algorithm according to its relation?","you will just hit that one pin. And if you bowl in the middle between two pins, you will knock down-- that's a ball, sorry-- you will knock down two pins. And this is your model of bowling, model of computation. Now, what makes this interesting is that the pins have values. Pin i has value-- this is obviously a toy problem, though this problem-- this type of bowling does go back to 1908, it was also a toy problem in that setting. So each of these bowling pins has some number on it, let's say 1, 9, 9-- I'll do a slightly more interesting example, maybe another one here and a 2 and a 5 and a 5, something like this. OK. Or maybe make it a little more interesting. Let's put some negative numbers on here. OK. And the model-- so you're at the carnival bowling. Each pin has different-- potentially different values. And the model is if you hit one pin, i, then you get vi points. So that's straight forward. To make it interesting, when you hit two pins, you get the product. So if I hit two pins, it's always i and i plus 1 for some I. You get vi times vi plus 1 points. This is the game you're playing. And it doesn't really matter that this is a product. Product is just some weird function that's hard to imagine. If you stare at this long enough, you should convince yourself that the optimal solution is probably to-- so, for each of these numbers, I could leave it singleton or pair it with its left neighbor or pair it with its right neighbor. But the pairings can't overlap because once I hit a pin, it's gone. It's knocked over. It disappears. So because of these nine, which are a very high value, what I'd probably like to do is hit both of them together, so pair them up, because 9 times 9 is 81. That's really big, much better than hitting them individually or hitting 9 times 1 or 9 times 2. 1 and 1 is kind of funny, because it's actually better to hit them individually. That will give you two points, whereas if I'd pair them up, I only get one point. 2 and minus 5, that seems bad. Negative 10 points. My goal is to maximize score. Do you have to hit all the pins? Let's say no, you don't have to hit all the pins. So I could skip the minus fives. But in fact, here, because they're adjacent, minus 5 times minus 5 is good. That's 25 points. So the optimal solution for this particular instance are to hit all the pins, these positive, these together, these together. If I added, for example, another pin of minus 3 here, I would choose not to hit that pin. Good question. So you just play until you are tired.","67.66128540039062","4","DPRSearchEngine","r4-cftqTcdI.en-j3PyPqV-e1s_10_mp4","r4-cftqTcdI.en-j3PyPqV-e1s","6.006","15"
"122","How is the maximum score obtained in the dynamic programming Bowling Algorithm according to its relation?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","67.52983093261719","5","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"122","How is the maximum score obtained in the dynamic programming Bowling Algorithm according to its relation?"," 
 
 
 
 
Lecture: Sampling and 
Standard Error 
6.0002  LECTURE 8 
 
1
","67.52880859375","6","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_1_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"122","How is the maximum score obtained in the dynamic programming Bowling Algorithm according to its relation?"," 
 
 
  
 
 
 
    
 
 
    
 
        
 
        
 
 
    
 
        
 
 
 
 
        
 
 
 
              
 
    
 
 
 
  
 
 
 
 
    
 
 
        
 
 
 
Monte Carlo Simulation  
def playRoulette(game, numSpins, pocket, bet): 
totPocket = 0 
for i in range(numSpins): 
game.spin()  
totPocket += game.betPocket(pocket, bet)  
if toPrint: 
print(numSpins, 'spins of', game) 
print('Expected return betting', pocket, '=',\\ 
str(100*totPocket/numSpins) + '%\\n') 
return (totPocket/numSpins) 
game = FairRoulette() 
for numSpins in (100, 1000000): 
for i in range(3): 
playRoulette(game, numSpins, 2, 1, True) 
6.0002 LECTURE 6 
12
","67.45280456542969","7","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_12_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"122","How is the maximum score obtained in the dynamic programming Bowling Algorithm according to its relation?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 4: Hashing 
Lecture 4: Hashing 
Review 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
• Idea! Want faster search and dynamic operations. Can we find(k) faster than Θ(log n)? 
• Answer is no (lower bound)! (But actually, yes...!?) 
Comparison Model 
• In this model, assume algorithm can only differentiate items via comparisons 
• Comparable items: black boxes only supporting comparisons between pairs 
• Comparisons are <, ≤, >, ≥, =, =6 , outputs are binary: True or False 
• Goal: Store a set of n comparable items, support find(k) operation 
• Running time is lower bounded by # comparisons performed, so count comparisons! 
Decision Tree 
• Any algorithm can be viewed as a decision tree of operations performed 
• An internal node represents a binary comparison, branching either True or False 
• For a comparison algorithm, the decision tree is binary (draw example) 
• A leaf represents algorithm termination, resulting in an algorithm output 
• A root-to-leaf path represents an execution of the algorithm on some input 
• Need at least one leaf for each algorithm output, so search requires ≥ n + 1 leaves 
","67.08103942871094","8","DPRSearchEngine","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_1_pdf","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4","6.006","4"
"122","How is the maximum score obtained in the dynamic programming Bowling Algorithm according to its relation?","  
 
 
  
 
 
 
    
 
    
 
 
        
 
        
 
            
 
        
 
            
  
    
 
          
 
    
 
 
    
 
          
 
 
 
 
A Simulation of Die Rolling  
def runSim(goal, numTrials, txt): 
total = 0 
for i in range(numTrials): 
result = '' 
for j in range(len(goal)): 
result += str(rollDie()) 
if result == goal: 
total += 1 
print('Actual probability of', txt, '=', 
round(1/(6**len(goal)), 8)) 
estProbability = round(total/numTrials, 8) 
print('Estimated Probability of', txt, '=', 
round(estProbability, 8)) 
runSim('11111', 1000, '11111') 
6.0002 LECTURE 4 
15
","67.03321838378906","9","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_15_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"122","How is the maximum score obtained in the dynamic programming Bowling Algorithm according to its relation?","7 
Lecture 18: Pseudopolynomial 
Main Features of Dynamic Programs 
• Review of examples from lecture 
• Subproblems: 
– Preﬁx/sufﬁxes: Bowling, LCS, LIS, Floyd–Warshall, Rod Cutting (coincidentally, re­
ally Integer subproblems), Subset Sum 
– Substrings: Alternating Coin Game, Arithmetic Parenthesization 
– Multiple sequences: LCS 
– Integers: Fibonacci, Rod Cutting, Subset Sum 
Pseudopolynomial: Fibonacci, Subset Sum 
* 
– Vertices: DAG shortest paths, Bellman–Ford, Floyd–Warshall 
• Subproblem constraints/expansion: 
– Nonexpansive constraint: LIS (include ﬁrst item) 
– 2× expansion: Alternating Coin Game (who goes ﬁrst?), Arithmetic Parenthesization 
(min/max) 
– Θ(1)× expansion: Piano Fingering (ﬁrst ﬁnger assignment) 
– Θ(n)× expansion: Bellman–Ford (# edges) 
• Relation: 
– Branching = # dependant subproblems in each subproblem 
– Θ(1) branching: Fibonacci, Bowling, LCS, Alternating Coin Game, Floyd–Warshall, 
Subset Sum 
– Θ(degree) branching (source of |E| in running time): DAG shortest paths, Bellman– 
Ford 
– Θ(n) branching: LIS, Arithmetic Parenthesization, Rod Cutting 
– Combine multiple solutions (not path in subproblem DAG): Fibonacci, Floyd– 
Warshall, Arithmetic Parenthesization 
• Original problem: 
– Combine multiple subproblems: DAG shortest paths, Bellman–Ford, Floyd–Warshall, 
LIS, Piano Fingering 
","67.03103637695312","10","DPRSearchEngine","mit6_006s20_lec18_7_pdf","mit6_006s20_lec18","6.006","18"
"123","What are the three cases for adjustment in an AVL tree when the lowest bad node has been identified, and how are rotations applied in each case to restore balance?"," 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 7: Binary Trees II: AVL 
Lecture 7: Binary Trees II: AVL 
Last Time and Today’s Goal 
Sequence 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
build(X) 
get at(i) 
set at(i,x) 
insert first(x) 
delete first() 
insert last(x) 
delete last() 
insert at(i, x) 
delete at(i) 
Binary Tree 
n 
h 
h 
h 
h 
AVL Tree 
n 
log n 
log n 
log n 
log n 
Set 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Binary Tree 
n log n 
h 
h 
h 
h 
AVL Tree 
n log n 
log n 
log n 
log n 
log n 
Height Balance 
• How to maintain height h = O(log n) where n is number of nodes in tree? 
• A binary tree that maintains O(log n) height under dynamic operations is called balanced 
– There are many balancing schemes (Red-Black Trees, Splay Trees, 2-3 Trees, . . . ) 
– First proposed balancing scheme was the AVL Tree (Adelson-Velsky and Landis, 1962) 
Rotations 
• Need to reduce height of tree without changing its traversal order, so that we represent the 
same sequence of items 
• How to change the structure of a tree, while preserving traversal order? Rotations! 
1 
_____<D>__ 
rotate_right(<D>) 
__<B>_____ 
2 
__<B>__ 
<E> 
=> 
<A> 
__<D>__ 
3 
<A> 
<C> 
/ \\ 
/ \\ 
<C> 
<E> 
4 
/ \\ 
/ \\ 
/___\\ 
<= 
/___\\ 
/ \\ 
/ \\ 
5 
/___\\ /___\\ 
rotate_left(<B>) 
/___\\ /___\\ 
• A rotation relinks O(1) pointers to modify tree structure and maintains traversal order 
","68.4503173828125","1","DPRSearchEngine","a2c80596cf4a2b5fbc854afdd2f23dcb_MIT6_006S20_lec7_1_pdf","a2c80596cf4a2b5fbc854afdd2f23dcb_MIT6_006S20_lec7","6.006","7"
"123","What are the three cases for adjustment in an AVL tree when the lowest bad node has been identified, and how are rotations applied in each case to restore balance?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","68.25636291503906","2","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"123","What are the three cases for adjustment in an AVL tree when the lowest bad node has been identified, and how are rotations applied in each case to restore balance?","can do in a tree that won't affect any of the stuff we've done so far. It's a tool that we can use to rebalance. Notice how deep things are in the tree changes. Our problem with this linear tree is that there are some nodes of linear depth. We want to get rid of those. How? Well, we could take these edges and start rotating them up. If you look at depths, in this picture, A and B are deeper than C. And in this picture, B and C are deeper than A. So it's a trade off. This one moved up. This one moved down. This one stayed at the same depth. So hopefully, if A is too deep and C is too shallow, they can trade off like this. It may sound difficult, but in fact, there's a pretty simple way, which are called AVL trees, that maintain balance in a particular way called height balance. This is if we take the height of node.left-- actually, I'd prefer to-- node.right, minus height of node.left,","65.94236755371094","3","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_18_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"123","What are the three cases for adjustment in an AVL tree when the lowest bad node has been identified, and how are rotations applied in each case to restore balance?","Header for Decision Tree Implementa#on 
6.0002 LECTURE 2 
9 
def maxVal(toConsider, avail): 
    """"""Assumes toConsider a list of items,  
               avail a weight 
       Returns a tuple of the total value of a  
           solution to 0/1 knapsack problem and  
           the items of that solution""""” 
toConsider. Those items that nodes higher up in the tree 
(corresponding to earlier calls in the recursive call stack) 
have not yet considered 
 
avail. The amount of space still available  
","65.74683380126953","4","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_9_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"123","What are the three cases for adjustment in an AVL tree when the lowest bad node has been identified, and how are rotations applied in each case to restore balance?"," 
 
 
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
  
 
  
 
  
 
 
  
 
 
   
 
 
   
 
 
 
 
TMs and Encodings – review 
A TM has 3 possible outcomes for each input !: 
1. Accept ! (enter ""acc ) 
2. Reject ! by halting (enter ""rej ) 
3. Reject ! by looping (running forever) 
( is T-recognizable if ( = *(,) for some TM ,. 
( is T-decidable if ( = *(,) for some TM decider ,. 
halts on all inputs 
〈/0, /2, … , /4〉 encodes objects /0, /2, … , /4 as a single string. 
Notation for writing a TM , is 
, = “On input ! 
[English description of the algorithm]” 
2 
","65.63420104980469","5","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_2_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"123","What are the three cases for adjustment in an AVL tree when the lowest bad node has been identified, and how are rotations applied in each case to restore balance?"," 
 
 
   
 
 
 
   
   
      
 
 
 
 
 
 
  
 
Stochastic Processes  
An ongoing process where the next state might depend on 
both the previous states and some random element 
def rollDie(): 
"""""" returns an int between 1 and 6"""""" 
def rollDie(): 
"""""" returns a randomly chosen int 
between 1 and 6"""""" 
6.0002 LECTURE 4 
8
","65.50749969482422","6","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_8_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"123","What are the three cases for adjustment in an AVL tree when the lowest bad node has been identified, and how are rotations applied in each case to restore balance?","4 
Lecture 7: Binary Trees II: AVL 
• Global Rebalance: Add or remove a leaf from height-balanced tree T to produce tree T 0 . 
Then T 0 can be transformed into a height-balanced tree T 00 using at most O(log n) rotations. 
• Proof: 
– Only ancestors of the affected leaf have different height in T 0 than in T 
– Affected leaf has at most h = O(log n) ancestors whose subtrees may have changed 
– Let <X> be lowest ancestor that is not height-balanced (with skew magnitude 2) 
– If a leaf was added into T : 
∗ Insertion increases height of <X>, so in Case 2 or 3 of Local Rebalancing 
∗ Rotation decreases subtree height: balanced after one rotation 
– If a leaf was removed from T : 
∗ Deletion decreased height of one child of <X>, not <X>, so only imbalance 
∗ Could decrease height of <X> by 1; parent of <X> may now be imbalanced 
∗ So may have to rebalance every ancestor of <X>, but at most h = O(log n) of them 
• So can maintain height-balance using only O(log n) rotations after insertion/deletion! 
• But requires us to evaluate whether possibly O(log n) nodes were height-balanced 
Computing Height 
• How to tell whether node <X> is height-balanced? Compute heights of subtrees! 
• How to compute the height of node <X>? Naive algorithm: 
– Recursively compute height of the left and right subtrees of <X> 
– Add 1 to the max of the two heights 
– Runs in Ω(n) time, since we recurse on every node :( 
• Idea: Augment each node with the height of its subtree! (Save for later!) 
• Height of <X> can be computed in O(1) time from the heights of its children: 
– Look up the stored heights of left and right subtrees in O(1) time 
– Add 1 to the max of the two heights 
• During dynamic operations, we must maintain our augmentation as the tree changes shape 
• Recompute subtree augmentations at every node whose subtree changes: 
– Update relinked nodes in a rotation operation in O(1) time (ancestors don’t change) 
– Update all ancestors of an inserted or deleted node in O(h) time by walking up the tree 
","65.49055480957031","7","DPRSearchEngine","a2c80596cf4a2b5fbc854afdd2f23dcb_MIT6_006S20_lec7_4_pdf","a2c80596cf4a2b5fbc854afdd2f23dcb_MIT6_006S20_lec7","6.006","7"
"123","What are the three cases for adjustment in an AVL tree when the lowest bad node has been identified, and how are rotations applied in each case to restore balance?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 5: Linear Sorting 
Lecture 5: Linear Sorting 
Review 
• Comparison search lower bound: any decision tree with n nodes has height ≥dlg(n+1)e−1 
• Can do faster using random access indexing: an operation with linear branching factor! 
• Direct access array is fast, but may use a lot of space (Θ(u)) 
• Solve space problem by mapping (hashing) key space u down to m = Θ(n) 
• Hash tables give expected O(1) time operations, amortized if dynamic 
• Expectation input-independent: choose hash function randomly from universal hash family 
• Data structure overview! 
• Last time we achieved faster ﬁnd. Can we also achieve faster sort? 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
Direct Access Array 
u 
1 
1 
u 
u 
Hash Table 
n(e) 
1(e) 
1(a)(e) 
n 
n 
","64.84625244140625","8","DPRSearchEngine","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5_1_pdf","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5","6.006","5"
"123","What are the three cases for adjustment in an AVL tree when the lowest bad node has been identified, and how are rotations applied in each case to restore balance?"," &&%$3$%'9
class Digraph(object): 
 """"""edges is a dict mapping each node to a list of 
    its children""""” 
    def __init__(self): 
self.edges = {} 
    def addNode(self, node): 
if node in self.edges: 
 raise ValueError('Duplicate node') 
else: 
self.edges[node] = [] 
    def addEdge(self, edge): 
src = edge.getSource() 
dest = edge.getDestination() 
if not (src in self.edges and dest in self.edges): 
raise ValueError('Node not in graph') 
self.edges[src].append(dest) 
Q>KKKMN
LS
mapping each node 
list 
","64.68072509765625","9","DPRSearchEngine","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_18_pdf","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3","6.0002","3"
"123","What are the three cases for adjustment in an AVL tree when the lowest bad node has been identified, and how are rotations applied in each case to restore balance?"," 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
a
-
)
⋯
Tableau for ! on "" 
Defn: An (accepting) tableau for NTM ! on "" is an #$×#$ table 
representing an computation history for ! on "" on an accepting branch 
of the nondeterministic computation. 
#$
#$
""* ⋯"", ˽ … ˽
&'
&
""( "")
← Start configuration for ! on "" 
Construct 45,7 to “say” ! accepts "".
⋮ 
45,7 “says” a tableau for ! on "" exists. 
45,7 = 4cell ∧ 4start ∧ 4move ∧ 4accept
⋯ &accept ⋯
← Accepting configuration 
4 
","64.50479888916016","10","DPRSearchEngine","8212b19fc5a34f500ca6acf03a3a7d74_MIT18_404f20_lec16_4_pdf","8212b19fc5a34f500ca6acf03a3a7d74_MIT18_404f20_lec16","18.404J","16"
"124","How can a set interface be used to manage a collection of students and their associated information?","In any event, today, in our lecture, we're concerned with one particular interface, which is called a set. A set is exactly what it sounds like. It's a big pile of things. And so a set interface is like an object that just you can keep adding things to it. And then querying inside of my set, is this object here? Can I find it? And then maybe I associate with my objects in my set different information. So for example, maybe I have a set which represents all the students in our classroom today. Yeah, and all of you guys are associated with your student ID, which I believe at MIT is a number, which has less than sign, which is convenient. So we can sort all of you guys. And that might be the key that's associated to every object in the room. And so when I'm searching for students, maybe I enter in the student number. And then I want to ask my set, does this number exist in the set of students that are in 6.006? And if it does, then I can pull that student back. And then associated with that object is a bunch of other information that I'm not using to search-- so for instance, your name, your-- I don't know-- your social security number, your credit card number, all the other stuff that I need to have a more interesting profession.","73.54417419433594","1","DPRSearchEngine","oS9aPzUNG-s.en-j3PyPqV-e1s_4_mp4","oS9aPzUNG-s.en-j3PyPqV-e1s","6.006","3"
"124","How can a set interface be used to manage a collection of students and their associated information?","It's basically-- it's a set type thing, where I can make a set of just a single element, I can take two sets, merge them together, make them their union, and then given an object, I say, which set am I part of, essentially by electing a leader within a set and saying, return me a pointer to that one. And so this can be useful in dynamically maintaining, say, the connected components in a dynamically changing graph supporting the query of, am I in the same component as this other guy? That could be a very useful thing to know about a graph as it's changing. So that's an application of this problem. And they get near-constant performance for a lot of these queries. It's not quite, but pretty close. OK, on the graph side, they solve","72.61349487304688","2","DPRSearchEngine","2NMtS1ecb3o.en-j3PyPqV-e1s_6_mp4","2NMtS1ecb3o.en-j3PyPqV-e1s","6.006","20"
"124","How can a set interface be used to manage a collection of students and their associated information?","Now, this description here-- notice that I've labeled this as a set interface. This is not a set data structure. And the way to remember that is that I haven't told you how I've actually implemented this. I haven't told you that I'm going to behind the scenes have an array of information, and look inside of it, and that's how I'm going to implement find min or find max with a for loop or whatever. All I'm telling you is that a set is a thing that implements these operations. And behind the scenes, my computer does what it does. Now, it might sound abstract. But it's more or less what you guys do when you write code in Python. I think in Python what we're calling a set is maybe a dictionary. I'm a Matlab Coder. I'm sorry. I'm a numerical analysis kind of guy. But essentially, one of the beautiful things about coding in these high level programming languages is that they take care of these ugly details. And what you're left with is just the high level interfacing with this object","71.45315551757812","3","DPRSearchEngine","oS9aPzUNG-s.en-j3PyPqV-e1s_6_mp4","oS9aPzUNG-s.en-j3PyPqV-e1s","6.006","3"
"124","How can a set interface be used to manage a collection of students and their associated information?"," &&
class Edge(object): 
    def __init__(self, src, dest): 
        """"""Assumes src and dest are nodes"""""" 
        self.src = src 
        self.dest = dest 
    def getSource(self): 
        return self.src 
    def getDestination(self): 
        return self.dest 
    def __str__(self): 
        return self.src.getName() + '->’\\ 
               + self.dest.getName() 
Q>KKKMN
LQ
","70.48027038574219","4","DPRSearchEngine","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_16_pdf","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3","6.0002","3"
"124","How can a set interface be used to manage a collection of students and their associated information?"," &&#
class Node(object): 
    def __init__(self, name): 
""""""Assumes name is a string"""""" 
self.name = name 
    def getName(self): 
return self.name 
    def __str__(self): 
return self.name 
Q>KKKMN
LP
","70.27739715576172","5","DPRSearchEngine","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_15_pdf","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3","6.0002","3"
"124","How can a set interface be used to manage a collection of students and their associated information?"," 
 
  
 
 
 
   
 
 
  
 
 
 
 
 
 
  
 
K-means Algorithm 
randomly chose k examples as initial centroids  
while true:  
create k clusters by assigning each  
example to closest centroid  
compute k new centroids by averaging  
examples in each cluster  
if centroids don’t change:  
break  
What is complexity of one iteration? 
k*n*d,  where n is number  of points and d time required 
to compute the distance between a pair  of points 
6.0002  LECTURE 12 
10 
","69.24021911621094","6","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_10_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"124","How can a set interface be used to manage a collection of students and their associated information?"," 
 
 
 
 
 
 
 
 
Machine  Learning Paradigm  
§Observe set of examples: training data 
§Infer something about process that generated that 
data 
§Use inference to make predictions about previously 
unseen data: test data 
§Supervised: given a set of feature/label pairs, find a 
rule that predicts the label associated with a previously 
unseen input 
§Unsupervised: given a set of feature vectors (without 
labels) group them into “natural clusters” 
6.0002  LECTURE 12 
3 
","69.21724700927734","7","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_3_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"124","How can a set interface be used to manage a collection of students and their associated information?",";
/
def testGreedys(maxUnits):
print('Use greedy by value to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits, Food.getValue)
print('\\nUse greedy by cost to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits,
lambda x: 1/Food.getCost(x))
print('\\nUse greedy by density to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits, Food.density)
testGreedys(800)
	


4
","68.77324676513672","8","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_26_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"124","How can a set interface be used to manage a collection of students and their associated information?","interface a little bit more. So our set is a container. It contains all of the students in this classroom, in some virtual sense at least. And so to build up our set, of course, we need an operation that takes some iterable object A and builds a set out of it. So in other words, I have all the students in this classroom represented maybe in some other fashion. And I have to insert them all into my set. I can also ask my set for how much stuff is in it. Personally, I would call that size. But length is cool, too. And then of course, there are a lot of different ways that we can interact with our set. So for instance, we could say, is this student taking 6.006? So in set language, one way to understand that is to say that the key-- each person in this classroom is associated with a key. Does that key k exist in my set? In which case, I'll call this find function, which will give me back the item with key k or maybe null or something if it doesn't exist. Maybe I can delete an object from my set or insert it. Notice that these are dynamic operations, meaning that they actually edit what's inside of my set. And then finally, there are all kinds of different operations that I might want to do to interact with my set beyond is this thing inside of it. So for instance, so for the student ID example, probably finding the minimum ID number in a class isn't a terribly exciting exercise. But maybe I'm trying to find the student who's been at MIT the longest. And so that would be a reasonable heuristic. I actually have no idea whether MIT student IDs are assigned linearly or not. But in any event, I could find the smallest key, the largest key, and so on in my set. And these are all reasonable operations to query, where my object is just","68.66804504394531","9","DPRSearchEngine","oS9aPzUNG-s.en-j3PyPqV-e1s_5_mp4","oS9aPzUNG-s.en-j3PyPqV-e1s","6.006","3"
"124","How can a set interface be used to manage a collection of students and their associated information?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 2: Data Structures 
Lecture 2: Data Structures 
Data Structure Interfaces 
• A data structure is a way to store data, with algorithms that support operations on the data 
• Collection of supported operations is called an interface (also API or ADT) 
• Interface is a speciﬁcation: what operations are supported (the problem!) 
• Data structure is a representation: how operations are supported (the solution!) 
• In this class, two main interfaces: Sequence and Set 
Sequence Interface (L02, L07) 
• Maintain a sequence of items (order is extrinsic) 
• Ex: (x0, x1, x2, . . . , xn−1) (zero indexing) 
• (use n to denote the number of items stored in the data structure) 
• Supports sequence operations: 
Container 
build(X) 
len() 
given an iterable X, build sequence from items in X 
return the number of stored items 
Static 
iter seq() 
get at(i) 
set at(i, x) 
return the stored items one-by-one in sequence order 
return the ith item 
replace the ith item with x 
Dynamic 
insert at(i, x) 
delete at(i) 
insert first(x) 
delete first() 
insert last(x) 
delete last() 
add x as the ith item 
remove and return the ith item 
add x as the ﬁrst item 
remove and return the ﬁrst item 
add x as the last item 
remove and return the last item 
• Special case interfaces: 
stack 
insert last(x) and delete last() 
queue 
insert last(x) and delete first() 
","68.64466857910156","10","DPRSearchEngine","79a07dc1cb47d76dae2ffedc701e3d2b_MIT6_006S20_lec2_1_pdf","79a07dc1cb47d76dae2ffedc701e3d2b_MIT6_006S20_lec2","6.006","2"
"125","How can the structure of a complete binary tree be maintained implicitly without storing explicit pointers, and how are the relationships between nodes computed?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","77.7265625","1","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"125","How can the structure of a complete binary tree be maintained implicitly without storing explicit pointers, and how are the relationships between nodes computed?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","77.07111358642578","2","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"125","How can the structure of a complete binary tree be maintained implicitly without storing explicit pointers, and how are the relationships between nodes computed?"," &&
class Edge(object): 
    def __init__(self, src, dest): 
        """"""Assumes src and dest are nodes"""""" 
        self.src = src 
        self.dest = dest 
    def getSource(self): 
        return self.src 
    def getDestination(self): 
        return self.dest 
    def __str__(self): 
        return self.src.getName() + '->’\\ 
               + self.dest.getName() 
Q>KKKMN
LQ
","74.56680297851562","3","DPRSearchEngine","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_16_pdf","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3","6.0002","3"
"125","How can the structure of a complete binary tree be maintained implicitly without storing explicit pointers, and how are the relationships between nodes computed?"," 
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
(
&
&
Constructing the !! graph ! 
Illustrate construction by example 
Say "" = ∃%& ∀%( ∃%) ⋯ ∀%+ [ ( %& ∨%( ∨%) ) ∧(%& ∨%( ∨%1) ∧⋯∧( ⋯) ]
! = 
3( 
3+ 
Endgame 
∀
∃ should win if assignment satisfied all clauses
3+ 
∀ should win if some unsatisfied clause 
Implementation 
∃
∀ picks clause node claimed unsatisfied
∃ picks literal node claimed to satisfy the clause 
liar will be stuck 
TRUE 
FALSE 
∀ 
⋯
3
3
%)
%
%( 
%&
%( %1 
%( 
⋮ 
%5 
%& 
3& 
∃ 
∀ 
∀ 
I = ∃ 
II = ∀ 
∃ 
∀ 
∃
∃ 
∀ 
∃ 
6
∃ 6 
%&
%& 
3& 
3( 
∀ 
5 
","74.46539306640625","4","DPRSearchEngine","fd9c1b8656c7def498dcf662f6750d87_MIT18_404f20_lec19_5_pdf","fd9c1b8656c7def498dcf662f6750d87_MIT18_404f20_lec19","18.404J","19"
"125","How can the structure of a complete binary tree be maintained implicitly without storing explicit pointers, and how are the relationships between nodes computed?"," 
 
  
 
 
 
 
 
 
  
 
 
 
 
 
 
  
18.404/6.840 Lecture 23 
Last time: 
- !""#$%↑ is EXPSPACE-complete 
- Thus !""#$%↑ ∉ PSPACE 
- Oracles and P versus NP 
Today: (Sipser §10.2) 
- Probabilistic computation 
- The class BPP 
- Branching programs 
1 
","74.13797760009766","5","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_1_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"125","How can the structure of a complete binary tree be maintained implicitly without storing explicit pointers, and how are the relationships between nodes computed?","namely, random accessing. And if we stored the things that we're looking for, we have unique keys, and those keys are integers. Then, if I have an item with key K, if I store it at index K in my array, then I can find it and manipulate it in constant time.","73.965576171875","6","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_2_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"125","How can the structure of a complete binary tree be maintained implicitly without storing explicit pointers, and how are the relationships between nodes computed?"," 
 
 
  
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
Computation with Oracles 
Let ! be any language. 
Defn: A TM "" with oracle for !, written ""#, is a TM equipped 
with a “black box” that can answer queries “is $ ∈!?” for free. 
Example: A TM with an oracle for &!' can decide all ( ∈ NP in polynomial time. 
Defn: P# = ( ( is decidable in polynomial time with an oracle for !} 
Thus NP ⊆ P+#, 
NP = P+#,? Probably No because coNP ⊆ P+#, 
Defn: NP# = ( ( is decidable in nondeterministic polynomial time with an oracle for !} 
Recall MIN-FORMULA = 7 7 is a minimal Boolean formula } 
Example: MIN−FORMULA ∈ NP+#, 
“On input 7 
1. Guess shorter formula 9 
2.  Use &!' oracle to solve the coNP problem: 7 and 9 are equivalent 
3. Accept if 7 and 9 are equivalent. Reject if not.” 
8 
","73.79142761230469","7","DPRSearchEngine","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_8_pdf","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22","18.404J","22"
"125","How can the structure of a complete binary tree be maintained implicitly without storing explicit pointers, and how are the relationships between nodes computed?","Notation for encodings and TMs
Notation for encoding objects into strings
- If ! is some object (e.g., polynomial, automaton, graph, etc.), 
we write 〈!〉to be an encoding of that object into a string.  
- If !$, !&, … , !( is a list of objects then we write 〈!$, !&, … , !(〉
to be an encoding of them together into a single string. 
Notation for writing Turing machines
We will use high-level English descriptions of algorithms when we describe TMs, 
knowing that we could (in principle) convert those descriptions into states, 
transition function, etc.  Our notation for writing a TM ) is
) = “On input +
[English description of the algorithm]”
Check-in 6.3
If , and - are strings, would ,- be a good choice 
for their encoding 〈,, -〉into a single string?
a)
Yes.
b)
No. 
Check-in 6.3
8
","73.76847839355469","8","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_8_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"125","How can the structure of a complete binary tree be maintained implicitly without storing explicit pointers, and how are the relationships between nodes computed?","If you think about it a little bit, this is exactly binary search on an array. It just happens to be on a tree instead. If you think of an array like this, what does binary search do? It first looks at the key in the middle. I'm going to draw that as the root. And then, it recurses either on the left chunk, which I will draw recursively, or on the right chunk. And so if you happen to have a perfect binary tree like this one, it is simulating exactly binary search in this array. But this we're going to be able to maintain dynamically-- not perfect any more, but close. Whereas this we could not maintain in sorted order. So this is like a generalization of binary search to work on trees instead of on arrays. And for this reason, set binary trees are called binary search trees, because they're the tree version of binary search. So there's many equivalent names. So binary search tree is another name for set binary tree. And the key thing that makes this algorithm work is the so-called binary search tree property, which is all the keys in the left subtree of a node are less than the root, or of that node, and that key is less than all the keys in the right subtree. And this is true recursively all the way down. And so that's how you prove that this algorithm is correct by this property. Why is this true? Because if we can maintain traversal order to be increasing key, then that's exactly what traversal order means. It tells you all the things in the left subtree come before the root, which come before all the things in the right subtree.","73.73052978515625","9","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_4_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"125","How can the structure of a complete binary tree be maintained implicitly without storing explicit pointers, and how are the relationships between nodes computed?"," 
 
  
 
 
  
 
 
 
 
 
18.404/6.840 Lecture 25 
Last time: 
- Schwartz-Zippel Theorem 
- !""ROBP ∈ BPP 
Today: (Sipser §10.4) 
- Interactive Proof Systems 
- The class IP 
- Graph isomorphism problem 
- coNP ⊆ IP  (part 1) 
1 
","73.63001251220703","10","DPRSearchEngine","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25_1_pdf","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25","18.404J","25"
"126","What does the relaxation process in Dijkstra's algorithm achieve?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","72.67220306396484","1","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"126","What does the relaxation process in Dijkstra's algorithm achieve?"," 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
   
 
    
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
Linearly Bounded Automata 
Defn: A linearly bounded automaton (LBA) is a 1-tape TM 
that cannot move its head off the input portion of the tape. 
LBA 
a a b a a b a 
Tape size adjusts to length of input. 
Let !LBA = &, ( LBA & accepts ( } 
Theorem:  !LBA is decidable 
Proof: (idea) If & on ( runs for long, it must be cycling. 
Decider for !LBA: 
Claim: For inputs of length ), an LBA can have 
.A−LBA = “On input &, ( 
only * ×)× Γ - different configurations. 
1.  Let ) = |(|. 
Therefore, if an LBA runs for longer, it must repeat some 
2. Run & on ( for * ×)× Γ - steps. 
configuration and thus will never halt. 
3. If has accepted, accept. 
4. If it has rejected or is still running, reject.” 
must be looping 
7 
","71.4191665649414","2","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_7_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"126","What does the relaxation process in Dijkstra's algorithm achieve?"," 
 
 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) 
General Unweighted 
BFS 
|V | + |E|
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Non-negative Dijkstra 
Bellman-Ford 
|V | log |V | + |E|
General Any 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 14: Johnson’s Algorithm 
Lecture 14: Johnson’s Algorithm 
Previously 
|V | · |E| 
All-Pairs Shortest Paths (APSP) 
• Input: directed graph G = (V, E) with weights w : E → Z 
• Output: δ(u, v) for all u, v ∈ V , or abort if G contains negative-weight cycle 
• Useful when understanding whole network, e.g., transportation, circuit layout, supply chains... 
• Just doing a SSSP algorithm |V | times is actually pretty good, since output has size O(|V |2) 
– |V | · O(|V | + |E|) with BFS if weights positive and bounded by O(|V | + |E|) 
– |V | · O(|V | + |E|) with DAG Relaxation if acyclic 
– |V | · O(|V | log |V | + |E|) with Dijkstra if weights non-negative or graph undirected 
– |V | · O(|V | · |E|) with Bellman-Ford (general) 
• Today: Solve APSP in any weighted graph in |V | · O(|V | log |V | + |E|) time 
","70.65097045898438","3","DPRSearchEngine","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14_1_pdf","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14","6.006","14"
"126","What does the relaxation process in Dijkstra's algorithm achieve?"," 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Relationships among models 
Informal Defn: Two models of computation are polynomially related 
if each can simulate the other with a polynomial overhead: 
So ! "" time → !$("") time on the other model, for some '. 
All reasonable deterministic models are polynomially related. 
• 1-tape TMs 
• multi-tape TMs 
• multi-dimensional TMs 
• random access machine (RAM) 
• cellular automata 
9 
","70.52198028564453","4","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_9_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"126","What does the relaxation process in Dijkstra's algorithm achieve?"," 
 
 
   
 
 
 
   
   
      
 
 
 
 
 
 
  
 
Stochastic Processes  
An ongoing process where the next state might depend on 
both the previous states and some random element 
def rollDie(): 
"""""" returns an int between 1 and 6"""""" 
def rollDie(): 
"""""" returns a randomly chosen int 
between 1 and 6"""""" 
6.0002 LECTURE 4 
8
","70.1123275756836","5","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_8_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"126","What does the relaxation process in Dijkstra's algorithm achieve?","2 
Lecture 20: Course Review 
Next Steps 
• (U) 6.046: Design & Analysis of Algorithms 
• (G) 6.851: Advanced Data Structures 
• (G) 6.854: Advanced Algorithms 
6.046 
• Extension of 6.006 
– Data Structures: Union-Find, Amortization via potential analysis 
– Graphs: Minimum Spanning Trees, Network Flows/Cuts 
– Algorithm Design (Paradigms): Divide & Conquer, Dynamic Programming, Greedy 
– Complexity: Reductions 
• Relax Problem (change deﬁnition of correct/efﬁcient) 
– Randomized Algorithms 
∗ 6.006 mostly deterministic (hashing) 
∗ Las Vegas: always correct, probably fast (like hashing) 
∗ Monte Carlo: always fast, probably correct 
∗ Can generally get faster randomized algorithms on structured data 
– Numerical Algorithms/Continuous Optimization 
∗ 6.006 only deals with integers 
∗ Approximate real numbers! Pay time for precision 
– Approximation Algorithms 
∗ Input optimization problem (min/max over weighted outputs) 
∗ Many optimization problems NP-hard 
∗ How close can we get to an optimal solution in polynomial time? 
• Change Model of Computation 
– Cache Models (memory hierarchy cost model) 
– Quantum Computer (exploiting quantum properties) 
– Parallel Processors (use multiple CPUs instead of just one) 
∗ Multicore, large shared memory 
∗ Distributed cores, message passing 
","69.72607421875","6","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_2_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"126","What does the relaxation process in Dijkstra's algorithm achieve?"," 
 
 
  
 
   
   
  
   
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
  
 
   
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
Relationships between 
Time and SPACE Complexity 
Theorem: For ! "" ≥"" 
1) TIME ! "" 
⊆ SPACE ! "" 
2) SPACE ! "" 
⊆ TIME 2& ' ( 
= ⋃+ TIME ,' ( 
Proof: 
1) A TM that runs in !("") steps cannot use more than !("") tape cells. 
2) A TM that uses !("") tape cells cannot use more than ,' ( time 
without repeating a configuration and looping (for some ,). 
Corollary: P ⊆ PSPACE 
Theorem: NP ⊆ PSPACE [next slide] 
3 
","69.64122009277344","7","DPRSearchEngine","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17_3_pdf","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17","18.404J","17"
"126","What does the relaxation process in Dijkstra's algorithm achieve?"," 
 
  
  
  
 
 
  
       
   
 
 
 
 
 
 
  
 
 
 
  
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
  
 
 
 
  
 
 
   
 
 
   
 
 
 
 
   
 
 
 
 
 
 
 
 
    
 
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
  
 
TM – Formal Definition 
Defn: A Turing Machine (TM) is a 7-tuple ("", Σ, Γ, &, '(, 'acc , 'rej)
Σ input alphabet 
Γ tape alphabet (Σ ⊆Γ)
&: Q×Γ → ""×Γ× {L, R} 
(L = Left, R = Right) 
& ', a = (5, b, R) 
On input 6 a TM 7 may halt (enter 'acc or 'rej) 
Check-in 5.3 
or 7 may run forever (“loop”). 
This Turing machine model is deterministic. 
So 7 has 3 possible outcomes for each input 6: 
How would we change it to be nondeterministic? 
1. Accept 6 (enter 'acc ) 
a) Add a second transition function. 
2. Reject 6 by halting (enter 'rej ) 
b) Change & to be &: Q×Γ → 8( ""×Γ× {L, R} ) 
3. Reject 6 by looping (running forever) 
c) Change the tape alphabet Γ to be infinite. 
10 
Check-in 5.3 
","69.60761260986328","8","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_10_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"126","What does the relaxation process in Dijkstra's algorithm achieve?"," 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
  
 
Nondeterministic Complexity 
In a nondeterministic TM (NTM) decider, all branches halt on all inputs. 
Defn: An NTM runs in time !(#) if all branches halt within !(#) steps 
on all inputs of length #. 
Defn: NTIME ! # 
= {'| some 1-tape NTM decides ' 
and runs in time ( ! # 
} 
Defn: NP = ⋃* NTIME(#*)
= nondeterministic polynomial time decidable languages 
• Invariant for all reasonable nondeterministic models 
• Corresponds roughly to easily verifiable problems 
3 
Computation tree 
for NTM on input +. 
! # 
all branches halt 
within !(#) steps 
. . . 
","69.454345703125","9","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_3_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"126","What does the relaxation process in Dijkstra's algorithm achieve?","just talking about the correctness of Dijkstra's algorithm. OK. Correctness follows from two main observations. So the claim here that we're trying to prove is that d of s equals the delta s-- so the estimates equal the shortest-path distance is at the end of Dijkstra for all v and V at end. And this is going to follow from two observations. So the proof here, first, if ever relaxation sets d of s of v-- it sets the estimate equal to the shortest-path distance, if it ever does that, I argue to you that still true at end. OK, that's not a very strong statement. This is saying if I ever set the distance estimate to the true distance, I'm never going to set it to a different value later on. And why is that? Well, relaxation only ever decreases the distance. Relaxation only decreases d s, v. But we proved in lecture 11-- so two lectures ago that relaxation is safe. And what does safe mean? Safe means that relaxation-- that relaxation will only ever change these distant estimates to be either infinite-- it was never-- there was never a path to my vertex. Or it was the length of some path to v. Length of some path. OK. So what does that mean? It only decreases, but it's always the length of some path to v. So if this is the length of the shortest path to v, I could never set it to a smaller length, because there are no paths with shorter distance. That's the whole point. OK. So with this observation, I'm going to argue this final claim. It suffices to show that my estimate equals the shortest distance when v is removed from the Q. And since I removed every vertex from the Q in this while loop, I will eventually said to all of the distance estimates to the real distance and we'll be golden. Happy days. All right. So we'll be done if we can prove that statement. All right. So we're going to prove this by induction obviously. Induction on first k vertices removed from the Q. So the Q, we're popping vertices from this Q in some order. So I'm going to just argue that this claim is true for the first k. Clearly that's true for k equals 1. Base case, k equals 1. What is k equals 1? That means the first word vertex that I pop has this property, which is definitely true, because we set the shortest distance to s to be 0. That's all good. Now we have our inductive step. Assume it's true for k prime-- sorry, k less than k prime. And let's let v prime be k prime vertex popped. v prime. OK. And now let's look at some shortest path from s to v prime. So we got the shortest path from s to v prime. It exists. v prime is accessible. Let's say we pruned our graph to be only the things accessible from s so that, yeah, there exists the shortest path to v prime. And now let's think about these vertices. Some of them were removed from the Q and some of them were not. s was definitely removed from the Q. But some of these other vertices might not be. I want to be able to induct on this path, in particular, the vertex before me so that I can say that when I removed it and I relax the edge to v prime, then we're all golden. But that might not be the case. There could be a vertex, the vertex preceding me in the graph in this shortest path that was not popped from Q. I need to argue that it was or some other thing. So let's consider the first vertex in this path from s to v. I'm going to call it y, I think. Yeah. A vertex y that is not in Q. After I pop v prime, this is the first-- or before I pop v prime, y is not in the Q. Now these might be the same vertex if all of the preceding ones on this path were in the Q. But in particular, we're going to look at this guy. And say its predecessor's x in the path. Well what do I know? I know that x is in the queue. Everything here was popped from the Q-- not in. Which means that by induction, the shortest-path distance was set here correctly. So that the distance estimate at y can't be bigger than the shortest path to x plus w x, y. But this is on the shortest path to y, because the subpaths of shortest paths or shortest paths. So this has to equal d s, y, the distance to y. So actually, y is all good here. And so if v prime were y, we'd be done. That's the same argument is DAG relaxation. But we need to prove something about v prime. Well, because we have non-negative weights, the distance to v prime has to be at least as big as this distance, because it's a subpath. So this has to be less than or equal to the true distance to v prime. Because of negative-- non-negative weights, because the weights are non-negative. But because relaxation is safe, we know that our distance estimate for v prime has to be at least the shortest-path distance. This is because it's safe. This is-- weights are greater than or equal to 0. The last step here is that because we're popping the minimum from our priority queue, the thing with the smallest shortest-path distance, this has to be less than or equal to the shortest-path distance estimate to y. Because this is the smallest among all such vertices in my Q. But these are the same value. So everything between here is the same value. In particular, the estimate here is equal to my true shortest-path distance, which is exactly what we're trying to prove. OK, so that's why Dijkstra's correct. I'm going to spend the last five minutes on the running time of Dijkstra. We set this up so that we did everything in terms of these Q operations. Right so we have these Q operations, we have three of them. I'm going to say if I have a build operation, let's say it takes B time; to lead min, I'm going to say it takes M time; and this decreased key,","69.23234558105469","10","DPRSearchEngine","NSHizBK9JD8.en-j3PyPqV-e1s_5_mp4","NSHizBK9JD8.en-j3PyPqV-e1s","6.006","13"
"127","What is the main argument for why most decision problems are uncomputable?"," 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
   
 
 
 
 
   
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
  
 
 
  
 
  
 
  
Turing machine model – review 
head 
˽ ˽ . . .
a
b
a
b
b
Finite 
read/write input tape 
control 
On input ! a TM "" may halt (enter #acc or #rej) 
) is T-recognizable if ) = +("") for some TM "". 
or loop (run forever). 
) is T-decidable if ) = +("") for some TM decider "". 
So "" has 3 possible outcomes for each input !: 
halts on all inputs 
1. Accept ! (enter #acc ) 
Turing machines model general-purpose computation. 
2. Reject ! by halting (enter #rej ) 
Q: Why pick this model? 
3. Reject ! by looping (running forever) 
A: Choice of model doesn't matter. 
All reasonable models are equivalent in power. 
Virtues of TMs: simplicity, familiarity. 
2 
","73.337646484375","1","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_2_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"127","What is the main argument for why most decision problems are uncomputable?"," 
 
 
 
  
 
 
  
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Intro to Complexity Theory 
Computability theory (1930s - 1950s): 
Is A decidable? 
Complexity theory (1960s - present): 
Is A decidable with restricted resources? 
(time/memory/…) 
Example: Let ! = a#b# $ ≥0 . 
Q: How many steps are needed to decide !? 
Depends on the input. 
We give an upper bound for all inputs of length '. 
Called “worst-case complexity”. 
2 
","72.77008056640625","2","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_2_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"127","What is the main argument for why most decision problems are uncomputable?"," 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Turing Machines (TMs) 
head 
˽ ˽
a
b
a 
. . .
b b
Finite 
read/write input tape 
control 
1) Head can read and write 
2) Head is two way (can move left or right) 
3) Tape is infinite (to the right) 
4) Infinitely many blanks “˽“ follow input 
5) Can accept or reject any time (not only at end of input) 
8 
","72.31855010986328","3","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_8_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"127","What is the main argument for why most decision problems are uncomputable?","§ Problem is exponen<al 
§ Have we overturned the laws of the universe? 
§ Is dynamic programming a miracle? 
§ No, but computa<onal complexity can be subtle 
§ Running <me of fastMaxVal is governed by number of 
dis<nct pairs, <toConsider, avail> 
◦Number of possible values of toConsider bounded 
by len(items)
◦Possible values of avail a bit harder to characterize 
◦Bounded by number of dis<nct sums of weights 
◦Covered in more detail in assigned reading 
How Can This Be? 
6.0002 LECTURE 2 
30 
","71.54269409179688","4","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_30_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"127","What is the main argument for why most decision problems are uncomputable?","Many problems of practical importance can be formulated as optimization problems. Greedy algorithms often provide an adequate though often not optimal solution. Even though finding an optimal solution is, in theory, exponentially hard, dynamic programming really often yields great results. It always gives you a correct result and it's sometimes, in fact, most of the times gives it to you very quickly. Finally, in the PowerPoint, you'll find an interesting optimization problem","71.4539794921875","5","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_15_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"127","What is the main argument for why most decision problems are uncomputable?"," 
 
 
 
 
 
 
 
 
 
 
  
Other applications 
1. Computer viruses. 
2. A true but unprovable mathematical statement due to Kurt Gödel: 
“This statement is unprovable.” 
10 
","71.02842712402344","6","DPRSearchEngine","779043ea724131d008eae652d703938f_MIT18_404f20_lec11_10_pdf","779043ea724131d008eae652d703938f_MIT18_404f20_lec11","18.404J","11"
"127","What is the main argument for why most decision problems are uncomputable?","This is just another word for being not in R. OK, and next thing I'd like to do is prove to you that most decision problems are uncomputable, or sketcher proof. So remember, decision problems are problems where the answer is just yes or no. This is a very special kind of problem. And even those, almost all of them, cannot be solved. So halting is an example of a problem we want-- we can't solve. This whole class, this 006, is about problems we can solve. But today I'm going to show you that, actually, those are in the minority. Most problems cannot be computed. This is very strange and also a little depressing. So we'll talk more about that in a moment. First let me argue why this is the case. So I'm going to be a little informal about what exactly is a computer program and what exactly is a decision problem. But roughly, all I need to do, the only level of precision I need is just to count how many are there. What is a computer program? Well, it's usually a file. What's a file? It's like a string of characters. What's a character? It's a string of bits. So a program is just, in the end, a string of bits, finite string of bits. We all understand that. Whatever language you define, in the end, every program is just a string of bits. And a string of bits we can translate into a number. So we can convert between strings of bits and numbers. When I say number, I mean what's usually called a natural number or a non-negative integer. This is usually represented by bold board bold-- blackboard bold capital N. So this is just 0, 1, 2, and so on. Now, what about decision problems? Decision problem is a specification of what we want to solve. So we can think of it as saying, for every input, is the answer yes or no? That's literally what a decision problem is. The only question is, what is an input? And we've talked about inputs and the size of inputs. And there's lots of different ways to measure them. But in the end, we can think of an input as a string of bits also. It's just a file. So a decision problem is a function from inputs to yes or no. And inputs we're going to say, well, that's a string of bits, which we can associate with a number in N. So here we can start to tie things together. So in other words, a program is a finite string of bits, and a problem is, in some sense, an infinite string of bits because there are infinitely many possible inputs. And for each of them, we specify yes or no. So this is basically an infinite string of bits. So we can imagine 011010001110, infinitely. Just some-- for every string of bits, we can say, OK, if your input is the number 0, here's the answer-- no. If your input is the number 1, then the answer is yes. If your input is the number 2, your answer is yes, and so on down this line. Every infinite string of bits corresponds to exactly one decision problem, which specifies for every possible input integer, which corresponds to a string of bits, what is the answer, yes or no? So this may seem subtle, or it may seem like not a big deal. This is a finite string of bits. This is an infinite string of bits. But mathematics has well studied this problem. And infinite strings of bits, there are very many of them, infinitely many. It's not surprising. There are also infinitely many integers. So maybe it doesn't seem that deep. But there's a difference in infinitude. Programs and integers are countably infinite. And infinite strings of bits are what's called uncountable. I think the most intuitive way to see this is, an infinite string of bits, if I put a decimal or a binary point in front, this encodes a real number between 0 and 1. So this is roughly a real number in 01. And when I'm writing approximately equal here, this really goes in both directions. Given a decision problem, I can define a string of bits, of course giving me the answer for all inputs. And I can convert that into a real number between 0 and 1. But also the other direction, if I take any real number, that is a corresponding decision problem. These are 1 to 1 bijection between them. And the bad news is, real numbers are uncountable, and natural numbers are countable, which means there's a lot more of these than there are these. So one way you might phrase this is, informally, the number of natural numbers is way smaller than the number of real numbers. And so from that, we derive that most problems are unsolvable, because every program solves exactly one decision problem. We can also run a program, conceptually, on all possible inputs, and we will figure out what function at solving. And if we don't allow random numbers in our program, which I'm not here, then every program solves exactly one decision problem. Possibly, it's even worse for us because multiple programs probably solve the same decision problem. They're just-- they add irrelevant lines of code or they don't do anything different. Or you run Bellman-Ford versus running Bellman-Ford five times, you'll get the same result. And that's actually the bad direction for us. We'd like to know whether there is a program that solves every decision problem. And because there are only this many programs and this many decision problems, it just-- there aren't enough to go around.","70.89434814453125","7","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_4_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"127","What is the main argument for why most decision problems are uncomputable?","So E TM is the emptiness problem for Turing machines. Is this language empty? I'm just going to give you a machine. I want to know, is this language empty or not? Does it accept something or is this language empty? That's going to be undecidable, no surprise, proof by contradiction. And we're going to show that A TM is reducible to E TM. So these things often take a very similar form. And I'm going to try to use the same form. So if you're feeling shaky on it, at least you'll get the form of the way the solution goes and that will help you maybe plug-in to solve problems, OK.","70.7965087890625","8","DPRSearchEngine","N28g_YBXY8Y.en-j3PyPqV-e1s_7_mp4","N28g_YBXY8Y.en-j3PyPqV-e1s","18.404J","9"
"127","What is the main argument for why most decision problems are uncomputable?","OK. So to start this off, we're going to have to talk about non-deterministic complexity as a variation of deterministic complexity. So first of all, all of the machines in this part of the course and the languages, everything is going to be decidable and all the machines are going to be deciders. So what do we mean when we have a non-deterministic machine which is a decider? And that just simply means that all of the branches-- it's not just the machine halts on every input, but all of the branches halt on every input. So the non-deterministic machine is non-deterministic, it has lots of possible branches. They all have to halt-- all of them-- on every input. That's what makes a non-deterministic machine a decider. And you're going to convert a non-deterministic decider into a deterministic decider. But the question is, how much time would that introduce? How much extra time is that going to cost? And the only way that people know at the present time for that conversion would be to do an exponential increase. Basically, to try all possible branches.","70.79090881347656","9","DPRSearchEngine","1VhnDdQsELo.en-j3PyPqV-e1s_4_mp4","1VhnDdQsELo.en-j3PyPqV-e1s","18.404J","14"
"127","What is the main argument for why most decision problems are uncomputable?","Turing machines, as we set them up, they have-- on any input w, they have three possible outcomes. The Turing machine can halt and accept w, can halt and reject w, or it can go forever on w, which is rejecting by looping in our language. A Turing machine can recognize a language, the collection of old strings that it accepts. And if the Turing machine always halts, we say it decides the language, and it's a decider, and so therefore, that language is a decided language, a Turing decider. Often we just say decidable, because we don't really have a notion of deciding in other models, so we often talk about Turing-recognizable or just decidable. Or we'll sometimes just say recognizable, when we understand that we're talking about Turing machines. We briefly talked about encodings. When you write it inside brackets, some objects-- whatever they are-- could be strings, could be machines, could be graphs, could be polynomials-- we're representing them as strings, and maybe a collection of objects together represented as a string in order so that we can present that information as an input to a machine. And we talk about-- our languages our collections of strings. And a notation for writing a Turing machine is going to be simply that English description put inside quotation marks to represent our informal way of talking about the formal object that we could produce, if we wanted to. But we're never going to ask you to do that. OK, so now let me see. Let's just take a quick break, as I promised. If there's any quick questions here, you can ask. Let's see-- got a lot of questions here. All right, why don't we move on? And some of these things are good questions.","70.6676254272461","10","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_2_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"128","What is the key distinction between directed and undirected graphs in terms of edge representation?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 9: Breadth-First Search 
Lecture 9: Breadth-First Search 
New Unit: Graphs! 
• Quiz 1 next week covers lectures L01 - L08 on Data Structures and Sorting 
• Today, start new unit, lectures L09 - L14 on Graph Algorithms 
Graph Applications 
• Why? Graphs are everywhere! 
• any network system has direct connection to graphs 
• e.g., road networks, computer networks, social networks 
• the state space of any discrete system can be represented by a transition graph 
• e.g., puzzle & games like Chess, Tetris, Rubik’s cube 
• e.g., application workﬂows, speciﬁcations 
Graph Deﬁnitions 
G1 
0 
1 
2 
3 
G2 
0 
1 
2 
G3 
a 
b 
s 
c 
d 
e 
f 
g 
• Graph G = (V, E) is a set of vertices V and a set of pairs of vertices E ⊆ V × V . 
• Directed edges are ordered pairs, e.g., (u, v) for u, v ∈ V 
• Undirected edges are unordered pairs, e.g., {u, v} for u, v ∈ V 
i.e., (u, v) and (v, u) 
• In this class, we assume all graphs are simple: 
– edges are distinct, e.g., (u, v) only occurs once in E (though (v, u) may appear), and 
– edges are pairs of distinct vertices, e.g., u =6 v for all (u, v) ∈ E 
 

|V |
|V |
– Simple implies |E| = O(|V |2), since |E| ≤ 
for undirected, ≤ 2 
for directed 
2
2 
","75.20751953125","1","DPRSearchEngine","196a95604877d326c6586e60477b59d4_MIT6_006S20_lec9_1_pdf","196a95604877d326c6586e60477b59d4_MIT6_006S20_lec9","6.006","9"
"128","What is the key distinction between directed and undirected graphs in terms of edge representation?","So a graph is connected if there's a path getting from every vertex to every other vertex. Right. Now connectivity in a directed graph is kind of a weird object. Like, for instance, think of a directed graph with just two edges. And one edge goes from u to v. Then I can get from v to u, but not vise versa. That's kind of a weird notion. So here in 6006 we'll mostly worry about connectivity only for undirected graphs because they're-- the vertices just basically come in like, big connected clumps. Or the more technical term for a big connected clump is a connected component. Yeah? So let's see an example. So let's say that I have a graph, which has an edge and then a triangle. This is one graph. Do you see that? There's a collection of vertices, and there's a collection of edges. But it has two connected components-- the guy on the right and the guy on the left, meaning that each vertex here is reachable from every other vertex here. Each vertex here is reachable from every vertex here. But there's no edge that goes from the triangle to the line segment. Yeah? And so in the connected components problem, we're given a graph like this guy. And initially, we don't, you know-- OK. When I draw it like this, it's pretty clear that my graph has two connected components. Maybe my graph-embedding algorithm failed and it drew an edge like that. Well, then maybe-- I don't know-- it's still pretty obvious that there's two connected components. But you can imagine a universe where you don't know that a priori. And the problem you're trying to solve is just to enumerate all these clumps of vertices that are reachable from one another in an undirected graph. And conveniently, we can use depth-first search to solve this problem pretty easily. Right? So how could we do it? Well, in some sense how can we find one connected component? So let's say that I just choose a vertex in my graph. Well, what do I know about everything in its connected component? Well, it's reachable from that vertex. Remember, we just solved the reachability problem, which says, if I have a vertex, I can now tell you all the other vertices that are reachable from this guy. So I could call DFS on, well, any vertex of this cycle here. Call the reachability thing. And I know that for every vertex there's one of two things. Either the vertex has a parent in that object P, or it's the source. So I can very easily find the connected component corresponding to that vertex. Does that makes sense? Have I found all the connected components? No. I found one. I found the one corresponding to the arbitrary vertex that I just chose. So how could I fix this? Well, it's super simple. I could put a for loop on the outside, which just loops over all the vertices, maybe. And if that vertex is not part of a connected component yet, then I need to make a new one. So then I call DFS on that vertex. I collect all the vertices that I got. And I iterate.","73.7789306640625","2","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_12_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"128","What is the key distinction between directed and undirected graphs in terms of edge representation?","And that's cycle detection. So there's a bit of an exercise left to the reader here. So the problem that we're looking for now is that we're given a directed graph. There's a G in graph, in case you're wondering. But now, we don't know if it's a DAG or not. And so the question that we're trying to ask is, does there exist a cycle in our directed acyclic graph? So we're just given our graph, and we want to know, can we do this? Let's think through the logic of this a bit. So what do we know? We know that if our graph were a DAG, then I could call DGS, get the ordering out, and then I guess flip its ordering backwards. So I could compute the reverse finishing order. And it would give me a topological order of my graph. So if I were a DAG, I would get a topological order when I call DFS. So let's say that I ran DFS. I got whatever ordering I got. And now I found an edge the points in the wrong direction. I can just double check my list of edges, and I find one that does not respect the relationship that I see in the second bullet point here. Can my graph be a DAG? No. Because if my graph were a DAG, the algorithm would work. I just proved it to you. Right? So if my graph were a DAG, then I could do reverse finishing order. And what I would get back is a topological order. So if I found a certificate that my order wasn't topological, something went wrong, and the only thing that could go wrong is that my graph isn't a DAG. Yeah. Isn't a DAG. In fact, sort of an exercise left to the reader and/or to your section-- do we still have section? I think we do, as of now-- is that this is an if and only if, meaning that the only time that you even have a topological ordering in your graph is if your graph is a DAG. This is a really easy fact to sanity check, by the way. This is not like, a particularly challenging problem. But you should think through it because it's a good exercise to make sure you understand the definitions, which is to say that if you have a topological order, your graph is a DAG. If you don't have a topological order, your graph isn't a DAG. So in other words, we secretly gave you an algorithm for checking if a graph is a DAG at all. Right? What could I do? I could compute reverse finishing order. Check if it obeys the relationship on the second bullet point here for every edge. And if it does, then we're in good shape. My graph is a DAG. If it doesn't, something went wrong. And the only thing that could have gone wrong is not being a DAG. OK. So in other words, secretly we just solved-- well, I guess the way that I've written it here, we've solved the cycle detection problem here, which is to say that, well, I have a cycle if and only if I'm not a DAG, which I can check using this technique. Of course, the word ""detection"" here probably means that I actually want to find that cycle, and I haven't told you how to do that yet. All we know how to do so far is say, like, somewhere in this graph there's a cycle. And that's not so good. So we can do one additional piece of information in the two minutes we have remaining to sort of complete our story here, which is to modify our algorithm ever so slightly to not only say thumbs up, thumbs down, is there a cycle in this graph, but also to actually return the vertices as a cycle. And here's the property that we're going to do that, which is following, which is that if G contains a cycle, right, then full DFS will traverse an edge from a vertex v to some ancestor of v. I guess we haven't carefully defined the term ""ancestor"" here. Essentially, if you think of the sort of the running of the DFS algorithm, then an ancestor is like something that appears in the recursive call tree before I got to v. OK. So how could we prove that? Well, let's take a cycle. And we'll give it a name. In particular, we'll say that it's a cycle from v0 v1 to vk. And then it's a cycle, so it goes back to v0. OK. And I can order this cycle any way I want. Notice that if I permute the vertices in this list in a cyclical way, meaning that I take the last few of them and stick them at the beginning of the list, it's still a cycle. That's the nice thing about cycles. So in particular, without loss of generality, we're going to assume that v0 is the first vertex visited by DFS. What does that mean? That means, like, when I do my DFS algorithm making all these recursive calls, the very first vertex to be touched by this technique is v0. OK. Well, now what's going to end up happening? Well, think about the recursive call tree starting at v0. By the time that completes, anything that's reachable from v0 is also going to be complete. Do you see that? So for instance, v0 somewhere in its call tree might call v2. And notice that v2 was not already visited. So in fact, it will. For v1 I got to call v2 and so on. And in particular, we're going to get all the way to vertex k. Right? So in other words, we're going to visit a vertex vk. And notice what's going to happen. So remember our algorithm. In fact, we should probably just put it up on the screen would be easier than talking about it a bunch. Well, vk is now going to iterate over every one of the neighbors of vk. And in particular, it's going to see vertex v0. Right? So we're going to see the edge from vk to v0, which is an edge kind of by definition because we took this to be a cycle here. But notice that's exactly the thing we set out to prove, namely that full DFS traverses an edge from a vertex to one of its ancestors. Here's a vertex k. Here's the ancestor v0. Why do we know that it's an ancestor? Well, because v0 was called in our call tree before any of these other guys. Right? So we wanted an algorithm that not only did cycle detection, but also actually gave me the cycle. What could I do? Well, it's essentially a small modification of what we already have. Right. So-- whoops. Right. If I want to compute topological order or whatever, I can just do DFS. And that'll tell me like, yay or nay, does there exist a cycle. If I want to actually find that cycle, all I have to do is check that topological order property at the same time that it traversed the graph during DFS. And the second that I find an edge that loops back, I'm done. And so that's our basic algorithm here. And this is a technique for actually just finding the cycle in a graph using the DFS algorithm.","73.26715087890625","3","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_20_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"128","What is the key distinction between directed and undirected graphs in terms of edge representation?"," &&%$3$%'9
class Digraph(object): 
 """"""edges is a dict mapping each node to a list of 
    its children""""” 
    def __init__(self): 
self.edges = {} 
    def addNode(self, node): 
if node in self.edges: 
 raise ValueError('Duplicate node') 
else: 
self.edges[node] = [] 
    def addEdge(self, edge): 
src = edge.getSource() 
dest = edge.getDestination() 
if not (src in self.edges and dest in self.edges): 
raise ValueError('Node not in graph') 
self.edges[src].append(dest) 
Q>KKKMN
LS
mapping each node 
list 
","73.19085693359375","4","DPRSearchEngine","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_18_pdf","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3","6.0002","3"
"128","What is the key distinction between directed and undirected graphs in terms of edge representation?","is called depth-first search, which doesn't do that, but rather, starts with its first vertex and just starts walking all the way out until it can't do that anymore. And then it kind of backtracks. That's one way to think about it. And so somehow, in breadth-first search, we're like, drawing concentric circles. In depth-first search, we're doing the opposite. We're like, shooting outward until we reach the outer boundary, and then exploring the graph that way. OK. And these are sort of the two extremes in terms of graph search kind of techniques that are typically used under the basic building blocks for algorithms in graph theory. So in order to motivate and think about depth-first search, we're going to define a second problem, which is closely related to shortest path, but not exactly the same. And that's the reachability problem. So here I have the world's simplest directed graph. So the black things are the edges. And the circles are the nodes or the vertices. And I've marked one special node in blue. And his name is the source node. And now the question I want to ask is, what are all of the other nodes in my graph that I can reach by following edges-- directed edges-- starting with the source? So obviously, I can get to the node in the lower right, no problem. And of course once I get there, I can traverse and edge upward to get to that second green vertex. Notice that I was really sneaky and evil, and I drew edges in this graph that might make you think that the red node is reachable. The red one being on the upper left. I'm realizing now that for colorblind people, this isn't a great slide. But of course, because all the edges from the red vertex on the left here point out, I can't actually reach it from the blue source node. So the reachability problem is just asking, which nodes can I reach from a given source? Pretty straightforward, I think. Of course, there are many ways to solve this. Right? In fact, one way we could do it would be to use our previous lecture. We could compute the shortest path distance from the source to all the other nodes. And then what would the length of the shortest path from the source to an unreachable node be? Any thoughts from our audience here? Infinity. Thank you, Professor Demaine. Right. So in addition to this, of course, a totally reasonable question, thinking back to our shortest path lecture, there are sort of two queries we might make. Right? One is just what is the length of the shortest path? The other is like, what is the actual shortest path from the source to a given vertex? We can ask a very similar thing here, which is like, OK. You tell me that the green guy is reachable, but how? Give me a path as evidence or a certificate, if you want to be fancy about it. So in order to do that, just like last time, remember, we defined a particular data structure that was the shortest path tree. We can do something very similar here. In particular, this is like the extent of my PowerPoint skills here. If I have a reachability problem, I can additionally store-- I can decorate every node in my graph with one other piece of information, which is the previous node along some path from my source to that thing. Right? And just like last time, if I want to get an actual path from the source to w, what could I do? I can start with w and then just keep following those parent relationships until I get back to the source. Then if I flip the order of that list of vertices, I get a path from the source to the target that's valid. So this object is called a path tree, just like we talked-- or a parent tree, rather. Just like we talked about in our last lecture, there's no reason why this thing should ever have a cycle in it. It's certainly a tree. Right. So that's the basic reachability problem. And in addition to that, we can compute this object P, which is going to give me sort of information about how any given node was reachable. There's a slight difference between the parent tree that I've defined here and the shortest path tree, which I defined last time, which is, I'm not going to require that the shortest path I get-- oh, man-- the path I get when I backtrack along my tree P is the shortest path, it's just a path because for the reachability problem, I actually don't care. Like, I could have a weird, circuitous, crazy long path. And it still tells me that a node is reachable. Right. So that's our basic set up and our data structure. And now we can introduce a problem to solve reachability. Again, we already have an algorithm for doing that, which is to compute shortest paths. And remember that our shortest path algorithm from previous lecture took linear time and the size of the input. It took v plus e time. Now the question is, can we do a little better? The answer, obviously, is yes, because I just asked it, and I gave you this problem. OK. And here's a technique for doing that, which unsurprisingly, is a recursive algorithm. I'm going to swap my notes for my handwritten notes.","73.07872009277344","5","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_8_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"128","What is the key distinction between directed and undirected graphs in terms of edge representation?","I want to print out what an edge looks like, I'm going to ask that it print out the name of the source, and then an arrow, and then the name of the destination. So notice what I do there. Given an instance of an edge, I can print it. And it will get the source or the node associated with source inside this instance, get for that the getName method, and then call it. Notice the open-close paren there to actually call it. What does that do? It says, inside the edge I've got something that points to a node. I get that node. I take the method associated with it. And I call it. That returns the string. And then I glue that together with the arrow. I do the same thing on the destination. And I just print it out. Pretty straightforward, hopefully. OK, now I have to make a decision about the graph. I'm going to start with digraphs, directed graphs. And I need to think about how I might represent the graph. I can create nodes. I can create edges, but I've got to bring them all together. So I'll remind you, a digraph is a directed graph. The edges pass in only one direction. And here's one way I could do it. Given all the sources and all the destinations, I could just create a big matrix called an adjacency matrix. The rows would be all the sources. The columns would be all the destinations. And then in a particular spot in the matrix, if there is an edge between a source and a destination, I'd just put a one. Otherwise I'd put a zero. Note, by the way, because it's a directed graph, it's not symmetric. There might be a one between S and D, but not between D and S, unless there are edges both ways. This would be a perfectly reasonable way to represent a graph, but not the most convenient one. I'd have to go into the matrix to look things up. It may also not be a very efficient way of representing things. For example, if there are very few edges in the graph, I could have a huge matrix with mostly zeros. And that's not the most effective way to do it. So I'm going to use an alternative called an adjacency list. And the idea here is, for every node in the graph. I'm going to associate with it a list of destinations. That is, for a node, what are the places I can reach with a single edge? OK, so let's see what that does if we want to build it. And yes, there's a lot of code here, but it's pretty easy to look through I hope. Here's the choice I'm going to make. Again, what's a graph? It's a set of nodes. It's a set of edges. I'm going to have a way of putting nodes into the graph. And I'm going to choose to, when I put a node into the graph, to store it as a key in a dictionary. OK? When I initialize the graph, I'm just going to set this internal variable, edges, to be an empty dictionary. And the second part of it is, when I add an edge to the graph between two nodes from a source to a destination, I'm going to take that point in the dictionary associated with the source. It's a key. And associated with it, I'm going to just have a list of the nodes I can reach from edges from that source. So notice what happens here. If I want to add a node, remember, it's a node not an edge-- I'll first check to make sure that it's not already in the dictionary. That little loop is basic, or that if is saying, if it's in this set of keys, it will return true. And I'm going to complain. I'm trying to copy a node or duplicate a node. Otherwise, notice what I do. When I put a node into the dictionary, I go into that dictionary, edges. I create an entry with the key that is the node. And the value I put in there is initially an empty list. I'm going to say one more piece carefully. It's a node not a name. And that's OK in Python. It is literally the key is the node itself. It's an object, which is what I'd like. All right, what if I want to add an edge? Well, an edge is going to go from a source to a destination node. So, I'm going to get out from the edge the source piece. I'm going to get out from the edge the destination piece by calling those methods. Again, notice the open-close paren, which takes the method and actually calls it. Because remember, an edge was an object itself. Given those, I'll check to make sure that they are both in the dictionary. That is, I've already added them to the graph. I can't make a connection between things that aren't in the graph. And then notice the nice little thing I do.","72.72091674804688","6","DPRSearchEngine","V_TulH374hw.en-qlPKC2UN_YU_2_mp4","V_TulH374hw.en-qlPKC2UN_YU","6.0002","3"
"128","What is the key distinction between directed and undirected graphs in terms of edge representation?","Longest path is maybe a problem we've talked about in problem session, because it's a DAG-- well, longest path is the same thing as shortest path, if you just negate all the weights. There are no weights in this picture, so if you just put negative 1 on all these edges and ask for the shortest path from the base to anywhere-- so single source shortest paths from this base-- then we would end up getting this path, which, if you look at it, is E-M-P-T-Y, empty. And so that shortest path is indeed the right answer. What I've drawn here is the shortest path tree. So also, if you wanted the longest increasing subsequence starting at A, then it is A-T-Y, just by following the red arrows here. And how do you get that? You just draw the parent pointers, just like we did before.","72.66498565673828","7","DPRSearchEngine","KLBCUx1is2c.en-j3PyPqV-e1s_8_mp4","KLBCUx1is2c.en-j3PyPqV-e1s","6.006","16"
"128","What is the key distinction between directed and undirected graphs in terms of edge representation?","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","72.39598083496094","8","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"128","What is the key distinction between directed and undirected graphs in terms of edge representation?","So topological ordering. So we think of f as a function that assigns maybe every node an index in array. I guess I shouldn't use the word array here. But just like an index, an ordering. So like, this is the first vertex. And this is the second vertex. And so on. Then a topological order is one that has the properties shown here, which is that if I have a directed edge from u to v, then f of u is less than f of v. So in other words, if I look at the ordering that I get on my topological order, u has to appear before v. Yeah? Let's look at our example again. So let's give our nodes names. So here's A, B, C, D. Well, what clearly has to be the first node in my topological order? A. Right. It goes all the way to the left-hand side. Yeah. Well, after that it's a bit of a toss-up. What do we know? We know that B and C have to appear before D. So maybe just to be annoying, I do A, C, B-- that's a B-- and then D. So it's a topological order. Notice that things that are on the left appear in my graph before things that are on the right, where the word ""before"" here means that there's an edge that points from one to the other. OK. By the way, are topological orderings unique? No. So if we look at our graph example here, ABCD is also a topological order. And what that means is somehow very liberating. It means that when we design an algorithm for finding a topological order, so there's some design decisions that we can make. And we just have to find one among many. But in any event, we're going to define a slightly different notion of order. And then we're going to show that they're closely","72.2125473022461","9","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_18_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"128","What is the key distinction between directed and undirected graphs in terms of edge representation?","the runtime of this full DFS algorithm is v plus e time because every edge is touched no more than one time. Kind of amortized over all the different calls to DGS here. And there's this for loop over vertices. So there's clearly an order v that you need here. Does that argument make sense? So again, we call that linear in the size of the input. I'm going to say it as many times to get it in my own head correctly. OK. Right. So this is the basic problem. This comes up all the time, by the way. Like, it seems like somehow a totally brain dead weird algorithm. Like, somehow, why would you want an algorithm that finds connected components. Like, why would you even have a graph that's disconnected or something? But of course, that can happen a lot. So for instance, maybe you work at a social media company, and people have friends. But like, Eric and I are friends. And we're not friends with anybody else. We have a-- there's like, a blood oath kind of thing. Then that might be not so easy to find in the graph because, of course, we're just two among a sea of students in this classroom, all of which have different interconnections that are just enumerated based on the list of edges. And so even though like, pictorially, it's kind of hard to draw a connecting component algorithm in a way that doesn't make it sound kind of like a useless technique from the start, because it's very clear there are two connected components there. Of course, we still have to be able to write code to solve this sort of thing. OK. So for once, I think I'm almost on time in lecture today. So we have one additional application of depth-first search in our class today, which is sort of on the opposite end of the spectrum. So we just talked about graphs that are undirected and thinking about cycles. Now, on the opposite end we might think of a DAG. So a DAG is a Directed Acyclic Graph. Can anyone think of a special case of a DAG? I suppose I should define it first. And then we'll come back to that question, which means exactly what it sounds like. So it's a graph that has directed edges now and doesn't have any cycles in it. So actually, the graph I gave you all the way at the beginning of lecture I think secretly was an example of one of these. So let's say that I have directed edges. Maybe if I make the head a triangle, it's a little easier to see. I'm not so sure. In any event, so I'm going to have an edge up and an edge to the right, and similarly, an edge down and an edge to the right. This graph looks like a cycle. But it's not because the only direction that I can move is from the left-hand side to the right-hand side. So this is a directed graph. And it doesn't contain any cycles, meaning there's no path that it can take from a vertex that gets back to itself along the directed edges. OK. And DAGs show up all the time. Now that I've defined what a DAG is,","71.70964813232422","10","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_15_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"130","What does BFS do when every edge in a graph is assigned a weight of 1?","BFS. Can anyone think of such a scenario? So let's say, I mean, kind of what we did before was we counted the number of edges. So if we gave a weight of 1 to every edge in my graph, then just that graph, that weighted graph, corresponds to an unweighted graph using the other distance metric. So in that case, BFS just solves our problem. And in fact, we can generalize further. What if all of our weights were positive, but the same value? If it was all positive and the same value, then we could just divide by that value. Now we have an unweighted graph which we can run BFS, and then multiply shortest path distances by that value later on. And in fact, there's one further generalization we can make, which is a little bit of a tricky graph transformation problem.","74.95562744140625","1","DPRSearchEngine","5cF5Bgv59Sc.en-j3PyPqV-e1s_5_mp4","5cF5Bgv59Sc.en-j3PyPqV-e1s","6.006","11"
"130","What does BFS do when every edge in a graph is assigned a weight of 1?"," 
 
 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) 
General Unweighted 
BFS 
|V | + |E|
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Non-negative Dijkstra 
Bellman-Ford 
|V | log |V | + |E|
General Any 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 14: Johnson’s Algorithm 
Lecture 14: Johnson’s Algorithm 
Previously 
|V | · |E| 
All-Pairs Shortest Paths (APSP) 
• Input: directed graph G = (V, E) with weights w : E → Z 
• Output: δ(u, v) for all u, v ∈ V , or abort if G contains negative-weight cycle 
• Useful when understanding whole network, e.g., transportation, circuit layout, supply chains... 
• Just doing a SSSP algorithm |V | times is actually pretty good, since output has size O(|V |2) 
– |V | · O(|V | + |E|) with BFS if weights positive and bounded by O(|V | + |E|) 
– |V | · O(|V | + |E|) with DAG Relaxation if acyclic 
– |V | · O(|V | log |V | + |E|) with Dijkstra if weights non-negative or graph undirected 
– |V | · O(|V | · |E|) with Bellman-Ford (general) 
• Today: Solve APSP in any weighted graph in |V | · O(|V | log |V | + |E|) time 
","74.5921859741211","2","DPRSearchEngine","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14_1_pdf","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14","6.006","14"
"130","What does BFS do when every edge in a graph is assigned a weight of 1?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 11: Weighted Shortest Paths 
Lecture 11: Weighted Shortest Paths 
Review 
• Single-Source Shortest Paths with BFS in O(|V | + |E|) time (return distance per vertex) 
• Single-Source Reachability with BFS or DFS in O(|E|) time (return only reachable vertices) 
• Connected components with Full-BFS or Full-DFS in O(|V | + |E|) time 
• Topological Sort of a DAG with Full-DFS in O(|V | + |E|) time 
• Previously: distance = number of edges in path Today: generalize meaning of distance 
Weighted Graphs 
• A weighted graph is a graph G = (V, E) together with a weight function w : E → Z 
• i.e., assigns each edge e = (u, v) ∈ E an integer weight: w(e) = w(u, v) 
• Many applications for edge weights in a graph: 
– distances in road network 
– latency in network connections 
– strength of a relationship in a social network 
• Two common ways to represent weights computationally: 
– Inside graph representation: store edge weight with each vertex in adjacency lists 
– Store separate Set data structure mapping each edge to its weight 
• We assume a representation that allows querying the weight of an edge in O(1) time 
Examples 
G1 
G2 
a 
e 
b 
f 
c 
g 
d 
h 
6 
8 
−2 
5 
9 
−5 
7 
3 
2 
−1 
−4 
1 
4 
a 
e 
b 
f 
c 
g 
d 
h 
6 
8 
−2 
5 
9 
−5 
7 
3 
2 
−1 
−4 
1 
4 
","73.20787048339844","3","DPRSearchEngine","aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11_1_pdf","aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11","6.006","11"
"130","What does BFS do when every edge in a graph is assigned a weight of 1?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 10: Depth-First Search 
Lecture 10: Depth-First Search 
Previously 
• Graph deﬁnitions (directed/undirected, simple, neighbors, degree) 
• Graph representations (Set mapping vertices to adjacency lists) 
• Paths and simple paths, path length, distance, shortest path 
• Graph Path Problems 
– Single Pair Reachability(G,s,t) 
– Single Source Reachability(G,s) 
– Single Pair Shortest Path(G,s,t) 
– Single Source Shortest Paths(G,s) (SSSP) 
• Breadth-First Search (BFS) 
– algorithm that solves Single Source Shortest Paths 
– with appropriate data structures, runs in O(|V | + |E|) time (linear in input size) 
Examples 
G1 
a 
d 
b 
e 
c 
f 
G2 
a 
d 
b 
e 
c 
f 
","71.58880615234375","4","DPRSearchEngine","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10_1_pdf","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10","6.006","10"
"130","What does BFS do when every edge in a graph is assigned a weight of 1?"," 
 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) Lecture 
General Unweighted 
BFS 
|V | + |E| L09 
L11 
L12 (Today!) 
L13 
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Any 
Bellman-Ford 
Dijkstra 
|V | · |E|
General Non-negative 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 12: Bellman-Ford 
Lecture 12: Bellman-Ford 
Previously 
• Weighted graphs, shortest-path weight, negative-weight cycles 
• Finding shortest-path tree from shortest-path weights in O(|V | + |E|) time 
• DAG Relaxation: algorithm to solve SSSP on a weighted DAG in O(|V | + |E|) time 
• SSSP for graph with negative weights 
– Compute δ(s, v) for all v ∈ V (−∞ if v reachable via negative-weight cycle) 
– If a negative-weight cycle reachable from s, return one 
Warmups 
• Exercise 1: Given undirected graph G, return whether G contains a negative-weight cycle 
• Solution: Return Yes if there is an edge with negative weight in G in O(|E|) time 
:O 
• So for this lecture, we restrict our discussion to directed graphs 
• Exercise 2: Given SSSP algorithm A that runs in O(|V |(|V | + |E|) time, 
show how to use it to solve SSSP in O(|V ||E|) time 
• Solution: Run BFS or DFS to ﬁnd the vertices reachable from s in O(|E|) time 
– Mark each vertex v not reachable from s with δ(s, v) = ∞ in O(|V |) time 
– Make graph G0 = (V 0, E0) with only vertices reachable from s in O(|V | + |E|) time 
– Run A from s in G0 . 
– G0 is connected, so |V 0| = O(|E0|) = O(|E|) so A runs in O(|V ||E|) time 
• Today, we will ﬁnd a SSSP algorithm with this running time that works for general graphs! 
|V | log |V | + |E| 
","69.90821838378906","5","DPRSearchEngine","2430d7903a5529451d80c17f89a41fe8_MIT6_006S20_lec12_1_pdf","2430d7903a5529451d80c17f89a41fe8_MIT6_006S20_lec12","6.006","12"
"130","What does BFS do when every edge in a graph is assigned a weight of 1?","But the point of a subtree property is it's downward looking. If I have a node here, and I want to compute some property about it-- call it, we want to store P of the node-- and suppose we already know P over here, the property computed for the left subtree or for the left node, and we already know the property for the right node, then what I'd like is for this to be computable in constant time. So I can compute P of this node given P of the left node and P of the right node. That's a subtree property. Now, in particular, size is a substrate property. Why? Because I can write this kind of recurrence, node.size equals node.left.size-- this is very tedious to write-- plus node.right.size, plus? 1, thank you. The size of the entire subtree here, called node, is the size of the left subtree plus size of the right subtree, plus 1 for that node itself. So this is an update rule. It takes constant time to evaluate. It's two editions. Sorry, my t's look kind of like plus signs. I'll make the pluses a little bigger. So we're just summing those three things. Boom, we can get node.size. So I claim that as long as my property has this feature, I can maintain it dynamically as I'm changing the tree. Now, this is a little bit of a forward reference, because we haven't said exactly how we're going to change the tree yet. But question?","69.88008117675781","6","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_10_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"130","What does BFS do when every edge in a graph is assigned a weight of 1?"," 
 
 
 
  
  
  
  
 
 
 
 
 
 
 
 
 
 
   
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
    
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
  
   
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
  
 
Equivalence of CFGs and PDAs 
Recall Theorem: ! is a CFL iff some PDA recognizes ! 
Done. 
Need to know the fact, not the proof 
Corollaries: 
1) Every regular language is a CFL. 
2) If ! is a CFL and "" is regular then ! ∩ "" is a CFL. 
Proof sketch of (2):  
While reading the input, the finite control of the PDA for ! simulates the DFA for "". 
Note 1: If ! and "" are CFLs then ! ∩ "" may not be a CFL (will show today). 
Therefore the class of CFLs is not closed under ∩. 
Note 2: The class of CFLs is closed under ∪,∘,∗ (see Pset 2). 
2 
","69.29238891601562","7","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_2_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"130","What does BFS do when every edge in a graph is assigned a weight of 1?","There's not a bound on the number of edges for a shortest path, because I could just keep going around that cycle as many times as I want and get a shorter path. And so we assign those distances to be minus infinity. So that's what we're going to do today in Bellman-Ford. In particular, what we're going to do is compute our shortest path distances, the shortest path waits for every vertex in our graph, setting the ones that are not reachable to infinity, and the ones that are reachable through a negative weight cycle to minus infinity, and all other ones we're going to set to a finite weight. And another thing that we might want is if there's a negative weight cycle in the graph, let's return one. So those are the two kinds of things that we're trying to solve in today's lecture. But before we do that, let's warm up with two short exercises. The first one, exercise 1, given an undirected graph, given undirected graph G, return whether G contains a negative weight cycle. Anyone have an idea of how we can solve this in linear time, actually? In fact, we can do it in order E. No-- yes, yes. Reachable from S. I guess-- let's just say a negative weight cycle at all. Not in the context of single-source shortest paths.","68.98954772949219","8","DPRSearchEngine","f9cVS_URPc0.en-j3PyPqV-e1s_3_mp4","f9cVS_URPc0.en-j3PyPqV-e1s","6.006","12"
"130","What does BFS do when every edge in a graph is assigned a weight of 1?",";
/
def testGreedys(maxUnits):
print('Use greedy by value to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits, Food.getValue)
print('\\nUse greedy by cost to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits,
lambda x: 1/Food.getCost(x))
print('\\nUse greedy by density to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits, Food.density)
testGreedys(800)
	


4
","68.92049407958984","9","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_26_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"130","What does BFS do when every edge in a graph is assigned a weight of 1?","  
  
  
  
 
 
 
  
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Equivalence of CFGs and PDAs 
Theorem: ! is a CFL iff* some PDA recognizes ! 
Done. 
In book.  You are responsible for knowing 
it is true, but not for knowing the proof. 
* “iff” = “if an only if” means the implication goes both ways. 
So we need to prove both directions: forward (→) and reverse (←). 
Check-in 4.3 
Is every Regular Language also 
a Context Free Language? 
(a) Yes 
(b) No 
(c) Not sure 
Check-in 4.3 
10 
","68.79913330078125","10","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_10_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"132","How does tuple sort make use of auxiliary sorting algorithms to sort tuples, and why is sorting from least significant to most significant key crucial?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","70.57512664794922","1","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"132","How does tuple sort make use of auxiliary sorting algorithms to sort tuples, and why is sorting from least significant to most significant key crucial?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","70.43873596191406","2","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"132","How does tuple sort make use of auxiliary sorting algorithms to sort tuples, and why is sorting from least significant to most significant key crucial?","What's the worst case performance of a hash table? If I have to look up something in a hash table, and I happen to choose a bad hash table-- hash function, what's the worst case here? What? n, right? It's worse than a sorted array, because potentially, I hashed everything that I was storing to the same index in my hash table, and to be able to distinguish between them, I can't do anything more than a linear search. I could store another set's data structure as my chain and do better that way. That's actually how Java does it. They store a data structure we're going to be talking about next week as the chains so that they can get, worst case, log n. But in general, that hash table is only good if we're allowing-- OK, I want this to be expected good, but in the worst case, if I really need that operation to be worst case-- I really can't afford linear time ever for an operation of that kind-- then I don't want to use a hash table. And so on your p set 2, everything we ask you for is worst case, so probably, you don't want to be using hash tables. OK? Yes? AUDIENCE: What does the subscript e mean? JASON KU: What does the subscript e mean? That's great. In this chart, I put a subscript on this is an expected runtime, or an A meaning this is an amortized runtime. At the end, we talked about how, if we had too many things in our hash table, then, as long as we didn't do it too often-- this is a little hand wavey argument, but the same kinds of ideas as the dynamic array-- if, whenever we got a linear-- we are more than a linear factor away from where we are trying-- basically, the fill factor we were trying to be, then we could just completely rebuild the hash table with the new hash function randomly chosen from our hash table with a new size, and we could get amortized bounds. And so that's what Python-- how Python implements dictionaries, or sets, or even objects when it's trying to map keys to different things. So that's hash tables. That's great. The key thing here is, well, actually, if your range of keys is small, or if you as a programmer have the ability to choose the keys that you identify your objects with, you can actually choose that range to be small, to be linear, to be small with respect to your items. And you don't need a hash table. You can just use a direct access array, because if you know your key space is small, that's great. So a lot of C programmers probably would like to do something like that, because they don't have access to-- maybe C++ programmers would have access to their hash table. Any questions on this stuff before we move on? Yeah? AUDIENCE: So why is [INAUDIBLE]? JASON KU: Why is it expected? When I'm building, I could insert-- I'm inserting these things from x 1 by 1 into my hash table. Each of those insert operations-- I'm looking up to see whether that-- an item with that key already exists in my hash table. And so I have to look down the chain to see where it is. However, if I happen to know that all of my keys are unique in my input, all the items I'm trying to store are unique, then I don't have to do that check and I can get worst case linear time. Does that make sense? All right. It's a subtlety, but that's a great question. OK, so today, instead of talking about searching, we're talking about sorting. Last week, we saw a few ways to do sort. Some of them were quadratic-- insertion sort and selection sort-- and then we had one that was n log n. And this thing, n log n, seemed pretty good, but can I do better? Can I do better? Well, what we're going to show at the beginning of this class is, in this comparison model, no. n log n is optimal. And we're going to go through the exact same line of reasoning that we had last week. So in the comparison model, what did we use when we were trying to make this argument that any comparison model algorithm was going to take at least log n time? What we did was we said, OK, I can think of any model in the comparison model-- any algorithm in the comparison model as kind of this-- some comparisons happen. They branch in a binary sense, but you could have it generalized to any constant branching factor. But for our purposes, binary's fine. And what we said was that there were at least n outputs-- really n plus 1, but-- at least order n outputs. And we showed that-- or we argued to you that the height of this tree had to be at least log n-- log the number of leaves. It had to be at least log the number of leaves. That was the height of the decision tree. And if this decision tree represented a search algorithm, I had to walk down and perform these comparisons in order, reach a leaf where I would output something. If the minimum height of any binary tree on a linear number of leaves is log n, then any algorithm in the comparison model also has to take log n time, because it has to do that many comparisons to differentiate between all possible outputs. Does that make sense? All right. So in the sort problem, how many possible outputs are there?","69.72025299072266","3","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_4_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"132","How does tuple sort make use of auxiliary sorting algorithms to sort tuples, and why is sorting from least significant to most significant key crucial?","4 
Lecture 1: Introduction 
1 
def birthday_match(students): 
2 
’’’ 
3 
Find a pair of students with the same birthday 
4 
Input: 
tuple of student (name, bday) tuples 
5 
Output: tuple of student names or None 
6 
’’’ 
7 
n = len(students) 
# O(1) 
8 
record = StaticArray(n) 
# O(n) 
9 
for k in range(n): 
# n 
10 
(name1, bday1) = students[k] 
# O(1) 
11 
# Return pair if bday1 in record 
12 
for i in range(k): 
# k 
13 
(name2, bday2) = record.get_at(i) 
# O(1) 
14 
if bday1 == bday2: 
# O(1) 
15 
return (name1, name2) 
# O(1) 
16 
record.set_at(k, (name1, bday1)) 
# O(1) 
17 
return None 
# O(1) 
Example: Running Time Analysis 
• Two loops: outer k ∈{0, . . . , n − 1}, inner is i ∈{0, . . . , k}
P n−1
• Running time is O(n) + 
k=0 (O(1) + k · O(1)) = O(n2) 
• Quadratic in n is polynomial. Efﬁcient? Use different data structure for record! 
How to Solve an Algorithms Problem 
1. Reduce to a problem you already know (use data structure or algorithm) 
Search Problem (Data Structures) 
Sort Algorithms 
Static Array (L01) 
Insertion Sort (L03) 
Linked List (L02) 
Selection Sort (L03) 
Dynamic Array (L02) 
Merge Sort (L03) 
Sorted Array (L03) 
Counting Sort (L05) 
Direct-Access Array (L04) 
Radix Sort (L05) 
Hash Table (L04) 
AVL Sort (L07) 
Balanced Binary Tree (L06-L07) 
Heap Sort (L08) 
Binary Heap (L08) 
2. Design your own (recursive) algorithm 
• Brute Force 
• Decrease and Conquer 
• Divide and Conquer 
• Dynamic Programming (L15-L19) 
• Greedy / Incremental 
Shortest Path Algorithms 
Breadth First Search (L09) 
DAG Relaxation (L11) 
Depth First Search (L10) 
Topological Sort (L10) 
Bellman-Ford (L12) 
Dijkstra (L13) 
Johnson (L14) 
Floyd-Warshall (L18) 
","69.65201568603516","4","DPRSearchEngine","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_4_pdf","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1","6.006","1"
"132","How does tuple sort make use of auxiliary sorting algorithms to sort tuples, and why is sorting from least significant to most significant key crucial?","algorithm. And so if we have a stable sorting algorithm when we're doing tuple sort, when we're sorting on different keys or columns of a set, we really want to be using a stable sorting algorithm. Does that makes sense? Because otherwise, we may mess up work we did before in a previous sort of the less significant things. And so yes, we want a stable sorting algorithm here, because then we will end up sorting our thing. Does that make sense? Yes? AUDIENCE: [INAUDIBLE] JASON KU: So what your colleague is saying-- let's sort by most significant, then look at all of the things with one of those that are the same, and now sort that. That's something we could do. How long would that take? Well, let's say I didn't use half of my more significant set of digits. Say I'm only using n/2 or-- that's not quite going to get what I want. AUDIENCE: [INAUDIBLE] JASON KU: Say again. AUDIENCE: We'll take n squared [INAUDIBLE].. JASON KU: Yeah. So what we're going to do, if we have direct access array sort-- if I then go into each one of these digits and try to sort the things that are in there, that's going to take time. It's going to take time for each of those digits. There might be a ton of collisions into one of the things, and so I might take more time to sort that than linear. Does that make sense? So I would prefer to do this tuple sort kind of behavior, sorting the smaller thing, sorting the bigger thing. And because I only have a constant number of things in my tuples, this is important, because I only have two things I'm worried about here. I only have to do two passes of a sorting algorithm to be able to sort these numbers. However, can I use direct access array sort here? What was the initial stipulation I had on direct access array? That the keys were unique-- that's exactly the opposite of what we have here. We have things that could be the same. So we give up-- can't do it. What do we do instead? Yeah? AUDIENCE: [INAUDIBLE] JASON KU: You've already said the thing that I'm looking for, so that's great. Your colleague said, why can't we just put more things at a key? Why can't we put a list there?","69.4167709350586","5","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_8_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"132","How does tuple sort make use of auxiliary sorting algorithms to sort tuples, and why is sorting from least significant to most significant key crucial?","namely, random accessing. And if we stored the things that we're looking for, we have unique keys, and those keys are integers. Then, if I have an item with key K, if I store it at index K in my array, then I can find it and manipulate it in constant time.","69.084228515625","6","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_2_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"132","How does tuple sort make use of auxiliary sorting algorithms to sort tuples, and why is sorting from least significant to most significant key crucial?","What is the output of a sorting algorithm? AUDIENCE: [INAUDIBLE] JASON KU: What? What's up? A list-- in particular, given my input-- some set of items A that has size n-- what I'm going to give you is some permutation of that list. So for each index, say, I could tell you where it goes. Another way I could say is, where does the first item go to, where does the second item go to, where does the third item go to-- blah, blah, blah-- like that. So how many different choices of a permutation are there? Well, how many choices do I have for the first thing of where it could be in the final sorted array? It could be in any of the places, so it's n. How about this one, the second one? Well, it can't go to where this one went, right but it can go anywhere else. So it's n minus 1. And since these are independent choices I'm making, if I multiply them all together, I get 9 factorial permutations that are the number of possible outputs that I have to my sorting algorithm. So for me, to have an output to my sorting algorithm be correct, I need at least n factorial leaves. Does that make sense? OK. The nice thing about doing this last week is this is really just the number of leaves and this is really the number of leaves. So what's the number of leaves is theta n factorial. Here it's actually n factorial, but I'm just going to put it there. And here we get an n factorial. I see. So it's at least omega n factorial. Does that make you happier? Theta here-- thank you-- has to be at least. So this was right. OK, so at least this many-- there are algorithms that, if it got-- it could take two different routes to get to the same output. So this is a lower bound on the number of leaves. OK? So what this argument is saying is that, if I just replace the number of leaves n here with n factorial, I get a similar comparison sort lower bound now. So what is log of n factorial? This is familiar from p set 1 maybe. So one thing I could do is I could put in Sterling formula, right? And that'll give me something of the form n log n. But what's another way I could lower bound n factorial? Well, I have a bunch of things here. That's n factorial. Half of these things-- these half, n/2 things-- are bigger than or equal to n/2. That make sense? So I can certainly lower bound this thing by n/2 to the n/2. That's a little easier thing to take a log of. If you take a log of that, that's asymptotically n log n. So what we're getting here is any sorting algorithm here takes at least n log n comparisons, and so a merge sort's the best we can do. That make sense to everybody? We're just piggybacking on the analysis we had about decision trees, connecting leaves with the minimum height of any binary tree on that number of leaves, and just replacing n with n factorial-- nothing super interesting here. Yeah? AUDIENCE: [INAUDIBLE] the n over 2. JASON KU: Yeah, sure. You can just plug in Sterling formula, but I did this, so I might as well clarify. There are n terms here in the product. Half of them are at least n/2. Does that make sense? I can lower bound this product by something smaller than half of the terms-- a product of that, and that'll be fine. So I'm taking n/2 of them and I'm multiplying n/2 altogether, n/2 times. Does that make sense? It's just providing a lower bound. I just need something that's smaller than all of these terms. And multiply them all together, and that'll give me a lower bound. OK, so we can't do better than n log n in the comparison model, but what we did last week was use random access and a direct access array to do better. OK? Can anyone think of how to use that idea to sort faster? And I'm going to give you a caveat here. I'm going to let you assume that the keys of the things you're trying to sort out are unique.","69.0544204711914","7","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_5_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"132","How does tuple sort make use of auxiliary sorting algorithms to sort tuples, and why is sorting from least significant to most significant key crucial?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","68.76725006103516","8","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"132","How does tuple sort make use of auxiliary sorting algorithms to sort tuples, and why is sorting from least significant to most significant key crucial?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 5: Linear Sorting 
Lecture 5: Linear Sorting 
Review 
• Comparison search lower bound: any decision tree with n nodes has height ≥dlg(n+1)e−1 
• Can do faster using random access indexing: an operation with linear branching factor! 
• Direct access array is fast, but may use a lot of space (Θ(u)) 
• Solve space problem by mapping (hashing) key space u down to m = Θ(n) 
• Hash tables give expected O(1) time operations, amortized if dynamic 
• Expectation input-independent: choose hash function randomly from universal hash family 
• Data structure overview! 
• Last time we achieved faster ﬁnd. Can we also achieve faster sort? 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
Direct Access Array 
u 
1 
1 
u 
u 
Hash Table 
n(e) 
1(e) 
1(a)(e) 
n 
n 
","68.56013488769531","9","DPRSearchEngine","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5_1_pdf","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5","6.006","5"
"132","How does tuple sort make use of auxiliary sorting algorithms to sort tuples, and why is sorting from least significant to most significant key crucial?","§ Time based on number of nodes generated 
§ Number of levels is number of items to choose from 
§ Number of nodes at level i is 2i 
§ So, if there are n items the number of nodes is 
◦ ∑𝑖=0↑𝑖=𝑛▒​2↑𝑖   
◦ I.e., O(​2↑𝑛+1 ) 
§ An obvious op<miza<on: don’t explore parts of tree 
that violate constraint (e.g., too many calories) 
◦ Doesn’t change complexity 
§ Does this mean that brute force is never useful? 
◦ Let’s give it a try 
Computa#onal Complexity 
6.0002 LECTURE 2 
8 
","68.55662536621094","10","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_8_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"133","How can one solve the Single-Source Shortest Paths problem quickly if given the order of vertices in increasing distance from the source?","single source shortest paths in linear time. Last time we discussed another linear time algorithm, DAG relaxation. And today we're going to be talking about Bellman-Ford, which isn't limited to asymptotic graphs. In particular, there could be negative weight cycles in our graph. If it has cycles, if it has negative weights, the worry is that we could have negative weight cycles, in which case there-- if a negative weight cycle is reachable from our source, then the vertices in that cycle and anything reachable from that cycle will potentially","76.06314849853516","1","DPRSearchEngine","f9cVS_URPc0.en-j3PyPqV-e1s_2_mp4","f9cVS_URPc0.en-j3PyPqV-e1s","6.006","12"
"133","How can one solve the Single-Source Shortest Paths problem quickly if given the order of vertices in increasing distance from the source?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 10: Depth-First Search 
Lecture 10: Depth-First Search 
Previously 
• Graph deﬁnitions (directed/undirected, simple, neighbors, degree) 
• Graph representations (Set mapping vertices to adjacency lists) 
• Paths and simple paths, path length, distance, shortest path 
• Graph Path Problems 
– Single Pair Reachability(G,s,t) 
– Single Source Reachability(G,s) 
– Single Pair Shortest Path(G,s,t) 
– Single Source Shortest Paths(G,s) (SSSP) 
• Breadth-First Search (BFS) 
– algorithm that solves Single Source Shortest Paths 
– with appropriate data structures, runs in O(|V | + |E|) time (linear in input size) 
Examples 
G1 
a 
d 
b 
e 
c 
f 
G2 
a 
d 
b 
e 
c 
f 
","72.43675231933594","2","DPRSearchEngine","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10_1_pdf","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10","6.006","10"
"133","How can one solve the Single-Source Shortest Paths problem quickly if given the order of vertices in increasing distance from the source?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 4: Hashing 
Lecture 4: Hashing 
Review 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
• Idea! Want faster search and dynamic operations. Can we find(k) faster than Θ(log n)? 
• Answer is no (lower bound)! (But actually, yes...!?) 
Comparison Model 
• In this model, assume algorithm can only differentiate items via comparisons 
• Comparable items: black boxes only supporting comparisons between pairs 
• Comparisons are <, ≤, >, ≥, =, =6 , outputs are binary: True or False 
• Goal: Store a set of n comparable items, support find(k) operation 
• Running time is lower bounded by # comparisons performed, so count comparisons! 
Decision Tree 
• Any algorithm can be viewed as a decision tree of operations performed 
• An internal node represents a binary comparison, branching either True or False 
• For a comparison algorithm, the decision tree is binary (draw example) 
• A leaf represents algorithm termination, resulting in an algorithm output 
• A root-to-leaf path represents an execution of the algorithm on some input 
• Need at least one leaf for each algorithm output, so search requires ≥ n + 1 leaves 
","70.62664794921875","3","DPRSearchEngine","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_1_pdf","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4","6.006","4"
"133","How can one solve the Single-Source Shortest Paths problem quickly if given the order of vertices in increasing distance from the source?","So we're going to introduce an algorithm called Breadth-First search which does roughly that. So Breadth-First search, the way we'll introduce it today is going to be an algorithm for computing all of those level sets, L sub i, and then from that, we can construct the length and even the shape of the shortest path. And I'm going to move to my handwritten notes. OK, and here's what our algorithm is going to do. I'm going to write it in a slightly different way than what's in the notes and on the screen, but only slightly. So first of all, one thing I think we can all agree on is that level set 0-- oh, that's-- this chalk bifurcated-- it contains one node. What should that node be? The source because the only thing that's distance is 0 away from the source, is the source node. OK, and in addition to that, we can initialize the distance from the source to itself. Everybody on three, what is the distance from the source to itself-- 1, 2, 3. AUDIENCE: 0. JUSTIN SOLOMON: Thank you. See you're waking up now, it's almost 11:00-- 12:00. What time is it? Almost 12:00-- OK, and then finally-- well maybe initially we don't really know anything about the array p, so we just make it empty. Because p of the source, it somehow doesn't matter. Because once I've made it back to the source, I'm done computing shortest path. So we're going to write an algorithm that computes all the level sets and fills in this array p and fills in the distances all in one big shot. We're going to call it Breadth-First search. OK, so let's do that.","70.02130126953125","4","DPRSearchEngine","oFVYVzlvk9c.en-j3PyPqV-e1s_13_mp4","oFVYVzlvk9c.en-j3PyPqV-e1s","6.006","9"
"133","How can one solve the Single-Source Shortest Paths problem quickly if given the order of vertices in increasing distance from the source?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","69.85221862792969","5","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"133","How can one solve the Single-Source Shortest Paths problem quickly if given the order of vertices in increasing distance from the source?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","69.82264709472656","6","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"133","How can one solve the Single-Source Shortest Paths problem quickly if given the order of vertices in increasing distance from the source?","Longest path is maybe a problem we've talked about in problem session, because it's a DAG-- well, longest path is the same thing as shortest path, if you just negate all the weights. There are no weights in this picture, so if you just put negative 1 on all these edges and ask for the shortest path from the base to anywhere-- so single source shortest paths from this base-- then we would end up getting this path, which, if you look at it, is E-M-P-T-Y, empty. And so that shortest path is indeed the right answer. What I've drawn here is the shortest path tree. So also, if you wanted the longest increasing subsequence starting at A, then it is A-T-Y, just by following the red arrows here. And how do you get that? You just draw the parent pointers, just like we did before.","68.90045166015625","7","DPRSearchEngine","KLBCUx1is2c.en-j3PyPqV-e1s_8_mp4","KLBCUx1is2c.en-j3PyPqV-e1s","6.006","16"
"133","How can one solve the Single-Source Shortest Paths problem quickly if given the order of vertices in increasing distance from the source?","search-- BFS, for those in the know. Breadth-first search is an algorithm. And the reason we use the word breadth is because it's kind of, remember, we talked about level sets last time because we talked about breadth-first search in the context of computing shortest paths. And in particular, we have our source node all the way on the left-hand side. And then breadth-first search constructed all the nodes that were distance 1 away. Right. That's the first level set, and then all the distance 2 away, and then all the distance 3 away, and so on. So in particular, the level set L3 isn't visited until we're completely done with level set L2.","68.74608612060547","8","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_7_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"133","How can one solve the Single-Source Shortest Paths problem quickly if given the order of vertices in increasing distance from the source?","But of course, there's sort of many variations on that theme when we talk about shortest path or even just existence of a path. So these are three sort of model problems that we might solve on a graph. So the first one, which in this of course we're calling the single pair reachability, would be the idea that I take two vertices s and t on my graph g, and I ask you does there exists a path between s and t. So what would be the sort of extreme example where this problem may not always give back the answer yes? Somehow in our head, I think we think of all graphs as being connected. But a perfectly valid graph the way we've defined it would be like 10 vertices and no edges. This function would be very easy to code if that were the only graph you ever cared about. But any event, the existence of a path is already a query that takes a little bit of algorithmic thinking. We haven't figured out how to do that yet. Now another problem we can solve would be the shortest path. Given a graph and two vertices, we might say, well, how far apart are these vertices of my graph if I want to use the shortest possible distance from one to the other. Notice that I can use the second problem to solve the first one. Because what's the length of the shortest path between two vertices that don't have a path between them? Infinity or a shrug-- that's actually a totally valid answer. Yeah, that's right. So how could I implement the reachability code? Well, I could call my shortest path code, and it gives me infinity. Then I return no, it's not reachable. And if it gives me not infinity, I return yes. So remember that a key idea in an algorithms class is this idea of reduction. That I can use one function to solve another. So in case, if we can solve shortest path, then we can certainly solve the reachability problem by calling that piece of code. And then finally we could talk about single source shortest path. So notice now that there's only one input node here s-- so what this problem is saying is give me the length of the shortest path from s to every single other vertex in my graph. Does that makes sense? Like maybe I return a big array with all the information, every single shortest distance. So can we solve single pair shortest path using single source shortest path? Absolutely. I could take s in my single pair shortest path problem, compute the shortest path from s to literally everything else, and then throw away all of that information except the shortest path to t, and now I'm good. Now I haven't justified that this is the fastest possible way to solve that second problem, but at least it shows that if I can solve problem three I can also solve problem two. If I can solve from two I can also solve problem one. So in today's lecture, we're just going to worry about problem three. In other words, these things are sort of listed in increasing order of their difficulty. OK, so in order to think about the single source shortest path problem, we're going to make one additional construction. And this is an idea called the shortest path tree. I got lazy drawing PowerPoint slides at 2:00 AM yesterday,","68.42041015625","9","DPRSearchEngine","oFVYVzlvk9c.en-j3PyPqV-e1s_10_mp4","oFVYVzlvk9c.en-j3PyPqV-e1s","6.006","9"
"133","How can one solve the Single-Source Shortest Paths problem quickly if given the order of vertices in increasing distance from the source?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","68.1715087890625","10","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"134","What is the time complexity of Dijkstra's algorithm compared to Bellman-Ford when solving single source shortest paths and how does this relate to sorting algorithms?","[SQUEAKING][RUSTLING][CLICKING] JASON KU: Welcome, everybody, to our lecture 14 of 6.006. This is our last lecture on graph algorithms, in particular, the last lecture we'll have on weighted shortest paths. But we're going to talk about a slightly different problem today, different than single source shortest paths. We're going to be talking about all-pairs shortest paths. But first, let's review our single source shortest paths algorithms. We had BFS, DAG relaxation, Dijkstra, which we saw last time, which gets pretty close to linear. V log V plus E is pretty close to linear. It's much closer to linear than the general algorithm we have for solving single source shortest paths, namely, Bellman-Ford, which is a little bit more like quadratic. This is like the difference between-- for sparse graphs, this is like the difference between sorting, using insertion sort and n squared, and merge sort in N log N, for example. We're going to get actually quite a big bonus for large input sizes by using Dijkstra when we can. Today, we're going to be focusing","74.67659759521484","1","DPRSearchEngine","EmSmaW-ud6A.en-j3PyPqV-e1s_1_mp4","EmSmaW-ud6A.en-j3PyPqV-e1s","6.006","14"
"134","What is the time complexity of Dijkstra's algorithm compared to Bellman-Ford when solving single source shortest paths and how does this relate to sorting algorithms?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","73.54737854003906","2","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"134","What is the time complexity of Dijkstra's algorithm compared to Bellman-Ford when solving single source shortest paths and how does this relate to sorting algorithms?","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","71.86776733398438","3","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"134","What is the time complexity of Dijkstra's algorithm compared to Bellman-Ford when solving single source shortest paths and how does this relate to sorting algorithms?","single source shortest paths in linear time. Last time we discussed another linear time algorithm, DAG relaxation. And today we're going to be talking about Bellman-Ford, which isn't limited to asymptotic graphs. In particular, there could be negative weight cycles in our graph. If it has cycles, if it has negative weights, the worry is that we could have negative weight cycles, in which case there-- if a negative weight cycle is reachable from our source, then the vertices in that cycle and anything reachable from that cycle will potentially","71.7894287109375","4","DPRSearchEngine","f9cVS_URPc0.en-j3PyPqV-e1s_2_mp4","f9cVS_URPc0.en-j3PyPqV-e1s","6.006","12"
"134","What is the time complexity of Dijkstra's algorithm compared to Bellman-Ford when solving single source shortest paths and how does this relate to sorting algorithms?"," 
 
 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) 
General Unweighted 
BFS 
|V | + |E|
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Non-negative Dijkstra 
Bellman-Ford 
|V | log |V | + |E|
General Any 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 14: Johnson’s Algorithm 
Lecture 14: Johnson’s Algorithm 
Previously 
|V | · |E| 
All-Pairs Shortest Paths (APSP) 
• Input: directed graph G = (V, E) with weights w : E → Z 
• Output: δ(u, v) for all u, v ∈ V , or abort if G contains negative-weight cycle 
• Useful when understanding whole network, e.g., transportation, circuit layout, supply chains... 
• Just doing a SSSP algorithm |V | times is actually pretty good, since output has size O(|V |2) 
– |V | · O(|V | + |E|) with BFS if weights positive and bounded by O(|V | + |E|) 
– |V | · O(|V | + |E|) with DAG Relaxation if acyclic 
– |V | · O(|V | log |V | + |E|) with Dijkstra if weights non-negative or graph undirected 
– |V | · O(|V | · |E|) with Bellman-Ford (general) 
• Today: Solve APSP in any weighted graph in |V | · O(|V | log |V | + |E|) time 
","71.15845489501953","5","DPRSearchEngine","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14_1_pdf","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14","6.006","14"
"134","What is the time complexity of Dijkstra's algorithm compared to Bellman-Ford when solving single source shortest paths and how does this relate to sorting algorithms?"," 
 
 
 
  
 
 
  
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Intro to Complexity Theory 
Computability theory (1930s - 1950s): 
Is A decidable? 
Complexity theory (1960s - present): 
Is A decidable with restricted resources? 
(time/memory/…) 
Example: Let ! = a#b# $ ≥0 . 
Q: How many steps are needed to decide !? 
Depends on the input. 
We give an upper bound for all inputs of length '. 
Called “worst-case complexity”. 
2 
","70.92239379882812","6","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_2_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"134","What is the time complexity of Dijkstra's algorithm compared to Bellman-Ford when solving single source shortest paths and how does this relate to sorting algorithms?","This data structure is called the Fibonacci heap. We're not going to talk about it in 6.006. They talk about it-- and you can look at chapter 19 in CLRS or you can look at-- I think they talk about it in 6.854 if you're interested in learning about Fibonacci heaps. But these are almost never-- I mean, they get good theoretical bounds. So what you want to say is, whenever we give you a theory problem where you might want to use Dijkstra, you want to use this theoretical running time bound for your problem E plus V log V. But if you happen to know that your graph is sparse or dense, just using an array or a heap is going to get you just as good of a running time. Very close to linear. And so in practice, most people, when they are implementing a graph search algorithm, they know if their graph is sparse or dense, and so they never bother implementing a Fibonacci heap, which is a little complicated. So they're usually either in one of these first two cases where V squared is linear when your graph is dense, or we're very close to linear, E times log V, which is V log V if your graph is sparse. So that's the running time of Dijkstra. So so far, we've gotten all of these nice bounds. Some special cases where we're-- I mean, special cases where we're linear. Dijkstra where we're close to linear. And Bellman-Ford, if we throw our hands up in the air, there might be negative cycles in our graph, we gotta spend that quadratic running time bound. Now there are faster algorithms, but this is the fastest we're going to teach you in this class. Now and in the next lecture we're going to be talking about all pair shortest paths, and we'll pick it up next time.","70.9049072265625","7","DPRSearchEngine","NSHizBK9JD8.en-j3PyPqV-e1s_8_mp4","NSHizBK9JD8.en-j3PyPqV-e1s","6.006","13"
"134","What is the time complexity of Dijkstra's algorithm compared to Bellman-Ford when solving single source shortest paths and how does this relate to sorting algorithms?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 10: Depth-First Search 
Lecture 10: Depth-First Search 
Previously 
• Graph deﬁnitions (directed/undirected, simple, neighbors, degree) 
• Graph representations (Set mapping vertices to adjacency lists) 
• Paths and simple paths, path length, distance, shortest path 
• Graph Path Problems 
– Single Pair Reachability(G,s,t) 
– Single Source Reachability(G,s) 
– Single Pair Shortest Path(G,s,t) 
– Single Source Shortest Paths(G,s) (SSSP) 
• Breadth-First Search (BFS) 
– algorithm that solves Single Source Shortest Paths 
– with appropriate data structures, runs in O(|V | + |E|) time (linear in input size) 
Examples 
G1 
a 
d 
b 
e 
c 
f 
G2 
a 
d 
b 
e 
c 
f 
","70.8160171508789","8","DPRSearchEngine","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10_1_pdf","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10","6.006","10"
"134","What is the time complexity of Dijkstra's algorithm compared to Bellman-Ford when solving single source shortest paths and how does this relate to sorting algorithms?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","70.78755187988281","9","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"134","What is the time complexity of Dijkstra's algorithm compared to Bellman-Ford when solving single source shortest paths and how does this relate to sorting algorithms?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Clustering Algorithms  
§Hierarchical  clustering  
◦ Can select number  of clusters using dendogram 
◦ Deterministic 
◦ Flexible with respect to linkage criteria 
◦ Slow 
◦ Naïve algorithm n3 
◦ n2 algorithms exist for some linkage criteria 
§K-means a much faster greedy algorithm 
◦ Most useful when you know how many clusters  you want  
6.0002  LECTURE 12 
9 
","70.75647735595703","10","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_9_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"135","What is the runtime complexity of the merge function in merge sort?","&

	
	
	/
def greedy(items, maxCost, keyFunction):
itemsCopy = sorted(items, key = keyFunction,
reverse = True)
result = []
totalValue, totalCost = 0.0, 0.0
for i in range(len(itemsCopy)):
if (totalCost+itemsCopy[i].getCost()) <= maxCost:
result.append(itemsCopy[i])
totalCost += itemsCopy[i].getCost()
totalValue += itemsCopy[i].getValue()
return (result, totalValue) 
	

2
	

","78.597900390625","1","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_24_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"135","What is the runtime complexity of the merge function in merge sort?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","76.75515747070312","2","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"135","What is the runtime complexity of the merge function in merge sort?","They take linear time for some of the operations. So the sorting algorithms are not efficient. But they're ones we've seen before, so it's neat to see how they fit in here. They had the-- selection sort and insertion sort had the advantage that they were in place. You just needed a constant number of pointers or indices beyond the array itself. So they're very space efficient. So that was a plus for them. But they take n squared time, so you should never use them, except for n, at most, 100 or something. AVL tree sort is great and then it gets n log n time, probably more complicated than merge sort and you could stick to merge sort. But neither merge sort nor set AVL tree sort are in place. And so the goal of today is to get the best of all those worlds in sorting to get n log n comparisons, which is optimal in the comparison model, but get it to be in place. And that's what we're going to get with binary heaps. We're going to design a data structure that happens to build a little bit faster-- as I mentioned, linear time building. So it's not representing a sorted order in the same way that AVL trees are. But it will be kind of tree-based. It will also be array-based. We're going to get logarithmic time for insert and delete_max. It happens to be amortized, because we use arrays. But the key thing is that it's an in-place data structure. It only consists of an array of the items. And so, when we plug it into our sorting algorithm-- priority queue sort or generic sorting algorithm-- not only do we get n log n performance, but we also get an in-place sorting algorithm. This will be our first and only-- to this class-- n log n in-place sorting algorithm. Cool. That's the goal.","76.0080337524414","3","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_5_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"135","What is the runtime complexity of the merge function in merge sort?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","75.8738784790039","4","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"135","What is the runtime complexity of the merge function in merge sort?","Header for Decision Tree Implementa#on 
6.0002 LECTURE 2 
9 
def maxVal(toConsider, avail): 
    """"""Assumes toConsider a list of items,  
               avail a weight 
       Returns a tuple of the total value of a  
           solution to 0/1 knapsack problem and  
           the items of that solution""""” 
toConsider. Those items that nodes higher up in the tree 
(corresponding to earlier calls in the recursive call stack) 
have not yet considered 
 
avail. The amount of space still available  
","75.38749694824219","5","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_9_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"135","What is the runtime complexity of the merge function in merge sort?","which is merge sort, so a divide and conquer algorithm, phrased with this structure of SRTBOT. So for the sub problems-- so our original problem is to sort the elements of A. And some sub-problems that we solve along the way are sorting different sub-arrays of A. So for every-- well, not for every i and j, but for some i and js, we sort the items from i up to j minus 1. So I'm going to define that subproblem to be s of ij. So this is something that I might want to solve. The original problem that I want to solve is s of 0 comma n, where n is the length of the array. So that's what I actually care about in the end. But we're going to solve that by writing it recursively in terms of sorting different sub-arrays as follows. This is the recurrence relation. I've written it very simply here. Of course, there's a merge algorithm, which is somewhat complicated. But as we saw the two finger linear time merge algorithm, given two sorted arrays-- so this is supposed to be the sorted array version of the items i through m. m is the middle element between i and j and the sorted array of the items from m up to j. If we merge those, that gives us the sorted array from i up to j. And that's exactly what merge sort does. So in general, this relation is just some algorithm for if you're given the solutions to some smaller subproblems, how do I solve the subproblem that I want to solve? And so we need to make sure that this problem is bigger than the ones that we recursively call on and that we don't get an infinite cyclic loop of recursions. And here our valid topological order is to say, solve these problems in order where j minus i-- the length of the sub-array-- is increasing. And then you can check because m is strictly between i and j. As long as we're not in a base case, then we know we can-- these subarrays will be smaller than this one. And so this increasing order gives us a valid topological order on all of the problems, all the subproblems. We have a base case, which is if we don't want to sort anything, that's the empty array, or at least in the original problem. And then running time is-- I mean, there's no better way to solve it than the recurrence that we already saw how to solve. So this is just another way to think of n log n","73.28144836425781","6","DPRSearchEngine","r4-cftqTcdI.en-j3PyPqV-e1s_3_mp4","r4-cftqTcdI.en-j3PyPqV-e1s","6.006","15"
"135","What is the runtime complexity of the merge function in merge sort?","
7:
/
def greedy(items, maxCost, keyFunction):
""""""Assumes items a list, maxCost >= 0,
keyFunction maps elements of items to numbers""""""
itemsCopy = sorted(items, key = keyFunction,
reverse = True)
result = []
totalValue, totalCost = 0.0, 0.0
for i in range(len(itemsCopy)):
if (totalCost+itemsCopy[i].getCost()) <= maxCost:
result.append(itemsCopy[i])
totalCost += itemsCopy[i].getCost()
totalValue += itemsCopy[i].getValue()
return (result, totalValue) 
	

&
","72.68087768554688","7","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_23_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"135","What is the runtime complexity of the merge function in merge sort?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 4: Hashing 
Lecture 4: Hashing 
Review 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
• Idea! Want faster search and dynamic operations. Can we find(k) faster than Θ(log n)? 
• Answer is no (lower bound)! (But actually, yes...!?) 
Comparison Model 
• In this model, assume algorithm can only differentiate items via comparisons 
• Comparable items: black boxes only supporting comparisons between pairs 
• Comparisons are <, ≤, >, ≥, =, =6 , outputs are binary: True or False 
• Goal: Store a set of n comparable items, support find(k) operation 
• Running time is lower bounded by # comparisons performed, so count comparisons! 
Decision Tree 
• Any algorithm can be viewed as a decision tree of operations performed 
• An internal node represents a binary comparison, branching either True or False 
• For a comparison algorithm, the decision tree is binary (draw example) 
• A leaf represents algorithm termination, resulting in an algorithm output 
• A root-to-leaf path represents an execution of the algorithm on some input 
• Need at least one leaf for each algorithm output, so search requires ≥ n + 1 leaves 
","72.64603424072266","8","DPRSearchEngine","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_1_pdf","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4","6.006","4"
"135","What is the runtime complexity of the merge function in merge sort?","4 
Lecture 1: Introduction 
1 
def birthday_match(students): 
2 
’’’ 
3 
Find a pair of students with the same birthday 
4 
Input: 
tuple of student (name, bday) tuples 
5 
Output: tuple of student names or None 
6 
’’’ 
7 
n = len(students) 
# O(1) 
8 
record = StaticArray(n) 
# O(n) 
9 
for k in range(n): 
# n 
10 
(name1, bday1) = students[k] 
# O(1) 
11 
# Return pair if bday1 in record 
12 
for i in range(k): 
# k 
13 
(name2, bday2) = record.get_at(i) 
# O(1) 
14 
if bday1 == bday2: 
# O(1) 
15 
return (name1, name2) 
# O(1) 
16 
record.set_at(k, (name1, bday1)) 
# O(1) 
17 
return None 
# O(1) 
Example: Running Time Analysis 
• Two loops: outer k ∈{0, . . . , n − 1}, inner is i ∈{0, . . . , k}
P n−1
• Running time is O(n) + 
k=0 (O(1) + k · O(1)) = O(n2) 
• Quadratic in n is polynomial. Efﬁcient? Use different data structure for record! 
How to Solve an Algorithms Problem 
1. Reduce to a problem you already know (use data structure or algorithm) 
Search Problem (Data Structures) 
Sort Algorithms 
Static Array (L01) 
Insertion Sort (L03) 
Linked List (L02) 
Selection Sort (L03) 
Dynamic Array (L02) 
Merge Sort (L03) 
Sorted Array (L03) 
Counting Sort (L05) 
Direct-Access Array (L04) 
Radix Sort (L05) 
Hash Table (L04) 
AVL Sort (L07) 
Balanced Binary Tree (L06-L07) 
Heap Sort (L08) 
Binary Heap (L08) 
2. Design your own (recursive) algorithm 
• Brute Force 
• Decrease and Conquer 
• Divide and Conquer 
• Dynamic Programming (L15-L19) 
• Greedy / Incremental 
Shortest Path Algorithms 
Breadth First Search (L09) 
DAG Relaxation (L11) 
Depth First Search (L10) 
Topological Sort (L10) 
Bellman-Ford (L12) 
Dijkstra (L13) 
Johnson (L14) 
Floyd-Warshall (L18) 
","72.36775207519531","9","DPRSearchEngine","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_4_pdf","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1","6.006","1"
"135","What is the runtime complexity of the merge function in merge sort?"," 
 
 
 
 
  
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Constructing !"",$: 1st try 
% on & 
Recall: A tableau for % on & represents 
a computation history for % on & 
when % accepts &. 
Rows of that tableau are configurations. 
% runs in space 45, its tableau has: 
- 45 columns (max size of a configuration)
-8
- 6
rows (max number of steps) 
Constructing !"",$. Try Cook-Levin method. 
Then !"",$ will be as big as tableau. 
-8
But that is exponential: 45×6 
.
Too big! • 
7 
Tableau for % on &
'( &) &* &+ ⋯&-
a
'. &*
⋯
⋯
'accept ⋯
˽   … ˽
45
6(-8)
","72.31636810302734","10","DPRSearchEngine","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18_7_pdf","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18","18.404J","18"
"136","How can subtree properties in binary trees be efficiently maintained when nodes are added or removed?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","77.88790130615234","1","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"136","How can subtree properties in binary trees be efficiently maintained when nodes are added or removed?","We're almost done. This will actually work. It's really quite awesome. But for it to work, we need something called subtree augmentation, which I'll talk about generally. And then, we'll apply it to size. So the idea with subtree augmentation is that each node in our binary tree can store a constant number of extra fields. Why not? And in particular, if these fields are of a particular type-- maybe I'll call them properties. I'm going to define a subtree property to be something that can be computed from the properties of the nodes' children. So I should say this is of a node. So children are node.left and node.right. You can also access constant amount of other stuff,","77.06917572021484","2","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_9_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"136","How can subtree properties in binary trees be efficiently maintained when nodes are added or removed?","If you think about it a little bit, this is exactly binary search on an array. It just happens to be on a tree instead. If you think of an array like this, what does binary search do? It first looks at the key in the middle. I'm going to draw that as the root. And then, it recurses either on the left chunk, which I will draw recursively, or on the right chunk. And so if you happen to have a perfect binary tree like this one, it is simulating exactly binary search in this array. But this we're going to be able to maintain dynamically-- not perfect any more, but close. Whereas this we could not maintain in sorted order. So this is like a generalization of binary search to work on trees instead of on arrays. And for this reason, set binary trees are called binary search trees, because they're the tree version of binary search. So there's many equivalent names. So binary search tree is another name for set binary tree. And the key thing that makes this algorithm work is the so-called binary search tree property, which is all the keys in the left subtree of a node are less than the root, or of that node, and that key is less than all the keys in the right subtree. And this is true recursively all the way down. And so that's how you prove that this algorithm is correct by this property. Why is this true? Because if we can maintain traversal order to be increasing key, then that's exactly what traversal order means. It tells you all the things in the left subtree come before the root, which come before all the things in the right subtree.","76.9396743774414","3","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_4_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"136","How can subtree properties in binary trees be efficiently maintained when nodes are added or removed?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","76.16148376464844","4","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"136","How can subtree properties in binary trees be efficiently maintained when nodes are added or removed?","&

	
	
	/
def greedy(items, maxCost, keyFunction):
itemsCopy = sorted(items, key = keyFunction,
reverse = True)
result = []
totalValue, totalCost = 0.0, 0.0
for i in range(len(itemsCopy)):
if (totalCost+itemsCopy[i].getCost()) <= maxCost:
result.append(itemsCopy[i])
totalCost += itemsCopy[i].getCost()
totalValue += itemsCopy[i].getValue()
return (result, totalValue) 
	

2
	

","75.40396881103516","5","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_24_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"136","How can subtree properties in binary trees be efficiently maintained when nodes are added or removed?"," 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Relationships among models 
Informal Defn: Two models of computation are polynomially related 
if each can simulate the other with a polynomial overhead: 
So ! "" time → !$("") time on the other model, for some '. 
All reasonable deterministic models are polynomially related. 
• 1-tape TMs 
• multi-tape TMs 
• multi-dimensional TMs 
• random access machine (RAM) 
• cellular automata 
9 
","74.63836669921875","6","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_9_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"136","How can subtree properties in binary trees be efficiently maintained when nodes are added or removed?","4 
Lecture 1: Introduction 
1 
def birthday_match(students): 
2 
’’’ 
3 
Find a pair of students with the same birthday 
4 
Input: 
tuple of student (name, bday) tuples 
5 
Output: tuple of student names or None 
6 
’’’ 
7 
n = len(students) 
# O(1) 
8 
record = StaticArray(n) 
# O(n) 
9 
for k in range(n): 
# n 
10 
(name1, bday1) = students[k] 
# O(1) 
11 
# Return pair if bday1 in record 
12 
for i in range(k): 
# k 
13 
(name2, bday2) = record.get_at(i) 
# O(1) 
14 
if bday1 == bday2: 
# O(1) 
15 
return (name1, name2) 
# O(1) 
16 
record.set_at(k, (name1, bday1)) 
# O(1) 
17 
return None 
# O(1) 
Example: Running Time Analysis 
• Two loops: outer k ∈{0, . . . , n − 1}, inner is i ∈{0, . . . , k}
P n−1
• Running time is O(n) + 
k=0 (O(1) + k · O(1)) = O(n2) 
• Quadratic in n is polynomial. Efﬁcient? Use different data structure for record! 
How to Solve an Algorithms Problem 
1. Reduce to a problem you already know (use data structure or algorithm) 
Search Problem (Data Structures) 
Sort Algorithms 
Static Array (L01) 
Insertion Sort (L03) 
Linked List (L02) 
Selection Sort (L03) 
Dynamic Array (L02) 
Merge Sort (L03) 
Sorted Array (L03) 
Counting Sort (L05) 
Direct-Access Array (L04) 
Radix Sort (L05) 
Hash Table (L04) 
AVL Sort (L07) 
Balanced Binary Tree (L06-L07) 
Heap Sort (L08) 
Binary Heap (L08) 
2. Design your own (recursive) algorithm 
• Brute Force 
• Decrease and Conquer 
• Divide and Conquer 
• Dynamic Programming (L15-L19) 
• Greedy / Incremental 
Shortest Path Algorithms 
Breadth First Search (L09) 
DAG Relaxation (L11) 
Depth First Search (L10) 
Topological Sort (L10) 
Bellman-Ford (L12) 
Dijkstra (L13) 
Johnson (L14) 
Floyd-Warshall (L18) 
","74.23609924316406","7","DPRSearchEngine","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_4_pdf","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1","6.006","1"
"136","How can subtree properties in binary trees be efficiently maintained when nodes are added or removed?","namely, random accessing. And if we stored the things that we're looking for, we have unique keys, and those keys are integers. Then, if I have an item with key K, if I store it at index K in my array, then I can find it and manipulate it in constant time.","74.14730072021484","8","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_2_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"136","How can subtree properties in binary trees be efficiently maintained when nodes are added or removed?","I'll call them left justified. And these two properties together is what I call a complete binary tree. Why is this interesting? Because I claim I can represent a tree like this as an array. I've narrowed things down enough that I can draw an array down here. And what I'm going to do is write these nodes in depth order. So I write A first, because that's step 0. Then B, C, that's step 1. Then, well, they're alphabetical. I made it that way. D, E, F, G is depth 2. And then H, I, J is step 3. This is very different from traversal order of a tree. Traversal order would have been H, D, I, B, J, E, A, F, C, G, OK? But this is what we might call depth order, do the lowest depth nodes first-- very different way to lay things out or to linearize our data. And this is what a heap is going to look like. So the cool thing is, between complete binary trees and arrays is a bijection. For every array, there's a unique complete binary tree. And for every complete binary tree, there's a unique array. Why? Because the complete constraint forces everything-- forces my hand. There's only-- if I give you a number n, there is one tree shape of size n, right? You just fill in the nodes top down until you get to the last level. And then you have to fill them in left to right. It's what you might call reading order for writing down nodes. And the array is telling you which keys go where. This is the first node you write down at the root, this is the next node you write down at the left child of the root, and so on. So here we have a binary tree represented as an array, or array representing a binary tree. The very specific binary tree, it has a clear advantage, which is it is guaranteed balance. No rotations necessary in heaps, because complete binary trees are always balanced. In fact, they have the best height they possibly could, which is ceiling of log n. Balanced, remember, just meant you were big O of log n. This is 1 times log n. So it's the best level of balance you could hope for. So somehow, I claim, we can maintain a complete binary tree for solving priority queues. This would not be possible if you were trying to solve the whole set interface. And that's kind of the cool thing about heaps, is that by just focusing on the subset of the set interface, we can do more. We can maintain this very strong property. And because we have this very strong property, we don't even need to store this tree. We're not going to store left and right pointers and parent pointers, we're just going to store the array.","73.87938690185547","9","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_8_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"136","How can subtree properties in binary trees be efficiently maintained when nodes are added or removed?","Header for Decision Tree Implementa#on 
6.0002 LECTURE 2 
9 
def maxVal(toConsider, avail): 
    """"""Assumes toConsider a list of items,  
               avail a weight 
       Returns a tuple of the total value of a  
           solution to 0/1 knapsack problem and  
           the items of that solution""""” 
toConsider. Those items that nodes higher up in the tree 
(corresponding to earlier calls in the recursive call stack) 
have not yet considered 
 
avail. The amount of space still available  
","73.42332458496094","10","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_9_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"137","How do you determine the optimal way to hit pins in this carnival bowling game to maximize the score given the possibility of negative values and pair combinations?","you will just hit that one pin. And if you bowl in the middle between two pins, you will knock down-- that's a ball, sorry-- you will knock down two pins. And this is your model of bowling, model of computation. Now, what makes this interesting is that the pins have values. Pin i has value-- this is obviously a toy problem, though this problem-- this type of bowling does go back to 1908, it was also a toy problem in that setting. So each of these bowling pins has some number on it, let's say 1, 9, 9-- I'll do a slightly more interesting example, maybe another one here and a 2 and a 5 and a 5, something like this. OK. Or maybe make it a little more interesting. Let's put some negative numbers on here. OK. And the model-- so you're at the carnival bowling. Each pin has different-- potentially different values. And the model is if you hit one pin, i, then you get vi points. So that's straight forward. To make it interesting, when you hit two pins, you get the product. So if I hit two pins, it's always i and i plus 1 for some I. You get vi times vi plus 1 points. This is the game you're playing. And it doesn't really matter that this is a product. Product is just some weird function that's hard to imagine. If you stare at this long enough, you should convince yourself that the optimal solution is probably to-- so, for each of these numbers, I could leave it singleton or pair it with its left neighbor or pair it with its right neighbor. But the pairings can't overlap because once I hit a pin, it's gone. It's knocked over. It disappears. So because of these nine, which are a very high value, what I'd probably like to do is hit both of them together, so pair them up, because 9 times 9 is 81. That's really big, much better than hitting them individually or hitting 9 times 1 or 9 times 2. 1 and 1 is kind of funny, because it's actually better to hit them individually. That will give you two points, whereas if I'd pair them up, I only get one point. 2 and minus 5, that seems bad. Negative 10 points. My goal is to maximize score. Do you have to hit all the pins? Let's say no, you don't have to hit all the pins. So I could skip the minus fives. But in fact, here, because they're adjacent, minus 5 times minus 5 is good. That's 25 points. So the optimal solution for this particular instance are to hit all the pins, these positive, these together, these together. If I added, for example, another pin of minus 3 here, I would choose not to hit that pin. Good question. So you just play until you are tired.","72.977294921875","1","DPRSearchEngine","r4-cftqTcdI.en-j3PyPqV-e1s_10_mp4","r4-cftqTcdI.en-j3PyPqV-e1s","6.006","15"
"137","How do you determine the optimal way to hit pins in this carnival bowling game to maximize the score given the possibility of negative values and pair combinations?","7 
Lecture 18: Pseudopolynomial 
Main Features of Dynamic Programs 
• Review of examples from lecture 
• Subproblems: 
– Preﬁx/sufﬁxes: Bowling, LCS, LIS, Floyd–Warshall, Rod Cutting (coincidentally, re­
ally Integer subproblems), Subset Sum 
– Substrings: Alternating Coin Game, Arithmetic Parenthesization 
– Multiple sequences: LCS 
– Integers: Fibonacci, Rod Cutting, Subset Sum 
Pseudopolynomial: Fibonacci, Subset Sum 
* 
– Vertices: DAG shortest paths, Bellman–Ford, Floyd–Warshall 
• Subproblem constraints/expansion: 
– Nonexpansive constraint: LIS (include ﬁrst item) 
– 2× expansion: Alternating Coin Game (who goes ﬁrst?), Arithmetic Parenthesization 
(min/max) 
– Θ(1)× expansion: Piano Fingering (ﬁrst ﬁnger assignment) 
– Θ(n)× expansion: Bellman–Ford (# edges) 
• Relation: 
– Branching = # dependant subproblems in each subproblem 
– Θ(1) branching: Fibonacci, Bowling, LCS, Alternating Coin Game, Floyd–Warshall, 
Subset Sum 
– Θ(degree) branching (source of |E| in running time): DAG shortest paths, Bellman– 
Ford 
– Θ(n) branching: LIS, Arithmetic Parenthesization, Rod Cutting 
– Combine multiple solutions (not path in subproblem DAG): Fibonacci, Floyd– 
Warshall, Arithmetic Parenthesization 
• Original problem: 
– Combine multiple subproblems: DAG shortest paths, Bellman–Ford, Floyd–Warshall, 
LIS, Piano Fingering 
","65.30257415771484","2","DPRSearchEngine","mit6_006s20_lec18_7_pdf","mit6_006s20_lec18","6.006","18"
"137","How do you determine the optimal way to hit pins in this carnival bowling game to maximize the score given the possibility of negative values and pair combinations?","When I had all heads, there was no variability in my answer. I got the same answer all the time. And so there was no variability, and that intuitively-- and in fact, mathematically-- should make us feel confident that, OK, maybe that's really the way the world is. On the other hand, when almost half are heads and almost half are tails, there's a lot of variance. Right, it's hard to predict what the next one will be. And so we should have very little confidence that it isn't an accident that it happened to be 52-48 in one direction. So as the variance grows, we need larger samples to have the same amount of confidence. All right, let's look at that with a detailed example. We'll look at roulette in keeping with the theme of Monte Carlo simulation. This is a roulette wheel that could well be at Monte Carlo. There's no need to simulate roulette, by the way. It's a very simple game, but as we've seen with our earlier examples, it's nice when we're learning about simulations to simulate things where we actually can know what the actual answer is so that we can then understand our simulation better. For those of you who don't know how roulette is played-- is there anyone here who doesn't know how roulette is played? Good for you. You grew up virtuous. All right, so-- well all right. Maybe I won't go there. So you have a wheel that spins around, and in the middle are a bunch of pockets. Each pocket has a number and a color. You bet in advance on what number you think is going to come up, or what color you think is going to come up. Then somebody drops a ball in that wheel, gives it a spin. And through centrifugal force, the ball stays on the outside for a while. But as the wheel slows down and heads towards the middle, and eventually settles in one of those pockets. And you win or you lose. Now you can bet on it, and so let's look at an example of that. So here is a roulette game. I've called it fair roulette, because it's set up in such a way that in principle, if you bet, your expected value should be 0. You'll win some, you'll lose some, but it's fair in the sense that it's not either a negative or positive sum game. So as always, we have an underbar underbar in it. Well we're setting up the wheel with 36 pockets on it, so you can bet on the numbers 1 through 36. That's way range work, you'll recall. Initially, we don't know where the ball is, so we'll say it's none. And here's the key thing is, if you make a bet, this tells you what your odds are. That if you bet on a pocket and you win, you get len of pockets minus 1. So This is why it's a fair game, right? You bet $1. If you win, you get $36, your dollar plus $35 back. If you lose, you lose. All right, self dot spin will be random dot choice among the pockets. And then there is simply bet, where you just can choose an amount to bet and the pocket you want to bet on. I've simplified it. I'm not allowing you to bet here on colors. All right, so then we can play it. So here is play roulette. I've made game the class a parameter,","65.07736206054688","3","DPRSearchEngine","OgO1gpXSUzU.en-j3PyPqV-e1s_5_mp4","OgO1gpXSUzU.en-j3PyPqV-e1s","6.0002","6"
"137","How do you determine the optimal way to hit pins in this carnival bowling game to maximize the score given the possibility of negative values and pair combinations?","   
 
 
 
 
How  Likely Is it Just Bad Luck?  
A variant of cherry picking called  
multiple hypothesis testing 
6.0002  LECTURE 15 
14 
","65.0176773071289","4","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_13_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"137","How do you determine the optimal way to hit pins in this carnival bowling game to maximize the score given the possibility of negative values and pair combinations?"," 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Comparing the Games  
Simulate 20 trials of 1000 spins each  
Exp. return for Fair Roulette = 6.56%  
Exp. return for European Roulette = -2.26%  
Exp. return for American Roulette = -8.92%  
Simulate 20 trials of 10000 spins each  
Exp. return for Fair Roulette = -1.234%  
Exp. return for European Roulette = -4.168%  
Exp. return for American Roulette = -5.752%  
Simulate 20 trials of 100000 spins each  
Exp. return for Fair Roulette = 0.8144%  
Exp. return for European Roulette = -2.6506%  
Exp. return for American Roulette = -5.113%  
Simulate 20 trials of 1000000 spins each  
Exp. return for Fair Roulette = -0.0723%  
Exp. return for European Roulette = -2.7329%  
6.0002 LECTURE 6 
Exp. return for American Roulette = -5.212% 
19
","64.89013671875","5","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_19_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"137","How do you determine the optimal way to hit pins in this carnival bowling game to maximize the score given the possibility of negative values and pair combinations?"," 
 
 
  
 
 
 
    
 
 
    
 
        
 
        
 
 
    
 
        
 
 
 
 
        
 
 
 
              
 
    
 
 
 
  
 
 
 
 
    
 
 
        
 
 
 
Monte Carlo Simulation  
def playRoulette(game, numSpins, pocket, bet): 
totPocket = 0 
for i in range(numSpins): 
game.spin()  
totPocket += game.betPocket(pocket, bet)  
if toPrint: 
print(numSpins, 'spins of', game) 
print('Expected return betting', pocket, '=',\\ 
str(100*totPocket/numSpins) + '%\\n') 
return (totPocket/numSpins) 
game = FairRoulette() 
for numSpins in (100, 1000000): 
for i in range(3): 
playRoulette(game, numSpins, 2, 1, True) 
6.0002 LECTURE 6 
12
","64.4383316040039","6","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_12_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"137","How do you determine the optimal way to hit pins in this carnival bowling game to maximize the score given the possibility of negative values and pair combinations?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
Regression to the Mean  
Following an extreme random event, the next random 
event is likely to be less extreme 
If you spin a fair roulette wheel 10 times and get 100% 
reds, that is an extreme event (probability = 1/1024) 
It is likely that in the next 10 spins, you will get fewer 
than 10 reds 
◦ But the expected number is only 5 
So, if you look at the average of the 20 spins, it will be 
closer to the expected mean of 50% reds than to the 
100% of the first 10 spins 
6.0002 LECTURE 6 
16
","64.26171112060547","7","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_16_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"137","How do you determine the optimal way to hit pins in this carnival bowling game to maximize the score given the possibility of negative values and pair combinations?","A pretty small number. But the probability of 26 consecutive reds when the previous 25 rolls were red is what? No, that. AUDIENCE: Oh, I thought you meant it had been 26 times again. JOHN GUTTAG: No, if you had 25 reds and then you spun the wheel once more, the probability of it having 26 reds is now 0.5, because these are independent events. Unless of course the wheel is rigged, and we're assuming it's not. People have a hard time accepting this, and I know it seems funny. But I guarantee there will be some point in the next month or so when you will find yourself thinking this way, that something has to even out. I did so badly on the midterm, I will have to do better on the final. That was mean, I'm sorry. All right, speaking of means-- see? Professor Grimson not the only one who can make bad jokes. There is something-- it's not the gambler's fallacy-- that's often confused with it, and that's called regression to the mean. This term was coined in 1885 by Francis Galton in a paper, of which I've shown you a page from it here.","64.07682800292969","8","DPRSearchEngine","OgO1gpXSUzU.en-j3PyPqV-e1s_8_mp4","OgO1gpXSUzU.en-j3PyPqV-e1s","6.0002","6"
"137","How do you determine the optimal way to hit pins in this carnival bowling game to maximize the score given the possibility of negative values and pair combinations?","I would never show that to high school students, or GREs to you guys. But you can see that they are amazingly well-distributed along a normal distribution. On down here, this is plotting percent change in oil prices. And again, we see something very close to a normal distribution. And here is just looking at heights of men and women. And again, they clearly look very normal. So it's really quite impressive how often they occur. But not everything is normal. So we saw that the empirical rule works for normal distributions. I won't say I proved it for you. I illustrated it for you with a bunch of examples. But are the outcomes of the spins of a roulette wheel normal? No. They're totally uniform, right? Everything is equally probable-- a 4, a 6, an 11, a 13, double-0 if you're in Las Vegas. They're all equally probable. So if I plotted those, I'd basically just get a straight line with everything at 1 over however many pockets there are. So in that case, why does the empirical rule work? We saw that we were doing some estimates about returns and we used the empirical rule, we checked it and, by George, it was telling us the truth. And the reason is because we're not reasoning about a single spin of the wheel but about the mean of a set of spins. So if you think about it, what we were reasoning about was the return of betting. If we look at one spin-- well, let's say we bet $1. The return is either minus 1 because we've lost our dollar. Or if we get lucky and our pocket happens to come up, it was 36, I think, or 35. I forget which, OK? But that's all. So if we plotted a histogram, we would see a huge peak at minus 1 and a little bump here at 36 and nothing in the middle. Clearly, not a normal distribution. But what we're reasoning about is not the return of a single spin but the return of many spins. If we played 1,000 spins, what is our expected return? As soon as we end up reasoning, not about a single event but about the mean of something, we can imply something","63.90471649169922","9","DPRSearchEngine","rUxP7TM8-wo.en-qlPKC2UN_YU_6_mp4","rUxP7TM8-wo.en-qlPKC2UN_YU","6.0002","7"
"137","How do you determine the optimal way to hit pins in this carnival bowling game to maximize the score given the possibility of negative values and pair combinations?","But sometimes it's not enough. And we'll have to go to substrings. That won't be for another lecture or two. Today I claim that prefixes or suffixes are enough to solve the bowling problem. So what we're going to do is think about-- I prefer suffixes usually, because I like to work from left to right, from the beginning to the end. So we're going to think of a suffix of the bowling pins. And so what is the sub-problem on a suffix? Well, a natural version is just to solve the original problem, bowling. How do I maximize my score if all I were given were these pins? Suppose the pins to the left of i didn't exist. How would I maximize my score on the remaining pins? Or for this suffix, given these four pins, what would I do? And there's some weird sub problems here. If I just gave you the last pin, what would you do? Nothing. That's clearly different from what I would do globally here. But I claim if I can solve all suffixes I can solve my original problem, because one of the suffixes is the whole sequence. So let's do it. Sort by for bowling. So here is our dynamic program. The sub-problems are suffixes. So I'll write b of i is the maximum score we could get possible with our starting-- if we started a game with pins i, i plus 1, up to n minus 1, which is a suffix of the pins. Very important whenever you write a dynamic program to define what your sub-problems are. Don't just say how to compute them, but first say what is the goal of the sub problem. This is a common mistake to forget to state what you're trying to do. So now I have defined b of i. Now, what is the original thing I'm trying to solve? You also put in SRTBOT-- you could put the O earlier, then it actually spells sort. So why don't I do that for fun. The original problem we're trying to solve is b of 0, because that is all of the pins. The suffix starting at 0 is everything. So if we can solve that, we're done. Next is r for relate. This is the test of, did I get the sub-problems right, is whether I can write a recurrence relation. So let's try to do it. We want to compute b of i. So we have pin i here and then the remaining pins. And the big idea here is to just think about-- the nice thing about suffixes is if I take off something from the beginning, I still have a suffix. Remember, my goal is to take this sub-problem, which is suffix starting at i, and reduce it to a smaller sub problem, which means a smaller suffix. So I'd like to clip off one or two items here. And then the remaining problem will be one of my sub problems. I'll be able to recursively call b of something smaller than i-- or sorry, b of something larger than i will be a smaller subsequence because we're starting later. OK, so what could I do? Well, the idea is to just look at pin i and think, well, what could I do to pin i? I could not hit it ever with a ball. I could skip it. That's one option. What would be my score then? Well, if I skip pin i, that leaves the remaining pins, which is just a smaller suffix. So that is b of i plus 1. I'm going to write a max out here because I'd like to maximize my score. And one of the options is, forget about pin i. Just solve the rest. Another option is I throw a ball. And I exactly hit pin i. That's one thing I could do. And it would leave exactly the same remainder. So another option is b of i plus 1 plus vi. Why would I prefer this over this? Well, if vi is negative, I'd prefer this. But if vi is positive, I'd actually prefer this over that. So you can figure out which is better, just locally. But then there's another thing I can do, which is maybe I hit this pin in a pair with some other pin. Now, there's no pin to the left of this one. We're assuming we only have the suffix. And so the only other thing I can do is throw a ball and hit i together with i plus 1. And then I get the product. Now, what pins remain? i plus 2 on. Still a suffix. So if I remove one or two items, of course, I still get a suffix-- in this case, b of i plus 2-- and then the number of points that I add on are vi times vi plus 1. So this is a max of three things. So how long does it take me to compute it? I claim constant time. If I don't count the time it takes to compute these other sub problems, which are smaller because they are smaller suffixes further to the right, then I'm doing a couple of additions-- product, max. These are all nice numbers and I'll assume that they live in the w-bit word, because we're only doing constant sized products. That's good. So this takes constant, constant non-recursive work. How many sub problems are? Well, it's suffixes, so it's a linear number of sub problems. And so the time I'm going to end up needing is number of sub problems, n, times the non-recursive work I do per sub problem, which is constant. And so this is linear time. Great. And I didn't finish SRTBOT, so there's another t, which is to make sure that there is a topological order and that is in decreasing i order. Or I might write that as a for loop-- for i equals n, n minus 1. This is the order that I would compute my problems because the suffix starting at n is the empty suffix. The suffix starting at 0, that's the one I actually want to compute. That's the final suffix I should be computing. And then we have a b for base case, which is that first case, b of n equals 0, because there's no pins. So I don't get any points. Sad.","63.49589538574219","10","DPRSearchEngine","r4-cftqTcdI.en-j3PyPqV-e1s_12_mp4","r4-cftqTcdI.en-j3PyPqV-e1s","6.006","15"
"138","What is a binary heap and how does it simplify the priority queue operations compared to AVL trees?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","82.25732421875","1","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"138","What is a binary heap and how does it simplify the priority queue operations compared to AVL trees?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","78.93032836914062","2","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"138","What is a binary heap and how does it simplify the priority queue operations compared to AVL trees?","&

	
	
	/
def greedy(items, maxCost, keyFunction):
itemsCopy = sorted(items, key = keyFunction,
reverse = True)
result = []
totalValue, totalCost = 0.0, 0.0
for i in range(len(itemsCopy)):
if (totalCost+itemsCopy[i].getCost()) <= maxCost:
result.append(itemsCopy[i])
totalCost += itemsCopy[i].getCost()
totalValue += itemsCopy[i].getValue()
return (result, totalValue) 
	

2
	

","78.47383117675781","3","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_24_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"138","What is a binary heap and how does it simplify the priority queue operations compared to AVL trees?","They take linear time for some of the operations. So the sorting algorithms are not efficient. But they're ones we've seen before, so it's neat to see how they fit in here. They had the-- selection sort and insertion sort had the advantage that they were in place. You just needed a constant number of pointers or indices beyond the array itself. So they're very space efficient. So that was a plus for them. But they take n squared time, so you should never use them, except for n, at most, 100 or something. AVL tree sort is great and then it gets n log n time, probably more complicated than merge sort and you could stick to merge sort. But neither merge sort nor set AVL tree sort are in place. And so the goal of today is to get the best of all those worlds in sorting to get n log n comparisons, which is optimal in the comparison model, but get it to be in place. And that's what we're going to get with binary heaps. We're going to design a data structure that happens to build a little bit faster-- as I mentioned, linear time building. So it's not representing a sorted order in the same way that AVL trees are. But it will be kind of tree-based. It will also be array-based. We're going to get logarithmic time for insert and delete_max. It happens to be amortized, because we use arrays. But the key thing is that it's an in-place data structure. It only consists of an array of the items. And so, when we plug it into our sorting algorithm-- priority queue sort or generic sorting algorithm-- not only do we get n log n performance, but we also get an in-place sorting algorithm. This will be our first and only-- to this class-- n log n in-place sorting algorithm. Cool. That's the goal.","78.08737182617188","4","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_5_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"138","What is a binary heap and how does it simplify the priority queue operations compared to AVL trees?","2 
Lecture 8: Binary Heaps 
Priority Queue: Set AVL Tree 
• Set AVL trees support insert(x), find min(), find max(), delete min(), and 
delete max() in O(log n) time per operation 
• So priority queue sort runs in O(n log n) time 
– This is (essentially) AVL sort from Lecture 7 
• Can speed up find min() and find max() to O(1) time via subtree augmentation 
• But this data structure is complicated and resulting sort is not in-place 
• Is there a simpler data structure for just priority queue, and in-place O(n lg n) sort? 
YES, binary heap and heap sort 
• Essentially implement a Set data structure on top of a Sequence data structure (array), using 
what we learned about binary trees 
Priority Queue: Array 
• Store elements in an unordered dynamic array 
• insert(x): append x to end in amortized O(1) time 
• delete max(): ﬁnd max in O(n), swap max to the end and remove 
• insert is quick, but delete max is slow 
• Priority queue sort is selection sort! (plus some copying) 
Priority Queue: Sorted Array 
• Store elements in a sorted dynamic array 
• insert(x): append x to end, swap down to sorted position in O(n) time 
• delete max(): delete from end in O(1) amortized 
• delete max is quick, but insert is slow 
• Priority queue sort is insertion sort! (plus some copying) 
• Can we ﬁnd a compromise between these two array priority queue extremes? 
","77.26213073730469","5","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_2_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"138","What is a binary heap and how does it simplify the priority queue operations compared to AVL trees?","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","76.830810546875","6","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"138","What is a binary heap and how does it simplify the priority queue operations compared to AVL trees?"," 
 
 
 
 
 
   
  
 
  
 
 
   
 
 
  
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
  
 
 
 
 
 
 
Check-in 8.2 
Recall the Queue Automaton (QA) defined in Pset 2. 
It is similar to a PDA except that it is deterministic 
and it has a queue instead of a stack. 
Let !QA = { &, ( | & is a QA and & accepts (} 
Is !QA decidable? 
(a) Yes, because QA are similar to PDA and !PDA is decidable. 
(b) No, because “yes” would contradict results we now know. 
(c) We don’t have enough information to answer this question. 
8 
Check-in 8.2 
","76.59796905517578","7","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_8_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"138","What is a binary heap and how does it simplify the priority queue operations compared to AVL trees?","Header for Decision Tree Implementa#on 
6.0002 LECTURE 2 
9 
def maxVal(toConsider, avail): 
    """"""Assumes toConsider a list of items,  
               avail a weight 
       Returns a tuple of the total value of a  
           solution to 0/1 knapsack problem and  
           the items of that solution""""” 
toConsider. Those items that nodes higher up in the tree 
(corresponding to earlier calls in the recursive call stack) 
have not yet considered 
 
avail. The amount of space still available  
","76.55278015136719","8","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_9_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"138","What is a binary heap and how does it simplify the priority queue operations compared to AVL trees?","4 
Lecture 1: Introduction 
1 
def birthday_match(students): 
2 
’’’ 
3 
Find a pair of students with the same birthday 
4 
Input: 
tuple of student (name, bday) tuples 
5 
Output: tuple of student names or None 
6 
’’’ 
7 
n = len(students) 
# O(1) 
8 
record = StaticArray(n) 
# O(n) 
9 
for k in range(n): 
# n 
10 
(name1, bday1) = students[k] 
# O(1) 
11 
# Return pair if bday1 in record 
12 
for i in range(k): 
# k 
13 
(name2, bday2) = record.get_at(i) 
# O(1) 
14 
if bday1 == bday2: 
# O(1) 
15 
return (name1, name2) 
# O(1) 
16 
record.set_at(k, (name1, bday1)) 
# O(1) 
17 
return None 
# O(1) 
Example: Running Time Analysis 
• Two loops: outer k ∈{0, . . . , n − 1}, inner is i ∈{0, . . . , k}
P n−1
• Running time is O(n) + 
k=0 (O(1) + k · O(1)) = O(n2) 
• Quadratic in n is polynomial. Efﬁcient? Use different data structure for record! 
How to Solve an Algorithms Problem 
1. Reduce to a problem you already know (use data structure or algorithm) 
Search Problem (Data Structures) 
Sort Algorithms 
Static Array (L01) 
Insertion Sort (L03) 
Linked List (L02) 
Selection Sort (L03) 
Dynamic Array (L02) 
Merge Sort (L03) 
Sorted Array (L03) 
Counting Sort (L05) 
Direct-Access Array (L04) 
Radix Sort (L05) 
Hash Table (L04) 
AVL Sort (L07) 
Balanced Binary Tree (L06-L07) 
Heap Sort (L08) 
Binary Heap (L08) 
2. Design your own (recursive) algorithm 
• Brute Force 
• Decrease and Conquer 
• Divide and Conquer 
• Dynamic Programming (L15-L19) 
• Greedy / Incremental 
Shortest Path Algorithms 
Breadth First Search (L09) 
DAG Relaxation (L11) 
Depth First Search (L10) 
Topological Sort (L10) 
Bellman-Ford (L12) 
Dijkstra (L13) 
Johnson (L14) 
Floyd-Warshall (L18) 
","75.81196594238281","9","DPRSearchEngine","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_4_pdf","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1","6.006","1"
"138","What is a binary heap and how does it simplify the priority queue operations compared to AVL trees?","If you think about it a little bit, this is exactly binary search on an array. It just happens to be on a tree instead. If you think of an array like this, what does binary search do? It first looks at the key in the middle. I'm going to draw that as the root. And then, it recurses either on the left chunk, which I will draw recursively, or on the right chunk. And so if you happen to have a perfect binary tree like this one, it is simulating exactly binary search in this array. But this we're going to be able to maintain dynamically-- not perfect any more, but close. Whereas this we could not maintain in sorted order. So this is like a generalization of binary search to work on trees instead of on arrays. And for this reason, set binary trees are called binary search trees, because they're the tree version of binary search. So there's many equivalent names. So binary search tree is another name for set binary tree. And the key thing that makes this algorithm work is the so-called binary search tree property, which is all the keys in the left subtree of a node are less than the root, or of that node, and that key is less than all the keys in the right subtree. And this is true recursively all the way down. And so that's how you prove that this algorithm is correct by this property. Why is this true? Because if we can maintain traversal order to be increasing key, then that's exactly what traversal order means. It tells you all the things in the left subtree come before the root, which come before all the things in the right subtree.","75.72371673583984","10","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_4_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"139","What is merge sort?","They take linear time for some of the operations. So the sorting algorithms are not efficient. But they're ones we've seen before, so it's neat to see how they fit in here. They had the-- selection sort and insertion sort had the advantage that they were in place. You just needed a constant number of pointers or indices beyond the array itself. So they're very space efficient. So that was a plus for them. But they take n squared time, so you should never use them, except for n, at most, 100 or something. AVL tree sort is great and then it gets n log n time, probably more complicated than merge sort and you could stick to merge sort. But neither merge sort nor set AVL tree sort are in place. And so the goal of today is to get the best of all those worlds in sorting to get n log n comparisons, which is optimal in the comparison model, but get it to be in place. And that's what we're going to get with binary heaps. We're going to design a data structure that happens to build a little bit faster-- as I mentioned, linear time building. So it's not representing a sorted order in the same way that AVL trees are. But it will be kind of tree-based. It will also be array-based. We're going to get logarithmic time for insert and delete_max. It happens to be amortized, because we use arrays. But the key thing is that it's an in-place data structure. It only consists of an array of the items. And so, when we plug it into our sorting algorithm-- priority queue sort or generic sorting algorithm-- not only do we get n log n performance, but we also get an in-place sorting algorithm. This will be our first and only-- to this class-- n log n in-place sorting algorithm. Cool. That's the goal.","71.37750244140625","1","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_5_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"139","What is merge sort?","which is merge sort, so a divide and conquer algorithm, phrased with this structure of SRTBOT. So for the sub problems-- so our original problem is to sort the elements of A. And some sub-problems that we solve along the way are sorting different sub-arrays of A. So for every-- well, not for every i and j, but for some i and js, we sort the items from i up to j minus 1. So I'm going to define that subproblem to be s of ij. So this is something that I might want to solve. The original problem that I want to solve is s of 0 comma n, where n is the length of the array. So that's what I actually care about in the end. But we're going to solve that by writing it recursively in terms of sorting different sub-arrays as follows. This is the recurrence relation. I've written it very simply here. Of course, there's a merge algorithm, which is somewhat complicated. But as we saw the two finger linear time merge algorithm, given two sorted arrays-- so this is supposed to be the sorted array version of the items i through m. m is the middle element between i and j and the sorted array of the items from m up to j. If we merge those, that gives us the sorted array from i up to j. And that's exactly what merge sort does. So in general, this relation is just some algorithm for if you're given the solutions to some smaller subproblems, how do I solve the subproblem that I want to solve? And so we need to make sure that this problem is bigger than the ones that we recursively call on and that we don't get an infinite cyclic loop of recursions. And here our valid topological order is to say, solve these problems in order where j minus i-- the length of the sub-array-- is increasing. And then you can check because m is strictly between i and j. As long as we're not in a base case, then we know we can-- these subarrays will be smaller than this one. And so this increasing order gives us a valid topological order on all of the problems, all the subproblems. We have a base case, which is if we don't want to sort anything, that's the empty array, or at least in the original problem. And then running time is-- I mean, there's no better way to solve it than the recurrence that we already saw how to solve. So this is just another way to think of n log n","71.3629379272461","2","DPRSearchEngine","r4-cftqTcdI.en-j3PyPqV-e1s_3_mp4","r4-cftqTcdI.en-j3PyPqV-e1s","6.006","15"
"139","What is merge sort?","Now, our implementation of merge-- well, we can also do this in a recursive fashion. But personally, I find this a little complicated. I'm going to admit. But here's the basic idea here, which I'm now rushing. So I'm going to think of my upper finger as finger i and my lower finger as finger j. Does that makes sense? So I have two sorted lists. So maybe like that. I don't know, 1, 3, 5, 7. And then I have a second sorted list here, which is maybe 2, 4, 6, 72, as one does. Then I'm going to have one pointer like this, which is i, and a pointer down here, which is j. And my goal is to construct an array A with a bunch of elements in it. And the way that I'm going to do it is I'm going to use exactly the same kind of recursive argument, that I can either have the biggest element of my be the last element of the first guy or be the last element of the second one. So here's going to be our recursive call. And in addition to that, for convenience, we'll have a third index, which is B, which is pointing to this thing inside of my sorted array that I'm currently processing Yeah? It's going to start at A, go to B. Incidentally, I see a lot of people taking photos of the slides. These are just copy pasted from the notes. OK. So in this case, what should I put in B for my two arrays? I have 1, 3, 5, 7; 2, 4, 6, 72. 72, yeah? Great. So now, what am I going to do? I'm just going to call the merge function. But I'm going to decrement B because now I'm happy with that last element. And in addition to that, I'm going to decrement j because I already used it up. And so that's our recursive call here. It's saying, if j is less than or equal to 0-- so in other words, I have an element to use in one of the lists of the other. And maybe the left one is bigger than the right one. That's our first case. That does not apply in this example here. Well, then I should make the last element of a from the first list and then recurse with one fewer element i, and similarly","70.03677368164062","3","DPRSearchEngine","oS9aPzUNG-s.en-j3PyPqV-e1s_21_mp4","oS9aPzUNG-s.en-j3PyPqV-e1s","6.006","3"
"139","What is merge sort?","5 
Lecture 3: Sorting 
Merge Sort 
• Recursively sort ﬁrst half and second half (may assume power of two) 
• Merge sorted halves into one sorted list (two ﬁnger algorithm) 
• Example: [7, 1, 5, 6, 2, 4, 9, 3], [1, 7, 5, 6, 2, 4, 3, 9], [1, 5, 6, 7, 2, 3, 4, 9], [1, 2, 3, 4, 5, 6, 7, 9] 
1 
def merge_sort(A, a = 0, b = None): 
# T(b - a = n) 
2 
’’’Sort A[a:b]’’’ 
3 
if b is None: b = len(A) 
# O(1) 
4 
if 1 < b - a: 
# O(1) 
5 
c = (a + b + 1) // 2 
# O(1) 
6 
merge_sort(A, a, c) 
# T(n / 2) 
7 
merge_sort(A, c, b) 
# T(n / 2) 
8 
L, R = A[a:c], A[c:b] 
# O(n) 
9 
merge(L, R, A, len(L), len(R), a, b) 
# S(n) 
10 
11 
def merge(L, R, A, i, j, a, b): 
# S(b - a = n) 
12 
’’’Merge sorted L[:i] and R[:j] into A[a:b]’’’ 
13 
if a < b: 
# O(1) 
14 
if (j <= 0) or (i > 0 and L[i - 1] > R[j - 1]): # O(1) 
15 
A[b - 1] = L[i - 1] 
# O(1) 
16 
i = i - 1 
# O(1) 
17 
else: 
# O(1) 
18 
A[b - 1] = R[j - 1] 
# O(1) 
19 
j = j - 1 
# O(1) 
20 
merge(L, R, A, i, j, a, b - 1) 
# S(n - 1) 
• merge analysis: 
– Base case: for n = 0, arrays are empty, so vacuously correct 
– Induction: assume correct for n, item in A[r] must be a largest number from remaining 
preﬁxes of L and R, and since they are sorted, taking largest of last items sufﬁces; 
remainder is merged by induction 
– S(0) = Θ(1), S(n) = S(n − 1) + Θ(1) =⇒ S(n) = Θ(n) 
• merge sort analysis: 
– Base case: for n = 1, array has one element so is sorted 
– Induction: assume correct for k < n, algorithm sorts smaller halves by induction, and 
then merge merges into a sorted array as proved above. 
– T (1) = Θ(1), T (n) = 2T (n/2) + Θ(n) 
∗ Substitution: Guess T (n) = Θ(n log n) 
cn log n = Θ(n) + 2c(n/2) log(n/2) =⇒ cn log(2) = Θ(n) 
∗ Recurrence Tree: complete binary tree with depth log2 n and n leaves, level i has 2i 
Plog2 n 
Plog2 n
nodes with O(n/2i) work each, total: 
i=0 (2i)(n/2i) = 
i=0 n = Θ(n log n) 
","70.00469970703125","4","DPRSearchEngine","6d1ae5278d02bbecb5c4428928b24194_MIT6_006S20_lec3_5_pdf","6d1ae5278d02bbecb5c4428928b24194_MIT6_006S20_lec3","6.006","3"
"139","What is merge sort?","And instead, we should jump to an algorithm that actually matters, which is something called merge sort. How many of us have encountered merge sort before? Fabulous. Good. So then I'm done. So let's say that I have a list. Now, I'm sending a message back to Jason. I made this one up last night. So I have 7, 1, 5, 6, 2, 4, 9, 3. This is not in sorted order. But I can make a very deep observation, which is that every number by itself is in sorted order if I think of it as an array of length 1. It's really deep, like deep learning deep. So now, what can I do? Well, I could take every pair of numbers, draw a little red box. Well, now, they're not in sorted order any more inside of the red boxes. So I'm going to sort inside of every box. In this case, it's not too exciting because it's just pairs. And now, they're in sorted order because they said they were. Now, I'm going to keep doubling the size of my boxes. So now, let's say I have box of length 4. What do I know about the left and right-hand sides of the dotted lines here? On the two sides of the dotted lines, the array is in sorted order. There's a 1 and then a 7. Those are in sorted order, 5 and a 6. That's because, in the previous step, I sorted every pair. So when I merge these two sides together, I have an additional useful piece of information, namely that the two sides of the dotted line are already in sorted order. That's going to be our basic inductive step here. So in this case, I merge the two sides. I get 1, 5, 6, 7, and 2, 3, 4, 9. Then finally, I put these two things together. And I have to sort these two. I have to merge these two sorted lists. But they're in sorted order. And that's going to give me a big advantage because-- oops, I lost my chalk. I suppose I've got space on this board here. Oh no. So if I want to merge 1, 5, 6, 7 and 2, 3, 4, 9, there's a nice, clever technique that we can do that's going to take just linear time. Jason tells me it's the two finger algorithm. I think that's a cute analogy here. So here are my two fingers. They're going to point at the end of the list. And I'm going to construct the merged array backwards. So how many elements are in my merged array, if I'm merging two things of length 4? I don't ask you guys hard questions. It's 8, yeah? 4 plus 4. 8, yeah? So what do I know? I know that my merge array-- 5, 6, 7-- has eight elements. And now, I'm going to have two fingers at the end of my array. Which one should I put at the end of the merged guy? The 7 of the 9? AUDIENCE: The 9 JUSTIN: The 9. Right, thank you. So now, I can move my lower finger to the left because I've already added that. Notice that I never need to look to the left of where my finger is because they're already in sorted order. Now what should I add, the 4 or the 7? AUDIENCE: 7. JUSTIN: The 7. And so on, dot, dot, dot, yeah? So that's going to be the basic idea of the merge sort. I'm going to take two sorted lists. And I'm going to make a new sorted list, which is twice as long, by using two fingers and moving from the and backward. So that's the basic intuition here. Indeed, there's our sorted list. It's stressing me out that there's no eight. I need the power of 2. So I think merge sort, we're going to present it in a backward way from the previous one, where I'm going to give you the high level algorithm. And then actually, the headache is that merging step, which I have four minutes for. And I apologize for it. So what does the merger sort do? Well, it computes an index c, which is the middle of my array. And it's going to make a recursive call which is sort the left, which is everything between index A and index C. And then sort everything on the right, which is everything from index C to index B. I know this is confusing because usually letters appear in order. But C, if you think of as standing for center, then it makes sense like. Here's my array. I'm going to choose an index right in the middle. I've done myself a disservice by not using a power of 2. But that's OK. I'm going to say sort everything to the left of the dotted line first. Sort everything to the right of the dotted line second. Now, I have two sorted lists on the two sides of the dotted line. And then I'm going to use my two fingers to put them together. So that's what this is implementing here. See, there's two recursive calls-- sort from A to C, and then sort from C to B. Oops, I didn't actually label this. So this is A, C, B. And then I've got to call merge.","69.84609985351562","5","DPRSearchEngine","oS9aPzUNG-s.en-j3PyPqV-e1s_20_mp4","oS9aPzUNG-s.en-j3PyPqV-e1s","6.006","3"
"139","What is merge sort?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","68.8487548828125","6","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"139","What is merge sort?","It's basically-- it's a set type thing, where I can make a set of just a single element, I can take two sets, merge them together, make them their union, and then given an object, I say, which set am I part of, essentially by electing a leader within a set and saying, return me a pointer to that one. And so this can be useful in dynamically maintaining, say, the connected components in a dynamically changing graph supporting the query of, am I in the same component as this other guy? That could be a very useful thing to know about a graph as it's changing. So that's an application of this problem. And they get near-constant performance for a lot of these queries. It's not quite, but pretty close. OK, on the graph side, they solve","68.51341247558594","7","DPRSearchEngine","2NMtS1ecb3o.en-j3PyPqV-e1s_6_mp4","2NMtS1ecb3o.en-j3PyPqV-e1s","6.006","20"
"139","What is merge sort?","&

	
	
	/
def greedy(items, maxCost, keyFunction):
itemsCopy = sorted(items, key = keyFunction,
reverse = True)
result = []
totalValue, totalCost = 0.0, 0.0
for i in range(len(itemsCopy)):
if (totalCost+itemsCopy[i].getCost()) <= maxCost:
result.append(itemsCopy[i])
totalCost += itemsCopy[i].getCost()
totalValue += itemsCopy[i].getValue()
return (result, totalValue) 
	

2
	

","67.40626525878906","8","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_24_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"139","What is merge sort?","found by combining optimal solutions to local subproblems. So for example, when x is greater than 1 we can solve fib x by solving fib x minus 1 and fib x minus 2 and adding those two things together. So there is optimal substructure-- you solve these two smaller problems independently of each other and then combine the solutions in a fast way. You also have to have something called overlapping subproblems. This is why the memo worked. Finding an optimal solution has to involve solving the same problem multiple times. Even if you have optimal substructure, if you don't see the same problem more than once-- creating a memo. Well, it'll work, you can still create the memo. You'll just never find anything in it when you look things up because you're solving each problem once. So you have to be solving the same problem multiple times and you have to be able to solve it by combining solutions to smaller problems. Now, we've seen things with optimal substructure before. In some sense, merge sort worked that way-- we were combining separate problems. Did merge sort have overlapping subproblems? No, because-- well, I guess, it might have if the list had the same element many, many times. But we would expect, mostly not. Because each time we're solving a different problem, because we have different lists that we're now sorting and merging. So it has half of it but not the other. Dynamic programming will not help us for sorting, cannot be used to improve merge sort. Oh, well, nothing is a silver bullet. What about the knapsack problem? Does it have these two properties? We can look at it in terms of these pictures. And it's pretty clear that it does have optimal substructure because we're taking the left branch and the right branch and choosing the winner. But what about overlapping subproblems? Are we ever solving, in this case, the same problem-- add two nodes? Well, do any of these nodes look identical? In this case, no. We could write a dynamic programming solution to the knapsack problem-- and we will-- and run it on this example, and we'd get the right answer. We would get zero speedup. Because at each node, if you can see, the problems are different. We have different things in the knapsack or different things to consider. Never do we have the same contents and the same things left to decide. So ""maybe"" was not a bad answer if that was the answer you gave to this question. But let's look at a different menu. This menu happens to have two beers in it. Now, if we look at what happens, do we see two nodes that are solving the same problem? The answer is what? Yes or no? I haven't drawn the whole tree here. Well, you'll notice the answer is yes.","67.34580993652344","9","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_11_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"139","What is merge sort?","OK. So let's fill in some more interesting algorithms. As usual, I'm talking too much. And I'm nervous about the time. But we can skip one of them if we need to. So how many of us have seen selection sort before? I see your hand. But we're going to defer for a little bit. I'm sorry? AUDIENCE: [INAUDIBLE] JUSTIN: That's fabulous. Why don't we defer to the end of lecture? And we'll do it then. OK. So the first algorithm that we'll talk about for sorting, which is somewhat sensible, is something called selection sort. Selection sort is exactly what it sounds like. So let's say that we have a list of-- whoops, my laptop and the screen are not agreeing. OK. Let's say I have a list of numbers-- 8, 2, 4, 9, 3. There's a message that Jason I think is sending me in the course notes. But I haven't figured it out. But in any event, I want to sort this list of numbers. Here's a simple algorithm for how to do it, which is I can find the biggest number in this whole list and stick it at the end. So in this case, what's the biggest number in this list everybody? 9. Good. See, this is why you go to MIT. So I'm going to take that 9. I find it. And then swap it out with the 3, which is at the end. And now, what's my inductive hypothesis? Well, in some sense, it's that everything to the right of this little red line that I've drawn here is in sorted order, in this case because there's only one thing. So now, what am I going to do? I'm going to look to the left of the red line, find the next biggest thing. What's that? Come on. AUDIENCE: 8. JUSTIN: There we go. Yeah, wake up. OK. So right, the next biggest one is the 8. So we're going to swap it with the 3, put it at the end, and so on. I think you guys could all finish this off. I suppose there should be one last line here where everything is green and we're happy. But in some sense, we're pretty sure that an array of one item is in sorted order. And so essentially, from a high level, what does selection sort do? Well, it just kept choosing the element which was the biggest and swapping it into the back and then iterating. Now, in 6.006, we're going to write selection sort in a way that you might not be familiar with. In some sense, this is not so hard to implement with two for loops. I think you guys could all do this at home. In fact, you may have already. But in this class, because we're concerned with proving correctness, proving efficiency, all that good stuff, we're going to write it in kind of a funny way, which is recursive. Now, I can't emphasize strongly enough how little you guys should implement this at home. This is mostly a theoretical version of selection sort rather than one that you would actually want to write in code because there's obviously a much better way to do it. And you'll see that in your recitation this week, I believe. But in terms of analysis, there's a nice, easy way to write it down. So we're going to take the selection sort algorithm. And we're going to divide it into two chunks. One of them is find me the biggest thing in the first k elements of my array. I shouldn't use k because that means key. The first i elements of my array. And the next one is to swap it into place and then sort everything to the left. That's the two pieces here. So let's write that down. So what did I do? Well, in some sense, in step 1 here, I found the biggest with index less than or equal to i. So I started at the end of the list, and then moved backward. And then step 2 was to swap that into place. Notice when I say swap-- so for instance, when I put the 8 there, well, I had to do something with that 3. So I just put it where the 8 used to be. And then finally, well, am I done? No, I just put the biggest thing at the end of my array. So now, I have to sort from index 1 to i minus 1 because now I know that the last guy is in sorted order. I see you. I'll turn it over to you in just a sec. Yes? AUDIENCE: [INAUDIBLE] JUSTIN: You can't read the handwriting? AUDIENCE: [INAUDIBLE] JUSTIN: This is index less than or equal to i. Great question. I warned you. It's going to be a problem. So let's do step 1 first. So I'm going to put code on the board. And then we're going to fill in the details. Erik is posting on Facebook. I'm going to turn that feature off on my watch later. So right, let's implement this helper function here. This is something we're going to call prefix max. And this is going to find me the biggest element of array between index 0 and index i inclusive, I believe. Yeah? AUDIENCE: [INAUDIBLE] JUSTIN: Well, here's an interesting observation, really a deep one, which is that the biggest element from 0 to i-- that's an i, sorry. There's two cases. Either it's at index i, meaning I have the first 10 elements of my right-- either it is element number 10 or what's the other case? It ain't, Yeah? In other words, it has index less than i. This is a tautology, rate? Either the biggest thing is at this index or it's not. In which case, it has to be to the left. Does that makes sense? So this gives us a really simple algorithm for finding the biggest element in the array between index 0 and index i, which is what I've shown you on the screen here. I'd write it on the board. But I am a slow writer and already low on time. And so essentially, what did I implement? Well, I found the biggest element between index 0 and index i minus 1. So let's say that I have an array-- I forget the sequence of numbers-- 8, 3, 5, 7, 9. That'll do it. And so like I give a pointer here, which is i. And the very first thing that I do is I compute the biggest number all the way to the left of this stuff. In this case, that is? AUDIENCE: 8. JUSTIN: 8. There we go. Now, I look at the very last element of my array, which is-- 9. You're killing me today, guys. And then what do I return? Well, I want the biggest one between 0 and index i. So in this case, I return the 9.","66.91644287109375","10","DPRSearchEngine","oS9aPzUNG-s.en-j3PyPqV-e1s_16_mp4","oS9aPzUNG-s.en-j3PyPqV-e1s","6.006","3"
"140","What is a Directed Acyclic Graph (DAG) and why is it significant?","And that's cycle detection. So there's a bit of an exercise left to the reader here. So the problem that we're looking for now is that we're given a directed graph. There's a G in graph, in case you're wondering. But now, we don't know if it's a DAG or not. And so the question that we're trying to ask is, does there exist a cycle in our directed acyclic graph? So we're just given our graph, and we want to know, can we do this? Let's think through the logic of this a bit. So what do we know? We know that if our graph were a DAG, then I could call DGS, get the ordering out, and then I guess flip its ordering backwards. So I could compute the reverse finishing order. And it would give me a topological order of my graph. So if I were a DAG, I would get a topological order when I call DFS. So let's say that I ran DFS. I got whatever ordering I got. And now I found an edge the points in the wrong direction. I can just double check my list of edges, and I find one that does not respect the relationship that I see in the second bullet point here. Can my graph be a DAG? No. Because if my graph were a DAG, the algorithm would work. I just proved it to you. Right? So if my graph were a DAG, then I could do reverse finishing order. And what I would get back is a topological order. So if I found a certificate that my order wasn't topological, something went wrong, and the only thing that could go wrong is that my graph isn't a DAG. Yeah. Isn't a DAG. In fact, sort of an exercise left to the reader and/or to your section-- do we still have section? I think we do, as of now-- is that this is an if and only if, meaning that the only time that you even have a topological ordering in your graph is if your graph is a DAG. This is a really easy fact to sanity check, by the way. This is not like, a particularly challenging problem. But you should think through it because it's a good exercise to make sure you understand the definitions, which is to say that if you have a topological order, your graph is a DAG. If you don't have a topological order, your graph isn't a DAG. So in other words, we secretly gave you an algorithm for checking if a graph is a DAG at all. Right? What could I do? I could compute reverse finishing order. Check if it obeys the relationship on the second bullet point here for every edge. And if it does, then we're in good shape. My graph is a DAG. If it doesn't, something went wrong. And the only thing that could have gone wrong is not being a DAG. OK. So in other words, secretly we just solved-- well, I guess the way that I've written it here, we've solved the cycle detection problem here, which is to say that, well, I have a cycle if and only if I'm not a DAG, which I can check using this technique. Of course, the word ""detection"" here probably means that I actually want to find that cycle, and I haven't told you how to do that yet. All we know how to do so far is say, like, somewhere in this graph there's a cycle. And that's not so good. So we can do one additional piece of information in the two minutes we have remaining to sort of complete our story here, which is to modify our algorithm ever so slightly to not only say thumbs up, thumbs down, is there a cycle in this graph, but also to actually return the vertices as a cycle. And here's the property that we're going to do that, which is following, which is that if G contains a cycle, right, then full DFS will traverse an edge from a vertex v to some ancestor of v. I guess we haven't carefully defined the term ""ancestor"" here. Essentially, if you think of the sort of the running of the DFS algorithm, then an ancestor is like something that appears in the recursive call tree before I got to v. OK. So how could we prove that? Well, let's take a cycle. And we'll give it a name. In particular, we'll say that it's a cycle from v0 v1 to vk. And then it's a cycle, so it goes back to v0. OK. And I can order this cycle any way I want. Notice that if I permute the vertices in this list in a cyclical way, meaning that I take the last few of them and stick them at the beginning of the list, it's still a cycle. That's the nice thing about cycles. So in particular, without loss of generality, we're going to assume that v0 is the first vertex visited by DFS. What does that mean? That means, like, when I do my DFS algorithm making all these recursive calls, the very first vertex to be touched by this technique is v0. OK. Well, now what's going to end up happening? Well, think about the recursive call tree starting at v0. By the time that completes, anything that's reachable from v0 is also going to be complete. Do you see that? So for instance, v0 somewhere in its call tree might call v2. And notice that v2 was not already visited. So in fact, it will. For v1 I got to call v2 and so on. And in particular, we're going to get all the way to vertex k. Right? So in other words, we're going to visit a vertex vk. And notice what's going to happen. So remember our algorithm. In fact, we should probably just put it up on the screen would be easier than talking about it a bunch. Well, vk is now going to iterate over every one of the neighbors of vk. And in particular, it's going to see vertex v0. Right? So we're going to see the edge from vk to v0, which is an edge kind of by definition because we took this to be a cycle here. But notice that's exactly the thing we set out to prove, namely that full DFS traverses an edge from a vertex to one of its ancestors. Here's a vertex k. Here's the ancestor v0. Why do we know that it's an ancestor? Well, because v0 was called in our call tree before any of these other guys. Right? So we wanted an algorithm that not only did cycle detection, but also actually gave me the cycle. What could I do? Well, it's essentially a small modification of what we already have. Right. So-- whoops. Right. If I want to compute topological order or whatever, I can just do DFS. And that'll tell me like, yay or nay, does there exist a cycle. If I want to actually find that cycle, all I have to do is check that topological order property at the same time that it traversed the graph during DFS. And the second that I find an edge that loops back, I'm done. And so that's our basic algorithm here. And this is a technique for actually just finding the cycle in a graph using the DFS algorithm.","72.57182312011719","1","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_20_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"140","What is a Directed Acyclic Graph (DAG) and why is it significant?","that we've already seen in 6006? AUDIENCE: A tree. JUSTIN SOLOMON: A tree. At least if we orient all all the edges kind of pointing downward in the tree. Yeah. Otherwise, it gets kind of debatable over whether it's a DAG or not. If there's no direction to the edges, then somehow the definition just doesn't apply. OK. So in processing directed acyclic graphs, there's a really useful thing that you can do that's going to show up in this class apparently quite a bit, which is kind of interesting to me, I'm curious to see what that looks like, which is to compute a topological order on the graph. We're at topologies here.","72.01283264160156","2","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_16_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"140","What is a Directed Acyclic Graph (DAG) and why is it significant?","Longest path is maybe a problem we've talked about in problem session, because it's a DAG-- well, longest path is the same thing as shortest path, if you just negate all the weights. There are no weights in this picture, so if you just put negative 1 on all these edges and ask for the shortest path from the base to anywhere-- so single source shortest paths from this base-- then we would end up getting this path, which, if you look at it, is E-M-P-T-Y, empty. And so that shortest path is indeed the right answer. What I've drawn here is the shortest path tree. So also, if you wanted the longest increasing subsequence starting at A, then it is A-T-Y, just by following the red arrows here. And how do you get that? You just draw the parent pointers, just like we did before.","71.412109375","3","DPRSearchEngine","KLBCUx1is2c.en-j3PyPqV-e1s_8_mp4","KLBCUx1is2c.en-j3PyPqV-e1s","6.006","16"
"140","What is a Directed Acyclic Graph (DAG) and why is it significant?","the runtime of this full DFS algorithm is v plus e time because every edge is touched no more than one time. Kind of amortized over all the different calls to DGS here. And there's this for loop over vertices. So there's clearly an order v that you need here. Does that argument make sense? So again, we call that linear in the size of the input. I'm going to say it as many times to get it in my own head correctly. OK. Right. So this is the basic problem. This comes up all the time, by the way. Like, it seems like somehow a totally brain dead weird algorithm. Like, somehow, why would you want an algorithm that finds connected components. Like, why would you even have a graph that's disconnected or something? But of course, that can happen a lot. So for instance, maybe you work at a social media company, and people have friends. But like, Eric and I are friends. And we're not friends with anybody else. We have a-- there's like, a blood oath kind of thing. Then that might be not so easy to find in the graph because, of course, we're just two among a sea of students in this classroom, all of which have different interconnections that are just enumerated based on the list of edges. And so even though like, pictorially, it's kind of hard to draw a connecting component algorithm in a way that doesn't make it sound kind of like a useless technique from the start, because it's very clear there are two connected components there. Of course, we still have to be able to write code to solve this sort of thing. OK. So for once, I think I'm almost on time in lecture today. So we have one additional application of depth-first search in our class today, which is sort of on the opposite end of the spectrum. So we just talked about graphs that are undirected and thinking about cycles. Now, on the opposite end we might think of a DAG. So a DAG is a Directed Acyclic Graph. Can anyone think of a special case of a DAG? I suppose I should define it first. And then we'll come back to that question, which means exactly what it sounds like. So it's a graph that has directed edges now and doesn't have any cycles in it. So actually, the graph I gave you all the way at the beginning of lecture I think secretly was an example of one of these. So let's say that I have directed edges. Maybe if I make the head a triangle, it's a little easier to see. I'm not so sure. In any event, so I'm going to have an edge up and an edge to the right, and similarly, an edge down and an edge to the right. This graph looks like a cycle. But it's not because the only direction that I can move is from the left-hand side to the right-hand side. So this is a directed graph. And it doesn't contain any cycles, meaning there's no path that it can take from a vertex that gets back to itself along the directed edges. OK. And DAGs show up all the time. Now that I've defined what a DAG is,","70.59625244140625","4","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_15_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"140","What is a Directed Acyclic Graph (DAG) and why is it significant?","in a DAG in linear time? Well, a DAG-- I mean, this is actually a super useful, convenient thing in algorithms in general. DAGs are just nice things. They're kind of ordered in a way. There's this topological sort order that we were talking about before. This is going to play a key role. There's a really nice structure to DAGs not having cycles, not having to deal with this negative weight cycle problem. You can only go in one direction along this graph. It's a very nice structure to exploit. And so we're going to exploit it. And here's the idea. DAG relaxation, what it's going to do is it's going to start out with some estimates of what these distances should be. So maintain distance estimates. And now I'm going to try to be careful here about how I draw my Ds. This is a d, this is a delta. This is shortest paths. This is a distance estimate. So that's what I'm going to be using for the rest of this time. So we're going to maintain these estimates of distance d, which are going to start at initially infinite. I don't know what they are. I don't know what the shortest paths are, but they better be less than infinite or else I don't care. So that's the worst case scenario. It can't be worse than this-- for every vertex. And we're going to maintain the property that estimates upper bound-- that should probably be two words-- upper bound delta s, v-- we're going to maintain that they upper-bound this thing and gradually lower until they're equal. So this is the idea. We start from an over-estimate, an upper bound on the distance estimate. And then we're repeatedly going to lower that value as we gain more information about the graph, maintaining that we're always upper-bounding the distance. And we're going to keep doing it, keep doing it, keep doing it, until, as we will try to prove to you, these estimates reach, actually reach down, all the way to our shortest path distances. So when do we lower these things? When do we lower these things? We are going to lower these distance estimates whenever","70.58018493652344","5","DPRSearchEngine","5cF5Bgv59Sc.en-j3PyPqV-e1s_8_mp4","5cF5Bgv59Sc.en-j3PyPqV-e1s","6.006","11"
"140","What is a Directed Acyclic Graph (DAG) and why is it significant?","Any questions about this or about machine learning in general? If so, this would be a good time to ask them, since I'm about to totally change the topic. Yes? AUDIENCE: At what level does AUROC start to be statistically significant? And how many data points do you need to also prove that [INAUDIBLE]? JOHN GUTTAG: Right. So the question is, at what point does the AUROC become statistically significant? And that is, essentially, an unanswerable question. Whoops, relay it back. Needed to put more air under the throw. I look like the quarterback for the Rams, if you saw them play lately. So if you ask this question about significance, it will depend upon a number of things. So you're always asking, is it significantly better than x? And so the question is, is it significantly better than random? And you can't just say, for example, that 0.6 isn't and 0.7 is. Because it depends how many points you have. If you have a lot of points, it could be only a tiny bit better than 0.5 and still be statistically significant. It may be uninterestingly better. It may not be significant in the English sense, but you still get statistical significance. So that's a problem when studies have lots of points. In general, it depends upon the application. For a lot of applications, you'll see things in the 0.7's being considered pretty useful. And the real question shouldn't be whether it's significant, but whether it's useful. Can you make useful decisions based upon it? And the other thing is, typically, when you're talking about that, you're selecting some point and really talking about a region relative to that point. We usually don't really care what it does out here. Because we hardly ever operate out there anyway. We're usually somewhere in the middle. But good question. Yeah? AUDIENCE: Why are we doing 1 minus specificity? JOHN GUTTAG: Why are we doing 1 minus specificity instead of specificity? Is that the question? And the answer is, essentially, so we can do this trick of computing the area. It gives us this nice curve. This nice, if you will, concave curve which lets us compute this area under here nicely if you were to take specificity and just draw it, it would look different. Obviously, mathematically, they're, in some sense, the same right. If you have 1 minus x and x, you can get either from the other. So it really just has to do with the way people want to draw this picture. AUDIENCE: [INAUDIBLE]? JOHN GUTTAG: Pardon? AUDIENCE: Does that not change [INAUDIBLE]? JOHN GUTTAG: Does it not-- AUDIENCE: Doesn't it change the meaning of what you're [INAUDIBLE]? JOHN GUTTAG: Well, you'd have to use a different statistic. You couldn't cite the AUROC if you did specificity directly. Which is why they do 1 minus. The goal is you want to have this point at 0 and this 0.00 and 1.1. And playing 1 minus gives you this trick, of anchoring those two points. And so then you get a curve connecting them, which you can then easily compare to the random curve. It's just one of these little tricks that statisticians like to play to make things easy to visualize and easy to compute statistics about. It's not a fundamentally important issue.","69.91401672363281","6","DPRSearchEngine","K2SC-WPdT6k.en-qlPKC2UN_YU_4_mp4","K2SC-WPdT6k.en-qlPKC2UN_YU","6.0002","14"
"140","What is a Directed Acyclic Graph (DAG) and why is it significant?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","69.88372039794922","7","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"140","What is a Directed Acyclic Graph (DAG) and why is it significant?","I want to print out what an edge looks like, I'm going to ask that it print out the name of the source, and then an arrow, and then the name of the destination. So notice what I do there. Given an instance of an edge, I can print it. And it will get the source or the node associated with source inside this instance, get for that the getName method, and then call it. Notice the open-close paren there to actually call it. What does that do? It says, inside the edge I've got something that points to a node. I get that node. I take the method associated with it. And I call it. That returns the string. And then I glue that together with the arrow. I do the same thing on the destination. And I just print it out. Pretty straightforward, hopefully. OK, now I have to make a decision about the graph. I'm going to start with digraphs, directed graphs. And I need to think about how I might represent the graph. I can create nodes. I can create edges, but I've got to bring them all together. So I'll remind you, a digraph is a directed graph. The edges pass in only one direction. And here's one way I could do it. Given all the sources and all the destinations, I could just create a big matrix called an adjacency matrix. The rows would be all the sources. The columns would be all the destinations. And then in a particular spot in the matrix, if there is an edge between a source and a destination, I'd just put a one. Otherwise I'd put a zero. Note, by the way, because it's a directed graph, it's not symmetric. There might be a one between S and D, but not between D and S, unless there are edges both ways. This would be a perfectly reasonable way to represent a graph, but not the most convenient one. I'd have to go into the matrix to look things up. It may also not be a very efficient way of representing things. For example, if there are very few edges in the graph, I could have a huge matrix with mostly zeros. And that's not the most effective way to do it. So I'm going to use an alternative called an adjacency list. And the idea here is, for every node in the graph. I'm going to associate with it a list of destinations. That is, for a node, what are the places I can reach with a single edge? OK, so let's see what that does if we want to build it. And yes, there's a lot of code here, but it's pretty easy to look through I hope. Here's the choice I'm going to make. Again, what's a graph? It's a set of nodes. It's a set of edges. I'm going to have a way of putting nodes into the graph. And I'm going to choose to, when I put a node into the graph, to store it as a key in a dictionary. OK? When I initialize the graph, I'm just going to set this internal variable, edges, to be an empty dictionary. And the second part of it is, when I add an edge to the graph between two nodes from a source to a destination, I'm going to take that point in the dictionary associated with the source. It's a key. And associated with it, I'm going to just have a list of the nodes I can reach from edges from that source. So notice what happens here. If I want to add a node, remember, it's a node not an edge-- I'll first check to make sure that it's not already in the dictionary. That little loop is basic, or that if is saying, if it's in this set of keys, it will return true. And I'm going to complain. I'm trying to copy a node or duplicate a node. Otherwise, notice what I do. When I put a node into the dictionary, I go into that dictionary, edges. I create an entry with the key that is the node. And the value I put in there is initially an empty list. I'm going to say one more piece carefully. It's a node not a name. And that's OK in Python. It is literally the key is the node itself. It's an object, which is what I'd like. All right, what if I want to add an edge? Well, an edge is going to go from a source to a destination node. So, I'm going to get out from the edge the source piece. I'm going to get out from the edge the destination piece by calling those methods. Again, notice the open-close paren, which takes the method and actually calls it. Because remember, an edge was an object itself. Given those, I'll check to make sure that they are both in the dictionary. That is, I've already added them to the graph. I can't make a connection between things that aren't in the graph. And then notice the nice little thing I do.","69.46282196044922","8","DPRSearchEngine","V_TulH374hw.en-qlPKC2UN_YU_2_mp4","V_TulH374hw.en-qlPKC2UN_YU","6.0002","3"
"140","What is a Directed Acyclic Graph (DAG) and why is it significant?","which is how do I actually compute shortest paths? Yeah, and the basic thing we're going to do is sort of build on this tree analogy here. We are going to define one more object, which I really like-- actually I enjoy this from Jason's notes because it looks like calculus, and I enjoy that-- and that's an idea of the level set. And so this is a whole set of things L sub k. And these are all the vertices that are distance k away from my source. So for instance, if my source vertex in this example is the vertex all the way on the left, then L0 obviously contains just that vertex, right. L1 is the next one. L2 is the third one. But now L3 is a set of three vertices because those are all the things that are distance 3 away from the source. That's what I've labeled in pink here. OK, so that's all that this notation here means. Oh, I've made a slight typo because in this class distance is delta and not d, but whatever. AUDIENCE: [INAUDIBLE] JUSTIN SOLOMON: The shortest distance-- that's absolutely right. So for instance, I could have a very long distance from L0 to L2, right. I could just flip back and forth between L0 and L1, maybe go over to L4 and then go back. But that wouldn't be a terribly helpful thing to compute. That's absolutely right. Yes? AUDIENCE: [INAUDIBLE]. JUSTIN SOLOMON: Oh, the red background is the set L. So for example, L3 contains these three vertices because they're all the things that are distance 3 away from the left. I got a little too slick drawing my diagram late last night. I'm kind of proud of it. OK, so essentially if I wanted to compute the length of the shortest path from all the way on the left to all the other vertices, one way to do that would be to compute all these level sets and then","69.4285659790039","9","DPRSearchEngine","oFVYVzlvk9c.en-j3PyPqV-e1s_12_mp4","oFVYVzlvk9c.en-j3PyPqV-e1s","6.006","9"
"140","What is a Directed Acyclic Graph (DAG) and why is it significant?","which is the drunk class. Then the origin, distances, and for t in range number of trials, we'll just do it, and then we'll return the distances. So it's initialized to the empty list. So we're going to return a list for however many trials we do, how far the drunk ended up from the origin. Then we can average that, and we look at the mean. Maybe we'll look at the min or the max. Lots of different questions we could ask about the behavior. And now we can put it all together here. So drunkTest will take a set of different walk lengths, a list of different walk lengths, the number of trials, and the class. And for a number of steps and walk lengths, distances will be simWalks of number of steps, numTrials, dClass. And then I'm going to just print some statistics. You may or may not have seen this. This is something that's built in to Python. I can ask for the name of a class. So dClass, remember, is a class, and _name_ will give me the name of the class. Might be usual, it might be drunk, in this case. So let's try it. So the code we've looked at. So let's go down here, and we'll run it, and we'll try it for walks of 10, 100, 1,000, and 10,000 steps. And we'll do 100 trials. Here's what we got. So my question to you is does this look plausible? What is it telling us here? Well, it's telling us here that the length of the walk actually doesn't really affect-- the number of steps doesn't affect how far the drunk gets. There's some randomness. 8.6, 8.57, 9.2, 8.7. Not much variance. So we've done this simulation and we've learned something, maybe. So does this look plausible? We can look at it here. I've just transcribed it. What do you think? Well, go ahead. AUDIENCE: I was going to say, it seems plausible because after the first two steps, there's a 50% chance he's going closer to the origin. And a 50% chance he's going away from it. JOHN GUTTAG: So we have at least one vote for plausible, and it's certainly a plausible argument. Well, one of the things we need to learn to do is whenever we build a simulation, we need to do what I call a sanity check to see whether or not the simulation actually makes sense. So if we're going to do a sanity check, what might we do in this case? We should try it on cases where we think we know the answer. So we say, let's take a really simple case where we're pretty sure we know what the answer is. Let's run our simulation and make sure it gives us the right answer for this simple case. So if we think of a sanity check here, maybe we should look at these numbers. We just did it. We know how far the drunk should get in zero steps. How far should the drunk move in zero steps? Zero. How far should the drunk move in one steps? We know that should be one. Two steps, well, we knew what that should be. Well, if I run this sanity check, these are the numbers I get. I should be pretty suspicious. I should also be suspicious they're kind of the same numbers I got for 10,000 steps. What should I think about? I should think that maybe there's a bug in my code. So if we now go back and look at the code, yes, this fails the pants on fire test that there's clearly something wrong with these numbers.","69.26516723632812","10","DPRSearchEngine","6wUD_gp5WeE.en-qlPKC2UN_YU_12_mp4","6wUD_gp5WeE.en-qlPKC2UN_YU","6.0002","5"
"141","How can transforming a graph into a Directed Acyclic Graph (DAG) using vertex duplication facilitate finding the shortest paths in linear time?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","82.32948303222656","1","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"141","How can transforming a graph into a Directed Acyclic Graph (DAG) using vertex duplication facilitate finding the shortest paths in linear time?","[SQUEAKING][RUSTLING][CLICKING] JASON KU: Welcome, everybody, to our lecture 14 of 6.006. This is our last lecture on graph algorithms, in particular, the last lecture we'll have on weighted shortest paths. But we're going to talk about a slightly different problem today, different than single source shortest paths. We're going to be talking about all-pairs shortest paths. But first, let's review our single source shortest paths algorithms. We had BFS, DAG relaxation, Dijkstra, which we saw last time, which gets pretty close to linear. V log V plus E is pretty close to linear. It's much closer to linear than the general algorithm we have for solving single source shortest paths, namely, Bellman-Ford, which is a little bit more like quadratic. This is like the difference between-- for sparse graphs, this is like the difference between sorting, using insertion sort and n squared, and merge sort in N log N, for example. We're going to get actually quite a big bonus for large input sizes by using Dijkstra when we can. Today, we're going to be focusing","76.64202117919922","2","DPRSearchEngine","EmSmaW-ud6A.en-j3PyPqV-e1s_1_mp4","EmSmaW-ud6A.en-j3PyPqV-e1s","6.006","14"
"141","How can transforming a graph into a Directed Acyclic Graph (DAG) using vertex duplication facilitate finding the shortest paths in linear time?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","76.24319458007812","3","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"141","How can transforming a graph into a Directed Acyclic Graph (DAG) using vertex duplication facilitate finding the shortest paths in linear time?","And that's cycle detection. So there's a bit of an exercise left to the reader here. So the problem that we're looking for now is that we're given a directed graph. There's a G in graph, in case you're wondering. But now, we don't know if it's a DAG or not. And so the question that we're trying to ask is, does there exist a cycle in our directed acyclic graph? So we're just given our graph, and we want to know, can we do this? Let's think through the logic of this a bit. So what do we know? We know that if our graph were a DAG, then I could call DGS, get the ordering out, and then I guess flip its ordering backwards. So I could compute the reverse finishing order. And it would give me a topological order of my graph. So if I were a DAG, I would get a topological order when I call DFS. So let's say that I ran DFS. I got whatever ordering I got. And now I found an edge the points in the wrong direction. I can just double check my list of edges, and I find one that does not respect the relationship that I see in the second bullet point here. Can my graph be a DAG? No. Because if my graph were a DAG, the algorithm would work. I just proved it to you. Right? So if my graph were a DAG, then I could do reverse finishing order. And what I would get back is a topological order. So if I found a certificate that my order wasn't topological, something went wrong, and the only thing that could go wrong is that my graph isn't a DAG. Yeah. Isn't a DAG. In fact, sort of an exercise left to the reader and/or to your section-- do we still have section? I think we do, as of now-- is that this is an if and only if, meaning that the only time that you even have a topological ordering in your graph is if your graph is a DAG. This is a really easy fact to sanity check, by the way. This is not like, a particularly challenging problem. But you should think through it because it's a good exercise to make sure you understand the definitions, which is to say that if you have a topological order, your graph is a DAG. If you don't have a topological order, your graph isn't a DAG. So in other words, we secretly gave you an algorithm for checking if a graph is a DAG at all. Right? What could I do? I could compute reverse finishing order. Check if it obeys the relationship on the second bullet point here for every edge. And if it does, then we're in good shape. My graph is a DAG. If it doesn't, something went wrong. And the only thing that could have gone wrong is not being a DAG. OK. So in other words, secretly we just solved-- well, I guess the way that I've written it here, we've solved the cycle detection problem here, which is to say that, well, I have a cycle if and only if I'm not a DAG, which I can check using this technique. Of course, the word ""detection"" here probably means that I actually want to find that cycle, and I haven't told you how to do that yet. All we know how to do so far is say, like, somewhere in this graph there's a cycle. And that's not so good. So we can do one additional piece of information in the two minutes we have remaining to sort of complete our story here, which is to modify our algorithm ever so slightly to not only say thumbs up, thumbs down, is there a cycle in this graph, but also to actually return the vertices as a cycle. And here's the property that we're going to do that, which is following, which is that if G contains a cycle, right, then full DFS will traverse an edge from a vertex v to some ancestor of v. I guess we haven't carefully defined the term ""ancestor"" here. Essentially, if you think of the sort of the running of the DFS algorithm, then an ancestor is like something that appears in the recursive call tree before I got to v. OK. So how could we prove that? Well, let's take a cycle. And we'll give it a name. In particular, we'll say that it's a cycle from v0 v1 to vk. And then it's a cycle, so it goes back to v0. OK. And I can order this cycle any way I want. Notice that if I permute the vertices in this list in a cyclical way, meaning that I take the last few of them and stick them at the beginning of the list, it's still a cycle. That's the nice thing about cycles. So in particular, without loss of generality, we're going to assume that v0 is the first vertex visited by DFS. What does that mean? That means, like, when I do my DFS algorithm making all these recursive calls, the very first vertex to be touched by this technique is v0. OK. Well, now what's going to end up happening? Well, think about the recursive call tree starting at v0. By the time that completes, anything that's reachable from v0 is also going to be complete. Do you see that? So for instance, v0 somewhere in its call tree might call v2. And notice that v2 was not already visited. So in fact, it will. For v1 I got to call v2 and so on. And in particular, we're going to get all the way to vertex k. Right? So in other words, we're going to visit a vertex vk. And notice what's going to happen. So remember our algorithm. In fact, we should probably just put it up on the screen would be easier than talking about it a bunch. Well, vk is now going to iterate over every one of the neighbors of vk. And in particular, it's going to see vertex v0. Right? So we're going to see the edge from vk to v0, which is an edge kind of by definition because we took this to be a cycle here. But notice that's exactly the thing we set out to prove, namely that full DFS traverses an edge from a vertex to one of its ancestors. Here's a vertex k. Here's the ancestor v0. Why do we know that it's an ancestor? Well, because v0 was called in our call tree before any of these other guys. Right? So we wanted an algorithm that not only did cycle detection, but also actually gave me the cycle. What could I do? Well, it's essentially a small modification of what we already have. Right. So-- whoops. Right. If I want to compute topological order or whatever, I can just do DFS. And that'll tell me like, yay or nay, does there exist a cycle. If I want to actually find that cycle, all I have to do is check that topological order property at the same time that it traversed the graph during DFS. And the second that I find an edge that loops back, I'm done. And so that's our basic algorithm here. And this is a technique for actually just finding the cycle in a graph using the DFS algorithm.","74.7642593383789","4","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_20_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"141","How can transforming a graph into a Directed Acyclic Graph (DAG) using vertex duplication facilitate finding the shortest paths in linear time?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","74.44269561767578","5","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"141","How can transforming a graph into a Directed Acyclic Graph (DAG) using vertex duplication facilitate finding the shortest paths in linear time?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 4: Hashing 
Lecture 4: Hashing 
Review 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
• Idea! Want faster search and dynamic operations. Can we find(k) faster than Θ(log n)? 
• Answer is no (lower bound)! (But actually, yes...!?) 
Comparison Model 
• In this model, assume algorithm can only differentiate items via comparisons 
• Comparable items: black boxes only supporting comparisons between pairs 
• Comparisons are <, ≤, >, ≥, =, =6 , outputs are binary: True or False 
• Goal: Store a set of n comparable items, support find(k) operation 
• Running time is lower bounded by # comparisons performed, so count comparisons! 
Decision Tree 
• Any algorithm can be viewed as a decision tree of operations performed 
• An internal node represents a binary comparison, branching either True or False 
• For a comparison algorithm, the decision tree is binary (draw example) 
• A leaf represents algorithm termination, resulting in an algorithm output 
• A root-to-leaf path represents an execution of the algorithm on some input 
• Need at least one leaf for each algorithm output, so search requires ≥ n + 1 leaves 
","74.42959594726562","6","DPRSearchEngine","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_1_pdf","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4","6.006","4"
"141","How can transforming a graph into a Directed Acyclic Graph (DAG) using vertex duplication facilitate finding the shortest paths in linear time?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","74.30294799804688","7","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"141","How can transforming a graph into a Directed Acyclic Graph (DAG) using vertex duplication facilitate finding the shortest paths in linear time?","It may never get taught again. But it has video, so you can watch-- instead of time traveling, if you don't want to watch it live, you can just watch the recorded version. It was taught by a bunch of postdocs that were here, and a bit myself. What I like to do with graphs is the world of planar graphs, or near-planar graphs. We've talked a lot about, this class, algorithms that work for arbitrary graphs. And the algorithms we've seen in this class are pretty much the best we know for a lot of problems for arbitrary graphs. But if your graph has some structure, like it's a road network and there aren't too many overpasses, you can usually draw these graphs in the plane without crossings. That's the meaning of planar. Maybe not exactly. Maybe just a few crossings. There's a generalization of this, which I won't get into. But let's just think about planar graphs. Planar graphs have some nice features, like they always have a linear number of edges. They're always sparse. So you can immediately plug that into our existing bounds. But even so, Dijkstra, in such a graph, would take v log v time. For planar graphs, you can do the equivalent of Dijkstra, meaning, I can compute single-source shortest paths with negative edge weights in linear time. No log. Not that impressive, but remove a log. More impressive is, we can do the equivalent of Bellman-Ford, which is a single-source shortest paths with arbitrary edge weights in a planar graph in some time-- almost linear time. The log squared v over log log v. So there's a couple of factors here-- but for almost linear time, whereas Bellman-Ford would take v squared time. So this is a huge improvement over what we've seen in the class. These are quite complicated algorithms, but they're covered in that class, if you're interested in them. Then the area I work in a lot is approximation algorithms for planar graphs. And let me just give you a fun flavor using something we know, which is breadth-first search. Breath-first search you can think of as building sort of rings around a single root node. And there's this general approach-- this was introduced by Baker in 1994, we've used for lots of different problems. We want to solve some NP-hard problem on a graph. So just run breadth-first search from an arbitrary vertex and decompose your graph into these layers. You could number them-- 0, 1, 2, 3. These are levels. And let's just, like, delete some of those layers. Let's say, let's delete every fourth layer. So maybe I delete this one. I delete all of the vertices in that layer. And then I delete all of the things in layer 8, and layer 12, and so on. Guessing-- I don't know which one to start with, but from-- I'll just try them all. And then I delete every fourth layer after that. So I've deleted, on average, about a quarter of the graph. And it turns out, for a lot of problems that you care about, like choosing where to place fire stations in this graph to minimize travel time for if there's a fire somewhere in the graph-- this happens, you know? Fires and graphs. Then this will only hurt your solution by, like, a factor of 1 plus a quarter. So you will get a solution that's within 25% of the optimal, for a lot of problems. And that works for any value 4. So I could do it for 10, and then I would get within 10% of the optimal solution. OK, but how do I actually solve the problem once I delete every fourth layer? Well, then your graph has this extra special structure, which is a constant number of layers, let's say. A constant number of breadth-first search layers. If you just look at this portion, this connected component, or this connected component in here, you can-- your graph is almost like a cycle. It's like four cycles stacked up together with some connections between them. And it turns out, that's something you can solve with very fancy dynamic programming, like the stuff we've seen in this class, which focuses on just a single path or a single cycle. If you just have a constant number of cycles, with more work, you can still do everything in polynomial time. This is a very general approach for getting arbitrarily good approximation algorithms. We call these 1 plus epsilon approximation for any epsilon. But the larger the epsilon, the more time you take. It's something like 2 to the order 1 over epsilon times polynomial n. So as long as epsilon is constant, this is polynomial time. This is called a PTAS. Anyway, that was graph algorithms. Last topic is recreational algorithms, which is maybe best encompassed by this class.","74.17459106445312","8","DPRSearchEngine","4nXw-f6NJ9s.en-j3PyPqV-e1s_5_mp4","4nXw-f6NJ9s.en-j3PyPqV-e1s","6.006","21"
"141","How can transforming a graph into a Directed Acyclic Graph (DAG) using vertex duplication facilitate finding the shortest paths in linear time?","Longest path is maybe a problem we've talked about in problem session, because it's a DAG-- well, longest path is the same thing as shortest path, if you just negate all the weights. There are no weights in this picture, so if you just put negative 1 on all these edges and ask for the shortest path from the base to anywhere-- so single source shortest paths from this base-- then we would end up getting this path, which, if you look at it, is E-M-P-T-Y, empty. And so that shortest path is indeed the right answer. What I've drawn here is the shortest path tree. So also, if you wanted the longest increasing subsequence starting at A, then it is A-T-Y, just by following the red arrows here. And how do you get that? You just draw the parent pointers, just like we did before.","73.90464782714844","9","DPRSearchEngine","KLBCUx1is2c.en-j3PyPqV-e1s_8_mp4","KLBCUx1is2c.en-j3PyPqV-e1s","6.006","16"
"141","How can transforming a graph into a Directed Acyclic Graph (DAG) using vertex duplication facilitate finding the shortest paths in linear time?","in a DAG in linear time? Well, a DAG-- I mean, this is actually a super useful, convenient thing in algorithms in general. DAGs are just nice things. They're kind of ordered in a way. There's this topological sort order that we were talking about before. This is going to play a key role. There's a really nice structure to DAGs not having cycles, not having to deal with this negative weight cycle problem. You can only go in one direction along this graph. It's a very nice structure to exploit. And so we're going to exploit it. And here's the idea. DAG relaxation, what it's going to do is it's going to start out with some estimates of what these distances should be. So maintain distance estimates. And now I'm going to try to be careful here about how I draw my Ds. This is a d, this is a delta. This is shortest paths. This is a distance estimate. So that's what I'm going to be using for the rest of this time. So we're going to maintain these estimates of distance d, which are going to start at initially infinite. I don't know what they are. I don't know what the shortest paths are, but they better be less than infinite or else I don't care. So that's the worst case scenario. It can't be worse than this-- for every vertex. And we're going to maintain the property that estimates upper bound-- that should probably be two words-- upper bound delta s, v-- we're going to maintain that they upper-bound this thing and gradually lower until they're equal. So this is the idea. We start from an over-estimate, an upper bound on the distance estimate. And then we're repeatedly going to lower that value as we gain more information about the graph, maintaining that we're always upper-bounding the distance. And we're going to keep doing it, keep doing it, keep doing it, until, as we will try to prove to you, these estimates reach, actually reach down, all the way to our shortest path distances. So when do we lower these things? When do we lower these things? We are going to lower these distance estimates whenever","73.2398452758789","10","DPRSearchEngine","5cF5Bgv59Sc.en-j3PyPqV-e1s_8_mp4","5cF5Bgv59Sc.en-j3PyPqV-e1s","6.006","11"
"142","How does the inductive hypothesis assure the correctness of the shortest-path distances computed by the Bellman-Ford algorithm?","[SQUEAKING] [RUSTLING] [CLICKING] ERIK DEMAINE: All right. Welcome back to 006 and our dynamic programming quadruple of lectures. We are over halfway through, into lecture three of four. Today, we're going to follow up on this idea of problem constraints and expansion that was mentioned, especially, towards the end of last lecture. We saw an example of subproblem expansion by a factor of 2 in the two-player game with coins where we wanted to have two versions of the game, one where I go first and one where you go first. So this was expanding the number of such problems by a factor of 2. Today, we'll see a bunch more examples of this idea, including in one setting we've seen already, which is Bellman-Ford, which you can think of as a dynamic program. Maybe it's a good time to mention that Bellman invented dynamic programming in the '50s. Same Bellman in the Bellman-Ford algorithm. This was actually an independent discovery by both of them-- and other people. He invented dynamic programming, and then, a few years later, he applied it to solve the single-source shortest paths problem. We saw them in the other order. We saw single-source shortest paths first, because it was a little easier. And now we're seeing the general framework that this fits into.","66.50993347167969","1","DPRSearchEngine","TDo3r5M1LNo.en-j3PyPqV-e1s_1_mp4","TDo3r5M1LNo.en-j3PyPqV-e1s","6.006","17"
"142","How does the inductive hypothesis assure the correctness of the shortest-path distances computed by the Bellman-Ford algorithm?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","65.03395080566406","2","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"142","How does the inductive hypothesis assure the correctness of the shortest-path distances computed by the Bellman-Ford algorithm?","These are called linkage metrics. The most common one used is probably single-linkage, and that says the distance between a pair of clusters is equal to the shortest distance from any member of one cluster to any member of the other cluster. So if I have two clusters, here and here, and they have bunches of points in them, single-linkage distance would say, well, let's use these two points which are the closest, and the distance between these two is the distance between the clusters. You can also use complete-linkage, and that says the distance between any two clusters is equal to the greatest distance from any member to any other member. OK? So if we had the same picture we had before-- probably not the same picture, but it's a picture. Whoops. Then we would say, well, I guess complete-linkage is probably the distance, maybe, between those two. And finally, not surprisingly, you can take the average distance. These are all plausible metrics. They're all used and practiced for different kinds of results depending upon the application of the clustering.","64.88365936279297","3","DPRSearchEngine","esmzYhuFnds.en-qlPKC2UN_YU_3_mp4","esmzYhuFnds.en-qlPKC2UN_YU","6.0002","12"
"142","How does the inductive hypothesis assure the correctness of the shortest-path distances computed by the Bellman-Ford algorithm?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 4: Hashing 
Lecture 4: Hashing 
Review 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
• Idea! Want faster search and dynamic operations. Can we find(k) faster than Θ(log n)? 
• Answer is no (lower bound)! (But actually, yes...!?) 
Comparison Model 
• In this model, assume algorithm can only differentiate items via comparisons 
• Comparable items: black boxes only supporting comparisons between pairs 
• Comparisons are <, ≤, >, ≥, =, =6 , outputs are binary: True or False 
• Goal: Store a set of n comparable items, support find(k) operation 
• Running time is lower bounded by # comparisons performed, so count comparisons! 
Decision Tree 
• Any algorithm can be viewed as a decision tree of operations performed 
• An internal node represents a binary comparison, branching either True or False 
• For a comparison algorithm, the decision tree is binary (draw example) 
• A leaf represents algorithm termination, resulting in an algorithm output 
• A root-to-leaf path represents an execution of the algorithm on some input 
• Need at least one leaf for each algorithm output, so search requires ≥ n + 1 leaves 
","64.87355041503906","4","DPRSearchEngine","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_1_pdf","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4","6.006","4"
"142","How does the inductive hypothesis assure the correctness of the shortest-path distances computed by the Bellman-Ford algorithm?"," 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
18.404/6.840 Lecture 9 
Last time: 
- !TM is undecidable 
- The diagonalization method 
- !TM is T-unrecognizable 
- The Reducibility Method, preview 
Today: (Sipser §5.1, §5.3) 
- The Reducibility Method for proving undecidability 
and T-unrecognizability. 
- General reducibility 
- Mapping reducibility 
1 
","64.6207275390625","5","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_1_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"142","How does the inductive hypothesis assure the correctness of the shortest-path distances computed by the Bellman-Ford algorithm?"," 
 
  
 
  
 
 
  
 
 
 
 
 
 
 
18.404/6.840 Lecture 22 
Last time: 
- Finished NL = coNL 
- Time and Space Hierarchy Theorems 
Today: (Sipser §9.2) 
- A “natural” intractable problem 
- Oracles and P versus NP 
1 
","64.55598449707031","6","DPRSearchEngine","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_1_pdf","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22","18.404J","22"
"142","How does the inductive hypothesis assure the correctness of the shortest-path distances computed by the Bellman-Ford algorithm?","single source shortest paths in linear time. Last time we discussed another linear time algorithm, DAG relaxation. And today we're going to be talking about Bellman-Ford, which isn't limited to asymptotic graphs. In particular, there could be negative weight cycles in our graph. If it has cycles, if it has negative weights, the worry is that we could have negative weight cycles, in which case there-- if a negative weight cycle is reachable from our source, then the vertices in that cycle and anything reachable from that cycle will potentially","64.35851287841797","7","DPRSearchEngine","f9cVS_URPc0.en-j3PyPqV-e1s_2_mp4","f9cVS_URPc0.en-j3PyPqV-e1s","6.006","12"
"142","How does the inductive hypothesis assure the correctness of the shortest-path distances computed by the Bellman-Ford algorithm?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
Reducibility terminology 
Why do we use the term “reduce”? 
When we reduce ! to "", we show how to solve ! by using "" 
and conclude that ! is no harder than "". (suggests the ≤$ notation) 
Possibility 1: We bring !’s difficulty down to ""’s difficulty. 
Possibility 2: We bring ""’s difficulty up to !’s difficulty. 
11 
","64.21289825439453","8","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_11_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"142","How does the inductive hypothesis assure the correctness of the shortest-path distances computed by the Bellman-Ford algorithm?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","64.19188690185547","9","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"142","How does the inductive hypothesis assure the correctness of the shortest-path distances computed by the Bellman-Ford algorithm?"," 
 
 
  
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
Computation with Oracles 
Let ! be any language. 
Defn: A TM "" with oracle for !, written ""#, is a TM equipped 
with a “black box” that can answer queries “is $ ∈!?” for free. 
Example: A TM with an oracle for &!' can decide all ( ∈ NP in polynomial time. 
Defn: P# = ( ( is decidable in polynomial time with an oracle for !} 
Thus NP ⊆ P+#, 
NP = P+#,? Probably No because coNP ⊆ P+#, 
Defn: NP# = ( ( is decidable in nondeterministic polynomial time with an oracle for !} 
Recall MIN-FORMULA = 7 7 is a minimal Boolean formula } 
Example: MIN−FORMULA ∈ NP+#, 
“On input 7 
1. Guess shorter formula 9 
2.  Use &!' oracle to solve the coNP problem: 7 and 9 are equivalent 
3. Accept if 7 and 9 are equivalent. Reject if not.” 
8 
","64.11647033691406","10","DPRSearchEngine","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_8_pdf","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22","18.404J","22"
"143","What does ""recurse but re-use"" mean in dynamic programming?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","77.8154067993164","1","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"143","What does ""recurse but re-use"" mean in dynamic programming?","	 
def getYearlyMeans(data): 
    years = {} 
    for d in data: 
        try: 
            years[d.getYear()].append(d.getHigh()) 
        except: 
            years[d.getYear()] = [d.getHigh()] 
    for y in years: 
        years[y] = sum(years[y])/len(years[y]) 
    return years 
	

?
","76.75247192382812","2","DPRSearchEngine","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10_42_pdf","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10","6.0002","10"
"143","What does ""recurse but re-use"" mean in dynamic programming?"," &&%$3$%'9
class Digraph(object): 
 """"""edges is a dict mapping each node to a list of 
    its children""""” 
    def __init__(self): 
self.edges = {} 
    def addNode(self, node): 
if node in self.edges: 
 raise ValueError('Duplicate node') 
else: 
self.edges[node] = [] 
    def addEdge(self, edge): 
src = edge.getSource() 
dest = edge.getDestination() 
if not (src in self.edges and dest in self.edges): 
raise ValueError('Node not in graph') 
self.edges[src].append(dest) 
Q>KKKMN
LS
mapping each node 
list 
","76.44303894042969","3","DPRSearchEngine","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_18_pdf","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3","6.0002","3"
"143","What does ""recurse but re-use"" mean in dynamic programming?"," &&
class Edge(object): 
    def __init__(self, src, dest): 
        """"""Assumes src and dest are nodes"""""" 
        self.src = src 
        self.dest = dest 
    def getSource(self): 
        return self.src 
    def getDestination(self): 
        return self.dest 
    def __str__(self): 
        return self.src.getName() + '->’\\ 
               + self.dest.getName() 
Q>KKKMN
LQ
","75.98521423339844","4","DPRSearchEngine","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_16_pdf","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3","6.0002","3"
"143","What does ""recurse but re-use"" mean in dynamic programming?"," 
 
 
Class LogisticRegression  
fit(sequence of feature vectors, sequence of labels) 
Returns object of type LogisticRegression 
coef_ 
Returns weights of features 
predict_proba(feature vector) 
Returns probabilities of labels 
6.0002 LECTURE 13 
22 
","75.68152618408203","5","DPRSearchEngine","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13_22_pdf","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13","6.0002","13"
"143","What does ""recurse but re-use"" mean in dynamic programming?","&

	
	
	/
def greedy(items, maxCost, keyFunction):
itemsCopy = sorted(items, key = keyFunction,
reverse = True)
result = []
totalValue, totalCost = 0.0, 0.0
for i in range(len(itemsCopy)):
if (totalCost+itemsCopy[i].getCost()) <= maxCost:
result.append(itemsCopy[i])
totalCost += itemsCopy[i].getCost()
totalValue += itemsCopy[i].getValue()
return (result, totalValue) 
	

2
	

","75.61538696289062","6","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_24_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"143","What does ""recurse but re-use"" mean in dynamic programming?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","75.57967376708984","7","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"143","What does ""recurse but re-use"" mean in dynamic programming?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 16: Dyn. Prog. Subproblems 
Lecture 16: Dyn. Prog. Subproblems 
Dynamic Programming Review 
• Recursion where subproblem dependencies overlap, forming DAG 
• “Recurse but re-use” (Top down: record and lookup subproblem solutions) 
• “Careful brute force” (Bottom up: do each subproblem in order) 
Dynamic Programming Steps (SRT BOT) 
1. Subproblem deﬁnition 
subproblem x 2 X 
• Describe the meaning of a subproblem in words, in terms of parameters 
• Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence 
• Often multiply possible subsets across multiple inputs 
• Often record partial state: add subproblems by incrementing some auxiliary variables 
2. Relate subproblem solutions recursively 
x(i) =  f(x(j), . . .) for one or more j < i  
• Identify a question about a subproblem solution that, if you knew the answer to, reduces 
the subproblem to smaller subproblem(s) 
• Locally brute-force all possible answers to the question 
3. Topological order to argue relation is acyclic and subproblems form a DAG 
4. Base cases 
• State solutions for all (reachable) independent subproblems where relation breaks down 
5. Original problem 
• Show how to compute solution to original problem from solutions to subproblem(s) 
• Possibly use parent pointers to recover actual solution, not just objective function 
6. Time analysis 
P 
• 
x2X work(x), or if work(x) =  O(W) for all x 2 X, then |X| · O(W) 
• work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time 
","75.49815368652344","8","DPRSearchEngine","28461a74f81101874a13d9679a40584d_MIT6_006S20_lec16_1_pdf","28461a74f81101874a13d9679a40584d_MIT6_006S20_lec16","6.006","16"
"143","What does ""recurse but re-use"" mean in dynamic programming?","4 
Lecture 15: Recursive Algorithms 
Dynamic Programming 
• Weird name coined by Richard Bellman 
– Wanted government funding, needed cool name to disguise doing mathematics! 
– Updating (dynamic) a plan or schedule (program) 
• Existence of recursive solution implies decomposable subproblems1 
• Recursive algorithm implies a graph of computation 
• Dynamic programming if subproblem dependencies overlap (DAG, in-degree > 1) 
• “Recurse but re-use” (Top down: record and lookup subproblem solutions) 
• “Careful brute force” (Bottom up: do each subproblem in order) 
• Often useful for counting/optimization problems: almost trivially correct recurrences 
How to Solve a Problem Recursively (SRT BOT) 
1. Subproblem deﬁnition 
subproblem x ∈ X 
• Describe the meaning of a subproblem in words, in terms of parameters 
• Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence 
• Often record partial state: add subproblems by incrementing some auxiliary variables 
2. Relate subproblem solutions recursively 
x(i) = f(x(j), . . .) for one or more j < i 
3. Topological order to argue relation is acyclic and subproblems form a DAG 
4. Base cases 
• State solutions for all (reachable) independent subproblems where relation breaks down 
5. Original problem 
• Show how to compute solution to original problem from solutions to subproblem(s) 
• Possibly use parent pointers to recover actual solution, not just objective function 
6. Time analysis 
P 
• 
work(x), or if work(x) = O(W ) for all x ∈ X, then |X| · O(W )
x∈X 
• work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time 
1This property often called optimal substructure. It is a property of recursion, not just dynamic programming 
","74.95233154296875","9","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_4_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"143","What does ""recurse but re-use"" mean in dynamic programming?","which, I think, most of us would agree was not a very big number. And let's look what's going on here. If you look at this, what in some sense seems really stupid about it? What is it doing that a rational person would not want to do if they could avoid it? It's bad enough to do something once. But to do the same thing over and over again is really wasteful. And if we look at this, we'll see, for example, that fib 4 is being computed here, and fib 4 is being computed here. Fib 3 is being considered here, and here, and here. And do you think we'll get a different answer for fib 3 in one place when we get it in the other place? You sure hope not. So you think, well, what should we do about this? How would we go about avoiding doing the same work over and over again? And there's kind of an obvious answer, and that answer is at the heart of dynamic programming. What's the answer? AUDIENCE: [INAUDIBLE] JOHN GUTTAG: Exactly. And I'm really happy that someone in the front row answered the question because I can throw it that far. You store the answer and then look it up when you need it. Because we know that we can look things up very quickly. Dictionary, despite what Eric said in his lecture, almost all the time works in constant time if you make it big enough, and it usually is in Python. We'll see later in the term how to do that trick. So you store it and then you'd never have to compute it again. And that's the basic trick behind dynamic programming. And it's something called memoization, as in you create a memo and you store it in the memo. So we see this here. Notice that what we're doing is trading time for space. It takes some space to store the old results, but negligible related to the time we save. So here's the trick. We're going to create a table to record what we've done. And then before computing fib of x, we'll check if the value has already been computed. If so, we just look it up and return it. Otherwise, we'll compute it-- it's the first time-- and store it in the table. Here is a fast implementation of Fibonacci that does that. It looks like the old one, except it's got an extra argument-- memo-- which is a dictionary. The first time we call it, the memo will be empty. It tries to return the value in the memo. If it's not there, an exception will get raised, we know that.","74.4953842163086","10","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_9_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"145","What is one conservative test to eliminate unnecessary computation when rendering a 3D scene?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","73.06106567382812","1","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"145","What is one conservative test to eliminate unnecessary computation when rendering a 3D scene?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
Regression to the Mean  
Following an extreme random event, the next random 
event is likely to be less extreme 
If you spin a fair roulette wheel 10 times and get 100% 
reds, that is an extreme event (probability = 1/1024) 
It is likely that in the next 10 spins, you will get fewer 
than 10 reds 
◦ But the expected number is only 5 
So, if you look at the average of the 20 spins, it will be 
closer to the expected mean of 50% reds than to the 
100% of the first 10 spins 
6.0002 LECTURE 6 
16
","71.50126647949219","2","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_16_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"145","What is one conservative test to eliminate unnecessary computation when rendering a 3D scene?","§ Problem is exponen<al 
§ Have we overturned the laws of the universe? 
§ Is dynamic programming a miracle? 
§ No, but computa<onal complexity can be subtle 
§ Running <me of fastMaxVal is governed by number of 
dis<nct pairs, <toConsider, avail> 
◦Number of possible values of toConsider bounded 
by len(items)
◦Possible values of avail a bit harder to characterize 
◦Bounded by number of dis<nct sums of weights 
◦Covered in more detail in assigned reading 
How Can This Be? 
6.0002 LECTURE 2 
30 
","70.68146514892578","3","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_30_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"145","What is one conservative test to eliminate unnecessary computation when rendering a 3D scene?","need to make each polyhedron. And some of these problems are NP-hard, and it's a lot of fun. Cool. I think that's the end of the slides. The last thing I wanted to show you is a problem, a puzzle/magic trick-- it comes from the puzzle world-- called the picture hanging problem. So imagine you have a picture. You want to hang it on a wall. So you invested in some nice rope, and you hang it on a nail. If the nail falls out, the picture falls, and you're sad. So you invest in two nails, like I have here, and maybe you hang your picture on both those nails. Now, if one of the nails falls out, you still have a crookedly hung picture. If the other nail falls out, OK, it's gone. I want to hang a picture on two nails such that, if I remove either nail, the picture falls. So, Jason, pick a nail, left or right. Left, we remove. Make sure this doesn't fall off-- and, boom, the picture falls. Same wrapping. You can check-- you can rewind the video, make sure I did the same wrapping. JASON KU: And take out the right. ERIK DEMAINE: Then take out the right one. Good choice. Then, also, the picture falls. This is a classic puzzle, but you can generalize it. So let me do it for three nails, which is all I have here. This nail is sagging a little bit. y, x-- y inverse, x inverse. I think that's right. So this is one way to hang a picture on three nails such that, if I remove any of the nails, the picture falls. Justin, 1, 2, or 3? 2. OK. Yeah, I want to get out of the way and make sure I don't go over the edge here. Yeah. It's a lot easier to make this one work. But you can see, boom, picture falls there. And of course, imagine infinite gravity. And the picture falls. Ta-da! You can generalize this to do essentially any-- what's called a monotone Boolean function-- on any set of nails. I mean, you can make any subset of the nails cause the picture to fall and any collection of subsets of nails to make it fall. Of course, if you remove more nails, it's still going to fall. That's the monotone sense. But otherwise, you can do an arbitrary pattern, which is fun. That's actually a result with Ron Rivest and a bunch of other people. I think I'm approximately on time. So that was a quick tour. And there are obviously various classes here you can take. 6.892, the hardness class, was just offered last semester, so it probably won't be for a while. But all of these classes are online. Watch the videos, feel free to ask me questions. And now we have Justin. I left you space here for your outline. You don't have to, but I'll put your name. JUSTIN SOLOMON: Thank you. JASON KU: So Justin is also a geometer. ERIK DEMAINE: Yeah, we've got a lot of geometry people in 006 this semester. JUSTIN SOLOMON: Thank you. OK. I can't help but share that, on our instructor chat, Erik was texting that he was going to be-- he was somehow nervous that the applied guy would have all of the cool stuff to show off, and now I feel totally boring. [LAUGHING] Right. Yeah. We have three different geometry instructors in this class. In this class, I think we have many different flavors of geometry that are kind of represented in this room here, from mechanical engineering, to theory plus lots of other cool stuff, to whatever it is that I do. I'm a professor, also, in CSAIL, and lead a group that studies slightly more applied geometry problems, in some sense, and in CSAIL, we kind of cross a lot of boundaries-- actually, closer to the math department than to the theory group and computer science, which I would argue is largely a historical artifact rather than anything interesting about computer science or math. Continuing in our whirlwind tour of interesting geometry classes here at MIT, I have some more fun things to add to the list. And we'll introduce some of the ideas in the next couple of slides here.","69.4437484741211","4","DPRSearchEngine","4nXw-f6NJ9s.en-j3PyPqV-e1s_7_mp4","4nXw-f6NJ9s.en-j3PyPqV-e1s","6.006","21"
"145","What is one conservative test to eliminate unnecessary computation when rendering a 3D scene?"," 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
Issues with k-means  
§Choosing the “wrong” k can lead to strange results  
◦ Consider  k = 3 
§Result can depend upon initial centroids 
◦ Number  of iterations 
◦ Even final result 
◦ Greedy algorithm can find different local optimas 
6.0002  LECTURE 12 
18 
","69.1767349243164","5","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_18_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"145","What is one conservative test to eliminate unnecessary computation when rendering a 3D scene?","I'm defining something called LR, for logistic regression. It takes the training data, the test data, the probability, it builds a model, and then it gets the results by calling apply model with the label survived and whatever this prob was. Again, we'll do it for both leave one out and random splits, and again for 10 random splits. You'll notice it actually runs-- maybe you won't notice, but it does run faster than KNN. One of the nice things about logistic regression is building the model takes a while, but once you've got the model, applying it to a large number of variables-- feature vectors is fast. It's independent of the number of training examples, because we've got our weights. So solving the optimization problem, getting the weights, depends upon the number of training examples. Once we've got the weights, it's just evaluating a polynomial. It's very fast, so that's a nice advantage. If we look at those-- and we should probably compare them to our earlier KNN","69.14117431640625","6","DPRSearchEngine","eg8DJYwdMyg.en-qlPKC2UN_YU_10_mp4","eg8DJYwdMyg.en-qlPKC2UN_YU","6.0002","13"
"145","What is one conservative test to eliminate unnecessary computation when rendering a 3D scene?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 4: Hashing 
Lecture 4: Hashing 
Review 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
• Idea! Want faster search and dynamic operations. Can we find(k) faster than Θ(log n)? 
• Answer is no (lower bound)! (But actually, yes...!?) 
Comparison Model 
• In this model, assume algorithm can only differentiate items via comparisons 
• Comparable items: black boxes only supporting comparisons between pairs 
• Comparisons are <, ≤, >, ≥, =, =6 , outputs are binary: True or False 
• Goal: Store a set of n comparable items, support find(k) operation 
• Running time is lower bounded by # comparisons performed, so count comparisons! 
Decision Tree 
• Any algorithm can be viewed as a decision tree of operations performed 
• An internal node represents a binary comparison, branching either True or False 
• For a comparison algorithm, the decision tree is binary (draw example) 
• A leaf represents algorithm termination, resulting in an algorithm output 
• A root-to-leaf path represents an execution of the algorithm on some input 
• Need at least one leaf for each algorithm output, so search requires ≥ n + 1 leaves 
","68.94755554199219","7","DPRSearchEngine","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_1_pdf","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4","6.006","4"
"145","What is one conservative test to eliminate unnecessary computation when rendering a 3D scene?"," 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
Modeling the  World  
§Models  always  inaccurate
◦Provide abstractions of reality
§Deterministic models, e.g., graph theoretic
§Statistical models
◦Simulation models: Monte Carlo simulation
◦Models  based on sampling
◦Characterizing accuracy is critical
◦Central limit theorem
◦Empirical rule
◦Machine learning
◦Unsupervised and supervised
§Presentation of data
◦Plotting
◦Good and bad practices
6.0002  LECTURE 15 
21 
","68.7061996459961","8","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_18_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"145","What is one conservative test to eliminate unnecessary computation when rendering a 3D scene?"," 
 
 
 
 
  
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Constructing !"",$: 1st try 
% on & 
Recall: A tableau for % on & represents 
a computation history for % on & 
when % accepts &. 
Rows of that tableau are configurations. 
% runs in space 45, its tableau has: 
- 45 columns (max size of a configuration)
-8
- 6
rows (max number of steps) 
Constructing !"",$. Try Cook-Levin method. 
Then !"",$ will be as big as tableau. 
-8
But that is exponential: 45×6 
.
Too big! • 
7 
Tableau for % on &
'( &) &* &+ ⋯&-
a
'. &*
⋯
⋯
'accept ⋯
˽   … ˽
45
6(-8)
","68.66548156738281","9","DPRSearchEngine","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18_7_pdf","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18","18.404J","18"
"145","What is one conservative test to eliminate unnecessary computation when rendering a 3D scene?"," 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Non-representative Sampling  
§“Convenience sampling” not usually random, e.g.,
◦Survivor  bias,  e.g.,  course evaluations at end of course or
grading final exam in 6.0002  on a strict curve
◦Non-response bias,  e.g.,  opinion polls conducted by mail
or  online
§When samples not random and independent, we can
still do things like computer means and standard 
deviations, but we should not draw conclusions from 
them using things like the empirical rule and central 
limit theorem. 
§Moral: Understand how data was collected, and
whether assumptions used in the analysis are satisfied. 
If not, be wary. 
6.0002  LECTURE 14 
22 
","68.65827178955078","10","DPRSearchEngine","b9d60f4ecb325e4648f9cf0379419338_MIT6_0002F16_lec14_22_pdf","b9d60f4ecb325e4648f9cf0379419338_MIT6_0002F16_lec14","6.0002","14"
"146","What is the formula for calculating the minimum total difficulty from note t_i with starting finger f?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
Reducibility terminology 
Why do we use the term “reduce”? 
When we reduce ! to "", we show how to solve ! by using "" 
and conclude that ! is no harder than "". (suggests the ≤$ notation) 
Possibility 1: We bring !’s difficulty down to ""’s difficulty. 
Possibility 2: We bring ""’s difficulty up to !’s difficulty. 
11 
","70.91656494140625","1","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_11_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"146","What is the formula for calculating the minimum total difficulty from note t_i with starting finger f?","And this is going to use subproblem expansion. So the subproblems are going to be x of i, comma f-- this is the minimum total difficulty to play suffix-- because I like suffixes-- t i up to t n minus 1, starting with finger f on note t i. The obvious subproblems would be without this constraint.","70.73334503173828","2","DPRSearchEngine","TDo3r5M1LNo.en-j3PyPqV-e1s_14_mp4","TDo3r5M1LNo.en-j3PyPqV-e1s","6.006","17"
"146","What is the formula for calculating the minimum total difficulty from note t_i with starting finger f?"," 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
  
 
  
 
 
 
  
 
  
 
  
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
Games and Quantifiers 
-
The Formula Game 
Given QBF ! = ∃$% ∀$' ∃$( ⋯ ∃/∀ $+ 
⋯ ∧⋯∧ ⋯ 
There are two Players “∃” and “∀”. 
Player ∃ assigns values to the ∃-quantified variables. 
Player ∀ assigns values to the ∀-quantified variables. 
The players choose the values according to the order of the quantifiers in !. 
After all variables have been assigned values, we determine the winner: Check-in 19.2 
Player ∃ wins if the assignment satisfies -. 
Which player has a winning 
Player ∀ wins if not. 
strategy in the formula game on 
Claim: Player ∃ has a forced win in the formula game on ! iff ! is TRUE. 
! = ∃$ ∀6 $ ∨6 ∧ $ ∨6 
Therefore 
! Player ∃ has a forced win on !} = /012. 
(a) ∃-player 
Next: show /012 ≤4 55. 
(b) ∀-player 
(c) Neither player 
Check-in 19.2 
3 
","68.93153381347656","3","DPRSearchEngine","fd9c1b8656c7def498dcf662f6750d87_MIT18_404f20_lec19_3_pdf","fd9c1b8656c7def498dcf662f6750d87_MIT18_404f20_lec19","18.404J","19"
"146","What is the formula for calculating the minimum total difficulty from note t_i with starting finger f?","Here, we're given a sequence of notes t 0, t 1-- t for note-- up to t n minus 1. These are single notes. And all of the single notes-- all of the single notes, right? And we have fingers on our hands. This is not like two-finger algorithm. This is the five-finger algorithm. So in general, I'm going to assume an arbitrary anthropomorphic object. So this is 5 for humans-- most humans. Some humans-- I think the maximum on each hand is 7. Could be smaller. Maybe you've had an accident.","68.64447021484375","4","DPRSearchEngine","TDo3r5M1LNo.en-j3PyPqV-e1s_12_mp4","TDo3r5M1LNo.en-j3PyPqV-e1s","6.006","17"
"146","What is the formula for calculating the minimum total difficulty from note t_i with starting finger f?","The “Roll-over” Op#miza#on Problem 
6.0002 LECTURE 2 
32 
Score = ((60 – (a+b+c+d+e))*F + a*ps1 + b*ps2 + c*ps3 + d*ps4 + e*ps5 
Objec<ve: 
 Given values for F, ps1, ps2, ps3, ps4, ps5 
 Find values for a, b, c, d, e that maximize score 
Constraints: 
        a, b, c, d, e are each 10 or 0 
 a + b + c + d + e ≥ 20 
","67.7587661743164","5","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_32_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"146","What is the formula for calculating the minimum total difficulty from note t_i with starting finger f?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Quick review of today 
Finished #""#$ ∈ IP and coNP ⊆ IP 
Additional subjects: 
18.405/6.841 Advanced complexity F2021 
18.425/6.875 Cryptography F2021 
6.842 Randomness and Computation ? 
Good luck on the final! 
Best wishes for the holidays and the New Year! 
10 
","66.81951141357422","6","DPRSearchEngine","7ac944716e076209c3964e073929f42e_MIT18_404f20_lec26_10_pdf","7ac944716e076209c3964e073929f42e_MIT18_404f20_lec26","18.404J","26"
"146","What is the formula for calculating the minimum total difficulty from note t_i with starting finger f?","	$
	&$	!	 	
	

9
","66.75969696044922","7","DPRSearchEngine","20a7e184a1a2b3c34a5055dc1f1dc066_MIT6_0002F16_lec9_9_pdf","20a7e184a1a2b3c34a5055dc1f1dc066_MIT6_0002F16_lec9","6.0002","9"
"146","What is the formula for calculating the minimum total difficulty from note t_i with starting finger f?"," 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
Computation History Method - recap 
Computation History Method is useful for showing the undecidability 
of problems involving testing for the existence of some object. 
!
Is there an integral solution (to the polynomial equation)?
""LBA 
Is there some accepted string (for the LBA)?
&'& 
Is there a match (for the given dominos)?
())CFG Is there some rejected string (for the CFG)?
In each case, the object is the computation history in some form.
12
","66.3976058959961","8","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_12_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"146","What is the formula for calculating the minimum total difficulty from note t_i with starting finger f?","§ Time based on number of nodes generated 
§ Number of levels is number of items to choose from 
§ Number of nodes at level i is 2i 
§ So, if there are n items the number of nodes is 
◦ ∑𝑖=0↑𝑖=𝑛▒​2↑𝑖   
◦ I.e., O(​2↑𝑛+1 ) 
§ An obvious op<miza<on: don’t explore parts of tree 
that violate constraint (e.g., too many calories) 
◦ Doesn’t change complexity 
§ Does this mean that brute force is never useful? 
◦ Let’s give it a try 
Computa#onal Complexity 
6.0002 LECTURE 2 
8 
","66.30333709716797","9","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_8_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"146","What is the formula for calculating the minimum total difficulty from note t_i with starting finger f?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
Use our knowledge that !TM is undecidable to show other 
problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
10 
","66.27597045898438","10","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_10_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"147","What is a changeable priority queue?"," 
 
 
   
 
 
 
   
   
      
 
 
 
 
 
 
  
 
Stochastic Processes  
An ongoing process where the next state might depend on 
both the previous states and some random element 
def rollDie(): 
"""""" returns an int between 1 and 6"""""" 
def rollDie(): 
"""""" returns a randomly chosen int 
between 1 and 6"""""" 
6.0002 LECTURE 4 
8
","70.62939453125","1","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_8_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"147","What is a changeable priority queue?"," 
 
 
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
  
 
  
 
  
 
 
  
 
 
   
 
 
   
 
 
 
 
TMs and Encodings – review 
A TM has 3 possible outcomes for each input !: 
1. Accept ! (enter ""acc ) 
2. Reject ! by halting (enter ""rej ) 
3. Reject ! by looping (running forever) 
( is T-recognizable if ( = *(,) for some TM ,. 
( is T-decidable if ( = *(,) for some TM decider ,. 
halts on all inputs 
〈/0, /2, … , /4〉 encodes objects /0, /2, … , /4 as a single string. 
Notation for writing a TM , is 
, = “On input ! 
[English description of the algorithm]” 
2 
","69.41438293457031","2","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_2_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"147","What is a changeable priority queue?"," 
 
 
 
 
 
   
  
 
  
 
 
   
 
 
  
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
  
 
 
 
 
 
 
Check-in 8.2 
Recall the Queue Automaton (QA) defined in Pset 2. 
It is similar to a PDA except that it is deterministic 
and it has a queue instead of a stack. 
Let !QA = { &, ( | & is a QA and & accepts (} 
Is !QA decidable? 
(a) Yes, because QA are similar to PDA and !PDA is decidable. 
(b) No, because “yes” would contradict results we now know. 
(c) We don’t have enough information to answer this question. 
8 
Check-in 8.2 
","69.3843994140625","3","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_8_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"147","What is a changeable priority queue?","[SQUEAKING] [RUSTLING] [CLICKING] ERIK DEMAINE: All right, welcome back to 006 Data Structures. Today, we're going to cover a different kind of tree-like data structure called a heap-- a binary heap. It's going to let us solve sorting problem in a new way. Let me first remind you of a portion-- the problem we're going to be solving today is called priority queue. This is the interface. We'll see several data structures,","69.26286315917969","4","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_1_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"147","What is a changeable priority queue?","  
 
  
 
 
 
  
 
 
 
 
 
   
 
 
 
 
  
 
 
 
  
 
  
   
 
  
 
 
  
  
  
 
 
 
 
 
 
  
  
 
 
 
 
 
 
 
  
 
 
 
 
   
 
 
 
 
 
  
 
 
Example: Ladder Problem 
A ladder is a sequence of strings of a common length where 
WORK
consecutive strings differ in a single symbol. 
PORK 
A word ladder for English is a ladder of English words. 
PORT 
SORT
Let ! be a language. A ladder in ! is a ladder of strings in !. 
SOOT 
Defn: ""!##$%DFA = *, ,, ­
* is a DFA and ""(*) contains 
SLOT 
a ladder 01, 02, … , 04 where 01 = , and 04 = -}. 
PLOT 
Theorem: ""!##$%DFA ∈ NPSPACE 
PLOY 
PLAY
PLAY 
7 
","68.59571838378906","5","DPRSearchEngine","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17_7_pdf","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17","18.404J","17"
"147","What is a changeable priority queue?"," 
 
 
 
 
 
Class Field, continued  
def moveDrunk(self, drunk):  
if drunk not in self.drunks:  
raise ValueError('Drunk not in field')  
xDist, yDist = drunk.takeStep()  
#use move method of Location to get new location  
self.drunks[drunk] =\\  
self.drunks[drunk].move(xDist, yDist)  
Immutable or not? 
6.0002  LECTURE 5 
19 
","68.35482788085938","6","DPRSearchEngine","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_19_pdf","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5","6.0002","5"
"147","What is a changeable priority queue?","And this is a subset of the set interface. And subsets are interesting because, potentially, we can solve them better, faster, simpler, something. And so you'll recognize-- you should recognize all of these operations, except we didn't normally highlight the max operation. So here, we're interested in storing a bunch of items. They have keys which we think of as priorities. And we want to be able to identify the maximum priority item in our set and remove it. And so there's lots of motivations for this. Maybe you have a router, packets going into the router. They have different priorities assigned to them. You want to route the highest priority first. Or you have processes on your computer trying to run on your single threaded-- single core, and you've got to choose which one to run next. And you usually run higher priority processes first. Or you're trying to simulate a system where events happen at different times, and you want to process the next event ordered by time. All of these are examples of the priority queue interface. We'll even see applications within this class when we get to graph algorithms. But the main two things we want to be able to support are inserting an item, which includes a key, and leading the maximum item, and also returning it at the same time. We'll also talk some about being able to build the structure faster than just inserting it. But of course, we could implement build by starting empty and repeatedly inserting. And also the complexity of just finding the max without deleting it, this you could simulate with these two operations by deleting the max and then reinserting it, which works. But often, we can do faster. But the two key, main operations are insert and delete max. And we're going to see a few data structures to do this. Any suggestions among the data structures we've seen in this class? What should we use to solve priority queue interface? Many possible answers.","67.95205688476562","7","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_2_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"147","What is a changeable priority queue?","So what is the running time of Dijkstra? If I take a look at that algorithm over there-- well I guess let's switch these back up again. OK, so what does this do? We build once. Then we delete the minimum from the Q how many times? v times. We remove every vertex from our Q. Then for every possible edge, we may need to relax and decrease the key in our queue once for every outgoing edge. So the running time is B plus V times M plus E times D. OK. So how could we implement this priority queue? Well, if we use the stupidest priority queue in the world, here's a list of different implementations we could have for our priority queues. And when I say priority queue, I mean this priority queue. We're already implementing the changeable priority queue by linking it with a dictionary that's efficient If I just use an array, I can find the min in linear time, sure. And I don't have to update that array in any way. I mean, I can just keep the distances in my direct access array. I don't have to store a separate data structure. I just store the distances in my direct access array D, and so I can find it in constant time and I can update the values stored there. And then whenever I want the minimum, I can just loop through the whole thing. So that gives me a really fast decrease key,","67.8663101196289","8","DPRSearchEngine","NSHizBK9JD8.en-j3PyPqV-e1s_6_mp4","NSHizBK9JD8.en-j3PyPqV-e1s","6.006","13"
"147","What is a changeable priority queue?"," 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Quick review of today 
1. Proved the CFL Pumping Lemma as a tool 
for showing that languages are not context 
free. 
2. Defined Turing machines (TMs). 
3. Defined TM deciders (halt on all inputs). 
4. T-recognizable and T-decidable languages. 
12 
","67.76502990722656","9","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_12_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"147","What is a changeable priority queue?"," 
 
 
 
 
 
Two Kinds of Drunks  
import random  
class UsualDrunk(Drunk):  
def takeStep(self):  
stepChoices = [(0,1), (0,-1), (1, 0), (-1, 0)]  
return random.choice(stepChoices)  
class MasochistDrunk(Drunk):  
def takeStep(self):  
stepChoices = [(0.0,1.1), (0.0,-0.9),  
(1.0, 0.0), (-1.0, 0.0)]  
return random.choice(stepChoices)  
Immutable or not? 
6.0002  LECTURE 5 
17 
","67.14173126220703","10","DPRSearchEngine","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_17_pdf","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5","6.0002","5"
"148","What is the max-heap property?","&

	
	
	/
def greedy(items, maxCost, keyFunction):
itemsCopy = sorted(items, key = keyFunction,
reverse = True)
result = []
totalValue, totalCost = 0.0, 0.0
for i in range(len(itemsCopy)):
if (totalCost+itemsCopy[i].getCost()) <= maxCost:
result.append(itemsCopy[i])
totalCost += itemsCopy[i].getCost()
totalValue += itemsCopy[i].getValue()
return (result, totalValue) 
	

2
	

","70.65754699707031","1","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_24_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"148","What is the max-heap property?",";
/
def testGreedy(items, constraint, keyFunction):
taken, val = greedy(items, constraint, keyFunction)
print('Total value of items taken =', val)
for item in taken:
print('   ', item)
	

'
","70.33966827392578","2","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_25_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"148","What is the max-heap property?",";
/
def testGreedys(maxUnits):
print('Use greedy by value to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits, Food.getValue)
print('\\nUse greedy by cost to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits,
lambda x: 1/Food.getCost(x))
print('\\nUse greedy by density to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits, Food.density)
testGreedys(800)
	


4
","70.26220703125","3","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_26_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"148","What is the max-heap property?","
7:
/
def greedy(items, maxCost, keyFunction):
""""""Assumes items a list, maxCost >= 0,
keyFunction maps elements of items to numbers""""""
itemsCopy = sorted(items, key = keyFunction,
reverse = True)
result = []
totalValue, totalCost = 0.0, 0.0
for i in range(len(itemsCopy)):
if (totalCost+itemsCopy[i].getCost()) <= maxCost:
result.append(itemsCopy[i])
totalCost += itemsCopy[i].getCost()
totalValue += itemsCopy[i].getValue()
return (result, totalValue) 
	

&
","69.48902893066406","4","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_23_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"148","What is the max-heap property?","As we see in this tree, for the example we just saw, the box is around a place where we're actually solving the same problem, even though we've made different decisions about what to take, A versus B. And in fact, we have different amounts of value in the knapsack-- 6 versus 7. What matters is we still have C and D to consider and we have two units left. It's a small and easy step. I'm not going to walk you through the code because it's kind of boring to do so. How do you modify the maxVal we looked at before to use a memo? First, you have to add the third argument, which is initially going to be set to the empty dictionary. The key of the memo will be a tuple-- the items left to be considered and the available weight. Because the items left to be considered are in a list, we can represent the items left to be considered by how long the list is. Because we'll start at the front item and just work our way to the end. And then the function works, essentially, exactly the same way fastFib worked. I'm not going to run it for you because we're running out of time. You might want to run it yourself because it is kind of fun to see how really fast it is.","68.52616119384766","5","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_13_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"148","What is the max-heap property?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","68.51236724853516","6","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"148","What is the max-heap property?","I've been talking about-- build, insert, and delete_max. So we have set AVL trees there-- n log n build, log n insert, log n delete. So along the way to our heap, I want to mention two other data structures. One is a dynamic but unsorted array. And the other is a dynamic sorted array. These are simpler data structures we've talked about many times before. And they're useful kind of motivations for getting started, because a heap is going to be built on top of arrays instead of-- well, it's sort of a fusion between arrays and trees. So if I have an unsorted array, this is very easy to insert into, right? I just append to the end. This is what we called insert last. So insert is fast, constant amortized. We might have to resize the array, but so that's the amortized part. But delete max is slow. In an unsorted array, I don't know where the maximum is. So I have to scan through the whole array. So I scan through the array, identify that the max is somewhere in the middle, and then, if I want to delete it-- I want to delete that maximum element, well, in a dynamic array, all I can really do is delete the last element efficiently. So I could, for example, swap it with the last element. So I take this element and put it here, and then delete the last element in that array, which is pop in Python or delete_last in our world. So overall, this is linear time, which is bad. But I wanted to highlight exactly how it's done for a reason we'll get to in a moment. A sorted array is sort of the reverse. It's very easy to find the max. Where is it? At the end. delete_max, the maximum element is always the last element in a increasing sorted array. I guess that's constant amortized, because then I have to delete it, which may incur resizing. Insert, though, is going to be linear, because maybe I can binary search to find where the added item belongs. Let's say I just added this item here. I could binary search to find it, but then I'm going to have to do a big shift. So I might as well just swap repeatedly until I find the position where the added item x belongs. And now I've restored sorted order. That takes linear time, which is bad. And what we want is somehow the best of these two worlds. Insert is fast for array. Delete is fast for a sorted array. We can't get constant time for both. But we can get log n time for both. We already know how with set AVL trees. But we're going to see a different way to do it today. And the main motivation for a different way to do this is sorting. So I want to define a priority queue sort. So given any data structure that implements a priority queue interface, in particular insert and delete_max, I can make a sorting algorithm. What do I do? Insert all the items, delete all the items. But because when I delete them they come out largest first, I get them in reverse sorted order. Then I could reverse in linear time and I've sorted my items. So we can insert (x) for x in A, or (build(A)), and then repeatedly delete_max. How much time does this algorithm take? I'm going to introduce some notation here. It takes however long it takes to build n items, call that T sub build (n) plus-- sorry-- plus n times the time to do a delete_max. Or we can write this as n times time to do an insert, plus time to do a delete_max. So I'm using these T functions to just abstract what are the running times provided by my data structure that implements this interface. Interface says what's correct is, and these T functions give me my performance bounds. So if I plug in each of these data structures, I get a sorting algorithm. I get AVL sort, I get array sort, I get assorted array sort. What do those look like? It turns out many of these are familiar. So set AVLs take log n per operation. So we get an n log n sorting algorithm out of them, which is insert all of the items into the AVL tree. I don't want to use AVL build because that uses sort, and not allowed to sort in order to implement sort. But we saw how to insert into an AVL tree and keep the thing balanced. So that takes log n each. And then we can find the max, delete it, rebalance, and so on. Total time will be n log n. This is an algorithm we call AVL sort. It's a bit complicated, because AVL trees are complicated. But it gives us optimal comparison bound and log n. Now, what about array sort? So suppose I use an unsorted array. I insert the item. So if I insert the items-- so I'm doing all the insertions here before all the deletions. So what's going to happen is I just insert the items in the original array order. In other words, I just take the array. And then what I do is repeatedly extract the maximum item by searching for it, moving it to the end of the array, and then repeating that process. That sound familiar? That's selection sort from lecture three. So this-- arrays give us selection sort. This is a new way to think about what we were doing way back then. With a sorted array, what are we doing? We insert all the items. That's actually where all the work happens, because we maintain the sorted array. So we start with an empty array. It's sorted. We add an item. OK, it's still sorted. We add a second item, and we swap if we need to in order to sort. In general, when we add an item, we swap it to the left until it's sorted again. That is insertion sort. Kind of cool, this is a unifying framework for three sorting algorithms that we saw before. We didn't actually talk about AVL sort last time, but it was in the notes. And so that is the right part of this table.","68.18620300292969","7","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_4_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"148","What is the max-heap property?"," ! 
dist, numSamples = [], 1000000
for i in range(numSamples):
dist.append(random.gauss(0, 100))
weights = [1/numSamples]*len(dist)
v = pylab.hist(dist, bins = 100,
weights = [1/numSamples]*len(dist))
pylab.xlabel('x')
pylab.ylabel('Relative Frequency')
print('Fraction within ~200 of mean =',
sum(v[0][30:70]))
	

""
","68.01522064208984","8","DPRSearchEngine","3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7_3_pdf","3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7","6.0002","7"
"148","What is the max-heap property?","5 
Lecture 8: Binary Heaps 
Heap Delete Max 
• Can only easily remove last element from dynamic array, but max key is in root of tree 
• So swap item at root node i = 0 with last item at node n − 1 in heap array 
• max heapify down(i): swap root with larger child until Max-Heap Property 
– Check whether Q[i] ≥ Q[j] for j ∈{left(i), right(i)} 
(Max-Heap Property at i) 
– If not, swap Q[i] with Q[j] for child j ∈{left(i), right(i)} with maximum key, and 
recursively max heapify down(j) 
• Correctness: 
– Max-Heap Property guarantees all nodes ≥ descendants, except Q[i] might be < some 
descendants (unless i is a leaf, so we’re done) 
– If swap is necessary, same guarantee is true with Q[j] instead of Q[i] 
• Running time: height of tree, so Θ(log n)! 
Heap Sort 
• Plugging max-heap into priority queue sort gives us a new sorting algorithm 
• Running time is O(n log n) because each insert and delete max takes O(log n) 
• But often include two improvements to this sorting algorithm: 
In-place Priority Queue Sort 
• Max-heap Q is a preﬁx of a larger array A, remember how many items |Q| belong to heap 
• |Q| is initially zero, eventually |A| (after inserts), then zero again (after deletes) 
• insert() absorbs next item in array at index |Q| into heap 
• delete max() moves max item to end, then abandons it by decrementing |Q| 
• In-place priority queue sort with Array is exactly Selection Sort 
• In-place priority queue sort with Sorted Array is exactly Insertion Sort 
• In-place priority queue sort with binary Max Heap is Heap Sort 
","67.3944091796875","9","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_5_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"148","What is the max-heap property?","sorry, delete_max, thank you. You can of course define all of these things for min instead of max. Everything works the same. I just have a hard time remembering which one we're doing. Just don't switch you can't use a max-heap to do delete_min. You can't use a min-heap to do delete_max, but you can use a min-heap to do delete_min. That's fine. So like I said, the only node we really know how to delete is the last leaf on the last level, which is the end of the array. Because that's what arrays can delete efficiently. And what we need to delete is the root item, because that's always the maximum one, which is at the first position in the array. So what do we do? Swap them, our usual trick. I think the cool thing about heaps is we never have to do rotations. We're only going to do swaps, which is something we had to do with trees also-- binary trees. Q[0] with Q of the last item-- great, done. Now we have the last item is the one we want to delete. So we do delete_last, or pop in Python, and boom, we've got-- we've now deleted the maximum item. Of course, we may have also messed up the max-heap property just like we did with insert. So with insert, we were adding a last leaf. Now, what we're doing is swapping the last leaf with the-- I'm pointing at the wrong picture. Let me go back to this tree. What we did is swap item J with A. So the problem is now-- and then we deleted this node. The problem is now that that root node has maybe a very small key. Because the key that's here now is whatever was down here, which is very low in the tree. So intuitively, that's a small value. This is supposed to be the maximum value, and we just put a small value in the root. So what do we do? Heapify down. We're going to take that item and somehow push it down to the tree until the-- down in the tree until max-heap property is satisfied. So this is going to be max_heapify_down. And we will start at position 0, which is the root. And max_heapify_down is going to be a recursive algorithm. So we'll start at some position i. And initially, that's the root. And what we're going to do is look at position i and its two children. So let's say we put a very small value up here, like 0. And let's say we have our children, 5 and 10. We don't know-- maybe I'll swap their order just to be more generic, because that looks like not quite a binary search tree, but we don't know their relative order. But one of them is greater than or equal to the other in some order. And so what would I like to do to fix this local picture? Yeah, I want to swap. And I could swap-- 0 is clearly in the wrong spot. It needs to go lower in the tree. I can swap 0 with 5 or 0 with 10. Which one? 10. I could draw the picture with 5, but it will not be happy. Why 10? We want to do it with the larger one, because then this edge will be happy, and also this edge will be happy. If I swapped 5 up there instead, the 5/10 edge would be unhappy. It wouldn't satisfy the max-heap property. So I can do one swap and fix max-heap property. Except that, again, 0 may be unhappy with its children. 0 was this one item that was in the wrong spot. And so it made it have to go farther down. But 5 will be-- 5 didn't even move. So it's happy. Everything in this subtree is good. What about the parent? Well, if you think about it, because everything was a correct heap before we added 0, or before we put 0 too high, all of these nodes will be greater than or equal to 10 on the ancestor path. And all of these nodes were less than or equal to 10 before, unless you're equal to 5. So that's still true. But you see, this tree is happy. This tree still may be unhappy. 0 still might need to push down farther. That's going to be the recursion. So we check down here. There's a base case, which is if i is a leaf, we're done. Because there's nothing below them. So we satisfy the max-heap property at i because there's no children. Otherwise, let's look at the leaf among the left-- sorry, left not leaf-- among the two children left and right of i. Right if i might not exist. Then ignore it. But among the two children that exist, find the one that has maximum key value, Q[j].key. That was 10 in our example. And then, if these items are out of order, if we do not satisfy-- so greater than would be satisfy. Less than Q[j] would be the opposite of the max-heap property here. If max-heap property is violated, then we fix it by swapping Q[i] with Q[j], and then we recurse on j-- call max_heapify_down of j. That's it. So pretty symmetric. Insert was a little bit simpler, because we only have one parent. Delete_min, because we're pushing down, we have two children. We have to pick one. But there's a clear choice-- the bigger one. And again, this algorithm-- this whole thing-- will take order h time, the height of the tree, which is log n, because our node just sort of bubbles down. At some point, it stops. When it stops, we know the max-heap property was satisfied there. And if you check along the way, by induction, all the other max-heap properties will be satisfied, because they were before. So almost forced what we could do here. The amazing thing is that you can actually maintain a complete binary tree that satisfies the max-heap property. But once you're told that, the algorithm kind of falls out. Because we have an array. The only thing we can do is insert and delete the last item. And so we've got to swap things to there in order-- or out of there in order to make that work. And then, the rest is just checking locally that you can fix the property. Cool. So that's almost it, not quite what we wanted. So we now have log n amortize insert and delete_max in our heap. We did not yet cover linear build. Right now, it's n log n if you insert n times. And we did not yet cover how to make this an in-place sorting algorithm. So let me sketch each of those. I think first is in-place. So how do we make this algorithm in-place? I guess I want that, but I don't need this. So we want to follow priority queue sort. Maybe I do want that. But I don't want to have to grow and shrink my array. I would just like to start with the array itself. So this is in place. So what we're going to do is say, OK, here's my array that I want to sort. That's given to me. That's the input to priority queue sort. And what I'd like is to build a priority queue out of it. Initially, it's empty. And then I want to insert the items one at a time, let's say. So in general, what I'm going to do is maintain that Q is some prefix of A. That's going to be my priority queue. It's going to live in this sub array-- this prefix. So how do I insert a new item? Well, I just increment. So to do an insert, the first step is increment size of Q. Then I will have taken the next item from A and injected into this Q. And conveniently, if we look at our insert code, which is here, the first thing we wanted to do was add an item at the end of the array. So we just did it without any actual work, just conceptual work. We just said, oh, our Q is one bigger. Boom! Now this is at the end of the array. no more amortization, in fact, because we're not ever resizing our array, we're just saying, oh, now Q is a little bit bigger of a prefix. It just absorb the next item of A. Similarly, delete_max is going to, at the end, decrement the size of Q. Why is that OK? Because at the end of our delete_max operation-- not quite at the end, but almost the end-- we deleted the last item from our array. So we just replaced that delete last with a decrement, and that's going to shrink the Q by 1. It has the exact same impact as leading the last item. But now, it's constant time, worst case not amortized. And the result is we never actually build a dynamic array. We just use a portion of A to do it. So what's going to happen is we're going to absorb all the items into the priority queue, and then start kicking them out. As we kick them out, we kick out the largest key item first, and we put it here, then the next largest, then the next largest, and so on. The minimum item is going to be here. And, boom, it's sorted. This is the whole reason I did max-heaps instead of min-heaps, is that in the end, this will be a upward sorted array with the max at the end. Because we always kick out items at the end. We delete the max first. So that is what's normally called heapsort. You can apply this same trick to insertion sort and selection sort, and you actually get the insertion sort and selection sort algorithms that we've seen which operate in prefixes of the array. Cool, so now we have-- we've achieved the y up there, which is n log n sorting algorithm that is in-place. So that was our main goal-- heapsort. Let me very quickly mention you can build a heap in linear time with a clever trick. So if you insert the items one at a time, that would correspond to inserting down the array. And every time I insert an item, I have to walk up the tree. So this would be the sum of the depth of each node. If you do that, you get n log n. This is the sum over i of log i. That turns out to be n log n. It's a log of n factorial. The cool trick is to, instead, imagine adding all the items at once and not heapifying anything, and then heapify up-- sorry, heapify down from the bottom up. So here we're heapifying up. Now, we're going to heapify down. And surprisingly, that's better. Because this is the sum of the heights of the nodes. And that turns out to be linear. It's not obvious. But intuitively, for a depth, this is 0, this is log n, and we've got a whole ton of leaves. So right at the leaf level, you can see, we're paying n log n, right? Because there are n of them, and each one costs log n. Down here, at the leaf level, we're paying constant. Because the height of the leaves are 1. Here, the height of the root is log n. And this is better. Now we're paying a small amount for the thing of which there are many. It's not quite a geometric series, but it turns out this is linear. So that's how you can do linear building heap. To come back to your question about sequence AVL trees, turns out you can get all of the same bounds as heaps, except for the in-place part, by taking a sequence AVL tree, storing the items in an arbitrary order, and augmenting by max, which is a crazy idea. But it also gives you a linear build time. And yeah, there's other fun stuff in your notes. But I'll stop there.","66.68329620361328","10","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_11_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"149","Why is it sufficient to check only the ancestor nodes after an insertion or deletion in an AVL tree?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","76.8663330078125","1","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"149","Why is it sufficient to check only the ancestor nodes after an insertion or deletion in an AVL tree?"," 
 
 
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
  
 
  
 
  
 
 
  
 
 
   
 
 
   
 
 
 
 
TMs and Encodings – review 
A TM has 3 possible outcomes for each input !: 
1. Accept ! (enter ""acc ) 
2. Reject ! by halting (enter ""rej ) 
3. Reject ! by looping (running forever) 
( is T-recognizable if ( = *(,) for some TM ,. 
( is T-decidable if ( = *(,) for some TM decider ,. 
halts on all inputs 
〈/0, /2, … , /4〉 encodes objects /0, /2, … , /4 as a single string. 
Notation for writing a TM , is 
, = “On input ! 
[English description of the algorithm]” 
2 
","74.00984954833984","2","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_2_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"149","Why is it sufficient to check only the ancestor nodes after an insertion or deletion in an AVL tree?","Header for Decision Tree Implementa#on 
6.0002 LECTURE 2 
9 
def maxVal(toConsider, avail): 
    """"""Assumes toConsider a list of items,  
               avail a weight 
       Returns a tuple of the total value of a  
           solution to 0/1 knapsack problem and  
           the items of that solution""""” 
toConsider. Those items that nodes higher up in the tree 
(corresponding to earlier calls in the recursive call stack) 
have not yet considered 
 
avail. The amount of space still available  
","73.96440887451172","3","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_9_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"149","Why is it sufficient to check only the ancestor nodes after an insertion or deletion in an AVL tree?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","73.94903564453125","4","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"149","Why is it sufficient to check only the ancestor nodes after an insertion or deletion in an AVL tree?"," 
 
 
 
 
 
   
  
 
  
 
 
   
 
 
  
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
  
 
 
 
 
 
 
Check-in 8.2 
Recall the Queue Automaton (QA) defined in Pset 2. 
It is similar to a PDA except that it is deterministic 
and it has a queue instead of a stack. 
Let !QA = { &, ( | & is a QA and & accepts (} 
Is !QA decidable? 
(a) Yes, because QA are similar to PDA and !PDA is decidable. 
(b) No, because “yes” would contradict results we now know. 
(c) We don’t have enough information to answer this question. 
8 
Check-in 8.2 
","73.91531372070312","5","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_8_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"149","Why is it sufficient to check only the ancestor nodes after an insertion or deletion in an AVL tree?"," &&%$3$%'9
class Digraph(object): 
 """"""edges is a dict mapping each node to a list of 
    its children""""” 
    def __init__(self): 
self.edges = {} 
    def addNode(self, node): 
if node in self.edges: 
 raise ValueError('Duplicate node') 
else: 
self.edges[node] = [] 
    def addEdge(self, edge): 
src = edge.getSource() 
dest = edge.getDestination() 
if not (src in self.edges and dest in self.edges): 
raise ValueError('Node not in graph') 
self.edges[src].append(dest) 
Q>KKKMN
LS
mapping each node 
list 
","72.76071166992188","6","DPRSearchEngine","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_18_pdf","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3","6.0002","3"
"149","Why is it sufficient to check only the ancestor nodes after an insertion or deletion in an AVL tree?","They take linear time for some of the operations. So the sorting algorithms are not efficient. But they're ones we've seen before, so it's neat to see how they fit in here. They had the-- selection sort and insertion sort had the advantage that they were in place. You just needed a constant number of pointers or indices beyond the array itself. So they're very space efficient. So that was a plus for them. But they take n squared time, so you should never use them, except for n, at most, 100 or something. AVL tree sort is great and then it gets n log n time, probably more complicated than merge sort and you could stick to merge sort. But neither merge sort nor set AVL tree sort are in place. And so the goal of today is to get the best of all those worlds in sorting to get n log n comparisons, which is optimal in the comparison model, but get it to be in place. And that's what we're going to get with binary heaps. We're going to design a data structure that happens to build a little bit faster-- as I mentioned, linear time building. So it's not representing a sorted order in the same way that AVL trees are. But it will be kind of tree-based. It will also be array-based. We're going to get logarithmic time for insert and delete_max. It happens to be amortized, because we use arrays. But the key thing is that it's an in-place data structure. It only consists of an array of the items. And so, when we plug it into our sorting algorithm-- priority queue sort or generic sorting algorithm-- not only do we get n log n performance, but we also get an in-place sorting algorithm. This will be our first and only-- to this class-- n log n in-place sorting algorithm. Cool. That's the goal.","72.15274810791016","7","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_5_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"149","Why is it sufficient to check only the ancestor nodes after an insertion or deletion in an AVL tree?","4 
Lecture 1: Introduction 
1 
def birthday_match(students): 
2 
’’’ 
3 
Find a pair of students with the same birthday 
4 
Input: 
tuple of student (name, bday) tuples 
5 
Output: tuple of student names or None 
6 
’’’ 
7 
n = len(students) 
# O(1) 
8 
record = StaticArray(n) 
# O(n) 
9 
for k in range(n): 
# n 
10 
(name1, bday1) = students[k] 
# O(1) 
11 
# Return pair if bday1 in record 
12 
for i in range(k): 
# k 
13 
(name2, bday2) = record.get_at(i) 
# O(1) 
14 
if bday1 == bday2: 
# O(1) 
15 
return (name1, name2) 
# O(1) 
16 
record.set_at(k, (name1, bday1)) 
# O(1) 
17 
return None 
# O(1) 
Example: Running Time Analysis 
• Two loops: outer k ∈{0, . . . , n − 1}, inner is i ∈{0, . . . , k}
P n−1
• Running time is O(n) + 
k=0 (O(1) + k · O(1)) = O(n2) 
• Quadratic in n is polynomial. Efﬁcient? Use different data structure for record! 
How to Solve an Algorithms Problem 
1. Reduce to a problem you already know (use data structure or algorithm) 
Search Problem (Data Structures) 
Sort Algorithms 
Static Array (L01) 
Insertion Sort (L03) 
Linked List (L02) 
Selection Sort (L03) 
Dynamic Array (L02) 
Merge Sort (L03) 
Sorted Array (L03) 
Counting Sort (L05) 
Direct-Access Array (L04) 
Radix Sort (L05) 
Hash Table (L04) 
AVL Sort (L07) 
Balanced Binary Tree (L06-L07) 
Heap Sort (L08) 
Binary Heap (L08) 
2. Design your own (recursive) algorithm 
• Brute Force 
• Decrease and Conquer 
• Divide and Conquer 
• Dynamic Programming (L15-L19) 
• Greedy / Incremental 
Shortest Path Algorithms 
Breadth First Search (L09) 
DAG Relaxation (L11) 
Depth First Search (L10) 
Topological Sort (L10) 
Bellman-Ford (L12) 
Dijkstra (L13) 
Johnson (L14) 
Floyd-Warshall (L18) 
","72.1225357055664","8","DPRSearchEngine","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_4_pdf","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1","6.006","1"
"149","Why is it sufficient to check only the ancestor nodes after an insertion or deletion in an AVL tree?","&

	
	
	/
def greedy(items, maxCost, keyFunction):
itemsCopy = sorted(items, key = keyFunction,
reverse = True)
result = []
totalValue, totalCost = 0.0, 0.0
for i in range(len(itemsCopy)):
if (totalCost+itemsCopy[i].getCost()) <= maxCost:
result.append(itemsCopy[i])
totalCost += itemsCopy[i].getCost()
totalValue += itemsCopy[i].getValue()
return (result, totalValue) 
	

2
	

","71.90141296386719","9","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_24_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"149","Why is it sufficient to check only the ancestor nodes after an insertion or deletion in an AVL tree?","What's the worst case performance of a hash table? If I have to look up something in a hash table, and I happen to choose a bad hash table-- hash function, what's the worst case here? What? n, right? It's worse than a sorted array, because potentially, I hashed everything that I was storing to the same index in my hash table, and to be able to distinguish between them, I can't do anything more than a linear search. I could store another set's data structure as my chain and do better that way. That's actually how Java does it. They store a data structure we're going to be talking about next week as the chains so that they can get, worst case, log n. But in general, that hash table is only good if we're allowing-- OK, I want this to be expected good, but in the worst case, if I really need that operation to be worst case-- I really can't afford linear time ever for an operation of that kind-- then I don't want to use a hash table. And so on your p set 2, everything we ask you for is worst case, so probably, you don't want to be using hash tables. OK? Yes? AUDIENCE: What does the subscript e mean? JASON KU: What does the subscript e mean? That's great. In this chart, I put a subscript on this is an expected runtime, or an A meaning this is an amortized runtime. At the end, we talked about how, if we had too many things in our hash table, then, as long as we didn't do it too often-- this is a little hand wavey argument, but the same kinds of ideas as the dynamic array-- if, whenever we got a linear-- we are more than a linear factor away from where we are trying-- basically, the fill factor we were trying to be, then we could just completely rebuild the hash table with the new hash function randomly chosen from our hash table with a new size, and we could get amortized bounds. And so that's what Python-- how Python implements dictionaries, or sets, or even objects when it's trying to map keys to different things. So that's hash tables. That's great. The key thing here is, well, actually, if your range of keys is small, or if you as a programmer have the ability to choose the keys that you identify your objects with, you can actually choose that range to be small, to be linear, to be small with respect to your items. And you don't need a hash table. You can just use a direct access array, because if you know your key space is small, that's great. So a lot of C programmers probably would like to do something like that, because they don't have access to-- maybe C++ programmers would have access to their hash table. Any questions on this stuff before we move on? Yeah? AUDIENCE: So why is [INAUDIBLE]? JASON KU: Why is it expected? When I'm building, I could insert-- I'm inserting these things from x 1 by 1 into my hash table. Each of those insert operations-- I'm looking up to see whether that-- an item with that key already exists in my hash table. And so I have to look down the chain to see where it is. However, if I happen to know that all of my keys are unique in my input, all the items I'm trying to store are unique, then I don't have to do that check and I can get worst case linear time. Does that make sense? All right. It's a subtlety, but that's a great question. OK, so today, instead of talking about searching, we're talking about sorting. Last week, we saw a few ways to do sort. Some of them were quadratic-- insertion sort and selection sort-- and then we had one that was n log n. And this thing, n log n, seemed pretty good, but can I do better? Can I do better? Well, what we're going to show at the beginning of this class is, in this comparison model, no. n log n is optimal. And we're going to go through the exact same line of reasoning that we had last week. So in the comparison model, what did we use when we were trying to make this argument that any comparison model algorithm was going to take at least log n time? What we did was we said, OK, I can think of any model in the comparison model-- any algorithm in the comparison model as kind of this-- some comparisons happen. They branch in a binary sense, but you could have it generalized to any constant branching factor. But for our purposes, binary's fine. And what we said was that there were at least n outputs-- really n plus 1, but-- at least order n outputs. And we showed that-- or we argued to you that the height of this tree had to be at least log n-- log the number of leaves. It had to be at least log the number of leaves. That was the height of the decision tree. And if this decision tree represented a search algorithm, I had to walk down and perform these comparisons in order, reach a leaf where I would output something. If the minimum height of any binary tree on a linear number of leaves is log n, then any algorithm in the comparison model also has to take log n time, because it has to do that many comparisons to differentiate between all possible outputs. Does that make sense? All right. So in the sort problem, how many possible outputs are there?","71.61143493652344","10","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_4_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"150","Does Depth-First Search (DFS) ever visit a vertex that is not reachable from the source?","search-- BFS, for those in the know. Breadth-first search is an algorithm. And the reason we use the word breadth is because it's kind of, remember, we talked about level sets last time because we talked about breadth-first search in the context of computing shortest paths. And in particular, we have our source node all the way on the left-hand side. And then breadth-first search constructed all the nodes that were distance 1 away. Right. That's the first level set, and then all the distance 2 away, and then all the distance 3 away, and so on. So in particular, the level set L3 isn't visited until we're completely done with level set L2.","74.17295837402344","1","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_7_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"150","Does Depth-First Search (DFS) ever visit a vertex that is not reachable from the source?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","73.6655044555664","2","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"150","Does Depth-First Search (DFS) ever visit a vertex that is not reachable from the source?"," &&%$3$%'9
class Digraph(object): 
 """"""edges is a dict mapping each node to a list of 
    its children""""” 
    def __init__(self): 
self.edges = {} 
    def addNode(self, node): 
if node in self.edges: 
 raise ValueError('Duplicate node') 
else: 
self.edges[node] = [] 
    def addEdge(self, edge): 
src = edge.getSource() 
dest = edge.getDestination() 
if not (src in self.edges and dest in self.edges): 
raise ValueError('Node not in graph') 
self.edges[src].append(dest) 
Q>KKKMN
LS
mapping each node 
list 
","73.44021606445312","3","DPRSearchEngine","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_18_pdf","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3","6.0002","3"
"150","Does Depth-First Search (DFS) ever visit a vertex that is not reachable from the source?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 10: Depth-First Search 
Lecture 10: Depth-First Search 
Previously 
• Graph deﬁnitions (directed/undirected, simple, neighbors, degree) 
• Graph representations (Set mapping vertices to adjacency lists) 
• Paths and simple paths, path length, distance, shortest path 
• Graph Path Problems 
– Single Pair Reachability(G,s,t) 
– Single Source Reachability(G,s) 
– Single Pair Shortest Path(G,s,t) 
– Single Source Shortest Paths(G,s) (SSSP) 
• Breadth-First Search (BFS) 
– algorithm that solves Single Source Shortest Paths 
– with appropriate data structures, runs in O(|V | + |E|) time (linear in input size) 
Examples 
G1 
a 
d 
b 
e 
c 
f 
G2 
a 
d 
b 
e 
c 
f 
","72.53700256347656","4","DPRSearchEngine","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10_1_pdf","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10","6.006","10"
"150","Does Depth-First Search (DFS) ever visit a vertex that is not reachable from the source?","§ Time based on number of nodes generated 
§ Number of levels is number of items to choose from 
§ Number of nodes at level i is 2i 
§ So, if there are n items the number of nodes is 
◦ ∑𝑖=0↑𝑖=𝑛▒​2↑𝑖   
◦ I.e., O(​2↑𝑛+1 ) 
§ An obvious op<miza<on: don’t explore parts of tree 
that violate constraint (e.g., too many calories) 
◦ Doesn’t change complexity 
§ Does this mean that brute force is never useful? 
◦ Let’s give it a try 
Computa#onal Complexity 
6.0002 LECTURE 2 
8 
","72.18556213378906","5","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_8_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"150","Does Depth-First Search (DFS) ever visit a vertex that is not reachable from the source?","2 
Lecture 10: Depth-First Search 
Depth-First Search (DFS) 
• Searches a graph from a vertex s, similar to BFS 
• Solves Single Source Reachability, not SSSP. Useful for solving other problems (later!) 
• Return (not necessarily shortest) parent tree of parent pointers back to s 
• Idea! Visit outgoing adjacencies recursively, but never revisit a vertex 
• i.e., follow any path until you get stuck, backtrack until ﬁnding an unexplored path to explore 
• P (s) = None, then run visit(s), where 
• visit(u) : 
– for every v ∈ Adj(u) that does not appear in P : 
∗ set P (v) = u and recursively call visit(v) 
– (DFS ﬁnishes visiting vertex u, for use later!) 
• Example: Run DFS on G1 and/or G2 from a 
Correctness 
• Claim: DFS visits v and correctly sets P (v) for every vertex v reachable from s 
• Proof: induct on k, for claim on only vertices within distance k from s 
– Base case (k = 0): P (s) is set correctly for s and s is visited 
– Inductive step: Consider vertex v with δ(s, v) = k0 + 1 
– Consider vertex u, the second to last vertex on some shortest path from s to v 
– By induction, since δ(s, u) = k0, DFS visits u and sets P (u) correctly 
– While visiting u, DFS considers v ∈ Adj(u) 
– Either v is in P , so has already been visited, or v will be visited while visiting u 
– In either case, v will be visited by DFS and will be added correctly to P 
Running Time 
• Algorithm visits each vertex u at most once and spends O(1) time for each v ∈ Adj(u) 
P 
• Work upper bounded by O(1) × 
deg(u) = O(|E|)
u∈V 
• Unlike BFS, not returning a distance for each vertex, so DFS runs in O(|E|) time 
","71.97199249267578","6","DPRSearchEngine","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10_2_pdf","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10","6.006","10"
"150","Does Depth-First Search (DFS) ever visit a vertex that is not reachable from the source?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 4: Hashing 
Lecture 4: Hashing 
Review 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
• Idea! Want faster search and dynamic operations. Can we find(k) faster than Θ(log n)? 
• Answer is no (lower bound)! (But actually, yes...!?) 
Comparison Model 
• In this model, assume algorithm can only differentiate items via comparisons 
• Comparable items: black boxes only supporting comparisons between pairs 
• Comparisons are <, ≤, >, ≥, =, =6 , outputs are binary: True or False 
• Goal: Store a set of n comparable items, support find(k) operation 
• Running time is lower bounded by # comparisons performed, so count comparisons! 
Decision Tree 
• Any algorithm can be viewed as a decision tree of operations performed 
• An internal node represents a binary comparison, branching either True or False 
• For a comparison algorithm, the decision tree is binary (draw example) 
• A leaf represents algorithm termination, resulting in an algorithm output 
• A root-to-leaf path represents an execution of the algorithm on some input 
• Need at least one leaf for each algorithm output, so search requires ≥ n + 1 leaves 
","71.30426025390625","7","DPRSearchEngine","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_1_pdf","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4","6.006","4"
"150","Does Depth-First Search (DFS) ever visit a vertex that is not reachable from the source?","Right. Now, does DFS ever visit a vertex that is not reachable from the source? Well, the answer is no because all I ever do is recursively call on my neighbors. And so kind of by definition, if I'm not reachable, DFS will never see it. So if I think about my runtime carefully, it's not quite the same as breadth-first search. Remember that breadth-first search took v plus e time. In depth-first search, it just takes order e time because I'm expanding outward from the source vertex, hitting every edge adjacent to every vertex that I've seen so far. But I never reach a vertex that I haven't-- that isn't reachable. Right? And so because this only ever touches every edge one time, we're in good shape. And I see a question here. Yeah. AUDIENCE: Does BFS reach vertices that are not reachable? JUSTIN SOLOMON: Does BFS reach vertices that are not reachable? I guess not, now that you mention it. But at least in my boring proof of order v time last time, our very first step of BFS, reserve space proportional to v, which is enough to already make that runtime correct. Good question. Yeah. So I guess the way that we've talked about it where you can stretch one little set after a time, if you think of that as reachability, then no. It doesn't reach it in the for loop. But just by construction, when we started we already took the time that we're talking about here. So notice these run times aren't exactly the same. So for example, if my graph has no edges, BFS still is going to take time because it still has to take order v time, at least in the sort of brain-dead way that we've implemented it last time. Obviously, in that case, we could probably do something better. Whereas the way that we've defined the DFS algorithm, it only takes edge time. I see confusion on my instructor's face. No? OK. Good. The one thing to notice is that these are algorithms for slightly different tasks in some sense. The way that we wrote down breadth-first search last time, conveniently, it gives us the shortest path. There are breadth-first search algorithms that doesn't. I think in this class we kind of think of breadth-first search-- we motivate it in terms of the shortest path problem. But it's just kind of a strategy of working outwards from a vertex. Whereas here, the way we've written down depth-first search, there's no reason why the path that we get should be the shortest. Right? So to think of a really extreme example, let's say that I have a cycle graph. So I get a big loop like this. Let's say that I do depth-first search starting from this vertex. Well, what will happen? Well, this guy will call its neighbor recursively, who will then call its neighbor recursively, who will then call his neighbor recursively, and so on. So of course, when I do depth-first search, when I get to this vertex, there's a chain of 1, 2, 3, 4 vertices behind it. Is that the shortest path from the source to the target here? Well, clearly not. Right? I could have traversed that edge. I just chose not to. OK. So that's the depth-first search algorithm. It's just essentially a recursive strategy where I traverse all my neighbors, and each of my neighbors traverses their neighbors, and so on. OK. So why might we want to use this algorithm? Well, we've already solved the reachability problem. So let's solve a few more things using the same basic strategy here. So there's some notions that we've sort of-- actually, in some sense, already used in the lecture here. But we might as well call them out","71.27899932861328","8","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_11_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"150","Does Depth-First Search (DFS) ever visit a vertex that is not reachable from the source?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","70.79971313476562","9","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"150","Does Depth-First Search (DFS) ever visit a vertex that is not reachable from the source?"," 
 
 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) Lecture 
General Unweighted 
BFS 
|V | + |E| L09 
L11 
L12 
L13 (Today!) 
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Any 
Bellman-Ford 
Dijkstra 
|V | · |E|
General Non-negative 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 13: Dijkstra’s Algorithm 
Lecture 13: Dijkstra’s Algorithm 
Review 
• Single-Source Shortest Paths on weighted graphs 
• Previously: O(|V | + |E|)-time algorithms for small positive weights or DAGs 
• Last time: Bellman-Ford, O(|V ||E|)-time algorithm for general graphs with negative weights 
• Today: faster for general graphs with non-negative edge weights, i.e., for e ∈ E, w(e) ≥ 0 
|V | log |V | + |E| 
Non-negative Edge Weights 
• Idea! Generalize BFS approach to weighted graphs: 
– Grow a sphere centered at source s 
– Repeatedly explore closer vertices before further ones 
– But how to explore closer vertices if you don’t know distances beforehand? 
:( 
• Observation 1: If weights non-negative, monotonic distance increase along shortest paths 
– i.e., if vertex u appears on a shortest path from s to v, then δ(s, u) ≤ δ(s, v) 
– Let Vx ⊂ V be the subset of vertices reachable within distance ≤ x from s 
– If v ∈ Vx, then any shortest path from s to v only contains vertices from Vx 
– Perhaps grow Vx one vertex at a time! (but growing for every x is slow if weights large) 
• Observation 2: Can solve SSSP fast if given order of vertices in increasing distance from s 
– Remove edges that go against this order (since cannot participate in shortest paths) 
– May still have cycles if zero-weight edges: repeatedly collapse into single vertices 
– Compute δ(s, v) for each v ∈ V using DAG relaxation in O(|V | + |E|) time 
","70.2092514038086","10","DPRSearchEngine","d819e7f4568aced8d5b59e03db6c7b67_MIT6_006S20_lec13_1_pdf","d819e7f4568aced8d5b59e03db6c7b67_MIT6_006S20_lec13","6.006","13"
"151","How does memoization change the time complexity of computing Fibonacci numbers?","and then store it in the memo and return it. It's the same old recursive thing we did before but with the memo. Notice, by the way, that I'm using exceptions not as an error handling mechanism, really, but just as a flow of control. To me, this is cleaner than writing code that says, if this is in the keys, then do this, otherwise, do that. It's slightly fewer lines of code, and for me, at least, easier to read to use try-except for this sort of thing. Let's see what happens if we run this one. Get rid of the slow fib and we'll run fastFib. Wow. We're already done with fib 120. Pretty amazing, considering last time we got stuck around 40. It really works, this memoization trick. An enormous difference. When can you use it? It's not that memorization is a magic bullet that will solve all problems. The problems it can solve, it can help with, really, is the right thing. And by the way, as we'll see, it finds an optimal solution, not an approximation. Problems have two things called optimal substructure, overlapping subproblems. What are these mean? We have optimal substructure when","73.57524871826172","1","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_10_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"151","How does memoization change the time complexity of computing Fibonacci numbers?","Actually, what a modern computer is addressed in is bytes, collections of 8 bits. So there's an address I have for every 8 bits in memory-- consecutive 8 bits in memory. And so if I want to pull something in into the CPU, I give it an address. It'll take some chunk, and bring it into the CPU, operate on it, and spit it back. How big is that chunk? This goes to the answer that you were asking, which-- or saying, which is it's some sequence of some fixed number of bits, which we call a word. A word is how big of a chunk that the CPU can take in from memory at a time and operate on. In your computers, how big is that word size? 64 bits-- that's how much I can operate on at a time. When I was growing up, when I was your age, my word size was 32 bits. And that actually was a problem for my computer, because in order for me to be able to read to address in memory, I need to be able to store that address in my CPU, in a word. But if I have 32 bits, how many different addresses can I address? I have a limitation on the memory addresses I can address, right? So how many different memory addresses can I address with 32 bits? 2 to the 32, right? That makes sense. Well, if you do that calculation out, how big of a hard disk can I have to access? It's about 4 gigabytes. So in my day, all the hard drives were limited to being partitioned-- even if you had a bigger than 4 gigabyte hard drive, I had to partition it into these 4 gigabyte chunks, which","73.33699035644531","2","DPRSearchEngine","ZA-tUyM_y7s.en-j3PyPqV-e1s_8_mp4","ZA-tUyM_y7s.en-j3PyPqV-e1s","6.006","1"
"151","How does memoization change the time complexity of computing Fibonacci numbers?","we can turn this into code. We define f of i. And it says am I in a base case? If so, return this. Otherwise, do this recursive call. That's our recursive algorithm. But we're going to do a little more now. And first we're going to check whether this sub problem that we're trying to solve has already been solved. And if so, we return that storage solution. That's the easy case, but it might not exist. And then we'll compute it in the usual way. So what the code then would look like to define f of i is first we check is i in our data structure. This is usually called the memo. So we say, is this sub-problem-- is i in my memo data structure? If so just return memo of i. Done. No recursion necessary. Otherwise, check if I'm a base case. If so, done. Otherwise, recurse. So recursively call f of i minus 1 and f of i minus 2. And in this recursion, we can see that after we call f of i minus 1, in fact, it will have already computed f of i minus 2. So while this call is recursive, this one will immediately terminate because i minus 2 will already be in the memo table. And so if you think about what happens, in fact, we'll just have recursion down the left branch of this thing. And all the right branches will be free. We can just look things up in the memo table. So what is the overall running time? For Fibonacci, this should be order n. Why is it order n? This is number of additions. Come back to that in a second. In general, the way to analyze an algorithm like this that uses memoization is we just count how many different sub-problems are there? Because once we solve the sub-problem, we will never solve it again. That's the whole idea of a memo table. So we will solve each sub-problem at most once. And so we just need to count, how much time does it take to solve every sub-problem? And here you can see it's constant. Either it's a base case and it takes constant time or we recursively call these things. But those are different sub-problems. So we're going to count those later. And then the work that's actually done by this recurrence is a single addition. So in fact, it's n additions. To compute fn would be exactly n additions. So it turns out to be very nice closed form in this case. It should be exactly n sub problems to compute f of n because we started as dot at 1. And each one has one additional-- I guess not the base case. Maybe n minus 2. OK. Definitely order n. Now, there's this one subtlety which-- let's forget about dynamic programming for a moment","73.236572265625","3","DPRSearchEngine","r4-cftqTcdI.en-j3PyPqV-e1s_7_mp4","r4-cftqTcdI.en-j3PyPqV-e1s","6.006","15"
"151","How does memoization change the time complexity of computing Fibonacci numbers?","This column is what we would get with the original recursive implementation where we didn't use a memo. And it was therefore 2 to the length of items. And as you can see, it gets really big or, as we say at the end, huge. But the number of calls grows incredibly slowly for the dynamic programming solution. In the beginning it's worth Oh, well. But by the time we get to the last number I wrote, we're looking at 43,000 versus some really big number I don't know how to pronounce-- 18 somethings. Incredible improvement in performance. And then at the end, it's a number we couldn't fit on the slide, even in tiny font. And yet, only 703,000 calls. How can this be? We know the problem is inherently exponential. Have we overturned the laws of the universe? Is dynamic programming a miracle in the liturgical sense? No. But the thing I want you to carry away is that computational complexity can be a very subtle notion. The running time of fastMaxVal is governed by the number of distinct pairs that we might be able to use as keys in the memo-- toConsider and available. The number of possible values of toConsider is small. It's bounded by the length of the items. If I have a 100 items, it's 0, 1, 2, up to a 100. The possible values of available weight is harder to characterize. But it's bounded by the number of distinct sums of weights you can get. If I start with 750 calories left, what are the possibilities? Well, in fact, in this case, maybe we can take only 750 because we're using with units. So it's small. But it's actually smaller than that because it has to do with the combinations of ways I can add up the units I have. I know this is complicated. It's not worth my going through the details in the lectures. It's covered in considerable detail in the assigned reading. Quickly summarizing lectures 1 and 2,","72.02023315429688","4","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_14_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"151","How does memoization change the time complexity of computing Fibonacci numbers?","talking about the word ram model of computation. A question here that usually doesn't matter in this class. Usually we assume additions take constant time. And we usually do that because it's usually true. And in general, our model is the w bit additions-- where w is our machine word size-- takes constant time. But for this problem and this problem only, pretty much, for Fibonacci numbers, I happen to know that the Fibonacci numbers grow exponentially. So to write them down actually requires theta n bits because they are some constant to the n power. And so they're actually really big . n is probably bigger than w. Usually you think of problems that are much bigger than 64 or whatever your word size happens to be. We do assume that w is at least log n. But n is probably bigger than w. It might be bigger or smaller. We don't know. And in general, to do an n bit addition-- these are n bit additions-- is going to take ceiling of n over w time. So in the end, we will spend this times n, because we have to do that, many of them, which is n plus n squared over w time. So a bit of a weird running time. But it's polynomial, whereas this original recursive algorithm was exponential here. Using this one simple idea of just remembering the work we've done, suddenly this exponential time algorithm becomes polynomial. Why? Because we have few sub problems. We had n sub problems. And for each sub problem, we could write a recurrence relation that if we already knew the solutions to smaller sub problems, we could compute this bigger problem very efficiently. This happened to be constant time or constant additions. n over w time. But as long as this is polynomial and this is polynomial, we're happy, because we have this nice formula that the time it takes is, at most, the sum over all sub problems of the relation time. So I'm referring to sub problems, like a number of them and the time it takes to evaluate this, ignoring the recursive calls. That's important. This is the non recursive part. In the notes, I call this non-recursive work. So this formula gives us a way to bound the running time of one of these algorithms if we use memoization. Without memoization, this is not true, Fibonacci to exponential time. But if we add memoization, we know that we only solve each sub-problem once. And so we just need to see, for each one, how much did it cost me to compute it, assuming all the recursion work is free, because that's already taken into account by the summation. So in particular, this summation is at most the number of sub-problems times the time per sub-problem,","71.09957122802734","5","DPRSearchEngine","r4-cftqTcdI.en-j3PyPqV-e1s_8_mp4","r4-cftqTcdI.en-j3PyPqV-e1s","6.006","15"
"151","How does memoization change the time complexity of computing Fibonacci numbers?"," 
Using a Memo to Compute Fibonnaci 
6.0002 LECTURE 2 
19 
def fastFib(n, memo = {}): 
    """"""Assumes n is an int >= 0, memo used only by 
recursive calls 
Returns Fibonacci of n"""""" 
    if n == 0 or n == 1: 
return 1 
    try: 
return memo[n] 
    except KeyError: 
result = fastFib(n-1, memo) +\\ 
fastFib(n-2, memo) 
memo[n] = result 
return result 
","71.041015625","6","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_19_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"151","How does memoization change the time complexity of computing Fibonacci numbers?","but this is generally what we analyze algorithms with respect to. OK? But you'll notice that my CPU is only built to operate on a constant amount of information at once-- generally, two words in memory. An operation produces a third one, and I spit it out. It takes a constant amount of time to operate on a constant amount of memory. If I want to operate on a linear amount of memory-- n things-- how long is that going to take? If I just want to read everything in that thing, it's going to take me linear time, because I have to read every part of that thing. OK, so in general, what we're going to do for the first half of this class mostly-- first eight lectures, anyway-- is talk about data structures. And it's going to be concerned about not operating on constant amount of data at a time, like our CPU is doing, but instead, what it's going to do is operate on-- store a large amount of data and support different operations on that data. So if I had a record that I want to maintain to store those birthdays that we had before, I might use something like a static array, which you guys maybe are not familiar with, if you have been working in Python is your only programming language. Python has a lot of really interesting data structures, like a list, and a set, and a dictionary, and all these kinds of things that are actually not in this model. There's actually a lot of code between you and the computer, and it's not always clear how much time that interface is taking. And so what we're going to do starting on Thursday is talk about ways of storing a non-constant amount of information to make operations on that information faster. So just before you go, I just want to give you a quick overview of the class. To solve an algorithms class-- an algorithm problem in this class, we essentially have two different strategies. We can either reduced to using the solution to a problem we know how to solve, or we can design our own algorithm, which is going to be recursive in nature. We're going to either put stuff in the data structure and solve a sorting problem, or search in a graph. And then, to design a recursive algorithm, we have various design paradigms. This is all in your notes, but this is essentially the structure of the class. We're going to spend quiz 1, the first eight lectures on data structures and sorting. Second quiz will be on shortest paths, algorithms, and graphs, and then the last one will be on dynamic programming. OK, that's the end of the first lecture. Thanks for coming.","70.6746597290039","7","DPRSearchEngine","ZA-tUyM_y7s.en-j3PyPqV-e1s_11_mp4","ZA-tUyM_y7s.en-j3PyPqV-e1s","6.006","1"
"151","How does memoization change the time complexity of computing Fibonacci numbers?","which, I think, most of us would agree was not a very big number. And let's look what's going on here. If you look at this, what in some sense seems really stupid about it? What is it doing that a rational person would not want to do if they could avoid it? It's bad enough to do something once. But to do the same thing over and over again is really wasteful. And if we look at this, we'll see, for example, that fib 4 is being computed here, and fib 4 is being computed here. Fib 3 is being considered here, and here, and here. And do you think we'll get a different answer for fib 3 in one place when we get it in the other place? You sure hope not. So you think, well, what should we do about this? How would we go about avoiding doing the same work over and over again? And there's kind of an obvious answer, and that answer is at the heart of dynamic programming. What's the answer? AUDIENCE: [INAUDIBLE] JOHN GUTTAG: Exactly. And I'm really happy that someone in the front row answered the question because I can throw it that far. You store the answer and then look it up when you need it. Because we know that we can look things up very quickly. Dictionary, despite what Eric said in his lecture, almost all the time works in constant time if you make it big enough, and it usually is in Python. We'll see later in the term how to do that trick. So you store it and then you'd never have to compute it again. And that's the basic trick behind dynamic programming. And it's something called memoization, as in you create a memo and you store it in the memo. So we see this here. Notice that what we're doing is trading time for space. It takes some space to store the old results, but negligible related to the time we save. So here's the trick. We're going to create a table to record what we've done. And then before computing fib of x, we'll check if the value has already been computed. If so, we just look it up and return it. Otherwise, we'll compute it-- it's the first time-- and store it in the table. Here is a fast implementation of Fibonacci that does that. It looks like the old one, except it's got an extra argument-- memo-- which is a dictionary. The first time we call it, the memo will be empty. It tries to return the value in the memo. If it's not there, an exception will get raised, we know that.","70.11972045898438","8","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_9_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"151","How does memoization change the time complexity of computing Fibonacci numbers?","3 
Lecture 15: Recursive Algorithms 
Re-using Subproblem Solutions 
• Draw subproblem dependencies as a DAG 
• To solve, either: 
– Top down: record subproblem solutions in a memo and re-use 
(recursion + memoization) 
– Bottom up: solve subproblems in topological sort order (usually via loops) 
• For Fibonacci, n + 1 subproblems (vertices) and < 2n dependencies (edges) 
• Time to compute is then O(n) additions 
1 
# recursive solution (top down) 
2 
def fib(n): 
3 
memo = {} 
4 
def F(i): 
5 
if i < 2: return i 
# base cases 
6 
if i not in memo: 
# check memo 
7 
memo[i] = F(i - 1) + F(i - 2) 
# relation 
8 
return memo[i] 
9 
return F(n) 
# original 
1 
# iterative solution (bottom up) 
2 
def fib(n): 
3 
F = {} 
4 
F[0], F[1] = 0, 1 
# base cases 
5 
for i in range(2, n + 1): 
# topological order 
6 
F[i] = F[i - 1] + F[i - 2] 
# relation 
7 
return F[n] 
# original 
• A subtlety is that Fibonacci numbers grow to Θ(n) bits long, potentially ≫ word size w 
• Each addition costs O(dn/we) time 
• So total cost is O(ndn/we) = O(n + n2/w) time 
","70.10598754882812","9","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_3_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"151","How does memoization change the time complexity of computing Fibonacci numbers?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 1: Introduction 
Lecture 1: Introduction 
The goal of this class is to teach you to solve computation problems, and to communicate that 
your solutions are correct and efﬁcient. 
Problem 
• Binary relation from problem inputs to correct outputs 
• Usually don’t specify every correct output for all inputs (too many!) 
• Provide a veriﬁable predicate (a property) that correct outputs must satisfy 
• 6.006 studies problems on large general input spaces 
• Not general: small input instance 
– Example: In this room, is there a pair of students with same birthday? 
• General: arbitrarily large inputs 
– Example: Given any set of n students, is there a pair of students with same birthday? 
– If birthday is just one of 365, for n > 365, answer always true by pigeon-hole 
– Assume resolution of possible birthdays exceeds n (include year, time, etc.) 
Algorithm 
• Procedure mapping each input to a single output (deterministic) 
• Algorithm solves a problem if it returns a correct output for every problem input 
• Example: An algorithm to solve birthday matching 
– Maintain a record of names and birthdays (initially empty) 
– Interview each student in some order 
∗ If birthday exists in record, return found pair! 
∗ Else add name and birthday to record 
– Return None if last student interviewed without success 
","69.97786712646484","10","DPRSearchEngine","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_1_pdf","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1","6.006","1"
"152","What is a weighted graph?","So here's an example of a weighted graph G. And I've labeled, in red, weights for each of these edges. This is a directed graph on eight vertices. And I've got an integer associated with each edge. You'll notice, some of them are positive, some of them are negative. It's OK to be zero as well. It's just any integer edge weight here. So generally we're going to be-- along with our graph G, we're going to be given a weight function that maps the edges of G to, we're going to say, integers, in this class anyway. In other contexts, in mathematics, you might have these be real numbers. But in this class, we're going to deal with integers. So each edge, if you have an edge, we're going to say this is the edge weight-- the weight of this edge e, from e. Sometimes, if this edge e is u, v, we might sometimes say the weight from u to v, since we have a simple graph that's unambiguous. All right, so but this is just talking about our notation. So in general, for example, the weight from vertex b to f in this graph is what? Can someone tell me? AUDIENCE: Minus 4. JASON KU: Minus 4, right? It's right here. And I'll be consistent with my coloring, because I've got colored chalk today. Minus 4. Happiness.","77.97850799560547","1","DPRSearchEngine","5cF5Bgv59Sc.en-j3PyPqV-e1s_3_mp4","5cF5Bgv59Sc.en-j3PyPqV-e1s","6.006","11"
"152","What is a weighted graph?","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","77.01953125","2","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"152","What is a weighted graph?","It's not really complicated. Instead of having a single source, we are essentially wanting to, given an input-- this is our weighted graph, where we've got a graph V, E, and we've got a weight function from the edges to the integers. This is our general weighted graph. We want our output to be something like, the shortest path distance from u to v for every u and v in our vortex set. That's what we want to return. Now, there's one caveat here that, if there's a negative weight cycle in our graph-- in other words, if any of these delta u, v's is minus infinity,","75.60597229003906","3","DPRSearchEngine","EmSmaW-ud6A.en-j3PyPqV-e1s_2_mp4","EmSmaW-ud6A.en-j3PyPqV-e1s","6.006","14"
"152","What is a weighted graph?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 11: Weighted Shortest Paths 
Lecture 11: Weighted Shortest Paths 
Review 
• Single-Source Shortest Paths with BFS in O(|V | + |E|) time (return distance per vertex) 
• Single-Source Reachability with BFS or DFS in O(|E|) time (return only reachable vertices) 
• Connected components with Full-BFS or Full-DFS in O(|V | + |E|) time 
• Topological Sort of a DAG with Full-DFS in O(|V | + |E|) time 
• Previously: distance = number of edges in path Today: generalize meaning of distance 
Weighted Graphs 
• A weighted graph is a graph G = (V, E) together with a weight function w : E → Z 
• i.e., assigns each edge e = (u, v) ∈ E an integer weight: w(e) = w(u, v) 
• Many applications for edge weights in a graph: 
– distances in road network 
– latency in network connections 
– strength of a relationship in a social network 
• Two common ways to represent weights computationally: 
– Inside graph representation: store edge weight with each vertex in adjacency lists 
– Store separate Set data structure mapping each edge to its weight 
• We assume a representation that allows querying the weight of an edge in O(1) time 
Examples 
G1 
G2 
a 
e 
b 
f 
c 
g 
d 
h 
6 
8 
−2 
5 
9 
−5 
7 
3 
2 
−1 
−4 
1 
4 
a 
e 
b 
f 
c 
g 
d 
h 
6 
8 
−2 
5 
9 
−5 
7 
3 
2 
−1 
−4 
1 
4 
","74.30237579345703","4","DPRSearchEngine","aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11_1_pdf","aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11","6.006","11"
"152","What is a weighted graph?","Minimum Spanning Tree-- so I'm trying to find a tree connecting all of the vertices in a connected component of my graph. And I'm trying to find-- in a weighted graph, I'm trying to find the spanning tree that has minimum total weight. So that's a problem-- a fundamental problem in weighted-graph algorithms. They've solved this via a greedy algorithm. And network flows and I guess cuts. So this is-- what is this? This is, I'm given a weighted graph. Basically, each of the weights correspond to a capacity. I could push water through along this edge. And I may be given a source vertex and a sink vertex. And I want to say, I want to shove water through the source vertex along the edges with their various capacities. And I'll get some amount of water on the other end in the source. So the question is, what's the most amount of water that I can push through this? Well, I could build that pipe network with the different things and just do this experimentally. I just stick a bunch of-- maybe-- I'm a mechanical engineer, so that maybe makes sense to me. But you want to be able to just look at those numbers and be able to tell me how much water can I push through. That's what the max flow in a network is talking about.","73.86944580078125","5","DPRSearchEngine","2NMtS1ecb3o.en-j3PyPqV-e1s_7_mp4","2NMtS1ecb3o.en-j3PyPqV-e1s","6.006","20"
"152","What is a weighted graph?","And that's cycle detection. So there's a bit of an exercise left to the reader here. So the problem that we're looking for now is that we're given a directed graph. There's a G in graph, in case you're wondering. But now, we don't know if it's a DAG or not. And so the question that we're trying to ask is, does there exist a cycle in our directed acyclic graph? So we're just given our graph, and we want to know, can we do this? Let's think through the logic of this a bit. So what do we know? We know that if our graph were a DAG, then I could call DGS, get the ordering out, and then I guess flip its ordering backwards. So I could compute the reverse finishing order. And it would give me a topological order of my graph. So if I were a DAG, I would get a topological order when I call DFS. So let's say that I ran DFS. I got whatever ordering I got. And now I found an edge the points in the wrong direction. I can just double check my list of edges, and I find one that does not respect the relationship that I see in the second bullet point here. Can my graph be a DAG? No. Because if my graph were a DAG, the algorithm would work. I just proved it to you. Right? So if my graph were a DAG, then I could do reverse finishing order. And what I would get back is a topological order. So if I found a certificate that my order wasn't topological, something went wrong, and the only thing that could go wrong is that my graph isn't a DAG. Yeah. Isn't a DAG. In fact, sort of an exercise left to the reader and/or to your section-- do we still have section? I think we do, as of now-- is that this is an if and only if, meaning that the only time that you even have a topological ordering in your graph is if your graph is a DAG. This is a really easy fact to sanity check, by the way. This is not like, a particularly challenging problem. But you should think through it because it's a good exercise to make sure you understand the definitions, which is to say that if you have a topological order, your graph is a DAG. If you don't have a topological order, your graph isn't a DAG. So in other words, we secretly gave you an algorithm for checking if a graph is a DAG at all. Right? What could I do? I could compute reverse finishing order. Check if it obeys the relationship on the second bullet point here for every edge. And if it does, then we're in good shape. My graph is a DAG. If it doesn't, something went wrong. And the only thing that could have gone wrong is not being a DAG. OK. So in other words, secretly we just solved-- well, I guess the way that I've written it here, we've solved the cycle detection problem here, which is to say that, well, I have a cycle if and only if I'm not a DAG, which I can check using this technique. Of course, the word ""detection"" here probably means that I actually want to find that cycle, and I haven't told you how to do that yet. All we know how to do so far is say, like, somewhere in this graph there's a cycle. And that's not so good. So we can do one additional piece of information in the two minutes we have remaining to sort of complete our story here, which is to modify our algorithm ever so slightly to not only say thumbs up, thumbs down, is there a cycle in this graph, but also to actually return the vertices as a cycle. And here's the property that we're going to do that, which is following, which is that if G contains a cycle, right, then full DFS will traverse an edge from a vertex v to some ancestor of v. I guess we haven't carefully defined the term ""ancestor"" here. Essentially, if you think of the sort of the running of the DFS algorithm, then an ancestor is like something that appears in the recursive call tree before I got to v. OK. So how could we prove that? Well, let's take a cycle. And we'll give it a name. In particular, we'll say that it's a cycle from v0 v1 to vk. And then it's a cycle, so it goes back to v0. OK. And I can order this cycle any way I want. Notice that if I permute the vertices in this list in a cyclical way, meaning that I take the last few of them and stick them at the beginning of the list, it's still a cycle. That's the nice thing about cycles. So in particular, without loss of generality, we're going to assume that v0 is the first vertex visited by DFS. What does that mean? That means, like, when I do my DFS algorithm making all these recursive calls, the very first vertex to be touched by this technique is v0. OK. Well, now what's going to end up happening? Well, think about the recursive call tree starting at v0. By the time that completes, anything that's reachable from v0 is also going to be complete. Do you see that? So for instance, v0 somewhere in its call tree might call v2. And notice that v2 was not already visited. So in fact, it will. For v1 I got to call v2 and so on. And in particular, we're going to get all the way to vertex k. Right? So in other words, we're going to visit a vertex vk. And notice what's going to happen. So remember our algorithm. In fact, we should probably just put it up on the screen would be easier than talking about it a bunch. Well, vk is now going to iterate over every one of the neighbors of vk. And in particular, it's going to see vertex v0. Right? So we're going to see the edge from vk to v0, which is an edge kind of by definition because we took this to be a cycle here. But notice that's exactly the thing we set out to prove, namely that full DFS traverses an edge from a vertex to one of its ancestors. Here's a vertex k. Here's the ancestor v0. Why do we know that it's an ancestor? Well, because v0 was called in our call tree before any of these other guys. Right? So we wanted an algorithm that not only did cycle detection, but also actually gave me the cycle. What could I do? Well, it's essentially a small modification of what we already have. Right. So-- whoops. Right. If I want to compute topological order or whatever, I can just do DFS. And that'll tell me like, yay or nay, does there exist a cycle. If I want to actually find that cycle, all I have to do is check that topological order property at the same time that it traversed the graph during DFS. And the second that I find an edge that loops back, I'm done. And so that's our basic algorithm here. And this is a technique for actually just finding the cycle in a graph using the DFS algorithm.","73.82500457763672","6","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_20_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"152","What is a weighted graph?","for weighted single-source shortest paths in contexts where the weights aren't that large. So if I have positive edge weights-- if I have a positive edge weight, let's say-- using my weight color here-- that's, like, weight of 4, that's kind of problematic, because I don't know how to simulate that using an unweighted graph. Or do I? Anyone have an idea of how I could simulate an edge of weight 4 with an unweighted graph? Yeah. AUDIENCE: Have four edges of weight 1. JASON KU: Yeah, I can just put four edges of weight 1 in parallel here-- I'm sorry, in series, the opposite of parallel. I can just convert this here into 1, 2, 3, 4 edges. And if I do that for every edge in my graph and we have positive edge weights, then that transformation can hold. Now, that's not necessarily a good transformation to make. Why? AUDIENCE: The weight might be very big. JASON KU: Yeah, the weights might be very big compared to the number of vertices and edges in my graph. However, if the sum of all weights in my graph is asymptotically less than v plus e, we can get a linear time algorithm again by reducing to BFS. OK, so that's great. But in general, that gives us a linear time algorithm in these very special cases. And in general, it's an open problem. We don't know whether we can solve the single-source shortest paths problem in the weighted context for general graphs in linear time. We don't know how to do it. But what we do know are some algorithms that do pretty well. And that's what we use all the time. But one more special case we're going to go over today is when we have this really nice structure where we have a DAG, a Directed Acyclic Graph, like we were talking about in the last lecture. For any set of edge weights-- remember, with BFS, we needed to restrict our edge weights to be positive and maybe bounded to get this good running time? For any set of edge weights, if our graph structure is DAG-- it really has nothing to do with the weights-- if the graph structure is a DAG, then we can actually solve this single-source shortest paths problem in linear time, which is pretty awesome. Now, for general graphs, we're going to show you in the next lecture how to, for any graph-- even with cycles, even with negative weight cycles-- we're going to show you how to solve this single-source shortest paths problem in something like a quadratic running time bound. Now, this isn't the best known, but it's a really practical algorithm and people use it all the time. And we are going to show Bellman-Ford in the context of the DAG algorithm we're going to solve today. So that's the very general case in terms of restrictions on our graph. But in reality, most problems that come up in applications occur with graphs that have positive edge weights. You can think of a road network. You've got-- or non-negative ones anyway. You're traveling along, and it's not ever useful to go back to where you came from, because you want to make progress to where you're going. So in the context where you don't have negative weights, you don't have this problem where you have negative weight cycles. We can actually do a lot better by exploiting that property. And we get a bound that's a little bit-- that looks a little bit more like n log n. It's pretty close to linear. You're losing a log factor on the number of vertices.","73.43053436279297","7","DPRSearchEngine","5cF5Bgv59Sc.en-j3PyPqV-e1s_6_mp4","5cF5Bgv59Sc.en-j3PyPqV-e1s","6.006","11"
"152","What is a weighted graph?","that we've already seen in 6006? AUDIENCE: A tree. JUSTIN SOLOMON: A tree. At least if we orient all all the edges kind of pointing downward in the tree. Yeah. Otherwise, it gets kind of debatable over whether it's a DAG or not. If there's no direction to the edges, then somehow the definition just doesn't apply. OK. So in processing directed acyclic graphs, there's a really useful thing that you can do that's going to show up in this class apparently quite a bit, which is kind of interesting to me, I'm curious to see what that looks like, which is to compute a topological order on the graph. We're at topologies here.","72.61257934570312","8","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_16_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"152","What is a weighted graph?","I want to print out what an edge looks like, I'm going to ask that it print out the name of the source, and then an arrow, and then the name of the destination. So notice what I do there. Given an instance of an edge, I can print it. And it will get the source or the node associated with source inside this instance, get for that the getName method, and then call it. Notice the open-close paren there to actually call it. What does that do? It says, inside the edge I've got something that points to a node. I get that node. I take the method associated with it. And I call it. That returns the string. And then I glue that together with the arrow. I do the same thing on the destination. And I just print it out. Pretty straightforward, hopefully. OK, now I have to make a decision about the graph. I'm going to start with digraphs, directed graphs. And I need to think about how I might represent the graph. I can create nodes. I can create edges, but I've got to bring them all together. So I'll remind you, a digraph is a directed graph. The edges pass in only one direction. And here's one way I could do it. Given all the sources and all the destinations, I could just create a big matrix called an adjacency matrix. The rows would be all the sources. The columns would be all the destinations. And then in a particular spot in the matrix, if there is an edge between a source and a destination, I'd just put a one. Otherwise I'd put a zero. Note, by the way, because it's a directed graph, it's not symmetric. There might be a one between S and D, but not between D and S, unless there are edges both ways. This would be a perfectly reasonable way to represent a graph, but not the most convenient one. I'd have to go into the matrix to look things up. It may also not be a very efficient way of representing things. For example, if there are very few edges in the graph, I could have a huge matrix with mostly zeros. And that's not the most effective way to do it. So I'm going to use an alternative called an adjacency list. And the idea here is, for every node in the graph. I'm going to associate with it a list of destinations. That is, for a node, what are the places I can reach with a single edge? OK, so let's see what that does if we want to build it. And yes, there's a lot of code here, but it's pretty easy to look through I hope. Here's the choice I'm going to make. Again, what's a graph? It's a set of nodes. It's a set of edges. I'm going to have a way of putting nodes into the graph. And I'm going to choose to, when I put a node into the graph, to store it as a key in a dictionary. OK? When I initialize the graph, I'm just going to set this internal variable, edges, to be an empty dictionary. And the second part of it is, when I add an edge to the graph between two nodes from a source to a destination, I'm going to take that point in the dictionary associated with the source. It's a key. And associated with it, I'm going to just have a list of the nodes I can reach from edges from that source. So notice what happens here. If I want to add a node, remember, it's a node not an edge-- I'll first check to make sure that it's not already in the dictionary. That little loop is basic, or that if is saying, if it's in this set of keys, it will return true. And I'm going to complain. I'm trying to copy a node or duplicate a node. Otherwise, notice what I do. When I put a node into the dictionary, I go into that dictionary, edges. I create an entry with the key that is the node. And the value I put in there is initially an empty list. I'm going to say one more piece carefully. It's a node not a name. And that's OK in Python. It is literally the key is the node itself. It's an object, which is what I'd like. All right, what if I want to add an edge? Well, an edge is going to go from a source to a destination node. So, I'm going to get out from the edge the source piece. I'm going to get out from the edge the destination piece by calling those methods. Again, notice the open-close paren, which takes the method and actually calls it. Because remember, an edge was an object itself. Given those, I'll check to make sure that they are both in the dictionary. That is, I've already added them to the graph. I can't make a connection between things that aren't in the graph. And then notice the nice little thing I do.","72.59198760986328","9","DPRSearchEngine","V_TulH374hw.en-qlPKC2UN_YU_2_mp4","V_TulH374hw.en-qlPKC2UN_YU","6.0002","3"
"152","What is a weighted graph?","BFS. Can anyone think of such a scenario? So let's say, I mean, kind of what we did before was we counted the number of edges. So if we gave a weight of 1 to every edge in my graph, then just that graph, that weighted graph, corresponds to an unweighted graph using the other distance metric. So in that case, BFS just solves our problem. And in fact, we can generalize further. What if all of our weights were positive, but the same value? If it was all positive and the same value, then we could just divide by that value. Now we have an unweighted graph which we can run BFS, and then multiply shortest path distances by that value later on. And in fact, there's one further generalization we can make, which is a little bit of a tricky graph transformation problem.","72.42008209228516","10","DPRSearchEngine","5cF5Bgv59Sc.en-j3PyPqV-e1s_5_mp4","5cF5Bgv59Sc.en-j3PyPqV-e1s","6.006","11"
"153","What is the role of the word RAM model in accessing static arrays and how does it influence the operations on the arrays?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","80.04581451416016","1","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"153","What is the role of the word RAM model in accessing static arrays and how does it influence the operations on the arrays?","to this interface problem-- the natural solution-- is what I'll call a static array. Jason mentioned these in lecture one. It's a little tricky because there are no static arrays in Python. There are only dynamic arrays, which is something we will get to. But I want to talk about, what is a static array, really? And this relates to our notion of-- our model of computation, Jason also talked about, which we call the word RAM, remember? The idea, in word RAM, is that your memory is an array of w-bit words. This is a bit circular. I'm going to define an array in terms of the word RAM, which is defined in terms of arrays. But I think you know the idea. So we have a big memory which goes off to infinity, maybe. It's divided into words. Each word here is w bits long. This is word 0, word 1, word 2. And you can access this array randomly-- random access memory. So I can give you the number 5 and get 0 1, 2, 3, 4, 5, the fifth word in this RAM. That's how actual memories work. You can access any of them equally quickly. OK, so that's memory. And so what we want to do is, when we say an array, we want this to be a consecutive chunk of memory. Let me get color. Let's say I have an array of size 4 and it lives here. Jason can't spell, but I can't count. So I think that's four. We've got-- so the array starts here and it ends over here. It's of size 4. And it's consecutive, which means, if I want to access the array at position-- at index i, then this is the same thing as accessing my memory array at position-- wherever the array starts, which I'll call the address of the array-- in Python, this is ID of array-- plus i. OK. This is just simple offset arithmetic. If I want to know the 0th item of the array, it's right here, where it starts. The first item is one after that. The second item is one after that. So as long as I store my array consecutively in memory, I can access the array in constant time. I can do get_at and set_at as quickly as I can randomly access the memory and get value-- or set a value-- which we're assuming is constant time. My array access is constant time. This is what allows a static array to actually solve this problem in constant time per get_at and set_at operation. This may seem simple, but we're really going to need this model and really rely on this model increasingly as we get to more interesting data structures. This is the first time we're actually needing it. Let's see. Length is also constant time. We're just going to store that number n, along with its address. And build is going to take linear time. Iteration will take linear time. Pretty straightforward. I guess one thing here, when defining build, I need to introduce a little bit more of our model of computation, which is, how do you create an array in the beginning? I claim I could do it in linear time, but that's just part of the model. This is called the memory allocation model. There are a few possible choices here, but the cleanest one is just to assume that you can allocate an array of size n in theta n time. So it takes linear time to make an array of size n. You could imagine this being constant. It doesn't really matter much. But it does take work. And in particular, if you just allocate some chunk of memory, you have no idea whether it's initialized. So initializing that array to 0s will cost linear time. It won't really matter, constant versus linear, but a nice side effect of this model is that space-- if you're just allocating arrays, the amount of space you use is, at most, the amount of time you use. Or, I guess, big O of that. So that's a nice feature. It's pretty weird if you imagine-- it's unrealistic to imagine you can allocate an array that's infinite size and then just use a few items out of it. That won't give you a good data structure. So we'll assume it costs to allocate memory. OK, great. We solved the sequence problem. Very simple, kind of boring. These are optimal running times. Now, let's make it interesting-- make sure I didn't miss anything--","79.1064453125","2","DPRSearchEngine","CHhwJjR0mZA.en-j3PyPqV-e1s_3_mp4","CHhwJjR0mZA.en-j3PyPqV-e1s","6.006","2"
"153","What is the role of the word RAM model in accessing static arrays and how does it influence the operations on the arrays?","And this is a subset of the set interface. And subsets are interesting because, potentially, we can solve them better, faster, simpler, something. And so you'll recognize-- you should recognize all of these operations, except we didn't normally highlight the max operation. So here, we're interested in storing a bunch of items. They have keys which we think of as priorities. And we want to be able to identify the maximum priority item in our set and remove it. And so there's lots of motivations for this. Maybe you have a router, packets going into the router. They have different priorities assigned to them. You want to route the highest priority first. Or you have processes on your computer trying to run on your single threaded-- single core, and you've got to choose which one to run next. And you usually run higher priority processes first. Or you're trying to simulate a system where events happen at different times, and you want to process the next event ordered by time. All of these are examples of the priority queue interface. We'll even see applications within this class when we get to graph algorithms. But the main two things we want to be able to support are inserting an item, which includes a key, and leading the maximum item, and also returning it at the same time. We'll also talk some about being able to build the structure faster than just inserting it. But of course, we could implement build by starting empty and repeatedly inserting. And also the complexity of just finding the max without deleting it, this you could simulate with these two operations by deleting the max and then reinserting it, which works. But often, we can do faster. But the two key, main operations are insert and delete max. And we're going to see a few data structures to do this. Any suggestions among the data structures we've seen in this class? What should we use to solve priority queue interface? Many possible answers.","78.2544174194336","3","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_2_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"153","What is the role of the word RAM model in accessing static arrays and how does it influence the operations on the arrays?","namely, random accessing. And if we stored the things that we're looking for, we have unique keys, and those keys are integers. Then, if I have an item with key K, if I store it at index K in my array, then I can find it and manipulate it in constant time.","77.23741912841797","4","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_2_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"153","What is the role of the word RAM model in accessing static arrays and how does it influence the operations on the arrays?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","75.90592193603516","5","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"153","What is the role of the word RAM model in accessing static arrays and how does it influence the operations on the arrays?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 2: Data Structures 
Lecture 2: Data Structures 
Data Structure Interfaces 
• A data structure is a way to store data, with algorithms that support operations on the data 
• Collection of supported operations is called an interface (also API or ADT) 
• Interface is a speciﬁcation: what operations are supported (the problem!) 
• Data structure is a representation: how operations are supported (the solution!) 
• In this class, two main interfaces: Sequence and Set 
Sequence Interface (L02, L07) 
• Maintain a sequence of items (order is extrinsic) 
• Ex: (x0, x1, x2, . . . , xn−1) (zero indexing) 
• (use n to denote the number of items stored in the data structure) 
• Supports sequence operations: 
Container 
build(X) 
len() 
given an iterable X, build sequence from items in X 
return the number of stored items 
Static 
iter seq() 
get at(i) 
set at(i, x) 
return the stored items one-by-one in sequence order 
return the ith item 
replace the ith item with x 
Dynamic 
insert at(i, x) 
delete at(i) 
insert first(x) 
delete first() 
insert last(x) 
delete last() 
add x as the ith item 
remove and return the ith item 
add x as the ﬁrst item 
remove and return the ﬁrst item 
add x as the last item 
remove and return the last item 
• Special case interfaces: 
stack 
insert last(x) and delete last() 
queue 
insert last(x) and delete first() 
","75.67509460449219","6","DPRSearchEngine","79a07dc1cb47d76dae2ffedc701e3d2b_MIT6_006S20_lec2_1_pdf","79a07dc1cb47d76dae2ffedc701e3d2b_MIT6_006S20_lec2","6.006","2"
"153","What is the role of the word RAM model in accessing static arrays and how does it influence the operations on the arrays?"," 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Relationships among models 
Informal Defn: Two models of computation are polynomially related 
if each can simulate the other with a polynomial overhead: 
So ! "" time → !$("") time on the other model, for some '. 
All reasonable deterministic models are polynomially related. 
• 1-tape TMs 
• multi-tape TMs 
• multi-dimensional TMs 
• random access machine (RAM) 
• cellular automata 
9 
","75.64495849609375","7","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_9_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"153","What is the role of the word RAM model in accessing static arrays and how does it influence the operations on the arrays?","That was a brief tour of computational geometry. I work mostly in four different areas of algorithms-- geometry, data structures, graph algorithms, and what I call recreational algorithms. I think I made up that term. And let's go into data structures, which is represented by this class, 6.851. All of the classes I mentioned have online video lectures, especially for those watching at home on OpenCourseWare. Most of these classes are on OpenCourseWare, and if not, they're on my webpage. 6.851, Advanced Data Structures, is an extension of the sorts of data structures you've seen here, in 006 and the ones you will see in 6.046. I thought I would give you a flavor of one such result, which is a problem we've seen in this class done better. Suppose you want to store a dynamic ordered set. This is the set interface. Dynamic in the sense that I have insert and delete, and ordered in the sense that I want to support find-next and find-previous. Exactly which subset of the set interface you choose influences what data structure you've seen. We've seen, for dynamic sets, you want to use hashing. If you don't care about find-next, if you just care about find, then hashing is great-- constant expected. You can prove stronger things about hashing. And we do in that class. But if you want dynamic and ordered, you cannot do constant time per operation. You can prove that, which is cool. What data structure have we seen that solves this problem pretty well? Set AVL trees, which solve everything in log n. So log n is one competitor. Yeah. I'm interested in the word RAM model, which is the only model we've seen in this class. This happens to work in a stronger model. And we can do better than log n in the following-- it will take me a while before I get better, but here's, at least, a different bound we can get-- log w. This is via a structure called van Emde Boas, who is a person. AVL is two people. van Emde Boas, I've actually met. Log w-- remember, w is our word size. So this is a bit of a weird running time. It's great if w is log n, then this is log log n. And we know w is at least log n, but it could be bigger. We don't really have a sense of how big w could get. Maybe it's even n. Maybe it's big-- and then these are the same. Maybe it's bigger than n, and then this is maybe worse. But for most ws, this is actually pretty good-- and indeed, optimal. But it's not strictly better, in any sense, yet. On the other hand, there's another data structure which runs in log n divided by log w. This is called fusion trees. This was invented around the time that cold fusion was in the news, and so they wanted data structures to represent. We can achieve this bound or we can achieve this bound. And this bound is good is if w is large. This band as good if w is small. You can always take the min of the two, whatever is better. And in particular, the min of those two things is at most-- I think it's square root log n over log log n. If you want to bound just in terms of n, then the crossover point between these two is this place. And so you're always, at most, this, which is quite a bit better than the log n of AVL. We've got a square root and we've got a slight thing in the denominator. Pretty tiny. But the big thing is the square root. And that's kind of cool. And it turns out, that's pretty much optimal. In terms of an n bound, this is optimal. The min of these two, in general, is roughly optimal up to log log terms. For fun, I threw up the actual formula for the right-bound, which is tight up to constant factors of matching upper and lower bounds, which we talk about. It's min of three things-- four things, including log of w over a divided by log of log w over a log of log n over a. That's the last term that I just read. This was messy. Surprisingly, that is the right answer for this very particular problem-- a very natural problem. AUDIENCE: What is a? ERIK DEMAINE: A is the log of the space you're using. So it's the address size. Good question. If you throw it-- so it depends. If you have a polynomial space data structure, then basically, these are optimal. And this is generalizing to beyond that. Maybe you have a little bit more than polynomial space. Cool. So that's data structures. I'm going to jump ahead to graph algorithms, which, if you want to take this class, I recommend a time travel device.","75.41166687011719","8","DPRSearchEngine","4nXw-f6NJ9s.en-j3PyPqV-e1s_4_mp4","4nXw-f6NJ9s.en-j3PyPqV-e1s","6.006","21"
"153","What is the role of the word RAM model in accessing static arrays and how does it influence the operations on the arrays?","sorry, delete_max, thank you. You can of course define all of these things for min instead of max. Everything works the same. I just have a hard time remembering which one we're doing. Just don't switch you can't use a max-heap to do delete_min. You can't use a min-heap to do delete_max, but you can use a min-heap to do delete_min. That's fine. So like I said, the only node we really know how to delete is the last leaf on the last level, which is the end of the array. Because that's what arrays can delete efficiently. And what we need to delete is the root item, because that's always the maximum one, which is at the first position in the array. So what do we do? Swap them, our usual trick. I think the cool thing about heaps is we never have to do rotations. We're only going to do swaps, which is something we had to do with trees also-- binary trees. Q[0] with Q of the last item-- great, done. Now we have the last item is the one we want to delete. So we do delete_last, or pop in Python, and boom, we've got-- we've now deleted the maximum item. Of course, we may have also messed up the max-heap property just like we did with insert. So with insert, we were adding a last leaf. Now, what we're doing is swapping the last leaf with the-- I'm pointing at the wrong picture. Let me go back to this tree. What we did is swap item J with A. So the problem is now-- and then we deleted this node. The problem is now that that root node has maybe a very small key. Because the key that's here now is whatever was down here, which is very low in the tree. So intuitively, that's a small value. This is supposed to be the maximum value, and we just put a small value in the root. So what do we do? Heapify down. We're going to take that item and somehow push it down to the tree until the-- down in the tree until max-heap property is satisfied. So this is going to be max_heapify_down. And we will start at position 0, which is the root. And max_heapify_down is going to be a recursive algorithm. So we'll start at some position i. And initially, that's the root. And what we're going to do is look at position i and its two children. So let's say we put a very small value up here, like 0. And let's say we have our children, 5 and 10. We don't know-- maybe I'll swap their order just to be more generic, because that looks like not quite a binary search tree, but we don't know their relative order. But one of them is greater than or equal to the other in some order. And so what would I like to do to fix this local picture? Yeah, I want to swap. And I could swap-- 0 is clearly in the wrong spot. It needs to go lower in the tree. I can swap 0 with 5 or 0 with 10. Which one? 10. I could draw the picture with 5, but it will not be happy. Why 10? We want to do it with the larger one, because then this edge will be happy, and also this edge will be happy. If I swapped 5 up there instead, the 5/10 edge would be unhappy. It wouldn't satisfy the max-heap property. So I can do one swap and fix max-heap property. Except that, again, 0 may be unhappy with its children. 0 was this one item that was in the wrong spot. And so it made it have to go farther down. But 5 will be-- 5 didn't even move. So it's happy. Everything in this subtree is good. What about the parent? Well, if you think about it, because everything was a correct heap before we added 0, or before we put 0 too high, all of these nodes will be greater than or equal to 10 on the ancestor path. And all of these nodes were less than or equal to 10 before, unless you're equal to 5. So that's still true. But you see, this tree is happy. This tree still may be unhappy. 0 still might need to push down farther. That's going to be the recursion. So we check down here. There's a base case, which is if i is a leaf, we're done. Because there's nothing below them. So we satisfy the max-heap property at i because there's no children. Otherwise, let's look at the leaf among the left-- sorry, left not leaf-- among the two children left and right of i. Right if i might not exist. Then ignore it. But among the two children that exist, find the one that has maximum key value, Q[j].key. That was 10 in our example. And then, if these items are out of order, if we do not satisfy-- so greater than would be satisfy. Less than Q[j] would be the opposite of the max-heap property here. If max-heap property is violated, then we fix it by swapping Q[i] with Q[j], and then we recurse on j-- call max_heapify_down of j. That's it. So pretty symmetric. Insert was a little bit simpler, because we only have one parent. Delete_min, because we're pushing down, we have two children. We have to pick one. But there's a clear choice-- the bigger one. And again, this algorithm-- this whole thing-- will take order h time, the height of the tree, which is log n, because our node just sort of bubbles down. At some point, it stops. When it stops, we know the max-heap property was satisfied there. And if you check along the way, by induction, all the other max-heap properties will be satisfied, because they were before. So almost forced what we could do here. The amazing thing is that you can actually maintain a complete binary tree that satisfies the max-heap property. But once you're told that, the algorithm kind of falls out. Because we have an array. The only thing we can do is insert and delete the last item. And so we've got to swap things to there in order-- or out of there in order to make that work. And then, the rest is just checking locally that you can fix the property. Cool. So that's almost it, not quite what we wanted. So we now have log n amortize insert and delete_max in our heap. We did not yet cover linear build. Right now, it's n log n if you insert n times. And we did not yet cover how to make this an in-place sorting algorithm. So let me sketch each of those. I think first is in-place. So how do we make this algorithm in-place? I guess I want that, but I don't need this. So we want to follow priority queue sort. Maybe I do want that. But I don't want to have to grow and shrink my array. I would just like to start with the array itself. So this is in place. So what we're going to do is say, OK, here's my array that I want to sort. That's given to me. That's the input to priority queue sort. And what I'd like is to build a priority queue out of it. Initially, it's empty. And then I want to insert the items one at a time, let's say. So in general, what I'm going to do is maintain that Q is some prefix of A. That's going to be my priority queue. It's going to live in this sub array-- this prefix. So how do I insert a new item? Well, I just increment. So to do an insert, the first step is increment size of Q. Then I will have taken the next item from A and injected into this Q. And conveniently, if we look at our insert code, which is here, the first thing we wanted to do was add an item at the end of the array. So we just did it without any actual work, just conceptual work. We just said, oh, our Q is one bigger. Boom! Now this is at the end of the array. no more amortization, in fact, because we're not ever resizing our array, we're just saying, oh, now Q is a little bit bigger of a prefix. It just absorb the next item of A. Similarly, delete_max is going to, at the end, decrement the size of Q. Why is that OK? Because at the end of our delete_max operation-- not quite at the end, but almost the end-- we deleted the last item from our array. So we just replaced that delete last with a decrement, and that's going to shrink the Q by 1. It has the exact same impact as leading the last item. But now, it's constant time, worst case not amortized. And the result is we never actually build a dynamic array. We just use a portion of A to do it. So what's going to happen is we're going to absorb all the items into the priority queue, and then start kicking them out. As we kick them out, we kick out the largest key item first, and we put it here, then the next largest, then the next largest, and so on. The minimum item is going to be here. And, boom, it's sorted. This is the whole reason I did max-heaps instead of min-heaps, is that in the end, this will be a upward sorted array with the max at the end. Because we always kick out items at the end. We delete the max first. So that is what's normally called heapsort. You can apply this same trick to insertion sort and selection sort, and you actually get the insertion sort and selection sort algorithms that we've seen which operate in prefixes of the array. Cool, so now we have-- we've achieved the y up there, which is n log n sorting algorithm that is in-place. So that was our main goal-- heapsort. Let me very quickly mention you can build a heap in linear time with a clever trick. So if you insert the items one at a time, that would correspond to inserting down the array. And every time I insert an item, I have to walk up the tree. So this would be the sum of the depth of each node. If you do that, you get n log n. This is the sum over i of log i. That turns out to be n log n. It's a log of n factorial. The cool trick is to, instead, imagine adding all the items at once and not heapifying anything, and then heapify up-- sorry, heapify down from the bottom up. So here we're heapifying up. Now, we're going to heapify down. And surprisingly, that's better. Because this is the sum of the heights of the nodes. And that turns out to be linear. It's not obvious. But intuitively, for a depth, this is 0, this is log n, and we've got a whole ton of leaves. So right at the leaf level, you can see, we're paying n log n, right? Because there are n of them, and each one costs log n. Down here, at the leaf level, we're paying constant. Because the height of the leaves are 1. Here, the height of the root is log n. And this is better. Now we're paying a small amount for the thing of which there are many. It's not quite a geometric series, but it turns out this is linear. So that's how you can do linear building heap. To come back to your question about sequence AVL trees, turns out you can get all of the same bounds as heaps, except for the in-place part, by taking a sequence AVL tree, storing the items in an arbitrary order, and augmenting by max, which is a crazy idea. But it also gives you a linear build time. And yeah, there's other fun stuff in your notes. But I'll stop there.","74.38194274902344","9","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_11_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"153","What is the role of the word RAM model in accessing static arrays and how does it influence the operations on the arrays?","OK, so change in the model of computation. So what we've been talking to you in terms of model of computation is our word-RAM-- word-RAM. And that essentially says I can do arithmetic operations, and I can look up stuff in my memory in constant time. And but if I allocate a certain amount, I have to pay that amount and that kind of thing. So that's this word-RAM model. But in actuality, all of your computers, it's a lot easier for me to figure-- to find and read memory that's on my CPU in a register than it is for me to go out to the hard disk, ask this-- well, in my day, it used to be this movable mechanical head that had to go and scan over a bit on a CD-ROM drive and actually read what that thing was. So we can add complexity to our model to better account for the costs of operations on my machine.","74.36176300048828","10","DPRSearchEngine","2NMtS1ecb3o.en-j3PyPqV-e1s_13_mp4","2NMtS1ecb3o.en-j3PyPqV-e1s","6.006","20"
"155","What is the difference between the depth and the height of a node in a binary tree?","can do in a tree that won't affect any of the stuff we've done so far. It's a tool that we can use to rebalance. Notice how deep things are in the tree changes. Our problem with this linear tree is that there are some nodes of linear depth. We want to get rid of those. How? Well, we could take these edges and start rotating them up. If you look at depths, in this picture, A and B are deeper than C. And in this picture, B and C are deeper than A. So it's a trade off. This one moved up. This one moved down. This one stayed at the same depth. So hopefully, if A is too deep and C is too shallow, they can trade off like this. It may sound difficult, but in fact, there's a pretty simple way, which are called AVL trees, that maintain balance in a particular way called height balance. This is if we take the height of node.left-- actually, I'd prefer to-- node.right, minus height of node.left,","70.637939453125","1","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_18_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"155","What is the difference between the depth and the height of a node in a binary tree?"," 
 
 
 
 
 
 
 
 
   
 
 
  
 
 
 
 
 
 
 
  
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
Constructing !"",$: 3rd try 
!34, 35, 6 = ∃89:; !34, 3<=>, 6/2 ∧ !3<=>, 35, 6/2 
, , J
Check-in 18.3 
Would this construction still work if N were 
nondeterministic? 
(a) Yes. 
(b) No. 
∀(K ∈L) M
∀ 8B, 8C ∈ 
8E, 89:; , 89:;, 8F 
!3G, 3H, 6/2 
is equivalent to 
⋮ 
∀K K ∈L 
M
!"",$ = !3OPQRP, 3QSSTUP, V 
! 
defined as in Cook-Levin 
/
W = - . 
Size analysis: 
Each recursive level adds %('() to the QBF. 
Number of levels is log - ./ = % '( . 
→ Size is % 
'2( 
•
'(×'( = % 
9 
Check-in 18.3 
","69.2832260131836","2","DPRSearchEngine","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18_9_pdf","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18","18.404J","18"
"155","What is the difference between the depth and the height of a node in a binary tree?","!""#$""%&'(% ∈NP
Defn:  !""#$""%&'(% = + + is not prime and + is written in binary} 
= + + = ,- for integers ,, - > 1,  + in binary} 
Theorem:  !""#$""%&'(% ∈NP
Proof:   “On input +
1.  Nondeterministically write , where 1 < , < +.
2.  Accept if , divides + with remainder 0.
Reject if not.”
Note:  Using base 10 instead of base 2 wouldn’t matter because can convert in 
polynomial time.
Bad encoding:  write number 3 in unary:  14 = 111 ⋯1
4
, exponentially longer.
Theorem (2002):  !""#$""%&'(% ∈P
We won’t cover this proof.
5
","69.24839782714844","3","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_5_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"155","What is the difference between the depth and the height of a node in a binary tree?","I'll call them left justified. And these two properties together is what I call a complete binary tree. Why is this interesting? Because I claim I can represent a tree like this as an array. I've narrowed things down enough that I can draw an array down here. And what I'm going to do is write these nodes in depth order. So I write A first, because that's step 0. Then B, C, that's step 1. Then, well, they're alphabetical. I made it that way. D, E, F, G is depth 2. And then H, I, J is step 3. This is very different from traversal order of a tree. Traversal order would have been H, D, I, B, J, E, A, F, C, G, OK? But this is what we might call depth order, do the lowest depth nodes first-- very different way to lay things out or to linearize our data. And this is what a heap is going to look like. So the cool thing is, between complete binary trees and arrays is a bijection. For every array, there's a unique complete binary tree. And for every complete binary tree, there's a unique array. Why? Because the complete constraint forces everything-- forces my hand. There's only-- if I give you a number n, there is one tree shape of size n, right? You just fill in the nodes top down until you get to the last level. And then you have to fill them in left to right. It's what you might call reading order for writing down nodes. And the array is telling you which keys go where. This is the first node you write down at the root, this is the next node you write down at the left child of the root, and so on. So here we have a binary tree represented as an array, or array representing a binary tree. The very specific binary tree, it has a clear advantage, which is it is guaranteed balance. No rotations necessary in heaps, because complete binary trees are always balanced. In fact, they have the best height they possibly could, which is ceiling of log n. Balanced, remember, just meant you were big O of log n. This is 1 times log n. So it's the best level of balance you could hope for. So somehow, I claim, we can maintain a complete binary tree for solving priority queues. This would not be possible if you were trying to solve the whole set interface. And that's kind of the cool thing about heaps, is that by just focusing on the subset of the set interface, we can do more. We can maintain this very strong property. And because we have this very strong property, we don't even need to store this tree. We're not going to store left and right pointers and parent pointers, we're just going to store the array.","68.79639434814453","4","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_8_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"155","What is the difference between the depth and the height of a node in a binary tree?","  
 
  
 
 
  
 
 
 
  
 
 
New in  Code  
§pylab.axvline(x = popMean,  color  = 'r')  draws a red
vertical line at popMean on the x-axis 
§There’s also a pylab.axhline function 
6.0002  LECTURE 8 
 
12
","68.39683532714844","5","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_12_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"155","What is the difference between the depth and the height of a node in a binary tree?"," ! 
dist, numSamples = [], 1000000
for i in range(numSamples):
dist.append(random.gauss(0, 100))
weights = [1/numSamples]*len(dist)
v = pylab.hist(dist, bins = 100,
weights = [1/numSamples]*len(dist))
pylab.xlabel('x')
pylab.ylabel('Relative Frequency')
print('Fraction within ~200 of mean =',
sum(v[0][30:70]))
	

""
","68.08292388916016","6","DPRSearchEngine","3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7_3_pdf","3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7","6.0002","7"
"155","What is the difference between the depth and the height of a node in a binary tree?","Example of Hierarchical Clustering
6.0002 LECTURE 12
8
BOS
NY
CHI
DEN
SF
SEA
BOS
0
206
963
1949
3095
2979
NY
0
802
1771
2934
2815
CHI
0
966
2142
2013
DEN
0
1235
1307
SF
0
808
SEA
0
{BOS}
{NY}
{CHI}
{DEN}
{SF}
{SEA}
{BOS, NY}
{CHI}
{DEN}
{SF}
{SEA}
{BOS, NY, CHI}
{DEN}
{SF}
{SEA}
{BOS, NY, CHI}
{DEN}
{SF, SEA}
{BOS, NY, CHI, DEN}
{SF, SEA}
{BOS, NY, CHI}
{DEN, SF, SEA}
or
Single linkage
Complete linkage
","67.93560791015625","7","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_8_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"155","What is the difference between the depth and the height of a node in a binary tree?","Conclusion:  !""# is NP-complete
$% &' &( &) ⋯&+
a
$, &(
⋯
⋯
$accept ⋯
˽    … ˽
23
23
Summary: 
For "" ∈NP, decided by NTM 5, 
we gave a reduction 6 from "" to !""#:
6: Σ∗→formulas
6 &
= 〈=>,@〉
& ∈"" iff  =>,@ is satisfiable.
=>,@ = =cell ∧=start ∧=move ∧=accept
The size of =>,@ is roughly the size of the tableau 
for 5 on &, so size is I 23×23 = I 2(3 .
Therefore 6 is computable in polynomial time.
8
","67.82846069335938","8","DPRSearchEngine","8212b19fc5a34f500ca6acf03a3a7d74_MIT18_404f20_lec16_8_pdf","8212b19fc5a34f500ca6acf03a3a7d74_MIT18_404f20_lec16","18.404J","16"
"155","What is the difference between the depth and the height of a node in a binary tree?","Let me draw a tree. If I got to choose any old tree I want, I would choose a tree that's basically perfectly balanced. Perfectly balanced would be like this, where-- what's the property? That I have all of these levels-- all of these depths are completely filled with nodes. This is depth 0. Remember, this is depth 1, this is depth 2, this is depth 3. So what I'd really like is to have 2 to the i nodes at depth i. That would be a perfect binary tree. But that only works when n is 1 less than a power of 2, right? I can't always achieve that for any n. And so the next best thing I could hope for is 2 to the i at nodes at depth i until the very last i-- the largest depth. And in that level, I'm still going to restrict things. I'm going to force all of the nodes to be as far left as possible.","67.29327392578125","9","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_7_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"155","What is the difference between the depth and the height of a node in a binary tree?","And instead, we should jump to an algorithm that actually matters, which is something called merge sort. How many of us have encountered merge sort before? Fabulous. Good. So then I'm done. So let's say that I have a list. Now, I'm sending a message back to Jason. I made this one up last night. So I have 7, 1, 5, 6, 2, 4, 9, 3. This is not in sorted order. But I can make a very deep observation, which is that every number by itself is in sorted order if I think of it as an array of length 1. It's really deep, like deep learning deep. So now, what can I do? Well, I could take every pair of numbers, draw a little red box. Well, now, they're not in sorted order any more inside of the red boxes. So I'm going to sort inside of every box. In this case, it's not too exciting because it's just pairs. And now, they're in sorted order because they said they were. Now, I'm going to keep doubling the size of my boxes. So now, let's say I have box of length 4. What do I know about the left and right-hand sides of the dotted lines here? On the two sides of the dotted lines, the array is in sorted order. There's a 1 and then a 7. Those are in sorted order, 5 and a 6. That's because, in the previous step, I sorted every pair. So when I merge these two sides together, I have an additional useful piece of information, namely that the two sides of the dotted line are already in sorted order. That's going to be our basic inductive step here. So in this case, I merge the two sides. I get 1, 5, 6, 7, and 2, 3, 4, 9. Then finally, I put these two things together. And I have to sort these two. I have to merge these two sorted lists. But they're in sorted order. And that's going to give me a big advantage because-- oops, I lost my chalk. I suppose I've got space on this board here. Oh no. So if I want to merge 1, 5, 6, 7 and 2, 3, 4, 9, there's a nice, clever technique that we can do that's going to take just linear time. Jason tells me it's the two finger algorithm. I think that's a cute analogy here. So here are my two fingers. They're going to point at the end of the list. And I'm going to construct the merged array backwards. So how many elements are in my merged array, if I'm merging two things of length 4? I don't ask you guys hard questions. It's 8, yeah? 4 plus 4. 8, yeah? So what do I know? I know that my merge array-- 5, 6, 7-- has eight elements. And now, I'm going to have two fingers at the end of my array. Which one should I put at the end of the merged guy? The 7 of the 9? AUDIENCE: The 9 JUSTIN: The 9. Right, thank you. So now, I can move my lower finger to the left because I've already added that. Notice that I never need to look to the left of where my finger is because they're already in sorted order. Now what should I add, the 4 or the 7? AUDIENCE: 7. JUSTIN: The 7. And so on, dot, dot, dot, yeah? So that's going to be the basic idea of the merge sort. I'm going to take two sorted lists. And I'm going to make a new sorted list, which is twice as long, by using two fingers and moving from the and backward. So that's the basic intuition here. Indeed, there's our sorted list. It's stressing me out that there's no eight. I need the power of 2. So I think merge sort, we're going to present it in a backward way from the previous one, where I'm going to give you the high level algorithm. And then actually, the headache is that merging step, which I have four minutes for. And I apologize for it. So what does the merger sort do? Well, it computes an index c, which is the middle of my array. And it's going to make a recursive call which is sort the left, which is everything between index A and index C. And then sort everything on the right, which is everything from index C to index B. I know this is confusing because usually letters appear in order. But C, if you think of as standing for center, then it makes sense like. Here's my array. I'm going to choose an index right in the middle. I've done myself a disservice by not using a power of 2. But that's OK. I'm going to say sort everything to the left of the dotted line first. Sort everything to the right of the dotted line second. Now, I have two sorted lists on the two sides of the dotted line. And then I'm going to use my two fingers to put them together. So that's what this is implementing here. See, there's two recursive calls-- sort from A to C, and then sort from C to B. Oops, I didn't actually label this. So this is A, C, B. And then I've got to call merge.","67.13672637939453","10","DPRSearchEngine","oS9aPzUNG-s.en-j3PyPqV-e1s_20_mp4","oS9aPzUNG-s.en-j3PyPqV-e1s","6.006","3"
"156","Is there an algorithm that can solve the halting problem for all possible computer programs?","OK. So to start this off, we're going to have to talk about non-deterministic complexity as a variation of deterministic complexity. So first of all, all of the machines in this part of the course and the languages, everything is going to be decidable and all the machines are going to be deciders. So what do we mean when we have a non-deterministic machine which is a decider? And that just simply means that all of the branches-- it's not just the machine halts on every input, but all of the branches halt on every input. So the non-deterministic machine is non-deterministic, it has lots of possible branches. They all have to halt-- all of them-- on every input. That's what makes a non-deterministic machine a decider. And you're going to convert a non-deterministic decider into a deterministic decider. But the question is, how much time would that introduce? How much extra time is that going to cost? And the only way that people know at the present time for that conversion would be to do an exponential increase. Basically, to try all possible branches.","74.31648254394531","1","DPRSearchEngine","1VhnDdQsELo.en-j3PyPqV-e1s_4_mp4","1VhnDdQsELo.en-j3PyPqV-e1s","18.404J","14"
"156","Is there an algorithm that can solve the halting problem for all possible computer programs?","Given a computer program, does it ever halt? Does it ever terminate? This would be a great thing if we knew how to solve. It's basically an infinite loop detector. If your problem doesn't halt, then it has an infinite loop of some sort. And you'd like to tell your user, hey, you have a bug in your program. So this is one part of bug detection. And it's impossible. There is no algorithm that always-- that solves all inputs to this problem. Maybe given one program that, say, has 0 lines of code, it could solve that. It says, yeah, that one terminates. And maybe you can detect simple kinds of infinite loops. So there's some inputs, some computer programs that you could detect. But there's no one algorithm that solves all inputs. This is kind of sad news.","73.49638366699219","2","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_3_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"156","Is there an algorithm that can solve the halting problem for all possible computer programs?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","72.25300598144531","3","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"156","Is there an algorithm that can solve the halting problem for all possible computer programs?"," 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
   
 
 
 
 
   
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
  
 
 
  
 
  
 
  
Turing machine model – review 
head 
˽ ˽ . . .
a
b
a
b
b
Finite 
read/write input tape 
control 
On input ! a TM "" may halt (enter #acc or #rej) 
) is T-recognizable if ) = +("") for some TM "". 
or loop (run forever). 
) is T-decidable if ) = +("") for some TM decider "". 
So "" has 3 possible outcomes for each input !: 
halts on all inputs 
1. Accept ! (enter #acc ) 
Turing machines model general-purpose computation. 
2. Reject ! by halting (enter #rej ) 
Q: Why pick this model? 
3. Reject ! by looping (running forever) 
A: Choice of model doesn't matter. 
All reasonable models are equivalent in power. 
Virtues of TMs: simplicity, familiarity. 
2 
","72.02558135986328","4","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_2_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"156","Is there an algorithm that can solve the halting problem for all possible computer programs?","§ Problem is exponen<al 
§ Have we overturned the laws of the universe? 
§ Is dynamic programming a miracle? 
§ No, but computa<onal complexity can be subtle 
§ Running <me of fastMaxVal is governed by number of 
dis<nct pairs, <toConsider, avail> 
◦Number of possible values of toConsider bounded 
by len(items)
◦Possible values of avail a bit harder to characterize 
◦Bounded by number of dis<nct sums of weights 
◦Covered in more detail in assigned reading 
How Can This Be? 
6.0002 LECTURE 2 
30 
","71.17604064941406","5","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_30_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"156","Is there an algorithm that can solve the halting problem for all possible computer programs?"," 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
  
 
Nondeterministic Complexity 
In a nondeterministic TM (NTM) decider, all branches halt on all inputs. 
Defn: An NTM runs in time !(#) if all branches halt within !(#) steps 
on all inputs of length #. 
Defn: NTIME ! # 
= {'| some 1-tape NTM decides ' 
and runs in time ( ! # 
} 
Defn: NP = ⋃* NTIME(#*)
= nondeterministic polynomial time decidable languages 
• Invariant for all reasonable nondeterministic models 
• Corresponds roughly to easily verifiable problems 
3 
Computation tree 
for NTM on input +. 
! # 
all branches halt 
within !(#) steps 
. . . 
","70.79542541503906","6","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_3_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"156","Is there an algorithm that can solve the halting problem for all possible computer programs?"," 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Turing Machines (TMs) 
head 
˽ ˽
a
b
a 
. . .
b b
Finite 
read/write input tape 
control 
1) Head can read and write 
2) Head is two way (can move left or right) 
3) Tape is infinite (to the right) 
4) Infinitely many blanks “˽“ follow input 
5) Can accept or reject any time (not only at end of input) 
8 
","70.63008117675781","7","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_8_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"156","Is there an algorithm that can solve the halting problem for all possible computer programs?"," 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
   
 
    
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
Linearly Bounded Automata 
Defn: A linearly bounded automaton (LBA) is a 1-tape TM 
that cannot move its head off the input portion of the tape. 
LBA 
a a b a a b a 
Tape size adjusts to length of input. 
Let !LBA = &, ( LBA & accepts ( } 
Theorem:  !LBA is decidable 
Proof: (idea) If & on ( runs for long, it must be cycling. 
Decider for !LBA: 
Claim: For inputs of length ), an LBA can have 
.A−LBA = “On input &, ( 
only * ×)× Γ - different configurations. 
1.  Let ) = |(|. 
Therefore, if an LBA runs for longer, it must repeat some 
2. Run & on ( for * ×)× Γ - steps. 
configuration and thus will never halt. 
3. If has accepted, accept. 
4. If it has rejected or is still running, reject.” 
must be looping 
7 
","70.60768127441406","8","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_7_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"156","Is there an algorithm that can solve the halting problem for all possible computer programs?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
If we know that some problem (say !TM) is undecidable, 
we can use that to show other problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Recall Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
2 
","70.25297546386719","9","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_2_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"156","Is there an algorithm that can solve the halting problem for all possible computer programs?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
Use our knowledge that !TM is undecidable to show other 
problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
10 
","69.87003326416016","10","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_10_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"157","What is a binary tree?","so what is a binary tree let me draw an example and then define it more precisely mathematicians will call this a rooted binary tree because in case you've seen that in o42 say here is a picture","77.07719421386719","1","DPRSearchEngine","76dhtgZt38A.en_3_mp4","76dhtgZt38A.en","6.006","6"
"157","What is a binary tree?","Now, there are-- I mean, I could completely redraw the tree. And that's an operation that requires everything to be recomputed. So it is limited exactly what I'm allowed to do in the tree. But I claim everything we'll do, last class and today, we can afford this augmentation. So it's a feature, not of all binary trees necessarily, but of the ones that we would cover. Yeah? AUDIENCE: What is a min? ERIK DEMAINE: What is a min? AUDIENCE: [INAUDIBLE] ERIK DEMAINE: Binary tree, yeah. OK, this will make a little more sense in a moment when I say what we're actually going to do with trees. We need a new tool for manipulating a tree.","74.6631088256836","2","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_14_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"157","What is a binary tree?","we can talk about that more over the break. And so we'll return here in five minutes. Somebody's asking about-- can infinite sequences be generated by the machine. When we're talking about, especially in the complexity section of the course, all of the computations are going to be bounded in time. So we're not going to be thinking about infinite runs of the machine. That's not going to be relevant for us. So let's not think about that. How does a Turing machine perform division? How does a Turing machine perform division? Well, how do you perform division? [LAUGHS] Long division is an operation that can run in-- the long division procedure that you learn in grade school, you can implement that on a Turing machine. Yes, a Turing machine can definitely perform-- do long division, or division of one integer by another in polynomial time. Another question. Can we generally say, try dividing y by x? Or do we have to enumerate a string of length y and cross off every-- no. I think that's the same question. I mean, if you have numbers written in binary, how would you do the division? You're not going to use long division. Anything such as the thing that's proposed here by the questioner is going to be an exponential algorithm. So don't do it that way. Why does primes in P-- composites in P not imply primes in P? It does imply. If composites are in P, then primes is in P as well. When you have a deterministic machine, you can flip the answer. When you have a non-deterministic machine, you may not be able to flip the answer. So deterministic machine just having a single branch, you can make another deterministic machine that runs in the same amount of time that does the complementary language. Because for deterministic machines, just like for deciders in the computability section, you can just invert the answer. There is an analogy here between P and decidability, and NP and recognizability. It's not an airtight analogy here, but there is some relationship there. Somebody's asking me, what are the implications of P equal to NP? Lots of implications. Too long to enumerate now. But, for example, you would be able to break basically all cryptosystems that I'm aware of, if P equal to NP. So we would have a lot of consequences. Somebody's asking, so composites-- primality and compositeness testing is solvable in polynomial time. But factoring, interestingly enough, is not known to be solvable in polynomial time. We may talk about this a little bit toward the end of the term if we have time. The algorithms for testing whether a number is prime or composite in polynomial time do not operate by looking for factors. They operate in an entirely different way, basically by showing that a number is prime or composite by looking at certain properties of that number. But without testing whether it has-- testing, but without finding a factor. Another question here about asking when we talk about encodings, do we have to say how we encode numbers, values? No, we don't have to. We usually don't have to get into spelling out encodings, as long as they're reasonable encodings. So you don't have to usually. We're going to be talking about things at a high enough level that the specific encodings are not going to matter. Let's return to the rest of our lecture.","73.88438415527344","3","DPRSearchEngine","1VhnDdQsELo.en-j3PyPqV-e1s_10_mp4","1VhnDdQsELo.en-j3PyPqV-e1s","18.404J","14"
"157","What is a binary tree?","!""#$""%&'(% ∈NP
Defn:  !""#$""%&'(% = + + is not prime and + is written in binary} 
= + + = ,- for integers ,, - > 1,  + in binary} 
Theorem:  !""#$""%&'(% ∈NP
Proof:   “On input +
1.  Nondeterministically write , where 1 < , < +.
2.  Accept if , divides + with remainder 0.
Reject if not.”
Note:  Using base 10 instead of base 2 wouldn’t matter because can convert in 
polynomial time.
Bad encoding:  write number 3 in unary:  14 = 111 ⋯1
4
, exponentially longer.
Theorem (2002):  !""#$""%&'(% ∈P
We won’t cover this proof.
5
","72.31459045410156","4","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_5_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"157","What is a binary tree?","I'll call them left justified. And these two properties together is what I call a complete binary tree. Why is this interesting? Because I claim I can represent a tree like this as an array. I've narrowed things down enough that I can draw an array down here. And what I'm going to do is write these nodes in depth order. So I write A first, because that's step 0. Then B, C, that's step 1. Then, well, they're alphabetical. I made it that way. D, E, F, G is depth 2. And then H, I, J is step 3. This is very different from traversal order of a tree. Traversal order would have been H, D, I, B, J, E, A, F, C, G, OK? But this is what we might call depth order, do the lowest depth nodes first-- very different way to lay things out or to linearize our data. And this is what a heap is going to look like. So the cool thing is, between complete binary trees and arrays is a bijection. For every array, there's a unique complete binary tree. And for every complete binary tree, there's a unique array. Why? Because the complete constraint forces everything-- forces my hand. There's only-- if I give you a number n, there is one tree shape of size n, right? You just fill in the nodes top down until you get to the last level. And then you have to fill them in left to right. It's what you might call reading order for writing down nodes. And the array is telling you which keys go where. This is the first node you write down at the root, this is the next node you write down at the left child of the root, and so on. So here we have a binary tree represented as an array, or array representing a binary tree. The very specific binary tree, it has a clear advantage, which is it is guaranteed balance. No rotations necessary in heaps, because complete binary trees are always balanced. In fact, they have the best height they possibly could, which is ceiling of log n. Balanced, remember, just meant you were big O of log n. This is 1 times log n. So it's the best level of balance you could hope for. So somehow, I claim, we can maintain a complete binary tree for solving priority queues. This would not be possible if you were trying to solve the whole set interface. And that's kind of the cool thing about heaps, is that by just focusing on the subset of the set interface, we can do more. We can maintain this very strong property. And because we have this very strong property, we don't even need to store this tree. We're not going to store left and right pointers and parent pointers, we're just going to store the array.","71.78813934326172","5","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_8_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"157","What is a binary tree?","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","71.61639404296875","6","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"157","What is a binary tree?"," 
 
  
 
 
 
 
 
 
  
 
 
 
 
 
 
  
18.404/6.840 Lecture 23 
Last time: 
- !""#$%↑ is EXPSPACE-complete 
- Thus !""#$%↑ ∉ PSPACE 
- Oracles and P versus NP 
Today: (Sipser §10.2) 
- Probabilistic computation 
- The class BPP 
- Branching programs 
1 
","71.33434295654297","7","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_1_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"157","What is a binary tree?","What are oracles? Oracles are a simple thing. But they are a useful concept for a number of reasons. Especially because they're going to tell us something interesting about methods, which may or may not be useful for proving the P versus NP question, when someday somebody hopefully does that. What is an oracle? An oracle is free information you're going to give to a Turing machine, which might affect the difficulty of solving problems. And the way we're going to represent that free information is, we're going to allow the Turing machine to test membership in some specified language, without charging for the work involved. I'm going to allow you have any language at all, some language A. And say a Turing machine with an oracle for A is written this way, M with a superscript A. It's a machine that has a black box that can answer questions. Is some string, which the machine can choose, in A or not? And it gets that answer in one step, effectively for free. So you can imagine, depending upon the language that you're providing to the machine, that may or may not be useful. For example, suppose I give you an oracle for the SAT language. That can be very useful. It could be very useful for deciding SAT, for example. Because now you don't have to go through a brute force search to solve SAT. You just ask the oracle. And the oracle is going to say, yes it's satisfiable, or no it's not satisfiable. But you can use that to solve other languages too, quickly. Because anything that you can do in NP, you can reduce to SAT. So you can convert it to a SAT question, which you can then ship up to the oracle, and the oracle is going to tell you the answer. The word ""oracle"" already sort of conveys something magical. We're not really going to be concerned with the operation of the oracle, so don't ask me how does the oracle work, or what does it correspond to in reality. It doesn't. It's just a mathematical device which provides this free information to the Turing machine, which enables it to compute certain things. It turns out to be a useful concept. It's used in cryptography, where you might imagine the oracle could provide the factors to some number, or the password to some system or something. Free information. And then what can you do with that? So this is a notion that comes up in other places. If we have an oracle, we can think of all of the things that you can compute in polynomial time relative to that oracle. So that's what we-- the terminology that people usually use is sometimes called relativism, or computation relative to having this extra information. So P with an A oracle is all of the language that you can decide in polynomial time if you have an oracle for A. Let's see. Yeah. Somebody's asking me, is it really free or does it cost one unit? Even just setting up the oracle and writing down the question to the oracle is going to take you some number of steps. So you're not going to be able do an infinite number of oracle calls in zero time. So charging one step or zero steps, not going to make a difference. Because you still have to formulate the question. As I pointed out, P with a SAT oracle-- so all the things you do in polynomial time with a SAT oracle includes NP. Does it perhaps include other stuff? Or does it equal NP? Would have been a good check-in question, but I'm not going to ask that. In fact, it seems like it contains other things too. Because co-NP is also contained within P, given a SAT oracle. Because the SAT oracle answer is both yes or no, depending upon the answer. So if the formula is unsatisfiable, the oracle is going to say no, it's not in the language. And now you can do the complement of the SAT problem as well. The unsatisfiability problem. So you can do all of co-NP in the same way. You can also define NP relative to some oracle. So all the things you can do with a non-deterministic Turing machine, where all of the branches have separately access. And they can ask multiple questions, by the way, of the oracle. Independently. Let's do another, a little bit of a more challenging example. The MIN-FORMULA language, which I hope you remember from your homework. So those are all of the formulas that do not have a shorter equivalent formula. They are minimal. You cannot make a smaller formula that's equivalent that gives you the same Boolean function. So you showed, for example, that that language is in P space, as I recall. And there was some other-- you had another two problems about that language. The complement of the MIN-FORMULA problem is in NP with a SAT oracle. So mull that over for a second and then we'll see why. Here's an algorithm, in NP with a SAT oracle algorithm. So in other words, now I want to kind of implement that strategy, which I argued in the homework problem was not legal. But now that I have the SAT oracle, it's going to make it possible where before it was not possible. So let's just understand what I mean by that. If I'm trying to do the non minimal formulas, namely the formulas that do have a shorter equivalent formula. I'm going to guess that shorter formula, called psi. The challenge before was testing whether that shorter formula was actually equivalent to phi. Because that's not obviously doable in polynomial time. But the equivalence problem for formulas is a co-NP problem. Or if you like to think about it the other way, any formula in equivalence is an NP problem, because you just have to-- the witness is the assignment on which they disagree. So two formulas are equivalent if they never disagree. And so that's a co-NP problem. A SAT oracle can solve a co-NP problem. Namely, the equivalence of the two formulas, the input formula and the one that you now deterministically guessed. And if it turns out that they are equivalent, a smaller formula is equivalent to the input formula, you know the input formula is not minimal. And so you can accept. And if it gets the wrong formula, it turns out not to be equivalent, then you reject on that branch of the non-determinism, just like we did before. And if the formula really was minimal, none of the branches is going to find a shorter equivalent formula. So that's why this problem here is in NP with a SAT oracle. So now we're going to try to investigate this on my-- we're getting near the end of the lecture. We're going to look at problems like, well, suppose I compare P with a SAT oracle and NP with a SAT oracle. Could those be the same? Well, there's reasons to believe those are not the same. But could there be any A where P with A oracle is the same as NP with an A oracle? It seems like no, but actually that's wrong. There is a language, there are languages for which NP with that oracle and P with that oracle are exactly the same. And that actually is an interest-- it's not just a curiosity, it actually has relevance to strategies for solving P versus NP. Hopefully I'll be able to have time to get to. Can we think of an oracle like a hash table? I think hashing is somehow different in spirit. I understand there's some similarity there, but I don't see the-- hashing is a way of finding sort of a short name for objects, which has a variety of different purposes why you might want to do that. So I don't really think it's the same. Let's see, an oracle question, OK, let's see. How do we use SAT oracle to solve whether two formulas are equivalent? OK, this is getting back to this point. How can we use a SAT oracle to solve whether two formulas are equivalent? Well, we can use a SAT oracle to solve any NP problem, because it's reducible to SAT. In other words-- P with a SAT oracle contains all of NP, so you have to make sure you understand that part. If you have the clique problem, you can reduce. If I give you a clique problem, which is an NP problem, and I want to use the oracle to test if the formula-- if the graph has a clique, I reduce that problem to a SAT problem using the Cook-Levin theorem. And knowing that a clique of a certain size is going to correspond to having a formula which is satisfiable, now I can ask the oracle. And if I can do NP problems, I can do co-NP problems, because P is a deterministic class. Even though it has an oracle, it's still deterministic. It can invert the answer. Something that non-deterministic machines cannot necessarily do. So I don't know, maybe that's-- let's move on. So there's an oracle where P to the A equals NP to the A, which kind of seems kind of amazing at some level. Because here's an oracle where the non-determinism-- if I give you that oracle, non-determinism doesn't help. And it's actually a language we've seen. It's TQBF. Why is that? Well, here's the whole proof. If I have NP with a TQBF oracle. Let's just check each of these steps. I claim I can do that with a non-deterministic polynomial space machine, which no longer has an oracle. The reason is that, if I have polynomial space, I can answer questions about TQBF without needing an oracle. I have enough space just to answer the question directly myself. And I use my non-determinism here to simulate the non-determinism of the NP machine. So every time the NP machine branches non-deterministically, so do I. Every time one of those branches asks the oracle a TQBF question, I just do my polynomial space algorithm to solve that question myself. But now NPSPACE equals PSPACE by Savitch's theorem. And because TQBF is PSPACE complete, for the very same reason that a SAT oracle allows me to do every NP problem, a TQBF problem allows me to do every PSPACE problem. And so I get NP contained within P for a TQBF oracle. And of course, you get the containment the other way immediately. So they're equal. What does that have to do with-- somebody said-- well, I'll just-- I don't want to run out of time. So I'll take any questions at the end. What does this got to do with the P versus NP problem? OK, so this is a very interesting connection. Remember, we just showed through a combination of today's lecture and yesterday's lecture, and I guess Thursday's lecture, that this problem, this equivalence problem, is not in PSPACE, and therefore it's not in P, and therefore it's intractable. That's what we just did. We showed it's complete for a class, which is provably outside of P, provably bigger than P. That's the kind of thing we would like to be able to do to separate P and NP. We would like to show that some other problem is not in P. Some other problem is intractable. Namely, SAT. If we could do SAT, then we're good. We've solved P and NP. So we already have an example of being able to do that. Could we use the same method? Which is something people did try to do many years ago, to show that SAT is not in P. So what is that method really? The guts of that method really comes from the hierarchy there. That's where you were actually proving problems that are hard. You're getting this problem with through the hierarchy construction that's provably outside of PSPACE. And outside of P. That's a diagonalization. And if you look carefully at what's going on there-- so we're going to say, no, we're not going to be able to solve SAT, show SAT's outside of P in the same way. And the reason is, suppose we could. Well the hierarchy theorems are proved by diagonalization. What I mean by that is that in the hierarchy theorem, there's a machine D, which is simulating some other machine, M. To remember what's going on there, remember that we made a machine which is going to make its language different from the language of every machine that's running with less space or with less time. That's how D was defined. It wants to make sure its language cannot be done in less space. So it makes sure that its language is different. It simulates the machines that use less space, and does something different from what they do. Well, that simulation-- if we had an oracle, if we're trying to show that if we provide both a simulator and the machine being simulated with the same oracle, the simulation still works. Every time the machine you're simulating asks a question, the simulator has the same oracle so it can also ask the same question, and can still do the simulation. So in other words, if you could prove P different from NP using basically a simulation, which is what a diagonalization is, then you would be able to prove that P is different from NP for every oracle. So if you can prove P different from NP by a diagonalization, that would also immediately prove that P is different from NP for every oracle. Because the argument is transparent to the oracle. If you just put the oracle down, everything still works. But-- here is the big but, it can't be that-- we know that P A is-- we know this is false. We just exhibit an oracle for which they're equal. It's not the case that P is different from NP for every oracle. Sometimes they're equal, for some oracles. So something that's just basically a very straightforward diagonalization, something that's at its core is a diagonalization, is not going to be enough to solve P and NP. Because otherwise it would prove that they're different for every oracle. And sometimes they're not different, for some oracles. That's an important insight for what kind of a method will not be adequate to prove P different from NP. And this comes up all the time. People who propose hypothetical solutions that they're trying to show P different from NP. One of the very first things people ask is, well, would that argument still work if you put an oracle there. Often it does, which points out there was a flaw. Anyway, last check in. So this is just a little test of your knowledge about oracles. Why don't we-- in our remaining minute here. Let's say 30 seconds. And then we'll do a wrap on this, and I'll point out which ones are right. Oh boy, we're all over the place on this one. You're liking them all. Well, I guess the ones that are false are lagging slightly. OK, let's conclude. Did I give you enough time there? Share results. So, in fact-- Yeah, so having an oracle for the complement is the same as having an oracle. So this is certainly true. NP SAT equal coNP SAT, we have no reason to believe that would be true, and we don't know it to be true. So B is not a good choice and that's the laggard here. MIN-FORMULA, well, is in PSPACE, and anything in PSPACE is reducible to TQBF, so this is certainly true. And same thing for NP with TQBF and coNP with TQBF. Once you have TQBF, you're going to get all of PSPACE. And as we pointed out, this is going to be equal as well. So why don't we end here. And I think that's my last slide. Oh no, there's my summary here. This is what we've done. And I will send you all off on your way. How does the interaction between the Turing machine and the oracle look? Yeah, I didn't define exactly how the machine interacts with an oracle. You can imagine having a separate tape where it writes the oracle question and then goes into a special query state. You can formalize it however you like. They're all going to be-- any reasonable way of formalizing it is going to come up with the same notion in the end. It does show that P with a TQBF oracle equals PSPACE. Yes, that is correct. Good point. Why do we need the oracle to be TQBF? Wouldn't SAT also work because it could solve any NP problem? So you're asking, does P with a SAT oracle equal NP with a SAT oracle? Not known. And believed not to be true, but we don't have a compelling reason for that. No one has any idea how to do that. Because, for example, we showed the complement of MIN-FORMULA is in NP with a SAT oracle. But no one knows how to do-- because there's sort of two levels of non-determinism there. There's guessing the smaller formula, and then guessing again to check the equivalence. And they really can't be combined, because one of them is sort of an exist type guessing, the other one is kind of a for all type guessing. No one knows how to do that in polynomial time with a SAT oracle. Generally believed that they're not the same. In the check-in, why was B false? B is the same question. Does NP with a SAT oracle equal coNP with a SAT oracle? I'm not saying it's false, it's just not known to be true. It doesn't follow from anything that we've shown so far. And I think that would be something that-- well, I guess it doesn't immediately imply any famous open problem. I wouldn't necessarily expect you to know that it's an unsolved problem, but it is. Could we have oracles for undecidable language? Absolutely. Would it be helpful? Well, if you're trying to solve an undecidable problem, it would be helpful. But people do study that. In fact, the original concept of oracles was presented, was derived in the computability theory. And a side note, you can talk about reducibility. No, I don't want to even go there. Too complicated. What is not known to be true? What is not known to be true is that NP with a SAT oracle equals coNP with a SAT oracle, or equals P with a SAT oracle. Nothing is known except the obvious relations among those. Those are all unknown, and just not known to be true or false. Is NP with a SAT oracle equal to NP? Probably not. NP with a SAT oracle, for one thing, contains coNP. Because it's even more powerful. We pointed out that P with a SAT oracle contains coNP. And so NP with a SAT oracle is going to be at least as good. And so it's going to contain coNP. And so, probably not going to be equal to NP unless shockingly unexpected things happen in our complexity world.","70.58582305908203","8","DPRSearchEngine","N32bnUliSzo.en-j3PyPqV-e1s_9_mp4","N32bnUliSzo.en-j3PyPqV-e1s","18.404J","22"
"157","What is a binary tree?","If you think about it a little bit, this is exactly binary search on an array. It just happens to be on a tree instead. If you think of an array like this, what does binary search do? It first looks at the key in the middle. I'm going to draw that as the root. And then, it recurses either on the left chunk, which I will draw recursively, or on the right chunk. And so if you happen to have a perfect binary tree like this one, it is simulating exactly binary search in this array. But this we're going to be able to maintain dynamically-- not perfect any more, but close. Whereas this we could not maintain in sorted order. So this is like a generalization of binary search to work on trees instead of on arrays. And for this reason, set binary trees are called binary search trees, because they're the tree version of binary search. So there's many equivalent names. So binary search tree is another name for set binary tree. And the key thing that makes this algorithm work is the so-called binary search tree property, which is all the keys in the left subtree of a node are less than the root, or of that node, and that key is less than all the keys in the right subtree. And this is true recursively all the way down. And so that's how you prove that this algorithm is correct by this property. Why is this true? Because if we can maintain traversal order to be increasing key, then that's exactly what traversal order means. It tells you all the things in the left subtree come before the root, which come before all the things in the right subtree.","70.11198425292969","9","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_4_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"157","What is a binary tree?","OK. So if I want to fill in the set interface and I have somehow a sorted array of students-- so again, they're organized by student ID number-- then my runtime starts to get a little more interesting. Yeah. So now, insertion, deletion they'd still take the same amount of time. But let's say that I want to find the student with the minimum ID number, this find min function. Well, how could I do it in a sorted array? Keyword is sorted here. Where's the min element of an array? Yes? AUDIENCE: [INAUDIBLE] JUSTIN: Yeah. In fact, I can give a moderately faster algorithm, which is just look at the first one. If I want the minimum element of an array and the array is in sorted order, I know that's the first thing. So that's order 1 time to answer that kind of a question. And similarly, if I want the thing with the biggest ID number, I look all the way at the end. Now, in 6.006-- MIT student class numbers are super confusing to me. In 6.0001, 6.042, you guys already I think learned about binary search and even may have implemented it. So what do we know? If my array is sorted, how long does it take for me to search for any given element? Yes? AUDIENCE: Log n time. JUSTIN: Log n time. That's absolutely right because I can cut my array in half. If my key is bigger or smaller, then I look on the left or the right. And so this is a much more efficient means of searching a set. So in particular, 6.006 this year has 400 students. Maybe next year, it has 4,000. And eventually, it's going to have billions. Then what's going to happen? Well, if I use my unordered array and I have a billion students in this class, what's going to happen? Well, then it's going to take me roughly a billion computations to find any one student in this course, whereas log of a billion is a heck of a lot faster. On the other hand, I've swept under the rug here, which is how do I actually get a sorted array to begin with. And what we're going to see in today's lecture is that that takes more time than building if I just have a disorganized list. Building a disorganized list is an easy thing to do.","69.83122253417969","10","DPRSearchEngine","oS9aPzUNG-s.en-j3PyPqV-e1s_11_mp4","oS9aPzUNG-s.en-j3PyPqV-e1s","6.006","3"
"158","What is the difference between solving a problem with a small input instance and an arbitrarily large input instance?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","73.87995147705078","1","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"158","What is the difference between solving a problem with a small input instance and an arbitrarily large input instance?","this is what I'm going to call h-- which maps this range down to a smaller range. Does that make sense? I'm going to have some function that takes that large base of keys-- sticks them down here. And instead of staring at an index of the key, I'm going to put the key through this function, the key space, into a compressed space and store it at that index location. Does that make sense? Sure. AUDIENCE: [INAUDIBLE] JASON KU: Your colleague is-- comes up with the question I was going to ask right away, which was, what's the problem here? The problem is it's the potential that we might be-- have to store more than one thing at the same index location. If I have a function that matches this big space down to this small space, I got to have multiple of these things going to the same places here, right? It can't be objective. But just based on pigeonhole principle, I have more of these things. At least two of them have to go to something over here. In fact, if I have, say, u is bigger than n squared, for example, there-- for any function I give you that maps this large space down to the small space, n of these things will map to the same place. So if I choose a bad function here, then I'll have to store n things at the same index location. And if I go there, I have to check to see whether any of those are the things that I'm looking for. I haven't gained anything. I really want a hash function that will evenly distribute keys over this space. Does that make sense? But we have a problem here. If we need to store multiple things at a given location in memory-- can't do that. I have one thing I can put there. So I have two options on how to deal-- what I call collisions. If I have two items here, like a and b, these are different keys in my universe of space. But it's possible that they both map down to some hash that has the same value. If I first hash a, and a is-- I put a there, where do I put b? There are two options. AUDIENCE: Is the second data structure [INAUDIBLE] so that it can store [INAUDIBLE]?? JASON KU: OK, so what your colleague is saying-- can I store this one is a linked list, and then I can just insert a guy right next to where it was? What's the problem there? Are linked lists good with direct accessing by an index? No, they're terrible with get_at and set_at They take linear time there. So really, the whole point of direct this array is that there is an array underneath, and I can do this index arithmetic and go down to the next thing. So I really don't want to replace a linked list as this data structure. Yeah? What's up? AUDIENCE: [INAUDIBLE] JASON KU: We can make it really unlikely. Sure. I don't know what likely means, because I'm giving you a hash function-- one hash function. And I don't know what the inputs are. Yeah? Go ahead. AUDIENCE: [INAUDIBLE] JASON KU: OK, right. So there are actually two solutions here. One is I-- maybe, if I choose m to be larger than n, there's going to be extra space in here. I'll just stick it somewhere else in the existing array. How I find an open space is a little complicated, but this is a technique called open addressing, which is much more common than the technique we're going to be talking about today in implementations. Python uses an open addressing scheme, which is essentially, find another place in the array to put this collision. Open addressing is notoriously difficult to analyze, so we're not going to do that in this class. There's a much easier technique that-- we have an implementation for you in the recitation handouts. It's what your colleague up here-- I can't find him-- over there was saying-- was, instead of storing it somewhere else in the existing direct access array down here, which we usually call the hash table-- instead of storing it somewhere else in that hash table, we'll instead, at that key, store a pointer to another data structure, some other data structure that can store a bunch of things-- just like any sequence data structure, like a dynamic array, or linked list, or anything right. All I need to do is be able to stick a bunch of things on there when there are collisions, and then, when I go up to look for that thing, I'll just look through all of the things in that data structure and see if my key exists. Does that make sense? Now, we want to make sure that those additional data structures, which I'll call chains-- we want to make sure that those chains are short. I don't want them to be long. So what I'm going to do is, when I have this collision here, instead I'll have a pointer to some-- I don't know-- maybe make it a dynamic array, or a linked list, or something like that. And I'll put a here and I'll b here. And then later, when I look up key K, or look up a or b-- let's look up b-- I'll go to this hash value here. I'll put it through the hash function. I'll go to this index. I'll go to the data structure, the chain associated to that index, and I'll look at all of these items. I'm just going to do a linear find. I'm going to look. I could put any data structure here, but I'm going to look at this one, see if it's b. It's not b. Look at this one-- it is b. I return yes. Does that make sense? So this is an idea called chaining. I can put anything I want there. Commonly, we talk about putting a linked list there, but you can put a dynamic array there. You can put a sorted array there to make it easier to check whether the key is there. You can put anything you want there. The point of this lecture is going to try to show that there's a choice of hash function I can make that make sure that these chains are small so that it really doesn't matter how I saw them there, because I can just-- if there's a constant number of things stored there, I can just look at all of them and do whatever I want, and still get constant time. Yeah? AUDIENCE: So does that means that, when you have [INAUDIBLE] let's just say, for some reason, the number of things [INAUDIBLE] is that most of them get multiple [INAUDIBLE].. Is it just a data structure that only holds one thing? JASON KU: Yeah. So what your colleague is saying is, at initialization, what is stored here? Initially, it points to an empty data structure. I'm just going to initialize all of these things to have-- now, you get some overhead here. We're paying something for this-- some extra space and having pointer and another data structure at all of these things. Or you could have the semantics where, if I only have one thing here, I'm going to store that thing at this location, but if I have multiple, it points to a data structure. These are kind of complicated implementation details, but you get the basic idea. If I just have a 0 size data structure at all of these things, I'm still going to have a constant factor overhead. It's still going to be a linear size data structure, as long as m is linear in n. Does that makes sense? OK. So how do we pick a good hash function? I already told you that any fixed hash function I give you is going to experience collisions. And if u is large, then there's the possibility that I-- for some input, all of the things in my set go directly to the same hashed index value. So that ain't great. Let's ignore that for a second. What's the easiest way to get down from this large space of keys down to a small one? What's the easiest thing you could do? Yeah? AUDIENCE: [INAUDIBLE] JASON KU: Modulus-- great. This is called the division method. And what its function is is essentially, it's going to take a key and it's going to say equal to be K mod m. I'm going to take something of a large space, and I'm going to mod it so that it just wraps around-- perfectly valid thing to do. It satisfies what we're doing in a hash table. And if my kids are completely uniformly distributed-- if, when I use my hash function, all of the keys here are uniformly distributed over this larger space, then actually, this isn't such a bad thing. But that's imposing some kind of distribution requirements on the type of inputs I'm allowed to use with this hash function for it to have good performance. But this plus a little bit of extra mixing and bit manipulation is essentially what Python does. Essentially, all it does is jumbles up that key for some fixed amount of jumbling, and then mods it m, and sticks it there. It's hard coded in the Python library, what this hash function is, and so there exist some sequences of inserts into a hash table in Python which will be really bad in terms of performance, because these chain links are the amount number of collisions that I'll get at a single hash is going to be large. But they do that for other reasons. They want a deterministic hash function. They want something that I do the program again-- it's going to do the same thing underneath. But sometimes Python gets it wrong. But if your data that you're storing is sufficiently uncorrelated to the hash function that they've chosen-- which, usually, it is-- this is a pretty good performance. But this is not a practical class. Well, it is a practical class, but one of the things that we are-- that's the emphasis of this class is making sure we can prove that this is good in theory as well. I don't want to know that sometimes this will be good. I really want to know that, if I choose-- if I make this data structure and I put some inputs on it, I want a running time that is independent on what inputs I decided to use, independent of what keys I decided to store. Does that makes sense? But it's impossible for me to pick a fixed hash function that will achieve this, because I just told you that, if u is large-- this is u-- if u is large, then there exists inputs that map everything to one place. I'm screwed, right? There's no way to solve this problem. That's true if I want a deterministic hash function-- I want the thing to be repeatable, to do the same thing over and over again for any set of inputs. What can I do instead? Weaken my notion of what constant time is to do better-- OK, use a non-deterministic-- what does non-deterministic mean? It means don't choose a hash function up front-- choose one randomly later. So have the user-- they pick whatever inputs they're going to do, and then I'm going to pick a hash function randomly. They don't know which hash function I'm going to pick, so it's hard for them to give me an input that's bad. I'm going to choose a random hash function. Can I choose a hash function from the space of all hash functions? What is the space of all hash functions of this form? For every one of these values, I give a value in here. For each one of these independently random number between this range, how many such hash functions are there? m to the this number-- that's a lot of things. So I can't do that. What I can do is fix a family of hash functions where, if I choose one from-- randomly, I get good performance. And so the hash function I'm going to use, and we're going to spend the rest of the time on,","73.68023681640625","2","DPRSearchEngine","Nu8YGneFCWE.en-j3PyPqV-e1s_8_mp4","Nu8YGneFCWE.en-j3PyPqV-e1s","6.006","4"
"158","What is the difference between solving a problem with a small input instance and an arbitrarily large input instance?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 19: Complexity 
Lecture 19: Complexity 
Decision Problems 
• Decision problem: assignment of inputs to YES (1) or NO (0) 
• Inputs are either NO inputs or YES inputs 
Problem 
s-t Shortest Path Does a given G contain a path from s to t with weight at most d? 
Negative Cycle Does a given G contain a negative weight cycle? 
Longest Simple Path Does a given G contain a simple path with weight at least d? 
Subset Sum Does a given set of integers A contain a subset with sum S? 
Tetris Can you survive a given sequence of pieces in given board? 
Chess Can a player force a win from a given board? 
Halting problem Does a given computer program terminate for a given input? 
Decision 
• Algorithm/Program: constant-length code (working on a word-RAM with Ω(log n)-bit 
words) to solve a problem, i.e., it produces correct output for every input and the length 
of the code is independent of the instance size 
• Problem is decidable if there exists a program to solve the problem in ﬁnite time 
Decidability 
• Program is ﬁnite (constant) string of bits, i.e., a nonnegative integer ∈ N. 
Problem is function p : N →{0, 1}, i.e., inﬁnite string of bits. 
• (# of programs |N|, countably inﬁnite) ≪ (# of problems |R|, uncountably inﬁnite) 
• (Proof by Cantor’s diagonalization argument, probably covered in 6.042) 
• Proves that most decision problems not solvable by any program (undecidable) 
• E.g., the Halting problem is undecidable (many awesome proofs in 6.045) 
• Fortunately most problems we think of are algorithmic in structure and are decidable 
Decidable Decision Problems 
R problems decidable in ﬁnite time 
(‘R’ comes from recursive languages) 
EXP problems decidable in exponential time 2nO(1) 
(most problems we think of are here) 
P problems decidable in polynomial time nO(1) 
(efﬁcient algorithms, the focus of this class) 
• These sets are distinct, i.e., P $ EXP $ R (via time hierarchy theorems, see 6.045) 
• E.g., Chess is in EXP \\ P 
","73.51971435546875","3","DPRSearchEngine","fda666a4db1dc65b3d71be08115502bd_MIT6_006S20_lec19_1_pdf","fda666a4db1dc65b3d71be08115502bd_MIT6_006S20_lec19","6.006","19"
"158","What is the difference between solving a problem with a small input instance and an arbitrarily large input instance?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 4: Hashing 
Lecture 4: Hashing 
Review 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
• Idea! Want faster search and dynamic operations. Can we find(k) faster than Θ(log n)? 
• Answer is no (lower bound)! (But actually, yes...!?) 
Comparison Model 
• In this model, assume algorithm can only differentiate items via comparisons 
• Comparable items: black boxes only supporting comparisons between pairs 
• Comparisons are <, ≤, >, ≥, =, =6 , outputs are binary: True or False 
• Goal: Store a set of n comparable items, support find(k) operation 
• Running time is lower bounded by # comparisons performed, so count comparisons! 
Decision Tree 
• Any algorithm can be viewed as a decision tree of operations performed 
• An internal node represents a binary comparison, branching either True or False 
• For a comparison algorithm, the decision tree is binary (draw example) 
• A leaf represents algorithm termination, resulting in an algorithm output 
• A root-to-leaf path represents an execution of the algorithm on some input 
• Need at least one leaf for each algorithm output, so search requires ≥ n + 1 leaves 
","73.31509399414062","4","DPRSearchEngine","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_1_pdf","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4","6.006","4"
"158","What is the difference between solving a problem with a small input instance and an arbitrarily large input instance?"," 
 
 
 
 
Clustering  Is  an Optimization Problem  
§Why not divide variability by size of cluster? 
◦ Big and bad worse than small and bad 
§Is optimization problem finding a C that minimizes 
dissimilarity(C)? 
◦ No, otherwise could put each example in its own 
cluster 
§Need a constraint, e.g., 
◦ Minimum distance between clusters 
◦ Number of clusters 
6.0002  LECTURE 12 
4 
","73.29302978515625","5","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_4_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"158","What is the difference between solving a problem with a small input instance and an arbitrarily large input instance?"," 
 
 
  
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
Computation with Oracles 
Let ! be any language. 
Defn: A TM "" with oracle for !, written ""#, is a TM equipped 
with a “black box” that can answer queries “is $ ∈!?” for free. 
Example: A TM with an oracle for &!' can decide all ( ∈ NP in polynomial time. 
Defn: P# = ( ( is decidable in polynomial time with an oracle for !} 
Thus NP ⊆ P+#, 
NP = P+#,? Probably No because coNP ⊆ P+#, 
Defn: NP# = ( ( is decidable in nondeterministic polynomial time with an oracle for !} 
Recall MIN-FORMULA = 7 7 is a minimal Boolean formula } 
Example: MIN−FORMULA ∈ NP+#, 
“On input 7 
1. Guess shorter formula 9 
2.  Use &!' oracle to solve the coNP problem: 7 and 9 are equivalent 
3. Accept if 7 and 9 are equivalent. Reject if not.” 
8 
","73.21681213378906","6","DPRSearchEngine","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_8_pdf","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22","18.404J","22"
"158","What is the difference between solving a problem with a small input instance and an arbitrarily large input instance?"," 
 
 
 
  
 
 
  
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Intro to Complexity Theory 
Computability theory (1930s - 1950s): 
Is A decidable? 
Complexity theory (1960s - present): 
Is A decidable with restricted resources? 
(time/memory/…) 
Example: Let ! = a#b# $ ≥0 . 
Q: How many steps are needed to decide !? 
Depends on the input. 
We give an upper bound for all inputs of length '. 
Called “worst-case complexity”. 
2 
","72.97128295898438","7","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_2_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"158","What is the difference between solving a problem with a small input instance and an arbitrarily large input instance?","And a comparison model means-- is that the items, the objects I'm storing-- I can kind of think of them as black boxes. I don't get to touch these things, except the only way that I can distinguish between them is to say, given a key and an item, or two items, I can do a comparison on those keys. Are these keys the same? Is this key bigger than this one? Is it smaller than this one? Those are the only operations I get to do with them. Say, if the keys are numbers, I don't get to look at what number that is. I just get to take two keys and compare them. And actually, all of the search algorithms that we saw on Tuesday we're comparison sort algorithms. What you did was stepped through the program. At some point, you came to a branch and you looked at two keys, and you branched based on whether one key was bigger than another. That was a comparison. And then you move some stuff around, but that was the general paradigm. Those three sorting operations lived in this comparison model.","72.70491027832031","8","DPRSearchEngine","Nu8YGneFCWE.en-j3PyPqV-e1s_2_mp4","Nu8YGneFCWE.en-j3PyPqV-e1s","6.006","4"
"158","What is the difference between solving a problem with a small input instance and an arbitrarily large input instance?","equivalents of regular expressions. Can we now conclude that this problem is also decidable, either immediately from stuff we've already shown; or yes, but would take some significant extra work; or no, because intersection is not a regular operation? So let's see if I can pull that out here-- launch the polling. Here we go. OK, I think we're just about done here. Five seconds more-- OK, ready, set, end. All right. Yes, the correct answer is A. We have basically already shown this fact, because-- why is that? Because we have shown that we can convert-- if you're given two regular expressions, and we want to test whether they're equivalent, they generate the same language, we can convert them both to find out automata. We can convert them to NFAs, and then the NFAs to DFAs. And then we can apply what we've just showed about testing equivalence of DFAs. So yes, it really follows immediately from stuff we've already shown-- the conversion, number one, and then the testing of equivalence for DFAs. So there's not really any work to do here. And in fact, what I'm trying to illustrate with this check-in-- that, once you've shown how to do some kind of a test for one model, it-- going to apply for all of the equivalent models that we've shown to be equivalent, because the Turing machine can do the constructions which show the equivalence. OK, so let's move on. Somebody didn't get the poll. Did most people not get the poll? Well, I think most of you have gotten it. Did you? I'm not seeing a lot of complaints. So if you didn't get the poll, something is wrong with your setup, and you're going to have to take the recorded check-ins that are going to launch right after this lecture's over. Sorry. But you should figure out what's wrong with the setup there, because I think most people are getting these. OK, and with that, we're going to take a little break, and then we'll continue on afterward. Let me know how this is-- should I be speed a little speedier about the little mini breaks that we're taking, or is this good for you? Feedback is always-- I'm trying to make this as good as I can for all of you. OK, I think there's a mixture of between people saying that these breaks are good. Someone says they're a little overlong, so I'll try to tighten them up a little. Some folks are saying what-- more people should be asking the TAs. I don't know how the TAs are doing, in terms of their-- I'll check with them afterward-- how well this is going for them, in terms of the questions. But I think some amount of break is good so that we don't-- so there's time to be asking questions. Otherwise, what's the point of having a live lecture? So we will start promptly when this timer runs down. So be ready to go in 55 seconds from now. Just to confirm, to show the decidability of the equivalence of two regular expressions, do we need to show that we can use a Turing machine to convert them to two DFAs first? If you want to test whether two regular expressions are equivalent, you can give any procedure for doing that deciding you want. I'm just offering one simple way to do it that takes advantage of stuff we've already shown. But if you want to dig down and do some analysis of those regular expressions to show that they describe the same language, they generate the same language, be my guest. I think that's-- actually would be complicated to do that that way. OK, so we're just about ready to go here, so let's continue. And let me take this timer off here. All right. Now, we are going to talk a little about context-free grammars. So we talked about decision problems for finite automata. Let's talk about some for grammars. OK, now I'm going to give us an analogous problem. I'm going to give you a-- I'm calling it the acceptance problem, but-- just for consistency with everything else, but it's really the generating problem. So I'm giving you a grammar-- context-free grammar G and a string that's in a string. And I want to know, is it in the language of G? So does G generate w? I'm calling that the ACFG problem. So that's going to be a decidable again. These are getting slightly harder as we're moving along, so I'm giving you a grammar and a string, and I want to know, does the grammar generate that string? Well, it's not totally trivial to solve that. One thing you might try doing is looking at all possible things, all possible derivations from that grammar and see if any one of them leads to w-- leads you to generate w. Well, you have to be careful, because as I've-- as we've shown in some of our examples, you actually could have-- because you're allowed to have variables that can get converted to empty string, you might have very long intermediate strings being generated from a, grammar which then ultimately give you a small string of terminals that get generated, a small string in the language that gets produced. You certainly don't want to try every possible derivation, because there's infinitely many different derivations-- most of them generating, of course, things that are irrelevant to the string w. But you have to know how to cut things off, and it's not immediately obvious how you do that-- unless you have done the homework problems that I asked you to do, which I'm sure very many of you have not done-- the zero point X problems, because they're-- that's going to come in handy right now. And so I'll help you through that. Remember-- you should remember, but you may not have looked at it-- something called Chomsky normal form, which is for context-free grammars, but only allows the rules to be of a special kind. And they have to look like this. They can be a variable that goes to two variables, on the right-hand side, or a variable that goes to a terminal. Those are the only kinds of rules that you're allowed. This is a special case for the empty string, but let's ignore that for-- the start variable can also work to the empty string, if you want to have a-- the empty string in a language. But that's a special case. Let's ignore that. These are the only two kinds of rules that you can have in a Chomsky normal form grammar. Once you have a Chomsky normal form grammar-- well, first of all, there's two things. First of all, you can always convert any context-free grammar into Chomsky normal form. So that's given in the textbook. You do the obvious thing. I'm not going to spend time on it. And you don't have to know it. It's just a little bit tedious, but it's straightforward and it's there, if you're curious. But the second lemma's the thing that's important to us, which is that, if you have a grammar which is in Chomsky normal form and a string that's generated, every derivation of that string has exactly 2 times the length of the string minus 1 steps. If you think about it, this is a lemma-- very easy to prove. I think the homework problem asks you to prove that in the 0.2 or whatever it was in problem set 1-- or problem set 2-- I don't remember. Rules of this kind allow you to make the string one longer, and rules of this kind allow you to produce a new terminal symbol. If the length w is n, you're going to have n minus 1 of these and n of. Those that's why you get 2n minus 1 steps. But the point is that I don't really care exactly how many. It's just that we have a bound. And once you have that bound, life is good from the point of view of giving a Turing machine which is going to decide this language-- because here's the Turing machine. What it's going to do-- the first thing is it's going to convert G into Chomsky normal form. That we assume we know how to do. Now, we're going to try all derivations, but only those of length 2-- twice the length of the string minus 1, because if any derivation is going to generate w, it has to be this many steps, now that we know the grammar is in Chomsky normal form. OK, so we have converted this problem of one that might be a very unboundedly lengthy problem and to one where it's going to terminate after some fixed number of steps. And so therefore, we can accept, if any of those generate w, and reject if not. OK? Before moving on, so this answers the problem-- shows that this language is decidable, the ACFG language. So that's something that-- make sure you understand. We're basically trying old derivations of up to-- of a certain length, because that's all that's needed when the grammar is in that form. Now we're going to use that to prove a corollary, which is important for understanding how everything fits together. And that corollary states that every context-free language is a decidable language. Every context-free language is decidable. Now, why does that follow from this? Well, suppose you have a context-free language. We know that language is generated by some context-free grammar G. That's what it means. So then you can take that grammar G and you can build it into a Turing machine. So there's going to be a term machine which is constructed with the knowledge of G. And that Turing machine is going to take its w and run the ACFG algorithm with w combined with a G that's already built into it. So it's just going to stick that grammar G in front of w, and now we run the ACFG decider. It's going to say, does degenerate w? Well, that's going to be yes every time w is in A. And so this machine here now is going to end up accepting every string that's in A, because it's every string that G generates. So that is, I think, what I wanted to say about this. Now, I feel that this corollary here throws a little bit of a curveball. And we can just pause for a moment here just to make sure you're understanding this. The tricky thing about this corollary is-- that I often get-- a question I often get where-- is when we start off with a context-free language, who gives-- how do we get G? Because we need G to build a Turing machine M sub G. So we know A is a context-free language, but how do we know what G is? Well, the point is that we may not know what G is, but we know G exists, because that's a definition of A being a context-free language. It must have a context-free grammar, by definition. And so because G exists, I now know my Turing machine, M sub G, exists. And that's enough to know that A is decidable, because it has a decider that exists. Now, if you're not going to tell me the grammar for G, I'm not going to tell you the Turing machine which decides A. But both of them exist. So if you tell me G, then I can tell you the Turing machine. So it's a subtle, tricky issue there. A certain little element maybe of-- sometimes people call it non-constructive, because we're just, in a sense, showing just that something is existing. It does the job for us, because it shows that A is a decidable language. OK, so not so many questions here-- maybe the TAs are getting them. So let's move on. Here's another check-in. So now, can we conclude that A-- instead of ACFG, APDA is decidable? People are getting this one pretty fast. Another 10 seconds-- three seconds-- OK, going to shut it down-- end polling, share results. Yeah. So this problem here is APDA is decidable. I was almost wondering whether or not to give this poll, because it has-- it's true for the same reason as poll number 1, because we know how to convert PDAs-- or we stated we can convert PDAs to CFGs. And that conversion has given in the book. We didn't do in lecture, but I just stated you have to know that fact, but not necessarily know how to do it. That's OK. But the fact is true. The conversion is in the book, and it could be implemented on a Turing machine. So if you want to know whether a PDA's language is empty, you convert it to a context-free grammar and then use this procedure here to test whether it's a language--","72.10761260986328","9","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_11_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"158","What is the difference between solving a problem with a small input instance and an arbitrarily large input instance?","you might find one way or the other more intuitive. They're equivalent. So as long as you understand at least one of them, it's good. NP is just a class of decision problems. So I define P and EXP and R arbitrary. They can be problems with any kind of output. But NP only makes sense for decision problems. And it's going to look almost like the definition of P-- problem solvable in polynomial time. We've just restricted to decision problems. But we're going to allow a strange kind of computer or algorithm, which I like to call a lucky algorithm. And this is going to relate to the notion of guessing that we talked about for the last four lectures in dynamic programming. With dynamic programming, we said, oh, there are all these different choices I could make. What's the right choice? I don't know, so I'd like to make a guess. And what that meant in terms of a real algorithm is, we tried all of the possibilities, and then took the max or the OR or whatever over all those possibilities. And so we were-- but what we were simulating is something that I call a lucky algorithm, which can make guesses and always makes the right guess. This is a computer that is impossible to buy. It would be great if you could buy a computer that's lucky. But we don't know how to build such a computer. So what does this mean? So informally, it means your algorithm can make lucky guesses, and it always makes the right guess. And whereas in DP, we had to try all the options and spend time for all of them, the lucky algorithm only has to spend time on the lucky guess, on the correct guess. More formally, this is called a non-deterministic model of computation. And this N is the-- the N in non-determinism is the N for NP. So this is non-deterministic polynomial time. So algorithm can make guesses. And then in the end, it should output yes or no. Like say if you're exploring a maze, this algorithm could say, should I go left or go right? I'm going to guess whether to go left or go right. And let's say it guesses left. And so then it just goes left. And then it reaches another junction. It says, should I go left or right? And it'll say, I'll guess, and it'll say, guess right this time. And in the end, if I get to some dead end maybe and I say no, or if I get to the destination I'm trying to get to, I say yes. So that's a non-deterministic algorithm. And what does it mean to run that algorithm? What does it mean for the guesses to be lucky? Here's what it means. These guesses are guaranteed-- which way you end up going is guaranteed to lead you to a yes if there is one-- if possible. So in my maze analogy, if my destination is reachable from my source, then I'm guaranteed, whenever I guessed left or right, I will choose a path that leads me to my destination. Whereas, if the destination is in some disconnected part of the maze and I can't get there, then I don't know what the guesses do. It doesn't really matter. Because no matter what I do, I'll end up in a dead end and say no. That's the model. As long as you have an algorithm that always outputs yes or no in polynomial time-- because we're only talking about polynomial time, lucky algorithms-- if there's any way to get to a yes, then your machine will magically find it without having to spend any time to make these decisions. So it's a pretty magical computer, and it's not a computer that exists in real life. But it's a computer that's great to program on. It's very powerful. You could solve lots of things with it. Yeah. AUDIENCE: If you had this magical computer, it can guess whether it's yes or no, why doesn't it just answer the question? ERIK DEMAINE: Right. So what if we-- so a nice check is, does this make all problems trivial, all decision problems? Maybe I should say, well, I don't know whether the answer to the problem is yes or no, so I'll just guess yes or no. This is problematic because-- so I might say, it will guess A or B, and if I choose the A option, I will output yes, and if I choose the B option, I will output no. In this model, that algorithm will always output yes. Because what it's saying is, if there's any way to get to a yes answer, I will do that way. And so such an algorithm that tries to cheat and just guess the whole answer to the problem will actually end up always saying yes, which means it doesn't solve a very interesting problem. It only solves the problem, which is represented by the bit vector 1111111, where all the answers are yes. But good check. Yeah. AUDIENCE: Does there have to be a bound of a number of things it has to choose between when it [AUDIO OUT] ERIK DEMAINE: Yes. AUDIENCE: Does it have an exponential number of them? ERIK DEMAINE: Exponential number of choices is OK. I usually like to think of it, as you can only guess one bit at a time. But we're allowed polynomial time, so you're actually allowed to guess polynomial number of bits. At that point, you can guess over an exponential size space, but not more than exponential. So it's-- yeah, polynomial time let's say in the one-bit guessing model. What did I say? Makes guesses-- let's add binary here. Otherwise we get some other class, which I don't want. OK, let's do an example, a real example of such an algorithm","71.80970764160156","10","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_6_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"161","What is the distinction between a set interface and a set data structure?","Now, this description here-- notice that I've labeled this as a set interface. This is not a set data structure. And the way to remember that is that I haven't told you how I've actually implemented this. I haven't told you that I'm going to behind the scenes have an array of information, and look inside of it, and that's how I'm going to implement find min or find max with a for loop or whatever. All I'm telling you is that a set is a thing that implements these operations. And behind the scenes, my computer does what it does. Now, it might sound abstract. But it's more or less what you guys do when you write code in Python. I think in Python what we're calling a set is maybe a dictionary. I'm a Matlab Coder. I'm sorry. I'm a numerical analysis kind of guy. But essentially, one of the beautiful things about coding in these high level programming languages is that they take care of these ugly details. And what you're left with is just the high level interfacing with this object","76.49005889892578","1","DPRSearchEngine","oS9aPzUNG-s.en-j3PyPqV-e1s_6_mp4","oS9aPzUNG-s.en-j3PyPqV-e1s","6.006","3"
"161","What is the distinction between a set interface and a set data structure?","It's basically-- it's a set type thing, where I can make a set of just a single element, I can take two sets, merge them together, make them their union, and then given an object, I say, which set am I part of, essentially by electing a leader within a set and saying, return me a pointer to that one. And so this can be useful in dynamically maintaining, say, the connected components in a dynamically changing graph supporting the query of, am I in the same component as this other guy? That could be a very useful thing to know about a graph as it's changing. So that's an application of this problem. And they get near-constant performance for a lot of these queries. It's not quite, but pretty close. OK, on the graph side, they solve","73.77323913574219","2","DPRSearchEngine","2NMtS1ecb3o.en-j3PyPqV-e1s_6_mp4","2NMtS1ecb3o.en-j3PyPqV-e1s","6.006","20"
"161","What is the distinction between a set interface and a set data structure?","Fairly simple data structures today. This is the beginning of several data structures we'll be talking about in the next few lectures. But before we actually start with one, let me tell you/remind remind you of the difference between an interface-- which you might call an API if you're a programmer, or an ADT if you're an ancient algorithms person like me-- versus a data structure. These are useful distinctions. The idea is that an interface says what you want to do. A data structure says how you do it. So you might call this a specification. And in the context of data structures, we're trying to store some data. So the interface will specify what data you can store, whereas the data structure will give you an actual representation and tell you how to store it. This is pretty boring. Just storing data is really easy. You just throw it in a file or something. What makes it interesting is having operations on that data. In the interface, you specify what the operations do, what operations are supported, and in some sense, what they mean. And the data structure actually gives you algorithms-- this is where the algorithms come in-- for how to support those operations. All right. In this class, we're going to focus on two main interfaces and various special of them. The idea is to separate what you want to do versus how to do it. Because-- you can think of this as the problem statement. Yesterday-- or, last class, Jason talked about problems and defined what a problem was versus algorithmic solutions to the problem. And this is the analogous notion for data structures, where we want to maintain some data according to various operations. The same problem can be solved by many different data structures. And we're going to see that. And different data structures are going to have different advantages. They might support some operations faster than others. And depending on what you actually use those data structures for, you choose the right data structure. But you can maintain the same interface. We're going to think about two data structures. One is called a set and one is called a sequence. These are highly loaded terms. Set means something to a mathematician. It means something else to a Python programmer. Sequence, similarly. I guess there's not a Python sequence data type built in. The idea is, we want to store n things. The things will be fairly arbitrary. Think of them as integers or strings. And on the one hand, we care about their values. And maybe we want to maintain them in sorted order and be able to search for a given value, which we'll call a key. And on the other hand, we care about representing a particular sequence that we care about. Maybe we want to represent the numbers 5, 2, 9, 7 in that order and store that. In Python, you could store that in a list, for example. And it will keep track of that order. And this is the first item, the second item, the last item. Today, we're going to be focusing on this sequence data structure, although at the end, I'll mention the interface for sets. But we're going to be actually solving sequences today. And in the next several lectures, we'll be bouncing back and forth between these. They're closely related. Pretty abstract at the moment. On the other hand, we're going to have two main-- let's call them data structure tools or approaches. One is arrays and the other is pointers-- pointer-based or linked data structures. You may have seen these. They're used a lot in programming, of course. But we're going to see both of these today. I'll come back to this sort of highlight in a moment. Let's jump into the sequence interface, which I conveniently have part of here. There's a few different levels of sequences that we might care about. I'm going to start with the static sequence interface. This is where the number of items doesn't change, though the actual items might. Here, we have n items. I'm going to label them x 0 to x n minus 1, as in Python. So the number of items is n. And the operations I want to support are build, length, iteration, get, and set. So what do these do? Build is how you get started. To build a data structure in this interface, you call build of x. Exactly how you specify x isn't too important, but the idea is, I give you some items in some order. In Python, this would be an iterable. I'm going to want to also know its length. And I want to make a new data structure of size and a new static sequence of size n that has those items in that order. So that's how you build one of these. Because somehow, we have to specify n to this data structure, because n is not going to be allowed to change. I'm going to give you a length method. Methods are the object-oriented way of thinking of operations that your interface supports. Length will just return this fixed value n. Iter sequence. This is the sense in which we want to maintain the order. I want to be able to output x 0 through x n minus 1 in the sequence order, in that specified order that they were built in or that it was changed to. This is going to iterate through all of the items. So it's going to take at least linear time to output that. But more interesting is, we can dynamically access anywhere in the middle of the sequence. We can get the ith item, x i, given the value i, and we can change x i to a given new item. OK. So that's called get_at and set_at. Pretty straightforward. This should remind you very closely of something-- a data structure. So this is an interface. This is something I might want to solve. But what is the obvious data structure that solves this problem? Yeah? AUDIENCE: A list. ERIK DEMAINE: A list. In Python, it's called a list. I prefer to call it an array, but to each their own. We're going to use ""list.""","72.84746551513672","3","DPRSearchEngine","CHhwJjR0mZA.en-j3PyPqV-e1s_2_mp4","CHhwJjR0mZA.en-j3PyPqV-e1s","6.006","2"
"161","What is the distinction between a set interface and a set data structure?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 2: Data Structures 
Lecture 2: Data Structures 
Data Structure Interfaces 
• A data structure is a way to store data, with algorithms that support operations on the data 
• Collection of supported operations is called an interface (also API or ADT) 
• Interface is a speciﬁcation: what operations are supported (the problem!) 
• Data structure is a representation: how operations are supported (the solution!) 
• In this class, two main interfaces: Sequence and Set 
Sequence Interface (L02, L07) 
• Maintain a sequence of items (order is extrinsic) 
• Ex: (x0, x1, x2, . . . , xn−1) (zero indexing) 
• (use n to denote the number of items stored in the data structure) 
• Supports sequence operations: 
Container 
build(X) 
len() 
given an iterable X, build sequence from items in X 
return the number of stored items 
Static 
iter seq() 
get at(i) 
set at(i, x) 
return the stored items one-by-one in sequence order 
return the ith item 
replace the ith item with x 
Dynamic 
insert at(i, x) 
delete at(i) 
insert first(x) 
delete first() 
insert last(x) 
delete last() 
add x as the ith item 
remove and return the ith item 
add x as the ﬁrst item 
remove and return the ﬁrst item 
add x as the last item 
remove and return the last item 
• Special case interfaces: 
stack 
insert last(x) and delete last() 
queue 
insert last(x) and delete first() 
","72.17085266113281","4","DPRSearchEngine","79a07dc1cb47d76dae2ffedc701e3d2b_MIT6_006S20_lec2_1_pdf","79a07dc1cb47d76dae2ffedc701e3d2b_MIT6_006S20_lec2","6.006","2"
"161","What is the distinction between a set interface and a set data structure?"," &&
class Edge(object): 
    def __init__(self, src, dest): 
        """"""Assumes src and dest are nodes"""""" 
        self.src = src 
        self.dest = dest 
    def getSource(self): 
        return self.src 
    def getDestination(self): 
        return self.dest 
    def __str__(self): 
        return self.src.getName() + '->’\\ 
               + self.dest.getName() 
Q>KKKMN
LQ
","71.98904418945312","5","DPRSearchEngine","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_16_pdf","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3","6.0002","3"
"161","What is the distinction between a set interface and a set data structure?","In any event, today, in our lecture, we're concerned with one particular interface, which is called a set. A set is exactly what it sounds like. It's a big pile of things. And so a set interface is like an object that just you can keep adding things to it. And then querying inside of my set, is this object here? Can I find it? And then maybe I associate with my objects in my set different information. So for example, maybe I have a set which represents all the students in our classroom today. Yeah, and all of you guys are associated with your student ID, which I believe at MIT is a number, which has less than sign, which is convenient. So we can sort all of you guys. And that might be the key that's associated to every object in the room. And so when I'm searching for students, maybe I enter in the student number. And then I want to ask my set, does this number exist in the set of students that are in 6.006? And if it does, then I can pull that student back. And then associated with that object is a bunch of other information that I'm not using to search-- so for instance, your name, your-- I don't know-- your social security number, your credit card number, all the other stuff that I need to have a more interesting profession.","71.40780639648438","6","DPRSearchEngine","oS9aPzUNG-s.en-j3PyPqV-e1s_4_mp4","oS9aPzUNG-s.en-j3PyPqV-e1s","6.006","3"
"161","What is the distinction between a set interface and a set data structure?","Notation for encodings and TMs
Notation for encoding objects into strings
- If ! is some object (e.g., polynomial, automaton, graph, etc.), 
we write 〈!〉to be an encoding of that object into a string.  
- If !$, !&, … , !( is a list of objects then we write 〈!$, !&, … , !(〉
to be an encoding of them together into a single string. 
Notation for writing Turing machines
We will use high-level English descriptions of algorithms when we describe TMs, 
knowing that we could (in principle) convert those descriptions into states, 
transition function, etc.  Our notation for writing a TM ) is
) = “On input +
[English description of the algorithm]”
Check-in 6.3
If , and - are strings, would ,- be a good choice 
for their encoding 〈,, -〉into a single string?
a)
Yes.
b)
No. 
Check-in 6.3
8
","70.52680969238281","7","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_8_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"161","What is the distinction between a set interface and a set data structure?","That was a brief tour of computational geometry. I work mostly in four different areas of algorithms-- geometry, data structures, graph algorithms, and what I call recreational algorithms. I think I made up that term. And let's go into data structures, which is represented by this class, 6.851. All of the classes I mentioned have online video lectures, especially for those watching at home on OpenCourseWare. Most of these classes are on OpenCourseWare, and if not, they're on my webpage. 6.851, Advanced Data Structures, is an extension of the sorts of data structures you've seen here, in 006 and the ones you will see in 6.046. I thought I would give you a flavor of one such result, which is a problem we've seen in this class done better. Suppose you want to store a dynamic ordered set. This is the set interface. Dynamic in the sense that I have insert and delete, and ordered in the sense that I want to support find-next and find-previous. Exactly which subset of the set interface you choose influences what data structure you've seen. We've seen, for dynamic sets, you want to use hashing. If you don't care about find-next, if you just care about find, then hashing is great-- constant expected. You can prove stronger things about hashing. And we do in that class. But if you want dynamic and ordered, you cannot do constant time per operation. You can prove that, which is cool. What data structure have we seen that solves this problem pretty well? Set AVL trees, which solve everything in log n. So log n is one competitor. Yeah. I'm interested in the word RAM model, which is the only model we've seen in this class. This happens to work in a stronger model. And we can do better than log n in the following-- it will take me a while before I get better, but here's, at least, a different bound we can get-- log w. This is via a structure called van Emde Boas, who is a person. AVL is two people. van Emde Boas, I've actually met. Log w-- remember, w is our word size. So this is a bit of a weird running time. It's great if w is log n, then this is log log n. And we know w is at least log n, but it could be bigger. We don't really have a sense of how big w could get. Maybe it's even n. Maybe it's big-- and then these are the same. Maybe it's bigger than n, and then this is maybe worse. But for most ws, this is actually pretty good-- and indeed, optimal. But it's not strictly better, in any sense, yet. On the other hand, there's another data structure which runs in log n divided by log w. This is called fusion trees. This was invented around the time that cold fusion was in the news, and so they wanted data structures to represent. We can achieve this bound or we can achieve this bound. And this bound is good is if w is large. This band as good if w is small. You can always take the min of the two, whatever is better. And in particular, the min of those two things is at most-- I think it's square root log n over log log n. If you want to bound just in terms of n, then the crossover point between these two is this place. And so you're always, at most, this, which is quite a bit better than the log n of AVL. We've got a square root and we've got a slight thing in the denominator. Pretty tiny. But the big thing is the square root. And that's kind of cool. And it turns out, that's pretty much optimal. In terms of an n bound, this is optimal. The min of these two, in general, is roughly optimal up to log log terms. For fun, I threw up the actual formula for the right-bound, which is tight up to constant factors of matching upper and lower bounds, which we talk about. It's min of three things-- four things, including log of w over a divided by log of log w over a log of log n over a. That's the last term that I just read. This was messy. Surprisingly, that is the right answer for this very particular problem-- a very natural problem. AUDIENCE: What is a? ERIK DEMAINE: A is the log of the space you're using. So it's the address size. Good question. If you throw it-- so it depends. If you have a polynomial space data structure, then basically, these are optimal. And this is generalizing to beyond that. Maybe you have a little bit more than polynomial space. Cool. So that's data structures. I'm going to jump ahead to graph algorithms, which, if you want to take this class, I recommend a time travel device.","70.18707275390625","8","DPRSearchEngine","4nXw-f6NJ9s.en-j3PyPqV-e1s_4_mp4","4nXw-f6NJ9s.en-j3PyPqV-e1s","6.006","21"
"161","What is the distinction between a set interface and a set data structure?","interface a little bit more. So our set is a container. It contains all of the students in this classroom, in some virtual sense at least. And so to build up our set, of course, we need an operation that takes some iterable object A and builds a set out of it. So in other words, I have all the students in this classroom represented maybe in some other fashion. And I have to insert them all into my set. I can also ask my set for how much stuff is in it. Personally, I would call that size. But length is cool, too. And then of course, there are a lot of different ways that we can interact with our set. So for instance, we could say, is this student taking 6.006? So in set language, one way to understand that is to say that the key-- each person in this classroom is associated with a key. Does that key k exist in my set? In which case, I'll call this find function, which will give me back the item with key k or maybe null or something if it doesn't exist. Maybe I can delete an object from my set or insert it. Notice that these are dynamic operations, meaning that they actually edit what's inside of my set. And then finally, there are all kinds of different operations that I might want to do to interact with my set beyond is this thing inside of it. So for instance, so for the student ID example, probably finding the minimum ID number in a class isn't a terribly exciting exercise. But maybe I'm trying to find the student who's been at MIT the longest. And so that would be a reasonable heuristic. I actually have no idea whether MIT student IDs are assigned linearly or not. But in any event, I could find the smallest key, the largest key, and so on in my set. And these are all reasonable operations to query, where my object is just","70.16584777832031","9","DPRSearchEngine","oS9aPzUNG-s.en-j3PyPqV-e1s_5_mp4","oS9aPzUNG-s.en-j3PyPqV-e1s","6.006","3"
"161","What is the distinction between a set interface and a set data structure?","data, and I just said whether we're going to print something. You'll notice from this slide I've elighted the printed stuff. We'll come back in a later slide and look at what's in there. But for now I want to focus on actually building the model. I need to create two vectors, two lists in this case, the feature vectors and the labels. For e in examples, featurevectors.a ppend(e.getfeatures e.getfeatures e.getlabel. Couldn't be much simpler than that. Then, just because it wouldn't fit on a line on my slide, I've created this identifier called logistic regression, which is sklearn.linearmo del.logisticregression. So this is the thing I imported, and this is a class, and now I'll get a model by first creating an instance of the class, logistic regression. Here I'm getting an instance, and then I'll call dot fit with that instance, passing it feature vecs and labels. I now have built a logistic regression model, which is simply a set of weights for each of the variables. This makes sense? Now we're going to apply the model, and I think this is the last piece of Python I'm going to introduce this semester, in case you're tired of learning about Python. And this is at least list comprehension. This is how I'm going to build my set of test feature vectors.","69.96408081054688","10","DPRSearchEngine","eg8DJYwdMyg.en-qlPKC2UN_YU_7_mp4","eg8DJYwdMyg.en-qlPKC2UN_YU","6.0002","13"
"162","What is a strategy to handle new types of subproblems when solving dynamic programming problems?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","77.18830871582031","1","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"162","What is a strategy to handle new types of subproblems when solving dynamic programming problems?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 16: Dyn. Prog. Subproblems 
Lecture 16: Dyn. Prog. Subproblems 
Dynamic Programming Review 
• Recursion where subproblem dependencies overlap, forming DAG 
• “Recurse but re-use” (Top down: record and lookup subproblem solutions) 
• “Careful brute force” (Bottom up: do each subproblem in order) 
Dynamic Programming Steps (SRT BOT) 
1. Subproblem deﬁnition 
subproblem x 2 X 
• Describe the meaning of a subproblem in words, in terms of parameters 
• Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence 
• Often multiply possible subsets across multiple inputs 
• Often record partial state: add subproblems by incrementing some auxiliary variables 
2. Relate subproblem solutions recursively 
x(i) =  f(x(j), . . .) for one or more j < i  
• Identify a question about a subproblem solution that, if you knew the answer to, reduces 
the subproblem to smaller subproblem(s) 
• Locally brute-force all possible answers to the question 
3. Topological order to argue relation is acyclic and subproblems form a DAG 
4. Base cases 
• State solutions for all (reachable) independent subproblems where relation breaks down 
5. Original problem 
• Show how to compute solution to original problem from solutions to subproblem(s) 
• Possibly use parent pointers to recover actual solution, not just objective function 
6. Time analysis 
P 
• 
x2X work(x), or if work(x) =  O(W) for all x 2 X, then |X| · O(W) 
• work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time 
","76.9738998413086","2","DPRSearchEngine","28461a74f81101874a13d9679a40584d_MIT6_006S20_lec16_1_pdf","28461a74f81101874a13d9679a40584d_MIT6_006S20_lec16","6.006","16"
"162","What is a strategy to handle new types of subproblems when solving dynamic programming problems?"," 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 18: Pseudopolynomial 
Lecture 18: Pseudopolynomial 
Dynamic Programming Steps (SRT BOT) 
1. Subproblem deﬁnition 
subproblem x ∈ X 
• Describe the meaning of a subproblem in words, in terms of parameters 
• Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence 
• Often multiply possible subsets across multiple inputs 
• Often record partial state: add subproblems by incrementing some auxiliary variables 
• Often smaller integers than a given integer (today’s focus) 
2. Relate subproblem solutions recursively 
x(i) = f(x(j), . . .) for one or more j < i 
• Identify a question about a subproblem solution that, if you knew the answer to, reduces 
the subproblem to smaller subproblem(s) 
• Locally brute-force all possible answers to the question 
3. Topological order to argue relation is acyclic and subproblems form a DAG 
4. Base cases 
• State solutions for all (reachable) independent subproblems where relation breaks down 
5. Original problem 
• Show how to compute solution to original problem from solutions to subproblem(s) 
• Possibly use parent pointers to recover actual solution, not just objective function 
6. Time analysis 
P 
• 
work(x), or if work(x) = O(W ) for all x ∈ X, then |X| · O(W )
x∈X 
• work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time 
","76.36937713623047","3","DPRSearchEngine","mit6_006s20_lec18_1_pdf","mit6_006s20_lec18","6.006","18"
"162","What is a strategy to handle new types of subproblems when solving dynamic programming problems?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","75.58806610107422","4","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"162","What is a strategy to handle new types of subproblems when solving dynamic programming problems?","4 
Lecture 15: Recursive Algorithms 
Dynamic Programming 
• Weird name coined by Richard Bellman 
– Wanted government funding, needed cool name to disguise doing mathematics! 
– Updating (dynamic) a plan or schedule (program) 
• Existence of recursive solution implies decomposable subproblems1 
• Recursive algorithm implies a graph of computation 
• Dynamic programming if subproblem dependencies overlap (DAG, in-degree > 1) 
• “Recurse but re-use” (Top down: record and lookup subproblem solutions) 
• “Careful brute force” (Bottom up: do each subproblem in order) 
• Often useful for counting/optimization problems: almost trivially correct recurrences 
How to Solve a Problem Recursively (SRT BOT) 
1. Subproblem deﬁnition 
subproblem x ∈ X 
• Describe the meaning of a subproblem in words, in terms of parameters 
• Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence 
• Often record partial state: add subproblems by incrementing some auxiliary variables 
2. Relate subproblem solutions recursively 
x(i) = f(x(j), . . .) for one or more j < i 
3. Topological order to argue relation is acyclic and subproblems form a DAG 
4. Base cases 
• State solutions for all (reachable) independent subproblems where relation breaks down 
5. Original problem 
• Show how to compute solution to original problem from solutions to subproblem(s) 
• Possibly use parent pointers to recover actual solution, not just objective function 
6. Time analysis 
P 
• 
work(x), or if work(x) = O(W ) for all x ∈ X, then |X| · O(W )
x∈X 
• work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time 
1This property often called optimal substructure. It is a property of recursion, not just dynamic programming 
","75.58279418945312","5","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_4_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"162","What is a strategy to handle new types of subproblems when solving dynamic programming problems?","And this is a subset of the set interface. And subsets are interesting because, potentially, we can solve them better, faster, simpler, something. And so you'll recognize-- you should recognize all of these operations, except we didn't normally highlight the max operation. So here, we're interested in storing a bunch of items. They have keys which we think of as priorities. And we want to be able to identify the maximum priority item in our set and remove it. And so there's lots of motivations for this. Maybe you have a router, packets going into the router. They have different priorities assigned to them. You want to route the highest priority first. Or you have processes on your computer trying to run on your single threaded-- single core, and you've got to choose which one to run next. And you usually run higher priority processes first. Or you're trying to simulate a system where events happen at different times, and you want to process the next event ordered by time. All of these are examples of the priority queue interface. We'll even see applications within this class when we get to graph algorithms. But the main two things we want to be able to support are inserting an item, which includes a key, and leading the maximum item, and also returning it at the same time. We'll also talk some about being able to build the structure faster than just inserting it. But of course, we could implement build by starting empty and repeatedly inserting. And also the complexity of just finding the max without deleting it, this you could simulate with these two operations by deleting the max and then reinserting it, which works. But often, we can do faster. But the two key, main operations are insert and delete max. And we're going to see a few data structures to do this. Any suggestions among the data structures we've seen in this class? What should we use to solve priority queue interface? Many possible answers.","75.097900390625","6","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_2_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"162","What is a strategy to handle new types of subproblems when solving dynamic programming problems?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","74.8624267578125","7","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"162","What is a strategy to handle new types of subproblems when solving dynamic programming problems?"," 
 
 
Class LogisticRegression  
fit(sequence of feature vectors, sequence of labels) 
Returns object of type LogisticRegression 
coef_ 
Returns weights of features 
predict_proba(feature vector) 
Returns probabilities of labels 
6.0002 LECTURE 13 
22 
","74.66148376464844","8","DPRSearchEngine","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13_22_pdf","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13","6.0002","13"
"162","What is a strategy to handle new types of subproblems when solving dynamic programming problems?","What's the worst case performance of a hash table? If I have to look up something in a hash table, and I happen to choose a bad hash table-- hash function, what's the worst case here? What? n, right? It's worse than a sorted array, because potentially, I hashed everything that I was storing to the same index in my hash table, and to be able to distinguish between them, I can't do anything more than a linear search. I could store another set's data structure as my chain and do better that way. That's actually how Java does it. They store a data structure we're going to be talking about next week as the chains so that they can get, worst case, log n. But in general, that hash table is only good if we're allowing-- OK, I want this to be expected good, but in the worst case, if I really need that operation to be worst case-- I really can't afford linear time ever for an operation of that kind-- then I don't want to use a hash table. And so on your p set 2, everything we ask you for is worst case, so probably, you don't want to be using hash tables. OK? Yes? AUDIENCE: What does the subscript e mean? JASON KU: What does the subscript e mean? That's great. In this chart, I put a subscript on this is an expected runtime, or an A meaning this is an amortized runtime. At the end, we talked about how, if we had too many things in our hash table, then, as long as we didn't do it too often-- this is a little hand wavey argument, but the same kinds of ideas as the dynamic array-- if, whenever we got a linear-- we are more than a linear factor away from where we are trying-- basically, the fill factor we were trying to be, then we could just completely rebuild the hash table with the new hash function randomly chosen from our hash table with a new size, and we could get amortized bounds. And so that's what Python-- how Python implements dictionaries, or sets, or even objects when it's trying to map keys to different things. So that's hash tables. That's great. The key thing here is, well, actually, if your range of keys is small, or if you as a programmer have the ability to choose the keys that you identify your objects with, you can actually choose that range to be small, to be linear, to be small with respect to your items. And you don't need a hash table. You can just use a direct access array, because if you know your key space is small, that's great. So a lot of C programmers probably would like to do something like that, because they don't have access to-- maybe C++ programmers would have access to their hash table. Any questions on this stuff before we move on? Yeah? AUDIENCE: So why is [INAUDIBLE]? JASON KU: Why is it expected? When I'm building, I could insert-- I'm inserting these things from x 1 by 1 into my hash table. Each of those insert operations-- I'm looking up to see whether that-- an item with that key already exists in my hash table. And so I have to look down the chain to see where it is. However, if I happen to know that all of my keys are unique in my input, all the items I'm trying to store are unique, then I don't have to do that check and I can get worst case linear time. Does that make sense? All right. It's a subtlety, but that's a great question. OK, so today, instead of talking about searching, we're talking about sorting. Last week, we saw a few ways to do sort. Some of them were quadratic-- insertion sort and selection sort-- and then we had one that was n log n. And this thing, n log n, seemed pretty good, but can I do better? Can I do better? Well, what we're going to show at the beginning of this class is, in this comparison model, no. n log n is optimal. And we're going to go through the exact same line of reasoning that we had last week. So in the comparison model, what did we use when we were trying to make this argument that any comparison model algorithm was going to take at least log n time? What we did was we said, OK, I can think of any model in the comparison model-- any algorithm in the comparison model as kind of this-- some comparisons happen. They branch in a binary sense, but you could have it generalized to any constant branching factor. But for our purposes, binary's fine. And what we said was that there were at least n outputs-- really n plus 1, but-- at least order n outputs. And we showed that-- or we argued to you that the height of this tree had to be at least log n-- log the number of leaves. It had to be at least log the number of leaves. That was the height of the decision tree. And if this decision tree represented a search algorithm, I had to walk down and perform these comparisons in order, reach a leaf where I would output something. If the minimum height of any binary tree on a linear number of leaves is log n, then any algorithm in the comparison model also has to take log n time, because it has to do that many comparisons to differentiate between all possible outputs. Does that make sense? All right. So in the sort problem, how many possible outputs are there?","74.63202667236328","9","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_4_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"162","What is a strategy to handle new types of subproblems when solving dynamic programming problems?","Dynamic programming, while it was, in some sense, related to this graph material-- I'm constructing a graph-- I have to construct that graph. There's a creative process in trying to construct that graph. I don't give you a set of vertices. Usually what I give you are a set of-- a sequence or something like that. And you have to construct vertices, subproblems, that will be able to be related in a recursive way so you can solve the problem. This is a very much more difficult thing than these other things, I think, because there's a lot more creativity in this. In the same way that just applying-- reducing to the graph algorithms we have is fairly easy. But actually doing some graph transformations to change the shape of the graph so that you can apply these algorithms, that's a harder thing to do. The difficulty with these two sets of materials is very similar. Figuring out what the graph should be, figuring out what the subproblems should be and how they relate, is really the entire part of the-- the entire difficulty with solving problems recursively. And we've only given you a taste of solving problems recursively. In future classes, like 6.046, which is the follow-on to this one in the undergraduate curriculum, this is all about introduction to algorithms. The next one's about design and analysis of algorithms. It's quite a bit more difficult, because we've mostly left it to you to use the things that we gave you or make your own algorithms based on this very nice cookbook-like framework that you can plug in a recursive algorithm to. Now actually, that cookbook is super nice for any way of looking at a problem recursively, but while in dynamic programming, the inductive hypothesis of combining your subproblems is almost trivial, in other types of recursive algorithms, that's not necessarily the case. Especially when instead of looking at all possible choices, for example, in a greedy algorithm where you're just looking at one of the choices, the locally best thing, and recursing forward, you're not doing all the work. You're not locally brute-forcing. Your locally picking an optimal thing locally and hoping that will lead you to good thing. That's a much harder algorithmic paradigm to operate under. And so that's more like the material that you'll be talking about in 6.046. So that's 006, a very quick overview of the content of this class. And we really like the structure of how this class is laid out, because it gives you a fundamental idea of the things people use to store information on a computer and a sense of how you solve problems computationally and how to argue that they're correct and efficient. That's really what this problem-- this course is about. And if you feel like you enjoy this kind of stuff, that's where you go to take 6.046. And 6.046 was actually the first algorithms class I ever took here at MIT, as a grad student actually. This was hard for me. It's actually hard to look at these problems, these types, and think in a computational way, especially having not taken this class, 6.006. So hopefully you guys are all in a better position than I was when I took it. There's two ways I like to think of the content in 6.046. One is kind of just as an extension of 006. It's the natural follow-on to the things that we do in this class. They still talk about data structures. This isn't the core part of 046, but they do touch on data structures for more complicated-- that have more complicated analyses involved in them. It's really about-- usually in 046, stating what the algorithm is doing is not so hard. Basically, giving you the algorithm, number one here, is not so difficult, to state what's happening in the algorithm. But the number two and number three here, arguing that that thing is correct and arguing that thing is efficient, that's where the complexity comes in in 046. The analysis part is quite a bit more complicated in 046 than in 006. So they solve a problem called union-find and give a much-- we talked a little bit about amortization. This goes into a much better-- a much more formal way of proving things run in amortized time. So this is basically amortization via what we call a potential analysis. It's basically making that notion that we talked about when we were talking about dynamic arrays of, we're not doing this expensive thing too often. Basically what we do is we keep track of the cost of all sequence of operations and prove that the average cost is small. That's kind of what this potential analysis is doing. It's a little bit more formal process for making that argument a little more formal. Right. OK. So then on the graph side, this is kind of an extension of quiz 1-type material.","74.3896255493164","10","DPRSearchEngine","2NMtS1ecb3o.en-j3PyPqV-e1s_5_mp4","2NMtS1ecb3o.en-j3PyPqV-e1s","6.006","20"
"163","What are the main steps involved in the selection sort algorithm?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","70.17286682128906","1","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"163","What are the main steps involved in the selection sort algorithm?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","69.48973083496094","2","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"163","What are the main steps involved in the selection sort algorithm?","They take linear time for some of the operations. So the sorting algorithms are not efficient. But they're ones we've seen before, so it's neat to see how they fit in here. They had the-- selection sort and insertion sort had the advantage that they were in place. You just needed a constant number of pointers or indices beyond the array itself. So they're very space efficient. So that was a plus for them. But they take n squared time, so you should never use them, except for n, at most, 100 or something. AVL tree sort is great and then it gets n log n time, probably more complicated than merge sort and you could stick to merge sort. But neither merge sort nor set AVL tree sort are in place. And so the goal of today is to get the best of all those worlds in sorting to get n log n comparisons, which is optimal in the comparison model, but get it to be in place. And that's what we're going to get with binary heaps. We're going to design a data structure that happens to build a little bit faster-- as I mentioned, linear time building. So it's not representing a sorted order in the same way that AVL trees are. But it will be kind of tree-based. It will also be array-based. We're going to get logarithmic time for insert and delete_max. It happens to be amortized, because we use arrays. But the key thing is that it's an in-place data structure. It only consists of an array of the items. And so, when we plug it into our sorting algorithm-- priority queue sort or generic sorting algorithm-- not only do we get n log n performance, but we also get an in-place sorting algorithm. This will be our first and only-- to this class-- n log n in-place sorting algorithm. Cool. That's the goal.","68.98899841308594","3","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_5_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"163","What are the main steps involved in the selection sort algorithm?","4 
Lecture 1: Introduction 
1 
def birthday_match(students): 
2 
’’’ 
3 
Find a pair of students with the same birthday 
4 
Input: 
tuple of student (name, bday) tuples 
5 
Output: tuple of student names or None 
6 
’’’ 
7 
n = len(students) 
# O(1) 
8 
record = StaticArray(n) 
# O(n) 
9 
for k in range(n): 
# n 
10 
(name1, bday1) = students[k] 
# O(1) 
11 
# Return pair if bday1 in record 
12 
for i in range(k): 
# k 
13 
(name2, bday2) = record.get_at(i) 
# O(1) 
14 
if bday1 == bday2: 
# O(1) 
15 
return (name1, name2) 
# O(1) 
16 
record.set_at(k, (name1, bday1)) 
# O(1) 
17 
return None 
# O(1) 
Example: Running Time Analysis 
• Two loops: outer k ∈{0, . . . , n − 1}, inner is i ∈{0, . . . , k}
P n−1
• Running time is O(n) + 
k=0 (O(1) + k · O(1)) = O(n2) 
• Quadratic in n is polynomial. Efﬁcient? Use different data structure for record! 
How to Solve an Algorithms Problem 
1. Reduce to a problem you already know (use data structure or algorithm) 
Search Problem (Data Structures) 
Sort Algorithms 
Static Array (L01) 
Insertion Sort (L03) 
Linked List (L02) 
Selection Sort (L03) 
Dynamic Array (L02) 
Merge Sort (L03) 
Sorted Array (L03) 
Counting Sort (L05) 
Direct-Access Array (L04) 
Radix Sort (L05) 
Hash Table (L04) 
AVL Sort (L07) 
Balanced Binary Tree (L06-L07) 
Heap Sort (L08) 
Binary Heap (L08) 
2. Design your own (recursive) algorithm 
• Brute Force 
• Decrease and Conquer 
• Divide and Conquer 
• Dynamic Programming (L15-L19) 
• Greedy / Incremental 
Shortest Path Algorithms 
Breadth First Search (L09) 
DAG Relaxation (L11) 
Depth First Search (L10) 
Topological Sort (L10) 
Bellman-Ford (L12) 
Dijkstra (L13) 
Johnson (L14) 
Floyd-Warshall (L18) 
","68.91232299804688","4","DPRSearchEngine","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_4_pdf","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1","6.006","1"
"163","What are the main steps involved in the selection sort algorithm?","3 
Lecture 3: Sorting 
Selection Sort 
• Find a largest number in preﬁx A[:i + 1] and swap it to A[i] 
• Recursively sort preﬁx A[:i] 
• Example: [8, 2, 4, 9, 3], [8, 2, 4, 3, 9], [3, 2, 4, 8, 9], [3, 2, 4, 8, 9], [2, 3, 4, 8, 9] 
1 
def selection_sort(A, i = None): 
# T(i) 
2 
’’’Sort A[:i + 1]’’’ 
3 
if i is None: i = len(A) - 1 
# O(1) 
4 
if i > 0: 
# O(1) 
5 
j = prefix_max(A, i) 
# S(i) 
6 
A[i], A[j] = A[j], A[i] 
# O(1) 
7 
selection_sort(A, i - 1) 
# T(i - 1) 
8 
9 
def prefix_max(A, i): 
# S(i) 
10 
’’’Return index of maximum in A[:i + 1]’’’ 
11 
if i > 0: 
# O(1) 
12 
j = prefix_max(A, i - 1) 
# S(i - 1) 
13 
if A[i] < A[j]: 
# O(1) 
14 
return j 
# O(1) 
15 
return i 
# O(1) 
• prefix max analysis: 
– Base case: for i = 0, array has one element, so index of max is i 
– Induction: assume correct for i, maximum is either the maximum of A[:i] or A[i], 
returns correct index in either case. 
– S(1) = Θ(1), S(n) = S(n − 1) + Θ(1) 
∗ Substitution: S(n) = Θ(n), 
cn = Θ(1) + c(n − 1) =⇒ 1 = Θ(1)
P n−1
∗ Recurrence tree: chain of n nodes with Θ(1) work per node, 
i=0 1 = Θ(n) 
• selection sort analysis: 
– Base case: for i = 0, array has one element so is sorted 
– Induction: assume correct for i, last number of a sorted output is a largest number of 
the array, and the algorithm puts one there; then A[:i] is sorted by induction 
– T (1) = Θ(1), T (n) = T (n − 1) + Θ(n) 
∗ Substitution: T (n) = Θ(n2), 
cn2 = Θ(n) + c(n − 1)2 =⇒ c(2n − 1) = Θ(n)
P n−1
∗ Recurrence tree: chain of n nodes with Θ(i) work per node, 
i=0 i = Θ(n2) 
","68.3723373413086","5","DPRSearchEngine","6d1ae5278d02bbecb5c4428928b24194_MIT6_006S20_lec3_3_pdf","6d1ae5278d02bbecb5c4428928b24194_MIT6_006S20_lec3","6.006","3"
"163","What are the main steps involved in the selection sort algorithm?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Clustering Algorithms  
§Hierarchical  clustering  
◦ Can select number  of clusters using dendogram 
◦ Deterministic 
◦ Flexible with respect to linkage criteria 
◦ Slow 
◦ Naïve algorithm n3 
◦ n2 algorithms exist for some linkage criteria 
§K-means a much faster greedy algorithm 
◦ Most useful when you know how many clusters  you want  
6.0002  LECTURE 12 
9 
","67.91668701171875","6","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_9_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"163","What are the main steps involved in the selection sort algorithm?","And a comparison model means-- is that the items, the objects I'm storing-- I can kind of think of them as black boxes. I don't get to touch these things, except the only way that I can distinguish between them is to say, given a key and an item, or two items, I can do a comparison on those keys. Are these keys the same? Is this key bigger than this one? Is it smaller than this one? Those are the only operations I get to do with them. Say, if the keys are numbers, I don't get to look at what number that is. I just get to take two keys and compare them. And actually, all of the search algorithms that we saw on Tuesday we're comparison sort algorithms. What you did was stepped through the program. At some point, you came to a branch and you looked at two keys, and you branched based on whether one key was bigger than another. That was a comparison. And then you move some stuff around, but that was the general paradigm. Those three sorting operations lived in this comparison model.","67.36385345458984","7","DPRSearchEngine","Nu8YGneFCWE.en-j3PyPqV-e1s_2_mp4","Nu8YGneFCWE.en-j3PyPqV-e1s","6.006","4"
"163","What are the main steps involved in the selection sort algorithm?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 5: Linear Sorting 
Lecture 5: Linear Sorting 
Review 
• Comparison search lower bound: any decision tree with n nodes has height ≥dlg(n+1)e−1 
• Can do faster using random access indexing: an operation with linear branching factor! 
• Direct access array is fast, but may use a lot of space (Θ(u)) 
• Solve space problem by mapping (hashing) key space u down to m = Θ(n) 
• Hash tables give expected O(1) time operations, amortized if dynamic 
• Expectation input-independent: choose hash function randomly from universal hash family 
• Data structure overview! 
• Last time we achieved faster ﬁnd. Can we also achieve faster sort? 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
Direct Access Array 
u 
1 
1 
u 
u 
Hash Table 
n(e) 
1(e) 
1(a)(e) 
n 
n 
","67.18241882324219","8","DPRSearchEngine","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5_1_pdf","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5","6.006","5"
"163","What are the main steps involved in the selection sort algorithm?"," 
 
 
 
  
 
 
 
 
 
 
 
Stratified Sampling  
§Stratified sampling
◦Partition population into subgroups
◦Take a simple random sample from each subgroup
6.0002  LECTURE 8 
 
5
","67.10511779785156","9","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_5_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"163","What are the main steps involved in the selection sort algorithm?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 4: Hashing 
Lecture 4: Hashing 
Review 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
• Idea! Want faster search and dynamic operations. Can we find(k) faster than Θ(log n)? 
• Answer is no (lower bound)! (But actually, yes...!?) 
Comparison Model 
• In this model, assume algorithm can only differentiate items via comparisons 
• Comparable items: black boxes only supporting comparisons between pairs 
• Comparisons are <, ≤, >, ≥, =, =6 , outputs are binary: True or False 
• Goal: Store a set of n comparable items, support find(k) operation 
• Running time is lower bounded by # comparisons performed, so count comparisons! 
Decision Tree 
• Any algorithm can be viewed as a decision tree of operations performed 
• An internal node represents a binary comparison, branching either True or False 
• For a comparison algorithm, the decision tree is binary (draw example) 
• A leaf represents algorithm termination, resulting in an algorithm output 
• A root-to-leaf path represents an execution of the algorithm on some input 
• Need at least one leaf for each algorithm output, so search requires ≥ n + 1 leaves 
","66.9258804321289","10","DPRSearchEngine","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_1_pdf","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4","6.006","4"
"164","What is a non-deterministic algorithm and how does it guarantee a solution for decision problems in polynomial time?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","76.32279968261719","1","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"164","What is a non-deterministic algorithm and how does it guarantee a solution for decision problems in polynomial time?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","75.47008514404297","2","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"164","What is a non-deterministic algorithm and how does it guarantee a solution for decision problems in polynomial time?","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","75.26001739501953","3","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"164","What is a non-deterministic algorithm and how does it guarantee a solution for decision problems in polynomial time?","What are oracles? Oracles are a simple thing. But they are a useful concept for a number of reasons. Especially because they're going to tell us something interesting about methods, which may or may not be useful for proving the P versus NP question, when someday somebody hopefully does that. What is an oracle? An oracle is free information you're going to give to a Turing machine, which might affect the difficulty of solving problems. And the way we're going to represent that free information is, we're going to allow the Turing machine to test membership in some specified language, without charging for the work involved. I'm going to allow you have any language at all, some language A. And say a Turing machine with an oracle for A is written this way, M with a superscript A. It's a machine that has a black box that can answer questions. Is some string, which the machine can choose, in A or not? And it gets that answer in one step, effectively for free. So you can imagine, depending upon the language that you're providing to the machine, that may or may not be useful. For example, suppose I give you an oracle for the SAT language. That can be very useful. It could be very useful for deciding SAT, for example. Because now you don't have to go through a brute force search to solve SAT. You just ask the oracle. And the oracle is going to say, yes it's satisfiable, or no it's not satisfiable. But you can use that to solve other languages too, quickly. Because anything that you can do in NP, you can reduce to SAT. So you can convert it to a SAT question, which you can then ship up to the oracle, and the oracle is going to tell you the answer. The word ""oracle"" already sort of conveys something magical. We're not really going to be concerned with the operation of the oracle, so don't ask me how does the oracle work, or what does it correspond to in reality. It doesn't. It's just a mathematical device which provides this free information to the Turing machine, which enables it to compute certain things. It turns out to be a useful concept. It's used in cryptography, where you might imagine the oracle could provide the factors to some number, or the password to some system or something. Free information. And then what can you do with that? So this is a notion that comes up in other places. If we have an oracle, we can think of all of the things that you can compute in polynomial time relative to that oracle. So that's what we-- the terminology that people usually use is sometimes called relativism, or computation relative to having this extra information. So P with an A oracle is all of the language that you can decide in polynomial time if you have an oracle for A. Let's see. Yeah. Somebody's asking me, is it really free or does it cost one unit? Even just setting up the oracle and writing down the question to the oracle is going to take you some number of steps. So you're not going to be able do an infinite number of oracle calls in zero time. So charging one step or zero steps, not going to make a difference. Because you still have to formulate the question. As I pointed out, P with a SAT oracle-- so all the things you do in polynomial time with a SAT oracle includes NP. Does it perhaps include other stuff? Or does it equal NP? Would have been a good check-in question, but I'm not going to ask that. In fact, it seems like it contains other things too. Because co-NP is also contained within P, given a SAT oracle. Because the SAT oracle answer is both yes or no, depending upon the answer. So if the formula is unsatisfiable, the oracle is going to say no, it's not in the language. And now you can do the complement of the SAT problem as well. The unsatisfiability problem. So you can do all of co-NP in the same way. You can also define NP relative to some oracle. So all the things you can do with a non-deterministic Turing machine, where all of the branches have separately access. And they can ask multiple questions, by the way, of the oracle. Independently. Let's do another, a little bit of a more challenging example. The MIN-FORMULA language, which I hope you remember from your homework. So those are all of the formulas that do not have a shorter equivalent formula. They are minimal. You cannot make a smaller formula that's equivalent that gives you the same Boolean function. So you showed, for example, that that language is in P space, as I recall. And there was some other-- you had another two problems about that language. The complement of the MIN-FORMULA problem is in NP with a SAT oracle. So mull that over for a second and then we'll see why. Here's an algorithm, in NP with a SAT oracle algorithm. So in other words, now I want to kind of implement that strategy, which I argued in the homework problem was not legal. But now that I have the SAT oracle, it's going to make it possible where before it was not possible. So let's just understand what I mean by that. If I'm trying to do the non minimal formulas, namely the formulas that do have a shorter equivalent formula. I'm going to guess that shorter formula, called psi. The challenge before was testing whether that shorter formula was actually equivalent to phi. Because that's not obviously doable in polynomial time. But the equivalence problem for formulas is a co-NP problem. Or if you like to think about it the other way, any formula in equivalence is an NP problem, because you just have to-- the witness is the assignment on which they disagree. So two formulas are equivalent if they never disagree. And so that's a co-NP problem. A SAT oracle can solve a co-NP problem. Namely, the equivalence of the two formulas, the input formula and the one that you now deterministically guessed. And if it turns out that they are equivalent, a smaller formula is equivalent to the input formula, you know the input formula is not minimal. And so you can accept. And if it gets the wrong formula, it turns out not to be equivalent, then you reject on that branch of the non-determinism, just like we did before. And if the formula really was minimal, none of the branches is going to find a shorter equivalent formula. So that's why this problem here is in NP with a SAT oracle. So now we're going to try to investigate this on my-- we're getting near the end of the lecture. We're going to look at problems like, well, suppose I compare P with a SAT oracle and NP with a SAT oracle. Could those be the same? Well, there's reasons to believe those are not the same. But could there be any A where P with A oracle is the same as NP with an A oracle? It seems like no, but actually that's wrong. There is a language, there are languages for which NP with that oracle and P with that oracle are exactly the same. And that actually is an interest-- it's not just a curiosity, it actually has relevance to strategies for solving P versus NP. Hopefully I'll be able to have time to get to. Can we think of an oracle like a hash table? I think hashing is somehow different in spirit. I understand there's some similarity there, but I don't see the-- hashing is a way of finding sort of a short name for objects, which has a variety of different purposes why you might want to do that. So I don't really think it's the same. Let's see, an oracle question, OK, let's see. How do we use SAT oracle to solve whether two formulas are equivalent? OK, this is getting back to this point. How can we use a SAT oracle to solve whether two formulas are equivalent? Well, we can use a SAT oracle to solve any NP problem, because it's reducible to SAT. In other words-- P with a SAT oracle contains all of NP, so you have to make sure you understand that part. If you have the clique problem, you can reduce. If I give you a clique problem, which is an NP problem, and I want to use the oracle to test if the formula-- if the graph has a clique, I reduce that problem to a SAT problem using the Cook-Levin theorem. And knowing that a clique of a certain size is going to correspond to having a formula which is satisfiable, now I can ask the oracle. And if I can do NP problems, I can do co-NP problems, because P is a deterministic class. Even though it has an oracle, it's still deterministic. It can invert the answer. Something that non-deterministic machines cannot necessarily do. So I don't know, maybe that's-- let's move on. So there's an oracle where P to the A equals NP to the A, which kind of seems kind of amazing at some level. Because here's an oracle where the non-determinism-- if I give you that oracle, non-determinism doesn't help. And it's actually a language we've seen. It's TQBF. Why is that? Well, here's the whole proof. If I have NP with a TQBF oracle. Let's just check each of these steps. I claim I can do that with a non-deterministic polynomial space machine, which no longer has an oracle. The reason is that, if I have polynomial space, I can answer questions about TQBF without needing an oracle. I have enough space just to answer the question directly myself. And I use my non-determinism here to simulate the non-determinism of the NP machine. So every time the NP machine branches non-deterministically, so do I. Every time one of those branches asks the oracle a TQBF question, I just do my polynomial space algorithm to solve that question myself. But now NPSPACE equals PSPACE by Savitch's theorem. And because TQBF is PSPACE complete, for the very same reason that a SAT oracle allows me to do every NP problem, a TQBF problem allows me to do every PSPACE problem. And so I get NP contained within P for a TQBF oracle. And of course, you get the containment the other way immediately. So they're equal. What does that have to do with-- somebody said-- well, I'll just-- I don't want to run out of time. So I'll take any questions at the end. What does this got to do with the P versus NP problem? OK, so this is a very interesting connection. Remember, we just showed through a combination of today's lecture and yesterday's lecture, and I guess Thursday's lecture, that this problem, this equivalence problem, is not in PSPACE, and therefore it's not in P, and therefore it's intractable. That's what we just did. We showed it's complete for a class, which is provably outside of P, provably bigger than P. That's the kind of thing we would like to be able to do to separate P and NP. We would like to show that some other problem is not in P. Some other problem is intractable. Namely, SAT. If we could do SAT, then we're good. We've solved P and NP. So we already have an example of being able to do that. Could we use the same method? Which is something people did try to do many years ago, to show that SAT is not in P. So what is that method really? The guts of that method really comes from the hierarchy there. That's where you were actually proving problems that are hard. You're getting this problem with through the hierarchy construction that's provably outside of PSPACE. And outside of P. That's a diagonalization. And if you look carefully at what's going on there-- so we're going to say, no, we're not going to be able to solve SAT, show SAT's outside of P in the same way. And the reason is, suppose we could. Well the hierarchy theorems are proved by diagonalization. What I mean by that is that in the hierarchy theorem, there's a machine D, which is simulating some other machine, M. To remember what's going on there, remember that we made a machine which is going to make its language different from the language of every machine that's running with less space or with less time. That's how D was defined. It wants to make sure its language cannot be done in less space. So it makes sure that its language is different. It simulates the machines that use less space, and does something different from what they do. Well, that simulation-- if we had an oracle, if we're trying to show that if we provide both a simulator and the machine being simulated with the same oracle, the simulation still works. Every time the machine you're simulating asks a question, the simulator has the same oracle so it can also ask the same question, and can still do the simulation. So in other words, if you could prove P different from NP using basically a simulation, which is what a diagonalization is, then you would be able to prove that P is different from NP for every oracle. So if you can prove P different from NP by a diagonalization, that would also immediately prove that P is different from NP for every oracle. Because the argument is transparent to the oracle. If you just put the oracle down, everything still works. But-- here is the big but, it can't be that-- we know that P A is-- we know this is false. We just exhibit an oracle for which they're equal. It's not the case that P is different from NP for every oracle. Sometimes they're equal, for some oracles. So something that's just basically a very straightforward diagonalization, something that's at its core is a diagonalization, is not going to be enough to solve P and NP. Because otherwise it would prove that they're different for every oracle. And sometimes they're not different, for some oracles. That's an important insight for what kind of a method will not be adequate to prove P different from NP. And this comes up all the time. People who propose hypothetical solutions that they're trying to show P different from NP. One of the very first things people ask is, well, would that argument still work if you put an oracle there. Often it does, which points out there was a flaw. Anyway, last check in. So this is just a little test of your knowledge about oracles. Why don't we-- in our remaining minute here. Let's say 30 seconds. And then we'll do a wrap on this, and I'll point out which ones are right. Oh boy, we're all over the place on this one. You're liking them all. Well, I guess the ones that are false are lagging slightly. OK, let's conclude. Did I give you enough time there? Share results. So, in fact-- Yeah, so having an oracle for the complement is the same as having an oracle. So this is certainly true. NP SAT equal coNP SAT, we have no reason to believe that would be true, and we don't know it to be true. So B is not a good choice and that's the laggard here. MIN-FORMULA, well, is in PSPACE, and anything in PSPACE is reducible to TQBF, so this is certainly true. And same thing for NP with TQBF and coNP with TQBF. Once you have TQBF, you're going to get all of PSPACE. And as we pointed out, this is going to be equal as well. So why don't we end here. And I think that's my last slide. Oh no, there's my summary here. This is what we've done. And I will send you all off on your way. How does the interaction between the Turing machine and the oracle look? Yeah, I didn't define exactly how the machine interacts with an oracle. You can imagine having a separate tape where it writes the oracle question and then goes into a special query state. You can formalize it however you like. They're all going to be-- any reasonable way of formalizing it is going to come up with the same notion in the end. It does show that P with a TQBF oracle equals PSPACE. Yes, that is correct. Good point. Why do we need the oracle to be TQBF? Wouldn't SAT also work because it could solve any NP problem? So you're asking, does P with a SAT oracle equal NP with a SAT oracle? Not known. And believed not to be true, but we don't have a compelling reason for that. No one has any idea how to do that. Because, for example, we showed the complement of MIN-FORMULA is in NP with a SAT oracle. But no one knows how to do-- because there's sort of two levels of non-determinism there. There's guessing the smaller formula, and then guessing again to check the equivalence. And they really can't be combined, because one of them is sort of an exist type guessing, the other one is kind of a for all type guessing. No one knows how to do that in polynomial time with a SAT oracle. Generally believed that they're not the same. In the check-in, why was B false? B is the same question. Does NP with a SAT oracle equal coNP with a SAT oracle? I'm not saying it's false, it's just not known to be true. It doesn't follow from anything that we've shown so far. And I think that would be something that-- well, I guess it doesn't immediately imply any famous open problem. I wouldn't necessarily expect you to know that it's an unsolved problem, but it is. Could we have oracles for undecidable language? Absolutely. Would it be helpful? Well, if you're trying to solve an undecidable problem, it would be helpful. But people do study that. In fact, the original concept of oracles was presented, was derived in the computability theory. And a side note, you can talk about reducibility. No, I don't want to even go there. Too complicated. What is not known to be true? What is not known to be true is that NP with a SAT oracle equals coNP with a SAT oracle, or equals P with a SAT oracle. Nothing is known except the obvious relations among those. Those are all unknown, and just not known to be true or false. Is NP with a SAT oracle equal to NP? Probably not. NP with a SAT oracle, for one thing, contains coNP. Because it's even more powerful. We pointed out that P with a SAT oracle contains coNP. And so NP with a SAT oracle is going to be at least as good. And so it's going to contain coNP. And so, probably not going to be equal to NP unless shockingly unexpected things happen in our complexity world.","74.88763427734375","4","DPRSearchEngine","N32bnUliSzo.en-j3PyPqV-e1s_9_mp4","N32bnUliSzo.en-j3PyPqV-e1s","18.404J","22"
"164","What is a non-deterministic algorithm and how does it guarantee a solution for decision problems in polynomial time?","OK. So to start this off, we're going to have to talk about non-deterministic complexity as a variation of deterministic complexity. So first of all, all of the machines in this part of the course and the languages, everything is going to be decidable and all the machines are going to be deciders. So what do we mean when we have a non-deterministic machine which is a decider? And that just simply means that all of the branches-- it's not just the machine halts on every input, but all of the branches halt on every input. So the non-deterministic machine is non-deterministic, it has lots of possible branches. They all have to halt-- all of them-- on every input. That's what makes a non-deterministic machine a decider. And you're going to convert a non-deterministic decider into a deterministic decider. But the question is, how much time would that introduce? How much extra time is that going to cost? And the only way that people know at the present time for that conversion would be to do an exponential increase. Basically, to try all possible branches.","74.18122863769531","5","DPRSearchEngine","1VhnDdQsELo.en-j3PyPqV-e1s_4_mp4","1VhnDdQsELo.en-j3PyPqV-e1s","18.404J","14"
"164","What is a non-deterministic algorithm and how does it guarantee a solution for decision problems in polynomial time?","  
 
  
 
 
  
 
  
 
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
  
 
 
   
-
Review: Probabilistic TMs and BPP 
coin flip step 
each choice has 
Defn: A probabilistic Turing machine (PTM) is a variant of a NTM 
where each computation step has 1 or 2 possible choices. 
deterministic 
step 
50% probability 
Defn: For ! ≥0 say PTM $  decides language % with error probability !  
if for every &, Pr[ $  gives the wrong answer about & ∈% ] ≤! . 
Defn: BPP = % some poly-time PTM decides % with error !  = +⁄,  } Check-in 24.1 
Actually using a probabilistic algorithm 
Amplification lemma: 2−. /01 2 
presupposes a source of randomness. 
Can we use a standard pseudo-random 
number generator (PRG) as the source? 
& ∈% 
& ∉% 
(a) Yes, but the result isn’t guaranteed.
(b) Yes, but it will run in exponential time.
Many 
Few 
Few 
Many 
(c) No, a TM cannot implement a PRG. 
accepting 
rejecting 
accepting 
rejecting 
(d) No, because that would show P = BPP.
2 
Check-in 24.1 
","73.63301849365234","6","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_2_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"164","What is a non-deterministic algorithm and how does it guarantee a solution for decision problems in polynomial time?","What's the worst case performance of a hash table? If I have to look up something in a hash table, and I happen to choose a bad hash table-- hash function, what's the worst case here? What? n, right? It's worse than a sorted array, because potentially, I hashed everything that I was storing to the same index in my hash table, and to be able to distinguish between them, I can't do anything more than a linear search. I could store another set's data structure as my chain and do better that way. That's actually how Java does it. They store a data structure we're going to be talking about next week as the chains so that they can get, worst case, log n. But in general, that hash table is only good if we're allowing-- OK, I want this to be expected good, but in the worst case, if I really need that operation to be worst case-- I really can't afford linear time ever for an operation of that kind-- then I don't want to use a hash table. And so on your p set 2, everything we ask you for is worst case, so probably, you don't want to be using hash tables. OK? Yes? AUDIENCE: What does the subscript e mean? JASON KU: What does the subscript e mean? That's great. In this chart, I put a subscript on this is an expected runtime, or an A meaning this is an amortized runtime. At the end, we talked about how, if we had too many things in our hash table, then, as long as we didn't do it too often-- this is a little hand wavey argument, but the same kinds of ideas as the dynamic array-- if, whenever we got a linear-- we are more than a linear factor away from where we are trying-- basically, the fill factor we were trying to be, then we could just completely rebuild the hash table with the new hash function randomly chosen from our hash table with a new size, and we could get amortized bounds. And so that's what Python-- how Python implements dictionaries, or sets, or even objects when it's trying to map keys to different things. So that's hash tables. That's great. The key thing here is, well, actually, if your range of keys is small, or if you as a programmer have the ability to choose the keys that you identify your objects with, you can actually choose that range to be small, to be linear, to be small with respect to your items. And you don't need a hash table. You can just use a direct access array, because if you know your key space is small, that's great. So a lot of C programmers probably would like to do something like that, because they don't have access to-- maybe C++ programmers would have access to their hash table. Any questions on this stuff before we move on? Yeah? AUDIENCE: So why is [INAUDIBLE]? JASON KU: Why is it expected? When I'm building, I could insert-- I'm inserting these things from x 1 by 1 into my hash table. Each of those insert operations-- I'm looking up to see whether that-- an item with that key already exists in my hash table. And so I have to look down the chain to see where it is. However, if I happen to know that all of my keys are unique in my input, all the items I'm trying to store are unique, then I don't have to do that check and I can get worst case linear time. Does that make sense? All right. It's a subtlety, but that's a great question. OK, so today, instead of talking about searching, we're talking about sorting. Last week, we saw a few ways to do sort. Some of them were quadratic-- insertion sort and selection sort-- and then we had one that was n log n. And this thing, n log n, seemed pretty good, but can I do better? Can I do better? Well, what we're going to show at the beginning of this class is, in this comparison model, no. n log n is optimal. And we're going to go through the exact same line of reasoning that we had last week. So in the comparison model, what did we use when we were trying to make this argument that any comparison model algorithm was going to take at least log n time? What we did was we said, OK, I can think of any model in the comparison model-- any algorithm in the comparison model as kind of this-- some comparisons happen. They branch in a binary sense, but you could have it generalized to any constant branching factor. But for our purposes, binary's fine. And what we said was that there were at least n outputs-- really n plus 1, but-- at least order n outputs. And we showed that-- or we argued to you that the height of this tree had to be at least log n-- log the number of leaves. It had to be at least log the number of leaves. That was the height of the decision tree. And if this decision tree represented a search algorithm, I had to walk down and perform these comparisons in order, reach a leaf where I would output something. If the minimum height of any binary tree on a linear number of leaves is log n, then any algorithm in the comparison model also has to take log n time, because it has to do that many comparisons to differentiate between all possible outputs. Does that make sense? All right. So in the sort problem, how many possible outputs are there?","73.43601989746094","7","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_4_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"164","What is a non-deterministic algorithm and how does it guarantee a solution for decision problems in polynomial time?","2 
Lecture 20: Course Review 
Next Steps 
• (U) 6.046: Design & Analysis of Algorithms 
• (G) 6.851: Advanced Data Structures 
• (G) 6.854: Advanced Algorithms 
6.046 
• Extension of 6.006 
– Data Structures: Union-Find, Amortization via potential analysis 
– Graphs: Minimum Spanning Trees, Network Flows/Cuts 
– Algorithm Design (Paradigms): Divide & Conquer, Dynamic Programming, Greedy 
– Complexity: Reductions 
• Relax Problem (change deﬁnition of correct/efﬁcient) 
– Randomized Algorithms 
∗ 6.006 mostly deterministic (hashing) 
∗ Las Vegas: always correct, probably fast (like hashing) 
∗ Monte Carlo: always fast, probably correct 
∗ Can generally get faster randomized algorithms on structured data 
– Numerical Algorithms/Continuous Optimization 
∗ 6.006 only deals with integers 
∗ Approximate real numbers! Pay time for precision 
– Approximation Algorithms 
∗ Input optimization problem (min/max over weighted outputs) 
∗ Many optimization problems NP-hard 
∗ How close can we get to an optimal solution in polynomial time? 
• Change Model of Computation 
– Cache Models (memory hierarchy cost model) 
– Quantum Computer (exploiting quantum properties) 
– Parallel Processors (use multiple CPUs instead of just one) 
∗ Multicore, large shared memory 
∗ Distributed cores, message passing 
","73.38966369628906","8","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_2_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"164","What is a non-deterministic algorithm and how does it guarantee a solution for decision problems in polynomial time?"," 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
   
 
    
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
Linearly Bounded Automata 
Defn: A linearly bounded automaton (LBA) is a 1-tape TM 
that cannot move its head off the input portion of the tape. 
LBA 
a a b a a b a 
Tape size adjusts to length of input. 
Let !LBA = &, ( LBA & accepts ( } 
Theorem:  !LBA is decidable 
Proof: (idea) If & on ( runs for long, it must be cycling. 
Decider for !LBA: 
Claim: For inputs of length ), an LBA can have 
.A−LBA = “On input &, ( 
only * ×)× Γ - different configurations. 
1.  Let ) = |(|. 
Therefore, if an LBA runs for longer, it must repeat some 
2. Run & on ( for * ×)× Γ - steps. 
configuration and thus will never halt. 
3. If has accepted, accept. 
4. If it has rejected or is still running, reject.” 
must be looping 
7 
","73.34869384765625","9","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_7_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"164","What is a non-deterministic algorithm and how does it guarantee a solution for decision problems in polynomial time?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","73.34608459472656","10","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"165","What is the limitation on memory when using a 64-bit architecture with byte addressable memory?","That was very limiting, actually. That's a restriction. With 64 bits, what's my limitation on memory that I can address-- byte addressable? Turns out to be something like 20 exabytes-- to put this in context, all data that Google stores on their servers, on all drives throughout the world-- it's about 10.","86.24002075195312","1","DPRSearchEngine","ZA-tUyM_y7s.en-j3PyPqV-e1s_9_mp4","ZA-tUyM_y7s.en-j3PyPqV-e1s","6.006","1"
"165","What is the limitation on memory when using a 64-bit architecture with byte addressable memory?","Actually, what a modern computer is addressed in is bytes, collections of 8 bits. So there's an address I have for every 8 bits in memory-- consecutive 8 bits in memory. And so if I want to pull something in into the CPU, I give it an address. It'll take some chunk, and bring it into the CPU, operate on it, and spit it back. How big is that chunk? This goes to the answer that you were asking, which-- or saying, which is it's some sequence of some fixed number of bits, which we call a word. A word is how big of a chunk that the CPU can take in from memory at a time and operate on. In your computers, how big is that word size? 64 bits-- that's how much I can operate on at a time. When I was growing up, when I was your age, my word size was 32 bits. And that actually was a problem for my computer, because in order for me to be able to read to address in memory, I need to be able to store that address in my CPU, in a word. But if I have 32 bits, how many different addresses can I address? I have a limitation on the memory addresses I can address, right? So how many different memory addresses can I address with 32 bits? 2 to the 32, right? That makes sense. Well, if you do that calculation out, how big of a hard disk can I have to access? It's about 4 gigabytes. So in my day, all the hard drives were limited to being partitioned-- even if you had a bigger than 4 gigabyte hard drive, I had to partition it into these 4 gigabyte chunks, which","85.59031677246094","2","DPRSearchEngine","ZA-tUyM_y7s.en-j3PyPqV-e1s_8_mp4","ZA-tUyM_y7s.en-j3PyPqV-e1s","6.006","1"
"165","What is the limitation on memory when using a 64-bit architecture with byte addressable memory?","to talk about in the word RAM. A side effect of this assumption that array access should take constant time, and that accessing these positions in my memory should take constant time, is that we need to assume w is at least log n or so. w, remember, is the machine word size. In real computers, this is currently 64-- or 256, in some bizarre instructions. But we don't usually think of the machine as getting bigger over time, but you should think of the machine as getting bigger over time. This is a statement that says, the word size has to grow with n. It might faster than log n, but it has to grow at least as fast as log n. Why do I say that? Because if I have n things that I'm dealing with-- n, here, is the problem size. Maybe it's the array I'm trying to store-- whatever. If I'm having to deal with n things in my memory, at the very least, I need to be able to address them. I should be able to say, give me the ith one and represent that number i in a word. Otherwise-- because the machine is designed to only work with w-bit words in constant time, they'll want to be able to access the ith word in constant time, I need a word size that's at least log n just to address that and n things in my input. So this is a totally reasonable assumption. It may seem weird because you think of a real machine as having constant size, but a real machine has constant size RAM, also. My machine has 24 gigs of RAM, or whatever. That laptop has 8. But you don't think of that as changing over time. But of course, if you want it to process a larger input, you would buy more RAM. So eventually, when our n's get really, really big, we're going to have to increase w just so we can address that RAM. That's the intuition here. But this is a way to bridge reality, which are fixed machines, with theory. In. Algorithms, we care about scalability for very large n. We want to know what that growth function is and ignore the lead constant factor. That's what asymptotic notation is all about. And for that, we need a notion of word size also changing in this asymptotic way. All right. That would be more important next week, when we talk about hashing and why hashing is a reasonable thing to do. But let's move on to dynamic sequences, which is where things get interesting. I have the update here. We start with static sequences. All of these operations are still something we want to support in a dynamic sequence, but we add two dynamic operations-- somewhat controversial operations, very exciting. I want to be able to insert in the middle of my sequence and I want to be able to delete from the middle of my sequence. Here's my sequence, which I'm going to think of in a picture. I'm going to draw it as an array. But it's stored however it's stored. We don't know. This is an interface, not an implementation. So we have x 0, x 1, x 2, x 3. And let's say I insert at position 2. Position 2 is here. So I come in with my new x, and I would like x to be the new x 2, but I don't want to lose any information. If I did set_at 2, then I would erase this and replace it with x. But I want to do insert_at, which means all of these guys, conceptually, are going to shift over by 1 in terms of their indices. Then, I would get this picture that's one bigger. And now I've got the new x. I've got what was the old x 2, which I don't-- I hesitate to call x 2 because that's its old name, not its new name. I'm going to draw arrows to say, these guys get copied over. These ones are definitely unchanged. Our new x 2, which prime is x This is x3 prime, 4 prime, and so on. I want to be careful here-- and of course, the new n prime is n plus 1. I want to be careful about the labeling, because the key-- what makes insert_at interesting is that, later, when I call get_at, it's with the new indexing. So previously, if I did get_at at 2, I would get this value. And afterwards, if I did get_at at 2, I would get the new value. If I did get_at at 3 down here, I would get the value that used to be X 2. That's maybe hard to track. But this is a conceptually very useful thing to do, especially when you're inserting or deleting at the ends. So we're going to define, in particular, insert and delete first and last. These are sometimes given-- if you have an insert, it has an x. If you do a delete, it has no argument. This means insert_at the beginning of the array, which would be like adding it here. And insert_last means adding it on here. insert_last doesn't change the indices of any of the old items. That's a nice feature of insert_last. Insert-first changes all of them. They all get incremented by 1. And we're also interested in the similar things here. We could do get-first or -last or set-first or -last, which are the obvious special cases of get_at and set_at. Now, these special cases are particularly interesting in an algorithms context. If you were a mathematician, you would say, well, why do I even bother? This is just shorthand for a particular call to get or set. But what makes it interesting from a data structures perspective is that we care about algorithms for supporting these operations. And maybe, the algorithm for supporting get-first or set-first, or in particular, insert-first or insert_last, might be more efficient. Maybe we can solve this problem better than we can solve insert_at. So while, ideally, we could solve the entire dynamic sequence interface constant time preparation, that's not actually possible. You can prove that. But special cases of it-- where we're just inserting and leading from the end, say-- we can do that. That's why it's interesting to introduce special cases that we care about. Cool. That's the definition of the dynamic sequence interface. Now, we're going to actually solve it.","79.38127136230469","3","DPRSearchEngine","CHhwJjR0mZA.en-j3PyPqV-e1s_4_mp4","CHhwJjR0mZA.en-j3PyPqV-e1s","6.006","2"
"165","What is the limitation on memory when using a 64-bit architecture with byte addressable memory?","to this interface problem-- the natural solution-- is what I'll call a static array. Jason mentioned these in lecture one. It's a little tricky because there are no static arrays in Python. There are only dynamic arrays, which is something we will get to. But I want to talk about, what is a static array, really? And this relates to our notion of-- our model of computation, Jason also talked about, which we call the word RAM, remember? The idea, in word RAM, is that your memory is an array of w-bit words. This is a bit circular. I'm going to define an array in terms of the word RAM, which is defined in terms of arrays. But I think you know the idea. So we have a big memory which goes off to infinity, maybe. It's divided into words. Each word here is w bits long. This is word 0, word 1, word 2. And you can access this array randomly-- random access memory. So I can give you the number 5 and get 0 1, 2, 3, 4, 5, the fifth word in this RAM. That's how actual memories work. You can access any of them equally quickly. OK, so that's memory. And so what we want to do is, when we say an array, we want this to be a consecutive chunk of memory. Let me get color. Let's say I have an array of size 4 and it lives here. Jason can't spell, but I can't count. So I think that's four. We've got-- so the array starts here and it ends over here. It's of size 4. And it's consecutive, which means, if I want to access the array at position-- at index i, then this is the same thing as accessing my memory array at position-- wherever the array starts, which I'll call the address of the array-- in Python, this is ID of array-- plus i. OK. This is just simple offset arithmetic. If I want to know the 0th item of the array, it's right here, where it starts. The first item is one after that. The second item is one after that. So as long as I store my array consecutively in memory, I can access the array in constant time. I can do get_at and set_at as quickly as I can randomly access the memory and get value-- or set a value-- which we're assuming is constant time. My array access is constant time. This is what allows a static array to actually solve this problem in constant time per get_at and set_at operation. This may seem simple, but we're really going to need this model and really rely on this model increasingly as we get to more interesting data structures. This is the first time we're actually needing it. Let's see. Length is also constant time. We're just going to store that number n, along with its address. And build is going to take linear time. Iteration will take linear time. Pretty straightforward. I guess one thing here, when defining build, I need to introduce a little bit more of our model of computation, which is, how do you create an array in the beginning? I claim I could do it in linear time, but that's just part of the model. This is called the memory allocation model. There are a few possible choices here, but the cleanest one is just to assume that you can allocate an array of size n in theta n time. So it takes linear time to make an array of size n. You could imagine this being constant. It doesn't really matter much. But it does take work. And in particular, if you just allocate some chunk of memory, you have no idea whether it's initialized. So initializing that array to 0s will cost linear time. It won't really matter, constant versus linear, but a nice side effect of this model is that space-- if you're just allocating arrays, the amount of space you use is, at most, the amount of time you use. Or, I guess, big O of that. So that's a nice feature. It's pretty weird if you imagine-- it's unrealistic to imagine you can allocate an array that's infinite size and then just use a few items out of it. That won't give you a good data structure. So we'll assume it costs to allocate memory. OK, great. We solved the sequence problem. Very simple, kind of boring. These are optimal running times. Now, let's make it interesting-- make sure I didn't miss anything--","77.67288208007812","4","DPRSearchEngine","CHhwJjR0mZA.en-j3PyPqV-e1s_3_mp4","CHhwJjR0mZA.en-j3PyPqV-e1s","6.006","2"
"165","What is the limitation on memory when using a 64-bit architecture with byte addressable memory?"," 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Relationships among models 
Informal Defn: Two models of computation are polynomially related 
if each can simulate the other with a polynomial overhead: 
So ! "" time → !$("") time on the other model, for some '. 
All reasonable deterministic models are polynomially related. 
• 1-tape TMs 
• multi-tape TMs 
• multi-dimensional TMs 
• random access machine (RAM) 
• cellular automata 
9 
","75.67314910888672","5","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_9_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"165","What is the limitation on memory when using a 64-bit architecture with byte addressable memory?"," 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
   
 
    
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
Linearly Bounded Automata 
Defn: A linearly bounded automaton (LBA) is a 1-tape TM 
that cannot move its head off the input portion of the tape. 
LBA 
a a b a a b a 
Tape size adjusts to length of input. 
Let !LBA = &, ( LBA & accepts ( } 
Theorem:  !LBA is decidable 
Proof: (idea) If & on ( runs for long, it must be cycling. 
Decider for !LBA: 
Claim: For inputs of length ), an LBA can have 
.A−LBA = “On input &, ( 
only * ×)× Γ - different configurations. 
1.  Let ) = |(|. 
Therefore, if an LBA runs for longer, it must repeat some 
2. Run & on ( for * ×)× Γ - steps. 
configuration and thus will never halt. 
3. If has accepted, accept. 
4. If it has rejected or is still running, reject.” 
must be looping 
7 
","74.98013305664062","6","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_7_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"165","What is the limitation on memory when using a 64-bit architecture with byte addressable memory?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","74.60943603515625","7","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"165","What is the limitation on memory when using a 64-bit architecture with byte addressable memory?","All right. So let me define a new automaton that we're going to mainly use as just to provide an example for us today. I'm going to call this a linearly bounded automaton. And all it is is a Turing machine where the Turing machine is going to be restricted in where it can-- the tape is not going to be infinite anymore. The tape is just going to be big enough to hold the input. So the machine no longer has the ability to move into the portion of the tape to the right of the input because there is no tape out there. It just has the tape sitting here that contains the input, which the tape itself can vary in size. However big the input is, that's how big the tape is. So the tape adjusts to the length of the input. But once you've started the machine with some particular input, that's as big as the tape is. There's no more. The reason why it's called linearly bounded is because the amount of memory is a linear function of the size of the input because you can effectively get somewhat more memory by enlarging the tape alphabet, but that's going to be fixed for any given machine, so that's where the linearly comes from, if that's helpful. But if you don't get that, it's sort of a side remark. But what's important to me is that you understand what I mean by a Linearly Bounded Automaton, or an LBA. It's just like a Turing machine, but that portion of the tape that originally had blanks is just not there. As the machine tries to move its head off the right end of the input, it just sticks there just as if it tried to move its head off the left end of the input. Doesn't go anywhere. So now, we're going to ask the same kinds of questions about LBAs that we ask for other automa. So the acceptance problem. If I give you an input and some particular LBA and I want to know, does the LBA accept that input? Well, and now the question is, is that the decidable or not? So at first glance, you might think, well, an LBA is like a Turing machine, and the ATM problem is undecidable, so that might be a good first guess. And also, if you try to simulate them, if you try to figure out how you would go about simulating the machine, if given b and w, if you actually tried to simulate the machine to get the answer, so you run b on w, well, of course, if you run it for a while, and it eventually halts, either accepting or rejecting, then you know the answer and you're finished. But this machine might get into a loop. You know, nothing to prevent the machine from looping on that finite amount of-- on that limited amount of tape that it has. And then you might be in trouble. But in fact, that's not the case because when you start out with a limited amount of tape, if you run the machine for a long time and it's not halting, it's going and going and going, inevitably, it's going to have to repeat, get into exactly the same configuration that it did before because there's only a limited number of configurations that the machine has. And once it repeats a configuration, it's going to be repeating that configuration forever, and it's going to be in a loop. So this problem, in fact, is decidable because the idea is if b on w runs for a very long time and an amount that you can calculate, then you know it's got to be cycling. More than just looping. It's got to be repeating itself. And so therefore, once it starts repeating itself, it's going to be going forever. So and here is the actual calculation, which is something I'm sure you could do on your own, but just to spell it out. So if you have an input of length n that you're providing to b, so if w is of length n, the LBA can only go for this number of different-- it can only have this number of different configurations. The number of states times the number of head positions, which is n, the number of head positions on the tape, times the number of different tape contents. If the tape was only one long, this is the-- this is the size of the tape alphabet. So if the tape were two long, the tape had two cells on it, the number of possible tape contents would be the square of the alphabet. And if the tape is going to be n symbols long, it's going to be the tape alphabet size to the nth power. So therefore, if a Turing machine runs for longer, it's got to repeat some configuration, and it'll never hold. So the decider is going to be hopefully clear at this point. You're given b and w, so this is the decider for a LBA. It's going to run b on w for this number of steps. If it's accepted by then, then you accept, and if it hasn't, if it's rejected or it's still running, then you can reject. And you know, if it's still running at this point, it's never going to accept. All right. Any questions on this? OK, let's move on.","74.09367370605469","8","DPRSearchEngine","MGqoLm2aAgc.en-j3PyPqV-e1s_7_mp4","MGqoLm2aAgc.en-j3PyPqV-e1s","18.404J","10"
"165","What is the limitation on memory when using a 64-bit architecture with byte addressable memory?","That's the problem, right? When u largest key-- we're assuming integers here-- integer keys-- so in the comparison model, we could store any arbitrary objects that supported a comparison. Here we really need to have integer keys, or else we're not going to be able to use those as addresses. So we're making an assumption on the inputs that I can only store integers now. I can't store arbitrary objects-- items with keys. And in particular, I also need to-- this is a subtlety that's in the word RAM model-- how can I be assured that these keys can be looked up in constant time? I have this little CPU. It's got some number of registers it can act upon. How big is those registers? AUDIENCE: [INAUDIBLE] JASON KU: What? Right now, they're 64 bits, but in general, they're w. They're the size of your word on your machine. 2 to the w is the number of dresses I can access. If I'm going to be able to use this direct accessory, I need to make sure that the u is less than 2 to the w, if I want these operations to run in constant time. If I have kids that are much larger than this, I'm going to need to do something else, but this is kind of the assumption. In this class, when we give you an array of integers, or an array of strings, or something like that on your problem or on an exam, the assumption is, unless we give you bounds on the size of those things-- like the number of characters in your string or the size of the number in the-- you can assume that those things will fit in one word of memory. w is the word size of your machine, the number of bits that your machine can do operations on in constant time. Any other questions? OK, so we have this problem. We're using way too much space, when we have a large universe of keys. So how do we get around that Problem any ideas? Sure. AUDIENCE: Instead of [INAUDIBLE].. JASON KU: OK, so what your colleague is saying-- instead of just storing one value at each place, maybe store more than one value. If we're using this idea, where I am storing my key at the index of the key, that's getting around the us having to have unique keys in our data structure. It's not getting around this space usage problem. Does that make sense? We will end up storing multiple things at indices, but there's another trick that I'm looking for right now. We have a lot of space that we would need to allocate for this data structure. What's an alternative? Instead of allocating a lot of space, we allocate-- less space. Let's allocate less space. All right.","73.93667602539062","9","DPRSearchEngine","Nu8YGneFCWE.en-j3PyPqV-e1s_6_mp4","Nu8YGneFCWE.en-j3PyPqV-e1s","6.006","4"
"165","What is the limitation on memory when using a 64-bit architecture with byte addressable memory?","talking about the word ram model of computation. A question here that usually doesn't matter in this class. Usually we assume additions take constant time. And we usually do that because it's usually true. And in general, our model is the w bit additions-- where w is our machine word size-- takes constant time. But for this problem and this problem only, pretty much, for Fibonacci numbers, I happen to know that the Fibonacci numbers grow exponentially. So to write them down actually requires theta n bits because they are some constant to the n power. And so they're actually really big . n is probably bigger than w. Usually you think of problems that are much bigger than 64 or whatever your word size happens to be. We do assume that w is at least log n. But n is probably bigger than w. It might be bigger or smaller. We don't know. And in general, to do an n bit addition-- these are n bit additions-- is going to take ceiling of n over w time. So in the end, we will spend this times n, because we have to do that, many of them, which is n plus n squared over w time. So a bit of a weird running time. But it's polynomial, whereas this original recursive algorithm was exponential here. Using this one simple idea of just remembering the work we've done, suddenly this exponential time algorithm becomes polynomial. Why? Because we have few sub problems. We had n sub problems. And for each sub problem, we could write a recurrence relation that if we already knew the solutions to smaller sub problems, we could compute this bigger problem very efficiently. This happened to be constant time or constant additions. n over w time. But as long as this is polynomial and this is polynomial, we're happy, because we have this nice formula that the time it takes is, at most, the sum over all sub problems of the relation time. So I'm referring to sub problems, like a number of them and the time it takes to evaluate this, ignoring the recursive calls. That's important. This is the non recursive part. In the notes, I call this non-recursive work. So this formula gives us a way to bound the running time of one of these algorithms if we use memoization. Without memoization, this is not true, Fibonacci to exponential time. But if we add memoization, we know that we only solve each sub-problem once. And so we just need to see, for each one, how much did it cost me to compute it, assuming all the recursion work is free, because that's already taken into account by the summation. So in particular, this summation is at most the number of sub-problems times the time per sub-problem,","73.7684326171875","10","DPRSearchEngine","r4-cftqTcdI.en-j3PyPqV-e1s_8_mp4","r4-cftqTcdI.en-j3PyPqV-e1s","6.006","15"
"166","What data structure is suggested for fast lookup of outgoing edges in a graph?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","74.55735778808594","1","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"166","What data structure is suggested for fast lookup of outgoing edges in a graph?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","73.00674438476562","2","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"166","What data structure is suggested for fast lookup of outgoing edges in a graph?","I want to print out what an edge looks like, I'm going to ask that it print out the name of the source, and then an arrow, and then the name of the destination. So notice what I do there. Given an instance of an edge, I can print it. And it will get the source or the node associated with source inside this instance, get for that the getName method, and then call it. Notice the open-close paren there to actually call it. What does that do? It says, inside the edge I've got something that points to a node. I get that node. I take the method associated with it. And I call it. That returns the string. And then I glue that together with the arrow. I do the same thing on the destination. And I just print it out. Pretty straightforward, hopefully. OK, now I have to make a decision about the graph. I'm going to start with digraphs, directed graphs. And I need to think about how I might represent the graph. I can create nodes. I can create edges, but I've got to bring them all together. So I'll remind you, a digraph is a directed graph. The edges pass in only one direction. And here's one way I could do it. Given all the sources and all the destinations, I could just create a big matrix called an adjacency matrix. The rows would be all the sources. The columns would be all the destinations. And then in a particular spot in the matrix, if there is an edge between a source and a destination, I'd just put a one. Otherwise I'd put a zero. Note, by the way, because it's a directed graph, it's not symmetric. There might be a one between S and D, but not between D and S, unless there are edges both ways. This would be a perfectly reasonable way to represent a graph, but not the most convenient one. I'd have to go into the matrix to look things up. It may also not be a very efficient way of representing things. For example, if there are very few edges in the graph, I could have a huge matrix with mostly zeros. And that's not the most effective way to do it. So I'm going to use an alternative called an adjacency list. And the idea here is, for every node in the graph. I'm going to associate with it a list of destinations. That is, for a node, what are the places I can reach with a single edge? OK, so let's see what that does if we want to build it. And yes, there's a lot of code here, but it's pretty easy to look through I hope. Here's the choice I'm going to make. Again, what's a graph? It's a set of nodes. It's a set of edges. I'm going to have a way of putting nodes into the graph. And I'm going to choose to, when I put a node into the graph, to store it as a key in a dictionary. OK? When I initialize the graph, I'm just going to set this internal variable, edges, to be an empty dictionary. And the second part of it is, when I add an edge to the graph between two nodes from a source to a destination, I'm going to take that point in the dictionary associated with the source. It's a key. And associated with it, I'm going to just have a list of the nodes I can reach from edges from that source. So notice what happens here. If I want to add a node, remember, it's a node not an edge-- I'll first check to make sure that it's not already in the dictionary. That little loop is basic, or that if is saying, if it's in this set of keys, it will return true. And I'm going to complain. I'm trying to copy a node or duplicate a node. Otherwise, notice what I do. When I put a node into the dictionary, I go into that dictionary, edges. I create an entry with the key that is the node. And the value I put in there is initially an empty list. I'm going to say one more piece carefully. It's a node not a name. And that's OK in Python. It is literally the key is the node itself. It's an object, which is what I'd like. All right, what if I want to add an edge? Well, an edge is going to go from a source to a destination node. So, I'm going to get out from the edge the source piece. I'm going to get out from the edge the destination piece by calling those methods. Again, notice the open-close paren, which takes the method and actually calls it. Because remember, an edge was an object itself. Given those, I'll check to make sure that they are both in the dictionary. That is, I've already added them to the graph. I can't make a connection between things that aren't in the graph. And then notice the nice little thing I do.","71.62035369873047","3","DPRSearchEngine","V_TulH374hw.en-qlPKC2UN_YU_2_mp4","V_TulH374hw.en-qlPKC2UN_YU","6.0002","3"
"166","What data structure is suggested for fast lookup of outgoing edges in a graph?","search-- BFS, for those in the know. Breadth-first search is an algorithm. And the reason we use the word breadth is because it's kind of, remember, we talked about level sets last time because we talked about breadth-first search in the context of computing shortest paths. And in particular, we have our source node all the way on the left-hand side. And then breadth-first search constructed all the nodes that were distance 1 away. Right. That's the first level set, and then all the distance 2 away, and then all the distance 3 away, and so on. So in particular, the level set L3 isn't visited until we're completely done with level set L2.","71.4413833618164","4","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_7_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"166","What data structure is suggested for fast lookup of outgoing edges in a graph?","4 
Lecture 1: Introduction 
1 
def birthday_match(students): 
2 
’’’ 
3 
Find a pair of students with the same birthday 
4 
Input: 
tuple of student (name, bday) tuples 
5 
Output: tuple of student names or None 
6 
’’’ 
7 
n = len(students) 
# O(1) 
8 
record = StaticArray(n) 
# O(n) 
9 
for k in range(n): 
# n 
10 
(name1, bday1) = students[k] 
# O(1) 
11 
# Return pair if bday1 in record 
12 
for i in range(k): 
# k 
13 
(name2, bday2) = record.get_at(i) 
# O(1) 
14 
if bday1 == bday2: 
# O(1) 
15 
return (name1, name2) 
# O(1) 
16 
record.set_at(k, (name1, bday1)) 
# O(1) 
17 
return None 
# O(1) 
Example: Running Time Analysis 
• Two loops: outer k ∈{0, . . . , n − 1}, inner is i ∈{0, . . . , k}
P n−1
• Running time is O(n) + 
k=0 (O(1) + k · O(1)) = O(n2) 
• Quadratic in n is polynomial. Efﬁcient? Use different data structure for record! 
How to Solve an Algorithms Problem 
1. Reduce to a problem you already know (use data structure or algorithm) 
Search Problem (Data Structures) 
Sort Algorithms 
Static Array (L01) 
Insertion Sort (L03) 
Linked List (L02) 
Selection Sort (L03) 
Dynamic Array (L02) 
Merge Sort (L03) 
Sorted Array (L03) 
Counting Sort (L05) 
Direct-Access Array (L04) 
Radix Sort (L05) 
Hash Table (L04) 
AVL Sort (L07) 
Balanced Binary Tree (L06-L07) 
Heap Sort (L08) 
Binary Heap (L08) 
2. Design your own (recursive) algorithm 
• Brute Force 
• Decrease and Conquer 
• Divide and Conquer 
• Dynamic Programming (L15-L19) 
• Greedy / Incremental 
Shortest Path Algorithms 
Breadth First Search (L09) 
DAG Relaxation (L11) 
Depth First Search (L10) 
Topological Sort (L10) 
Bellman-Ford (L12) 
Dijkstra (L13) 
Johnson (L14) 
Floyd-Warshall (L18) 
","71.19020080566406","5","DPRSearchEngine","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_4_pdf","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1","6.006","1"
"166","What data structure is suggested for fast lookup of outgoing edges in a graph?","Now we think about graphs, of course, we just spent the last couple of weeks thinking about data structures. We should think about how to store a graph on a computer, and there's many different options. In fact, really one thing that you can do is sort of pair-- just like when we talked about sets. There are many different ways to store sets. And one way to think about it was depending on how we're going to interact with that set we might choose one data structure or another to sort optimize the types of interactions we're going to have with that set and make them as fast as possible. This is exactly the same story for a graph. So for instance, the world's dumbest representation of a graph would be to just have a long list of edges. So for example, for this graph up here maybe I have 0, 1, that's an edge, and then 0, 2, that's another edge, and then 1, 2, and then 2, 1. There's a big list of edges. It's really a set. I don't care about the order. AUDIENCE: The first one's 1, 2. JUSTIN SOLOMON: 1-- oh, you're right. I'm sorry. Yeah, the edge points up-- thanks Erik, or not Erik-- Jason. OK, so let's say that I have a graph algorithm, and I'm going to have to do something like check whether there exists an edge from v to w a bunch of times. How long is that going to take in this data structure? Well, if I just have like a hot mess disorganized list of edges and I want to know does there exist an edge from v to w, all I can do is write a FOR loop that just goes along this and says, like this the edge I'm looking for. No. Is that the edge I'm looking for? No. So every single time I want to find an edge, it's going to take me time proportional to the number of edges of my graph which could potentially be up to v squared. Yeah, so this is not such a great representation of a graph on my computer. So if we're thinking back to our data structure we may say, OK, so an edge list is probably not the way to go. Although notice that the way we notated what is a graph kind of looks like an edge list. But in any event, the more common thing to do is to source something like an adjacency list. So the basic idea of an adjacency list is that what I'm going to store is a set that maps a vertex u to everything adjacent to u. So in other words, I'm just going to keep track of all the outgoing edges from every vertex. And now I have to decide, how am I going to store this object. And oftentimes, we're going to have to answer queries like does there exist an edge from v to w. So how could I do that? First, I would look up v, and I get back sort of a list or a set of all the things that are adjacent to v. And I have to query that thing. And I want it to be pretty fast. So maybe what I do is I store the set of adjacent stuff as something like a direct access array or a hash table to make that look up fast. So for example, how long would it take-- I see, I'm going to finish the sentence here-- how long would it take me to check if an edge existed in my graph? Well, what would I do? I would first pull out this object, and then I'd look inside of here. So if I stored this as a hash table, then the expected time I would have order one look up, because this is order one and then you have another order one look up there. So we went from v squared to one with one simple trick. Yes? AUDIENCE: Does it matter what direction [INAUDIBLE] JUSTIN SOLOMON: That's a great question. So this is a design decision here. I'm sorry, in my head I think a lot about undirected graphs, and I'm going to make this mistake a lot. And I'm glad that you caught me. There's a totally reasonable thing to do, which is maybe just to keep track of the outgoing edges for every vertex. This is a design decision. For an algorithm maybe I want to keep track of the incoming edges. Whatever, I just have to make sure that it aligns with what I want to do with my graph later. Excellent point. Sorry, as a geometry person we rarely encounter directed graphs. But it's important to keep remembering that not everybody works on the same problems that I do. OK, now if I wanted to be totally extreme about it-- as just a third example of representation, which actually, in some sense, you could think of like an adjacency list-- we need an adjacency matrix where now I just keep a giant v by v array of like does this exist, does that edge exist. Now it's really, really easy to check if an edge exists. But now let's say that I make a graph algorithm that's going to have a FOR loop over all the neighbors of some vertex. So here, if I wanted to loop over all the neighbors of u, I could do that in time proportional to the number of neighbors of u. But if I just have a big adjacency matrix, just a bunch of binary values-- like for every pair of vertices are these vertices adjacent-- yea or nay. If I want to iterate over all my neighbors, now I have to iterate over all the vertices and check is that number one and then do something. So actually that can incur some additional time and additional space. Does that makes sense? So in any event, that's a sort of a lazy man's graph representation. I use it a lot when I'm coding because adjacency matrices are easy to work with. But it does incur a lot of additional space, and it's not always the most efficient thing even if you have the space because iterating over neighbors, it actually can take quite a bit of time.","70.46656799316406","6","DPRSearchEngine","oFVYVzlvk9c.en-j3PyPqV-e1s_8_mp4","oFVYVzlvk9c.en-j3PyPqV-e1s","6.006","9"
"166","What data structure is suggested for fast lookup of outgoing edges in a graph?","And that's cycle detection. So there's a bit of an exercise left to the reader here. So the problem that we're looking for now is that we're given a directed graph. There's a G in graph, in case you're wondering. But now, we don't know if it's a DAG or not. And so the question that we're trying to ask is, does there exist a cycle in our directed acyclic graph? So we're just given our graph, and we want to know, can we do this? Let's think through the logic of this a bit. So what do we know? We know that if our graph were a DAG, then I could call DGS, get the ordering out, and then I guess flip its ordering backwards. So I could compute the reverse finishing order. And it would give me a topological order of my graph. So if I were a DAG, I would get a topological order when I call DFS. So let's say that I ran DFS. I got whatever ordering I got. And now I found an edge the points in the wrong direction. I can just double check my list of edges, and I find one that does not respect the relationship that I see in the second bullet point here. Can my graph be a DAG? No. Because if my graph were a DAG, the algorithm would work. I just proved it to you. Right? So if my graph were a DAG, then I could do reverse finishing order. And what I would get back is a topological order. So if I found a certificate that my order wasn't topological, something went wrong, and the only thing that could go wrong is that my graph isn't a DAG. Yeah. Isn't a DAG. In fact, sort of an exercise left to the reader and/or to your section-- do we still have section? I think we do, as of now-- is that this is an if and only if, meaning that the only time that you even have a topological ordering in your graph is if your graph is a DAG. This is a really easy fact to sanity check, by the way. This is not like, a particularly challenging problem. But you should think through it because it's a good exercise to make sure you understand the definitions, which is to say that if you have a topological order, your graph is a DAG. If you don't have a topological order, your graph isn't a DAG. So in other words, we secretly gave you an algorithm for checking if a graph is a DAG at all. Right? What could I do? I could compute reverse finishing order. Check if it obeys the relationship on the second bullet point here for every edge. And if it does, then we're in good shape. My graph is a DAG. If it doesn't, something went wrong. And the only thing that could have gone wrong is not being a DAG. OK. So in other words, secretly we just solved-- well, I guess the way that I've written it here, we've solved the cycle detection problem here, which is to say that, well, I have a cycle if and only if I'm not a DAG, which I can check using this technique. Of course, the word ""detection"" here probably means that I actually want to find that cycle, and I haven't told you how to do that yet. All we know how to do so far is say, like, somewhere in this graph there's a cycle. And that's not so good. So we can do one additional piece of information in the two minutes we have remaining to sort of complete our story here, which is to modify our algorithm ever so slightly to not only say thumbs up, thumbs down, is there a cycle in this graph, but also to actually return the vertices as a cycle. And here's the property that we're going to do that, which is following, which is that if G contains a cycle, right, then full DFS will traverse an edge from a vertex v to some ancestor of v. I guess we haven't carefully defined the term ""ancestor"" here. Essentially, if you think of the sort of the running of the DFS algorithm, then an ancestor is like something that appears in the recursive call tree before I got to v. OK. So how could we prove that? Well, let's take a cycle. And we'll give it a name. In particular, we'll say that it's a cycle from v0 v1 to vk. And then it's a cycle, so it goes back to v0. OK. And I can order this cycle any way I want. Notice that if I permute the vertices in this list in a cyclical way, meaning that I take the last few of them and stick them at the beginning of the list, it's still a cycle. That's the nice thing about cycles. So in particular, without loss of generality, we're going to assume that v0 is the first vertex visited by DFS. What does that mean? That means, like, when I do my DFS algorithm making all these recursive calls, the very first vertex to be touched by this technique is v0. OK. Well, now what's going to end up happening? Well, think about the recursive call tree starting at v0. By the time that completes, anything that's reachable from v0 is also going to be complete. Do you see that? So for instance, v0 somewhere in its call tree might call v2. And notice that v2 was not already visited. So in fact, it will. For v1 I got to call v2 and so on. And in particular, we're going to get all the way to vertex k. Right? So in other words, we're going to visit a vertex vk. And notice what's going to happen. So remember our algorithm. In fact, we should probably just put it up on the screen would be easier than talking about it a bunch. Well, vk is now going to iterate over every one of the neighbors of vk. And in particular, it's going to see vertex v0. Right? So we're going to see the edge from vk to v0, which is an edge kind of by definition because we took this to be a cycle here. But notice that's exactly the thing we set out to prove, namely that full DFS traverses an edge from a vertex to one of its ancestors. Here's a vertex k. Here's the ancestor v0. Why do we know that it's an ancestor? Well, because v0 was called in our call tree before any of these other guys. Right? So we wanted an algorithm that not only did cycle detection, but also actually gave me the cycle. What could I do? Well, it's essentially a small modification of what we already have. Right. So-- whoops. Right. If I want to compute topological order or whatever, I can just do DFS. And that'll tell me like, yay or nay, does there exist a cycle. If I want to actually find that cycle, all I have to do is check that topological order property at the same time that it traversed the graph during DFS. And the second that I find an edge that loops back, I'm done. And so that's our basic algorithm here. And this is a technique for actually just finding the cycle in a graph using the DFS algorithm.","70.42782592773438","7","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_20_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"166","What data structure is suggested for fast lookup of outgoing edges in a graph?","[SQUEAKING][RUSTLING][CLICKING] JASON KU: Welcome, everybody, to our lecture 14 of 6.006. This is our last lecture on graph algorithms, in particular, the last lecture we'll have on weighted shortest paths. But we're going to talk about a slightly different problem today, different than single source shortest paths. We're going to be talking about all-pairs shortest paths. But first, let's review our single source shortest paths algorithms. We had BFS, DAG relaxation, Dijkstra, which we saw last time, which gets pretty close to linear. V log V plus E is pretty close to linear. It's much closer to linear than the general algorithm we have for solving single source shortest paths, namely, Bellman-Ford, which is a little bit more like quadratic. This is like the difference between-- for sparse graphs, this is like the difference between sorting, using insertion sort and n squared, and merge sort in N log N, for example. We're going to get actually quite a big bonus for large input sizes by using Dijkstra when we can. Today, we're going to be focusing","70.36579895019531","8","DPRSearchEngine","EmSmaW-ud6A.en-j3PyPqV-e1s_1_mp4","EmSmaW-ud6A.en-j3PyPqV-e1s","6.006","14"
"166","What data structure is suggested for fast lookup of outgoing edges in a graph?"," &&%$3$%'9
class Digraph(object): 
 """"""edges is a dict mapping each node to a list of 
    its children""""” 
    def __init__(self): 
self.edges = {} 
    def addNode(self, node): 
if node in self.edges: 
 raise ValueError('Duplicate node') 
else: 
self.edges[node] = [] 
    def addEdge(self, edge): 
src = edge.getSource() 
dest = edge.getDestination() 
if not (src in self.edges and dest in self.edges): 
raise ValueError('Node not in graph') 
self.edges[src].append(dest) 
Q>KKKMN
LS
mapping each node 
list 
","70.31880187988281","9","DPRSearchEngine","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_18_pdf","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3","6.0002","3"
"166","What data structure is suggested for fast lookup of outgoing edges in a graph?","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","70.31087493896484","10","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"167","What is the base case for the insert_last function in the insertion sort algorithm?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","81.16145324707031","1","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"167","What is the base case for the insert_last function in the insertion sort algorithm?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","79.4334716796875","2","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"167","What is the base case for the insert_last function in the insertion sort algorithm?","I've been talking about-- build, insert, and delete_max. So we have set AVL trees there-- n log n build, log n insert, log n delete. So along the way to our heap, I want to mention two other data structures. One is a dynamic but unsorted array. And the other is a dynamic sorted array. These are simpler data structures we've talked about many times before. And they're useful kind of motivations for getting started, because a heap is going to be built on top of arrays instead of-- well, it's sort of a fusion between arrays and trees. So if I have an unsorted array, this is very easy to insert into, right? I just append to the end. This is what we called insert last. So insert is fast, constant amortized. We might have to resize the array, but so that's the amortized part. But delete max is slow. In an unsorted array, I don't know where the maximum is. So I have to scan through the whole array. So I scan through the array, identify that the max is somewhere in the middle, and then, if I want to delete it-- I want to delete that maximum element, well, in a dynamic array, all I can really do is delete the last element efficiently. So I could, for example, swap it with the last element. So I take this element and put it here, and then delete the last element in that array, which is pop in Python or delete_last in our world. So overall, this is linear time, which is bad. But I wanted to highlight exactly how it's done for a reason we'll get to in a moment. A sorted array is sort of the reverse. It's very easy to find the max. Where is it? At the end. delete_max, the maximum element is always the last element in a increasing sorted array. I guess that's constant amortized, because then I have to delete it, which may incur resizing. Insert, though, is going to be linear, because maybe I can binary search to find where the added item belongs. Let's say I just added this item here. I could binary search to find it, but then I'm going to have to do a big shift. So I might as well just swap repeatedly until I find the position where the added item x belongs. And now I've restored sorted order. That takes linear time, which is bad. And what we want is somehow the best of these two worlds. Insert is fast for array. Delete is fast for a sorted array. We can't get constant time for both. But we can get log n time for both. We already know how with set AVL trees. But we're going to see a different way to do it today. And the main motivation for a different way to do this is sorting. So I want to define a priority queue sort. So given any data structure that implements a priority queue interface, in particular insert and delete_max, I can make a sorting algorithm. What do I do? Insert all the items, delete all the items. But because when I delete them they come out largest first, I get them in reverse sorted order. Then I could reverse in linear time and I've sorted my items. So we can insert (x) for x in A, or (build(A)), and then repeatedly delete_max. How much time does this algorithm take? I'm going to introduce some notation here. It takes however long it takes to build n items, call that T sub build (n) plus-- sorry-- plus n times the time to do a delete_max. Or we can write this as n times time to do an insert, plus time to do a delete_max. So I'm using these T functions to just abstract what are the running times provided by my data structure that implements this interface. Interface says what's correct is, and these T functions give me my performance bounds. So if I plug in each of these data structures, I get a sorting algorithm. I get AVL sort, I get array sort, I get assorted array sort. What do those look like? It turns out many of these are familiar. So set AVLs take log n per operation. So we get an n log n sorting algorithm out of them, which is insert all of the items into the AVL tree. I don't want to use AVL build because that uses sort, and not allowed to sort in order to implement sort. But we saw how to insert into an AVL tree and keep the thing balanced. So that takes log n each. And then we can find the max, delete it, rebalance, and so on. Total time will be n log n. This is an algorithm we call AVL sort. It's a bit complicated, because AVL trees are complicated. But it gives us optimal comparison bound and log n. Now, what about array sort? So suppose I use an unsorted array. I insert the item. So if I insert the items-- so I'm doing all the insertions here before all the deletions. So what's going to happen is I just insert the items in the original array order. In other words, I just take the array. And then what I do is repeatedly extract the maximum item by searching for it, moving it to the end of the array, and then repeating that process. That sound familiar? That's selection sort from lecture three. So this-- arrays give us selection sort. This is a new way to think about what we were doing way back then. With a sorted array, what are we doing? We insert all the items. That's actually where all the work happens, because we maintain the sorted array. So we start with an empty array. It's sorted. We add an item. OK, it's still sorted. We add a second item, and we swap if we need to in order to sort. In general, when we add an item, we swap it to the left until it's sorted again. That is insertion sort. Kind of cool, this is a unifying framework for three sorting algorithms that we saw before. We didn't actually talk about AVL sort last time, but it was in the notes. And so that is the right part of this table.","79.16832733154297","3","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_4_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"167","What is the base case for the insert_last function in the insertion sort algorithm?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 5: Linear Sorting 
Lecture 5: Linear Sorting 
Review 
• Comparison search lower bound: any decision tree with n nodes has height ≥dlg(n+1)e−1 
• Can do faster using random access indexing: an operation with linear branching factor! 
• Direct access array is fast, but may use a lot of space (Θ(u)) 
• Solve space problem by mapping (hashing) key space u down to m = Θ(n) 
• Hash tables give expected O(1) time operations, amortized if dynamic 
• Expectation input-independent: choose hash function randomly from universal hash family 
• Data structure overview! 
• Last time we achieved faster ﬁnd. Can we also achieve faster sort? 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
Direct Access Array 
u 
1 
1 
u 
u 
Hash Table 
n(e) 
1(e) 
1(a)(e) 
n 
n 
","78.17501831054688","4","DPRSearchEngine","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5_1_pdf","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5","6.006","5"
"167","What is the base case for the insert_last function in the insertion sort algorithm?","&

	
	
	/
def greedy(items, maxCost, keyFunction):
itemsCopy = sorted(items, key = keyFunction,
reverse = True)
result = []
totalValue, totalCost = 0.0, 0.0
for i in range(len(itemsCopy)):
if (totalCost+itemsCopy[i].getCost()) <= maxCost:
result.append(itemsCopy[i])
totalCost += itemsCopy[i].getCost()
totalValue += itemsCopy[i].getValue()
return (result, totalValue) 
	

2
	

","77.46685791015625","5","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_24_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"167","What is the base case for the insert_last function in the insertion sort algorithm?","They take linear time for some of the operations. So the sorting algorithms are not efficient. But they're ones we've seen before, so it's neat to see how they fit in here. They had the-- selection sort and insertion sort had the advantage that they were in place. You just needed a constant number of pointers or indices beyond the array itself. So they're very space efficient. So that was a plus for them. But they take n squared time, so you should never use them, except for n, at most, 100 or something. AVL tree sort is great and then it gets n log n time, probably more complicated than merge sort and you could stick to merge sort. But neither merge sort nor set AVL tree sort are in place. And so the goal of today is to get the best of all those worlds in sorting to get n log n comparisons, which is optimal in the comparison model, but get it to be in place. And that's what we're going to get with binary heaps. We're going to design a data structure that happens to build a little bit faster-- as I mentioned, linear time building. So it's not representing a sorted order in the same way that AVL trees are. But it will be kind of tree-based. It will also be array-based. We're going to get logarithmic time for insert and delete_max. It happens to be amortized, because we use arrays. But the key thing is that it's an in-place data structure. It only consists of an array of the items. And so, when we plug it into our sorting algorithm-- priority queue sort or generic sorting algorithm-- not only do we get n log n performance, but we also get an in-place sorting algorithm. This will be our first and only-- to this class-- n log n in-place sorting algorithm. Cool. That's the goal.","76.96524047851562","6","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_5_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"167","What is the base case for the insert_last function in the insertion sort algorithm?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 2: Data Structures 
Lecture 2: Data Structures 
Data Structure Interfaces 
• A data structure is a way to store data, with algorithms that support operations on the data 
• Collection of supported operations is called an interface (also API or ADT) 
• Interface is a speciﬁcation: what operations are supported (the problem!) 
• Data structure is a representation: how operations are supported (the solution!) 
• In this class, two main interfaces: Sequence and Set 
Sequence Interface (L02, L07) 
• Maintain a sequence of items (order is extrinsic) 
• Ex: (x0, x1, x2, . . . , xn−1) (zero indexing) 
• (use n to denote the number of items stored in the data structure) 
• Supports sequence operations: 
Container 
build(X) 
len() 
given an iterable X, build sequence from items in X 
return the number of stored items 
Static 
iter seq() 
get at(i) 
set at(i, x) 
return the stored items one-by-one in sequence order 
return the ith item 
replace the ith item with x 
Dynamic 
insert at(i, x) 
delete at(i) 
insert first(x) 
delete first() 
insert last(x) 
delete last() 
add x as the ith item 
remove and return the ith item 
add x as the ﬁrst item 
remove and return the ﬁrst item 
add x as the last item 
remove and return the last item 
• Special case interfaces: 
stack 
insert last(x) and delete last() 
queue 
insert last(x) and delete first() 
","76.5682373046875","7","DPRSearchEngine","79a07dc1cb47d76dae2ffedc701e3d2b_MIT6_006S20_lec2_1_pdf","79a07dc1cb47d76dae2ffedc701e3d2b_MIT6_006S20_lec2","6.006","2"
"167","What is the base case for the insert_last function in the insertion sort algorithm?","4 
Lecture 1: Introduction 
1 
def birthday_match(students): 
2 
’’’ 
3 
Find a pair of students with the same birthday 
4 
Input: 
tuple of student (name, bday) tuples 
5 
Output: tuple of student names or None 
6 
’’’ 
7 
n = len(students) 
# O(1) 
8 
record = StaticArray(n) 
# O(n) 
9 
for k in range(n): 
# n 
10 
(name1, bday1) = students[k] 
# O(1) 
11 
# Return pair if bday1 in record 
12 
for i in range(k): 
# k 
13 
(name2, bday2) = record.get_at(i) 
# O(1) 
14 
if bday1 == bday2: 
# O(1) 
15 
return (name1, name2) 
# O(1) 
16 
record.set_at(k, (name1, bday1)) 
# O(1) 
17 
return None 
# O(1) 
Example: Running Time Analysis 
• Two loops: outer k ∈{0, . . . , n − 1}, inner is i ∈{0, . . . , k}
P n−1
• Running time is O(n) + 
k=0 (O(1) + k · O(1)) = O(n2) 
• Quadratic in n is polynomial. Efﬁcient? Use different data structure for record! 
How to Solve an Algorithms Problem 
1. Reduce to a problem you already know (use data structure or algorithm) 
Search Problem (Data Structures) 
Sort Algorithms 
Static Array (L01) 
Insertion Sort (L03) 
Linked List (L02) 
Selection Sort (L03) 
Dynamic Array (L02) 
Merge Sort (L03) 
Sorted Array (L03) 
Counting Sort (L05) 
Direct-Access Array (L04) 
Radix Sort (L05) 
Hash Table (L04) 
AVL Sort (L07) 
Balanced Binary Tree (L06-L07) 
Heap Sort (L08) 
Binary Heap (L08) 
2. Design your own (recursive) algorithm 
• Brute Force 
• Decrease and Conquer 
• Divide and Conquer 
• Dynamic Programming (L15-L19) 
• Greedy / Incremental 
Shortest Path Algorithms 
Breadth First Search (L09) 
DAG Relaxation (L11) 
Depth First Search (L10) 
Topological Sort (L10) 
Bellman-Ford (L12) 
Dijkstra (L13) 
Johnson (L14) 
Floyd-Warshall (L18) 
","76.523681640625","8","DPRSearchEngine","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_4_pdf","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1","6.006","1"
"167","What is the base case for the insert_last function in the insertion sort algorithm?","What's the worst case performance of a hash table? If I have to look up something in a hash table, and I happen to choose a bad hash table-- hash function, what's the worst case here? What? n, right? It's worse than a sorted array, because potentially, I hashed everything that I was storing to the same index in my hash table, and to be able to distinguish between them, I can't do anything more than a linear search. I could store another set's data structure as my chain and do better that way. That's actually how Java does it. They store a data structure we're going to be talking about next week as the chains so that they can get, worst case, log n. But in general, that hash table is only good if we're allowing-- OK, I want this to be expected good, but in the worst case, if I really need that operation to be worst case-- I really can't afford linear time ever for an operation of that kind-- then I don't want to use a hash table. And so on your p set 2, everything we ask you for is worst case, so probably, you don't want to be using hash tables. OK? Yes? AUDIENCE: What does the subscript e mean? JASON KU: What does the subscript e mean? That's great. In this chart, I put a subscript on this is an expected runtime, or an A meaning this is an amortized runtime. At the end, we talked about how, if we had too many things in our hash table, then, as long as we didn't do it too often-- this is a little hand wavey argument, but the same kinds of ideas as the dynamic array-- if, whenever we got a linear-- we are more than a linear factor away from where we are trying-- basically, the fill factor we were trying to be, then we could just completely rebuild the hash table with the new hash function randomly chosen from our hash table with a new size, and we could get amortized bounds. And so that's what Python-- how Python implements dictionaries, or sets, or even objects when it's trying to map keys to different things. So that's hash tables. That's great. The key thing here is, well, actually, if your range of keys is small, or if you as a programmer have the ability to choose the keys that you identify your objects with, you can actually choose that range to be small, to be linear, to be small with respect to your items. And you don't need a hash table. You can just use a direct access array, because if you know your key space is small, that's great. So a lot of C programmers probably would like to do something like that, because they don't have access to-- maybe C++ programmers would have access to their hash table. Any questions on this stuff before we move on? Yeah? AUDIENCE: So why is [INAUDIBLE]? JASON KU: Why is it expected? When I'm building, I could insert-- I'm inserting these things from x 1 by 1 into my hash table. Each of those insert operations-- I'm looking up to see whether that-- an item with that key already exists in my hash table. And so I have to look down the chain to see where it is. However, if I happen to know that all of my keys are unique in my input, all the items I'm trying to store are unique, then I don't have to do that check and I can get worst case linear time. Does that make sense? All right. It's a subtlety, but that's a great question. OK, so today, instead of talking about searching, we're talking about sorting. Last week, we saw a few ways to do sort. Some of them were quadratic-- insertion sort and selection sort-- and then we had one that was n log n. And this thing, n log n, seemed pretty good, but can I do better? Can I do better? Well, what we're going to show at the beginning of this class is, in this comparison model, no. n log n is optimal. And we're going to go through the exact same line of reasoning that we had last week. So in the comparison model, what did we use when we were trying to make this argument that any comparison model algorithm was going to take at least log n time? What we did was we said, OK, I can think of any model in the comparison model-- any algorithm in the comparison model as kind of this-- some comparisons happen. They branch in a binary sense, but you could have it generalized to any constant branching factor. But for our purposes, binary's fine. And what we said was that there were at least n outputs-- really n plus 1, but-- at least order n outputs. And we showed that-- or we argued to you that the height of this tree had to be at least log n-- log the number of leaves. It had to be at least log the number of leaves. That was the height of the decision tree. And if this decision tree represented a search algorithm, I had to walk down and perform these comparisons in order, reach a leaf where I would output something. If the minimum height of any binary tree on a linear number of leaves is log n, then any algorithm in the comparison model also has to take log n time, because it has to do that many comparisons to differentiate between all possible outputs. Does that make sense? All right. So in the sort problem, how many possible outputs are there?","76.16216278076172","9","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_4_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"167","What is the base case for the insert_last function in the insertion sort algorithm?"," 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 6: Binary Trees I 
Lecture 6: Binary Trees I 
Previously and New Goal 
Sequence 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
build(X) 
get at(i) 
set at(i,x) 
insert first(x) 
delete first() 
insert last(x) 
delete last() 
insert at(i, x) 
delete at(i) 
Array 
n 
1 
n 
n 
n 
Linked List 
n 
n 
1 
n 
n 
Dynamic Array 
n 
1 
n 
1(a) 
n 
Goal 
n 
log n 
log n 
log n 
log n 
Set 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
Direct Access Array 
u 
1 
1 
u 
u 
Hash Table 
n(e) 
1(e) 
1(a)(e) 
n 
n 
Goal 
n log n 
log n 
log n 
log n 
log n 
How? Binary Trees! 
• Pointer-based data structures (like Linked List) can achieve worst-case performance 
• Binary tree is pointer-based data structure with three pointers per node 
• Node representation: node.{item, parent, left, right} 
• Example: 
1 
2 
3 
4 
5 
________<A>_____ 
__<B>_____ 
<C> 
__<D> 
<E> 
<F> 
node 
| 
item 
| 
parent | 
left 
| 
right 
| 
<A> | 
A 
| 
-
| 
<B> | 
<C> | 
<B> 
B 
<A> 
<C> 
<D> 
| 
| 
| 
| 
| 
<C> | 
C 
| 
<A> | 
-
| 
-
| 
<D> | 
D 
| 
<B> | 
<F> | 
-
| 
<E> | 
E 
| 
<B> | 
-
| 
-
| 
<F> 
F 
<D> 
-
-
| 
| 
| 
| 
| 
","75.94083404541016","10","DPRSearchEngine","376714cc85c6c784d90eec9c575ec027_MIT6_006S20_lec6_1_pdf","376714cc85c6c784d90eec9c575ec027_MIT6_006S20_lec6","6.006","6"
"168","How can the problem of finding the existence of a path between two vertices be solved using the shortest path approach?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","71.2729721069336","1","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"168","How can the problem of finding the existence of a path between two vertices be solved using the shortest path approach?","But of course, there's sort of many variations on that theme when we talk about shortest path or even just existence of a path. So these are three sort of model problems that we might solve on a graph. So the first one, which in this of course we're calling the single pair reachability, would be the idea that I take two vertices s and t on my graph g, and I ask you does there exists a path between s and t. So what would be the sort of extreme example where this problem may not always give back the answer yes? Somehow in our head, I think we think of all graphs as being connected. But a perfectly valid graph the way we've defined it would be like 10 vertices and no edges. This function would be very easy to code if that were the only graph you ever cared about. But any event, the existence of a path is already a query that takes a little bit of algorithmic thinking. We haven't figured out how to do that yet. Now another problem we can solve would be the shortest path. Given a graph and two vertices, we might say, well, how far apart are these vertices of my graph if I want to use the shortest possible distance from one to the other. Notice that I can use the second problem to solve the first one. Because what's the length of the shortest path between two vertices that don't have a path between them? Infinity or a shrug-- that's actually a totally valid answer. Yeah, that's right. So how could I implement the reachability code? Well, I could call my shortest path code, and it gives me infinity. Then I return no, it's not reachable. And if it gives me not infinity, I return yes. So remember that a key idea in an algorithms class is this idea of reduction. That I can use one function to solve another. So in case, if we can solve shortest path, then we can certainly solve the reachability problem by calling that piece of code. And then finally we could talk about single source shortest path. So notice now that there's only one input node here s-- so what this problem is saying is give me the length of the shortest path from s to every single other vertex in my graph. Does that makes sense? Like maybe I return a big array with all the information, every single shortest distance. So can we solve single pair shortest path using single source shortest path? Absolutely. I could take s in my single pair shortest path problem, compute the shortest path from s to literally everything else, and then throw away all of that information except the shortest path to t, and now I'm good. Now I haven't justified that this is the fastest possible way to solve that second problem, but at least it shows that if I can solve problem three I can also solve problem two. If I can solve from two I can also solve problem one. So in today's lecture, we're just going to worry about problem three. In other words, these things are sort of listed in increasing order of their difficulty. OK, so in order to think about the single source shortest path problem, we're going to make one additional construction. And this is an idea called the shortest path tree. I got lazy drawing PowerPoint slides at 2:00 AM yesterday,","71.17374420166016","2","DPRSearchEngine","oFVYVzlvk9c.en-j3PyPqV-e1s_10_mp4","oFVYVzlvk9c.en-j3PyPqV-e1s","6.006","9"
"168","How can the problem of finding the existence of a path between two vertices be solved using the shortest path approach?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","70.57377624511719","3","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"168","How can the problem of finding the existence of a path between two vertices be solved using the shortest path approach?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 4: Hashing 
Lecture 4: Hashing 
Review 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
• Idea! Want faster search and dynamic operations. Can we find(k) faster than Θ(log n)? 
• Answer is no (lower bound)! (But actually, yes...!?) 
Comparison Model 
• In this model, assume algorithm can only differentiate items via comparisons 
• Comparable items: black boxes only supporting comparisons between pairs 
• Comparisons are <, ≤, >, ≥, =, =6 , outputs are binary: True or False 
• Goal: Store a set of n comparable items, support find(k) operation 
• Running time is lower bounded by # comparisons performed, so count comparisons! 
Decision Tree 
• Any algorithm can be viewed as a decision tree of operations performed 
• An internal node represents a binary comparison, branching either True or False 
• For a comparison algorithm, the decision tree is binary (draw example) 
• A leaf represents algorithm termination, resulting in an algorithm output 
• A root-to-leaf path represents an execution of the algorithm on some input 
• Need at least one leaf for each algorithm output, so search requires ≥ n + 1 leaves 
","70.05667114257812","4","DPRSearchEngine","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_1_pdf","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4","6.006","4"
"168","How can the problem of finding the existence of a path between two vertices be solved using the shortest path approach?","single source shortest paths in linear time. Last time we discussed another linear time algorithm, DAG relaxation. And today we're going to be talking about Bellman-Ford, which isn't limited to asymptotic graphs. In particular, there could be negative weight cycles in our graph. If it has cycles, if it has negative weights, the worry is that we could have negative weight cycles, in which case there-- if a negative weight cycle is reachable from our source, then the vertices in that cycle and anything reachable from that cycle will potentially","70.01171112060547","5","DPRSearchEngine","f9cVS_URPc0.en-j3PyPqV-e1s_2_mp4","f9cVS_URPc0.en-j3PyPqV-e1s","6.006","12"
"168","How can the problem of finding the existence of a path between two vertices be solved using the shortest path approach?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","69.71598815917969","6","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"168","How can the problem of finding the existence of a path between two vertices be solved using the shortest path approach?","Longest path is maybe a problem we've talked about in problem session, because it's a DAG-- well, longest path is the same thing as shortest path, if you just negate all the weights. There are no weights in this picture, so if you just put negative 1 on all these edges and ask for the shortest path from the base to anywhere-- so single source shortest paths from this base-- then we would end up getting this path, which, if you look at it, is E-M-P-T-Y, empty. And so that shortest path is indeed the right answer. What I've drawn here is the shortest path tree. So also, if you wanted the longest increasing subsequence starting at A, then it is A-T-Y, just by following the red arrows here. And how do you get that? You just draw the parent pointers, just like we did before.","69.68822479248047","7","DPRSearchEngine","KLBCUx1is2c.en-j3PyPqV-e1s_8_mp4","KLBCUx1is2c.en-j3PyPqV-e1s","6.006","16"
"168","How can the problem of finding the existence of a path between two vertices be solved using the shortest path approach?","If you compare these two classes, P and NP. P, first of all, is going to be a subset of NP, both in terms of the way we defined it because, deterministic machines are a special case of non-deterministic machines. But also if you want to think about testing membership, if you can test membership easily then you can certainly verify it in terms of the certificate. You don't even need it. The certificate is irrelevant at that point. Because whatever the certificate is, you can still test yourself whether the input is in the language or not. The big question, as I mentioned, is whether these two classes are the same. So does being able to verify membership quickly, say with one of these certificates, allow you to dispense with the certificate? Not even need a certificate and just test it for yourself whether you're in the language. And do that in polynomial time. That's the question. For a problem like Hamiltonian path, do you need to search for the answer if you're doing it deterministically? Or can you somehow avoid that and just come up with the answer directly with a polynomial time solution? Nobody knows the answer to that. And it goes back, at this point, quite a long time. It's almost 60 years now. That problem has been around 60 years. No, that would be 50 years. No, 50 years, almost 50 years. Most people believe that P is different from NP. In other words, that there are problems in P-- in NP which are not in P. A candidate would be the Hamiltonian path problem. But it seems to be very hard to prove that. And part of the reason is, how do you prove that a problem like Hamiltonian path does not have a polynomial time algorithm. It's very tricky to do that, because the class of polynomial time algorithms is a very rich class. Polynomial time algorithms are very powerful. And to try to prove-- there's no clever way of solving the Hamiltonian path problem. It just seems to be beyond our present day mathematics. I believe someday somebody's going to solve it. But so far, no one has succeeded. So what I thought we would do is-- I think I have a check-in here.","69.51559448242188","8","DPRSearchEngine","1VhnDdQsELo.en-j3PyPqV-e1s_8_mp4","1VhnDdQsELo.en-j3PyPqV-e1s","18.404J","14"
"168","How can the problem of finding the existence of a path between two vertices be solved using the shortest path approach?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 10: Depth-First Search 
Lecture 10: Depth-First Search 
Previously 
• Graph deﬁnitions (directed/undirected, simple, neighbors, degree) 
• Graph representations (Set mapping vertices to adjacency lists) 
• Paths and simple paths, path length, distance, shortest path 
• Graph Path Problems 
– Single Pair Reachability(G,s,t) 
– Single Source Reachability(G,s) 
– Single Pair Shortest Path(G,s,t) 
– Single Source Shortest Paths(G,s) (SSSP) 
• Breadth-First Search (BFS) 
– algorithm that solves Single Source Shortest Paths 
– with appropriate data structures, runs in O(|V | + |E|) time (linear in input size) 
Examples 
G1 
a 
d 
b 
e 
c 
f 
G2 
a 
d 
b 
e 
c 
f 
","69.35526275634766","9","DPRSearchEngine","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10_1_pdf","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10","6.006","10"
"168","How can the problem of finding the existence of a path between two vertices be solved using the shortest path approach?","There's not a bound on the number of edges for a shortest path, because I could just keep going around that cycle as many times as I want and get a shorter path. And so we assign those distances to be minus infinity. So that's what we're going to do today in Bellman-Ford. In particular, what we're going to do is compute our shortest path distances, the shortest path waits for every vertex in our graph, setting the ones that are not reachable to infinity, and the ones that are reachable through a negative weight cycle to minus infinity, and all other ones we're going to set to a finite weight. And another thing that we might want is if there's a negative weight cycle in the graph, let's return one. So those are the two kinds of things that we're trying to solve in today's lecture. But before we do that, let's warm up with two short exercises. The first one, exercise 1, given an undirected graph, given undirected graph G, return whether G contains a negative weight cycle. Anyone have an idea of how we can solve this in linear time, actually? In fact, we can do it in order E. No-- yes, yes. Reachable from S. I guess-- let's just say a negative weight cycle at all. Not in the context of single-source shortest paths.","68.59654235839844","10","DPRSearchEngine","f9cVS_URPc0.en-j3PyPqV-e1s_3_mp4","f9cVS_URPc0.en-j3PyPqV-e1s","6.006","12"
"169","What is the goal when finding a Minimum Spanning Tree in a weighted graph?","Minimum Spanning Tree-- so I'm trying to find a tree connecting all of the vertices in a connected component of my graph. And I'm trying to find-- in a weighted graph, I'm trying to find the spanning tree that has minimum total weight. So that's a problem-- a fundamental problem in weighted-graph algorithms. They've solved this via a greedy algorithm. And network flows and I guess cuts. So this is-- what is this? This is, I'm given a weighted graph. Basically, each of the weights correspond to a capacity. I could push water through along this edge. And I may be given a source vertex and a sink vertex. And I want to say, I want to shove water through the source vertex along the edges with their various capacities. And I'll get some amount of water on the other end in the source. So the question is, what's the most amount of water that I can push through this? Well, I could build that pipe network with the different things and just do this experimentally. I just stick a bunch of-- maybe-- I'm a mechanical engineer, so that maybe makes sense to me. But you want to be able to just look at those numbers and be able to tell me how much water can I push through. That's what the max flow in a network is talking about.","76.2275390625","1","DPRSearchEngine","2NMtS1ecb3o.en-j3PyPqV-e1s_7_mp4","2NMtS1ecb3o.en-j3PyPqV-e1s","6.006","20"
"169","What is the goal when finding a Minimum Spanning Tree in a weighted graph?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","72.67613983154297","2","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"169","What is the goal when finding a Minimum Spanning Tree in a weighted graph?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 4: Hashing 
Lecture 4: Hashing 
Review 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
• Idea! Want faster search and dynamic operations. Can we find(k) faster than Θ(log n)? 
• Answer is no (lower bound)! (But actually, yes...!?) 
Comparison Model 
• In this model, assume algorithm can only differentiate items via comparisons 
• Comparable items: black boxes only supporting comparisons between pairs 
• Comparisons are <, ≤, >, ≥, =, =6 , outputs are binary: True or False 
• Goal: Store a set of n comparable items, support find(k) operation 
• Running time is lower bounded by # comparisons performed, so count comparisons! 
Decision Tree 
• Any algorithm can be viewed as a decision tree of operations performed 
• An internal node represents a binary comparison, branching either True or False 
• For a comparison algorithm, the decision tree is binary (draw example) 
• A leaf represents algorithm termination, resulting in an algorithm output 
• A root-to-leaf path represents an execution of the algorithm on some input 
• Need at least one leaf for each algorithm output, so search requires ≥ n + 1 leaves 
","72.19258880615234","3","DPRSearchEngine","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_1_pdf","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4","6.006","4"
"169","What is the goal when finding a Minimum Spanning Tree in a weighted graph?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","71.92642211914062","4","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"169","What is the goal when finding a Minimum Spanning Tree in a weighted graph?","single source shortest paths in linear time. Last time we discussed another linear time algorithm, DAG relaxation. And today we're going to be talking about Bellman-Ford, which isn't limited to asymptotic graphs. In particular, there could be negative weight cycles in our graph. If it has cycles, if it has negative weights, the worry is that we could have negative weight cycles, in which case there-- if a negative weight cycle is reachable from our source, then the vertices in that cycle and anything reachable from that cycle will potentially","71.82344055175781","5","DPRSearchEngine","f9cVS_URPc0.en-j3PyPqV-e1s_2_mp4","f9cVS_URPc0.en-j3PyPqV-e1s","6.006","12"
"169","What is the goal when finding a Minimum Spanning Tree in a weighted graph?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 11: Weighted Shortest Paths 
Lecture 11: Weighted Shortest Paths 
Review 
• Single-Source Shortest Paths with BFS in O(|V | + |E|) time (return distance per vertex) 
• Single-Source Reachability with BFS or DFS in O(|E|) time (return only reachable vertices) 
• Connected components with Full-BFS or Full-DFS in O(|V | + |E|) time 
• Topological Sort of a DAG with Full-DFS in O(|V | + |E|) time 
• Previously: distance = number of edges in path Today: generalize meaning of distance 
Weighted Graphs 
• A weighted graph is a graph G = (V, E) together with a weight function w : E → Z 
• i.e., assigns each edge e = (u, v) ∈ E an integer weight: w(e) = w(u, v) 
• Many applications for edge weights in a graph: 
– distances in road network 
– latency in network connections 
– strength of a relationship in a social network 
• Two common ways to represent weights computationally: 
– Inside graph representation: store edge weight with each vertex in adjacency lists 
– Store separate Set data structure mapping each edge to its weight 
• We assume a representation that allows querying the weight of an edge in O(1) time 
Examples 
G1 
G2 
a 
e 
b 
f 
c 
g 
d 
h 
6 
8 
−2 
5 
9 
−5 
7 
3 
2 
−1 
−4 
1 
4 
a 
e 
b 
f 
c 
g 
d 
h 
6 
8 
−2 
5 
9 
−5 
7 
3 
2 
−1 
−4 
1 
4 
","71.20067596435547","6","DPRSearchEngine","aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11_1_pdf","aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11","6.006","11"
"169","What is the goal when finding a Minimum Spanning Tree in a weighted graph?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 10: Depth-First Search 
Lecture 10: Depth-First Search 
Previously 
• Graph deﬁnitions (directed/undirected, simple, neighbors, degree) 
• Graph representations (Set mapping vertices to adjacency lists) 
• Paths and simple paths, path length, distance, shortest path 
• Graph Path Problems 
– Single Pair Reachability(G,s,t) 
– Single Source Reachability(G,s) 
– Single Pair Shortest Path(G,s,t) 
– Single Source Shortest Paths(G,s) (SSSP) 
• Breadth-First Search (BFS) 
– algorithm that solves Single Source Shortest Paths 
– with appropriate data structures, runs in O(|V | + |E|) time (linear in input size) 
Examples 
G1 
a 
d 
b 
e 
c 
f 
G2 
a 
d 
b 
e 
c 
f 
","71.08201599121094","7","DPRSearchEngine","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10_1_pdf","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10","6.006","10"
"169","What is the goal when finding a Minimum Spanning Tree in a weighted graph?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","70.90341186523438","8","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"169","What is the goal when finding a Minimum Spanning Tree in a weighted graph?","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","70.8552017211914","9","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"169","What is the goal when finding a Minimum Spanning Tree in a weighted graph?","that we've already seen in 6006? AUDIENCE: A tree. JUSTIN SOLOMON: A tree. At least if we orient all all the edges kind of pointing downward in the tree. Yeah. Otherwise, it gets kind of debatable over whether it's a DAG or not. If there's no direction to the edges, then somehow the definition just doesn't apply. OK. So in processing directed acyclic graphs, there's a really useful thing that you can do that's going to show up in this class apparently quite a bit, which is kind of interesting to me, I'm curious to see what that looks like, which is to compute a topological order on the graph. We're at topologies here.","70.05564880371094","10","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_16_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"170","What does the Max Flow problem involve in the context of network flows?","Minimum Spanning Tree-- so I'm trying to find a tree connecting all of the vertices in a connected component of my graph. And I'm trying to find-- in a weighted graph, I'm trying to find the spanning tree that has minimum total weight. So that's a problem-- a fundamental problem in weighted-graph algorithms. They've solved this via a greedy algorithm. And network flows and I guess cuts. So this is-- what is this? This is, I'm given a weighted graph. Basically, each of the weights correspond to a capacity. I could push water through along this edge. And I may be given a source vertex and a sink vertex. And I want to say, I want to shove water through the source vertex along the edges with their various capacities. And I'll get some amount of water on the other end in the source. So the question is, what's the most amount of water that I can push through this? Well, I could build that pipe network with the different things and just do this experimentally. I just stick a bunch of-- maybe-- I'm a mechanical engineer, so that maybe makes sense to me. But you want to be able to just look at those numbers and be able to tell me how much water can I push through. That's what the max flow in a network is talking about.","75.05410766601562","1","DPRSearchEngine","2NMtS1ecb3o.en-j3PyPqV-e1s_7_mp4","2NMtS1ecb3o.en-j3PyPqV-e1s","6.006","20"
"170","What does the Max Flow problem involve in the context of network flows?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","71.56748962402344","2","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"170","What does the Max Flow problem involve in the context of network flows?","And this is a subset of the set interface. And subsets are interesting because, potentially, we can solve them better, faster, simpler, something. And so you'll recognize-- you should recognize all of these operations, except we didn't normally highlight the max operation. So here, we're interested in storing a bunch of items. They have keys which we think of as priorities. And we want to be able to identify the maximum priority item in our set and remove it. And so there's lots of motivations for this. Maybe you have a router, packets going into the router. They have different priorities assigned to them. You want to route the highest priority first. Or you have processes on your computer trying to run on your single threaded-- single core, and you've got to choose which one to run next. And you usually run higher priority processes first. Or you're trying to simulate a system where events happen at different times, and you want to process the next event ordered by time. All of these are examples of the priority queue interface. We'll even see applications within this class when we get to graph algorithms. But the main two things we want to be able to support are inserting an item, which includes a key, and leading the maximum item, and also returning it at the same time. We'll also talk some about being able to build the structure faster than just inserting it. But of course, we could implement build by starting empty and repeatedly inserting. And also the complexity of just finding the max without deleting it, this you could simulate with these two operations by deleting the max and then reinserting it, which works. But often, we can do faster. But the two key, main operations are insert and delete max. And we're going to see a few data structures to do this. Any suggestions among the data structures we've seen in this class? What should we use to solve priority queue interface? Many possible answers.","70.61577606201172","3","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_2_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"170","What does the Max Flow problem involve in the context of network flows?"," 
 
 
   
 
 
 
   
   
      
 
 
 
 
 
 
  
 
Stochastic Processes  
An ongoing process where the next state might depend on 
both the previous states and some random element 
def rollDie(): 
"""""" returns an int between 1 and 6"""""" 
def rollDie(): 
"""""" returns a randomly chosen int 
between 1 and 6"""""" 
6.0002 LECTURE 4 
8
","70.57028198242188","4","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_8_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"170","What does the Max Flow problem involve in the context of network flows?","single source shortest paths in linear time. Last time we discussed another linear time algorithm, DAG relaxation. And today we're going to be talking about Bellman-Ford, which isn't limited to asymptotic graphs. In particular, there could be negative weight cycles in our graph. If it has cycles, if it has negative weights, the worry is that we could have negative weight cycles, in which case there-- if a negative weight cycle is reachable from our source, then the vertices in that cycle and anything reachable from that cycle will potentially","70.45562744140625","5","DPRSearchEngine","f9cVS_URPc0.en-j3PyPqV-e1s_2_mp4","f9cVS_URPc0.en-j3PyPqV-e1s","6.006","12"
"170","What does the Max Flow problem involve in the context of network flows?","It's not really complicated. Instead of having a single source, we are essentially wanting to, given an input-- this is our weighted graph, where we've got a graph V, E, and we've got a weight function from the edges to the integers. This is our general weighted graph. We want our output to be something like, the shortest path distance from u to v for every u and v in our vortex set. That's what we want to return. Now, there's one caveat here that, if there's a negative weight cycle in our graph-- in other words, if any of these delta u, v's is minus infinity,","69.7750015258789","6","DPRSearchEngine","EmSmaW-ud6A.en-j3PyPqV-e1s_2_mp4","EmSmaW-ud6A.en-j3PyPqV-e1s","6.006","14"
"170","What does the Max Flow problem involve in the context of network flows?"," 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
Law of Large Numbers  
In repeated independent tests with the same actual 
probability p of a particular outcome in each test, the 
chance that the fraction of times that outcome occurs 
differs from p converges to zero as the number of trials 
goes to infinity 
Does this imply that if 
deviations from expected 
behavior occur, these 
deviations are likely to be 
evened out by opposite 
deviations in the future? 
6.0002 LECTURE 6 
14
","69.57087707519531","7","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_14_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"170","What does the Max Flow problem involve in the context of network flows?","in general graphs, which we know as Bellman-Ford, but rephrased into the SRTBOT framework. So we defined this problem, in the Bellman-Ford lecture, delta sub k of s, v. Remember, this was the weight of a shortest path from s to v that is restricted to use, at most, k edges. This made the problem feasible. We ended up taking the product of the graph into all of these different subproblems, in fact.","69.45552825927734","8","DPRSearchEngine","TDo3r5M1LNo.en-j3PyPqV-e1s_4_mp4","TDo3r5M1LNo.en-j3PyPqV-e1s","6.006","17"
"170","What does the Max Flow problem involve in the context of network flows?"," 
 
 
 
  
 
 
  
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Intro to Complexity Theory 
Computability theory (1930s - 1950s): 
Is A decidable? 
Complexity theory (1960s - present): 
Is A decidable with restricted resources? 
(time/memory/…) 
Example: Let ! = a#b# $ ≥0 . 
Q: How many steps are needed to decide !? 
Depends on the input. 
We give an upper bound for all inputs of length '. 
Called “worst-case complexity”. 
2 
","69.13087463378906","9","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_2_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"170","What does the Max Flow problem involve in the context of network flows?","Header for Decision Tree Implementa#on 
6.0002 LECTURE 2 
9 
def maxVal(toConsider, avail): 
    """"""Assumes toConsider a list of items,  
               avail a weight 
       Returns a tuple of the total value of a  
           solution to 0/1 knapsack problem and  
           the items of that solution""""” 
toConsider. Those items that nodes higher up in the tree 
(corresponding to earlier calls in the recursive call stack) 
have not yet considered 
 
avail. The amount of space still available  
","68.67811584472656","10","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_9_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"172","How does ray casting determine the color for each pixel on the screen?","If you continue with me next fall, we'll teach 6.837, which is the Intro to Computer Graphics course. One thing that's always amazing to students is, these, algorithms that produce these really beautiful images, can fit in about 10, 20 lines of code. So really, this is totally facetious, because if you want those beautiful images and you use those 20 lines of code, you'll be waiting until the death of the universe to actually compute these things. But in any event, one nice one for rendering-- so drawing a bunch of shapes [INAUDIBLE],, something called ray casting, or its better known cousin, ray tracing. Typically, the difference is whether your rays can bounce off of the surface and have a secondary thing. Right. Here's the ray casting algorithm. Let's say I have a scene built out of spheres and cubes. I'm going to have a for loop over every pixel on the computer screen. For every pixel, I've got to discover what color that should be. So I shoot a ray from my eyeball through that pixel and find the first object that it runs into. It's not so hard to intersect a line of a sphere or a line of a cube. So what is that algorithm? I've given it to you on the screen here. Not too bad to think about. And I think you guys are all extremely well equipped to analyze the runtime of this, which is roughly the number of pixels times the number of objects. Because for every pixel, I've got to decide what object the ray out of my eyeball hits first. So I need a for loop over [INAUDIBLE].. Make sense? Cool. So let's look at a basic rendering problem.","71.28463745117188","1","DPRSearchEngine","4nXw-f6NJ9s.en-j3PyPqV-e1s_10_mp4","4nXw-f6NJ9s.en-j3PyPqV-e1s","6.006","21"
"172","How does ray casting determine the color for each pixel on the screen?","There's a very famous 3D model called the Stanford bunny. The Stanford bunny is actually a great example of a simplicial complex-- in fact, a manifold one, triangulated surface. Actually, I'm not sure it's manifold in its original form. But usually, it is. And this innocent-looking, extremely famous 3D model is actually quite pernicious. It's composed of 69,000 triangles. And if I wanted 1080p-- like a high def rendering of my triangle-- then, of course, there's two million pixels on the screen. So if we look at our big O expression, roughly, our computation time scales like the product of those two big numbers. So just to render this ugly gray bunny takes me a pretty large amount of time. And in fact, the reality-- by the way, the bunny is this famous test case in computer graphics, so if you take my class, you'll be rendering buddies all day. The reality is, we don't want just grayed, flat-shaded bunnies. We want bunnies that are transparent, and reflecting stuff, and I shoot my bunny with a bullet and shatters into a million pieces, and all of these cool things. So of course that, ray casting algorithm, with each one of these new graphics features I add, only adds to the time complexity of the technique that I implement. So pretty quickly-- and indeed, if you write your own ray tracer at home, which I strongly encourage you to do-- what you will discover is that a [INAUDIBLE] would be the technical phrase. What is our way out of this?","65.75804901123047","2","DPRSearchEngine","4nXw-f6NJ9s.en-j3PyPqV-e1s_11_mp4","4nXw-f6NJ9s.en-j3PyPqV-e1s","6.006","21"
"172","How does ray casting determine the color for each pixel on the screen?","You can also use it to build a replicator, where you're given an object like this that you don't know the shape of-- like, we don't know whether this exists, and we can't model it mathematically very well, and you stick it in a vat, and all of these tiles would attach and basically build a mold, and then start photocopying, in 3D, that mold. And you can build that with a system with only two steps, I believe, and a constant number of tile types. And it does all of that, in this model, in constant time. In reality, you would have to feed this machine and wait for it to print out all of these things, and these experiments take hours, if not days, to run. But in theory, it's really cool. And you get some really fun models and very general results. You can also use it to build a miniaturizer or a magnifier and other fun stuff.","64.02188110351562","3","DPRSearchEngine","4nXw-f6NJ9s.en-j3PyPqV-e1s_3_mp4","4nXw-f6NJ9s.en-j3PyPqV-e1s","6.006","21"
"172","How does ray casting determine the color for each pixel on the screen?","A Search Tree Enumerates Possibili#es 
6.0002 LECTURE 2 
6 
Take 
Don’tTake 
LeS-ﬁrst, depth-ﬁrst 
enumera<on 
Val = 170 
Cal = 766 
Val = 120 
Cal = 766 
Val = 140 
Cal = 508 
Val = 90 
Cal = 145 
Val = 80 
Cal = 612 
Val = 30 
Cal = 258 
Val = 50 
Cal = 354 
Val = 0 
Cal = 0 
","63.18124008178711","4","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_6_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"172","How does ray casting determine the color for each pixel on the screen?","need to make each polyhedron. And some of these problems are NP-hard, and it's a lot of fun. Cool. I think that's the end of the slides. The last thing I wanted to show you is a problem, a puzzle/magic trick-- it comes from the puzzle world-- called the picture hanging problem. So imagine you have a picture. You want to hang it on a wall. So you invested in some nice rope, and you hang it on a nail. If the nail falls out, the picture falls, and you're sad. So you invest in two nails, like I have here, and maybe you hang your picture on both those nails. Now, if one of the nails falls out, you still have a crookedly hung picture. If the other nail falls out, OK, it's gone. I want to hang a picture on two nails such that, if I remove either nail, the picture falls. So, Jason, pick a nail, left or right. Left, we remove. Make sure this doesn't fall off-- and, boom, the picture falls. Same wrapping. You can check-- you can rewind the video, make sure I did the same wrapping. JASON KU: And take out the right. ERIK DEMAINE: Then take out the right one. Good choice. Then, also, the picture falls. This is a classic puzzle, but you can generalize it. So let me do it for three nails, which is all I have here. This nail is sagging a little bit. y, x-- y inverse, x inverse. I think that's right. So this is one way to hang a picture on three nails such that, if I remove any of the nails, the picture falls. Justin, 1, 2, or 3? 2. OK. Yeah, I want to get out of the way and make sure I don't go over the edge here. Yeah. It's a lot easier to make this one work. But you can see, boom, picture falls there. And of course, imagine infinite gravity. And the picture falls. Ta-da! You can generalize this to do essentially any-- what's called a monotone Boolean function-- on any set of nails. I mean, you can make any subset of the nails cause the picture to fall and any collection of subsets of nails to make it fall. Of course, if you remove more nails, it's still going to fall. That's the monotone sense. But otherwise, you can do an arbitrary pattern, which is fun. That's actually a result with Ron Rivest and a bunch of other people. I think I'm approximately on time. So that was a quick tour. And there are obviously various classes here you can take. 6.892, the hardness class, was just offered last semester, so it probably won't be for a while. But all of these classes are online. Watch the videos, feel free to ask me questions. And now we have Justin. I left you space here for your outline. You don't have to, but I'll put your name. JUSTIN SOLOMON: Thank you. JASON KU: So Justin is also a geometer. ERIK DEMAINE: Yeah, we've got a lot of geometry people in 006 this semester. JUSTIN SOLOMON: Thank you. OK. I can't help but share that, on our instructor chat, Erik was texting that he was going to be-- he was somehow nervous that the applied guy would have all of the cool stuff to show off, and now I feel totally boring. [LAUGHING] Right. Yeah. We have three different geometry instructors in this class. In this class, I think we have many different flavors of geometry that are kind of represented in this room here, from mechanical engineering, to theory plus lots of other cool stuff, to whatever it is that I do. I'm a professor, also, in CSAIL, and lead a group that studies slightly more applied geometry problems, in some sense, and in CSAIL, we kind of cross a lot of boundaries-- actually, closer to the math department than to the theory group and computer science, which I would argue is largely a historical artifact rather than anything interesting about computer science or math. Continuing in our whirlwind tour of interesting geometry classes here at MIT, I have some more fun things to add to the list. And we'll introduce some of the ideas in the next couple of slides here.","62.4005012512207","5","DPRSearchEngine","4nXw-f6NJ9s.en-j3PyPqV-e1s_7_mp4","4nXw-f6NJ9s.en-j3PyPqV-e1s","6.006","21"
"172","How does ray casting determine the color for each pixel on the screen?","Let's look at another chart, just in case you think I'm the only one who likes to play with graphics. This is a chart from Fox News. And they're arguing here. It's the shocking statistics that there are 108.6 million people on welfare, and 101.7 with a full-time job. And you can imagine the rhetoric that accompanies this chart. This is actually correct. It is true from the Census Bureau data. Sort of. But notice that I said you should read the labels on the axes. There is no label here. But you can bet that the y-intercept is not 0 on this. Because you can see how small 101.7 looks like. So it makes the difference look bigger than it is. Now, that's not the only funny thing about it. I said you should look at the labels on the x-axis. Well, they've labeled them. But what do these things mean? Well, I looked it up, and I'll tell you what they actually mean. People on welfare counts the number of people in a household in which at least one person is on welfare. So if there is say, two parents, one is working and one is collecting welfare and there are four kids, that counts as six people on welfare. People with a full-time job, is actually does not count households. So in the same family, you would have six on the bar on the left, and one on the bar on the right. Clearly giving a very different impression. And so again, pictures can be good. But if you don't dive deep into them, they really can fool you. Now, before I should leave this slide, I should say that it's not the case that you can't believe anything you read on Fox News. Because in fact, the Red Sox did beat the St. Louis Cardinals 4 to 2 that day. So the moral here is to ask whether the things being compared are actually comparable. Or you're really comparing apples and oranges,","61.90351867675781","6","DPRSearchEngine","K2SC-WPdT6k.en-qlPKC2UN_YU_7_mp4","K2SC-WPdT6k.en-qlPKC2UN_YU","6.0002","14"
"172","How does ray casting determine the color for each pixel on the screen?","I've introduced a bug in my simulation. I've replaced the 4 that we saw we needed by 2, now, an easy kind of mistake to make. And now, if we go to the code-- well, what do you think will happen if we go to the code and run it? We'll try it. We'll go down here to the code. We'll make that a 2. And what you'll see as it runs is that once again we're getting very nice confidence intervals, but totally bogus values of pi. So the statistics can tell us something about how reproducible our simulation is but not whether the simulation is an actually, accurate model of reality. So what do you need to do? You need to do something like a sanity check. So here you might look at a polygon and say, well, clearly that's a totally wrong number. Something is wrong with my code. OK, so just to wrap-up. What we've shown is a way to find pi. This is a generally useful technique. To estimate the area of any region r, you pick an enclosing region, call it e, such that it's easy to estimate the area of e, and r lies within it. Pick some random sets of points within e, let f be the fraction and fall within r, multiply e by f and you're done. So this for example, is a very common way to do integration. I promised you we'd talk about integration. So here's a sine of x. If I want to integrate the sine of x over some region, as done here, all I need to do is pick a bunch of random points, red and black in this case, and look at the ratio of one to the other. So showing how we can use randomness to again, compute something that is not inherently random. This is a trick people use over and over and over again when confronted with some situation where it's not easy to solve for things mathematically. You just do a simulation and if you do it right, you get a very good answer. All right, we will move on to a different topic on Wednesday.","61.80773162841797","7","DPRSearchEngine","rUxP7TM8-wo.en-qlPKC2UN_YU_10_mp4","rUxP7TM8-wo.en-qlPKC2UN_YU","6.0002","7"
"172","How does ray casting determine the color for each pixel on the screen?","that our way out of these problems, in graphics, is data structures and algorithms. It's completely unavoidable. For instance, obviously, we spent quite a bit of time in this course talking about AVL trees. In 837, we'll spend a big chunk of our tours talking about space partitioning trees. Here-- I actually forgot what kind of tree this is. I think it's a KD tree. Doesn't matter. In any event, one thing I could do is take all of the triangles of my bunny, and I could put the entire bunny in a giant cube with the property that the cube is outside the bunny. Let's say I cast a ray and the ray doesn't touch the cube. Can the ray touch the bunny? No, right? It zings right past it. So suddenly, I just saved myself a lot of computation time, right? I don't have to iterate over all the triangles inside of the body to see whether they hit the ray or not, because I already convinced myself, by this conservative test, that I didn't hit even the bounding box of the whole bunny. Well, that's sort of a nice order 1 speed-up. But depending on how big the bunny is relative to the size of my rendered image, that might not be a super useful efficiency test. But of course, what could I do? I could take the box containing the bunny, I could slice it in half, and now it's saying, does my ray hit the front or the back of the bunny? Or maybe both. That's where you've got to-- that's where things get gnarly. And so on. So now you have this nice recursive tree structure, where I keep taking the box containing my bunny and chopping it in half and placing-- in some sense, usually, the triangles-- maybe not the leaves of my tree, but [INAUDIBLE] that's probably good enough. You get a structure like what you see on the screen here. And why should you do that? Well, remember, it takes pn time to render my image of my bunny normally. Well, now, the picture is actually misleadingly suggestive. But you might think that, maybe, it takes roughly-- remember, n is the number of objects in my scene-- p log n time to render my bunny now, because I can kind of traverse the tree of objects in my scene. Of course, notice, I put a question mark here. And the devil's in the details here. In fact, I think computer graphics people often believe that their rendering algorithm takes p log n time. That's often not possible, although kind of an interesting question, which is, the heuristics they use for building these sorts of trees often do, on average, give them log n time. And so there's something about the data that's making this problem easier than it might seem. So we'll dig into that a little bit in the graphics class. Of course, you're not going to proof as many bounds as you might in a theory course. But we're certainly building on the intuition that we've seen in this class to build on practical data structures. And these data structures appear everywhere in computer graphics. For instance, directed acyclic graphs appear all over the place in computer graphics literature to describe 3D scenes. For example, this classroom is a stark reminder of why we need DAGs and computer graphics, because we have all of these empty seats here, and they're all copies of one another. So would it make sense for me to store however many, like, 100 3D molds of the same chair? Probably not. So instead, what do I do? I store one instance of a chair, and then some instructions on how to tile it into my entire scene. One way that I can do that is to think of there being a node in a graph which knows how to draw one chair. And now, I can have a bunch of different nodes in my scene for all of the instances of the chair and then store a different transformation for each one. So if you think about the graph structure here, each of those ones is going to point into the same 3D model of the chair for rendering. And that makes a directed acyclic graph structure called a scene graph, which we'll spend quite a bit of time talking about in 837, how to traverse and construct all that good stuff. And there are lots of different models of computation in that universe, as well. Your graphics card is a very specific kind of parallel processor that's kind of like Lucille Ball on the conveyor belt, hammering at the same object over and over again. But if you ask it to do anything other than the one thing it knows how to do to a bunch of data at a time, then all of your computation grinds to a halt. This is called Single Instruction Multiple Data parallelism, SIMD. Numerical algorithms matter a lot for things like fluid simulation. And approximation algorithms are quite critical, too. In computer graphics, the complexity is kind of interesting, because of course, your eyeball is sensitive to about 29.97 frames per second worth of material. You can choose that time to do really well-rendering one object, but then you take out of the time rendering something else. There's kind of an interesting conservation law that you have to balance when you solve these kinds of problems, which is an interesting balance, now, between complexity and runtime of your algorithm and perception. What things can you get away with when you draw a scene? And maybe I can do tons of extra computation to get that extra shadow, but it's just not worth it. I'll quickly sketch out another completely different application of the material that we've covered in 6.006 from my own research. Again, just like Erik-- I guess, in a funny way, both of our groups, I think, are kind of broad in terms of subject material, rather than-- some of our colleagues have really laser focus on one topic or another. Another Research area that I have sort of backed into is the area of political redistricting. This is relevant in the United States. Recently, I've been reading this great proposal about other countries, which is really interesting, how they do this stuff. In the US, when we vote for people in Congress-- by the way, not necessarily for presidents. This is a common misconception. But certainly for Congress, your state is divided into little regions, each of which elects one member of the House. And there's sort of a subtle problem if you're not used to thinking about it, or one that's staring you in the face and screaming, depending on how often you read the news and politics. There is an issue called gerrymandering, where your legislature draws the lines for what area on the map elects a member of Congress. And depending on how you draw the lines, you can engineer different results for who's likely to get elected. So for instance, maybe there's some minority. I can cluster them all together into one voting district. Then they will only get the opportunity to elect one person. But maybe, if I divide the space where they live into two, I managed to engineer two districts with a high probability of electing somebody with their political interests in mind. It turns out that political redistricting, in a broad sense, is a great problem, computationally. Even if you're a totally heartless theorist, there are some really fun problems here. So for example, the state of Iowa-- we all pick on Iowa because it has a unique law, which is that districts have to be built out of counties, which are much larger than the typical census unit, so it computationally is easier. But even in Iowa, which is a giant grid-- with the exception of one shift in the middle, which is fascinating to me-- I know [INAUDIBLE], fun fact. Literally, people were making the map of Iowa, and they worked from the bottom up and the top down, and it meets in the middle and their grids were shifted, and now we're stuck with that. And it has an interesting effect on the topology of the graph, because it looks like squares, but then there's triangles in the middle. But in any event, even though there's only 99 counties in four districts, there's approximately quintillions of possible ways you can divide that state into four contiguous districts that satisfy the rules as they were-- at least, if you read the code literally in the law. It seems like computers are useful, but unfortunately, it's a little subtle how. For instance, there's no single ""best"" districting plan out there. I can't think of a single state with a law that gives you an objective function, similar to whatever cute characters that we've had in 6.006. They often have very clear objectives in life, but unfortunately, redistricting, that's very rarely the case. You have to balance contiguity, population balance, compactness, all of these different things. Reality check number two is that, even if somebody did give you an objective function, for just about any interesting objective function, it's very obvious that generating the best possible districting plan is NP-hard. And by the way, it doesn't even matter, because the law doesn't say that computers have to draw the best districts. Even if P equals NP really could extract the best possible districting plan using an algorithm, it doesn't mean you have to use it, at least the way the law's written now. Interestingly, this is not true in certain parts of Mexico, where they actually make you compare your districting plan against a computer-generated one, which is philosophically really interesting, although in practice, it doesn't work terribly well. Our researchers studied analysis of districting plans instead. So instead of running a piece of software that takes in your state, draws your districts, and then you're done-- instead, we ask statistical questions about, I propose a districting plan, what does it look like relative to the space of the possibilities? So that, of course, begs the question, what are the possibilities? So these are the connected graph partitions. Meaning, you have a graph, and you take the vertices and you cluster them together in a way where they're connected to one another. The one thing that we all agree on-- actually, philosophically, it's questionable why-- is that you should be able to start at any point in your district and walk to any other one without leaving. These days, with the internet, it's not clear that that's actually the best criterion. But that's a law that, I think, is never going to get passed in the near future. Anyway, I think I'm out of time, so I don't think I'll walk you guys through the theory here. Maybe I'll leave it in the slides. There's a sort of very simple proof that can show that, at least the very simplest thing you might think of for analyzing your districting plan, which is to say, you propose a plan, and now, I want your plan to be at least as good, under some axis, as it's a randomly drawn one from the space of all possible connected partitions-- all of the possible ways I could draw the lines. Well, then, it might be useful to have a piece of software that could just randomly draw such a thing. So in other words, to draw something where the probability of any one partition is 1 over the number of partitions. This seems innocent. In fact, there's a number of papers that claim to do things like this. But it turns out that it's computationally difficult, assuming that you believe that P doesn't equal NP. So I'll maybe leave some suggestive pictures in the slide that we can-- if you guys text me, or if we have a professor-student chat, I'm happy to sketch it out to you then. There's a very nice, easy proof that reduces this to Hamiltonian cycle, and shows you that maybe you shouldn't trust these tools, as much as they're argued about, literally, in the Supreme Court a couple of months ago. By the way, it was pretty fun. Our expert report was referenced in the defense of the case last summer. And when you read the discussion, you can see the judges trying to talk their way around complexity. And it's an interesting, if somewhat dry, read. In any event, that's just the starting point for our research, which says that, of course, these sampling problems are really hard. The questions is, what can you do?","61.51634216308594","8","DPRSearchEngine","4nXw-f6NJ9s.en-j3PyPqV-e1s_12_mp4","4nXw-f6NJ9s.en-j3PyPqV-e1s","6.006","21"
"172","How does ray casting determine the color for each pixel on the screen?","100,000, and a million. And what do we see as we look at this? Well, right away we can see that fair roulette is usually a much better bet than either of the other two. That even with only 1,000 spins the return is negative. And as we get more and more as I got to a million, it starts to look much more like closer to 0. And these, we have reason to believe at least, are much closer to true expectation saying that, while you break even in fair roulette, you'll lose 2.7% in Europe and over 5% in Las Vegas, or soon in Massachusetts. All right, we're sampling, right? That's why the results will change, and if I ran a different simulation with a different seed I'd get different numbers. Whenever you're sampling, you can't be guaranteed to get perfect accuracy. It's always possible you get a weird sample. That's not to say that you won't get exactly the right answer. I might have spun the wheel twice and happened to get the exact right answer of the return. Actually not twice, because the math doesn't work out, but 35 times and gotten exactly the right answer. But that's not the point. We need to be able to differentiate between what happens to be true and what we actually know, in a rigorous sense, is true. Or maybe don't know it, but have real good reason to believe it's true. So it's not just a question of faith. And that gets us to what's in some sense the fundamental question of all computational statistics, is how many samples do we need to look at before we can have real, justifiable confidence in our answer? As we've just seen-- not just, a few minutes ago-- with the coins, our intuition tells us that it depends upon the variability in the underlying possibilities. So let's look at that more carefully. We have to look at the variation in the data. So let's look at first something called variance.","61.05803298950195","9","DPRSearchEngine","OgO1gpXSUzU.en-j3PyPqV-e1s_11_mp4","OgO1gpXSUzU.en-j3PyPqV-e1s","6.0002","6"
"172","How does ray casting determine the color for each pixel on the screen?","Let's look at an example. So I've got a bunch of blue points here, and I actually wrote the code to do this. I'm not going to show you the code. And I chose four centroids at random, colored stars. A green one, a fuchsia-colored one, a red one, and a blue one. So maybe they're not the ones you would have chosen, but there they are. And I then, having chosen them, assign each point to one of those centroids, whichever one it's closest to. All right? Step one. And then I recompute the centroid. So let's go back. So we're here, and these are the initial centroids. Now, when I find the new centroids, if we look at where the red one is, the red one is this point, this point, and this point. Clearly, the new centroid is going to move, right? It's going to move somewhere along in here or something like that, right? So we'll get those new centroids. There it is. And now we'll re-assign points. And what we'll see is this point is now closer to the red star than it is to the fuchsia star, because we've moved the red star. Whoops. That one. Said the wrong thing. They were red to start with. This one is now suddenly closer to the purple, so-- and to the red. It will get recolored. We compute the new centroids. We're going to move something again. We continue. Points will move around. This time we move two points. Here we go again. Notice, again, the centroids don't correspond to actual examples. This one is close, but it's not really one of them. Move two more. Recompute centroids, and we're done. So here we've converged, and I think it was five iterations, and nothing will move again. All right? Does that make sense to everybody? So it's pretty simple. What are the downsides? Well, choosing k foolishly can lead to strange results. So if I chose k equal to 3, looking at this particular arrangement of points, it's not obvious what ""the right answer"" is, right? Maybe it's making all of this one cluster. I don't know. But there are weird k's and if you choose a k that is nonsensical with respect to your data, then your clustering will be nonsensical. So that's one problem we have think about. How do we choose k? Another problem, and this is one somebody raised last time, is that the results can depend upon the initial centroids. Unlike hierarchical clustering, k-means is non-deterministic. Depending upon what random examples we choose, we can get a different number of iterations. If we choose them poorly, it could take longer to converge. More worrisome, you get a different answer. You're running this greedy algorithm, and you might actually get to a different place, depending upon which centroids you chose. So these are the two issues we have to think about dealing with. So let's first think about choosing k. What often happens is people choose k using a priori knowledge about the application. If I'm in medicine, I actually know that there are only five different kinds of bacteria in the world. That's true. I mean, there are subspecies, but five large categories. And if I had a bunch of bacterium I wanted to cluster, may just set k equal to 5. Maybe I believe there are only two kinds of people in the world, those who are at MIT and those who are not. And so I'll choose k equal to 2. Often, we know enough about the application, we can choose k. As we'll see later, often we can think we do, and we don't. A better approach is to search for a good k. So you can try different values of k and evaluate the quality of the result. Assume you have some metric, as to say yeah, I like this clustering, I don't like this clustering. And we'll talk about do that in detail. Or you can run hierarchical clustering on a subset of data. I've got a million points. All right, what I'm going to do is take a subset of 1,000 of them or 10,000. Run hierarchical clustering. From that, get a sense of the structure underlying the data. Decide k should be 6, and then run k-means with k equals 6. People often do this. They run hierarchical clustering on a small subset of the data and then choose k. And we'll look-- but one we're going to look at is that one. What about unlucky centroids? So here I got the same points we started with. Different initial centroids. I've got a fuchsia one, a black one, and then I've got red and blue down here, which I happened to accidentally choose close to one another. Well, if I start with these centroids, certainly you would expect things to take longer to converge. But in fact, what happens is this-- I get this assignment of blue, this assignment of red, and I'm done. It converges on this, which probably is not what we wanted out of this. Maybe it is, but the fact that I converged on some very different place shows that it's a real weakness of the algorithm, that it's sensitive to the randomly-chosen initial conditions. Well, couple of things you can do about that. You could be clever and try and select good initial centroids. So people often will do that, and what they'll do is try and just make sure that they're distributed over the space. So they would look at some picture like this and say, well, let's just put my centroids at the corners or something like that so that they're far apart. Another approach is to try multiple sets of randomly-chosen centroids, and then just select the best results. And that's what this little algorithm on the screen does. So I'll say best is equal to k-means of the points themselves, or something, then for t in range number of trials, I'll say C equals k-means of points, and I'll just keep track and choose the one with the least dissimilarity. The thing I'm trying to minimize. OK? The first one is got all the points in one cluster. So it's very dissimilar. And then I'll just keep generating for different k's and I'll choose the k that seems to be the best, that does the best job of minimizing my objective function. And this is a very common solution, by the way, for any randomized greedy algorithm. And there are a lot of randomized greedy algorithms that you just choose multiple initial conditions, try them all out and pick the best.","60.68780517578125","10","DPRSearchEngine","esmzYhuFnds.en-qlPKC2UN_YU_6_mp4","esmzYhuFnds.en-qlPKC2UN_YU","6.0002","12"
"173","What is the role of ""w"" in the running time of data structures like van Emde Boas and fusion trees?"," 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Relationships among models 
Informal Defn: Two models of computation are polynomially related 
if each can simulate the other with a polynomial overhead: 
So ! "" time → !$("") time on the other model, for some '. 
All reasonable deterministic models are polynomially related. 
• 1-tape TMs 
• multi-tape TMs 
• multi-dimensional TMs 
• random access machine (RAM) 
• cellular automata 
9 
","74.16704559326172","1","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_9_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"173","What is the role of ""w"" in the running time of data structures like van Emde Boas and fusion trees?","That was a brief tour of computational geometry. I work mostly in four different areas of algorithms-- geometry, data structures, graph algorithms, and what I call recreational algorithms. I think I made up that term. And let's go into data structures, which is represented by this class, 6.851. All of the classes I mentioned have online video lectures, especially for those watching at home on OpenCourseWare. Most of these classes are on OpenCourseWare, and if not, they're on my webpage. 6.851, Advanced Data Structures, is an extension of the sorts of data structures you've seen here, in 006 and the ones you will see in 6.046. I thought I would give you a flavor of one such result, which is a problem we've seen in this class done better. Suppose you want to store a dynamic ordered set. This is the set interface. Dynamic in the sense that I have insert and delete, and ordered in the sense that I want to support find-next and find-previous. Exactly which subset of the set interface you choose influences what data structure you've seen. We've seen, for dynamic sets, you want to use hashing. If you don't care about find-next, if you just care about find, then hashing is great-- constant expected. You can prove stronger things about hashing. And we do in that class. But if you want dynamic and ordered, you cannot do constant time per operation. You can prove that, which is cool. What data structure have we seen that solves this problem pretty well? Set AVL trees, which solve everything in log n. So log n is one competitor. Yeah. I'm interested in the word RAM model, which is the only model we've seen in this class. This happens to work in a stronger model. And we can do better than log n in the following-- it will take me a while before I get better, but here's, at least, a different bound we can get-- log w. This is via a structure called van Emde Boas, who is a person. AVL is two people. van Emde Boas, I've actually met. Log w-- remember, w is our word size. So this is a bit of a weird running time. It's great if w is log n, then this is log log n. And we know w is at least log n, but it could be bigger. We don't really have a sense of how big w could get. Maybe it's even n. Maybe it's big-- and then these are the same. Maybe it's bigger than n, and then this is maybe worse. But for most ws, this is actually pretty good-- and indeed, optimal. But it's not strictly better, in any sense, yet. On the other hand, there's another data structure which runs in log n divided by log w. This is called fusion trees. This was invented around the time that cold fusion was in the news, and so they wanted data structures to represent. We can achieve this bound or we can achieve this bound. And this bound is good is if w is large. This band as good if w is small. You can always take the min of the two, whatever is better. And in particular, the min of those two things is at most-- I think it's square root log n over log log n. If you want to bound just in terms of n, then the crossover point between these two is this place. And so you're always, at most, this, which is quite a bit better than the log n of AVL. We've got a square root and we've got a slight thing in the denominator. Pretty tiny. But the big thing is the square root. And that's kind of cool. And it turns out, that's pretty much optimal. In terms of an n bound, this is optimal. The min of these two, in general, is roughly optimal up to log log terms. For fun, I threw up the actual formula for the right-bound, which is tight up to constant factors of matching upper and lower bounds, which we talk about. It's min of three things-- four things, including log of w over a divided by log of log w over a log of log n over a. That's the last term that I just read. This was messy. Surprisingly, that is the right answer for this very particular problem-- a very natural problem. AUDIENCE: What is a? ERIK DEMAINE: A is the log of the space you're using. So it's the address size. Good question. If you throw it-- so it depends. If you have a polynomial space data structure, then basically, these are optimal. And this is generalizing to beyond that. Maybe you have a little bit more than polynomial space. Cool. So that's data structures. I'm going to jump ahead to graph algorithms, which, if you want to take this class, I recommend a time travel device.","73.72332763671875","2","DPRSearchEngine","4nXw-f6NJ9s.en-j3PyPqV-e1s_4_mp4","4nXw-f6NJ9s.en-j3PyPqV-e1s","6.006","21"
"173","What is the role of ""w"" in the running time of data structures like van Emde Boas and fusion trees?","Header for Decision Tree Implementa#on 
6.0002 LECTURE 2 
9 
def maxVal(toConsider, avail): 
    """"""Assumes toConsider a list of items,  
               avail a weight 
       Returns a tuple of the total value of a  
           solution to 0/1 knapsack problem and  
           the items of that solution""""” 
toConsider. Those items that nodes higher up in the tree 
(corresponding to earlier calls in the recursive call stack) 
have not yet considered 
 
avail. The amount of space still available  
","73.18573760986328","3","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_9_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"173","What is the role of ""w"" in the running time of data structures like van Emde Boas and fusion trees?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","72.7749252319336","4","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"173","What is the role of ""w"" in the running time of data structures like van Emde Boas and fusion trees?"," 
 
 
   
 
 
 
   
   
      
 
 
 
 
 
 
  
 
Stochastic Processes  
An ongoing process where the next state might depend on 
both the previous states and some random element 
def rollDie(): 
"""""" returns an int between 1 and 6"""""" 
def rollDie(): 
"""""" returns a randomly chosen int 
between 1 and 6"""""" 
6.0002 LECTURE 4 
8
","72.72550201416016","5","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_8_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"173","What is the role of ""w"" in the running time of data structures like van Emde Boas and fusion trees?"," 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
18.404/6.840 Lecture 4 
Last time: 
- Finite automata → regular expressions 
- Proving languages aren’t regular 
- Context free grammars 
Today: (Sipser §2.2) 
- Context free grammars (CFGs) – definition 
- Context free languages (CFLs) 
- Pushdown automata (PDA) 
- Converting CFGs to PDAs 
1 
","72.5044937133789","6","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_1_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"173","What is the role of ""w"" in the running time of data structures like van Emde Boas and fusion trees?"," 
 
  
 
 
 
 
 
 
  
 
 
 
 
  
  
  
  
18.404/6.840 Lecture 24 
Last time: 
- Probabilistic computation
- The class BPP
- Branching programs
- Arithmetization
- Started showing !""
ROBP ∈ BPP
Today: (Sipser §10.2)
- Finish !""
ROBP ∈ BPP
1 
","71.87071228027344","7","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_1_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"173","What is the role of ""w"" in the running time of data structures like van Emde Boas and fusion trees?","So what we're going to do, because we're in place, basically we have to have an array storing our end items. That's sort of the definition of in-place, just using n slots of memory exactly the size of the number of items in our structure. But we're obviously not going to use a regular unsorted array or a regular sorted array. We're going to use array just as sort of the underlying technology for how things are stored. But we'd really like logarithmic performance, which should make you think tree. Only way to get a log is the binary tree, more or less. So somehow, we want to embed a tree into an array. Let me grab an example.","71.79727172851562","8","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_6_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"173","What is the role of ""w"" in the running time of data structures like van Emde Boas and fusion trees?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
18.404/6.840 Lecture 5 
Last time: 
- Context free grammars (CFGs) 
- Context free languages (CFLs) 
- Pushdown automata (PDA) 
- Converting CFGs to PDAs 
Today: (Sipser §2.3, §3.1) 
- Proving languages not Context Free 
- Turing machines 
- T-recognizable and T-decidable languages 
1 
","71.59341430664062","9","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_1_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"173","What is the role of ""w"" in the running time of data structures like van Emde Boas and fusion trees?","single source shortest paths in linear time. Last time we discussed another linear time algorithm, DAG relaxation. And today we're going to be talking about Bellman-Ford, which isn't limited to asymptotic graphs. In particular, there could be negative weight cycles in our graph. If it has cycles, if it has negative weights, the worry is that we could have negative weight cycles, in which case there-- if a negative weight cycle is reachable from our source, then the vertices in that cycle and anything reachable from that cycle will potentially","71.4918441772461","10","DPRSearchEngine","f9cVS_URPc0.en-j3PyPqV-e1s_2_mp4","f9cVS_URPc0.en-j3PyPqV-e1s","6.006","12"
"175","What is the goal of the picture hanging problem as described?","need to make each polyhedron. And some of these problems are NP-hard, and it's a lot of fun. Cool. I think that's the end of the slides. The last thing I wanted to show you is a problem, a puzzle/magic trick-- it comes from the puzzle world-- called the picture hanging problem. So imagine you have a picture. You want to hang it on a wall. So you invested in some nice rope, and you hang it on a nail. If the nail falls out, the picture falls, and you're sad. So you invest in two nails, like I have here, and maybe you hang your picture on both those nails. Now, if one of the nails falls out, you still have a crookedly hung picture. If the other nail falls out, OK, it's gone. I want to hang a picture on two nails such that, if I remove either nail, the picture falls. So, Jason, pick a nail, left or right. Left, we remove. Make sure this doesn't fall off-- and, boom, the picture falls. Same wrapping. You can check-- you can rewind the video, make sure I did the same wrapping. JASON KU: And take out the right. ERIK DEMAINE: Then take out the right one. Good choice. Then, also, the picture falls. This is a classic puzzle, but you can generalize it. So let me do it for three nails, which is all I have here. This nail is sagging a little bit. y, x-- y inverse, x inverse. I think that's right. So this is one way to hang a picture on three nails such that, if I remove any of the nails, the picture falls. Justin, 1, 2, or 3? 2. OK. Yeah, I want to get out of the way and make sure I don't go over the edge here. Yeah. It's a lot easier to make this one work. But you can see, boom, picture falls there. And of course, imagine infinite gravity. And the picture falls. Ta-da! You can generalize this to do essentially any-- what's called a monotone Boolean function-- on any set of nails. I mean, you can make any subset of the nails cause the picture to fall and any collection of subsets of nails to make it fall. Of course, if you remove more nails, it's still going to fall. That's the monotone sense. But otherwise, you can do an arbitrary pattern, which is fun. That's actually a result with Ron Rivest and a bunch of other people. I think I'm approximately on time. So that was a quick tour. And there are obviously various classes here you can take. 6.892, the hardness class, was just offered last semester, so it probably won't be for a while. But all of these classes are online. Watch the videos, feel free to ask me questions. And now we have Justin. I left you space here for your outline. You don't have to, but I'll put your name. JUSTIN SOLOMON: Thank you. JASON KU: So Justin is also a geometer. ERIK DEMAINE: Yeah, we've got a lot of geometry people in 006 this semester. JUSTIN SOLOMON: Thank you. OK. I can't help but share that, on our instructor chat, Erik was texting that he was going to be-- he was somehow nervous that the applied guy would have all of the cool stuff to show off, and now I feel totally boring. [LAUGHING] Right. Yeah. We have three different geometry instructors in this class. In this class, I think we have many different flavors of geometry that are kind of represented in this room here, from mechanical engineering, to theory plus lots of other cool stuff, to whatever it is that I do. I'm a professor, also, in CSAIL, and lead a group that studies slightly more applied geometry problems, in some sense, and in CSAIL, we kind of cross a lot of boundaries-- actually, closer to the math department than to the theory group and computer science, which I would argue is largely a historical artifact rather than anything interesting about computer science or math. Continuing in our whirlwind tour of interesting geometry classes here at MIT, I have some more fun things to add to the list. And we'll introduce some of the ideas in the next couple of slides here.","61.16089630126953","1","DPRSearchEngine","4nXw-f6NJ9s.en-j3PyPqV-e1s_7_mp4","4nXw-f6NJ9s.en-j3PyPqV-e1s","6.006","21"
"175","What is the goal of the picture hanging problem as described?","§ Given remaining weight, maximize value by choosing 
among remaining items 
§ Set of previously chosen items, or even value of that 
set, doesn’t mafer! 
What Problem is Solved at Each Node? 
6.0002 LECTURE 2 
26 
","60.67793273925781","2","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_26_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"175","What is the goal of the picture hanging problem as described?","Problem Set 2 
#5)  Show ! is T-recognizable  iff  there is a decidable "" where 
! =
$ ∃&
$, & ∈"" }
$, & ∈Σ∗
〈$, &〉is an encoding of the pair of strings $ and & into a single string.  
Think of "" as a collection of pairs of strings.
$-axis
&-axis
($, &)
""
!
! is a “projection” of ""
$
10
","60.62715530395508","3","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_10_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"175","What is the goal of the picture hanging problem as described?","  
 
 
 
 
 
Lecture 4: Stochastic 
Thinking and Random 
Walks 
ϲ͘ϬϬϬϮ [ĞĐƚƵƌĞ ϰ
1
","60.2658576965332","4","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_1_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"175","What is the goal of the picture hanging problem as described?","tell if the machine is looping or if it's really just taking a very long time? You can't. That's what we're going to prove not in today's lecture, but going to prove that on Thursday. You just can't tell. So if that's in reference to problem 5, you're going to have to find some other way of doing-- solving that problem without knowing whether the machine is actually ever going to halt.","60.149864196777344","5","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_3_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"175","What is the goal of the picture hanging problem as described?","So the file is in the zip file I uploaded. It looks more or less like this. Right? So it's very straightforward. The outcomes are binary. 1 is a positive outcome. Strangely enough in the medical jargon, a death is a positive outcome. I guess maybe if you're responsible for the medical bills, it's positive. If you're the patient, it's hard to think of it as a good thing. Nevertheless, that's the way that they talk. And the others are all there, right?","60.14490509033203","6","DPRSearchEngine","esmzYhuFnds.en-qlPKC2UN_YU_8_mp4","esmzYhuFnds.en-qlPKC2UN_YU","6.0002","12"
"175","What is the goal of the picture hanging problem as described?","TM – example revisited 
TM ! recognizing  "" = a$b$c$
% ≥0
! = “On input (
1.  Check if ( ∈a∗b∗c∗,  reject if not.
2.  Count the number of a’s, b’s, and c’s in (.
3.  Accept if all counts are equal; reject if not.”
High-level description is ok.  
You do not need to manage tapes, states, etc… 
9
","60.01715850830078","7","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_9_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"175","What is the goal of the picture hanging problem as described?","   
 
 
 
 
How  Likely Is it Just Bad Luck?  
A variant of cherry picking called  
multiple hypothesis testing 
6.0002  LECTURE 15 
14 
","59.77633285522461","8","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_13_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"175","What is the goal of the picture hanging problem as described?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Quick review of today 
Finished #""#$ ∈ IP and coNP ⊆ IP 
Additional subjects: 
18.405/6.841 Advanced complexity F2021 
18.425/6.875 Cryptography F2021 
6.842 Randomness and Computation ? 
Good luck on the final! 
Best wishes for the holidays and the New Year! 
10 
","59.66480255126953","9","DPRSearchEngine","7ac944716e076209c3964e073929f42e_MIT18_404f20_lec26_10_pdf","7ac944716e076209c3964e073929f42e_MIT18_404f20_lec26","18.404J","26"
"175","What is the goal of the picture hanging problem as described?","!
""

 
	

4
!$22
!$!!!!
!!!!
$!!
!!!!(4(
$!0$2!
k ≈35,000N / m

k ≈1N / m
0524$!!$!!
Images of suspension spring and slinky © sources unknown. All rights reserved. This content is excluded
from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.
","59.661376953125","10","DPRSearchEngine","20a7e184a1a2b3c34a5055dc1f1dc066_MIT6_0002F16_lec9_4_pdf","20a7e184a1a2b3c34a5055dc1f1dc066_MIT6_0002F16_lec9","6.0002","9"
"179","What does it mean for relaxation to be safe?","!		 	
def getTempData(): 
    inFile = open('temperatures.csv') 
    data = [] 
    for l in inFile: 
        data.append(tempDatum(l)) 
    return data 
	

?
","62.083892822265625","1","DPRSearchEngine","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10_41_pdf","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10","6.0002","10"
"179","What does it mean for relaxation to be safe?","This is plotting pulse rate against how much exercise you do or how frequently you exercise. And what you can see here is there's definitely a downward trend suggesting that the more you exercise, the lower your average resting pulse. That's probably worth knowing. And these error bars give us the 95% confidence intervals for different subpopulations. And what we can see here is that some of them overlap. So, yes, once a fortnight-- two weeks for those of you who don't speak British-- it does get a little bit smaller than rarely or never. But the confidence interval is very big. And so maybe we really shouldn't feel very comfortable that it would actually help. The thing we can say is that if the confidence intervals don't overlap, we can conclude that the means are actually statistically significantly different, in this case at the 95% level. So here we see that the more than weekly does not overlap with the rarely or never. And from that, we can conclude that this is actually, statistically true-- that if you exercise more than weekly, your pulse is likely to be lower than if you don't. If confidence intervals do overlap, you cannot conclude that there is no statistically significant difference. There might be, and you can use other tests to find out whether there are. When they don't overlap, it's a good thing. We can conclude something strong. When they do overlap, we need to investigate further. All right, let's look at the error bars for our temperatures. And again, we can plot those using something called","61.770198822021484","2","DPRSearchEngine","soZv_KKax3E.en-qlPKC2UN_YU_6_mp4","soZv_KKax3E.en-qlPKC2UN_YU","6.0002","8"
"179","What does it mean for relaxation to be safe?","you might run a fever. So here is someone who had the flu. And this is plotting their fever from the beginning to its peak. And it does appear, if we were to fit a curve to this, it would look pretty much like that. On the other hand, if we assume that somebody's temperature could range between 0 and 200, we can see that, in fact, your temperature doesn't move at all when you get the flu. So the moral is pretty clear, I think. Even though on Monday I talked about being suspicious when people start the y-axis too far from 0, you should truncate it to eliminate totally preposterous values. No living person has a temperature of 0 degrees Fahrenheit. So again, don't truncate it just to make something look like it isn't, but don't expand it to deceive either. Let's return to global warming.","61.28557586669922","3","DPRSearchEngine","iOZVbILaIZc.en-qlPKC2UN_YU_3_mp4","iOZVbILaIZc.en-qlPKC2UN_YU","6.0002","15"
"179","What does it mean for relaxation to be safe?","2


+
 An objective function that is to be maximized or 
minimized, e.g.,
# Minimize time spent traveling from New York to Boston
A set of constraints (possibly empty) that must be 
honored, e.g.,
# Cannot spend more than $100
# Must be in Boston before 5:00PM
	

;
Images © sources unknown. All rights reserved. This content is excluded from our Creative
Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use.
","61.20036697387695","4","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_9_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"179","What does it mean for relaxation to be safe?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Quick review of today 
Finished #""#$ ∈ IP and coNP ⊆ IP 
Additional subjects: 
18.405/6.841 Advanced complexity F2021 
18.425/6.875 Cryptography F2021 
6.842 Randomness and Computation ? 
Good luck on the final! 
Best wishes for the holidays and the New Year! 
10 
","60.12861251831055","5","DPRSearchEngine","7ac944716e076209c3964e073929f42e_MIT18_404f20_lec26_10_pdf","7ac944716e076209c3964e073929f42e_MIT18_404f20_lec26","18.404J","26"
"179","What does it mean for relaxation to be safe?","!
""

 
	

4
!$22
!$!!!!
!!!!
$!!
!!!!(4(
$!0$2!
k ≈35,000N / m

k ≈1N / m
0524$!!$!!
Images of suspension spring and slinky © sources unknown. All rights reserved. This content is excluded
from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.
","59.73137664794922","6","DPRSearchEngine","20a7e184a1a2b3c34a5055dc1f1dc066_MIT6_0002F16_lec9_4_pdf","20a7e184a1a2b3c34a5055dc1f1dc066_MIT6_0002F16_lec9","6.0002","9"
"179","What does it mean for relaxation to be safe?","		&$% 
	









6.0002 LECTURE 11 
Slide 3 
Images of rattlesnake, dart frog, boa constrictor © sources unknown. All rights reserved. This content is excluded
from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.
","59.59606170654297","7","DPRSearchEngine","4c4fc506075a8502ccc5191583d22882_MIT6_0002F16_lec11_36_pdf","4c4fc506075a8502ccc5191583d22882_MIT6_0002F16_lec11","6.0002","11"
"179","What does it mean for relaxation to be safe?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
Midterm exam 
90 minutes length + 20 minutes for printing/scanning/uploading. 
Open book, postings, piazza, notes, and lecture videos, from this year. 
Covers through Recursion Theorem presented today. 
Will not include section on mathematical logic. 
Not permitted: Communication with anyone except course staff, other materials, internet searching. 
Not permitted: Providing information about the exam to anyone who hasn’t completed it. 
Please respect our honor system. 
2 
","59.42955780029297","8","DPRSearchEngine","779043ea724131d008eae652d703938f_MIT18_404f20_lec11_2_pdf","779043ea724131d008eae652d703938f_MIT18_404f20_lec11","18.404J","11"
"179","What does it mean for relaxation to be safe?"," 6574
 80$!.0
$!!!$9
#$%&	 '
	

5
	

	

	
	53;
	
		
	
	
	

!2!4$!(
!!<
Images of suspension spring © source unknown. All rights reserved.
This content is excluded from our Creative Commons license. For
more information, see https://ocw.mit.edu/help/faq-fair-use/.
","59.13971710205078","9","DPRSearchEngine","20a7e184a1a2b3c34a5055dc1f1dc066_MIT6_0002F16_lec9_5_pdf","20a7e184a1a2b3c34a5055dc1f1dc066_MIT6_0002F16_lec9","6.0002","9"
"179","What does it mean for relaxation to be safe?"," 
 
 
 
 
 
 
  
 
  
  
 
 
 
 
 
 
 
 
 
 
Visualizing the Trend  
§Simulate walks of multiple lengths for each kind of
drunk 
§Plot distance at end of each length walk for each kind
of drunk 
6.0002  LECTURE 5 
28 
","58.94911575317383","10","DPRSearchEngine","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_28_pdf","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5","6.0002","5"
"180","What is the significance of having a negative weight edge in an undirected graph?","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","74.390869140625","1","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"180","What is the significance of having a negative weight edge in an undirected graph?"," 
 
 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) 
General Unweighted 
BFS 
|V | + |E|
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Non-negative Dijkstra 
Bellman-Ford 
|V | log |V | + |E|
General Any 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 14: Johnson’s Algorithm 
Lecture 14: Johnson’s Algorithm 
Previously 
|V | · |E| 
All-Pairs Shortest Paths (APSP) 
• Input: directed graph G = (V, E) with weights w : E → Z 
• Output: δ(u, v) for all u, v ∈ V , or abort if G contains negative-weight cycle 
• Useful when understanding whole network, e.g., transportation, circuit layout, supply chains... 
• Just doing a SSSP algorithm |V | times is actually pretty good, since output has size O(|V |2) 
– |V | · O(|V | + |E|) with BFS if weights positive and bounded by O(|V | + |E|) 
– |V | · O(|V | + |E|) with DAG Relaxation if acyclic 
– |V | · O(|V | log |V | + |E|) with Dijkstra if weights non-negative or graph undirected 
– |V | · O(|V | · |E|) with Bellman-Ford (general) 
• Today: Solve APSP in any weighted graph in |V | · O(|V | log |V | + |E|) time 
","73.49217987060547","2","DPRSearchEngine","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14_1_pdf","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14","6.006","14"
"180","What is the significance of having a negative weight edge in an undirected graph?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 11: Weighted Shortest Paths 
Lecture 11: Weighted Shortest Paths 
Review 
• Single-Source Shortest Paths with BFS in O(|V | + |E|) time (return distance per vertex) 
• Single-Source Reachability with BFS or DFS in O(|E|) time (return only reachable vertices) 
• Connected components with Full-BFS or Full-DFS in O(|V | + |E|) time 
• Topological Sort of a DAG with Full-DFS in O(|V | + |E|) time 
• Previously: distance = number of edges in path Today: generalize meaning of distance 
Weighted Graphs 
• A weighted graph is a graph G = (V, E) together with a weight function w : E → Z 
• i.e., assigns each edge e = (u, v) ∈ E an integer weight: w(e) = w(u, v) 
• Many applications for edge weights in a graph: 
– distances in road network 
– latency in network connections 
– strength of a relationship in a social network 
• Two common ways to represent weights computationally: 
– Inside graph representation: store edge weight with each vertex in adjacency lists 
– Store separate Set data structure mapping each edge to its weight 
• We assume a representation that allows querying the weight of an edge in O(1) time 
Examples 
G1 
G2 
a 
e 
b 
f 
c 
g 
d 
h 
6 
8 
−2 
5 
9 
−5 
7 
3 
2 
−1 
−4 
1 
4 
a 
e 
b 
f 
c 
g 
d 
h 
6 
8 
−2 
5 
9 
−5 
7 
3 
2 
−1 
−4 
1 
4 
","70.40574645996094","3","DPRSearchEngine","aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11_1_pdf","aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11","6.006","11"
"180","What is the significance of having a negative weight edge in an undirected graph?","So here's an example of a weighted graph G. And I've labeled, in red, weights for each of these edges. This is a directed graph on eight vertices. And I've got an integer associated with each edge. You'll notice, some of them are positive, some of them are negative. It's OK to be zero as well. It's just any integer edge weight here. So generally we're going to be-- along with our graph G, we're going to be given a weight function that maps the edges of G to, we're going to say, integers, in this class anyway. In other contexts, in mathematics, you might have these be real numbers. But in this class, we're going to deal with integers. So each edge, if you have an edge, we're going to say this is the edge weight-- the weight of this edge e, from e. Sometimes, if this edge e is u, v, we might sometimes say the weight from u to v, since we have a simple graph that's unambiguous. All right, so but this is just talking about our notation. So in general, for example, the weight from vertex b to f in this graph is what? Can someone tell me? AUDIENCE: Minus 4. JASON KU: Minus 4, right? It's right here. And I'll be consistent with my coloring, because I've got colored chalk today. Minus 4. Happiness.","70.30990600585938","4","DPRSearchEngine","5cF5Bgv59Sc.en-j3PyPqV-e1s_3_mp4","5cF5Bgv59Sc.en-j3PyPqV-e1s","6.006","11"
"180","What is the significance of having a negative weight edge in an undirected graph?","It's not really complicated. Instead of having a single source, we are essentially wanting to, given an input-- this is our weighted graph, where we've got a graph V, E, and we've got a weight function from the edges to the integers. This is our general weighted graph. We want our output to be something like, the shortest path distance from u to v for every u and v in our vortex set. That's what we want to return. Now, there's one caveat here that, if there's a negative weight cycle in our graph-- in other words, if any of these delta u, v's is minus infinity,","70.14817810058594","5","DPRSearchEngine","EmSmaW-ud6A.en-j3PyPqV-e1s_2_mp4","EmSmaW-ud6A.en-j3PyPqV-e1s","6.006","14"
"180","What is the significance of having a negative weight edge in an undirected graph?","There's not a bound on the number of edges for a shortest path, because I could just keep going around that cycle as many times as I want and get a shorter path. And so we assign those distances to be minus infinity. So that's what we're going to do today in Bellman-Ford. In particular, what we're going to do is compute our shortest path distances, the shortest path waits for every vertex in our graph, setting the ones that are not reachable to infinity, and the ones that are reachable through a negative weight cycle to minus infinity, and all other ones we're going to set to a finite weight. And another thing that we might want is if there's a negative weight cycle in the graph, let's return one. So those are the two kinds of things that we're trying to solve in today's lecture. But before we do that, let's warm up with two short exercises. The first one, exercise 1, given an undirected graph, given undirected graph G, return whether G contains a negative weight cycle. Anyone have an idea of how we can solve this in linear time, actually? In fact, we can do it in order E. No-- yes, yes. Reachable from S. I guess-- let's just say a negative weight cycle at all. Not in the context of single-source shortest paths.","70.03996276855469","6","DPRSearchEngine","f9cVS_URPc0.en-j3PyPqV-e1s_3_mp4","f9cVS_URPc0.en-j3PyPqV-e1s","6.006","12"
"180","What is the significance of having a negative weight edge in an undirected graph?","BFS. Can anyone think of such a scenario? So let's say, I mean, kind of what we did before was we counted the number of edges. So if we gave a weight of 1 to every edge in my graph, then just that graph, that weighted graph, corresponds to an unweighted graph using the other distance metric. So in that case, BFS just solves our problem. And in fact, we can generalize further. What if all of our weights were positive, but the same value? If it was all positive and the same value, then we could just divide by that value. Now we have an unweighted graph which we can run BFS, and then multiply shortest path distances by that value later on. And in fact, there's one further generalization we can make, which is a little bit of a tricky graph transformation problem.","70.03114318847656","7","DPRSearchEngine","5cF5Bgv59Sc.en-j3PyPqV-e1s_5_mp4","5cF5Bgv59Sc.en-j3PyPqV-e1s","6.006","11"
"180","What is the significance of having a negative weight edge in an undirected graph?","2 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) Lecture 
General Unweighted 
BFS 
|V | + |E| L09 
L11 (Today!) 
L12 
L13 
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Any 
Bellman-Ford 
Dijkstra 
|V | · |E|
General Non-negative 
Lecture 11: Weighted Shortest Paths 
Weighted Paths 
• The weight w(π) of a path π in a weighted graph is the sum of weights of edges in the path 
• The (weighted) shortest path from s ∈ V to t ∈ V is path of minimum weight from s to t 
• δ(s, t) = inf{w(π) | path π from s to t} is the shortest-path weight from s to t 
• (Often use “distance” for shortest-path weight in weighted graphs, not number of edges) 
• As with unweighted graphs: 
– δ(s, t) = ∞ if no path from s to t 
– Subpaths of shortest paths are shortest paths (or else could splice in a shorter path) 
• Why inﬁmum not minimum? Possible that no ﬁnite-length minimum-weight path exists 
• When? Can occur if there is a negative-weight cycle in the graph, Ex: (b, f, g, c, b) in G1 
• A negative-weight cycle is a path π starting and ending at same vertex with w(π) < 0 
• δ(s, t) = −∞ if there is a path from s to t through a vertex on a negative-weight cycle 
• If this occurs, don’t want a shortest path, but may want the negative-weight cycle 
Weighted Shortest Paths Algorithms 
• Next four lectures: algorithms to ﬁnd shortest-path weights in weighted graphs 
• (No parent pointers: can reconstruct shortest paths tree in linear time after. Next page!) 
• Already know one algorithm: Breadth-First Search! Runs in O(|V | + |E|) time when, e.g.: 
– graph has positive weights, and all weights are the same 
– graph has positive weights, and sum of all weights at most O(|V | + |E|) 
• For general weighted graphs, we don’t know how to solve SSSP in O(|V | + |E|) time 
• But if your graph is a Directed Acyclic Graph you can! 
|V | log |V | + |E| 
","69.83314514160156","8","DPRSearchEngine","aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11_2_pdf","aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11","6.006","11"
"180","What is the significance of having a negative weight edge in an undirected graph?"," 
 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) Lecture 
General Unweighted 
BFS 
|V | + |E| L09 
L11 
L12 (Today!) 
L13 
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Any 
Bellman-Ford 
Dijkstra 
|V | · |E|
General Non-negative 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 12: Bellman-Ford 
Lecture 12: Bellman-Ford 
Previously 
• Weighted graphs, shortest-path weight, negative-weight cycles 
• Finding shortest-path tree from shortest-path weights in O(|V | + |E|) time 
• DAG Relaxation: algorithm to solve SSSP on a weighted DAG in O(|V | + |E|) time 
• SSSP for graph with negative weights 
– Compute δ(s, v) for all v ∈ V (−∞ if v reachable via negative-weight cycle) 
– If a negative-weight cycle reachable from s, return one 
Warmups 
• Exercise 1: Given undirected graph G, return whether G contains a negative-weight cycle 
• Solution: Return Yes if there is an edge with negative weight in G in O(|E|) time 
:O 
• So for this lecture, we restrict our discussion to directed graphs 
• Exercise 2: Given SSSP algorithm A that runs in O(|V |(|V | + |E|) time, 
show how to use it to solve SSSP in O(|V ||E|) time 
• Solution: Run BFS or DFS to ﬁnd the vertices reachable from s in O(|E|) time 
– Mark each vertex v not reachable from s with δ(s, v) = ∞ in O(|V |) time 
– Make graph G0 = (V 0, E0) with only vertices reachable from s in O(|V | + |E|) time 
– Run A from s in G0 . 
– G0 is connected, so |V 0| = O(|E0|) = O(|E|) so A runs in O(|V ||E|) time 
• Today, we will ﬁnd a SSSP algorithm with this running time that works for general graphs! 
|V | log |V | + |E| 
","69.79471588134766","9","DPRSearchEngine","2430d7903a5529451d80c17f89a41fe8_MIT6_006S20_lec12_1_pdf","2430d7903a5529451d80c17f89a41fe8_MIT6_006S20_lec12","6.006","12"
"180","What is the significance of having a negative weight edge in an undirected graph?"," 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Looking at F eature Weights  
model.classes_  =  ['Died' 'Survived'] 
For  label Survived 
Be wary of reading too 
C1 = 1.66761946545 
much into the weights 
C2 = 0.460354552452 
Features are often 
C3 = -0.50338282535 
correlated 
age = -0.0314481062387 
male gender  = -2.39514860929 
L1 regression tends to drive one variable to zero 
L2 (default) regression spreads weights across variables 
6.0002  LECTURE 14 
4 
","69.6511001586914","10","DPRSearchEngine","b9d60f4ecb325e4648f9cf0379419338_MIT6_0002F16_lec14_4_pdf","b9d60f4ecb325e4648f9cf0379419338_MIT6_0002F16_lec14","6.0002","14"
"181","What is a simple shortest path in the context of graphs?","But of course, there's sort of many variations on that theme when we talk about shortest path or even just existence of a path. So these are three sort of model problems that we might solve on a graph. So the first one, which in this of course we're calling the single pair reachability, would be the idea that I take two vertices s and t on my graph g, and I ask you does there exists a path between s and t. So what would be the sort of extreme example where this problem may not always give back the answer yes? Somehow in our head, I think we think of all graphs as being connected. But a perfectly valid graph the way we've defined it would be like 10 vertices and no edges. This function would be very easy to code if that were the only graph you ever cared about. But any event, the existence of a path is already a query that takes a little bit of algorithmic thinking. We haven't figured out how to do that yet. Now another problem we can solve would be the shortest path. Given a graph and two vertices, we might say, well, how far apart are these vertices of my graph if I want to use the shortest possible distance from one to the other. Notice that I can use the second problem to solve the first one. Because what's the length of the shortest path between two vertices that don't have a path between them? Infinity or a shrug-- that's actually a totally valid answer. Yeah, that's right. So how could I implement the reachability code? Well, I could call my shortest path code, and it gives me infinity. Then I return no, it's not reachable. And if it gives me not infinity, I return yes. So remember that a key idea in an algorithms class is this idea of reduction. That I can use one function to solve another. So in case, if we can solve shortest path, then we can certainly solve the reachability problem by calling that piece of code. And then finally we could talk about single source shortest path. So notice now that there's only one input node here s-- so what this problem is saying is give me the length of the shortest path from s to every single other vertex in my graph. Does that makes sense? Like maybe I return a big array with all the information, every single shortest distance. So can we solve single pair shortest path using single source shortest path? Absolutely. I could take s in my single pair shortest path problem, compute the shortest path from s to literally everything else, and then throw away all of that information except the shortest path to t, and now I'm good. Now I haven't justified that this is the fastest possible way to solve that second problem, but at least it shows that if I can solve problem three I can also solve problem two. If I can solve from two I can also solve problem one. So in today's lecture, we're just going to worry about problem three. In other words, these things are sort of listed in increasing order of their difficulty. OK, so in order to think about the single source shortest path problem, we're going to make one additional construction. And this is an idea called the shortest path tree. I got lazy drawing PowerPoint slides at 2:00 AM yesterday,","76.22553253173828","1","DPRSearchEngine","oFVYVzlvk9c.en-j3PyPqV-e1s_10_mp4","oFVYVzlvk9c.en-j3PyPqV-e1s","6.006","9"
"181","What is a simple shortest path in the context of graphs?","Longest path is maybe a problem we've talked about in problem session, because it's a DAG-- well, longest path is the same thing as shortest path, if you just negate all the weights. There are no weights in this picture, so if you just put negative 1 on all these edges and ask for the shortest path from the base to anywhere-- so single source shortest paths from this base-- then we would end up getting this path, which, if you look at it, is E-M-P-T-Y, empty. And so that shortest path is indeed the right answer. What I've drawn here is the shortest path tree. So also, if you wanted the longest increasing subsequence starting at A, then it is A-T-Y, just by following the red arrows here. And how do you get that? You just draw the parent pointers, just like we did before.","76.15381622314453","2","DPRSearchEngine","KLBCUx1is2c.en-j3PyPqV-e1s_8_mp4","KLBCUx1is2c.en-j3PyPqV-e1s","6.006","16"
"181","What is a simple shortest path in the context of graphs?","So a graph is connected if there's a path getting from every vertex to every other vertex. Right. Now connectivity in a directed graph is kind of a weird object. Like, for instance, think of a directed graph with just two edges. And one edge goes from u to v. Then I can get from v to u, but not vise versa. That's kind of a weird notion. So here in 6006 we'll mostly worry about connectivity only for undirected graphs because they're-- the vertices just basically come in like, big connected clumps. Or the more technical term for a big connected clump is a connected component. Yeah? So let's see an example. So let's say that I have a graph, which has an edge and then a triangle. This is one graph. Do you see that? There's a collection of vertices, and there's a collection of edges. But it has two connected components-- the guy on the right and the guy on the left, meaning that each vertex here is reachable from every other vertex here. Each vertex here is reachable from every vertex here. But there's no edge that goes from the triangle to the line segment. Yeah? And so in the connected components problem, we're given a graph like this guy. And initially, we don't, you know-- OK. When I draw it like this, it's pretty clear that my graph has two connected components. Maybe my graph-embedding algorithm failed and it drew an edge like that. Well, then maybe-- I don't know-- it's still pretty obvious that there's two connected components. But you can imagine a universe where you don't know that a priori. And the problem you're trying to solve is just to enumerate all these clumps of vertices that are reachable from one another in an undirected graph. And conveniently, we can use depth-first search to solve this problem pretty easily. Right? So how could we do it? Well, in some sense how can we find one connected component? So let's say that I just choose a vertex in my graph. Well, what do I know about everything in its connected component? Well, it's reachable from that vertex. Remember, we just solved the reachability problem, which says, if I have a vertex, I can now tell you all the other vertices that are reachable from this guy. So I could call DFS on, well, any vertex of this cycle here. Call the reachability thing. And I know that for every vertex there's one of two things. Either the vertex has a parent in that object P, or it's the source. So I can very easily find the connected component corresponding to that vertex. Does that makes sense? Have I found all the connected components? No. I found one. I found the one corresponding to the arbitrary vertex that I just chose. So how could I fix this? Well, it's super simple. I could put a for loop on the outside, which just loops over all the vertices, maybe. And if that vertex is not part of a connected component yet, then I need to make a new one. So then I call DFS on that vertex. I collect all the vertices that I got. And I iterate.","75.23170471191406","3","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_12_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"181","What is a simple shortest path in the context of graphs?","but it's worth noting explicitly, is that we'll mostly be thinking about a particular type of graph which is a simple graph. And in fact often, depending on how you define your graph, you kind of accidentally made your graph simple even if you didn't intend to. So for example, we wrote that our edges were a subset of v cross v. Which maybe means that I can't have multiple edges that sort of traverse the same pair of vertices. So let's see an example of a graph that is not simple. So sorry, I haven't actually defined it. A simple graph is a graph that has no self loops, so it can't go from a vertex to itself, and every edge is distinct. So let's make the most non simple graph we can think of. Like let's say I have two vertices. So maybe if I want to make my-- so there's a graph, right, two vertices and one edge. This is simple. If I wanted to be annoying and make it not simple, maybe I take this edge and I'd duplicate it three times just for fun. That violates the second assumption. And now to make it even worse, I could violate the first one by adding an edge that goes from this vertex to itself. This is not simple. I don't know what you would call it actually-- general graph, I guess-- complicated because it's not simple. I don't know-- a multigraph. I always thought of that-- anyway, it doesn't matter. But in any event, in this class we're not going to worry about this particular circumstance. And of course, in many applications of graph theory that's a totally reasonable assumption to make. Any questions about the definition of a simple graph? OK, so from now on whenever we think about a graph, in the back of our head we're going to think of our graph as simple. There's one nice property that a simple graph has, which I've written in really big text on the screen here, which is that the edges are big O of v squared. And in fact, let's expand that formula just a tiny bit. So there's sort of two cases, one is when my graph is undirected, the other is when my graph is directed. So if I have a directed graph-- well, let's think about how many edges we could possibly have. So an edge is a pair of a from vertex and a to vertex, and I can never repeat it twice. That's sort of like the second assumption here. So in particular, what do we know? We know that mod E-- or rather the number of edges in our graph is upper bounded by what? Well, I can take any pair of vertices-- like that-- but I have to be a little bit careful because my graph is directed-- so from and to matter here. So this is v choose 2 is saying that I can take any unique pair of vertices, but I have to put a factor of 2 in front of it to account for the fact that the source and the target can be flip back and forth. And of course, if I want to do the undirected I don't have to worry about that. We'll get E here is less than or equal to just mod v choose 2. So this is just a fancy way of saying that every edge consists of two vertices, and my edges are unique. And one thing, if you just write down the formula for our binomial coefficient here, we'll see that both of these things-- oops, oh, yeah, sorry-- are at worse mod v squared here. And that makes perfect sense, because of course, an edge is a pair of vertices. You kind of expect there to be a square there. Yes? AUDIENCE: [INAUDIBLE] JUSTIN SOLOMON: I'm so sorry. I can't hear you. AUDIENCE: So the 2 comes from the fact that it's from the source. JUSTIN SOLOMON: Yes, exactly. So the 2 for the director case, comes from the fact that an edge from v to w is different than an edge from w to v. So remember that the binomial coefficient here, it's just counting the number of ways that I can choose two things from a set of size v, but it doesn't care about ordering. Yeah, any other questions? Fabulous. So why is this going to matter? Well, these sorts of bounds, I mean they might seem a little bit obvious to you, but we're going to write down graph algorithms. And now when we analyze the runtime and the space that they take, we now have sort of two different numbers that we can think about-- the number of vertices and the number of edges. And so for instance, if I write down an algorithm whose runtime is proportional to the number of edges, maybe then genErikally I could also think of the algorithm as having a runtime that looks like the number of vertices squared unless I put some additional assumptions on my graph. And so there's some connection between all of these different constants, and it's useful to kind of keep that at the back of our head. That sometimes you'll see a bunch of different expressions that really are encoding roughly the same relationship just in different language Of course, that also means that we can be more precise. So sometimes a graph is what we would call sparse. So in my universe, almost all graphs that I deal with in my day to day life are extremely sparse. This is a consequence of topology. And because of that, an algorithm that scales like the number of edges might actually be much preferable to an algorithm that scales like the number of vertices squared because, in practice, often there are fewer edges than like every single possible pair. And so that's the sort of reason why it's we're thinking about these numbers.","75.05802917480469","4","DPRSearchEngine","oFVYVzlvk9c.en-j3PyPqV-e1s_6_mp4","oFVYVzlvk9c.en-j3PyPqV-e1s","6.006","9"
"181","What is a simple shortest path in the context of graphs?","So let's draw a graph. So here we have a, b-- I'm going to use letters instead of numbers to refer to nodes from now on because I don't want to confuse the length of the shortest path with the index of my node. So here's a, b, c-- I'm going to match my notes here-- d, e, f. Here's a graph-- again undirected because your instructor likes to think about undirected graphs. But I know I'm going to get feedback that I shouldn't have done that later. But in any event, let's say that I want to compute the shortest path from a to everything else-- or the length rather. So first of all, even without talking about an algorithm, I think it's pretty easy to guess what it is. So clearly the shortest path from a to a has length 0. The shortest length from a to b is 1, from a to c is 2-- because I can follow these guys. Now it gets complicated. It branched. So the next shortest path is length 3, and then 4 like that. Does everybody agree with me that the numbers I've decorated here are the length of the shortest path from a to everything else? But what have I not done? I haven't told you how to actually compute the path, I've just given you the length of the path. So I may want a piece of code that in addition to doing single source shortest path length, also gives me a single source shortest path. So initially when I think about that, I might think about, well, how do I even write down a data structure that can store all of those paths. Well every path could have like v vertices in it, right. It could be that for whatever reason, there's a lot of branching in my graph. And all the paths are super long. Actually, I guess I have to think about whether branching would make them longer or shorter. But in any event, I could have a really boring data structure that just for every single vertex keeps track of the shortest path from a to that vertex. How big would that data structure be? Well, if the only bound I have on the length of a path is that-- it certainly at most it takes all the vertices in my graph-- then any one path will take v space. So that would take v squared space total. That wouldn't be so good. Because somehow I have an amount of information on my graph currently that's linear. It's just the length of the path. If I want to actually reconstruct that path, initially sort of spiritually feels like I need way more space to do that. But the answer is that we actually don't. That we're going to only need linear space, and the idea for that is to store an object called the shortest path tree. Yes? AUDIENCE: Just for [INAUDIBLE] previous [INAUDIBLE].. JUSTIN SOLOMON: So the question was about recursion. We haven't actually written down any graph algorithms. So we're going to defer on that until we actually recurse. And then we'll think about it more carefully. Yeah, but it's a totally reasonable question. There are plenty of recursive graph algorithms out there. And then we'll have to do our counting very carefully for sure. Right, so instead, we're going to define an object called the shortest path tree. And the basic trick here is to say, well, how did I get from a to c? Well, there's always a vertex, which is its predecessor, on the shortest path. And shortest path have this really beautiful property, which is that the shortest path from a to c, if I truncate it-- right, so it goes a to b to c-- then the truncated one is also the shortest path to that previous vertex. So let's think about that a little bit, because that sentence was, as usual, poorly phrased by your instructor. So let's say that I have the shortest path from a to d, which is very clearly a, b, c, d. I think we can all agree. And now I take like this sublist. I just look from a to c. Is there ever a circumstance when this is not the shortest path or a shortest path from a to c? No, right because if there existed a shorter path from a to c, I could splice it in here and find the shortest path from a to d. Do you see that? So based on that reasoning, rather than string like this giant set of shortest paths, sort of actually applying, in some senses, recursive suggestion, instead I can just think of the one vertex that's before me in my shortest path. I'm going to trace backwards. So let's take a look at our graph here. Essentially, the object I'm going to keep track of is like a predecessor, right. So what is the predecessor of f on the shortest path? It's actually either d or e. It doesn't matter in this case. Maybe the predecessor is e for fun, right. What's the predecessor of e? Well, clearly the previous vertex on the shortest path is c. Similarly for d-- now we have b and a and a bunch of arrows that point this way. So for every vertex I'm just going to start an arrow pointing toward the previous vertex on the shortest path. I'm not going to store the whole shortest path, just the very last edge. So first of all, how much storage does this take? It takes v space. Do you see that? Or the size of the vertices space. Because every vertex just has to store one thing, which is the previous vertex on the shortest path. Now what does my algorithm for tracing shortest path? It's really simple. I just start walking along these edges all the way until I get back to a. Now this object is called the shortest path tree. Notice I snuck in one additional word which is tree. Why is that? Can I ever have a cycle in this graph? It wouldn't really make any sense, right. These are shortest path. You should be able to kind of follow the gradient back to the original vertex. OK, so in other words, I'm going to basically decorate my graph with one additional thing. We'll call it p of v which is the previous vertex on the shortest path from my source point to my vertex v. And what I think I've tried to argue to you guys today is that if I have this information, that's actually enough to reconstruct the shortest path. I just keep taking p of v, and then p of p of v, and then p of p of p of v, and so on, which sounds more complicated than it is, until I trace back to my original vertex. And this object conceptually is called the shortest path tree. Any questions about that? Yes? AUDIENCE: [INAUDIBLE] JUSTIN SOLOMON: If I had an edge that connected a to d, OK. AUDIENCE: [INAUDIBLE] JUSTIN SOLOMON: Oh, OK so the question was, let's say that our colleague here added an edge-- this is a great question. You know somebody was evil, my adversarial neural network, stuck an edge here because it was adversarial, and it wanted my shortest path code to fail. And now somehow the tree that I gave you is no longer correct. And my answer to that is yes. Why is that? Well, by adding this edge here, the length of my shortest path changed. The shortest path from a to d is now 1. So this tree is no longer valid. I need a new tree. So now what would be the previous p of d here? Well, rather than being c, it would be a. Yes, that's absolutely right. And it actually is reflective of a really annoying property of shortest path, which is if I add one edge to my graph, the length of the shortest path to every vertex can change. Well, I guess with the exception of the source vertex. Yeah, and that's actually a really big headache in certain applications. So for instance-- and then I'll shut up about applications and do math again-- I work a lot with 3D models. And there's a big data set of 3D models of like ballerinas. And ballerinas are really annoying because sometimes they put their hands together like that. And then suddenly the shortest path between your fingers goes from your entire body to like 0. And so incremental algorithms for computing shortest path can fail here, right. Because I have to update like everything if I accidentally glued together fingers like that. So anyway, I'll let you think about how you might fix that problem. If you want to know more, you should take 6.838. Yes? AUDIENCE: [INAUDIBLE]. JUSTIN SOLOMON: If you change your source node, the shortest possible change again. Yeah, so this is going to be one of these really boring things where I'm going to keep answering like any time I change anything about my problem-- I change my source, I change my edges-- I have to just recompute all the shortest paths. There are obviously algorithms out there that don't do that. But we're not going to think about them yet. OK. So as usual, I've talked too much and left myself about 10 minutes to do the actual algorithm that's interesting in the lecture here-- although actually, it's really not so complicated,","74.1991958618164","5","DPRSearchEngine","oFVYVzlvk9c.en-j3PyPqV-e1s_11_mp4","oFVYVzlvk9c.en-j3PyPqV-e1s","6.006","9"
"181","What is a simple shortest path in the context of graphs?","is to start introducing sort of the canonical problem that we all worry about on graphs which is computing paths, in particular shortest paths. So the first thing we should do is, of course, define what a path is on a graph. So we're going to talk about our graph like a road network. Let's think of maybe every node here as an intersection. So this is a roughly Kendall Square. See it's a square. But in any event, let's say that I want to find-- maybe a question one would be does there exist a way to get from vertex 1 to vertex 3. And then a better question to ask would be does there exists a short way to get from vertex 1 to vertex 3. Then of course, the first thing I have to do is to define my enemy. I have define what I'm looking for, which is a path. So a path is nothing more than a sequence of vertices in a graph where every pair of adjacent vertices in that sequence is an edge. I think this all aligns with our intuition of what a path is in a graph. So for instance, here's a path p equals v1, v2, v3. So notice that there's an edge from v1 to v2 and also an edge from v2 to v3. So it satisfies the assumptions set forth in our definition. What would not be a path in our graph-- would be like v1 comma v3, because there's no edge there. OK, so if we talk about paths, then there's a very natural notion which is the length. Length, I guess you could think of like the number of vertices in your path minus 1, or the number of edges that your path traverses. Those are the same thing. So for instance, the length of the path p here is 2. Does everybody see that? A very common coding bug that I encounter a lot is adding 1 to that number by accident. Because of course, there's one more vertex in your path than there are edges. OK, and there are many different-- there could be potentially more than one path between any pair of vertices. So let's say that I have an undirected graph that looks like the following. So it's just a square plus a diagonal. So here are nodes. So then a perfectly valid path from the lower left to the upper right would be to go one over and one up, but of course, there's a more efficient way to get from the lower left to the upper right, which is to go across the diagonal. And so when we talk about the shortest path, it's nothing more than the length of the path that has the fewest number of edges or vertices between any pair of vertices in my graph. OK, so this is our enemy. This is what we're after. It's computing the shortest path between vertices in a graph. And this is the thing that we'll be talking about quite a bit in this course. Because of course, it's a very practical matter. Like when I want to solve routing problems, I want to move packets out of my network, I'd prefer not to-- well, unless I'm doing Tor-- I would prefer them not to hit too many computers in between. Then maybe I want a computer shortest path. Or on a surface maybe I want to move information","74.10151672363281","6","DPRSearchEngine","oFVYVzlvk9c.en-j3PyPqV-e1s_9_mp4","oFVYVzlvk9c.en-j3PyPqV-e1s","6.006","9"
"181","What is a simple shortest path in the context of graphs?","notes because I figured we'd define what a graph is first before telling you what the implications are. But in any event, I think it's really not a big stretch of the imagination to say that graphs are literally everywhere in our everyday life, right. Any time that we come up with a network of stuff connected together, implicitly the right abstraction often in the back of our heads is to think about a graph. So some simple examples that I think would all come to mind for us would be like computer networks-- so the nodes or the vertices of your graph in that case, maybe are computers, and then the edges are roughly the cables connecting them together in my very coarse understanding of how networks work-- or maybe at a social network-- the nodes are people on your social network, and the edges are friend relationships or frenemy relationships or whatever. In fact, I think you could think of both directed and undirected versions of that particular network. In road networks, maybe I'm working for Google and I want to tell you the shortest path between your house and MIT. Of course, in order to do that and essentially behind the scenes, we're solving some version of computing the shortest path between two vertices in a graph. That's a tiny bit of a lie in the sense that there's a lot of structure in that problem that we're not going to leverage in this course. A road network is a very special type of graph, and if you take an advanced course maybe you'll say, well, if I know a little more about my graph I can do better than the general case we'll talk about here. But the basic algorithms that we'll talk about in 6.006 are certainly relevant in that case and are really the building blocks for what goes on in the tools that are used every day on your phone when you open Google Maps or Ways or whatever. And of course, there's many others. So for instance, an example that maybe is a little bit more subtle would be the set of states and transitions of a discrete thing. So think about like a Rubik's cube. So I could make a graph where the node is every configuration of my Rubik's cube, like every rotation. And then the edges are like can I get from this configuration to that one by making one simple transition, like one flip. I don't actually know the terminology in Rubik's cube, I have a feeling you do, for one rotation. Twist-- thank you. And of course, there are many other places. So for instance, in my day job here at MIT","74.02261352539062","7","DPRSearchEngine","oFVYVzlvk9c.en-j3PyPqV-e1s_4_mp4","oFVYVzlvk9c.en-j3PyPqV-e1s","6.006","9"
"181","What is a simple shortest path in the context of graphs?","Whereas this is kind of an approximation algorithm, I'm approximating my outputs, this is an approximation algorithm from the standpoint of, well, there's a lot of problems that I can't solve efficiently. They're NP-hard. They're in EXP or even harder problems. But maybe I'm OK with not getting the optimal solution. So this is in the domain of optimization problems. So most of the dynamic programming problems that we gave you were optimization problems. They're the shortest paths problems. Those are optimization problems. Basically, the possible outputs are ranked in some way-- the distance of a path that you return or something like that. They're ranked in some way. There is an optimal one-- the one with the smallest metric or something like that. Well, in an approximation algorithm what I do is, OK, I get that it's computationally difficult for you to give me the longest simple path in this graph, or the shortest possible route for my traveling salesman, but maybe that's OK. I mean, my engineering Spidey-sense tells me that within 10% is fine. So maybe instead of giving me the most optimal thing, can I give you an algorithm that's guaranteed to be within a certain distance from the optimal thing? Usually, we're looking for constant factor approximations which have low constant, or maybe even have to do for worse if such things don't exist. OK, so that's approximation algorithms. Can we get close to an optimal solution in polynomial time? OK. And then the last way we could change things in, especially future classes, though sometimes they talk about this in 046","73.55231475830078","8","DPRSearchEngine","2NMtS1ecb3o.en-j3PyPqV-e1s_11_mp4","2NMtS1ecb3o.en-j3PyPqV-e1s","6.006","20"
"181","What is a simple shortest path in the context of graphs?","the runtime of this full DFS algorithm is v plus e time because every edge is touched no more than one time. Kind of amortized over all the different calls to DGS here. And there's this for loop over vertices. So there's clearly an order v that you need here. Does that argument make sense? So again, we call that linear in the size of the input. I'm going to say it as many times to get it in my own head correctly. OK. Right. So this is the basic problem. This comes up all the time, by the way. Like, it seems like somehow a totally brain dead weird algorithm. Like, somehow, why would you want an algorithm that finds connected components. Like, why would you even have a graph that's disconnected or something? But of course, that can happen a lot. So for instance, maybe you work at a social media company, and people have friends. But like, Eric and I are friends. And we're not friends with anybody else. We have a-- there's like, a blood oath kind of thing. Then that might be not so easy to find in the graph because, of course, we're just two among a sea of students in this classroom, all of which have different interconnections that are just enumerated based on the list of edges. And so even though like, pictorially, it's kind of hard to draw a connecting component algorithm in a way that doesn't make it sound kind of like a useless technique from the start, because it's very clear there are two connected components there. Of course, we still have to be able to write code to solve this sort of thing. OK. So for once, I think I'm almost on time in lecture today. So we have one additional application of depth-first search in our class today, which is sort of on the opposite end of the spectrum. So we just talked about graphs that are undirected and thinking about cycles. Now, on the opposite end we might think of a DAG. So a DAG is a Directed Acyclic Graph. Can anyone think of a special case of a DAG? I suppose I should define it first. And then we'll come back to that question, which means exactly what it sounds like. So it's a graph that has directed edges now and doesn't have any cycles in it. So actually, the graph I gave you all the way at the beginning of lecture I think secretly was an example of one of these. So let's say that I have directed edges. Maybe if I make the head a triangle, it's a little easier to see. I'm not so sure. In any event, so I'm going to have an edge up and an edge to the right, and similarly, an edge down and an edge to the right. This graph looks like a cycle. But it's not because the only direction that I can move is from the left-hand side to the right-hand side. So this is a directed graph. And it doesn't contain any cycles, meaning there's no path that it can take from a vertex that gets back to itself along the directed edges. OK. And DAGs show up all the time. Now that I've defined what a DAG is,","73.2930679321289","9","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_15_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"181","What is a simple shortest path in the context of graphs?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 9: Breadth-First Search 
Lecture 9: Breadth-First Search 
New Unit: Graphs! 
• Quiz 1 next week covers lectures L01 - L08 on Data Structures and Sorting 
• Today, start new unit, lectures L09 - L14 on Graph Algorithms 
Graph Applications 
• Why? Graphs are everywhere! 
• any network system has direct connection to graphs 
• e.g., road networks, computer networks, social networks 
• the state space of any discrete system can be represented by a transition graph 
• e.g., puzzle & games like Chess, Tetris, Rubik’s cube 
• e.g., application workﬂows, speciﬁcations 
Graph Deﬁnitions 
G1 
0 
1 
2 
3 
G2 
0 
1 
2 
G3 
a 
b 
s 
c 
d 
e 
f 
g 
• Graph G = (V, E) is a set of vertices V and a set of pairs of vertices E ⊆ V × V . 
• Directed edges are ordered pairs, e.g., (u, v) for u, v ∈ V 
• Undirected edges are unordered pairs, e.g., {u, v} for u, v ∈ V 
i.e., (u, v) and (v, u) 
• In this class, we assume all graphs are simple: 
– edges are distinct, e.g., (u, v) only occurs once in E (though (v, u) may appear), and 
– edges are pairs of distinct vertices, e.g., u =6 v for all (u, v) ∈ E 
 

|V |
|V |
– Simple implies |E| = O(|V |2), since |E| ≤ 
for undirected, ≤ 2 
for directed 
2
2 
","73.07965850830078","10","DPRSearchEngine","196a95604877d326c6586e60477b59d4_MIT6_006S20_lec9_1_pdf","196a95604877d326c6586e60477b59d4_MIT6_006S20_lec9","6.006","9"
"182","Why can't a simple shortest path in a graph contain a cycle with negative weight?","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","77.5984115600586","1","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"182","Why can't a simple shortest path in a graph contain a cycle with negative weight?"," 
 
 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) 
General Unweighted 
BFS 
|V | + |E|
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Non-negative Dijkstra 
Bellman-Ford 
|V | log |V | + |E|
General Any 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 14: Johnson’s Algorithm 
Lecture 14: Johnson’s Algorithm 
Previously 
|V | · |E| 
All-Pairs Shortest Paths (APSP) 
• Input: directed graph G = (V, E) with weights w : E → Z 
• Output: δ(u, v) for all u, v ∈ V , or abort if G contains negative-weight cycle 
• Useful when understanding whole network, e.g., transportation, circuit layout, supply chains... 
• Just doing a SSSP algorithm |V | times is actually pretty good, since output has size O(|V |2) 
– |V | · O(|V | + |E|) with BFS if weights positive and bounded by O(|V | + |E|) 
– |V | · O(|V | + |E|) with DAG Relaxation if acyclic 
– |V | · O(|V | log |V | + |E|) with Dijkstra if weights non-negative or graph undirected 
– |V | · O(|V | · |E|) with Bellman-Ford (general) 
• Today: Solve APSP in any weighted graph in |V | · O(|V | log |V | + |E|) time 
","73.84101867675781","2","DPRSearchEngine","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14_1_pdf","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14","6.006","14"
"182","Why can't a simple shortest path in a graph contain a cycle with negative weight?","It's not really complicated. Instead of having a single source, we are essentially wanting to, given an input-- this is our weighted graph, where we've got a graph V, E, and we've got a weight function from the edges to the integers. This is our general weighted graph. We want our output to be something like, the shortest path distance from u to v for every u and v in our vortex set. That's what we want to return. Now, there's one caveat here that, if there's a negative weight cycle in our graph-- in other words, if any of these delta u, v's is minus infinity,","73.3776626586914","3","DPRSearchEngine","EmSmaW-ud6A.en-j3PyPqV-e1s_2_mp4","EmSmaW-ud6A.en-j3PyPqV-e1s","6.006","14"
"182","Why can't a simple shortest path in a graph contain a cycle with negative weight?","single source shortest paths in linear time. Last time we discussed another linear time algorithm, DAG relaxation. And today we're going to be talking about Bellman-Ford, which isn't limited to asymptotic graphs. In particular, there could be negative weight cycles in our graph. If it has cycles, if it has negative weights, the worry is that we could have negative weight cycles, in which case there-- if a negative weight cycle is reachable from our source, then the vertices in that cycle and anything reachable from that cycle will potentially","72.82835388183594","4","DPRSearchEngine","f9cVS_URPc0.en-j3PyPqV-e1s_2_mp4","f9cVS_URPc0.en-j3PyPqV-e1s","6.006","12"
"182","Why can't a simple shortest path in a graph contain a cycle with negative weight?","There's not a bound on the number of edges for a shortest path, because I could just keep going around that cycle as many times as I want and get a shorter path. And so we assign those distances to be minus infinity. So that's what we're going to do today in Bellman-Ford. In particular, what we're going to do is compute our shortest path distances, the shortest path waits for every vertex in our graph, setting the ones that are not reachable to infinity, and the ones that are reachable through a negative weight cycle to minus infinity, and all other ones we're going to set to a finite weight. And another thing that we might want is if there's a negative weight cycle in the graph, let's return one. So those are the two kinds of things that we're trying to solve in today's lecture. But before we do that, let's warm up with two short exercises. The first one, exercise 1, given an undirected graph, given undirected graph G, return whether G contains a negative weight cycle. Anyone have an idea of how we can solve this in linear time, actually? In fact, we can do it in order E. No-- yes, yes. Reachable from S. I guess-- let's just say a negative weight cycle at all. Not in the context of single-source shortest paths.","72.76195526123047","5","DPRSearchEngine","f9cVS_URPc0.en-j3PyPqV-e1s_3_mp4","f9cVS_URPc0.en-j3PyPqV-e1s","6.006","12"
"182","Why can't a simple shortest path in a graph contain a cycle with negative weight?","This data structure is called the Fibonacci heap. We're not going to talk about it in 6.006. They talk about it-- and you can look at chapter 19 in CLRS or you can look at-- I think they talk about it in 6.854 if you're interested in learning about Fibonacci heaps. But these are almost never-- I mean, they get good theoretical bounds. So what you want to say is, whenever we give you a theory problem where you might want to use Dijkstra, you want to use this theoretical running time bound for your problem E plus V log V. But if you happen to know that your graph is sparse or dense, just using an array or a heap is going to get you just as good of a running time. Very close to linear. And so in practice, most people, when they are implementing a graph search algorithm, they know if their graph is sparse or dense, and so they never bother implementing a Fibonacci heap, which is a little complicated. So they're usually either in one of these first two cases where V squared is linear when your graph is dense, or we're very close to linear, E times log V, which is V log V if your graph is sparse. So that's the running time of Dijkstra. So so far, we've gotten all of these nice bounds. Some special cases where we're-- I mean, special cases where we're linear. Dijkstra where we're close to linear. And Bellman-Ford, if we throw our hands up in the air, there might be negative cycles in our graph, we gotta spend that quadratic running time bound. Now there are faster algorithms, but this is the fastest we're going to teach you in this class. Now and in the next lecture we're going to be talking about all pair shortest paths, and we'll pick it up next time.","72.57804870605469","6","DPRSearchEngine","NSHizBK9JD8.en-j3PyPqV-e1s_8_mp4","NSHizBK9JD8.en-j3PyPqV-e1s","6.006","13"
"182","Why can't a simple shortest path in a graph contain a cycle with negative weight?"," 
 
 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) Lecture 
General Unweighted 
BFS 
|V | + |E| L09 
L11 
L12 
L13 (Today!) 
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Any 
Bellman-Ford 
Dijkstra 
|V | · |E|
General Non-negative 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 13: Dijkstra’s Algorithm 
Lecture 13: Dijkstra’s Algorithm 
Review 
• Single-Source Shortest Paths on weighted graphs 
• Previously: O(|V | + |E|)-time algorithms for small positive weights or DAGs 
• Last time: Bellman-Ford, O(|V ||E|)-time algorithm for general graphs with negative weights 
• Today: faster for general graphs with non-negative edge weights, i.e., for e ∈ E, w(e) ≥ 0 
|V | log |V | + |E| 
Non-negative Edge Weights 
• Idea! Generalize BFS approach to weighted graphs: 
– Grow a sphere centered at source s 
– Repeatedly explore closer vertices before further ones 
– But how to explore closer vertices if you don’t know distances beforehand? 
:( 
• Observation 1: If weights non-negative, monotonic distance increase along shortest paths 
– i.e., if vertex u appears on a shortest path from s to v, then δ(s, u) ≤ δ(s, v) 
– Let Vx ⊂ V be the subset of vertices reachable within distance ≤ x from s 
– If v ∈ Vx, then any shortest path from s to v only contains vertices from Vx 
– Perhaps grow Vx one vertex at a time! (but growing for every x is slow if weights large) 
• Observation 2: Can solve SSSP fast if given order of vertices in increasing distance from s 
– Remove edges that go against this order (since cannot participate in shortest paths) 
– May still have cycles if zero-weight edges: repeatedly collapse into single vertices 
– Compute δ(s, v) for each v ∈ V using DAG relaxation in O(|V | + |E|) time 
","72.45731353759766","7","DPRSearchEngine","d819e7f4568aced8d5b59e03db6c7b67_MIT6_006S20_lec13_1_pdf","d819e7f4568aced8d5b59e03db6c7b67_MIT6_006S20_lec13","6.006","13"
"182","Why can't a simple shortest path in a graph contain a cycle with negative weight?","!""#$""%&'(% ∈NP
Defn:  !""#$""%&'(% = + + is not prime and + is written in binary} 
= + + = ,- for integers ,, - > 1,  + in binary} 
Theorem:  !""#$""%&'(% ∈NP
Proof:   “On input +
1.  Nondeterministically write , where 1 < , < +.
2.  Accept if , divides + with remainder 0.
Reject if not.”
Note:  Using base 10 instead of base 2 wouldn’t matter because can convert in 
polynomial time.
Bad encoding:  write number 3 in unary:  14 = 111 ⋯1
4
, exponentially longer.
Theorem (2002):  !""#$""%&'(% ∈P
We won’t cover this proof.
5
","72.27804565429688","8","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_5_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"182","Why can't a simple shortest path in a graph contain a cycle with negative weight?","And that's cycle detection. So there's a bit of an exercise left to the reader here. So the problem that we're looking for now is that we're given a directed graph. There's a G in graph, in case you're wondering. But now, we don't know if it's a DAG or not. And so the question that we're trying to ask is, does there exist a cycle in our directed acyclic graph? So we're just given our graph, and we want to know, can we do this? Let's think through the logic of this a bit. So what do we know? We know that if our graph were a DAG, then I could call DGS, get the ordering out, and then I guess flip its ordering backwards. So I could compute the reverse finishing order. And it would give me a topological order of my graph. So if I were a DAG, I would get a topological order when I call DFS. So let's say that I ran DFS. I got whatever ordering I got. And now I found an edge the points in the wrong direction. I can just double check my list of edges, and I find one that does not respect the relationship that I see in the second bullet point here. Can my graph be a DAG? No. Because if my graph were a DAG, the algorithm would work. I just proved it to you. Right? So if my graph were a DAG, then I could do reverse finishing order. And what I would get back is a topological order. So if I found a certificate that my order wasn't topological, something went wrong, and the only thing that could go wrong is that my graph isn't a DAG. Yeah. Isn't a DAG. In fact, sort of an exercise left to the reader and/or to your section-- do we still have section? I think we do, as of now-- is that this is an if and only if, meaning that the only time that you even have a topological ordering in your graph is if your graph is a DAG. This is a really easy fact to sanity check, by the way. This is not like, a particularly challenging problem. But you should think through it because it's a good exercise to make sure you understand the definitions, which is to say that if you have a topological order, your graph is a DAG. If you don't have a topological order, your graph isn't a DAG. So in other words, we secretly gave you an algorithm for checking if a graph is a DAG at all. Right? What could I do? I could compute reverse finishing order. Check if it obeys the relationship on the second bullet point here for every edge. And if it does, then we're in good shape. My graph is a DAG. If it doesn't, something went wrong. And the only thing that could have gone wrong is not being a DAG. OK. So in other words, secretly we just solved-- well, I guess the way that I've written it here, we've solved the cycle detection problem here, which is to say that, well, I have a cycle if and only if I'm not a DAG, which I can check using this technique. Of course, the word ""detection"" here probably means that I actually want to find that cycle, and I haven't told you how to do that yet. All we know how to do so far is say, like, somewhere in this graph there's a cycle. And that's not so good. So we can do one additional piece of information in the two minutes we have remaining to sort of complete our story here, which is to modify our algorithm ever so slightly to not only say thumbs up, thumbs down, is there a cycle in this graph, but also to actually return the vertices as a cycle. And here's the property that we're going to do that, which is following, which is that if G contains a cycle, right, then full DFS will traverse an edge from a vertex v to some ancestor of v. I guess we haven't carefully defined the term ""ancestor"" here. Essentially, if you think of the sort of the running of the DFS algorithm, then an ancestor is like something that appears in the recursive call tree before I got to v. OK. So how could we prove that? Well, let's take a cycle. And we'll give it a name. In particular, we'll say that it's a cycle from v0 v1 to vk. And then it's a cycle, so it goes back to v0. OK. And I can order this cycle any way I want. Notice that if I permute the vertices in this list in a cyclical way, meaning that I take the last few of them and stick them at the beginning of the list, it's still a cycle. That's the nice thing about cycles. So in particular, without loss of generality, we're going to assume that v0 is the first vertex visited by DFS. What does that mean? That means, like, when I do my DFS algorithm making all these recursive calls, the very first vertex to be touched by this technique is v0. OK. Well, now what's going to end up happening? Well, think about the recursive call tree starting at v0. By the time that completes, anything that's reachable from v0 is also going to be complete. Do you see that? So for instance, v0 somewhere in its call tree might call v2. And notice that v2 was not already visited. So in fact, it will. For v1 I got to call v2 and so on. And in particular, we're going to get all the way to vertex k. Right? So in other words, we're going to visit a vertex vk. And notice what's going to happen. So remember our algorithm. In fact, we should probably just put it up on the screen would be easier than talking about it a bunch. Well, vk is now going to iterate over every one of the neighbors of vk. And in particular, it's going to see vertex v0. Right? So we're going to see the edge from vk to v0, which is an edge kind of by definition because we took this to be a cycle here. But notice that's exactly the thing we set out to prove, namely that full DFS traverses an edge from a vertex to one of its ancestors. Here's a vertex k. Here's the ancestor v0. Why do we know that it's an ancestor? Well, because v0 was called in our call tree before any of these other guys. Right? So we wanted an algorithm that not only did cycle detection, but also actually gave me the cycle. What could I do? Well, it's essentially a small modification of what we already have. Right. So-- whoops. Right. If I want to compute topological order or whatever, I can just do DFS. And that'll tell me like, yay or nay, does there exist a cycle. If I want to actually find that cycle, all I have to do is check that topological order property at the same time that it traversed the graph during DFS. And the second that I find an edge that loops back, I'm done. And so that's our basic algorithm here. And this is a technique for actually just finding the cycle in a graph using the DFS algorithm.","72.177001953125","9","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_20_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"182","Why can't a simple shortest path in a graph contain a cycle with negative weight?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 11: Weighted Shortest Paths 
Lecture 11: Weighted Shortest Paths 
Review 
• Single-Source Shortest Paths with BFS in O(|V | + |E|) time (return distance per vertex) 
• Single-Source Reachability with BFS or DFS in O(|E|) time (return only reachable vertices) 
• Connected components with Full-BFS or Full-DFS in O(|V | + |E|) time 
• Topological Sort of a DAG with Full-DFS in O(|V | + |E|) time 
• Previously: distance = number of edges in path Today: generalize meaning of distance 
Weighted Graphs 
• A weighted graph is a graph G = (V, E) together with a weight function w : E → Z 
• i.e., assigns each edge e = (u, v) ∈ E an integer weight: w(e) = w(u, v) 
• Many applications for edge weights in a graph: 
– distances in road network 
– latency in network connections 
– strength of a relationship in a social network 
• Two common ways to represent weights computationally: 
– Inside graph representation: store edge weight with each vertex in adjacency lists 
– Store separate Set data structure mapping each edge to its weight 
• We assume a representation that allows querying the weight of an edge in O(1) time 
Examples 
G1 
G2 
a 
e 
b 
f 
c 
g 
d 
h 
6 
8 
−2 
5 
9 
−5 
7 
3 
2 
−1 
−4 
1 
4 
a 
e 
b 
f 
c 
g 
d 
h 
6 
8 
−2 
5 
9 
−5 
7 
3 
2 
−1 
−4 
1 
4 
","72.08221435546875","10","DPRSearchEngine","aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11_1_pdf","aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11","6.006","11"
"183","How many edges can a simple path in a graph have at most?","And then finding all the vertices reachable from those witnesses, we set all of the infinite ones to be minus infinity as desired. OK, so what's the running time of this thing? Well, we had to construct this graph, so we had to take that time. We ran DAG relaxation, that takes the same amount of time. For every vertex, we did order V at work. And then for each witness, how many could there be? And most, V. Checking the reachability of each vertex, that can be done in how long? Order E time. Because we don't need to consider the things that aren't connected to S-- or aren't connected to the witness. So this thing takes order V times E work. So we're upper-bounded by this time it took to construct the original graph and by the claim we had before, that takes V times E time. OK. So that's Bellman-Ford. I'm just going to leave you with two nuggets. First, the shortest path, if for any witness-- let's say we have a witness here. Do I have any witnesses here? I didn't fill in all these. But is there a vertex on this cycle that goes through who has the shortest path? That goes through four vertices that's smaller than any other. OK. I can go from a to c to b to d to b to c. And you can work out this algorithm-- I have it in the notes that you can take a look at. This will actually have a shorter path for vertex-- sorry. It'll have a shorter path for vertex b. a to b to c to d to b. Thank you. That's a path of length 4, of four edges. That has shorter path than any path that has fewer edges. In particular, there's only one other path to b using fewer than four-- there's two other paths. One path of length-- that has one edge, that has weight minus 5, and one path-- this path that has weight 9 minus 1 is 8. Whereas this path, minus 5, minus 4, 3, minus 1 has minus 10 plus 3 is minus 7, which is shorter than minus 5. So b and d is a witness. And if we actually take a look at that path through this graph, going from a to b to c to d back to b we see that there's a negative weight cycle in this graph. b to c to d to b. And indeed, that's always the case for our witnesses. You can see a proof of that in the notes, and you can see in recitation a little space optimization to make us not have to construct this entire graph on the fly, but actually only use order V space while they're going. OK. So that's Bellman-Ford. Sorry for running a little late.","70.87605285644531","1","DPRSearchEngine","f9cVS_URPc0.en-j3PyPqV-e1s_11_mp4","f9cVS_URPc0.en-j3PyPqV-e1s","6.006","12"
"183","How many edges can a simple path in a graph have at most?","So a graph is connected if there's a path getting from every vertex to every other vertex. Right. Now connectivity in a directed graph is kind of a weird object. Like, for instance, think of a directed graph with just two edges. And one edge goes from u to v. Then I can get from v to u, but not vise versa. That's kind of a weird notion. So here in 6006 we'll mostly worry about connectivity only for undirected graphs because they're-- the vertices just basically come in like, big connected clumps. Or the more technical term for a big connected clump is a connected component. Yeah? So let's see an example. So let's say that I have a graph, which has an edge and then a triangle. This is one graph. Do you see that? There's a collection of vertices, and there's a collection of edges. But it has two connected components-- the guy on the right and the guy on the left, meaning that each vertex here is reachable from every other vertex here. Each vertex here is reachable from every vertex here. But there's no edge that goes from the triangle to the line segment. Yeah? And so in the connected components problem, we're given a graph like this guy. And initially, we don't, you know-- OK. When I draw it like this, it's pretty clear that my graph has two connected components. Maybe my graph-embedding algorithm failed and it drew an edge like that. Well, then maybe-- I don't know-- it's still pretty obvious that there's two connected components. But you can imagine a universe where you don't know that a priori. And the problem you're trying to solve is just to enumerate all these clumps of vertices that are reachable from one another in an undirected graph. And conveniently, we can use depth-first search to solve this problem pretty easily. Right? So how could we do it? Well, in some sense how can we find one connected component? So let's say that I just choose a vertex in my graph. Well, what do I know about everything in its connected component? Well, it's reachable from that vertex. Remember, we just solved the reachability problem, which says, if I have a vertex, I can now tell you all the other vertices that are reachable from this guy. So I could call DFS on, well, any vertex of this cycle here. Call the reachability thing. And I know that for every vertex there's one of two things. Either the vertex has a parent in that object P, or it's the source. So I can very easily find the connected component corresponding to that vertex. Does that makes sense? Have I found all the connected components? No. I found one. I found the one corresponding to the arbitrary vertex that I just chose. So how could I fix this? Well, it's super simple. I could put a for loop on the outside, which just loops over all the vertices, maybe. And if that vertex is not part of a connected component yet, then I need to make a new one. So then I call DFS on that vertex. I collect all the vertices that I got. And I iterate.","70.81332397460938","2","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_12_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"183","How many edges can a simple path in a graph have at most?","But of course, there's sort of many variations on that theme when we talk about shortest path or even just existence of a path. So these are three sort of model problems that we might solve on a graph. So the first one, which in this of course we're calling the single pair reachability, would be the idea that I take two vertices s and t on my graph g, and I ask you does there exists a path between s and t. So what would be the sort of extreme example where this problem may not always give back the answer yes? Somehow in our head, I think we think of all graphs as being connected. But a perfectly valid graph the way we've defined it would be like 10 vertices and no edges. This function would be very easy to code if that were the only graph you ever cared about. But any event, the existence of a path is already a query that takes a little bit of algorithmic thinking. We haven't figured out how to do that yet. Now another problem we can solve would be the shortest path. Given a graph and two vertices, we might say, well, how far apart are these vertices of my graph if I want to use the shortest possible distance from one to the other. Notice that I can use the second problem to solve the first one. Because what's the length of the shortest path between two vertices that don't have a path between them? Infinity or a shrug-- that's actually a totally valid answer. Yeah, that's right. So how could I implement the reachability code? Well, I could call my shortest path code, and it gives me infinity. Then I return no, it's not reachable. And if it gives me not infinity, I return yes. So remember that a key idea in an algorithms class is this idea of reduction. That I can use one function to solve another. So in case, if we can solve shortest path, then we can certainly solve the reachability problem by calling that piece of code. And then finally we could talk about single source shortest path. So notice now that there's only one input node here s-- so what this problem is saying is give me the length of the shortest path from s to every single other vertex in my graph. Does that makes sense? Like maybe I return a big array with all the information, every single shortest distance. So can we solve single pair shortest path using single source shortest path? Absolutely. I could take s in my single pair shortest path problem, compute the shortest path from s to literally everything else, and then throw away all of that information except the shortest path to t, and now I'm good. Now I haven't justified that this is the fastest possible way to solve that second problem, but at least it shows that if I can solve problem three I can also solve problem two. If I can solve from two I can also solve problem one. So in today's lecture, we're just going to worry about problem three. In other words, these things are sort of listed in increasing order of their difficulty. OK, so in order to think about the single source shortest path problem, we're going to make one additional construction. And this is an idea called the shortest path tree. I got lazy drawing PowerPoint slides at 2:00 AM yesterday,","70.79605865478516","3","DPRSearchEngine","oFVYVzlvk9c.en-j3PyPqV-e1s_10_mp4","oFVYVzlvk9c.en-j3PyPqV-e1s","6.006","9"
"183","How many edges can a simple path in a graph have at most?","There are a few corollaries to that fact. So unless there are any questions about that, we'll get started with our new unit in 6.006 which is a graph theory. If you're wondering, there's a graph on the screen here. But of course, we'll fill in a little bit more information today throughout our lecture. When I was learning how to teach, which I'm still doing, actually my PhD advisor told me if you want somebody to learn something, you have to write it as big as possible. And so I'm really leaning into that approach today in our slides. So in any event, so today we're going to have our first lecture on graphs which I think will somewhat be a review for many of you guys. And if it's not, that's cool too. Because we'll start from the beginning and kind of build up all the notions that we need to understand and process graphs and hopefully by the end of lecture, have some style of algorithm for computing the shortest path from one vertex to all the other ones.","70.25215911865234","4","DPRSearchEngine","oFVYVzlvk9c.en-j3PyPqV-e1s_2_mp4","oFVYVzlvk9c.en-j3PyPqV-e1s","6.006","9"
"183","How many edges can a simple path in a graph have at most?","but it's worth noting explicitly, is that we'll mostly be thinking about a particular type of graph which is a simple graph. And in fact often, depending on how you define your graph, you kind of accidentally made your graph simple even if you didn't intend to. So for example, we wrote that our edges were a subset of v cross v. Which maybe means that I can't have multiple edges that sort of traverse the same pair of vertices. So let's see an example of a graph that is not simple. So sorry, I haven't actually defined it. A simple graph is a graph that has no self loops, so it can't go from a vertex to itself, and every edge is distinct. So let's make the most non simple graph we can think of. Like let's say I have two vertices. So maybe if I want to make my-- so there's a graph, right, two vertices and one edge. This is simple. If I wanted to be annoying and make it not simple, maybe I take this edge and I'd duplicate it three times just for fun. That violates the second assumption. And now to make it even worse, I could violate the first one by adding an edge that goes from this vertex to itself. This is not simple. I don't know what you would call it actually-- general graph, I guess-- complicated because it's not simple. I don't know-- a multigraph. I always thought of that-- anyway, it doesn't matter. But in any event, in this class we're not going to worry about this particular circumstance. And of course, in many applications of graph theory that's a totally reasonable assumption to make. Any questions about the definition of a simple graph? OK, so from now on whenever we think about a graph, in the back of our head we're going to think of our graph as simple. There's one nice property that a simple graph has, which I've written in really big text on the screen here, which is that the edges are big O of v squared. And in fact, let's expand that formula just a tiny bit. So there's sort of two cases, one is when my graph is undirected, the other is when my graph is directed. So if I have a directed graph-- well, let's think about how many edges we could possibly have. So an edge is a pair of a from vertex and a to vertex, and I can never repeat it twice. That's sort of like the second assumption here. So in particular, what do we know? We know that mod E-- or rather the number of edges in our graph is upper bounded by what? Well, I can take any pair of vertices-- like that-- but I have to be a little bit careful because my graph is directed-- so from and to matter here. So this is v choose 2 is saying that I can take any unique pair of vertices, but I have to put a factor of 2 in front of it to account for the fact that the source and the target can be flip back and forth. And of course, if I want to do the undirected I don't have to worry about that. We'll get E here is less than or equal to just mod v choose 2. So this is just a fancy way of saying that every edge consists of two vertices, and my edges are unique. And one thing, if you just write down the formula for our binomial coefficient here, we'll see that both of these things-- oops, oh, yeah, sorry-- are at worse mod v squared here. And that makes perfect sense, because of course, an edge is a pair of vertices. You kind of expect there to be a square there. Yes? AUDIENCE: [INAUDIBLE] JUSTIN SOLOMON: I'm so sorry. I can't hear you. AUDIENCE: So the 2 comes from the fact that it's from the source. JUSTIN SOLOMON: Yes, exactly. So the 2 for the director case, comes from the fact that an edge from v to w is different than an edge from w to v. So remember that the binomial coefficient here, it's just counting the number of ways that I can choose two things from a set of size v, but it doesn't care about ordering. Yeah, any other questions? Fabulous. So why is this going to matter? Well, these sorts of bounds, I mean they might seem a little bit obvious to you, but we're going to write down graph algorithms. And now when we analyze the runtime and the space that they take, we now have sort of two different numbers that we can think about-- the number of vertices and the number of edges. And so for instance, if I write down an algorithm whose runtime is proportional to the number of edges, maybe then genErikally I could also think of the algorithm as having a runtime that looks like the number of vertices squared unless I put some additional assumptions on my graph. And so there's some connection between all of these different constants, and it's useful to kind of keep that at the back of our head. That sometimes you'll see a bunch of different expressions that really are encoding roughly the same relationship just in different language Of course, that also means that we can be more precise. So sometimes a graph is what we would call sparse. So in my universe, almost all graphs that I deal with in my day to day life are extremely sparse. This is a consequence of topology. And because of that, an algorithm that scales like the number of edges might actually be much preferable to an algorithm that scales like the number of vertices squared because, in practice, often there are fewer edges than like every single possible pair. And so that's the sort of reason why it's we're thinking about these numbers.","69.9017333984375","5","DPRSearchEngine","oFVYVzlvk9c.en-j3PyPqV-e1s_6_mp4","oFVYVzlvk9c.en-j3PyPqV-e1s","6.006","9"
"183","How many edges can a simple path in a graph have at most?","So we can use the notation here. And notice that there's basically an induction going on, which is I'm going to compute level set 1 from level set 0, level set 2 from level set 1, and so on, until I fill in all my level sets. Does that makes sense? So here's a slightly different way to notate the same thing. I'm going to use a WHILE loop, which I know is like slightly non-kosher, but that's OK. So I'm going to initialize a number i to be 1. This is going to be like our counter. I'm going to say WHILE the previous level set is not empty, meaning that potentially there's a path that goes through the previous level set into the next one. Because as soon as one of my levels is empty, notice that like the Li for even bigger i are also going to be empty. There's like never a case when there's something not distance i but then distance i plus 5. OK, so now what am I going to do? Well, let's think back to our graph. So like now I know that this guy is distance 0 away. That's what I started with. So now I'm going to look at all the neighbors of this vertex. And I'm going to make them distance 1 away. Does that makes sense? And similarly here, this guy is distance 2. And eventually I'm going to get in trouble because maybe-- well, what's a good example here. I won't even try to draw. I could run into trouble if I don't want to add a vertex twice to two different level sets. Once I've put it in Li then I don't want to put it in Li plus 5 because I already know that it's distance i away. Does that makes sense? OK, so what I'm going to do is I'm going to iterate over all the vertices in my previous level set. And now I'm going to look at every vertex that is adjacent to u. Because what do I know? I know that if I can get to u in i minus 1 steps, how many steps should it take me to get to any neighbor of u? i steps because I can go through the path, which is the length of i minus 1, add one additional edge, and I'll get to that new guy. So what can I do? I can iterate over all of v, which is in the adjacent set of u. But I have to be a little bit careful because what if I have an edge backwards? So like for instance, here I have an edge back to the source. I guess this is-- yeah, that's a valid example. I wouldn't want to add the source to the third level set because I already added it in the previous guy. So I want to get rid of the union of all of the previous level sets. Does that make sense? So in other words, I'm only going to look at the adjacent vertices that I haven't visited yet in my level set computational algorithm. And all I have to do is update my arrays, right. So in particular, I'm going to add vertex v to level set i because I haven't seen v yet. I'm going to set the distance from s to v equal to i because I'm currently filling in my level set i. And then finally what is p of v? What is the previous vertex to v in my shortest path from my source? It's u, right. Because that's the guy in the previous level set that I'm building my path from, right. I'm going to set that to u. And then-- sorry, I ran out of space-- but I also have to increment i. OK, so what does this algorithm do? It's just building one level set at a time. If we go back to our picture, so it starts by initializing L0 to just be the source vertex, then it looks at all the edges coming out of that-- in that case just one-- it makes that length 1-- and so on. And so this is just incrementally building up all these level sets. Now there's a pretty straightforward proof by induction that this algorithm correctly computes the L's the p's and the deltas which is all the information that we need to compute the shortest path. I think you guys can do that in your recitation if you still need a little bit of induction proof practice here. And the final thing that we should check is what is the runtime of this algorithm. I'm going to squeeze it in there just at the last second here. So let's take a look. So first of all, I did something a little-- oh, no it's OK-- in my algorithm actually in step zero I had to make an array which was the size equal to the number of vertices. Remember that in 6.006 how much time does it take to allocate memory? Yeah, it takes the amount of time proportional to the amount of memory that I allocate. So already-- Steph, I see your hand but we're low on time. So we're to make it to the end. Already we've incurred v time because our shortest pathway array takes v space. But in addition to that, we have this kind of funny FOR loop where for every node I have to visit all of its neighbors. But first of all, do I ever see a node of twice here? No, because I'm going in order of distance. And the second that I've seen a node in one level set, it can't be in another. That's our basic construction here. Well, conveniently for you guys, you already proved exactly the formula that we need. And if I'm lucky, I didn't trace it. Yeah, here we are. So if we take a look here, this is exactly the scenario that we're in. Because what did we do? We iterated over all the nodes in our graph, and then we iterated over all the neighbors of those nodes. And that's the basic computational time in our algorithm. So that FOR loop, or that WHILE loop rather, in my code is incurring time proportional to the number of edges. So what is the total run time for Breadth-First search? Well, we need to construct that array. So just at step zero, we've incurred v time. And then we have to iterate over something that takes up most the number of edges. So overall our algorithm takes big O of mod v plus mod e time. Now, notice that this is-- you might view this as kind of redundant. By the way this-- I have a little bit of a quibble with Jason. But in this class we will call this a linear time algorithm because it's linear in the space that you're using to store your graph. I think that's a little fishy personally because this scale could scale quadratically in v, but I digress. In any event, why do we need both of these terms here? Well, notice that if I had no edges in my graph, now this term is going to dominate. But as I add edges to my graph, this thing could go up to v squared. So this is somehow a more informative expression than just saying, well at worst this is v squared time. Does that makes sense? It's a slightly better formula to have. OK, so with that we just squeaked into the finish line. We have an algorithm for computing shortest paths. And I will see you guys again I guess on Tuesday.","69.73148345947266","6","DPRSearchEngine","oFVYVzlvk9c.en-j3PyPqV-e1s_14_mp4","oFVYVzlvk9c.en-j3PyPqV-e1s","6.006","9"
"183","How many edges can a simple path in a graph have at most?","That was very limiting, actually. That's a restriction. With 64 bits, what's my limitation on memory that I can address-- byte addressable? Turns out to be something like 20 exabytes-- to put this in context, all data that Google stores on their servers, on all drives throughout the world-- it's about 10.","69.71556091308594","7","DPRSearchEngine","ZA-tUyM_y7s.en-j3PyPqV-e1s_9_mp4","ZA-tUyM_y7s.en-j3PyPqV-e1s","6.006","1"
"183","How many edges can a simple path in a graph have at most?","a very non-intuitive one, where we use some prefix of the vertices. But notice, it's prefixes again-- a number of the vertices from 1 up to v. And I took a prefix of those vertices. So I just solved the problem using prefix vertices 1 through k. So it's actually a familiar idea. If all you had seen are all dynamic programming examples of prefixes, suffixes, substrings, actually, it's pretty natural way to solve shortest paths-- maybe even more natural than this. Anyway, all right. Enough shortest paths. Let's solve two more problems that are more in our standard wheelhouse that will involve sequences of inputs, not graphs.","69.35902404785156","8","DPRSearchEngine","TDo3r5M1LNo.en-j3PyPqV-e1s_9_mp4","TDo3r5M1LNo.en-j3PyPqV-e1s","6.006","17"
"183","How many edges can a simple path in a graph have at most?"," 
 
 
 
 
 
  
  
 
 
 
  
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
  
    
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
  
 
   
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
…cutting and pasting
…start with the smallest parse tree for !
…pick the lowest repetition of a variable
Pumping Lemma – Proof details 
For ! ∈# where ! ≥%, we have ! = '()*+ where: 
1) '(,)*,+ ∈ # for all - ≥0 
2) (* ≠ ε 
3) ()* ≤% 
Let 1 = the length of the longest right hand side of a rule (E → E+T) 
= the max branching of the parse tree 
E 
E 
Let ℎ= the height of the parse tree for !. 
E + T  
A tree of height ℎ and max branching 1 has at most 14 leaves. 
So ! ≤14 . 
5
Let % = 1 
+ 1 where 8 = # variables in the grammar. 
5 
|5|
So if ! ≥% > 1 
then ! > 1 
and so ℎ> 8 
R 
R 
. 
Thus at least 8 + 1 variables occur in the longest path. 
! = 
use ! > 1 5 
set % = 1 5 + 1 
'
( 
)
*
+ 
So some variable ; must repeat on a path. 
5 
want
ℎ > 8 
","69.33575439453125","9","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_5_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"183","How many edges can a simple path in a graph have at most?","that we've already seen in 6006? AUDIENCE: A tree. JUSTIN SOLOMON: A tree. At least if we orient all all the edges kind of pointing downward in the tree. Yeah. Otherwise, it gets kind of debatable over whether it's a DAG or not. If there's no direction to the edges, then somehow the definition just doesn't apply. OK. So in processing directed acyclic graphs, there's a really useful thing that you can do that's going to show up in this class apparently quite a bit, which is kind of interesting to me, I'm curious to see what that looks like, which is to compute a topological order on the graph. We're at topologies here.","69.2803726196289","10","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_16_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"184","How can the parent node index be computed from a given left or right child node index in a binary heap stored as an array?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","78.49685668945312","1","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"184","How can the parent node index be computed from a given left or right child node index in a binary heap stored as an array?","4 
Lecture 8: Binary Heaps 
Binary Heaps 
• Idea: keep larger elements higher in tree, but only locally 
• Max-Heap Property at node i: Q[i] ≥ Q[j] for j ∈{left(i), right(i)} 
• Max-heap is an array satisfying max-heap property at all nodes 
• Claim: In a max-heap, every node i satisﬁes Q[i] ≥ Q[j] for all nodes j in subtree(i) 
• Proof: 
– Induction on d = depth(j) − depth(i) 
– Base case: d = 0 implies i = j implies Q[i] ≥ Q[j] (in fact, equal) 
– depth(parent(j)) − depth(i) = d − 1 < d, so Q[i] ≥ Q[parent(j)] by induction 
– Q[parent(j)] ≥ Q[j] by Max-Heap Property at parent(j) 
• In particular, max item is at root of max-heap 
Heap Insert 
• Append new item x to end of array in O(1) amortized, making it next leaf i in reading order 
• max heapify up(i): swap with parent until Max-Heap Property 
– Check whether Q[parent(i)] ≥ Q[i] 
(part of Max-Heap Property at parent(i)) 
– If not, swap items Q[i] and Q[parent(i)], and recursively max heapify up(parent(i)) 
• Correctness: 
– Max-Heap Property guarantees all nodes ≥ descendants, except Q[i] might be > some 
of its ancestors (unless i is the root, so we’re done) 
– If swap necessary, same guarantee is true with Q[parent(i)] instead of Q[i] 
• Running time: height of tree, so Θ(log n)! 
","76.99357604980469","2","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_4_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"184","How can the parent node index be computed from a given left or right child node index in a binary heap stored as an array?","&

	
	
	/
def greedy(items, maxCost, keyFunction):
itemsCopy = sorted(items, key = keyFunction,
reverse = True)
result = []
totalValue, totalCost = 0.0, 0.0
for i in range(len(itemsCopy)):
if (totalCost+itemsCopy[i].getCost()) <= maxCost:
result.append(itemsCopy[i])
totalCost += itemsCopy[i].getCost()
totalValue += itemsCopy[i].getValue()
return (result, totalValue) 
	

2
	

","76.52783203125","3","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_24_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"184","How can the parent node index be computed from a given left or right child node index in a binary heap stored as an array?","4 
Lecture 1: Introduction 
1 
def birthday_match(students): 
2 
’’’ 
3 
Find a pair of students with the same birthday 
4 
Input: 
tuple of student (name, bday) tuples 
5 
Output: tuple of student names or None 
6 
’’’ 
7 
n = len(students) 
# O(1) 
8 
record = StaticArray(n) 
# O(n) 
9 
for k in range(n): 
# n 
10 
(name1, bday1) = students[k] 
# O(1) 
11 
# Return pair if bday1 in record 
12 
for i in range(k): 
# k 
13 
(name2, bday2) = record.get_at(i) 
# O(1) 
14 
if bday1 == bday2: 
# O(1) 
15 
return (name1, name2) 
# O(1) 
16 
record.set_at(k, (name1, bday1)) 
# O(1) 
17 
return None 
# O(1) 
Example: Running Time Analysis 
• Two loops: outer k ∈{0, . . . , n − 1}, inner is i ∈{0, . . . , k}
P n−1
• Running time is O(n) + 
k=0 (O(1) + k · O(1)) = O(n2) 
• Quadratic in n is polynomial. Efﬁcient? Use different data structure for record! 
How to Solve an Algorithms Problem 
1. Reduce to a problem you already know (use data structure or algorithm) 
Search Problem (Data Structures) 
Sort Algorithms 
Static Array (L01) 
Insertion Sort (L03) 
Linked List (L02) 
Selection Sort (L03) 
Dynamic Array (L02) 
Merge Sort (L03) 
Sorted Array (L03) 
Counting Sort (L05) 
Direct-Access Array (L04) 
Radix Sort (L05) 
Hash Table (L04) 
AVL Sort (L07) 
Balanced Binary Tree (L06-L07) 
Heap Sort (L08) 
Binary Heap (L08) 
2. Design your own (recursive) algorithm 
• Brute Force 
• Decrease and Conquer 
• Divide and Conquer 
• Dynamic Programming (L15-L19) 
• Greedy / Incremental 
Shortest Path Algorithms 
Breadth First Search (L09) 
DAG Relaxation (L11) 
Depth First Search (L10) 
Topological Sort (L10) 
Bellman-Ford (L12) 
Dijkstra (L13) 
Johnson (L14) 
Floyd-Warshall (L18) 
","75.57911682128906","4","DPRSearchEngine","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_4_pdf","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1","6.006","1"
"184","How can the parent node index be computed from a given left or right child node index in a binary heap stored as an array?","I'll call them left justified. And these two properties together is what I call a complete binary tree. Why is this interesting? Because I claim I can represent a tree like this as an array. I've narrowed things down enough that I can draw an array down here. And what I'm going to do is write these nodes in depth order. So I write A first, because that's step 0. Then B, C, that's step 1. Then, well, they're alphabetical. I made it that way. D, E, F, G is depth 2. And then H, I, J is step 3. This is very different from traversal order of a tree. Traversal order would have been H, D, I, B, J, E, A, F, C, G, OK? But this is what we might call depth order, do the lowest depth nodes first-- very different way to lay things out or to linearize our data. And this is what a heap is going to look like. So the cool thing is, between complete binary trees and arrays is a bijection. For every array, there's a unique complete binary tree. And for every complete binary tree, there's a unique array. Why? Because the complete constraint forces everything-- forces my hand. There's only-- if I give you a number n, there is one tree shape of size n, right? You just fill in the nodes top down until you get to the last level. And then you have to fill them in left to right. It's what you might call reading order for writing down nodes. And the array is telling you which keys go where. This is the first node you write down at the root, this is the next node you write down at the left child of the root, and so on. So here we have a binary tree represented as an array, or array representing a binary tree. The very specific binary tree, it has a clear advantage, which is it is guaranteed balance. No rotations necessary in heaps, because complete binary trees are always balanced. In fact, they have the best height they possibly could, which is ceiling of log n. Balanced, remember, just meant you were big O of log n. This is 1 times log n. So it's the best level of balance you could hope for. So somehow, I claim, we can maintain a complete binary tree for solving priority queues. This would not be possible if you were trying to solve the whole set interface. And that's kind of the cool thing about heaps, is that by just focusing on the subset of the set interface, we can do more. We can maintain this very strong property. And because we have this very strong property, we don't even need to store this tree. We're not going to store left and right pointers and parent pointers, we're just going to store the array.","75.55169677734375","5","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_8_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"184","How can the parent node index be computed from a given left or right child node index in a binary heap stored as an array?","If you think about it a little bit, this is exactly binary search on an array. It just happens to be on a tree instead. If you think of an array like this, what does binary search do? It first looks at the key in the middle. I'm going to draw that as the root. And then, it recurses either on the left chunk, which I will draw recursively, or on the right chunk. And so if you happen to have a perfect binary tree like this one, it is simulating exactly binary search in this array. But this we're going to be able to maintain dynamically-- not perfect any more, but close. Whereas this we could not maintain in sorted order. So this is like a generalization of binary search to work on trees instead of on arrays. And for this reason, set binary trees are called binary search trees, because they're the tree version of binary search. So there's many equivalent names. So binary search tree is another name for set binary tree. And the key thing that makes this algorithm work is the so-called binary search tree property, which is all the keys in the left subtree of a node are less than the root, or of that node, and that key is less than all the keys in the right subtree. And this is true recursively all the way down. And so that's how you prove that this algorithm is correct by this property. Why is this true? Because if we can maintain traversal order to be increasing key, then that's exactly what traversal order means. It tells you all the things in the left subtree come before the root, which come before all the things in the right subtree.","75.16554260253906","6","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_4_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"184","How can the parent node index be computed from a given left or right child node index in a binary heap stored as an array?"," ! 
dist, numSamples = [], 1000000
for i in range(numSamples):
dist.append(random.gauss(0, 100))
weights = [1/numSamples]*len(dist)
v = pylab.hist(dist, bins = 100,
weights = [1/numSamples]*len(dist))
pylab.xlabel('x')
pylab.ylabel('Relative Frequency')
print('Fraction within ~200 of mean =',
sum(v[0][30:70]))
	

""
","75.10865783691406","7","DPRSearchEngine","3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7_3_pdf","3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7","6.0002","7"
"184","How can the parent node index be computed from a given left or right child node index in a binary heap stored as an array?"," &&%$3$%'9
class Digraph(object): 
 """"""edges is a dict mapping each node to a list of 
    its children""""” 
    def __init__(self): 
self.edges = {} 
    def addNode(self, node): 
if node in self.edges: 
 raise ValueError('Duplicate node') 
else: 
self.edges[node] = [] 
    def addEdge(self, edge): 
src = edge.getSource() 
dest = edge.getDestination() 
if not (src in self.edges and dest in self.edges): 
raise ValueError('Node not in graph') 
self.edges[src].append(dest) 
Q>KKKMN
LS
mapping each node 
list 
","75.00363159179688","8","DPRSearchEngine","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_18_pdf","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3","6.0002","3"
"184","How can the parent node index be computed from a given left or right child node index in a binary heap stored as an array?","We're almost done. This will actually work. It's really quite awesome. But for it to work, we need something called subtree augmentation, which I'll talk about generally. And then, we'll apply it to size. So the idea with subtree augmentation is that each node in our binary tree can store a constant number of extra fields. Why not? And in particular, if these fields are of a particular type-- maybe I'll call them properties. I'm going to define a subtree property to be something that can be computed from the properties of the nodes' children. So I should say this is of a node. So children are node.left and node.right. You can also access constant amount of other stuff,","74.91542053222656","9","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_9_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"184","How can the parent node index be computed from a given left or right child node index in a binary heap stored as an array?"," 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 6: Binary Trees I 
Lecture 6: Binary Trees I 
Previously and New Goal 
Sequence 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
build(X) 
get at(i) 
set at(i,x) 
insert first(x) 
delete first() 
insert last(x) 
delete last() 
insert at(i, x) 
delete at(i) 
Array 
n 
1 
n 
n 
n 
Linked List 
n 
n 
1 
n 
n 
Dynamic Array 
n 
1 
n 
1(a) 
n 
Goal 
n 
log n 
log n 
log n 
log n 
Set 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
Direct Access Array 
u 
1 
1 
u 
u 
Hash Table 
n(e) 
1(e) 
1(a)(e) 
n 
n 
Goal 
n log n 
log n 
log n 
log n 
log n 
How? Binary Trees! 
• Pointer-based data structures (like Linked List) can achieve worst-case performance 
• Binary tree is pointer-based data structure with three pointers per node 
• Node representation: node.{item, parent, left, right} 
• Example: 
1 
2 
3 
4 
5 
________<A>_____ 
__<B>_____ 
<C> 
__<D> 
<E> 
<F> 
node 
| 
item 
| 
parent | 
left 
| 
right 
| 
<A> | 
A 
| 
-
| 
<B> | 
<C> | 
<B> 
B 
<A> 
<C> 
<D> 
| 
| 
| 
| 
| 
<C> | 
C 
| 
<A> | 
-
| 
-
| 
<D> | 
D 
| 
<B> | 
<F> | 
-
| 
<E> | 
E 
| 
<B> | 
-
| 
-
| 
<F> 
F 
<D> 
-
-
| 
| 
| 
| 
| 
","74.79997253417969","10","DPRSearchEngine","376714cc85c6c784d90eec9c575ec027_MIT6_006S20_lec6_1_pdf","376714cc85c6c784d90eec9c575ec027_MIT6_006S20_lec6","6.006","6"
"186","Why is time complexity critical in the learning algorithms used in autonomous driving systems?"," 
 
 
 
  
 
 
  
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Intro to Complexity Theory 
Computability theory (1930s - 1950s): 
Is A decidable? 
Complexity theory (1960s - present): 
Is A decidable with restricted resources? 
(time/memory/…) 
Example: Let ! = a#b# $ ≥0 . 
Q: How many steps are needed to decide !? 
Depends on the input. 
We give an upper bound for all inputs of length '. 
Called “worst-case complexity”. 
2 
","75.8416519165039","1","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_2_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"186","Why is time complexity critical in the learning algorithms used in autonomous driving systems?","now, quickly is not so quick right now. Because everything is order h. And in the worst case, h is linear. Because we can have a tree like this. But today, we're going to make-- we're going to guarantee that h is log n. And so the goal of today is to take all of these operations that run in order h time and get them to run an order log n time, just by modifying the data structure we've already seen. So we've done a lot of the hard work, just a little bit more work we need to do today on something called","70.46968841552734","2","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_2_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"186","Why is time complexity critical in the learning algorithms used in autonomous driving systems?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","70.43376922607422","3","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"186","Why is time complexity critical in the learning algorithms used in autonomous driving systems?"," 
 
 
 
 
 
 
 
 
Machine  Learning Paradigm  
§Observe set of examples: training data 
§Infer something about process that generated that 
data 
§Use inference to make predictions about previously 
unseen data: test data 
§Supervised: given a set of feature/label pairs, find a 
rule that predicts the label associated with a previously 
unseen input 
§Unsupervised: given a set of feature vectors (without 
labels) group them into “natural clusters” 
6.0002  LECTURE 12 
3 
","70.08756256103516","4","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_3_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"186","Why is time complexity critical in the learning algorithms used in autonomous driving systems?"," 
 
  
  
 
 
 
 
 
 
   
 
 
 
 
  
 
  
 
  
 
 
  
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
   
 
    
   
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
   
  
Time Hierarchy Theorem (1/2) 
Theorem: For any !: ℕ → ℕ where ! is time constructible 
there is a language % where % requires & ! ' 
time, i.e, 
1) % is decidable in & ! ' 
time, and 
2) % is not decidable in ( ! ' / log ! ' 
time 
- .
On other words, TIME (
⊆, TIME ! ' 
/01 - . 
Proof outline:  Give TM 3 where 
1) 3 runs in & ! ' 
time 
2) 3 ensures that 4(3) ≠ 4(8) for every TM 8 that runs in ( ! ' / log ! ' 
time . 
Let % = 4(3). 
10 
","69.99534606933594","5","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_10_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"186","Why is time complexity critical in the learning algorithms used in autonomous driving systems?","§ Time based on number of nodes generated 
§ Number of levels is number of items to choose from 
§ Number of nodes at level i is 2i 
§ So, if there are n items the number of nodes is 
◦ ∑𝑖=0↑𝑖=𝑛▒​2↑𝑖   
◦ I.e., O(​2↑𝑛+1 ) 
§ An obvious op<miza<on: don’t explore parts of tree 
that violate constraint (e.g., too many calories) 
◦ Doesn’t change complexity 
§ Does this mean that brute force is never useful? 
◦ Let’s give it a try 
Computa#onal Complexity 
6.0002 LECTURE 2 
8 
","69.83914947509766","6","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_8_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"186","Why is time complexity critical in the learning algorithms used in autonomous driving systems?"," 
 
 
   
 
 
 
   
   
      
 
 
 
 
 
 
  
 
Stochastic Processes  
An ongoing process where the next state might depend on 
both the previous states and some random element 
def rollDie(): 
"""""" returns an int between 1 and 6"""""" 
def rollDie(): 
"""""" returns a randomly chosen int 
between 1 and 6"""""" 
6.0002 LECTURE 4 
8
","69.75308990478516","7","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_8_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"186","Why is time complexity critical in the learning algorithms used in autonomous driving systems?","§ Problem is exponen<al 
§ Have we overturned the laws of the universe? 
§ Is dynamic programming a miracle? 
§ No, but computa<onal complexity can be subtle 
§ Running <me of fastMaxVal is governed by number of 
dis<nct pairs, <toConsider, avail> 
◦Number of possible values of toConsider bounded 
by len(items)
◦Possible values of avail a bit harder to characterize 
◦Bounded by number of dis<nct sums of weights 
◦Covered in more detail in assigned reading 
How Can This Be? 
6.0002 LECTURE 2 
30 
","69.53589630126953","8","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_30_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"186","Why is time complexity critical in the learning algorithms used in autonomous driving systems?","Many problems of practical importance can be formulated as optimization problems. Greedy algorithms often provide an adequate though often not optimal solution. Even though finding an optimal solution is, in theory, exponentially hard, dynamic programming really often yields great results. It always gives you a correct result and it's sometimes, in fact, most of the times gives it to you very quickly. Finally, in the PowerPoint, you'll find an interesting optimization problem","69.41421508789062","9","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_15_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"186","Why is time complexity critical in the learning algorithms used in autonomous driving systems?"," 
 
 
 
 
 
 
 
 
  
 
  
 
   
 
 
 
 
  
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Model Dependence 
Number of steps to decide ! = a#b# $ ≥0 depends on the model. 
• 1-tape TM: '() log )) 
• Multi-tape TM: '()) 
Computability theory: model independence (Church-Turing Thesis) 
Therefore model choice doesn’t matter. Mathematically nice. 
Complexity Theory: model dependence 
But dependence is low (polynomial) for reasonable deterministic models. 
We will focus on questions that do not depend on the model choice. 
So… we will continue to use the 1-tape TM as the basic model for complexity. 
6 
","69.11026763916016","10","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_6_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"187","What is the reachability problem in graph theory?","§ Time based on number of nodes generated 
§ Number of levels is number of items to choose from 
§ Number of nodes at level i is 2i 
§ So, if there are n items the number of nodes is 
◦ ∑𝑖=0↑𝑖=𝑛▒​2↑𝑖   
◦ I.e., O(​2↑𝑛+1 ) 
§ An obvious op<miza<on: don’t explore parts of tree 
that violate constraint (e.g., too many calories) 
◦ Doesn’t change complexity 
§ Does this mean that brute force is never useful? 
◦ Let’s give it a try 
Computa#onal Complexity 
6.0002 LECTURE 2 
8 
","69.60677337646484","1","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_8_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"187","What is the reachability problem in graph theory?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","69.03765869140625","2","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"187","What is the reachability problem in graph theory?","But of course, there's sort of many variations on that theme when we talk about shortest path or even just existence of a path. So these are three sort of model problems that we might solve on a graph. So the first one, which in this of course we're calling the single pair reachability, would be the idea that I take two vertices s and t on my graph g, and I ask you does there exists a path between s and t. So what would be the sort of extreme example where this problem may not always give back the answer yes? Somehow in our head, I think we think of all graphs as being connected. But a perfectly valid graph the way we've defined it would be like 10 vertices and no edges. This function would be very easy to code if that were the only graph you ever cared about. But any event, the existence of a path is already a query that takes a little bit of algorithmic thinking. We haven't figured out how to do that yet. Now another problem we can solve would be the shortest path. Given a graph and two vertices, we might say, well, how far apart are these vertices of my graph if I want to use the shortest possible distance from one to the other. Notice that I can use the second problem to solve the first one. Because what's the length of the shortest path between two vertices that don't have a path between them? Infinity or a shrug-- that's actually a totally valid answer. Yeah, that's right. So how could I implement the reachability code? Well, I could call my shortest path code, and it gives me infinity. Then I return no, it's not reachable. And if it gives me not infinity, I return yes. So remember that a key idea in an algorithms class is this idea of reduction. That I can use one function to solve another. So in case, if we can solve shortest path, then we can certainly solve the reachability problem by calling that piece of code. And then finally we could talk about single source shortest path. So notice now that there's only one input node here s-- so what this problem is saying is give me the length of the shortest path from s to every single other vertex in my graph. Does that makes sense? Like maybe I return a big array with all the information, every single shortest distance. So can we solve single pair shortest path using single source shortest path? Absolutely. I could take s in my single pair shortest path problem, compute the shortest path from s to literally everything else, and then throw away all of that information except the shortest path to t, and now I'm good. Now I haven't justified that this is the fastest possible way to solve that second problem, but at least it shows that if I can solve problem three I can also solve problem two. If I can solve from two I can also solve problem one. So in today's lecture, we're just going to worry about problem three. In other words, these things are sort of listed in increasing order of their difficulty. OK, so in order to think about the single source shortest path problem, we're going to make one additional construction. And this is an idea called the shortest path tree. I got lazy drawing PowerPoint slides at 2:00 AM yesterday,","68.90699005126953","3","DPRSearchEngine","oFVYVzlvk9c.en-j3PyPqV-e1s_10_mp4","oFVYVzlvk9c.en-j3PyPqV-e1s","6.006","9"
"187","What is the reachability problem in graph theory?","[SQUEAKING] [RUSTLING] [CLICKING] MICHAEL SIPSER: Greetings, everybody. Welcome to our last lecture of the term. We have survived a semester online in 18.404 and we are going to conclude our last topic today, which is interactive proof systems that we started last time. And with the big-- well, the big theorem of interactive proof systems is that IP equals PSPACE. And we're going to give the main idea for that in a slightly weaker theorem, as we'll see. So why don't we jump in? So we have been doing interactive proofs. We gave an example of showing that the graph isomorphism problem, the complement of that is an IP, as I hope you remember. We had that interaction with the approver and a verifier. We're going to go through it quickly. Not that protocol, but just the setup. And then we're going to finish by showing that this number SAT problem is an IP and should conclude that coNP is a subset of IP. All right, so let's go for it. Yes.","68.15955352783203","4","DPRSearchEngine","eEXSv0jChO4.en-j3PyPqV-e1s_1_mp4","eEXSv0jChO4.en-j3PyPqV-e1s","18.404J","26"
"187","What is the reachability problem in graph theory?","in general graphs, which we know as Bellman-Ford, but rephrased into the SRTBOT framework. So we defined this problem, in the Bellman-Ford lecture, delta sub k of s, v. Remember, this was the weight of a shortest path from s to v that is restricted to use, at most, k edges. This made the problem feasible. We ended up taking the product of the graph into all of these different subproblems, in fact.","68.0871353149414","5","DPRSearchEngine","TDo3r5M1LNo.en-j3PyPqV-e1s_4_mp4","TDo3r5M1LNo.en-j3PyPqV-e1s","6.006","17"
"187","What is the reachability problem in graph theory?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 10: Depth-First Search 
Lecture 10: Depth-First Search 
Previously 
• Graph deﬁnitions (directed/undirected, simple, neighbors, degree) 
• Graph representations (Set mapping vertices to adjacency lists) 
• Paths and simple paths, path length, distance, shortest path 
• Graph Path Problems 
– Single Pair Reachability(G,s,t) 
– Single Source Reachability(G,s) 
– Single Pair Shortest Path(G,s,t) 
– Single Source Shortest Paths(G,s) (SSSP) 
• Breadth-First Search (BFS) 
– algorithm that solves Single Source Shortest Paths 
– with appropriate data structures, runs in O(|V | + |E|) time (linear in input size) 
Examples 
G1 
a 
d 
b 
e 
c 
f 
G2 
a 
d 
b 
e 
c 
f 
","67.48286437988281","6","DPRSearchEngine","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10_1_pdf","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10","6.006","10"
"187","What is the reachability problem in graph theory?","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","67.47193908691406","7","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"187","What is the reachability problem in graph theory?","Intuition for P and NP
NP = All languages where can verify membership quickly
P  = All languages where can  test membership quickly
Examples of quickly verifying membership:
- !""#$""%!:  Give the Hamiltonian path. 
- &'#$'()%*(:  Give the factor. 
The Hamiltonian path and the factor are called short certificates of membership.
P ⊆NP
Question:  P = NP?  Famous unsolved problem (Cook 1971).
Conjecture:  P ≠ NP.   Some problems are NP and not in P. 
Hard to prove the conjecture because polynomial-time algorithms are powerful.
Example:  Show ""CFG ∈P.
NP
P
Check-in 14.1
Check-in 14.1
Let !""#$""%! be the complement of !""#$""%!.
So 0, 2, 3 ∈!""#$""%! if 0 does not have a Hamiltonian path from 2 to 3.  
Is !""#$""%! ∈NP?
(a) Yes, we can invert the accept/reject output of the NTM for !""#$""%!. 
(b) No, we cannot give a short certificate for a graph not to have a Hamiltonian path. 
(c) I don’t know.
6
","67.4173812866211","8","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_6_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"187","What is the reachability problem in graph theory?","Right. Now, does DFS ever visit a vertex that is not reachable from the source? Well, the answer is no because all I ever do is recursively call on my neighbors. And so kind of by definition, if I'm not reachable, DFS will never see it. So if I think about my runtime carefully, it's not quite the same as breadth-first search. Remember that breadth-first search took v plus e time. In depth-first search, it just takes order e time because I'm expanding outward from the source vertex, hitting every edge adjacent to every vertex that I've seen so far. But I never reach a vertex that I haven't-- that isn't reachable. Right? And so because this only ever touches every edge one time, we're in good shape. And I see a question here. Yeah. AUDIENCE: Does BFS reach vertices that are not reachable? JUSTIN SOLOMON: Does BFS reach vertices that are not reachable? I guess not, now that you mention it. But at least in my boring proof of order v time last time, our very first step of BFS, reserve space proportional to v, which is enough to already make that runtime correct. Good question. Yeah. So I guess the way that we've talked about it where you can stretch one little set after a time, if you think of that as reachability, then no. It doesn't reach it in the for loop. But just by construction, when we started we already took the time that we're talking about here. So notice these run times aren't exactly the same. So for example, if my graph has no edges, BFS still is going to take time because it still has to take order v time, at least in the sort of brain-dead way that we've implemented it last time. Obviously, in that case, we could probably do something better. Whereas the way that we've defined the DFS algorithm, it only takes edge time. I see confusion on my instructor's face. No? OK. Good. The one thing to notice is that these are algorithms for slightly different tasks in some sense. The way that we wrote down breadth-first search last time, conveniently, it gives us the shortest path. There are breadth-first search algorithms that doesn't. I think in this class we kind of think of breadth-first search-- we motivate it in terms of the shortest path problem. But it's just kind of a strategy of working outwards from a vertex. Whereas here, the way we've written down depth-first search, there's no reason why the path that we get should be the shortest. Right? So to think of a really extreme example, let's say that I have a cycle graph. So I get a big loop like this. Let's say that I do depth-first search starting from this vertex. Well, what will happen? Well, this guy will call its neighbor recursively, who will then call its neighbor recursively, who will then call his neighbor recursively, and so on. So of course, when I do depth-first search, when I get to this vertex, there's a chain of 1, 2, 3, 4 vertices behind it. Is that the shortest path from the source to the target here? Well, clearly not. Right? I could have traversed that edge. I just chose not to. OK. So that's the depth-first search algorithm. It's just essentially a recursive strategy where I traverse all my neighbors, and each of my neighbors traverses their neighbors, and so on. OK. So why might we want to use this algorithm? Well, we've already solved the reachability problem. So let's solve a few more things using the same basic strategy here. So there's some notions that we've sort of-- actually, in some sense, already used in the lecture here. But we might as well call them out","67.21788787841797","9","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_11_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"187","What is the reachability problem in graph theory?","It changes names every once in a while. And I mentioned it in the hardness complexity lecture, because this class is all about hardness proofs, analyzing fun games and puzzles. We saw the Tetris NP-hardness in that lecture. But you can also prove Super Mario Brothers is hard, or Portal is hard, or Mario Kart is hard, or The Witness, a modern video game, is hard. Or, one of our latest results is that Recurse-- that game in the top right-- is undecidable. There's no algorithm to play that game perfectly. And you can even download the level-- an example of the level and play it, if you dare. So that's a lot of-- we have a lot of fun in that world of hardness of different games and puzzles. Where do I want to go next? OK. Next topic is balloon twisting. Totally different. This is recreational, but not about hardness. This is an octahedron twisted from one balloon. I made another one on a stick. Each of these is made for one balloon. What graphs can you make for one balloon? Well, you should read our paper.","67.1463623046875","10","DPRSearchEngine","4nXw-f6NJ9s.en-j3PyPqV-e1s_6_mp4","4nXw-f6NJ9s.en-j3PyPqV-e1s","6.006","21"
"188","How can we use a path tree to solve the reachability problem in a graph?","Longest path is maybe a problem we've talked about in problem session, because it's a DAG-- well, longest path is the same thing as shortest path, if you just negate all the weights. There are no weights in this picture, so if you just put negative 1 on all these edges and ask for the shortest path from the base to anywhere-- so single source shortest paths from this base-- then we would end up getting this path, which, if you look at it, is E-M-P-T-Y, empty. And so that shortest path is indeed the right answer. What I've drawn here is the shortest path tree. So also, if you wanted the longest increasing subsequence starting at A, then it is A-T-Y, just by following the red arrows here. And how do you get that? You just draw the parent pointers, just like we did before.","73.83416748046875","1","DPRSearchEngine","KLBCUx1is2c.en-j3PyPqV-e1s_8_mp4","KLBCUx1is2c.en-j3PyPqV-e1s","6.006","16"
"188","How can we use a path tree to solve the reachability problem in a graph?","single source shortest paths in linear time. Last time we discussed another linear time algorithm, DAG relaxation. And today we're going to be talking about Bellman-Ford, which isn't limited to asymptotic graphs. In particular, there could be negative weight cycles in our graph. If it has cycles, if it has negative weights, the worry is that we could have negative weight cycles, in which case there-- if a negative weight cycle is reachable from our source, then the vertices in that cycle and anything reachable from that cycle will potentially","73.36458587646484","2","DPRSearchEngine","f9cVS_URPc0.en-j3PyPqV-e1s_2_mp4","f9cVS_URPc0.en-j3PyPqV-e1s","6.006","12"
"188","How can we use a path tree to solve the reachability problem in a graph?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","72.68708801269531","3","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"188","How can we use a path tree to solve the reachability problem in a graph?","that we've already seen in 6006? AUDIENCE: A tree. JUSTIN SOLOMON: A tree. At least if we orient all all the edges kind of pointing downward in the tree. Yeah. Otherwise, it gets kind of debatable over whether it's a DAG or not. If there's no direction to the edges, then somehow the definition just doesn't apply. OK. So in processing directed acyclic graphs, there's a really useful thing that you can do that's going to show up in this class apparently quite a bit, which is kind of interesting to me, I'm curious to see what that looks like, which is to compute a topological order on the graph. We're at topologies here.","72.38663482666016","4","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_16_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"188","How can we use a path tree to solve the reachability problem in a graph?","Minimum Spanning Tree-- so I'm trying to find a tree connecting all of the vertices in a connected component of my graph. And I'm trying to find-- in a weighted graph, I'm trying to find the spanning tree that has minimum total weight. So that's a problem-- a fundamental problem in weighted-graph algorithms. They've solved this via a greedy algorithm. And network flows and I guess cuts. So this is-- what is this? This is, I'm given a weighted graph. Basically, each of the weights correspond to a capacity. I could push water through along this edge. And I may be given a source vertex and a sink vertex. And I want to say, I want to shove water through the source vertex along the edges with their various capacities. And I'll get some amount of water on the other end in the source. So the question is, what's the most amount of water that I can push through this? Well, I could build that pipe network with the different things and just do this experimentally. I just stick a bunch of-- maybe-- I'm a mechanical engineer, so that maybe makes sense to me. But you want to be able to just look at those numbers and be able to tell me how much water can I push through. That's what the max flow in a network is talking about.","72.08851623535156","5","DPRSearchEngine","2NMtS1ecb3o.en-j3PyPqV-e1s_7_mp4","2NMtS1ecb3o.en-j3PyPqV-e1s","6.006","20"
"188","How can we use a path tree to solve the reachability problem in a graph?","If you compare these two classes, P and NP. P, first of all, is going to be a subset of NP, both in terms of the way we defined it because, deterministic machines are a special case of non-deterministic machines. But also if you want to think about testing membership, if you can test membership easily then you can certainly verify it in terms of the certificate. You don't even need it. The certificate is irrelevant at that point. Because whatever the certificate is, you can still test yourself whether the input is in the language or not. The big question, as I mentioned, is whether these two classes are the same. So does being able to verify membership quickly, say with one of these certificates, allow you to dispense with the certificate? Not even need a certificate and just test it for yourself whether you're in the language. And do that in polynomial time. That's the question. For a problem like Hamiltonian path, do you need to search for the answer if you're doing it deterministically? Or can you somehow avoid that and just come up with the answer directly with a polynomial time solution? Nobody knows the answer to that. And it goes back, at this point, quite a long time. It's almost 60 years now. That problem has been around 60 years. No, that would be 50 years. No, 50 years, almost 50 years. Most people believe that P is different from NP. In other words, that there are problems in P-- in NP which are not in P. A candidate would be the Hamiltonian path problem. But it seems to be very hard to prove that. And part of the reason is, how do you prove that a problem like Hamiltonian path does not have a polynomial time algorithm. It's very tricky to do that, because the class of polynomial time algorithms is a very rich class. Polynomial time algorithms are very powerful. And to try to prove-- there's no clever way of solving the Hamiltonian path problem. It just seems to be beyond our present day mathematics. I believe someday somebody's going to solve it. But so far, no one has succeeded. So what I thought we would do is-- I think I have a check-in here.","71.81937408447266","6","DPRSearchEngine","1VhnDdQsELo.en-j3PyPqV-e1s_8_mp4","1VhnDdQsELo.en-j3PyPqV-e1s","18.404J","14"
"188","How can we use a path tree to solve the reachability problem in a graph?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 10: Depth-First Search 
Lecture 10: Depth-First Search 
Previously 
• Graph deﬁnitions (directed/undirected, simple, neighbors, degree) 
• Graph representations (Set mapping vertices to adjacency lists) 
• Paths and simple paths, path length, distance, shortest path 
• Graph Path Problems 
– Single Pair Reachability(G,s,t) 
– Single Source Reachability(G,s) 
– Single Pair Shortest Path(G,s,t) 
– Single Source Shortest Paths(G,s) (SSSP) 
• Breadth-First Search (BFS) 
– algorithm that solves Single Source Shortest Paths 
– with appropriate data structures, runs in O(|V | + |E|) time (linear in input size) 
Examples 
G1 
a 
d 
b 
e 
c 
f 
G2 
a 
d 
b 
e 
c 
f 
","71.60746002197266","7","DPRSearchEngine","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10_1_pdf","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10","6.006","10"
"188","How can we use a path tree to solve the reachability problem in a graph?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","71.60237121582031","8","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"188","How can we use a path tree to solve the reachability problem in a graph?","  
 
  
 
 
 
  
 
 
 
 
 
   
 
 
 
 
  
 
 
 
  
 
  
   
 
  
 
 
  
  
  
 
 
 
 
 
 
  
  
 
 
 
 
 
 
 
  
 
 
 
 
   
 
 
 
 
 
  
 
 
Example: Ladder Problem 
A ladder is a sequence of strings of a common length where 
WORK
consecutive strings differ in a single symbol. 
PORK 
A word ladder for English is a ladder of English words. 
PORT 
SORT
Let ! be a language. A ladder in ! is a ladder of strings in !. 
SOOT 
Defn: ""!##$%DFA = *, ,, ­
* is a DFA and ""(*) contains 
SLOT 
a ladder 01, 02, … , 04 where 01 = , and 04 = -}. 
PLOT 
Theorem: ""!##$%DFA ∈ NPSPACE 
PLOY 
PLAY
PLAY 
7 
","71.27980041503906","9","DPRSearchEngine","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17_7_pdf","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17","18.404J","17"
"188","How can we use a path tree to solve the reachability problem in a graph?","[SQUEAKING][RUSTLING][CLICKING] JASON KU: Welcome, everybody, to our lecture 14 of 6.006. This is our last lecture on graph algorithms, in particular, the last lecture we'll have on weighted shortest paths. But we're going to talk about a slightly different problem today, different than single source shortest paths. We're going to be talking about all-pairs shortest paths. But first, let's review our single source shortest paths algorithms. We had BFS, DAG relaxation, Dijkstra, which we saw last time, which gets pretty close to linear. V log V plus E is pretty close to linear. It's much closer to linear than the general algorithm we have for solving single source shortest paths, namely, Bellman-Ford, which is a little bit more like quadratic. This is like the difference between-- for sparse graphs, this is like the difference between sorting, using insertion sort and n squared, and merge sort in N log N, for example. We're going to get actually quite a big bonus for large input sizes by using Dijkstra when we can. Today, we're going to be focusing","71.27364349365234","10","DPRSearchEngine","EmSmaW-ud6A.en-j3PyPqV-e1s_1_mp4","EmSmaW-ud6A.en-j3PyPqV-e1s","6.006","14"
"189","Why might a path from a path tree not be the shortest path?","Longest path is maybe a problem we've talked about in problem session, because it's a DAG-- well, longest path is the same thing as shortest path, if you just negate all the weights. There are no weights in this picture, so if you just put negative 1 on all these edges and ask for the shortest path from the base to anywhere-- so single source shortest paths from this base-- then we would end up getting this path, which, if you look at it, is E-M-P-T-Y, empty. And so that shortest path is indeed the right answer. What I've drawn here is the shortest path tree. So also, if you wanted the longest increasing subsequence starting at A, then it is A-T-Y, just by following the red arrows here. And how do you get that? You just draw the parent pointers, just like we did before.","69.76222229003906","1","DPRSearchEngine","KLBCUx1is2c.en-j3PyPqV-e1s_8_mp4","KLBCUx1is2c.en-j3PyPqV-e1s","6.006","16"
"189","Why might a path from a path tree not be the shortest path?","is to start introducing sort of the canonical problem that we all worry about on graphs which is computing paths, in particular shortest paths. So the first thing we should do is, of course, define what a path is on a graph. So we're going to talk about our graph like a road network. Let's think of maybe every node here as an intersection. So this is a roughly Kendall Square. See it's a square. But in any event, let's say that I want to find-- maybe a question one would be does there exist a way to get from vertex 1 to vertex 3. And then a better question to ask would be does there exists a short way to get from vertex 1 to vertex 3. Then of course, the first thing I have to do is to define my enemy. I have define what I'm looking for, which is a path. So a path is nothing more than a sequence of vertices in a graph where every pair of adjacent vertices in that sequence is an edge. I think this all aligns with our intuition of what a path is in a graph. So for instance, here's a path p equals v1, v2, v3. So notice that there's an edge from v1 to v2 and also an edge from v2 to v3. So it satisfies the assumptions set forth in our definition. What would not be a path in our graph-- would be like v1 comma v3, because there's no edge there. OK, so if we talk about paths, then there's a very natural notion which is the length. Length, I guess you could think of like the number of vertices in your path minus 1, or the number of edges that your path traverses. Those are the same thing. So for instance, the length of the path p here is 2. Does everybody see that? A very common coding bug that I encounter a lot is adding 1 to that number by accident. Because of course, there's one more vertex in your path than there are edges. OK, and there are many different-- there could be potentially more than one path between any pair of vertices. So let's say that I have an undirected graph that looks like the following. So it's just a square plus a diagonal. So here are nodes. So then a perfectly valid path from the lower left to the upper right would be to go one over and one up, but of course, there's a more efficient way to get from the lower left to the upper right, which is to go across the diagonal. And so when we talk about the shortest path, it's nothing more than the length of the path that has the fewest number of edges or vertices between any pair of vertices in my graph. OK, so this is our enemy. This is what we're after. It's computing the shortest path between vertices in a graph. And this is the thing that we'll be talking about quite a bit in this course. Because of course, it's a very practical matter. Like when I want to solve routing problems, I want to move packets out of my network, I'd prefer not to-- well, unless I'm doing Tor-- I would prefer them not to hit too many computers in between. Then maybe I want a computer shortest path. Or on a surface maybe I want to move information","65.2238998413086","2","DPRSearchEngine","oFVYVzlvk9c.en-j3PyPqV-e1s_9_mp4","oFVYVzlvk9c.en-j3PyPqV-e1s","6.006","9"
"189","Why might a path from a path tree not be the shortest path?","search trees term you may have heard before so this is a special case of what we're doing where we're storing the keys in order and then if i want to search for a key like uh 13 i compare that key with the root i see oh it's not equal and it's to the left because it's less than 17. so 13 is left of here 13 is right of 7 13 is right of 12 and so i know that this is where 13 would belong but there's no right child there and so i know in find i just returned nothing if i was doing find previous i would return this note because i have tried to go to the right the last time before i fell off the tree i was trying to go to the right and therefore that last note i had was the previous item if i was trying to define next what would i do i would just take this node and compute its successor which we already know how to do and that happens to be the root okay so now i can do these inexact searches when i do find previous and find next when i fall off the tree i find either the previous or the next and then with predecessor or successor i can find the other one okay so that's how we can do find and find previous and find next to do uh sequences we need a little bit more work we'll do that next time","64.16984558105469","3","DPRSearchEngine","76dhtgZt38A.en_13_mp4","76dhtgZt38A.en","6.006","6"
"189","Why might a path from a path tree not be the shortest path?","a very non-intuitive one, where we use some prefix of the vertices. But notice, it's prefixes again-- a number of the vertices from 1 up to v. And I took a prefix of those vertices. So I just solved the problem using prefix vertices 1 through k. So it's actually a familiar idea. If all you had seen are all dynamic programming examples of prefixes, suffixes, substrings, actually, it's pretty natural way to solve shortest paths-- maybe even more natural than this. Anyway, all right. Enough shortest paths. Let's solve two more problems that are more in our standard wheelhouse that will involve sequences of inputs, not graphs.","63.99054718017578","4","DPRSearchEngine","TDo3r5M1LNo.en-j3PyPqV-e1s_9_mp4","TDo3r5M1LNo.en-j3PyPqV-e1s","6.006","17"
"189","Why might a path from a path tree not be the shortest path?","notes because I figured we'd define what a graph is first before telling you what the implications are. But in any event, I think it's really not a big stretch of the imagination to say that graphs are literally everywhere in our everyday life, right. Any time that we come up with a network of stuff connected together, implicitly the right abstraction often in the back of our heads is to think about a graph. So some simple examples that I think would all come to mind for us would be like computer networks-- so the nodes or the vertices of your graph in that case, maybe are computers, and then the edges are roughly the cables connecting them together in my very coarse understanding of how networks work-- or maybe at a social network-- the nodes are people on your social network, and the edges are friend relationships or frenemy relationships or whatever. In fact, I think you could think of both directed and undirected versions of that particular network. In road networks, maybe I'm working for Google and I want to tell you the shortest path between your house and MIT. Of course, in order to do that and essentially behind the scenes, we're solving some version of computing the shortest path between two vertices in a graph. That's a tiny bit of a lie in the sense that there's a lot of structure in that problem that we're not going to leverage in this course. A road network is a very special type of graph, and if you take an advanced course maybe you'll say, well, if I know a little more about my graph I can do better than the general case we'll talk about here. But the basic algorithms that we'll talk about in 6.006 are certainly relevant in that case and are really the building blocks for what goes on in the tools that are used every day on your phone when you open Google Maps or Ways or whatever. And of course, there's many others. So for instance, an example that maybe is a little bit more subtle would be the set of states and transitions of a discrete thing. So think about like a Rubik's cube. So I could make a graph where the node is every configuration of my Rubik's cube, like every rotation. And then the edges are like can I get from this configuration to that one by making one simple transition, like one flip. I don't actually know the terminology in Rubik's cube, I have a feeling you do, for one rotation. Twist-- thank you. And of course, there are many other places. So for instance, in my day job here at MIT","63.7125244140625","5","DPRSearchEngine","oFVYVzlvk9c.en-j3PyPqV-e1s_4_mp4","oFVYVzlvk9c.en-j3PyPqV-e1s","6.006","9"
"189","Why might a path from a path tree not be the shortest path?","But of course, there's sort of many variations on that theme when we talk about shortest path or even just existence of a path. So these are three sort of model problems that we might solve on a graph. So the first one, which in this of course we're calling the single pair reachability, would be the idea that I take two vertices s and t on my graph g, and I ask you does there exists a path between s and t. So what would be the sort of extreme example where this problem may not always give back the answer yes? Somehow in our head, I think we think of all graphs as being connected. But a perfectly valid graph the way we've defined it would be like 10 vertices and no edges. This function would be very easy to code if that were the only graph you ever cared about. But any event, the existence of a path is already a query that takes a little bit of algorithmic thinking. We haven't figured out how to do that yet. Now another problem we can solve would be the shortest path. Given a graph and two vertices, we might say, well, how far apart are these vertices of my graph if I want to use the shortest possible distance from one to the other. Notice that I can use the second problem to solve the first one. Because what's the length of the shortest path between two vertices that don't have a path between them? Infinity or a shrug-- that's actually a totally valid answer. Yeah, that's right. So how could I implement the reachability code? Well, I could call my shortest path code, and it gives me infinity. Then I return no, it's not reachable. And if it gives me not infinity, I return yes. So remember that a key idea in an algorithms class is this idea of reduction. That I can use one function to solve another. So in case, if we can solve shortest path, then we can certainly solve the reachability problem by calling that piece of code. And then finally we could talk about single source shortest path. So notice now that there's only one input node here s-- so what this problem is saying is give me the length of the shortest path from s to every single other vertex in my graph. Does that makes sense? Like maybe I return a big array with all the information, every single shortest distance. So can we solve single pair shortest path using single source shortest path? Absolutely. I could take s in my single pair shortest path problem, compute the shortest path from s to literally everything else, and then throw away all of that information except the shortest path to t, and now I'm good. Now I haven't justified that this is the fastest possible way to solve that second problem, but at least it shows that if I can solve problem three I can also solve problem two. If I can solve from two I can also solve problem one. So in today's lecture, we're just going to worry about problem three. In other words, these things are sort of listed in increasing order of their difficulty. OK, so in order to think about the single source shortest path problem, we're going to make one additional construction. And this is an idea called the shortest path tree. I got lazy drawing PowerPoint slides at 2:00 AM yesterday,","63.63166809082031","6","DPRSearchEngine","oFVYVzlvk9c.en-j3PyPqV-e1s_10_mp4","oFVYVzlvk9c.en-j3PyPqV-e1s","6.006","9"
"189","Why might a path from a path tree not be the shortest path?","So let's draw a graph. So here we have a, b-- I'm going to use letters instead of numbers to refer to nodes from now on because I don't want to confuse the length of the shortest path with the index of my node. So here's a, b, c-- I'm going to match my notes here-- d, e, f. Here's a graph-- again undirected because your instructor likes to think about undirected graphs. But I know I'm going to get feedback that I shouldn't have done that later. But in any event, let's say that I want to compute the shortest path from a to everything else-- or the length rather. So first of all, even without talking about an algorithm, I think it's pretty easy to guess what it is. So clearly the shortest path from a to a has length 0. The shortest length from a to b is 1, from a to c is 2-- because I can follow these guys. Now it gets complicated. It branched. So the next shortest path is length 3, and then 4 like that. Does everybody agree with me that the numbers I've decorated here are the length of the shortest path from a to everything else? But what have I not done? I haven't told you how to actually compute the path, I've just given you the length of the path. So I may want a piece of code that in addition to doing single source shortest path length, also gives me a single source shortest path. So initially when I think about that, I might think about, well, how do I even write down a data structure that can store all of those paths. Well every path could have like v vertices in it, right. It could be that for whatever reason, there's a lot of branching in my graph. And all the paths are super long. Actually, I guess I have to think about whether branching would make them longer or shorter. But in any event, I could have a really boring data structure that just for every single vertex keeps track of the shortest path from a to that vertex. How big would that data structure be? Well, if the only bound I have on the length of a path is that-- it certainly at most it takes all the vertices in my graph-- then any one path will take v space. So that would take v squared space total. That wouldn't be so good. Because somehow I have an amount of information on my graph currently that's linear. It's just the length of the path. If I want to actually reconstruct that path, initially sort of spiritually feels like I need way more space to do that. But the answer is that we actually don't. That we're going to only need linear space, and the idea for that is to store an object called the shortest path tree. Yes? AUDIENCE: Just for [INAUDIBLE] previous [INAUDIBLE].. JUSTIN SOLOMON: So the question was about recursion. We haven't actually written down any graph algorithms. So we're going to defer on that until we actually recurse. And then we'll think about it more carefully. Yeah, but it's a totally reasonable question. There are plenty of recursive graph algorithms out there. And then we'll have to do our counting very carefully for sure. Right, so instead, we're going to define an object called the shortest path tree. And the basic trick here is to say, well, how did I get from a to c? Well, there's always a vertex, which is its predecessor, on the shortest path. And shortest path have this really beautiful property, which is that the shortest path from a to c, if I truncate it-- right, so it goes a to b to c-- then the truncated one is also the shortest path to that previous vertex. So let's think about that a little bit, because that sentence was, as usual, poorly phrased by your instructor. So let's say that I have the shortest path from a to d, which is very clearly a, b, c, d. I think we can all agree. And now I take like this sublist. I just look from a to c. Is there ever a circumstance when this is not the shortest path or a shortest path from a to c? No, right because if there existed a shorter path from a to c, I could splice it in here and find the shortest path from a to d. Do you see that? So based on that reasoning, rather than string like this giant set of shortest paths, sort of actually applying, in some senses, recursive suggestion, instead I can just think of the one vertex that's before me in my shortest path. I'm going to trace backwards. So let's take a look at our graph here. Essentially, the object I'm going to keep track of is like a predecessor, right. So what is the predecessor of f on the shortest path? It's actually either d or e. It doesn't matter in this case. Maybe the predecessor is e for fun, right. What's the predecessor of e? Well, clearly the previous vertex on the shortest path is c. Similarly for d-- now we have b and a and a bunch of arrows that point this way. So for every vertex I'm just going to start an arrow pointing toward the previous vertex on the shortest path. I'm not going to store the whole shortest path, just the very last edge. So first of all, how much storage does this take? It takes v space. Do you see that? Or the size of the vertices space. Because every vertex just has to store one thing, which is the previous vertex on the shortest path. Now what does my algorithm for tracing shortest path? It's really simple. I just start walking along these edges all the way until I get back to a. Now this object is called the shortest path tree. Notice I snuck in one additional word which is tree. Why is that? Can I ever have a cycle in this graph? It wouldn't really make any sense, right. These are shortest path. You should be able to kind of follow the gradient back to the original vertex. OK, so in other words, I'm going to basically decorate my graph with one additional thing. We'll call it p of v which is the previous vertex on the shortest path from my source point to my vertex v. And what I think I've tried to argue to you guys today is that if I have this information, that's actually enough to reconstruct the shortest path. I just keep taking p of v, and then p of p of v, and then p of p of p of v, and so on, which sounds more complicated than it is, until I trace back to my original vertex. And this object conceptually is called the shortest path tree. Any questions about that? Yes? AUDIENCE: [INAUDIBLE] JUSTIN SOLOMON: If I had an edge that connected a to d, OK. AUDIENCE: [INAUDIBLE] JUSTIN SOLOMON: Oh, OK so the question was, let's say that our colleague here added an edge-- this is a great question. You know somebody was evil, my adversarial neural network, stuck an edge here because it was adversarial, and it wanted my shortest path code to fail. And now somehow the tree that I gave you is no longer correct. And my answer to that is yes. Why is that? Well, by adding this edge here, the length of my shortest path changed. The shortest path from a to d is now 1. So this tree is no longer valid. I need a new tree. So now what would be the previous p of d here? Well, rather than being c, it would be a. Yes, that's absolutely right. And it actually is reflective of a really annoying property of shortest path, which is if I add one edge to my graph, the length of the shortest path to every vertex can change. Well, I guess with the exception of the source vertex. Yeah, and that's actually a really big headache in certain applications. So for instance-- and then I'll shut up about applications and do math again-- I work a lot with 3D models. And there's a big data set of 3D models of like ballerinas. And ballerinas are really annoying because sometimes they put their hands together like that. And then suddenly the shortest path between your fingers goes from your entire body to like 0. And so incremental algorithms for computing shortest path can fail here, right. Because I have to update like everything if I accidentally glued together fingers like that. So anyway, I'll let you think about how you might fix that problem. If you want to know more, you should take 6.838. Yes? AUDIENCE: [INAUDIBLE]. JUSTIN SOLOMON: If you change your source node, the shortest possible change again. Yeah, so this is going to be one of these really boring things where I'm going to keep answering like any time I change anything about my problem-- I change my source, I change my edges-- I have to just recompute all the shortest paths. There are obviously algorithms out there that don't do that. But we're not going to think about them yet. OK. So as usual, I've talked too much and left myself about 10 minutes to do the actual algorithm that's interesting in the lecture here-- although actually, it's really not so complicated,","63.47468948364258","7","DPRSearchEngine","oFVYVzlvk9c.en-j3PyPqV-e1s_11_mp4","oFVYVzlvk9c.en-j3PyPqV-e1s","6.006","9"
"189","Why might a path from a path tree not be the shortest path?","  
 
  
 
 
 
  
 
 
 
 
 
   
 
 
 
 
  
 
 
 
  
 
  
   
 
  
 
 
  
  
  
 
 
 
 
 
 
  
  
 
 
 
 
 
 
 
  
 
 
 
 
   
 
 
 
 
 
  
 
 
Example: Ladder Problem 
A ladder is a sequence of strings of a common length where 
WORK
consecutive strings differ in a single symbol. 
PORK 
A word ladder for English is a ladder of English words. 
PORT 
SORT
Let ! be a language. A ladder in ! is a ladder of strings in !. 
SOOT 
Defn: ""!##$%DFA = *, ,, ­
* is a DFA and ""(*) contains 
SLOT 
a ladder 01, 02, … , 04 where 01 = , and 04 = -}. 
PLOT 
Theorem: ""!##$%DFA ∈ NPSPACE 
PLOY 
PLAY
PLAY 
7 
","63.225013732910156","8","DPRSearchEngine","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17_7_pdf","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17","18.404J","17"
"189","Why might a path from a path tree not be the shortest path?","[SQUEAKING] [RUSTLING] [CLICKING] JASON KU: Hi, everyone. Welcome to the 11th lecture of 6.006, our first lecture on weighted shortest paths. Until now, we've only been talking about graphs that-- where we measure distance in terms of the number of edges in a path. Today, we're going to generalize that notion. But I just want to go over what we've talked about in the last two lectures. In the last two lectures, we've talked about two algorithms, breadth-first search and depth-first search to solve a range of problems. Here's some of the problems that we've been solving. Single-source shortest paths, where distances are measured in number of edges in a path. And we used BFS to solve this problem, starting from a single source, usually a vertex s that we call. And we solve that in linear time. And we solve that in order v plus e. That's what we called linear time for a graph. For the special case of single-source reachability, here we had to return a shortest path distance for every vertex. And there was, at most, E things reachable from a vertex. So this is the bound we got. But in the special case for single-source reachability, when our output only has to list the vertices that are reachable from me, the number of things reachable in basically a spanning tree of the connected component of my source can almost be of order E. And so for all the little singleton vertices in my graph, I don't really care. So I can get this in order E, but that's kind of a little optimization.","63.10477066040039","9","DPRSearchEngine","5cF5Bgv59Sc.en-j3PyPqV-e1s_1_mp4","5cF5Bgv59Sc.en-j3PyPqV-e1s","6.006","11"
"189","Why might a path from a path tree not be the shortest path?","is that we have some set V, which is like the set of vertices. And then we have a set E, which is set of edges. And this was a subset of V cross V. And this is nothing more than fancy notation for saying that an edge is a pair of vertices, like a from and a to vertex. Of course, there are many variations on this theme. You could have a directed versus an undirected graph. So this one is directed, meaning the edges look like arrows. If they didn't have arrowheads, they'd be undirected. We define something called a simple graph where you have essentially no repeated edges. So for instance, you can't do something like this where you have the same edge twice. And then there are a couple of different definitions that were kind of useful. So in particular-- I'm going to erase this, whoops-- useless edge here. Maybe make my graph slightly more interesting. So add another edge going in the reverse direction. So maybe I have-- I'm going to give my vertices labels. x, y, z, and w. Then we talked about the neighbors of a given vertex, which are the vertices that you can reach by following edges in or out of your vertex.","63.08683776855469","10","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_4_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"190","What does the function 'prefix_max' return when the input 'i' is 0?","&

	
	
	/
def greedy(items, maxCost, keyFunction):
itemsCopy = sorted(items, key = keyFunction,
reverse = True)
result = []
totalValue, totalCost = 0.0, 0.0
for i in range(len(itemsCopy)):
if (totalCost+itemsCopy[i].getCost()) <= maxCost:
result.append(itemsCopy[i])
totalCost += itemsCopy[i].getCost()
totalValue += itemsCopy[i].getValue()
return (result, totalValue) 
	

2
	

","88.06307220458984","1","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_24_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"190","What does the function 'prefix_max' return when the input 'i' is 0?",";
/
def testGreedy(items, constraint, keyFunction):
taken, val = greedy(items, constraint, keyFunction)
print('Total value of items taken =', val)
for item in taken:
print('   ', item)
	

'
","86.34176635742188","2","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_25_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"190","What does the function 'prefix_max' return when the input 'i' is 0?",";
/
def testGreedys(maxUnits):
print('Use greedy by value to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits, Food.getValue)
print('\\nUse greedy by cost to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits,
lambda x: 1/Food.getCost(x))
print('\\nUse greedy by density to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits, Food.density)
testGreedys(800)
	


4
","84.77452850341797","3","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_26_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"190","What does the function 'prefix_max' return when the input 'i' is 0?","
7:
/
def greedy(items, maxCost, keyFunction):
""""""Assumes items a list, maxCost >= 0,
keyFunction maps elements of items to numbers""""""
itemsCopy = sorted(items, key = keyFunction,
reverse = True)
result = []
totalValue, totalCost = 0.0, 0.0
for i in range(len(itemsCopy)):
if (totalCost+itemsCopy[i].getCost()) <= maxCost:
result.append(itemsCopy[i])
totalCost += itemsCopy[i].getCost()
totalValue += itemsCopy[i].getValue()
return (result, totalValue) 
	

&
","84.2428970336914","4","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_23_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"190","What does the function 'prefix_max' return when the input 'i' is 0?","So I know Jerry Cain at Stanford likes to talk about the recursive leap of faith that happens. Another term for this is induction. So we want to prove that our algorithm works. Well, what do we have to do? We have to show that when I call this function, it gives me the max of my array between index 0 and index i for all i. So let's maybe do this inductive proof a little bit carefully. And then the rest, we'll be sloppy about it. So the base case is i equals 0. Well, in this case, there's only one element in my array. So it's pretty clear that it's the max. And now, we have to do our inductive step, which means that if I call prefix max with i minus 1, I really do get the max of my array between 0 and index i minus 1. And then really, I can just look at my very deep statement, which is that either my object is at the end of the array or it's not. And this is precisely what we need to justify the inductive step. Essentially, there are two cases. Either the biggest element of my arrays the last one or it's not. We already, by our inductive hypothesis, have argued that our code can find the biggest element between index 0 and index i minus 1. So as long as we take the max of that and the very last guy, we're in good shape.","83.31774139404297","5","DPRSearchEngine","oS9aPzUNG-s.en-j3PyPqV-e1s_17_mp4","oS9aPzUNG-s.en-j3PyPqV-e1s","6.006","3"
"190","What does the function 'prefix_max' return when the input 'i' is 0?","Defn:  BPP = "" some poly-time PTM decides "" with error # = ⁄
% & }
Amplification lemma: If '% is a poly-time PTM with error #% < ⁄
% ) then, 
for any 0 < #) < ⁄
% ), there is an equivalent poly-time PTM ') with error #).  
Can strengthen to make #) < 2−,-./ 0 . 
Proof idea:  ') = “On input 1
1.  Run '% on 1 for 2 times and output the majority response.”
Details:  Calculation to obtain 2 and the improved error probability. 
Significance:  Can make the error probability so small it is negligible.
The Class BPP
3
","82.47598266601562","6","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_3_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"190","What does the function 'prefix_max' return when the input 'i' is 0?","! ""
! #
! #
0
1
0 
1
0
1
0
1
Symbolic Execution
Leave the ! $ as variables and obtain an expression in the ! $
for the output of the BP. 
1
1 −! ""
! ""
1 −! ""
1 −! #
+ (! "" ) ! #
(1 −! "" ) 1 −! #
1 −! "" (x#)
(! "" ) ! #
(! "" ) 1 −! #
1 −! ""
x#
+ (! "" ) 1 −! #
! $
0 1
+
+(1 −! $)
+! $
+""
+#
+,
+"" + +# + +,
Recall 
labeling rules:
1 −! ""
! ""
= output
=
1 −! ""
x#
,
1 −! ,
! .
⋯(1 −! 0 )
+
! ""
! #
! ,
1 −! .
⋯
! 0
+
! ""
1 −! #
1 −! ,
! .
⋯
(! 0 )
⋮
+
! ""
! #
1 −! ,
! .
⋯
(! 0 )
form of 
output
Corresponds to the TRUE rows in the 
truth table of the Boolean function
Exponents ≤1
due to “read-once”
Assume read exactly once so that for each 3
(! $) or (1 −! $) appears in every row 
8
","81.31507110595703","7","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_8_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"190","What does the function 'prefix_max' return when the input 'i' is 0?"," 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
              
 
 
 
 
 
 
 
 
 
 
 
Pushdown Automata (PDA) 
“head” 
a
b
a
b
a 
… 
a
Finite 
input appears on a “tape” 
control 
c 
Schematic diagram for DFA or NFA
(pushdown) 
d 
stack 
Schematic diagram for PDA 
d 
Operates like an NFA except can write-add or read-remove symbols 
from the top of stack. 
push 
pop 
Example: PDA for ! = 0$1$ & ≥0 
1) Read 0s from input, push onto stack until read 1. 
2) Read 1s from input, while popping 0s from stack. 
3) Enter accept state if stack is empty. (note: acceptance only at end of input) 
6 
","80.5597915649414","8","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_6_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"190","What does the function 'prefix_max' return when the input 'i' is 0?"," 
	 	
def splitData(xVals, yVals): 
    toTrain = random.sample(range(len(xVals)), 
                            len(xVals)//2) 
    trainX, trainY, testX, testY = [],[],[],[] 
    for i in range(len(xVals)): 
        if i in toTrain: 
            trainX.append(xVals[i]) 
            trainY.append(yVals[i]) 
        else: 
            testX.append(xVals[i]) 
            testY.append(yVals[i]) 
    return trainX, trainY, testX, testY 
	

?
","80.44862365722656","9","DPRSearchEngine","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10_46_pdf","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10","6.0002","10"
"190","What does the function 'prefix_max' return when the input 'i' is 0?","Notation for encodings and TMs
Notation for encoding objects into strings
- If ! is some object (e.g., polynomial, automaton, graph, etc.), 
we write 〈!〉to be an encoding of that object into a string.  
- If !$, !&, … , !( is a list of objects then we write 〈!$, !&, … , !(〉
to be an encoding of them together into a single string. 
Notation for writing Turing machines
We will use high-level English descriptions of algorithms when we describe TMs, 
knowing that we could (in principle) convert those descriptions into states, 
transition function, etc.  Our notation for writing a TM ) is
) = “On input +
[English description of the algorithm]”
Check-in 6.3
If , and - are strings, would ,- be a good choice 
for their encoding 〈,, -〉into a single string?
a)
Yes.
b)
No. 
Check-in 6.3
8
","80.24185180664062","10","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_8_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"191","What is the running time of the direct access array sort if the range of keys \\( u \\) is \\( \\Theta(n) \\)?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","76.07416534423828","1","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"191","What is the running time of the direct access array sort if the range of keys \\( u \\) is \\( \\Theta(n) \\)?","§ Time based on number of nodes generated 
§ Number of levels is number of items to choose from 
§ Number of nodes at level i is 2i 
§ So, if there are n items the number of nodes is 
◦ ∑𝑖=0↑𝑖=𝑛▒​2↑𝑖   
◦ I.e., O(​2↑𝑛+1 ) 
§ An obvious op<miza<on: don’t explore parts of tree 
that violate constraint (e.g., too many calories) 
◦ Doesn’t change complexity 
§ Does this mean that brute force is never useful? 
◦ Let’s give it a try 
Computa#onal Complexity 
6.0002 LECTURE 2 
8 
","75.03437042236328","2","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_8_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"191","What is the running time of the direct access array sort if the range of keys \\( u \\) is \\( \\Theta(n) \\)?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","74.98982238769531","3","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"191","What is the running time of the direct access array sort if the range of keys \\( u \\) is \\( \\Theta(n) \\)?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 5: Linear Sorting 
Lecture 5: Linear Sorting 
Review 
• Comparison search lower bound: any decision tree with n nodes has height ≥dlg(n+1)e−1 
• Can do faster using random access indexing: an operation with linear branching factor! 
• Direct access array is fast, but may use a lot of space (Θ(u)) 
• Solve space problem by mapping (hashing) key space u down to m = Θ(n) 
• Hash tables give expected O(1) time operations, amortized if dynamic 
• Expectation input-independent: choose hash function randomly from universal hash family 
• Data structure overview! 
• Last time we achieved faster ﬁnd. Can we also achieve faster sort? 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
Direct Access Array 
u 
1 
1 
u 
u 
Hash Table 
n(e) 
1(e) 
1(a)(e) 
n 
n 
","74.60804748535156","4","DPRSearchEngine","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5_1_pdf","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5","6.006","5"
"191","What is the running time of the direct access array sort if the range of keys \\( u \\) is \\( \\Theta(n) \\)?","4 
Lecture 1: Introduction 
1 
def birthday_match(students): 
2 
’’’ 
3 
Find a pair of students with the same birthday 
4 
Input: 
tuple of student (name, bday) tuples 
5 
Output: tuple of student names or None 
6 
’’’ 
7 
n = len(students) 
# O(1) 
8 
record = StaticArray(n) 
# O(n) 
9 
for k in range(n): 
# n 
10 
(name1, bday1) = students[k] 
# O(1) 
11 
# Return pair if bday1 in record 
12 
for i in range(k): 
# k 
13 
(name2, bday2) = record.get_at(i) 
# O(1) 
14 
if bday1 == bday2: 
# O(1) 
15 
return (name1, name2) 
# O(1) 
16 
record.set_at(k, (name1, bday1)) 
# O(1) 
17 
return None 
# O(1) 
Example: Running Time Analysis 
• Two loops: outer k ∈{0, . . . , n − 1}, inner is i ∈{0, . . . , k}
P n−1
• Running time is O(n) + 
k=0 (O(1) + k · O(1)) = O(n2) 
• Quadratic in n is polynomial. Efﬁcient? Use different data structure for record! 
How to Solve an Algorithms Problem 
1. Reduce to a problem you already know (use data structure or algorithm) 
Search Problem (Data Structures) 
Sort Algorithms 
Static Array (L01) 
Insertion Sort (L03) 
Linked List (L02) 
Selection Sort (L03) 
Dynamic Array (L02) 
Merge Sort (L03) 
Sorted Array (L03) 
Counting Sort (L05) 
Direct-Access Array (L04) 
Radix Sort (L05) 
Hash Table (L04) 
AVL Sort (L07) 
Balanced Binary Tree (L06-L07) 
Heap Sort (L08) 
Binary Heap (L08) 
2. Design your own (recursive) algorithm 
• Brute Force 
• Decrease and Conquer 
• Divide and Conquer 
• Dynamic Programming (L15-L19) 
• Greedy / Incremental 
Shortest Path Algorithms 
Breadth First Search (L09) 
DAG Relaxation (L11) 
Depth First Search (L10) 
Topological Sort (L10) 
Bellman-Ford (L12) 
Dijkstra (L13) 
Johnson (L14) 
Floyd-Warshall (L18) 
","74.38811492919922","5","DPRSearchEngine","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_4_pdf","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1","6.006","1"
"191","What is the running time of the direct access array sort if the range of keys \\( u \\) is \\( \\Theta(n) \\)?"," 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
An NTM ' runs in space !(%) if all branches halt and each branch uses at
most !(%) tape cells on all inputs of length %. 
Defn: SPACE ! %
= {,| some deterministic 1-tape TM ' decides ,
and ' runs in space . ! %
}
NSPACE ! %
= {,| some nondeterministic 1-tape TM ' decides ,
and ' runs in space . ! %
}
PSPACE = ⋃1 SPACE(%1)
“polynomial space”
NPSPACE = ⋃1 NSPACE(%1)
“nondeterministic polynomial space”
SPACE Complexity 
Defn: Let !: ℕ→ℕ where ! % ≥%. Say TM ' runs in space !(%) if ' 
always halts and uses at most !(%) tape cells on all inputs of length %. 
Check-in 17.1 
We define space complexity for multi-tape TMs by 
taking the sum of the cells used on all tapes. 
Do we get the same class PSPACE for multi-tape TMs? 
(a) No. 
(b) Yes, converting a multi-tape TM to single-tape 
only squares the amount of space used. 
(c) Yes, converting a multi-tape TM to single-tape 
only increases the amount of space used by a 
constant factor. 
Check-in 17.1 
2 
","74.15532684326172","6","DPRSearchEngine","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17_2_pdf","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17","18.404J","17"
"191","What is the running time of the direct access array sort if the range of keys \\( u \\) is \\( \\Theta(n) \\)?","§ 1. Enumerate all possible combina<ons of items. 
§ 2. Remove all of the combina<ons whose total units 
exceeds the allowed weight. 
§ 3. From the remaining combina<ons choose any one 
whose value is the largest. 
Brute Force Algorithm 
6.0002 LECTURE 2 
4 
","74.14280700683594","7","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_4_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"191","What is the running time of the direct access array sort if the range of keys \\( u \\) is \\( \\Theta(n) \\)?","  
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
Review: SPACE Complexity 
Defn: Let !: ℕ→ℕ where ! % ≥%. Say TM ' runs in space !(%) if ' 
always halts and uses at most !(%) tape cells on all inputs of length %. 
An NTM ' runs in space !(%) if all branches halt and each branch uses at 
most !(%) tape cells on all inputs of length %. 
SPACE ! % 
= {,| some 1-tape TM decides , in space . ! % } 
NSPACE ! % 
= {,| some 1-tape NTM decides , in space . ! % } 
PSPACE = ⋃1 SPACE(%1) “polynomial space” 
NPSPACE = ⋃1 NSPACE(%1) 
“nondeterministic polynomial space” 
Today: PSPACE = NPSPACE 
Or possibly: 
P = NP = coNP = PSPACE 
2 
PSPACE 
= NPSPACE 
coNP 
NP 
P 
","74.05593872070312","8","DPRSearchEngine","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18_2_pdf","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18","18.404J","18"
"191","What is the running time of the direct access array sort if the range of keys \\( u \\) is \\( \\Theta(n) \\)?","&

	
	
	/
def greedy(items, maxCost, keyFunction):
itemsCopy = sorted(items, key = keyFunction,
reverse = True)
result = []
totalValue, totalCost = 0.0, 0.0
for i in range(len(itemsCopy)):
if (totalCost+itemsCopy[i].getCost()) <= maxCost:
result.append(itemsCopy[i])
totalCost += itemsCopy[i].getCost()
totalValue += itemsCopy[i].getValue()
return (result, totalValue) 
	

2
	

","73.63137817382812","9","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_24_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"191","What is the running time of the direct access array sort if the range of keys \\( u \\) is \\( \\Theta(n) \\)?"," 
 
 
 
 
  
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Constructing !"",$: 1st try 
% on & 
Recall: A tableau for % on & represents 
a computation history for % on & 
when % accepts &. 
Rows of that tableau are configurations. 
% runs in space 45, its tableau has: 
- 45 columns (max size of a configuration)
-8
- 6
rows (max number of steps) 
Constructing !"",$. Try Cook-Levin method. 
Then !"",$ will be as big as tableau. 
-8
But that is exponential: 45×6 
.
Too big! • 
7 
Tableau for % on &
'( &) &* &+ ⋯&-
a
'. &*
⋯
⋯
'accept ⋯
˽   … ˽
45
6(-8)
","73.53173828125","10","DPRSearchEngine","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18_7_pdf","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18","18.404J","18"
"192","What is the lower bound for the height of a decision tree required to sort an array of \\( n \\) elements using comparison sorts?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","79.8392333984375","1","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"192","What is the lower bound for the height of a decision tree required to sort an array of \\( n \\) elements using comparison sorts?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 5: Linear Sorting 
Lecture 5: Linear Sorting 
Review 
• Comparison search lower bound: any decision tree with n nodes has height ≥dlg(n+1)e−1 
• Can do faster using random access indexing: an operation with linear branching factor! 
• Direct access array is fast, but may use a lot of space (Θ(u)) 
• Solve space problem by mapping (hashing) key space u down to m = Θ(n) 
• Hash tables give expected O(1) time operations, amortized if dynamic 
• Expectation input-independent: choose hash function randomly from universal hash family 
• Data structure overview! 
• Last time we achieved faster ﬁnd. Can we also achieve faster sort? 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
Direct Access Array 
u 
1 
1 
u 
u 
Hash Table 
n(e) 
1(e) 
1(a)(e) 
n 
n 
","76.81155395507812","2","DPRSearchEngine","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5_1_pdf","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5","6.006","5"
"192","What is the lower bound for the height of a decision tree required to sort an array of \\( n \\) elements using comparison sorts?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 4: Hashing 
Lecture 4: Hashing 
Review 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
• Idea! Want faster search and dynamic operations. Can we find(k) faster than Θ(log n)? 
• Answer is no (lower bound)! (But actually, yes...!?) 
Comparison Model 
• In this model, assume algorithm can only differentiate items via comparisons 
• Comparable items: black boxes only supporting comparisons between pairs 
• Comparisons are <, ≤, >, ≥, =, =6 , outputs are binary: True or False 
• Goal: Store a set of n comparable items, support find(k) operation 
• Running time is lower bounded by # comparisons performed, so count comparisons! 
Decision Tree 
• Any algorithm can be viewed as a decision tree of operations performed 
• An internal node represents a binary comparison, branching either True or False 
• For a comparison algorithm, the decision tree is binary (draw example) 
• A leaf represents algorithm termination, resulting in an algorithm output 
• A root-to-leaf path represents an execution of the algorithm on some input 
• Need at least one leaf for each algorithm output, so search requires ≥ n + 1 leaves 
","76.45344543457031","3","DPRSearchEngine","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_1_pdf","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4","6.006","4"
"192","What is the lower bound for the height of a decision tree required to sort an array of \\( n \\) elements using comparison sorts?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","75.67249298095703","4","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"192","What is the lower bound for the height of a decision tree required to sort an array of \\( n \\) elements using comparison sorts?","They take linear time for some of the operations. So the sorting algorithms are not efficient. But they're ones we've seen before, so it's neat to see how they fit in here. They had the-- selection sort and insertion sort had the advantage that they were in place. You just needed a constant number of pointers or indices beyond the array itself. So they're very space efficient. So that was a plus for them. But they take n squared time, so you should never use them, except for n, at most, 100 or something. AVL tree sort is great and then it gets n log n time, probably more complicated than merge sort and you could stick to merge sort. But neither merge sort nor set AVL tree sort are in place. And so the goal of today is to get the best of all those worlds in sorting to get n log n comparisons, which is optimal in the comparison model, but get it to be in place. And that's what we're going to get with binary heaps. We're going to design a data structure that happens to build a little bit faster-- as I mentioned, linear time building. So it's not representing a sorted order in the same way that AVL trees are. But it will be kind of tree-based. It will also be array-based. We're going to get logarithmic time for insert and delete_max. It happens to be amortized, because we use arrays. But the key thing is that it's an in-place data structure. It only consists of an array of the items. And so, when we plug it into our sorting algorithm-- priority queue sort or generic sorting algorithm-- not only do we get n log n performance, but we also get an in-place sorting algorithm. This will be our first and only-- to this class-- n log n in-place sorting algorithm. Cool. That's the goal.","75.1623764038086","5","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_5_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"192","What is the lower bound for the height of a decision tree required to sort an array of \\( n \\) elements using comparison sorts?","&

	
	
	/
def greedy(items, maxCost, keyFunction):
itemsCopy = sorted(items, key = keyFunction,
reverse = True)
result = []
totalValue, totalCost = 0.0, 0.0
for i in range(len(itemsCopy)):
if (totalCost+itemsCopy[i].getCost()) <= maxCost:
result.append(itemsCopy[i])
totalCost += itemsCopy[i].getCost()
totalValue += itemsCopy[i].getValue()
return (result, totalValue) 
	

2
	

","74.84918212890625","6","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_24_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"192","What is the lower bound for the height of a decision tree required to sort an array of \\( n \\) elements using comparison sorts?","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","74.72134399414062","7","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"192","What is the lower bound for the height of a decision tree required to sort an array of \\( n \\) elements using comparison sorts?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","74.6731948852539","8","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"192","What is the lower bound for the height of a decision tree required to sort an array of \\( n \\) elements using comparison sorts?","And a comparison model means-- is that the items, the objects I'm storing-- I can kind of think of them as black boxes. I don't get to touch these things, except the only way that I can distinguish between them is to say, given a key and an item, or two items, I can do a comparison on those keys. Are these keys the same? Is this key bigger than this one? Is it smaller than this one? Those are the only operations I get to do with them. Say, if the keys are numbers, I don't get to look at what number that is. I just get to take two keys and compare them. And actually, all of the search algorithms that we saw on Tuesday we're comparison sort algorithms. What you did was stepped through the program. At some point, you came to a branch and you looked at two keys, and you branched based on whether one key was bigger than another. That was a comparison. And then you move some stuff around, but that was the general paradigm. Those three sorting operations lived in this comparison model.","74.415771484375","9","DPRSearchEngine","Nu8YGneFCWE.en-j3PyPqV-e1s_2_mp4","Nu8YGneFCWE.en-j3PyPqV-e1s","6.006","4"
"192","What is the lower bound for the height of a decision tree required to sort an array of \\( n \\) elements using comparison sorts?","!""#$""%&'(% ∈NP
Defn:  !""#$""%&'(% = + + is not prime and + is written in binary} 
= + + = ,- for integers ,, - > 1,  + in binary} 
Theorem:  !""#$""%&'(% ∈NP
Proof:   “On input +
1.  Nondeterministically write , where 1 < , < +.
2.  Accept if , divides + with remainder 0.
Reject if not.”
Note:  Using base 10 instead of base 2 wouldn’t matter because can convert in 
polynomial time.
Bad encoding:  write number 3 in unary:  14 = 111 ⋯1
4
, exponentially longer.
Theorem (2002):  !""#$""%&'(% ∈P
We won’t cover this proof.
5
","74.18798065185547","10","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_5_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"193","In the direct access sort algorithm, why is the direct access array initialized with size \\( u \\)?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","80.27870178222656","1","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"193","In the direct access sort algorithm, why is the direct access array initialized with size \\( u \\)?","4 
Lecture 1: Introduction 
1 
def birthday_match(students): 
2 
’’’ 
3 
Find a pair of students with the same birthday 
4 
Input: 
tuple of student (name, bday) tuples 
5 
Output: tuple of student names or None 
6 
’’’ 
7 
n = len(students) 
# O(1) 
8 
record = StaticArray(n) 
# O(n) 
9 
for k in range(n): 
# n 
10 
(name1, bday1) = students[k] 
# O(1) 
11 
# Return pair if bday1 in record 
12 
for i in range(k): 
# k 
13 
(name2, bday2) = record.get_at(i) 
# O(1) 
14 
if bday1 == bday2: 
# O(1) 
15 
return (name1, name2) 
# O(1) 
16 
record.set_at(k, (name1, bday1)) 
# O(1) 
17 
return None 
# O(1) 
Example: Running Time Analysis 
• Two loops: outer k ∈{0, . . . , n − 1}, inner is i ∈{0, . . . , k}
P n−1
• Running time is O(n) + 
k=0 (O(1) + k · O(1)) = O(n2) 
• Quadratic in n is polynomial. Efﬁcient? Use different data structure for record! 
How to Solve an Algorithms Problem 
1. Reduce to a problem you already know (use data structure or algorithm) 
Search Problem (Data Structures) 
Sort Algorithms 
Static Array (L01) 
Insertion Sort (L03) 
Linked List (L02) 
Selection Sort (L03) 
Dynamic Array (L02) 
Merge Sort (L03) 
Sorted Array (L03) 
Counting Sort (L05) 
Direct-Access Array (L04) 
Radix Sort (L05) 
Hash Table (L04) 
AVL Sort (L07) 
Balanced Binary Tree (L06-L07) 
Heap Sort (L08) 
Binary Heap (L08) 
2. Design your own (recursive) algorithm 
• Brute Force 
• Decrease and Conquer 
• Divide and Conquer 
• Dynamic Programming (L15-L19) 
• Greedy / Incremental 
Shortest Path Algorithms 
Breadth First Search (L09) 
DAG Relaxation (L11) 
Depth First Search (L10) 
Topological Sort (L10) 
Bellman-Ford (L12) 
Dijkstra (L13) 
Johnson (L14) 
Floyd-Warshall (L18) 
","78.74705505371094","2","DPRSearchEngine","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_4_pdf","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1","6.006","1"
"193","In the direct access sort algorithm, why is the direct access array initialized with size \\( u \\)?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","77.38017272949219","3","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"193","In the direct access sort algorithm, why is the direct access array initialized with size \\( u \\)?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 3: Sorting 
Lecture 3: Sorting 
Set Interface (L03-L08) 
Container 
build(X) 
len() 
given an iterable X, build set from items in X 
return the number of stored items 
Static 
find(k) 
return the stored item with key k 
Dynamic 
insert(x) 
delete(k) 
add x to set (replace item with key x.key if one already exists) 
remove and return the stored item with key k 
Order 
iter ord() 
find min() 
find max() 
find next(k) 
find prev(k) 
return the stored items one-by-one in key order 
return the stored item with smallest key 
return the stored item with largest key 
return the stored item with smallest key larger than k 
return the stored item with largest key smaller than k 
• Storing items in an array in arbitrary order can implement a (not so efﬁcient) set 
• Stored items sorted increasing by key allows: 
– faster ﬁnd min/max (at ﬁrst and last index of array) 
– faster ﬁnds via binary search: O(log n) 
Set 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
Data Structure 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
• But how to construct a sorted array efﬁciently? 
","76.88809204101562","4","DPRSearchEngine","6d1ae5278d02bbecb5c4428928b24194_MIT6_006S20_lec3_1_pdf","6d1ae5278d02bbecb5c4428928b24194_MIT6_006S20_lec3","6.006","3"
"193","In the direct access sort algorithm, why is the direct access array initialized with size \\( u \\)?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 5: Linear Sorting 
Lecture 5: Linear Sorting 
Review 
• Comparison search lower bound: any decision tree with n nodes has height ≥dlg(n+1)e−1 
• Can do faster using random access indexing: an operation with linear branching factor! 
• Direct access array is fast, but may use a lot of space (Θ(u)) 
• Solve space problem by mapping (hashing) key space u down to m = Θ(n) 
• Hash tables give expected O(1) time operations, amortized if dynamic 
• Expectation input-independent: choose hash function randomly from universal hash family 
• Data structure overview! 
• Last time we achieved faster ﬁnd. Can we also achieve faster sort? 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
Direct Access Array 
u 
1 
1 
u 
u 
Hash Table 
n(e) 
1(e) 
1(a)(e) 
n 
n 
","76.8310546875","5","DPRSearchEngine","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5_1_pdf","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5","6.006","5"
"193","In the direct access sort algorithm, why is the direct access array initialized with size \\( u \\)?","That's what we called a direct access array. A direct access array-- really not different than a regular array, except how are you using it when we were talking about sequences is we are giving extrinsic semantics to the slots where we are storing these things. Basically, I could put any item in any slot. Where it was in my array had nothing to do with what those things were. Here we are imposing intrinsic semantics on my array that, if I have an item with key K, it must be at index K. That's the thing that we're taking advantage of here. And then we can use this nice, powerful linear branching random access operation to find that thing in constant time, because that's our model of computation. OK, then what was the problem with this direct access array? Anyone shout it out. Space-- right. So we had to instantiate a direct access array that was the size of the space of our keys. In general, my index location is-- could go from 0 to some positive number. If I a very large positive numbers, if I was sorting-- if I was searching among your MIT IDs, I'd have to have a direct access array that was that spanned that space of possible keys you could have. And that could be much larger than n. And so the rest of the time we talked about how to fix that space problem. We can reduce the space by taking that larger key space from 0 to u, which could be very large, and map it down to a small space. Now, in general, if I give you a fixed hash function there, that's not going to be good in-- for all inputs. If your inputs are very well distributed over the key space, then it is good, but in general, there would be hash functions with some inputs that will be bad. That's what we argued. And so for the rest of the time there, we talked about hash families, choosing a hash function randomly from among a large set of hash functions, which had a property that, if I chose this thing randomly and you, generating your input, didn't know which random numbers I was picking, the expectation over my random choice-- me-- I'm the one running the algorithm, not you giving me the input-- that random choice-- my algorithm actually behaves really well in expectation. In particular, I got constant time for finding, inserting, and deleting into this data structure, in expectation. We did a little proof of-- that the chain links where we stored collisions in our hash function-- in our hash table-- sorry-- those wouldn't be very long, and so if they were constant, then I don't have to search more than a constant number of things when I go to an-- a hashed index location. Does everyone remember what we talked about last week? I didn't show you this chart at the end, but I'm showing it to you now. Essentially, what we had was we have a bunch of different ways to deal with this set interface. And last week, we talked about the sorted array, and then we talked about this direct access array and this hash table, which do better for these dictionary-- the find, and insert, and delete operations--","76.64813232421875","6","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_3_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"193","In the direct access sort algorithm, why is the direct access array initialized with size \\( u \\)?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 2: Data Structures 
Lecture 2: Data Structures 
Data Structure Interfaces 
• A data structure is a way to store data, with algorithms that support operations on the data 
• Collection of supported operations is called an interface (also API or ADT) 
• Interface is a speciﬁcation: what operations are supported (the problem!) 
• Data structure is a representation: how operations are supported (the solution!) 
• In this class, two main interfaces: Sequence and Set 
Sequence Interface (L02, L07) 
• Maintain a sequence of items (order is extrinsic) 
• Ex: (x0, x1, x2, . . . , xn−1) (zero indexing) 
• (use n to denote the number of items stored in the data structure) 
• Supports sequence operations: 
Container 
build(X) 
len() 
given an iterable X, build sequence from items in X 
return the number of stored items 
Static 
iter seq() 
get at(i) 
set at(i, x) 
return the stored items one-by-one in sequence order 
return the ith item 
replace the ith item with x 
Dynamic 
insert at(i, x) 
delete at(i) 
insert first(x) 
delete first() 
insert last(x) 
delete last() 
add x as the ith item 
remove and return the ith item 
add x as the ﬁrst item 
remove and return the ﬁrst item 
add x as the last item 
remove and return the last item 
• Special case interfaces: 
stack 
insert last(x) and delete last() 
queue 
insert last(x) and delete first() 
","76.22322082519531","7","DPRSearchEngine","79a07dc1cb47d76dae2ffedc701e3d2b_MIT6_006S20_lec2_1_pdf","79a07dc1cb47d76dae2ffedc701e3d2b_MIT6_006S20_lec2","6.006","2"
"193","In the direct access sort algorithm, why is the direct access array initialized with size \\( u \\)?","&

	
	
	/
def greedy(items, maxCost, keyFunction):
itemsCopy = sorted(items, key = keyFunction,
reverse = True)
result = []
totalValue, totalCost = 0.0, 0.0
for i in range(len(itemsCopy)):
if (totalCost+itemsCopy[i].getCost()) <= maxCost:
result.append(itemsCopy[i])
totalCost += itemsCopy[i].getCost()
totalValue += itemsCopy[i].getValue()
return (result, totalValue) 
	

2
	

","76.21435546875","8","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_24_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"193","In the direct access sort algorithm, why is the direct access array initialized with size \\( u \\)?","namely, random accessing. And if we stored the things that we're looking for, we have unique keys, and those keys are integers. Then, if I have an item with key K, if I store it at index K in my array, then I can find it and manipulate it in constant time.","75.44770050048828","9","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_2_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"193","In the direct access sort algorithm, why is the direct access array initialized with size \\( u \\)?","They take linear time for some of the operations. So the sorting algorithms are not efficient. But they're ones we've seen before, so it's neat to see how they fit in here. They had the-- selection sort and insertion sort had the advantage that they were in place. You just needed a constant number of pointers or indices beyond the array itself. So they're very space efficient. So that was a plus for them. But they take n squared time, so you should never use them, except for n, at most, 100 or something. AVL tree sort is great and then it gets n log n time, probably more complicated than merge sort and you could stick to merge sort. But neither merge sort nor set AVL tree sort are in place. And so the goal of today is to get the best of all those worlds in sorting to get n log n comparisons, which is optimal in the comparison model, but get it to be in place. And that's what we're going to get with binary heaps. We're going to design a data structure that happens to build a little bit faster-- as I mentioned, linear time building. So it's not representing a sorted order in the same way that AVL trees are. But it will be kind of tree-based. It will also be array-based. We're going to get logarithmic time for insert and delete_max. It happens to be amortized, because we use arrays. But the key thing is that it's an in-place data structure. It only consists of an array of the items. And so, when we plug it into our sorting algorithm-- priority queue sort or generic sorting algorithm-- not only do we get n log n performance, but we also get an in-place sorting algorithm. This will be our first and only-- to this class-- n log n in-place sorting algorithm. Cool. That's the goal.","75.18534088134766","10","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_5_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"194","How can keys in a larger range \\( u = \\Omega(n^2) \\) be represented for the direct access sort?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","78.15486145019531","1","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"194","How can keys in a larger range \\( u = \\Omega(n^2) \\) be represented for the direct access sort?","That's what we called a direct access array. A direct access array-- really not different than a regular array, except how are you using it when we were talking about sequences is we are giving extrinsic semantics to the slots where we are storing these things. Basically, I could put any item in any slot. Where it was in my array had nothing to do with what those things were. Here we are imposing intrinsic semantics on my array that, if I have an item with key K, it must be at index K. That's the thing that we're taking advantage of here. And then we can use this nice, powerful linear branching random access operation to find that thing in constant time, because that's our model of computation. OK, then what was the problem with this direct access array? Anyone shout it out. Space-- right. So we had to instantiate a direct access array that was the size of the space of our keys. In general, my index location is-- could go from 0 to some positive number. If I a very large positive numbers, if I was sorting-- if I was searching among your MIT IDs, I'd have to have a direct access array that was that spanned that space of possible keys you could have. And that could be much larger than n. And so the rest of the time we talked about how to fix that space problem. We can reduce the space by taking that larger key space from 0 to u, which could be very large, and map it down to a small space. Now, in general, if I give you a fixed hash function there, that's not going to be good in-- for all inputs. If your inputs are very well distributed over the key space, then it is good, but in general, there would be hash functions with some inputs that will be bad. That's what we argued. And so for the rest of the time there, we talked about hash families, choosing a hash function randomly from among a large set of hash functions, which had a property that, if I chose this thing randomly and you, generating your input, didn't know which random numbers I was picking, the expectation over my random choice-- me-- I'm the one running the algorithm, not you giving me the input-- that random choice-- my algorithm actually behaves really well in expectation. In particular, I got constant time for finding, inserting, and deleting into this data structure, in expectation. We did a little proof of-- that the chain links where we stored collisions in our hash function-- in our hash table-- sorry-- those wouldn't be very long, and so if they were constant, then I don't have to search more than a constant number of things when I go to an-- a hashed index location. Does everyone remember what we talked about last week? I didn't show you this chart at the end, but I'm showing it to you now. Essentially, what we had was we have a bunch of different ways to deal with this set interface. And last week, we talked about the sorted array, and then we talked about this direct access array and this hash table, which do better for these dictionary-- the find, and insert, and delete operations--","77.99091339111328","2","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_3_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"194","How can keys in a larger range \\( u = \\Omega(n^2) \\) be represented for the direct access sort?","&

	
	
	/
def greedy(items, maxCost, keyFunction):
itemsCopy = sorted(items, key = keyFunction,
reverse = True)
result = []
totalValue, totalCost = 0.0, 0.0
for i in range(len(itemsCopy)):
if (totalCost+itemsCopy[i].getCost()) <= maxCost:
result.append(itemsCopy[i])
totalCost += itemsCopy[i].getCost()
totalValue += itemsCopy[i].getValue()
return (result, totalValue) 
	

2
	

","77.96162414550781","3","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_24_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"194","How can keys in a larger range \\( u = \\Omega(n^2) \\) be represented for the direct access sort?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","77.88121032714844","4","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"194","How can keys in a larger range \\( u = \\Omega(n^2) \\) be represented for the direct access sort?","namely, random accessing. And if we stored the things that we're looking for, we have unique keys, and those keys are integers. Then, if I have an item with key K, if I store it at index K in my array, then I can find it and manipulate it in constant time.","77.01372528076172","5","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_2_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"194","How can keys in a larger range \\( u = \\Omega(n^2) \\) be represented for the direct access sort?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 5: Linear Sorting 
Lecture 5: Linear Sorting 
Review 
• Comparison search lower bound: any decision tree with n nodes has height ≥dlg(n+1)e−1 
• Can do faster using random access indexing: an operation with linear branching factor! 
• Direct access array is fast, but may use a lot of space (Θ(u)) 
• Solve space problem by mapping (hashing) key space u down to m = Θ(n) 
• Hash tables give expected O(1) time operations, amortized if dynamic 
• Expectation input-independent: choose hash function randomly from universal hash family 
• Data structure overview! 
• Last time we achieved faster ﬁnd. Can we also achieve faster sort? 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
Direct Access Array 
u 
1 
1 
u 
u 
Hash Table 
n(e) 
1(e) 
1(a)(e) 
n 
n 
","77.00425720214844","6","DPRSearchEngine","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5_1_pdf","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5","6.006","5"
"194","How can keys in a larger range \\( u = \\Omega(n^2) \\) be represented for the direct access sort?","What's the worst case performance of a hash table? If I have to look up something in a hash table, and I happen to choose a bad hash table-- hash function, what's the worst case here? What? n, right? It's worse than a sorted array, because potentially, I hashed everything that I was storing to the same index in my hash table, and to be able to distinguish between them, I can't do anything more than a linear search. I could store another set's data structure as my chain and do better that way. That's actually how Java does it. They store a data structure we're going to be talking about next week as the chains so that they can get, worst case, log n. But in general, that hash table is only good if we're allowing-- OK, I want this to be expected good, but in the worst case, if I really need that operation to be worst case-- I really can't afford linear time ever for an operation of that kind-- then I don't want to use a hash table. And so on your p set 2, everything we ask you for is worst case, so probably, you don't want to be using hash tables. OK? Yes? AUDIENCE: What does the subscript e mean? JASON KU: What does the subscript e mean? That's great. In this chart, I put a subscript on this is an expected runtime, or an A meaning this is an amortized runtime. At the end, we talked about how, if we had too many things in our hash table, then, as long as we didn't do it too often-- this is a little hand wavey argument, but the same kinds of ideas as the dynamic array-- if, whenever we got a linear-- we are more than a linear factor away from where we are trying-- basically, the fill factor we were trying to be, then we could just completely rebuild the hash table with the new hash function randomly chosen from our hash table with a new size, and we could get amortized bounds. And so that's what Python-- how Python implements dictionaries, or sets, or even objects when it's trying to map keys to different things. So that's hash tables. That's great. The key thing here is, well, actually, if your range of keys is small, or if you as a programmer have the ability to choose the keys that you identify your objects with, you can actually choose that range to be small, to be linear, to be small with respect to your items. And you don't need a hash table. You can just use a direct access array, because if you know your key space is small, that's great. So a lot of C programmers probably would like to do something like that, because they don't have access to-- maybe C++ programmers would have access to their hash table. Any questions on this stuff before we move on? Yeah? AUDIENCE: So why is [INAUDIBLE]? JASON KU: Why is it expected? When I'm building, I could insert-- I'm inserting these things from x 1 by 1 into my hash table. Each of those insert operations-- I'm looking up to see whether that-- an item with that key already exists in my hash table. And so I have to look down the chain to see where it is. However, if I happen to know that all of my keys are unique in my input, all the items I'm trying to store are unique, then I don't have to do that check and I can get worst case linear time. Does that make sense? All right. It's a subtlety, but that's a great question. OK, so today, instead of talking about searching, we're talking about sorting. Last week, we saw a few ways to do sort. Some of them were quadratic-- insertion sort and selection sort-- and then we had one that was n log n. And this thing, n log n, seemed pretty good, but can I do better? Can I do better? Well, what we're going to show at the beginning of this class is, in this comparison model, no. n log n is optimal. And we're going to go through the exact same line of reasoning that we had last week. So in the comparison model, what did we use when we were trying to make this argument that any comparison model algorithm was going to take at least log n time? What we did was we said, OK, I can think of any model in the comparison model-- any algorithm in the comparison model as kind of this-- some comparisons happen. They branch in a binary sense, but you could have it generalized to any constant branching factor. But for our purposes, binary's fine. And what we said was that there were at least n outputs-- really n plus 1, but-- at least order n outputs. And we showed that-- or we argued to you that the height of this tree had to be at least log n-- log the number of leaves. It had to be at least log the number of leaves. That was the height of the decision tree. And if this decision tree represented a search algorithm, I had to walk down and perform these comparisons in order, reach a leaf where I would output something. If the minimum height of any binary tree on a linear number of leaves is log n, then any algorithm in the comparison model also has to take log n time, because it has to do that many comparisons to differentiate between all possible outputs. Does that make sense? All right. So in the sort problem, how many possible outputs are there?","75.86666107177734","7","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_4_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"194","How can keys in a larger range \\( u = \\Omega(n^2) \\) be represented for the direct access sort?","4 
Lecture 1: Introduction 
1 
def birthday_match(students): 
2 
’’’ 
3 
Find a pair of students with the same birthday 
4 
Input: 
tuple of student (name, bday) tuples 
5 
Output: tuple of student names or None 
6 
’’’ 
7 
n = len(students) 
# O(1) 
8 
record = StaticArray(n) 
# O(n) 
9 
for k in range(n): 
# n 
10 
(name1, bday1) = students[k] 
# O(1) 
11 
# Return pair if bday1 in record 
12 
for i in range(k): 
# k 
13 
(name2, bday2) = record.get_at(i) 
# O(1) 
14 
if bday1 == bday2: 
# O(1) 
15 
return (name1, name2) 
# O(1) 
16 
record.set_at(k, (name1, bday1)) 
# O(1) 
17 
return None 
# O(1) 
Example: Running Time Analysis 
• Two loops: outer k ∈{0, . . . , n − 1}, inner is i ∈{0, . . . , k}
P n−1
• Running time is O(n) + 
k=0 (O(1) + k · O(1)) = O(n2) 
• Quadratic in n is polynomial. Efﬁcient? Use different data structure for record! 
How to Solve an Algorithms Problem 
1. Reduce to a problem you already know (use data structure or algorithm) 
Search Problem (Data Structures) 
Sort Algorithms 
Static Array (L01) 
Insertion Sort (L03) 
Linked List (L02) 
Selection Sort (L03) 
Dynamic Array (L02) 
Merge Sort (L03) 
Sorted Array (L03) 
Counting Sort (L05) 
Direct-Access Array (L04) 
Radix Sort (L05) 
Hash Table (L04) 
AVL Sort (L07) 
Balanced Binary Tree (L06-L07) 
Heap Sort (L08) 
Binary Heap (L08) 
2. Design your own (recursive) algorithm 
• Brute Force 
• Decrease and Conquer 
• Divide and Conquer 
• Dynamic Programming (L15-L19) 
• Greedy / Incremental 
Shortest Path Algorithms 
Breadth First Search (L09) 
DAG Relaxation (L11) 
Depth First Search (L10) 
Topological Sort (L10) 
Bellman-Ford (L12) 
Dijkstra (L13) 
Johnson (L14) 
Floyd-Warshall (L18) 
","75.4930419921875","8","DPRSearchEngine","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_4_pdf","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1","6.006","1"
"194","How can keys in a larger range \\( u = \\Omega(n^2) \\) be represented for the direct access sort?","If you think about it a little bit, this is exactly binary search on an array. It just happens to be on a tree instead. If you think of an array like this, what does binary search do? It first looks at the key in the middle. I'm going to draw that as the root. And then, it recurses either on the left chunk, which I will draw recursively, or on the right chunk. And so if you happen to have a perfect binary tree like this one, it is simulating exactly binary search in this array. But this we're going to be able to maintain dynamically-- not perfect any more, but close. Whereas this we could not maintain in sorted order. So this is like a generalization of binary search to work on trees instead of on arrays. And for this reason, set binary trees are called binary search trees, because they're the tree version of binary search. So there's many equivalent names. So binary search tree is another name for set binary tree. And the key thing that makes this algorithm work is the so-called binary search tree property, which is all the keys in the left subtree of a node are less than the root, or of that node, and that key is less than all the keys in the right subtree. And this is true recursively all the way down. And so that's how you prove that this algorithm is correct by this property. Why is this true? Because if we can maintain traversal order to be increasing key, then that's exactly what traversal order means. It tells you all the things in the left subtree come before the root, which come before all the things in the right subtree.","74.99038696289062","9","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_4_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"194","How can keys in a larger range \\( u = \\Omega(n^2) \\) be represented for the direct access sort?","I'll call them left justified. And these two properties together is what I call a complete binary tree. Why is this interesting? Because I claim I can represent a tree like this as an array. I've narrowed things down enough that I can draw an array down here. And what I'm going to do is write these nodes in depth order. So I write A first, because that's step 0. Then B, C, that's step 1. Then, well, they're alphabetical. I made it that way. D, E, F, G is depth 2. And then H, I, J is step 3. This is very different from traversal order of a tree. Traversal order would have been H, D, I, B, J, E, A, F, C, G, OK? But this is what we might call depth order, do the lowest depth nodes first-- very different way to lay things out or to linearize our data. And this is what a heap is going to look like. So the cool thing is, between complete binary trees and arrays is a bijection. For every array, there's a unique complete binary tree. And for every complete binary tree, there's a unique array. Why? Because the complete constraint forces everything-- forces my hand. There's only-- if I give you a number n, there is one tree shape of size n, right? You just fill in the nodes top down until you get to the last level. And then you have to fill them in left to right. It's what you might call reading order for writing down nodes. And the array is telling you which keys go where. This is the first node you write down at the root, this is the next node you write down at the left child of the root, and so on. So here we have a binary tree represented as an array, or array representing a binary tree. The very specific binary tree, it has a clear advantage, which is it is guaranteed balance. No rotations necessary in heaps, because complete binary trees are always balanced. In fact, they have the best height they possibly could, which is ceiling of log n. Balanced, remember, just meant you were big O of log n. This is 1 times log n. So it's the best level of balance you could hope for. So somehow, I claim, we can maintain a complete binary tree for solving priority queues. This would not be possible if you were trying to solve the whole set interface. And that's kind of the cool thing about heaps, is that by just focusing on the subset of the set interface, we can do more. We can maintain this very strong property. And because we have this very strong property, we don't even need to store this tree. We're not going to store left and right pointers and parent pointers, we're just going to store the array.","74.60565185546875","10","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_8_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"195","What does the comparison model imply about the decision tree of an algorithm?","And a comparison model means-- is that the items, the objects I'm storing-- I can kind of think of them as black boxes. I don't get to touch these things, except the only way that I can distinguish between them is to say, given a key and an item, or two items, I can do a comparison on those keys. Are these keys the same? Is this key bigger than this one? Is it smaller than this one? Those are the only operations I get to do with them. Say, if the keys are numbers, I don't get to look at what number that is. I just get to take two keys and compare them. And actually, all of the search algorithms that we saw on Tuesday we're comparison sort algorithms. What you did was stepped through the program. At some point, you came to a branch and you looked at two keys, and you branched based on whether one key was bigger than another. That was a comparison. And then you move some stuff around, but that was the general paradigm. Those three sorting operations lived in this comparison model.","80.07381439208984","1","DPRSearchEngine","Nu8YGneFCWE.en-j3PyPqV-e1s_2_mp4","Nu8YGneFCWE.en-j3PyPqV-e1s","6.006","4"
"195","What does the comparison model imply about the decision tree of an algorithm?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","77.44801330566406","2","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"195","What does the comparison model imply about the decision tree of an algorithm?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 4: Hashing 
Lecture 4: Hashing 
Review 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
• Idea! Want faster search and dynamic operations. Can we find(k) faster than Θ(log n)? 
• Answer is no (lower bound)! (But actually, yes...!?) 
Comparison Model 
• In this model, assume algorithm can only differentiate items via comparisons 
• Comparable items: black boxes only supporting comparisons between pairs 
• Comparisons are <, ≤, >, ≥, =, =6 , outputs are binary: True or False 
• Goal: Store a set of n comparable items, support find(k) operation 
• Running time is lower bounded by # comparisons performed, so count comparisons! 
Decision Tree 
• Any algorithm can be viewed as a decision tree of operations performed 
• An internal node represents a binary comparison, branching either True or False 
• For a comparison algorithm, the decision tree is binary (draw example) 
• A leaf represents algorithm termination, resulting in an algorithm output 
• A root-to-leaf path represents an execution of the algorithm on some input 
• Need at least one leaf for each algorithm output, so search requires ≥ n + 1 leaves 
","75.75862121582031","3","DPRSearchEngine","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_1_pdf","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4","6.006","4"
"195","What does the comparison model imply about the decision tree of an algorithm?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Monte Carlo Simulation  
A method of estimating the value of an unknown 
quantity using the principles of inferential statistics 
Inferential statistics 
◦ Population: a set of examples 
◦ Sample: a proper subset of a population 
◦ Key fact: a random sample tends to exhibit the same  
properties as the population from which it is drawn  
Exactly what we did with random walks 
6.0002 LECTURE 6 
4
","74.2265625","4","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_4_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"195","What does the comparison model imply about the decision tree of an algorithm?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","73.16090393066406","5","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"195","What does the comparison model imply about the decision tree of an algorithm?"," 
 
  
  
 
 
 
 
 
 
   
 
 
 
 
  
 
  
 
  
 
 
  
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
   
 
    
   
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
   
  
Time Hierarchy Theorem (1/2) 
Theorem: For any !: ℕ → ℕ where ! is time constructible 
there is a language % where % requires & ! ' 
time, i.e, 
1) % is decidable in & ! ' 
time, and 
2) % is not decidable in ( ! ' / log ! ' 
time 
- .
On other words, TIME (
⊆, TIME ! ' 
/01 - . 
Proof outline:  Give TM 3 where 
1) 3 runs in & ! ' 
time 
2) 3 ensures that 4(3) ≠ 4(8) for every TM 8 that runs in ( ! ' / log ! ' 
time . 
Let % = 4(3). 
10 
","73.0963134765625","6","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_10_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"195","What does the comparison model imply about the decision tree of an algorithm?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Clustering Algorithms  
§Hierarchical  clustering  
◦ Can select number  of clusters using dendogram 
◦ Deterministic 
◦ Flexible with respect to linkage criteria 
◦ Slow 
◦ Naïve algorithm n3 
◦ n2 algorithms exist for some linkage criteria 
§K-means a much faster greedy algorithm 
◦ Most useful when you know how many clusters  you want  
6.0002  LECTURE 12 
9 
","72.85546875","7","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_9_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"195","What does the comparison model imply about the decision tree of an algorithm?","It's the name of a class, and here are three methods of that class. Fit, which takes a sequence of feature vectors and a sequence of labels and returns an object of type logistic regression. So this is the place where the optimization is done. Now all the examples I'm going to show you, these two sequences will be-- well all right. So think of this as the sequence of feature vectors, one per passenger, and the labels associated with those. So this and this have to be the same length. That produces an object of this type, and then I can ask for the coefficients, which will return the weight of each variable, each feature. And then I can make a prediction, given a feature vector returned the probabilities of different labels. Let's look at it as an example. So first let's build the model.","72.84765625","8","DPRSearchEngine","eg8DJYwdMyg.en-qlPKC2UN_YU_6_mp4","eg8DJYwdMyg.en-qlPKC2UN_YU","6.0002","13"
"195","What does the comparison model imply about the decision tree of an algorithm?"," 
 
 
 
 
 
   
  
 
  
 
 
   
 
 
  
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
  
 
 
 
 
 
 
Check-in 8.2 
Recall the Queue Automaton (QA) defined in Pset 2. 
It is similar to a PDA except that it is deterministic 
and it has a queue instead of a stack. 
Let !QA = { &, ( | & is a QA and & accepts (} 
Is !QA decidable? 
(a) Yes, because QA are similar to PDA and !PDA is decidable. 
(b) No, because “yes” would contradict results we now know. 
(c) We don’t have enough information to answer this question. 
8 
Check-in 8.2 
","72.7098159790039","9","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_8_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"195","What does the comparison model imply about the decision tree of an algorithm?","What's the worst case performance of a hash table? If I have to look up something in a hash table, and I happen to choose a bad hash table-- hash function, what's the worst case here? What? n, right? It's worse than a sorted array, because potentially, I hashed everything that I was storing to the same index in my hash table, and to be able to distinguish between them, I can't do anything more than a linear search. I could store another set's data structure as my chain and do better that way. That's actually how Java does it. They store a data structure we're going to be talking about next week as the chains so that they can get, worst case, log n. But in general, that hash table is only good if we're allowing-- OK, I want this to be expected good, but in the worst case, if I really need that operation to be worst case-- I really can't afford linear time ever for an operation of that kind-- then I don't want to use a hash table. And so on your p set 2, everything we ask you for is worst case, so probably, you don't want to be using hash tables. OK? Yes? AUDIENCE: What does the subscript e mean? JASON KU: What does the subscript e mean? That's great. In this chart, I put a subscript on this is an expected runtime, or an A meaning this is an amortized runtime. At the end, we talked about how, if we had too many things in our hash table, then, as long as we didn't do it too often-- this is a little hand wavey argument, but the same kinds of ideas as the dynamic array-- if, whenever we got a linear-- we are more than a linear factor away from where we are trying-- basically, the fill factor we were trying to be, then we could just completely rebuild the hash table with the new hash function randomly chosen from our hash table with a new size, and we could get amortized bounds. And so that's what Python-- how Python implements dictionaries, or sets, or even objects when it's trying to map keys to different things. So that's hash tables. That's great. The key thing here is, well, actually, if your range of keys is small, or if you as a programmer have the ability to choose the keys that you identify your objects with, you can actually choose that range to be small, to be linear, to be small with respect to your items. And you don't need a hash table. You can just use a direct access array, because if you know your key space is small, that's great. So a lot of C programmers probably would like to do something like that, because they don't have access to-- maybe C++ programmers would have access to their hash table. Any questions on this stuff before we move on? Yeah? AUDIENCE: So why is [INAUDIBLE]? JASON KU: Why is it expected? When I'm building, I could insert-- I'm inserting these things from x 1 by 1 into my hash table. Each of those insert operations-- I'm looking up to see whether that-- an item with that key already exists in my hash table. And so I have to look down the chain to see where it is. However, if I happen to know that all of my keys are unique in my input, all the items I'm trying to store are unique, then I don't have to do that check and I can get worst case linear time. Does that make sense? All right. It's a subtlety, but that's a great question. OK, so today, instead of talking about searching, we're talking about sorting. Last week, we saw a few ways to do sort. Some of them were quadratic-- insertion sort and selection sort-- and then we had one that was n log n. And this thing, n log n, seemed pretty good, but can I do better? Can I do better? Well, what we're going to show at the beginning of this class is, in this comparison model, no. n log n is optimal. And we're going to go through the exact same line of reasoning that we had last week. So in the comparison model, what did we use when we were trying to make this argument that any comparison model algorithm was going to take at least log n time? What we did was we said, OK, I can think of any model in the comparison model-- any algorithm in the comparison model as kind of this-- some comparisons happen. They branch in a binary sense, but you could have it generalized to any constant branching factor. But for our purposes, binary's fine. And what we said was that there were at least n outputs-- really n plus 1, but-- at least order n outputs. And we showed that-- or we argued to you that the height of this tree had to be at least log n-- log the number of leaves. It had to be at least log the number of leaves. That was the height of the decision tree. And if this decision tree represented a search algorithm, I had to walk down and perform these comparisons in order, reach a leaf where I would output something. If the minimum height of any binary tree on a linear number of leaves is log n, then any algorithm in the comparison model also has to take log n time, because it has to do that many comparisons to differentiate between all possible outputs. Does that make sense? All right. So in the sort problem, how many possible outputs are there?","72.63232421875","10","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_4_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"196","What is the base case when dealing with an empty suffix in dynamic programming problems?"," 
 
 
 
   
 
 
 
 
 
 
 
 
 
   
 
 
 
 
  
 
 
  
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Closure Properties for Regular Languages 
Theorem: If !"", !$ are regular languages, so is !""!$ (closure under ∘) 
Recall proof attempt: Let &"" = ()"", Σ, +"", ,"", -"") recognize !"" 
&$ = ()$, Σ, +$, ,$, -$) recognize !$ 
Construct & = (), Σ, +, ,0, -) recognizing !""!$ 
&"" 
&$ 
& should accept input 0 
if 0 = 12 where 
&"" accepts 1 and &$ accepts 2. 
& 
0 
1
2 
Doesn’t work: Where to split 0? 
Hold off. Need new concept. 
3 
","79.3370132446289","1","DPRSearchEngine","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_3_pdf","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2","18.404J","2"
"196","What is the base case when dealing with an empty suffix in dynamic programming problems?"," 
 
 
    
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Return to Closure Properties 
Recall Theorem: If !"", !$ are regular languages, so is !"" ∪!$ 
(The class of regular languages is closed under union) 
New Proof (sketch): Given DFAs &"" and &$ recognizing !"" and !$ 
&$
&"" 
ε 
ε 
& 
Construct NFA & recognizing !"" ∪!$ 
Nondeterminism 
parallelism 
vs 
guessing 
7 
","79.05328369140625","2","DPRSearchEngine","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_7_pdf","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2","18.404J","2"
"196","What is the base case when dealing with an empty suffix in dynamic programming problems?","Header for Decision Tree Implementa#on 
6.0002 LECTURE 2 
9 
def maxVal(toConsider, avail): 
    """"""Assumes toConsider a list of items,  
               avail a weight 
       Returns a tuple of the total value of a  
           solution to 0/1 knapsack problem and  
           the items of that solution""""” 
toConsider. Those items that nodes higher up in the tree 
(corresponding to earlier calls in the recursive call stack) 
have not yet considered 
 
avail. The amount of space still available  
","78.82763671875","3","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_9_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"196","What is the base case when dealing with an empty suffix in dynamic programming problems?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
If we know that some problem (say !TM) is undecidable, 
we can use that to show other problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Recall Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
2 
","78.36528778076172","4","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_2_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"196","What is the base case when dealing with an empty suffix in dynamic programming problems?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
Use our knowledge that !TM is undecidable to show other 
problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
10 
","78.0730209350586","5","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_10_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"196","What is the base case when dealing with an empty suffix in dynamic programming problems?"," 
 
 
  
  
 
 
  
 
  
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Emptiness Problem for DFAs 
Let !DFA = & & is a DFA and ' & = ∅} 
Theorem: !DFA is decidable 
Proof: Give TM *E−DFA that decides !DFA . 
*E−DFA = “On input & 
[IDEA: Check for a path from start to accept.] 
1. 
Mark start state. 
2. 
Repeat until no new state is marked: 
Mark every state that has an incoming arrow 
from a previously marked state. 
3. 
Accept if no accept state is marked. 
Reject if some accept state is marked.” 
5 
","78.04517364501953","6","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_5_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"196","What is the base case when dealing with an empty suffix in dynamic programming problems?","   
  
 
 
   
 
 
 
 
 
 
 
   
 
 
 
 
 
 
   
 
   
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
!""#$ ∈ PSPACE 
Theorem: !""#$ ∈ PSPACE 
Proof: “On input 〈'〉 
1. If ' has no quantifiers, then ' has no variables 
so either ' = True or ' = False.  Output accordingly. 
2. If ' = ∃+ , then evaluate , with + = TRUE and + = FALSE recursively. 
Accept if either accepts. Reject if not. 
3. If ' = ∀+ , then evaluate , with + = TRUE and + = FALSE recursively. 
Accept if both accept. Reject if not.” 
Space analysis: 
Each recursive level uses constant space (to record the + value). 
The recursion depth is the number of quantifiers, at most . = | ' |. 
So !""#$ ∈ SPACE(.) 
6 
","77.92298126220703","7","DPRSearchEngine","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17_6_pdf","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17","18.404J","17"
"196","What is the base case when dealing with an empty suffix in dynamic programming problems?","What's the worst case performance of a hash table? If I have to look up something in a hash table, and I happen to choose a bad hash table-- hash function, what's the worst case here? What? n, right? It's worse than a sorted array, because potentially, I hashed everything that I was storing to the same index in my hash table, and to be able to distinguish between them, I can't do anything more than a linear search. I could store another set's data structure as my chain and do better that way. That's actually how Java does it. They store a data structure we're going to be talking about next week as the chains so that they can get, worst case, log n. But in general, that hash table is only good if we're allowing-- OK, I want this to be expected good, but in the worst case, if I really need that operation to be worst case-- I really can't afford linear time ever for an operation of that kind-- then I don't want to use a hash table. And so on your p set 2, everything we ask you for is worst case, so probably, you don't want to be using hash tables. OK? Yes? AUDIENCE: What does the subscript e mean? JASON KU: What does the subscript e mean? That's great. In this chart, I put a subscript on this is an expected runtime, or an A meaning this is an amortized runtime. At the end, we talked about how, if we had too many things in our hash table, then, as long as we didn't do it too often-- this is a little hand wavey argument, but the same kinds of ideas as the dynamic array-- if, whenever we got a linear-- we are more than a linear factor away from where we are trying-- basically, the fill factor we were trying to be, then we could just completely rebuild the hash table with the new hash function randomly chosen from our hash table with a new size, and we could get amortized bounds. And so that's what Python-- how Python implements dictionaries, or sets, or even objects when it's trying to map keys to different things. So that's hash tables. That's great. The key thing here is, well, actually, if your range of keys is small, or if you as a programmer have the ability to choose the keys that you identify your objects with, you can actually choose that range to be small, to be linear, to be small with respect to your items. And you don't need a hash table. You can just use a direct access array, because if you know your key space is small, that's great. So a lot of C programmers probably would like to do something like that, because they don't have access to-- maybe C++ programmers would have access to their hash table. Any questions on this stuff before we move on? Yeah? AUDIENCE: So why is [INAUDIBLE]? JASON KU: Why is it expected? When I'm building, I could insert-- I'm inserting these things from x 1 by 1 into my hash table. Each of those insert operations-- I'm looking up to see whether that-- an item with that key already exists in my hash table. And so I have to look down the chain to see where it is. However, if I happen to know that all of my keys are unique in my input, all the items I'm trying to store are unique, then I don't have to do that check and I can get worst case linear time. Does that make sense? All right. It's a subtlety, but that's a great question. OK, so today, instead of talking about searching, we're talking about sorting. Last week, we saw a few ways to do sort. Some of them were quadratic-- insertion sort and selection sort-- and then we had one that was n log n. And this thing, n log n, seemed pretty good, but can I do better? Can I do better? Well, what we're going to show at the beginning of this class is, in this comparison model, no. n log n is optimal. And we're going to go through the exact same line of reasoning that we had last week. So in the comparison model, what did we use when we were trying to make this argument that any comparison model algorithm was going to take at least log n time? What we did was we said, OK, I can think of any model in the comparison model-- any algorithm in the comparison model as kind of this-- some comparisons happen. They branch in a binary sense, but you could have it generalized to any constant branching factor. But for our purposes, binary's fine. And what we said was that there were at least n outputs-- really n plus 1, but-- at least order n outputs. And we showed that-- or we argued to you that the height of this tree had to be at least log n-- log the number of leaves. It had to be at least log the number of leaves. That was the height of the decision tree. And if this decision tree represented a search algorithm, I had to walk down and perform these comparisons in order, reach a leaf where I would output something. If the minimum height of any binary tree on a linear number of leaves is log n, then any algorithm in the comparison model also has to take log n time, because it has to do that many comparisons to differentiate between all possible outputs. Does that make sense? All right. So in the sort problem, how many possible outputs are there?","77.89070892333984","8","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_4_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"196","What is the base case when dealing with an empty suffix in dynamic programming problems?","&

	
	
	/
def greedy(items, maxCost, keyFunction):
itemsCopy = sorted(items, key = keyFunction,
reverse = True)
result = []
totalValue, totalCost = 0.0, 0.0
for i in range(len(itemsCopy)):
if (totalCost+itemsCopy[i].getCost()) <= maxCost:
result.append(itemsCopy[i])
totalCost += itemsCopy[i].getCost()
totalValue += itemsCopy[i].getValue()
return (result, totalValue) 
	

2
	

","77.8445053100586","9","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_24_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"196","What is the base case when dealing with an empty suffix in dynamic programming problems?"," 
 
 
  
  
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
    
  
 
 
 
 
 
  
 
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
S 
a
R 
T 
a
Emptiness Problem for CFGs 
Let !CFG = { ' | ' is a CFG and ) ' = ∅} 
Theorem: !CFG is decidable 
Proof: 
,E−CFG = “On input ' 
[IDEA: work backwards from terminals] 
1. Mark all occurrences of terminals in '. 
S → RTa
2. Repeat until no new variables are marked 
R → 
R
Tb
Tb
Mark all occurrences of variable A if 
A → B1B2 ⋯ B4 is a rule and all B5 were already marked. 
T → a 
3. 
Reject if the start variable is marked. 
Accept if not.” 
8 
","77.59130859375","10","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_8_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"197","What is the significance of a problem being classified as NP-complete?","If you compare these two classes, P and NP. P, first of all, is going to be a subset of NP, both in terms of the way we defined it because, deterministic machines are a special case of non-deterministic machines. But also if you want to think about testing membership, if you can test membership easily then you can certainly verify it in terms of the certificate. You don't even need it. The certificate is irrelevant at that point. Because whatever the certificate is, you can still test yourself whether the input is in the language or not. The big question, as I mentioned, is whether these two classes are the same. So does being able to verify membership quickly, say with one of these certificates, allow you to dispense with the certificate? Not even need a certificate and just test it for yourself whether you're in the language. And do that in polynomial time. That's the question. For a problem like Hamiltonian path, do you need to search for the answer if you're doing it deterministically? Or can you somehow avoid that and just come up with the answer directly with a polynomial time solution? Nobody knows the answer to that. And it goes back, at this point, quite a long time. It's almost 60 years now. That problem has been around 60 years. No, that would be 50 years. No, 50 years, almost 50 years. Most people believe that P is different from NP. In other words, that there are problems in P-- in NP which are not in P. A candidate would be the Hamiltonian path problem. But it seems to be very hard to prove that. And part of the reason is, how do you prove that a problem like Hamiltonian path does not have a polynomial time algorithm. It's very tricky to do that, because the class of polynomial time algorithms is a very rich class. Polynomial time algorithms are very powerful. And to try to prove-- there's no clever way of solving the Hamiltonian path problem. It just seems to be beyond our present day mathematics. I believe someday somebody's going to solve it. But so far, no one has succeeded. So what I thought we would do is-- I think I have a check-in here.","74.60437774658203","1","DPRSearchEngine","1VhnDdQsELo.en-j3PyPqV-e1s_8_mp4","1VhnDdQsELo.en-j3PyPqV-e1s","18.404J","14"
"197","What is the significance of a problem being classified as NP-complete?","≤ 
≤ 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
   
 
 
 
  
  
 
 
 
  
 
 
 
 
Why
% and not
%'%()* when defining PSPACE-complete?
- Reductions should be “weaker” than the class. Otherwise all
problems in the class would be reducible to each other, and then 
all problems in the class would be complete.
Theorem: +,!- is PSPACE-complete
PSPACE-completeness 
Defn: ! is PSPACE-complete if 
1) ! ∈ PSPACE 
2) For all # ∈ PSPACE, # ≤% ! 
If ! is PSPACE-complete and ! ∈ P then P = PSPACE. 
Check-in 18.1 
Knowing that +,!- is PSPACE-complete, 
what can we conclude if +,!- ∈ NP? 
Check all that apply. 
(a) P = PSPACE 
(b) NP = PSPACE 
(c) P = NP 
(d) NP = coNP 
5 
PSPACE-complete 
NP-complete 
PSPACE = 
NPSPACE 
NP
P 
Think of complete problems as the “hardest” 
in their associated class. 
Check-in 18.1 
","74.57865905761719","2","DPRSearchEngine","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18_5_pdf","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18","18.404J","18"
"197","What is the significance of a problem being classified as NP-complete?","So this is saying, it's possible to prove to me that an answer is yes, because if you ever have an input that the answer happens to be yes, you can prove it to me by giving me a certificate. There's always some certificate that proves the answer's yes. Because the verifier, which runs in regular polynomial time-- this is a regular, old-fashioned, down-to-earth verification algorithm, polynomial time in our usual sense-- it will say yes. And furthermore, the yes answers from the verifier are actually meaningful, because if I ever give it a no input, it always says no, no matter what certificate I give it. So this should really formalize what all this means. It's equivalent to the previous definition. This is saying that proofs exist for yes instances. And this is saying that proofs don't exist for no instances, meaning there are no false proofs. So if the verifier ever outputs yes, you know that the answer to your problem is yes. But if it outputs no, you're not sure. Maybe you got the certificate wrong because we only know there's some certificate where the verifier will say yes. Or maybe it was a no input, and then it didn't matter what certificate you used. But it's nice, because it says on, say, Tetris, if I give you the sequence of pieces, it's very easy to write down a verifier which just implements the rules of Tetris. And so then you can at least check whether a solution is valid in the yes case. In the no case, we don't have anything useful. So NP is a structure, some additional structure about the yes inputs in your problem. And a lot of decision problems are in NP. A lot of the problems that we care about can be phrased as an NP problem. As long as it's a decision problem, usually, answering yes or no is provable, like subset sum, like Tetris. These are all problems where, if the answer is yes, I can give you a convincing proof why. And it turns out a lot-- so a lot of problems fall into this NP setting. And so we have some tools for talking about problems being hard with respect to NP. Let me first talk a little bit about P. Does not equal NP, question mark. A lot of people conjecture that P does not equal NP. It's sort of a standard conjecture in theoretical computer science. But we don't know how to prove whether P equals NP or does not equal NP. And so in this picture, I've drawn the hypothesis, which is that NP is a strictly bigger region than P is. But we don't actually know whether there are problems in this region. We don't know whether there are problems in this region between NP and EXP. We conjecture there are problems here and there are problems here. There's definitely problems here or problems here, but we don't know which one. Because we know P does not equal EXP, but we don't know whether P equals NP, and we don't know whether P equals EXP. If you could prove that P does not equal NP, or disprove it, you would win $1 million, which not that much money these days. But you would be famous to for the rest of time if you could ever prove this. Every year, there's usually a crackpot proof that doesn't work out. Some of them go to me. Please don't send them. And anyway, it's a very hard problem. It is sort of the core problem in theoretical computer science, how to prove P does not equal NP. But for the most part, we just assume it. Now, what does this conjecture mean? It essentially means-- the way I like to say it is, you cannot engineer luck. Because NP problems are problems you can solve by lucky algorithms. P are problems you can solve by regular old algorithms. And so if P equalled NP, it means luck doesn't buy you anything, which seems weird. If I can magically make these super powerful guesses, then I can solve the problem that that's NP, that seems super powerful, way more powerful than regular algorithms, where we have to actually brute-force and try all the choices. And so it seems pretty solid that P does not equal NP. That's my-- of course, we don't know how to prove it. Another phrasing is that it's harder to come up with proofs than it is to check them, from a mathematical perspective. This is equivalent to P does not equal NP. So that's why you should believe it. Now, let's go over here.","74.32535552978516","3","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_8_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"197","What is the significance of a problem being classified as NP-complete?","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","73.72549438476562","4","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"197","What is the significance of a problem being classified as NP-complete?","NP-completeness
Defn:  ! is NP-complete if
1)
! ∈NP
2)
For all # ∈NP,  # ≤% !
If ! is NP-complete and ! ∈P then P = NP.
Cook-Levin Theorem:  '#( is NP-complete
Proof:  Next lecture; assume true
Importance of NP-completeness
1)  Showing ! is NP-complete is evidence of computational intractability.
2)  Gives a good candidate for proving P ≠NP.
≤% '#( ≤% 3'#( ≤% +,-./0
NP
To show some language + is NP-complete, 
show  3'#( ≤1 +.   
or some other previously shown 
NP-complete language
today
next lecture
≤% 2#34#(2
Check-in 15.2
Check-in 15.2
What language that we’ve previously seen is 
most analogous to '#(?
(a)
#TM
(b)
0TM
(c)
0616 8 ≥0}
6
","73.64965057373047","5","DPRSearchEngine","c1aca7046a69c913721e5eb910a5fb21_MIT18_404f20_lec15_6_pdf","c1aca7046a69c913721e5eb910a5fb21_MIT18_404f20_lec15","18.404J","15"
"197","What is the significance of a problem being classified as NP-complete?"," 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
   
 
 
 
 
   
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
  
 
 
  
 
  
 
  
Turing machine model – review 
head 
˽ ˽ . . .
a
b
a
b
b
Finite 
read/write input tape 
control 
On input ! a TM "" may halt (enter #acc or #rej) 
) is T-recognizable if ) = +("") for some TM "". 
or loop (run forever). 
) is T-decidable if ) = +("") for some TM decider "". 
So "" has 3 possible outcomes for each input !: 
halts on all inputs 
1. Accept ! (enter #acc ) 
Turing machines model general-purpose computation. 
2. Reject ! by halting (enter #rej ) 
Q: Why pick this model? 
3. Reject ! by looping (running forever) 
A: Choice of model doesn't matter. 
All reasonable models are equivalent in power. 
Virtues of TMs: simplicity, familiarity. 
2 
","73.39269256591797","6","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_2_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"197","What is the significance of a problem being classified as NP-complete?","OK, so now let's talk about NP completeness, because we've kind of set things up. We're not going to prove that the basic theorem, the Cook-Levin theorem about NP completeness, but at least we'll be able to make the definition. OK, here is our definition of what it means for a problem to be NP complete. So a language B is called the NP complete if it has two properties. Number one is that it has to be a member of NP, and number two-- every language in NP has the polynomial time reduce to that language-- to that NP complete language in order for it to be NP complete. So simple picture-- has to be in NP and everything an NP reduces to it. And so that's kind of the magical property that we claim that SAT has. sat, for one thing, is obviously in NP. And as we-- the Cook-Levin theorem shows-- or will show-- everything in NP is reducible to SAT, so SAT's going to be our first example of an NP complete problem. And we're going to get what we claimed also for SAT-- that, if SAT or any other NP complete problem turns out to be solvable in polynomial time, then every NP problem is solvable in polynomial time. And that's immediate, because everything is reducible in polynomial time to the NP complete problem. So if you can do it easily, you can do everything easily just by going through the reduction. OK. So the Cook-Levin theorem, as I mentioned, is that SAT is NP complete. And we're going to actually prove it next lecture, but let's assume for the remainder of this lecture that we know it to be true. So I'll use the terminology of problems being NP complete, assuming that we know-- that we have SAT as NP complete. OK? So we're going to be using some of the things that we're proving next lecture just in the terminology that we're going to be talking today. OK, so here's the picture. Here's the class NP. And everything in NP is polynomial time reducible to SAT. SAT itself is a member of NP, but I didn't want to show it that way because it makes the picture kind of hard to display. So just from the perspective of the reduction, everything in NP is polynomial time reducible to SAT. We'll show that next lecture. Another thing that we'll show next lecture is that SAT, in turn, is polynomial time reducible to 3SAT. So 3SAT, as you remember, are just those problems that are in conjunct-- are in 3CNF. And then what we show today is that 3SAT is polynomial time reducible to clique. So now, taking the assumption that SAT is NP complete-- so everything is polynomial time reduce both the SAT, which is, in turn, polynomial time reducible to 3SAT, and in turn, reducible to clique. These reductions, as we've seen before, composed. You can just apply one reduction function after the next. If each one individually is polynomial, the whole thing as a combination is going to be polynomial. So now we know that 3SAT is going to be also NP complete, because we can reduce anything in NP to SAT, and then to 3SAT, and then we get a reduction directly to 3SAT by composing those two reductions-- and then, furthermore, at the clique. So now we're-- have several NP complete problems. And moving beyond that, we have the HAMPATH problem, which we are going to talk about next. And we'll show another reduction in addition to the one we just showed to clique, now one going from 3SAT to HAMPATH. OK. So in general, I think the takeaway message is that, to show some language is NP complete, you want to show that 3SAT is polynomial time reducible to it. OK, some good questions coming in-- I'll try to answer those. So you're going to take 3SAT and reduce to C. That's the most typical case. There's going to be other examples too, we might start with another problem that you've already shown to be in NP complete, and reduce it to your language. So it doesn't have to start with 3SAT, though often, it does.","72.68266296386719","7","DPRSearchEngine","iZPzBHGDsWI.en-j3PyPqV-e1s_9_mp4","iZPzBHGDsWI.en-j3PyPqV-e1s","18.404J","15"
"197","What is the significance of a problem being classified as NP-complete?","Quick review of today
1.
NTIME ! ""
and NP
2.
#$%&$'# and  ()%&)*+',* ∈NP
3.
P versus NP question
4.
$CFG ∈P via Dynamic Programming
5.
The Satisfiability Problem *$'
6.
Polynomial time reducibility
13
","72.48989868164062","8","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_13_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"197","What is the significance of a problem being classified as NP-complete?","What are oracles? Oracles are a simple thing. But they are a useful concept for a number of reasons. Especially because they're going to tell us something interesting about methods, which may or may not be useful for proving the P versus NP question, when someday somebody hopefully does that. What is an oracle? An oracle is free information you're going to give to a Turing machine, which might affect the difficulty of solving problems. And the way we're going to represent that free information is, we're going to allow the Turing machine to test membership in some specified language, without charging for the work involved. I'm going to allow you have any language at all, some language A. And say a Turing machine with an oracle for A is written this way, M with a superscript A. It's a machine that has a black box that can answer questions. Is some string, which the machine can choose, in A or not? And it gets that answer in one step, effectively for free. So you can imagine, depending upon the language that you're providing to the machine, that may or may not be useful. For example, suppose I give you an oracle for the SAT language. That can be very useful. It could be very useful for deciding SAT, for example. Because now you don't have to go through a brute force search to solve SAT. You just ask the oracle. And the oracle is going to say, yes it's satisfiable, or no it's not satisfiable. But you can use that to solve other languages too, quickly. Because anything that you can do in NP, you can reduce to SAT. So you can convert it to a SAT question, which you can then ship up to the oracle, and the oracle is going to tell you the answer. The word ""oracle"" already sort of conveys something magical. We're not really going to be concerned with the operation of the oracle, so don't ask me how does the oracle work, or what does it correspond to in reality. It doesn't. It's just a mathematical device which provides this free information to the Turing machine, which enables it to compute certain things. It turns out to be a useful concept. It's used in cryptography, where you might imagine the oracle could provide the factors to some number, or the password to some system or something. Free information. And then what can you do with that? So this is a notion that comes up in other places. If we have an oracle, we can think of all of the things that you can compute in polynomial time relative to that oracle. So that's what we-- the terminology that people usually use is sometimes called relativism, or computation relative to having this extra information. So P with an A oracle is all of the language that you can decide in polynomial time if you have an oracle for A. Let's see. Yeah. Somebody's asking me, is it really free or does it cost one unit? Even just setting up the oracle and writing down the question to the oracle is going to take you some number of steps. So you're not going to be able do an infinite number of oracle calls in zero time. So charging one step or zero steps, not going to make a difference. Because you still have to formulate the question. As I pointed out, P with a SAT oracle-- so all the things you do in polynomial time with a SAT oracle includes NP. Does it perhaps include other stuff? Or does it equal NP? Would have been a good check-in question, but I'm not going to ask that. In fact, it seems like it contains other things too. Because co-NP is also contained within P, given a SAT oracle. Because the SAT oracle answer is both yes or no, depending upon the answer. So if the formula is unsatisfiable, the oracle is going to say no, it's not in the language. And now you can do the complement of the SAT problem as well. The unsatisfiability problem. So you can do all of co-NP in the same way. You can also define NP relative to some oracle. So all the things you can do with a non-deterministic Turing machine, where all of the branches have separately access. And they can ask multiple questions, by the way, of the oracle. Independently. Let's do another, a little bit of a more challenging example. The MIN-FORMULA language, which I hope you remember from your homework. So those are all of the formulas that do not have a shorter equivalent formula. They are minimal. You cannot make a smaller formula that's equivalent that gives you the same Boolean function. So you showed, for example, that that language is in P space, as I recall. And there was some other-- you had another two problems about that language. The complement of the MIN-FORMULA problem is in NP with a SAT oracle. So mull that over for a second and then we'll see why. Here's an algorithm, in NP with a SAT oracle algorithm. So in other words, now I want to kind of implement that strategy, which I argued in the homework problem was not legal. But now that I have the SAT oracle, it's going to make it possible where before it was not possible. So let's just understand what I mean by that. If I'm trying to do the non minimal formulas, namely the formulas that do have a shorter equivalent formula. I'm going to guess that shorter formula, called psi. The challenge before was testing whether that shorter formula was actually equivalent to phi. Because that's not obviously doable in polynomial time. But the equivalence problem for formulas is a co-NP problem. Or if you like to think about it the other way, any formula in equivalence is an NP problem, because you just have to-- the witness is the assignment on which they disagree. So two formulas are equivalent if they never disagree. And so that's a co-NP problem. A SAT oracle can solve a co-NP problem. Namely, the equivalence of the two formulas, the input formula and the one that you now deterministically guessed. And if it turns out that they are equivalent, a smaller formula is equivalent to the input formula, you know the input formula is not minimal. And so you can accept. And if it gets the wrong formula, it turns out not to be equivalent, then you reject on that branch of the non-determinism, just like we did before. And if the formula really was minimal, none of the branches is going to find a shorter equivalent formula. So that's why this problem here is in NP with a SAT oracle. So now we're going to try to investigate this on my-- we're getting near the end of the lecture. We're going to look at problems like, well, suppose I compare P with a SAT oracle and NP with a SAT oracle. Could those be the same? Well, there's reasons to believe those are not the same. But could there be any A where P with A oracle is the same as NP with an A oracle? It seems like no, but actually that's wrong. There is a language, there are languages for which NP with that oracle and P with that oracle are exactly the same. And that actually is an interest-- it's not just a curiosity, it actually has relevance to strategies for solving P versus NP. Hopefully I'll be able to have time to get to. Can we think of an oracle like a hash table? I think hashing is somehow different in spirit. I understand there's some similarity there, but I don't see the-- hashing is a way of finding sort of a short name for objects, which has a variety of different purposes why you might want to do that. So I don't really think it's the same. Let's see, an oracle question, OK, let's see. How do we use SAT oracle to solve whether two formulas are equivalent? OK, this is getting back to this point. How can we use a SAT oracle to solve whether two formulas are equivalent? Well, we can use a SAT oracle to solve any NP problem, because it's reducible to SAT. In other words-- P with a SAT oracle contains all of NP, so you have to make sure you understand that part. If you have the clique problem, you can reduce. If I give you a clique problem, which is an NP problem, and I want to use the oracle to test if the formula-- if the graph has a clique, I reduce that problem to a SAT problem using the Cook-Levin theorem. And knowing that a clique of a certain size is going to correspond to having a formula which is satisfiable, now I can ask the oracle. And if I can do NP problems, I can do co-NP problems, because P is a deterministic class. Even though it has an oracle, it's still deterministic. It can invert the answer. Something that non-deterministic machines cannot necessarily do. So I don't know, maybe that's-- let's move on. So there's an oracle where P to the A equals NP to the A, which kind of seems kind of amazing at some level. Because here's an oracle where the non-determinism-- if I give you that oracle, non-determinism doesn't help. And it's actually a language we've seen. It's TQBF. Why is that? Well, here's the whole proof. If I have NP with a TQBF oracle. Let's just check each of these steps. I claim I can do that with a non-deterministic polynomial space machine, which no longer has an oracle. The reason is that, if I have polynomial space, I can answer questions about TQBF without needing an oracle. I have enough space just to answer the question directly myself. And I use my non-determinism here to simulate the non-determinism of the NP machine. So every time the NP machine branches non-deterministically, so do I. Every time one of those branches asks the oracle a TQBF question, I just do my polynomial space algorithm to solve that question myself. But now NPSPACE equals PSPACE by Savitch's theorem. And because TQBF is PSPACE complete, for the very same reason that a SAT oracle allows me to do every NP problem, a TQBF problem allows me to do every PSPACE problem. And so I get NP contained within P for a TQBF oracle. And of course, you get the containment the other way immediately. So they're equal. What does that have to do with-- somebody said-- well, I'll just-- I don't want to run out of time. So I'll take any questions at the end. What does this got to do with the P versus NP problem? OK, so this is a very interesting connection. Remember, we just showed through a combination of today's lecture and yesterday's lecture, and I guess Thursday's lecture, that this problem, this equivalence problem, is not in PSPACE, and therefore it's not in P, and therefore it's intractable. That's what we just did. We showed it's complete for a class, which is provably outside of P, provably bigger than P. That's the kind of thing we would like to be able to do to separate P and NP. We would like to show that some other problem is not in P. Some other problem is intractable. Namely, SAT. If we could do SAT, then we're good. We've solved P and NP. So we already have an example of being able to do that. Could we use the same method? Which is something people did try to do many years ago, to show that SAT is not in P. So what is that method really? The guts of that method really comes from the hierarchy there. That's where you were actually proving problems that are hard. You're getting this problem with through the hierarchy construction that's provably outside of PSPACE. And outside of P. That's a diagonalization. And if you look carefully at what's going on there-- so we're going to say, no, we're not going to be able to solve SAT, show SAT's outside of P in the same way. And the reason is, suppose we could. Well the hierarchy theorems are proved by diagonalization. What I mean by that is that in the hierarchy theorem, there's a machine D, which is simulating some other machine, M. To remember what's going on there, remember that we made a machine which is going to make its language different from the language of every machine that's running with less space or with less time. That's how D was defined. It wants to make sure its language cannot be done in less space. So it makes sure that its language is different. It simulates the machines that use less space, and does something different from what they do. Well, that simulation-- if we had an oracle, if we're trying to show that if we provide both a simulator and the machine being simulated with the same oracle, the simulation still works. Every time the machine you're simulating asks a question, the simulator has the same oracle so it can also ask the same question, and can still do the simulation. So in other words, if you could prove P different from NP using basically a simulation, which is what a diagonalization is, then you would be able to prove that P is different from NP for every oracle. So if you can prove P different from NP by a diagonalization, that would also immediately prove that P is different from NP for every oracle. Because the argument is transparent to the oracle. If you just put the oracle down, everything still works. But-- here is the big but, it can't be that-- we know that P A is-- we know this is false. We just exhibit an oracle for which they're equal. It's not the case that P is different from NP for every oracle. Sometimes they're equal, for some oracles. So something that's just basically a very straightforward diagonalization, something that's at its core is a diagonalization, is not going to be enough to solve P and NP. Because otherwise it would prove that they're different for every oracle. And sometimes they're not different, for some oracles. That's an important insight for what kind of a method will not be adequate to prove P different from NP. And this comes up all the time. People who propose hypothetical solutions that they're trying to show P different from NP. One of the very first things people ask is, well, would that argument still work if you put an oracle there. Often it does, which points out there was a flaw. Anyway, last check in. So this is just a little test of your knowledge about oracles. Why don't we-- in our remaining minute here. Let's say 30 seconds. And then we'll do a wrap on this, and I'll point out which ones are right. Oh boy, we're all over the place on this one. You're liking them all. Well, I guess the ones that are false are lagging slightly. OK, let's conclude. Did I give you enough time there? Share results. So, in fact-- Yeah, so having an oracle for the complement is the same as having an oracle. So this is certainly true. NP SAT equal coNP SAT, we have no reason to believe that would be true, and we don't know it to be true. So B is not a good choice and that's the laggard here. MIN-FORMULA, well, is in PSPACE, and anything in PSPACE is reducible to TQBF, so this is certainly true. And same thing for NP with TQBF and coNP with TQBF. Once you have TQBF, you're going to get all of PSPACE. And as we pointed out, this is going to be equal as well. So why don't we end here. And I think that's my last slide. Oh no, there's my summary here. This is what we've done. And I will send you all off on your way. How does the interaction between the Turing machine and the oracle look? Yeah, I didn't define exactly how the machine interacts with an oracle. You can imagine having a separate tape where it writes the oracle question and then goes into a special query state. You can formalize it however you like. They're all going to be-- any reasonable way of formalizing it is going to come up with the same notion in the end. It does show that P with a TQBF oracle equals PSPACE. Yes, that is correct. Good point. Why do we need the oracle to be TQBF? Wouldn't SAT also work because it could solve any NP problem? So you're asking, does P with a SAT oracle equal NP with a SAT oracle? Not known. And believed not to be true, but we don't have a compelling reason for that. No one has any idea how to do that. Because, for example, we showed the complement of MIN-FORMULA is in NP with a SAT oracle. But no one knows how to do-- because there's sort of two levels of non-determinism there. There's guessing the smaller formula, and then guessing again to check the equivalence. And they really can't be combined, because one of them is sort of an exist type guessing, the other one is kind of a for all type guessing. No one knows how to do that in polynomial time with a SAT oracle. Generally believed that they're not the same. In the check-in, why was B false? B is the same question. Does NP with a SAT oracle equal coNP with a SAT oracle? I'm not saying it's false, it's just not known to be true. It doesn't follow from anything that we've shown so far. And I think that would be something that-- well, I guess it doesn't immediately imply any famous open problem. I wouldn't necessarily expect you to know that it's an unsolved problem, but it is. Could we have oracles for undecidable language? Absolutely. Would it be helpful? Well, if you're trying to solve an undecidable problem, it would be helpful. But people do study that. In fact, the original concept of oracles was presented, was derived in the computability theory. And a side note, you can talk about reducibility. No, I don't want to even go there. Too complicated. What is not known to be true? What is not known to be true is that NP with a SAT oracle equals coNP with a SAT oracle, or equals P with a SAT oracle. Nothing is known except the obvious relations among those. Those are all unknown, and just not known to be true or false. Is NP with a SAT oracle equal to NP? Probably not. NP with a SAT oracle, for one thing, contains coNP. Because it's even more powerful. We pointed out that P with a SAT oracle contains coNP. And so NP with a SAT oracle is going to be at least as good. And so it's going to contain coNP. And so, probably not going to be equal to NP unless shockingly unexpected things happen in our complexity world.","72.48069763183594","9","DPRSearchEngine","N32bnUliSzo.en-j3PyPqV-e1s_9_mp4","N32bnUliSzo.en-j3PyPqV-e1s","18.404J","22"
"197","What is the significance of a problem being classified as NP-complete?"," 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
Interactive Proofs – informal model 
Probabilistic 
polynomial time TM 
© Sesame Workshop. All rights reserved. This content 
is excluded from our Creative Commons license. For 
more information, see https://ocw.mit.edu/fairuse. 
Professor = Verifier (V) 
Unlimited 
computation 
Graduate Students = Prover (P) 
© Source unknown. All rights reserved. This content is excluded from our Creative 
Commons license. For more information, see https://ocw.mit.edu/fairuse. 
!
"" 
Professor wants to know if graphs ! and "" are isomorphic. 
- He asks his Students to figure out the answer. 
- But he doesn’t trust their answer. He must be convinced. 
If the Students claim that ! and "" are isomorphic, 
they can give the isomorphism and convince him. 
But what if they claim that ! and "" are not isomorphic? 
- The Professor randomly and secretly picks ! or "" and 
permutes it, then sends the result to the Students. 
- If Students can identify which graph the Professor picked 
reliably (repeat this 100 times), then he’s convinced. 
4 
","72.28022766113281","10","DPRSearchEngine","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25_4_pdf","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25","18.404J","25"
"198","What distinguishes a local property from a global property in the context of binary trees, and why is maintaining local properties preferable for subtree computations?","We're almost done. This will actually work. It's really quite awesome. But for it to work, we need something called subtree augmentation, which I'll talk about generally. And then, we'll apply it to size. So the idea with subtree augmentation is that each node in our binary tree can store a constant number of extra fields. Why not? And in particular, if these fields are of a particular type-- maybe I'll call them properties. I'm going to define a subtree property to be something that can be computed from the properties of the nodes' children. So I should say this is of a node. So children are node.left and node.right. You can also access constant amount of other stuff,","72.31260681152344","1","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_9_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"198","What distinguishes a local property from a global property in the context of binary trees, and why is maintaining local properties preferable for subtree computations?","If you think about it a little bit, this is exactly binary search on an array. It just happens to be on a tree instead. If you think of an array like this, what does binary search do? It first looks at the key in the middle. I'm going to draw that as the root. And then, it recurses either on the left chunk, which I will draw recursively, or on the right chunk. And so if you happen to have a perfect binary tree like this one, it is simulating exactly binary search in this array. But this we're going to be able to maintain dynamically-- not perfect any more, but close. Whereas this we could not maintain in sorted order. So this is like a generalization of binary search to work on trees instead of on arrays. And for this reason, set binary trees are called binary search trees, because they're the tree version of binary search. So there's many equivalent names. So binary search tree is another name for set binary tree. And the key thing that makes this algorithm work is the so-called binary search tree property, which is all the keys in the left subtree of a node are less than the root, or of that node, and that key is less than all the keys in the right subtree. And this is true recursively all the way down. And so that's how you prove that this algorithm is correct by this property. Why is this true? Because if we can maintain traversal order to be increasing key, then that's exactly what traversal order means. It tells you all the things in the left subtree come before the root, which come before all the things in the right subtree.","72.19326782226562","2","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_4_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"198","What distinguishes a local property from a global property in the context of binary trees, and why is maintaining local properties preferable for subtree computations?","But the point of a subtree property is it's downward looking. If I have a node here, and I want to compute some property about it-- call it, we want to store P of the node-- and suppose we already know P over here, the property computed for the left subtree or for the left node, and we already know the property for the right node, then what I'd like is for this to be computable in constant time. So I can compute P of this node given P of the left node and P of the right node. That's a subtree property. Now, in particular, size is a substrate property. Why? Because I can write this kind of recurrence, node.size equals node.left.size-- this is very tedious to write-- plus node.right.size, plus? 1, thank you. The size of the entire subtree here, called node, is the size of the left subtree plus size of the right subtree, plus 1 for that node itself. So this is an update rule. It takes constant time to evaluate. It's two editions. Sorry, my t's look kind of like plus signs. I'll make the pluses a little bigger. So we're just summing those three things. Boom, we can get node.size. So I claim that as long as my property has this feature, I can maintain it dynamically as I'm changing the tree. Now, this is a little bit of a forward reference, because we haven't said exactly how we're going to change the tree yet. But question?","71.200439453125","3","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_10_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"198","What distinguishes a local property from a global property in the context of binary trees, and why is maintaining local properties preferable for subtree computations?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","70.98408508300781","4","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"198","What distinguishes a local property from a global property in the context of binary trees, and why is maintaining local properties preferable for subtree computations?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","70.22981262207031","5","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"198","What distinguishes a local property from a global property in the context of binary trees, and why is maintaining local properties preferable for subtree computations?","namely, random accessing. And if we stored the things that we're looking for, we have unique keys, and those keys are integers. Then, if I have an item with key K, if I store it at index K in my array, then I can find it and manipulate it in constant time.","69.7299575805664","6","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_2_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"198","What distinguishes a local property from a global property in the context of binary trees, and why is maintaining local properties preferable for subtree computations?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 16: Dyn. Prog. Subproblems 
Lecture 16: Dyn. Prog. Subproblems 
Dynamic Programming Review 
• Recursion where subproblem dependencies overlap, forming DAG 
• “Recurse but re-use” (Top down: record and lookup subproblem solutions) 
• “Careful brute force” (Bottom up: do each subproblem in order) 
Dynamic Programming Steps (SRT BOT) 
1. Subproblem deﬁnition 
subproblem x 2 X 
• Describe the meaning of a subproblem in words, in terms of parameters 
• Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence 
• Often multiply possible subsets across multiple inputs 
• Often record partial state: add subproblems by incrementing some auxiliary variables 
2. Relate subproblem solutions recursively 
x(i) =  f(x(j), . . .) for one or more j < i  
• Identify a question about a subproblem solution that, if you knew the answer to, reduces 
the subproblem to smaller subproblem(s) 
• Locally brute-force all possible answers to the question 
3. Topological order to argue relation is acyclic and subproblems form a DAG 
4. Base cases 
• State solutions for all (reachable) independent subproblems where relation breaks down 
5. Original problem 
• Show how to compute solution to original problem from solutions to subproblem(s) 
• Possibly use parent pointers to recover actual solution, not just objective function 
6. Time analysis 
P 
• 
x2X work(x), or if work(x) =  O(W) for all x 2 X, then |X| · O(W) 
• work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time 
","69.26497650146484","7","DPRSearchEngine","28461a74f81101874a13d9679a40584d_MIT6_006S20_lec16_1_pdf","28461a74f81101874a13d9679a40584d_MIT6_006S20_lec16","6.006","16"
"198","What distinguishes a local property from a global property in the context of binary trees, and why is maintaining local properties preferable for subtree computations?","§ Problem is exponen<al 
§ Have we overturned the laws of the universe? 
§ Is dynamic programming a miracle? 
§ No, but computa<onal complexity can be subtle 
§ Running <me of fastMaxVal is governed by number of 
dis<nct pairs, <toConsider, avail> 
◦Number of possible values of toConsider bounded 
by len(items)
◦Possible values of avail a bit harder to characterize 
◦Bounded by number of dis<nct sums of weights 
◦Covered in more detail in assigned reading 
How Can This Be? 
6.0002 LECTURE 2 
30 
","69.2574691772461","8","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_30_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"198","What distinguishes a local property from a global property in the context of binary trees, and why is maintaining local properties preferable for subtree computations?","Header for Decision Tree Implementa#on 
6.0002 LECTURE 2 
9 
def maxVal(toConsider, avail): 
    """"""Assumes toConsider a list of items,  
               avail a weight 
       Returns a tuple of the total value of a  
           solution to 0/1 knapsack problem and  
           the items of that solution""""” 
toConsider. Those items that nodes higher up in the tree 
(corresponding to earlier calls in the recursive call stack) 
have not yet considered 
 
avail. The amount of space still available  
","69.13325500488281","9","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_9_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"198","What distinguishes a local property from a global property in the context of binary trees, and why is maintaining local properties preferable for subtree computations?"," 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Relationships among models 
Informal Defn: Two models of computation are polynomially related 
if each can simulate the other with a polynomial overhead: 
So ! "" time → !$("") time on the other model, for some '. 
All reasonable deterministic models are polynomially related. 
• 1-tape TMs 
• multi-tape TMs 
• multi-dimensional TMs 
• random access machine (RAM) 
• cellular automata 
9 
","69.109375","10","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_9_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"200","What is the difference between an interface and a data structure?","Fairly simple data structures today. This is the beginning of several data structures we'll be talking about in the next few lectures. But before we actually start with one, let me tell you/remind remind you of the difference between an interface-- which you might call an API if you're a programmer, or an ADT if you're an ancient algorithms person like me-- versus a data structure. These are useful distinctions. The idea is that an interface says what you want to do. A data structure says how you do it. So you might call this a specification. And in the context of data structures, we're trying to store some data. So the interface will specify what data you can store, whereas the data structure will give you an actual representation and tell you how to store it. This is pretty boring. Just storing data is really easy. You just throw it in a file or something. What makes it interesting is having operations on that data. In the interface, you specify what the operations do, what operations are supported, and in some sense, what they mean. And the data structure actually gives you algorithms-- this is where the algorithms come in-- for how to support those operations. All right. In this class, we're going to focus on two main interfaces and various special of them. The idea is to separate what you want to do versus how to do it. Because-- you can think of this as the problem statement. Yesterday-- or, last class, Jason talked about problems and defined what a problem was versus algorithmic solutions to the problem. And this is the analogous notion for data structures, where we want to maintain some data according to various operations. The same problem can be solved by many different data structures. And we're going to see that. And different data structures are going to have different advantages. They might support some operations faster than others. And depending on what you actually use those data structures for, you choose the right data structure. But you can maintain the same interface. We're going to think about two data structures. One is called a set and one is called a sequence. These are highly loaded terms. Set means something to a mathematician. It means something else to a Python programmer. Sequence, similarly. I guess there's not a Python sequence data type built in. The idea is, we want to store n things. The things will be fairly arbitrary. Think of them as integers or strings. And on the one hand, we care about their values. And maybe we want to maintain them in sorted order and be able to search for a given value, which we'll call a key. And on the other hand, we care about representing a particular sequence that we care about. Maybe we want to represent the numbers 5, 2, 9, 7 in that order and store that. In Python, you could store that in a list, for example. And it will keep track of that order. And this is the first item, the second item, the last item. Today, we're going to be focusing on this sequence data structure, although at the end, I'll mention the interface for sets. But we're going to be actually solving sequences today. And in the next several lectures, we'll be bouncing back and forth between these. They're closely related. Pretty abstract at the moment. On the other hand, we're going to have two main-- let's call them data structure tools or approaches. One is arrays and the other is pointers-- pointer-based or linked data structures. You may have seen these. They're used a lot in programming, of course. But we're going to see both of these today. I'll come back to this sort of highlight in a moment. Let's jump into the sequence interface, which I conveniently have part of here. There's a few different levels of sequences that we might care about. I'm going to start with the static sequence interface. This is where the number of items doesn't change, though the actual items might. Here, we have n items. I'm going to label them x 0 to x n minus 1, as in Python. So the number of items is n. And the operations I want to support are build, length, iteration, get, and set. So what do these do? Build is how you get started. To build a data structure in this interface, you call build of x. Exactly how you specify x isn't too important, but the idea is, I give you some items in some order. In Python, this would be an iterable. I'm going to want to also know its length. And I want to make a new data structure of size and a new static sequence of size n that has those items in that order. So that's how you build one of these. Because somehow, we have to specify n to this data structure, because n is not going to be allowed to change. I'm going to give you a length method. Methods are the object-oriented way of thinking of operations that your interface supports. Length will just return this fixed value n. Iter sequence. This is the sense in which we want to maintain the order. I want to be able to output x 0 through x n minus 1 in the sequence order, in that specified order that they were built in or that it was changed to. This is going to iterate through all of the items. So it's going to take at least linear time to output that. But more interesting is, we can dynamically access anywhere in the middle of the sequence. We can get the ith item, x i, given the value i, and we can change x i to a given new item. OK. So that's called get_at and set_at. Pretty straightforward. This should remind you very closely of something-- a data structure. So this is an interface. This is something I might want to solve. But what is the obvious data structure that solves this problem? Yeah? AUDIENCE: A list. ERIK DEMAINE: A list. In Python, it's called a list. I prefer to call it an array, but to each their own. We're going to use ""list.""","73.18341064453125","1","DPRSearchEngine","CHhwJjR0mZA.en-j3PyPqV-e1s_2_mp4","CHhwJjR0mZA.en-j3PyPqV-e1s","6.006","2"
"200","What is the difference between an interface and a data structure?","OK, so magically this is going to make this algorithm efficient with this very simple tweak. Let me write down the tweak more explicitly. I won't write code here. But just describe it as a data structure. So we're going to maintain our good friend, the dictionary, which is abstract data type or interface. We could use different data structures to do it. But we're going to map some problems to their solutions, at least the ones that we've solved already. And usually we can do this with just a direct access array, though you could use a hash table. Just get expected bounce. So when we write the code for our recursive function--","71.19833374023438","2","DPRSearchEngine","r4-cftqTcdI.en-j3PyPqV-e1s_6_mp4","r4-cftqTcdI.en-j3PyPqV-e1s","6.006","15"
"200","What is the difference between an interface and a data structure?","Now, this description here-- notice that I've labeled this as a set interface. This is not a set data structure. And the way to remember that is that I haven't told you how I've actually implemented this. I haven't told you that I'm going to behind the scenes have an array of information, and look inside of it, and that's how I'm going to implement find min or find max with a for loop or whatever. All I'm telling you is that a set is a thing that implements these operations. And behind the scenes, my computer does what it does. Now, it might sound abstract. But it's more or less what you guys do when you write code in Python. I think in Python what we're calling a set is maybe a dictionary. I'm a Matlab Coder. I'm sorry. I'm a numerical analysis kind of guy. But essentially, one of the beautiful things about coding in these high level programming languages is that they take care of these ugly details. And what you're left with is just the high level interfacing with this object","69.64500427246094","3","DPRSearchEngine","oS9aPzUNG-s.en-j3PyPqV-e1s_6_mp4","oS9aPzUNG-s.en-j3PyPqV-e1s","6.006","3"
"200","What is the difference between an interface and a data structure?","Incidentally, typically, I teach the intro graphics class, the geometry course. And last year, I got feedback that said I have serial killer handwriting. I'm not 100% sure what that means. But we're going to use the slides a tiny bit more than normal, just to make sure you guys can read. And when I'm writing on the board, at any point, if you can't tell what I wrote, it's definitely me and not you. So just let me know. But in any event, in 6.006, all the way back in our lecture 1-- I know that was a long time ago-- we introduced two big keywords that are closely related, but not precisely the same. Hopefully, I've gotten this right. But roughly, there's a theme here which is that there's an object called an interface, which is just a program specification. It's just telling us that there's a collection of operations that we want to implement. So for example, a set, as we're going to see today, is like a big pile of things. And behind the scenes, how I choose to implement","69.15767669677734","4","DPRSearchEngine","oS9aPzUNG-s.en-j3PyPqV-e1s_2_mp4","oS9aPzUNG-s.en-j3PyPqV-e1s","6.006","3"
"200","What is the difference between an interface and a data structure?","Notation for encodings and TMs
Notation for encoding objects into strings
- If ! is some object (e.g., polynomial, automaton, graph, etc.), 
we write 〈!〉to be an encoding of that object into a string.  
- If !$, !&, … , !( is a list of objects then we write 〈!$, !&, … , !(〉
to be an encoding of them together into a single string. 
Notation for writing Turing machines
We will use high-level English descriptions of algorithms when we describe TMs, 
knowing that we could (in principle) convert those descriptions into states, 
transition function, etc.  Our notation for writing a TM ) is
) = “On input +
[English description of the algorithm]”
Check-in 6.3
If , and - are strings, would ,- be a good choice 
for their encoding 〈,, -〉into a single string?
a)
Yes.
b)
No. 
Check-in 6.3
8
","69.07564544677734","5","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_8_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"200","What is the difference between an interface and a data structure?","I really lead kind of a weird, extremely [INAUDIBLE] group, where some of our students are essentially theory students-- touch your keyboard. I'm sorry. It was a reflex. But it was fast. All right. So we have some students whose background is in math, other ones that we're in autonomous driving industry and decided to come back and work in research. Because of that, we have this extremely broad set of research problems, everything from the sort of classic machine learning problems you might encounter in geometry world-- like if I have a self-driving car and I want to identify pedestrians and other cars on the road in an efficient and accurate fashion. By the way, part of that is machine learning and deep whatever, but there's another part, which is algorithms. Because actually, what comes into your LiDAR scanner is on the order of [INAUDIBLE] with points and some minuscule fraction of time. And time complexity of your learning algorithm actually is really critical to get it right, and something that there are a lot of open problems right now, because it's really not compatible with the hardware architecture that these cars often use. We also look at [INAUDIBLE] geometry problems, like if I give you data, can I find a geometric structure? So it's a classic example of natural language processing. When we use words like near and far, in terms of semantics and meaning, all the time. The question is, can we actually find an embedded of our word data into a geometric space to facilitate the statistical algorithms that we care about? And of course, we apply geometry to lots of practical problems, everything from meshing and scientific computing, which I think is sort of a classic one-- in fact, I think we're the first group that sort of enumerated all of the cool things that may happen to decahedral meshes, which is this bottom figure here. I should show this to people. There's some fun things to look at there. To other practical problems, like taking-- Erik took a zebra and folded it. We can take a zebra and move its texture onto a cat or a pig-- or, actually, off the side of the screen. But if we don't move the paper, [INAUDIBLE] for the 3D scan of what it might [INAUDIBLE]. In any event, in my five minutes remaining here, I thought I would dig into a little bit of detail of two-- or maybe one application, depending on when Jason and Erik get bored. And essentially, my message for you guys is, of course, [INAUDIBLE]. I'm not really a central CS theory group member here at MIT. But unfortunately for you guys, 6.006 is unavoidable. Even if you want to go into deep learning, statistics, whatever-- data science-- you're going to encounter the material that you've seen in this course. And in fact, it's really the bread and butter of just about everything everybody does here in this Data Center. So then, I'll give you two quick examples, one of which","68.70514678955078","6","DPRSearchEngine","4nXw-f6NJ9s.en-j3PyPqV-e1s_9_mp4","4nXw-f6NJ9s.en-j3PyPqV-e1s","6.006","21"
"200","What is the difference between an interface and a data structure?","3 
Lecture 1: Introduction 
Model of Computation 
• Speciﬁcation for what operations on the machine can be performed in O(1) time 
• Model in this class is called the Word-RAM 
• Machine word: block of w bits (w is word size of a w-bit Word-RAM) 
• Memory: Addressable sequence of machine words 
• Processor supports many constant time operations on a O(1) number of words (integers): 
– integer arithmetic: (+, -, *, //, %) 
– logical operators: (&&, ||, !, ==, <, >, <=, =>) 
– (bitwise arithmetic: (&, |, <<, >>, ...)) 
– Given word a, can read word at address a, write word to address a 
• Memory address must be able to access every place in memory 
– Requirement: w ≥ # bits to represent largest memory address, i.e., log2 n 
– 32-bit words → max ∼ 4 GB memory, 64-bit words → max ∼ 16 exabytes of memory 
• Python is a more complicated model of computation, implemented on a Word-RAM 
Data Structure 
• A data structure is a way to store non-constant data, that supports a set of operations 
• A collection of operations is called an interface 
– Sequence: Extrinsic order to items (ﬁrst, last, nth) 
– Set: Intrinsic order to items (queries based on item keys) 
• Data structures may implement the same interface with different performance 
• Example: Static Array - ﬁxed width slots, ﬁxed length, static sequence interface 
– StaticArray(n): allocate static array of size n initialized to 0 in Θ(n) time 
– StaticArray.get at(i): return word stored at array index i in Θ(1) time 
– StaticArray.set at(i, x): write word x to array index i in Θ(1) time 
• Stored word can hold the address of a larger object 
• Like Python tuple plus set at(i, x), Python list is a dynamic array (see L02) 
","68.68656921386719","7","DPRSearchEngine","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_3_pdf","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1","6.006","1"
"200","What is the difference between an interface and a data structure?","You've taken, probably-- you've probably seen linked lists before at some point. But the main new part here is, we're going to actually analyze them and see how efficiently they implement all of these operations we might care about. First, review. What is a linked list? We store our items in a bunch of nodes. Each node has an item in it and a next field. So you can think of these as class objects with two class variables, the item and the next pointer. And we assemble those into this kind of structure where we store-- in the item fields, we're going to store the actual values that we want to represent in our sequence, x 0 through x n minus 1, in order. And then we're going to use the next pointers to link these all together in that order. So the next pointers are what actually give us the order. And in addition, we're going to keep track of what's called the head of the list. The data structure is going to be represented by a head. If you wanted to, you could also store length. This could be the data structure itself. And it's pointing to all of these types of data structures. Notice, we've just seen an array-based data structure, which is just a static array, and we've seen a pointer-based data structure. And we're relying on the fact that pointers can be stored in a single word, which means we can de-reference them-- we can see what's on the other side of the pointer-- in constant time in our word RAM model. In reality, each of these nodes is stored somewhere in the array of the computer. So maybe each one is two words long, so maybe one node is-- the first node is here. Maybe the second node is here. The third node is here. They're in some arbitrary order. We're using this fact, that we can allocate an array of size n in linear time-- in this case, we're going to have arrays of size 2. We can just say, oh, please give me a new array of size 2. And that will make us one of these nodes. And then we're storing pointers. Pointers are just indices into the giant memory array. They're just, what is the address of this little array? If you've ever wondered how pointers are implemented, they're just numbers that say where, in memory, is this thing over here? And in memory, they're in arbitrary order. This is really nice because it's easy to manipulate the order of a linked list without actually physically moving nodes around, whereas arrays are problematic. Maybe it's worth mentioning. Let's start analyzing things. So we care about these dynamic sequence operations. And we could try to apply it to the static array data structure, or we could try to implement these operations in a static array. It's possible, just not going to be very good. And we can try to implement it with linked lists. And it's also not going to be that great.","68.5716552734375","8","DPRSearchEngine","CHhwJjR0mZA.en-j3PyPqV-e1s_5_mp4","CHhwJjR0mZA.en-j3PyPqV-e1s","6.006","2"
"200","What is the difference between an interface and a data structure?","Actually, what a modern computer is addressed in is bytes, collections of 8 bits. So there's an address I have for every 8 bits in memory-- consecutive 8 bits in memory. And so if I want to pull something in into the CPU, I give it an address. It'll take some chunk, and bring it into the CPU, operate on it, and spit it back. How big is that chunk? This goes to the answer that you were asking, which-- or saying, which is it's some sequence of some fixed number of bits, which we call a word. A word is how big of a chunk that the CPU can take in from memory at a time and operate on. In your computers, how big is that word size? 64 bits-- that's how much I can operate on at a time. When I was growing up, when I was your age, my word size was 32 bits. And that actually was a problem for my computer, because in order for me to be able to read to address in memory, I need to be able to store that address in my CPU, in a word. But if I have 32 bits, how many different addresses can I address? I have a limitation on the memory addresses I can address, right? So how many different memory addresses can I address with 32 bits? 2 to the 32, right? That makes sense. Well, if you do that calculation out, how big of a hard disk can I have to access? It's about 4 gigabytes. So in my day, all the hard drives were limited to being partitioned-- even if you had a bigger than 4 gigabyte hard drive, I had to partition it into these 4 gigabyte chunks, which","68.47616577148438","9","DPRSearchEngine","ZA-tUyM_y7s.en-j3PyPqV-e1s_8_mp4","ZA-tUyM_y7s.en-j3PyPqV-e1s","6.006","1"
"200","What is the difference between an interface and a data structure?","data, and I just said whether we're going to print something. You'll notice from this slide I've elighted the printed stuff. We'll come back in a later slide and look at what's in there. But for now I want to focus on actually building the model. I need to create two vectors, two lists in this case, the feature vectors and the labels. For e in examples, featurevectors.a ppend(e.getfeatures e.getfeatures e.getlabel. Couldn't be much simpler than that. Then, just because it wouldn't fit on a line on my slide, I've created this identifier called logistic regression, which is sklearn.linearmo del.logisticregression. So this is the thing I imported, and this is a class, and now I'll get a model by first creating an instance of the class, logistic regression. Here I'm getting an instance, and then I'll call dot fit with that instance, passing it feature vecs and labels. I now have built a logistic regression model, which is simply a set of weights for each of the variables. This makes sense? Now we're going to apply the model, and I think this is the last piece of Python I'm going to introduce this semester, in case you're tired of learning about Python. And this is at least list comprehension. This is how I'm going to build my set of test feature vectors.","68.45916748046875","10","DPRSearchEngine","eg8DJYwdMyg.en-qlPKC2UN_YU_7_mp4","eg8DJYwdMyg.en-qlPKC2UN_YU","6.0002","13"
"201","Why are subsequences not preferred for dynamic programming problems when finding subproblems?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 16: Dyn. Prog. Subproblems 
Lecture 16: Dyn. Prog. Subproblems 
Dynamic Programming Review 
• Recursion where subproblem dependencies overlap, forming DAG 
• “Recurse but re-use” (Top down: record and lookup subproblem solutions) 
• “Careful brute force” (Bottom up: do each subproblem in order) 
Dynamic Programming Steps (SRT BOT) 
1. Subproblem deﬁnition 
subproblem x 2 X 
• Describe the meaning of a subproblem in words, in terms of parameters 
• Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence 
• Often multiply possible subsets across multiple inputs 
• Often record partial state: add subproblems by incrementing some auxiliary variables 
2. Relate subproblem solutions recursively 
x(i) =  f(x(j), . . .) for one or more j < i  
• Identify a question about a subproblem solution that, if you knew the answer to, reduces 
the subproblem to smaller subproblem(s) 
• Locally brute-force all possible answers to the question 
3. Topological order to argue relation is acyclic and subproblems form a DAG 
4. Base cases 
• State solutions for all (reachable) independent subproblems where relation breaks down 
5. Original problem 
• Show how to compute solution to original problem from solutions to subproblem(s) 
• Possibly use parent pointers to recover actual solution, not just objective function 
6. Time analysis 
P 
• 
x2X work(x), or if work(x) =  O(W) for all x 2 X, then |X| · O(W) 
• work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time 
","75.93876647949219","1","DPRSearchEngine","28461a74f81101874a13d9679a40584d_MIT6_006S20_lec16_1_pdf","28461a74f81101874a13d9679a40584d_MIT6_006S20_lec16","6.006","16"
"201","Why are subsequences not preferred for dynamic programming problems when finding subproblems?"," 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 18: Pseudopolynomial 
Lecture 18: Pseudopolynomial 
Dynamic Programming Steps (SRT BOT) 
1. Subproblem deﬁnition 
subproblem x ∈ X 
• Describe the meaning of a subproblem in words, in terms of parameters 
• Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence 
• Often multiply possible subsets across multiple inputs 
• Often record partial state: add subproblems by incrementing some auxiliary variables 
• Often smaller integers than a given integer (today’s focus) 
2. Relate subproblem solutions recursively 
x(i) = f(x(j), . . .) for one or more j < i 
• Identify a question about a subproblem solution that, if you knew the answer to, reduces 
the subproblem to smaller subproblem(s) 
• Locally brute-force all possible answers to the question 
3. Topological order to argue relation is acyclic and subproblems form a DAG 
4. Base cases 
• State solutions for all (reachable) independent subproblems where relation breaks down 
5. Original problem 
• Show how to compute solution to original problem from solutions to subproblem(s) 
• Possibly use parent pointers to recover actual solution, not just objective function 
6. Time analysis 
P 
• 
work(x), or if work(x) = O(W ) for all x ∈ X, then |X| · O(W )
x∈X 
• work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time 
","75.90319061279297","2","DPRSearchEngine","mit6_006s20_lec18_1_pdf","mit6_006s20_lec18","6.006","18"
"201","Why are subsequences not preferred for dynamic programming problems when finding subproblems?"," 
  
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
New in  Code  
§numpy.std is function in the numpy module that
returns the standard deviation
§random.sample(population, sampleSize) returns a list
containing sampleSize randomly chosen distinct
elements of population
◦Sampling without replacement
6.0002  LECTURE 8 
 
8
","74.57000732421875","3","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_8_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"201","Why are subsequences not preferred for dynamic programming problems when finding subproblems?"," 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
  
  
 
 
 
 
 
  
  
 
 
  
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
A “Natural” Intractable Problem 
Defn: !""REX = '(, '* '( and '* are equivalent regular expressions} 
Theorem:  !""REX ∈ PSPACE 
Proof: Later (if time) or exercise (uses Savitch’s theorem). 
-
Notation: If ' is a regular expression write '- to mean '' ⋯' (exponent is written in binary). 
Defn: !""/01↑ = '(, '* '( and '* are equivalent regular expressions with exponentiation} 
Theorem:  !""/01↑ is EXPSPACE-complete 
Proof: 1) !""/01↑ ∈ EXPSPACE 
2)  If 3 ∈ EXPSPACE then 3 ≤5 !""/01↑ 
1) Given regular expressions with exponentiation '( and '*, 
expand the exponentiation by using repeated concatenation and then use !""REX ∈ PSPACE. 
The expansion is exponentially larger, so gives an EXPSPACE algorithm for !""/01↑. 
2)  Let 3 ∈ EXPSPACE be decided by TM 6 in space 2 89 . 
Give a polynomial-time reduction : mapping 3 to !""/01↑. 
4 
","74.49188232421875","4","DPRSearchEngine","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_4_pdf","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22","18.404J","22"
"201","Why are subsequences not preferred for dynamic programming problems when finding subproblems?","§ Time based on number of nodes generated 
§ Number of levels is number of items to choose from 
§ Number of nodes at level i is 2i 
§ So, if there are n items the number of nodes is 
◦ ∑𝑖=0↑𝑖=𝑛▒​2↑𝑖   
◦ I.e., O(​2↑𝑛+1 ) 
§ An obvious op<miza<on: don’t explore parts of tree 
that violate constraint (e.g., too many calories) 
◦ Doesn’t change complexity 
§ Does this mean that brute force is never useful? 
◦ Let’s give it a try 
Computa#onal Complexity 
6.0002 LECTURE 2 
8 
","74.19834899902344","5","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_8_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"201","Why are subsequences not preferred for dynamic programming problems when finding subproblems?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","73.62311553955078","6","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"201","Why are subsequences not preferred for dynamic programming problems when finding subproblems?"," 
 
 
 
 
 
Class Field, continued  
def moveDrunk(self, drunk):  
if drunk not in self.drunks:  
raise ValueError('Drunk not in field')  
xDist, yDist = drunk.takeStep()  
#use move method of Location to get new location  
self.drunks[drunk] =\\  
self.drunks[drunk].move(xDist, yDist)  
Immutable or not? 
6.0002  LECTURE 5 
19 
","73.46253967285156","7","DPRSearchEngine","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_19_pdf","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5","6.0002","5"
"201","Why are subsequences not preferred for dynamic programming problems when finding subproblems?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 17: Dyn. Prog. III 
Lecture 17: Dyn. Prog. III 
Dynamic Programming Steps (SRT BOT) 
1. Subproblem deﬁnition 
subproblem x ∈ X 
• Describe the meaning of a subproblem in words, in terms of parameters 
• Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence 
• Often multiply possible subsets across multiple inputs 
• Often record partial state: add subproblems by incrementing some auxiliary variables 
2. Relate subproblem solutions recursively 
x(i) = f(x(j), . . .) for one or more j < i 
• Identify a question about a subproblem solution that, if you knew the answer to, reduces 
the subproblem to smaller subproblem(s) 
• Locally brute-force all possible answers to the question 
3. Topological order to argue relation is acyclic and subproblems form a DAG 
4. Base cases 
• State solutions for all (reachable) independent subproblems where relation breaks down 
5. Original problem 
• Show how to compute solution to original problem from solutions to subproblem(s) 
• Possibly use parent pointers to recover actual solution, not just objective function 
6. Time analysis 
P 
• 
work(x), or if work(x) = O(W ) for all x ∈ X, then |X| · O(W )
x∈X 
• work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time 
Recall: DAG Shortest Paths [L15] 
• Subproblems: δ(s, v) for all v ∈ V 
• Relation: 
δ(s, v) = min{δ(s, u) + w(u, v) | u ∈ Adj−(v)} ∪ {∞} 
• Topo. order: 
Topological order of G 
","73.44245147705078","8","DPRSearchEngine","665523227a175e9e9ce26ea8d3e5b51c_MIT6_006S20_lec17_1_pdf","665523227a175e9e9ce26ea8d3e5b51c_MIT6_006S20_lec17","6.006","17"
"201","Why are subsequences not preferred for dynamic programming problems when finding subproblems?","4 
Lecture 1: Introduction 
1 
def birthday_match(students): 
2 
’’’ 
3 
Find a pair of students with the same birthday 
4 
Input: 
tuple of student (name, bday) tuples 
5 
Output: tuple of student names or None 
6 
’’’ 
7 
n = len(students) 
# O(1) 
8 
record = StaticArray(n) 
# O(n) 
9 
for k in range(n): 
# n 
10 
(name1, bday1) = students[k] 
# O(1) 
11 
# Return pair if bday1 in record 
12 
for i in range(k): 
# k 
13 
(name2, bday2) = record.get_at(i) 
# O(1) 
14 
if bday1 == bday2: 
# O(1) 
15 
return (name1, name2) 
# O(1) 
16 
record.set_at(k, (name1, bday1)) 
# O(1) 
17 
return None 
# O(1) 
Example: Running Time Analysis 
• Two loops: outer k ∈{0, . . . , n − 1}, inner is i ∈{0, . . . , k}
P n−1
• Running time is O(n) + 
k=0 (O(1) + k · O(1)) = O(n2) 
• Quadratic in n is polynomial. Efﬁcient? Use different data structure for record! 
How to Solve an Algorithms Problem 
1. Reduce to a problem you already know (use data structure or algorithm) 
Search Problem (Data Structures) 
Sort Algorithms 
Static Array (L01) 
Insertion Sort (L03) 
Linked List (L02) 
Selection Sort (L03) 
Dynamic Array (L02) 
Merge Sort (L03) 
Sorted Array (L03) 
Counting Sort (L05) 
Direct-Access Array (L04) 
Radix Sort (L05) 
Hash Table (L04) 
AVL Sort (L07) 
Balanced Binary Tree (L06-L07) 
Heap Sort (L08) 
Binary Heap (L08) 
2. Design your own (recursive) algorithm 
• Brute Force 
• Decrease and Conquer 
• Divide and Conquer 
• Dynamic Programming (L15-L19) 
• Greedy / Incremental 
Shortest Path Algorithms 
Breadth First Search (L09) 
DAG Relaxation (L11) 
Depth First Search (L10) 
Topological Sort (L10) 
Bellman-Ford (L12) 
Dijkstra (L13) 
Johnson (L14) 
Floyd-Warshall (L18) 
","73.36431884765625","9","DPRSearchEngine","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_4_pdf","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1","6.006","1"
"201","Why are subsequences not preferred for dynamic programming problems when finding subproblems?","4 
Lecture 15: Recursive Algorithms 
Dynamic Programming 
• Weird name coined by Richard Bellman 
– Wanted government funding, needed cool name to disguise doing mathematics! 
– Updating (dynamic) a plan or schedule (program) 
• Existence of recursive solution implies decomposable subproblems1 
• Recursive algorithm implies a graph of computation 
• Dynamic programming if subproblem dependencies overlap (DAG, in-degree > 1) 
• “Recurse but re-use” (Top down: record and lookup subproblem solutions) 
• “Careful brute force” (Bottom up: do each subproblem in order) 
• Often useful for counting/optimization problems: almost trivially correct recurrences 
How to Solve a Problem Recursively (SRT BOT) 
1. Subproblem deﬁnition 
subproblem x ∈ X 
• Describe the meaning of a subproblem in words, in terms of parameters 
• Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence 
• Often record partial state: add subproblems by incrementing some auxiliary variables 
2. Relate subproblem solutions recursively 
x(i) = f(x(j), . . .) for one or more j < i 
3. Topological order to argue relation is acyclic and subproblems form a DAG 
4. Base cases 
• State solutions for all (reachable) independent subproblems where relation breaks down 
5. Original problem 
• Show how to compute solution to original problem from solutions to subproblem(s) 
• Possibly use parent pointers to recover actual solution, not just objective function 
6. Time analysis 
P 
• 
work(x), or if work(x) = O(W ) for all x ∈ X, then |X| · O(W )
x∈X 
• work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time 
1This property often called optimal substructure. It is a property of recursion, not just dynamic programming 
","73.35870361328125","10","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_4_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"202","What is a trade-off that must be considered when using subproblem constraint/expansion in dynamic programming?","&

	
	
	/
def greedy(items, maxCost, keyFunction):
itemsCopy = sorted(items, key = keyFunction,
reverse = True)
result = []
totalValue, totalCost = 0.0, 0.0
for i in range(len(itemsCopy)):
if (totalCost+itemsCopy[i].getCost()) <= maxCost:
result.append(itemsCopy[i])
totalCost += itemsCopy[i].getCost()
totalValue += itemsCopy[i].getValue()
return (result, totalValue) 
	

2
	

","74.2711181640625","1","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_24_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"202","What is a trade-off that must be considered when using subproblem constraint/expansion in dynamic programming?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 16: Dyn. Prog. Subproblems 
Lecture 16: Dyn. Prog. Subproblems 
Dynamic Programming Review 
• Recursion where subproblem dependencies overlap, forming DAG 
• “Recurse but re-use” (Top down: record and lookup subproblem solutions) 
• “Careful brute force” (Bottom up: do each subproblem in order) 
Dynamic Programming Steps (SRT BOT) 
1. Subproblem deﬁnition 
subproblem x 2 X 
• Describe the meaning of a subproblem in words, in terms of parameters 
• Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence 
• Often multiply possible subsets across multiple inputs 
• Often record partial state: add subproblems by incrementing some auxiliary variables 
2. Relate subproblem solutions recursively 
x(i) =  f(x(j), . . .) for one or more j < i  
• Identify a question about a subproblem solution that, if you knew the answer to, reduces 
the subproblem to smaller subproblem(s) 
• Locally brute-force all possible answers to the question 
3. Topological order to argue relation is acyclic and subproblems form a DAG 
4. Base cases 
• State solutions for all (reachable) independent subproblems where relation breaks down 
5. Original problem 
• Show how to compute solution to original problem from solutions to subproblem(s) 
• Possibly use parent pointers to recover actual solution, not just objective function 
6. Time analysis 
P 
• 
x2X work(x), or if work(x) =  O(W) for all x 2 X, then |X| · O(W) 
• work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time 
","73.30351257324219","2","DPRSearchEngine","28461a74f81101874a13d9679a40584d_MIT6_006S20_lec16_1_pdf","28461a74f81101874a13d9679a40584d_MIT6_006S20_lec16","6.006","16"
"202","What is a trade-off that must be considered when using subproblem constraint/expansion in dynamic programming?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","73.2359619140625","3","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"202","What is a trade-off that must be considered when using subproblem constraint/expansion in dynamic programming?"," 
 
 
 
  
 
 
  
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Intro to Complexity Theory 
Computability theory (1930s - 1950s): 
Is A decidable? 
Complexity theory (1960s - present): 
Is A decidable with restricted resources? 
(time/memory/…) 
Example: Let ! = a#b# $ ≥0 . 
Q: How many steps are needed to decide !? 
Depends on the input. 
We give an upper bound for all inputs of length '. 
Called “worst-case complexity”. 
2 
","73.16775512695312","4","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_2_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"202","What is a trade-off that must be considered when using subproblem constraint/expansion in dynamic programming?","We're almost done. This will actually work. It's really quite awesome. But for it to work, we need something called subtree augmentation, which I'll talk about generally. And then, we'll apply it to size. So the idea with subtree augmentation is that each node in our binary tree can store a constant number of extra fields. Why not? And in particular, if these fields are of a particular type-- maybe I'll call them properties. I'm going to define a subtree property to be something that can be computed from the properties of the nodes' children. So I should say this is of a node. So children are node.left and node.right. You can also access constant amount of other stuff,","72.53741455078125","5","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_9_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"202","What is a trade-off that must be considered when using subproblem constraint/expansion in dynamic programming?"," 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
   
 
    
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
Linearly Bounded Automata 
Defn: A linearly bounded automaton (LBA) is a 1-tape TM 
that cannot move its head off the input portion of the tape. 
LBA 
a a b a a b a 
Tape size adjusts to length of input. 
Let !LBA = &, ( LBA & accepts ( } 
Theorem:  !LBA is decidable 
Proof: (idea) If & on ( runs for long, it must be cycling. 
Decider for !LBA: 
Claim: For inputs of length ), an LBA can have 
.A−LBA = “On input &, ( 
only * ×)× Γ - different configurations. 
1.  Let ) = |(|. 
Therefore, if an LBA runs for longer, it must repeat some 
2. Run & on ( for * ×)× Γ - steps. 
configuration and thus will never halt. 
3. If has accepted, accept. 
4. If it has rejected or is still running, reject.” 
must be looping 
7 
","72.4442138671875","6","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_7_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"202","What is a trade-off that must be considered when using subproblem constraint/expansion in dynamic programming?","§ Time based on number of nodes generated 
§ Number of levels is number of items to choose from 
§ Number of nodes at level i is 2i 
§ So, if there are n items the number of nodes is 
◦ ∑𝑖=0↑𝑖=𝑛▒​2↑𝑖   
◦ I.e., O(​2↑𝑛+1 ) 
§ An obvious op<miza<on: don’t explore parts of tree 
that violate constraint (e.g., too many calories) 
◦ Doesn’t change complexity 
§ Does this mean that brute force is never useful? 
◦ Let’s give it a try 
Computa#onal Complexity 
6.0002 LECTURE 2 
8 
","72.3208999633789","7","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_8_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"202","What is a trade-off that must be considered when using subproblem constraint/expansion in dynamic programming?"," 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
              
 
 
 
 
 
 
 
 
 
 
 
Pushdown Automata (PDA) 
“head” 
a
b
a
b
a 
… 
a
Finite 
input appears on a “tape” 
control 
c 
Schematic diagram for DFA or NFA
(pushdown) 
d 
stack 
Schematic diagram for PDA 
d 
Operates like an NFA except can write-add or read-remove symbols 
from the top of stack. 
push 
pop 
Example: PDA for ! = 0$1$ & ≥0 
1) Read 0s from input, push onto stack until read 1. 
2) Read 1s from input, while popping 0s from stack. 
3) Enter accept state if stack is empty. (note: acceptance only at end of input) 
6 
","72.2933349609375","8","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_6_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"202","What is a trade-off that must be considered when using subproblem constraint/expansion in dynamic programming?","As we see in this tree, for the example we just saw, the box is around a place where we're actually solving the same problem, even though we've made different decisions about what to take, A versus B. And in fact, we have different amounts of value in the knapsack-- 6 versus 7. What matters is we still have C and D to consider and we have two units left. It's a small and easy step. I'm not going to walk you through the code because it's kind of boring to do so. How do you modify the maxVal we looked at before to use a memo? First, you have to add the third argument, which is initially going to be set to the empty dictionary. The key of the memo will be a tuple-- the items left to be considered and the available weight. Because the items left to be considered are in a list, we can represent the items left to be considered by how long the list is. Because we'll start at the front item and just work our way to the end. And then the function works, essentially, exactly the same way fastFib worked. I'm not going to run it for you because we're running out of time. You might want to run it yourself because it is kind of fun to see how really fast it is.","72.25091552734375","9","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_13_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"202","What is a trade-off that must be considered when using subproblem constraint/expansion in dynamic programming?","
7:
/
def greedy(items, maxCost, keyFunction):
""""""Assumes items a list, maxCost >= 0,
keyFunction maps elements of items to numbers""""""
itemsCopy = sorted(items, key = keyFunction,
reverse = True)
result = []
totalValue, totalCost = 0.0, 0.0
for i in range(len(itemsCopy)):
if (totalCost+itemsCopy[i].getCost()) <= maxCost:
result.append(itemsCopy[i])
totalCost += itemsCopy[i].getCost()
totalValue += itemsCopy[i].getValue()
return (result, totalValue) 
	

&
","72.24274444580078","10","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_23_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"203","How can the single-source shortest path be calculated in a graph with cycles and negative weights?","single source shortest paths in linear time. Last time we discussed another linear time algorithm, DAG relaxation. And today we're going to be talking about Bellman-Ford, which isn't limited to asymptotic graphs. In particular, there could be negative weight cycles in our graph. If it has cycles, if it has negative weights, the worry is that we could have negative weight cycles, in which case there-- if a negative weight cycle is reachable from our source, then the vertices in that cycle and anything reachable from that cycle will potentially","78.98393249511719","1","DPRSearchEngine","f9cVS_URPc0.en-j3PyPqV-e1s_2_mp4","f9cVS_URPc0.en-j3PyPqV-e1s","6.006","12"
"203","How can the single-source shortest path be calculated in a graph with cycles and negative weights?","Longest path is maybe a problem we've talked about in problem session, because it's a DAG-- well, longest path is the same thing as shortest path, if you just negate all the weights. There are no weights in this picture, so if you just put negative 1 on all these edges and ask for the shortest path from the base to anywhere-- so single source shortest paths from this base-- then we would end up getting this path, which, if you look at it, is E-M-P-T-Y, empty. And so that shortest path is indeed the right answer. What I've drawn here is the shortest path tree. So also, if you wanted the longest increasing subsequence starting at A, then it is A-T-Y, just by following the red arrows here. And how do you get that? You just draw the parent pointers, just like we did before.","73.92390441894531","2","DPRSearchEngine","KLBCUx1is2c.en-j3PyPqV-e1s_8_mp4","KLBCUx1is2c.en-j3PyPqV-e1s","6.006","16"
"203","How can the single-source shortest path be calculated in a graph with cycles and negative weights?","It's not really complicated. Instead of having a single source, we are essentially wanting to, given an input-- this is our weighted graph, where we've got a graph V, E, and we've got a weight function from the edges to the integers. This is our general weighted graph. We want our output to be something like, the shortest path distance from u to v for every u and v in our vortex set. That's what we want to return. Now, there's one caveat here that, if there's a negative weight cycle in our graph-- in other words, if any of these delta u, v's is minus infinity,","73.59345245361328","3","DPRSearchEngine","EmSmaW-ud6A.en-j3PyPqV-e1s_2_mp4","EmSmaW-ud6A.en-j3PyPqV-e1s","6.006","14"
"203","How can the single-source shortest path be calculated in a graph with cycles and negative weights?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 11: Weighted Shortest Paths 
Lecture 11: Weighted Shortest Paths 
Review 
• Single-Source Shortest Paths with BFS in O(|V | + |E|) time (return distance per vertex) 
• Single-Source Reachability with BFS or DFS in O(|E|) time (return only reachable vertices) 
• Connected components with Full-BFS or Full-DFS in O(|V | + |E|) time 
• Topological Sort of a DAG with Full-DFS in O(|V | + |E|) time 
• Previously: distance = number of edges in path Today: generalize meaning of distance 
Weighted Graphs 
• A weighted graph is a graph G = (V, E) together with a weight function w : E → Z 
• i.e., assigns each edge e = (u, v) ∈ E an integer weight: w(e) = w(u, v) 
• Many applications for edge weights in a graph: 
– distances in road network 
– latency in network connections 
– strength of a relationship in a social network 
• Two common ways to represent weights computationally: 
– Inside graph representation: store edge weight with each vertex in adjacency lists 
– Store separate Set data structure mapping each edge to its weight 
• We assume a representation that allows querying the weight of an edge in O(1) time 
Examples 
G1 
G2 
a 
e 
b 
f 
c 
g 
d 
h 
6 
8 
−2 
5 
9 
−5 
7 
3 
2 
−1 
−4 
1 
4 
a 
e 
b 
f 
c 
g 
d 
h 
6 
8 
−2 
5 
9 
−5 
7 
3 
2 
−1 
−4 
1 
4 
","71.47132110595703","4","DPRSearchEngine","aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11_1_pdf","aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11","6.006","11"
"203","How can the single-source shortest path be calculated in a graph with cycles and negative weights?"," 
 
 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) 
General Unweighted 
BFS 
|V | + |E|
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Non-negative Dijkstra 
Bellman-Ford 
|V | log |V | + |E|
General Any 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 14: Johnson’s Algorithm 
Lecture 14: Johnson’s Algorithm 
Previously 
|V | · |E| 
All-Pairs Shortest Paths (APSP) 
• Input: directed graph G = (V, E) with weights w : E → Z 
• Output: δ(u, v) for all u, v ∈ V , or abort if G contains negative-weight cycle 
• Useful when understanding whole network, e.g., transportation, circuit layout, supply chains... 
• Just doing a SSSP algorithm |V | times is actually pretty good, since output has size O(|V |2) 
– |V | · O(|V | + |E|) with BFS if weights positive and bounded by O(|V | + |E|) 
– |V | · O(|V | + |E|) with DAG Relaxation if acyclic 
– |V | · O(|V | log |V | + |E|) with Dijkstra if weights non-negative or graph undirected 
– |V | · O(|V | · |E|) with Bellman-Ford (general) 
• Today: Solve APSP in any weighted graph in |V | · O(|V | log |V | + |E|) time 
","71.25772094726562","5","DPRSearchEngine","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14_1_pdf","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14","6.006","14"
"203","How can the single-source shortest path be calculated in a graph with cycles and negative weights?","There's not a bound on the number of edges for a shortest path, because I could just keep going around that cycle as many times as I want and get a shorter path. And so we assign those distances to be minus infinity. So that's what we're going to do today in Bellman-Ford. In particular, what we're going to do is compute our shortest path distances, the shortest path waits for every vertex in our graph, setting the ones that are not reachable to infinity, and the ones that are reachable through a negative weight cycle to minus infinity, and all other ones we're going to set to a finite weight. And another thing that we might want is if there's a negative weight cycle in the graph, let's return one. So those are the two kinds of things that we're trying to solve in today's lecture. But before we do that, let's warm up with two short exercises. The first one, exercise 1, given an undirected graph, given undirected graph G, return whether G contains a negative weight cycle. Anyone have an idea of how we can solve this in linear time, actually? In fact, we can do it in order E. No-- yes, yes. Reachable from S. I guess-- let's just say a negative weight cycle at all. Not in the context of single-source shortest paths.","70.95429229736328","6","DPRSearchEngine","f9cVS_URPc0.en-j3PyPqV-e1s_3_mp4","f9cVS_URPc0.en-j3PyPqV-e1s","6.006","12"
"203","How can the single-source shortest path be calculated in a graph with cycles and negative weights?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 10: Depth-First Search 
Lecture 10: Depth-First Search 
Previously 
• Graph deﬁnitions (directed/undirected, simple, neighbors, degree) 
• Graph representations (Set mapping vertices to adjacency lists) 
• Paths and simple paths, path length, distance, shortest path 
• Graph Path Problems 
– Single Pair Reachability(G,s,t) 
– Single Source Reachability(G,s) 
– Single Pair Shortest Path(G,s,t) 
– Single Source Shortest Paths(G,s) (SSSP) 
• Breadth-First Search (BFS) 
– algorithm that solves Single Source Shortest Paths 
– with appropriate data structures, runs in O(|V | + |E|) time (linear in input size) 
Examples 
G1 
a 
d 
b 
e 
c 
f 
G2 
a 
d 
b 
e 
c 
f 
","70.92823791503906","7","DPRSearchEngine","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10_1_pdf","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10","6.006","10"
"203","How can the single-source shortest path be calculated in a graph with cycles and negative weights?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","70.88374328613281","8","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"203","How can the single-source shortest path be calculated in a graph with cycles and negative weights?","So unless, I guess-- or abort if G contains a negative weight cycle. So we're not actually going to worry about negative weight cycles in today's class. If we have a graph, it could have negative weights. These are any integers. It could include negative weight edges. But as long as all of our path distances are bounded from below, none of them are negative infinity, we don't have any negative weight cycles, then I want you to output all of these shortest path distances. Now, in particular, this output could-- any of these outputs needs to have size theta of V squared. Because for every pair of vertices, I need to return to you a number, or infinity, or minus infinity or something like that. But we are not dealing with a case with minus infinity. The output could have size-- this is a theta here. It does have size V squared. But in particular, it's at least V squared because I need to give a number for each pair of vertices. And so we couldn't hope for linear time in the size of this graph for this problem, right? Single source shortest paths, for certain versions of the problem, we need to read the graph. And so we need to use linear time. But in this problem, our output has quadratic size in the number of vertices. So in a sense, we can't do better than this. We can't do better than quadratic. And actually, what's one way we could solve all-pairs shortest paths by using stuff we've already done in this class? That's why I put this slide up here. Yeah, we could just solve a single source shortest paths algorithm from every vertex in my graph. That seems like a stupid thing to do. It's almost brute force on the vertices. But it's certainly a way we could solve this problem, in polynomial time. And we could definitely solve it in order V squared E time, using Bellman-Ford. We just take V steps of Bellman-Ford and deal with a graph on any set of vertices. We can do better than this. We can do better than this for graphs that are special in some way. We can do V times V plus E, V times linear. If our weights are positive and bounded, we can use BFS V times. Or if our graph doesn't have cycles, we could use DAG relaxation V times. Or if our graph had non-negative edge weights, we could get, basically, V squared log V plus V times E. And that's actually not bad. In sparse graphs, this is what Bellman-Ford would give us. But if we had Dijkstra's, for example, if we had all positive edge weights-- or non-negative, sorry, we could get V squared log V plus V, E time. This is V times Dijkstra. OK, so how do these running times compare? This is V times Bellman-Ford. This is V times Dijkstra. Let's just get a feel for this separation here. If we had a sparse graph where V is upper-bounded by the number of vertices, this one looks like V squared log V. This one looks like V cubed. And we need to spend at least V squared time. So actually, this is really close to linear in the size of the graph, just off by a log factor, just like sorting would entail. And this one would have a linear factor. In the sparse graph, this would be a linear factor worse than this, instead of a logarithmic factor-- again, this linear to log separation. We don't want to have to do this running time if we don't have to. That's the name of the game. And really, all we're going to do in this lecture is try to solve how we can make this running time faster by doing something a little bit more intelligent than running a single source shortest path algorithm from every vertex. How are we going to do that? Well, we could-- let's see. What are we doing? Right. The idea here, if we had a graph-- should my graph be directed or undirected? I'm not sure. Let's see if we can make a directed graph. OK, so here's a directed graph. Why do I not care about undirected graphs? Can anyone tell me? Yeah, it's because-- I don't care about undirected graphs because, if I had an undirected graph, I could detect whether I had negative weight cycles in constant time-- I'm sorry, in linear time. I could just check each edge, see if it has negative weight, because a negative weight edge, an undirected edge is a cycle of negative weight. So I could just-- if it has any negative edge weights, I could return in linear time that it does, and I can abort. Or it has only positive weights, and I can still use Dijkstra. So that's all good. So we're only concerned about needing to run Bellman-Ford on directed graphs that potentially have negative edge weight. OK, so here's a graph. Let's see. Is this a graph that I want? Sure. Let's say we've got that direction and this direction. Say we have a directed graph like this. And let's say this is s. This is our source. And we have weights being 2-- sorry, weights being 4, 1, 1, 2, 2, 2, 2. So this is an example of a graph we might want to run all-pairs shortest paths on. Maybe we also have negative weights in this graph. In particular, this has a negative weight cycle. I don't want negative weight cycles, so I'm going to make this 0. So this graph doesn't have negative weight cycles. Great. That's true, great. All right, so here's an example that we might want to compute shortest paths on. There's no s in all-pairs shortest paths. But I'm going to be talking about a couple of shortest paths from s in my next argument, so I'm just labeling that vertex as s. OK, the claim-- the approach we're going to do, we're going to try to take a graph that has negative edge weights, directed graph. We don't know if it has negative cycles or not yet. But we want to compute all-pairs shortest paths, not in this running time, but in this running time. How could we do that? Well, maybe it's possible that we can change the weight of every edge so that they're all positive, but shortest paths are preserved. So basically, if a particular path-- like OK, the shortest path from s to t here is 1, 2, 3. I could change edge weights in this graph. Say, for example, if I changed 1 to 0 here, that would still make this a shortest path. I haven't done-- I've reweighted the graph. Shortest paths have to be the same in this graph. But now-- sorry. Yeah, this is not a shortest path. OK, I'll make that minus 2, and then these both 2, and I think this 4. Man, I really should have done my example beforehand. OK, so this still doesn't have negative weight cycles. It has a negative weight edge. But this path is longer than this path. So when this was 1, this had length of 3, which was shorter than this path. That is length 4. OK, cool. So this is the shortest path from s to t. I could change weights in this graph,","70.77529907226562","9","DPRSearchEngine","EmSmaW-ud6A.en-j3PyPqV-e1s_3_mp4","EmSmaW-ud6A.en-j3PyPqV-e1s","6.006","14"
"203","How can the single-source shortest path be calculated in a graph with cycles and negative weights?"," 
 
 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) Lecture 
General Unweighted 
BFS 
|V | + |E| L09 
L11 
L12 
L13 (Today!) 
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Any 
Bellman-Ford 
Dijkstra 
|V | · |E|
General Non-negative 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 13: Dijkstra’s Algorithm 
Lecture 13: Dijkstra’s Algorithm 
Review 
• Single-Source Shortest Paths on weighted graphs 
• Previously: O(|V | + |E|)-time algorithms for small positive weights or DAGs 
• Last time: Bellman-Ford, O(|V ||E|)-time algorithm for general graphs with negative weights 
• Today: faster for general graphs with non-negative edge weights, i.e., for e ∈ E, w(e) ≥ 0 
|V | log |V | + |E| 
Non-negative Edge Weights 
• Idea! Generalize BFS approach to weighted graphs: 
– Grow a sphere centered at source s 
– Repeatedly explore closer vertices before further ones 
– But how to explore closer vertices if you don’t know distances beforehand? 
:( 
• Observation 1: If weights non-negative, monotonic distance increase along shortest paths 
– i.e., if vertex u appears on a shortest path from s to v, then δ(s, u) ≤ δ(s, v) 
– Let Vx ⊂ V be the subset of vertices reachable within distance ≤ x from s 
– If v ∈ Vx, then any shortest path from s to v only contains vertices from Vx 
– Perhaps grow Vx one vertex at a time! (but growing for every x is slow if weights large) 
• Observation 2: Can solve SSSP fast if given order of vertices in increasing distance from s 
– Remove edges that go against this order (since cannot participate in shortest paths) 
– May still have cycles if zero-weight edges: repeatedly collapse into single vertices 
– Compute δ(s, v) for each v ∈ V using DAG relaxation in O(|V | + |E|) time 
","70.52245330810547","10","DPRSearchEngine","d819e7f4568aced8d5b59e03db6c7b67_MIT6_006S20_lec13_1_pdf","d819e7f4568aced8d5b59e03db6c7b67_MIT6_006S20_lec13","6.006","13"
"204","What is the time complexity of the procedure that involves finding all vertices reachable from witnesses and setting certain vertices to minus infinity?"," 
 
 
  
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
Computation with Oracles 
Let ! be any language. 
Defn: A TM "" with oracle for !, written ""#, is a TM equipped 
with a “black box” that can answer queries “is $ ∈!?” for free. 
Example: A TM with an oracle for &!' can decide all ( ∈ NP in polynomial time. 
Defn: P# = ( ( is decidable in polynomial time with an oracle for !} 
Thus NP ⊆ P+#, 
NP = P+#,? Probably No because coNP ⊆ P+#, 
Defn: NP# = ( ( is decidable in nondeterministic polynomial time with an oracle for !} 
Recall MIN-FORMULA = 7 7 is a minimal Boolean formula } 
Example: MIN−FORMULA ∈ NP+#, 
“On input 7 
1. Guess shorter formula 9 
2.  Use &!' oracle to solve the coNP problem: 7 and 9 are equivalent 
3. Accept if 7 and 9 are equivalent. Reject if not.” 
8 
","69.77587127685547","1","DPRSearchEngine","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_8_pdf","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22","18.404J","22"
"204","What is the time complexity of the procedure that involves finding all vertices reachable from witnesses and setting certain vertices to minus infinity?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
If we know that some problem (say !TM) is undecidable, 
we can use that to show other problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Recall Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
2 
","69.02682495117188","2","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_2_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"204","What is the time complexity of the procedure that involves finding all vertices reachable from witnesses and setting certain vertices to minus infinity?","   
  
 
 
 
 
 
 
 
 
 
  
  
 
 
 
 
 
 
 
 
 
  
  
 
 
  
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
 
 
 
  
  
 
 
   
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
   
 
 
 
 
  
 
  
   
 
 
 
 
  
 
 
 
  
  
!""#$ and $""%!""#$ 
Example: $""%!""#$ = ', ), * ' is a directed graph with a path from ) to * 
and the path goes through every node of ' } 
Recall Theorem: !""#$ ∈ P 
Called a Hamiltonian path 
' 
Question: $""%!""#$ ∈ P ? 
“On input ', ), * 
1. Let - be the number of nodes in '. 
2. For each path of length - in ': 
test if - is a Hamiltonian path from ) to *. 
Accept if yes. 
3. Reject if all paths fail.” 
May be -! > 22 paths of length ­
so algorithm is exponential time 
not polynomial time. 
) 
* 
Check-in 12.3 
Is $""%!""#$ ∈ P ? 
(a) Definitely Yes. You have a polynomial-time algorithm. 
(b) Probably Yes. It should be similar to showing !""#$ ∈ P. 
(c) Toss up. 
(d) Probably No. Hard to beat the exponential algorithm. 
(e) Definitely No. You can prove it! 
Check-in 12.3 
11 
","68.61772918701172","3","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_11_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"204","What is the time complexity of the procedure that involves finding all vertices reachable from witnesses and setting certain vertices to minus infinity?","And then finding all the vertices reachable from those witnesses, we set all of the infinite ones to be minus infinity as desired. OK, so what's the running time of this thing? Well, we had to construct this graph, so we had to take that time. We ran DAG relaxation, that takes the same amount of time. For every vertex, we did order V at work. And then for each witness, how many could there be? And most, V. Checking the reachability of each vertex, that can be done in how long? Order E time. Because we don't need to consider the things that aren't connected to S-- or aren't connected to the witness. So this thing takes order V times E work. So we're upper-bounded by this time it took to construct the original graph and by the claim we had before, that takes V times E time. OK. So that's Bellman-Ford. I'm just going to leave you with two nuggets. First, the shortest path, if for any witness-- let's say we have a witness here. Do I have any witnesses here? I didn't fill in all these. But is there a vertex on this cycle that goes through who has the shortest path? That goes through four vertices that's smaller than any other. OK. I can go from a to c to b to d to b to c. And you can work out this algorithm-- I have it in the notes that you can take a look at. This will actually have a shorter path for vertex-- sorry. It'll have a shorter path for vertex b. a to b to c to d to b. Thank you. That's a path of length 4, of four edges. That has shorter path than any path that has fewer edges. In particular, there's only one other path to b using fewer than four-- there's two other paths. One path of length-- that has one edge, that has weight minus 5, and one path-- this path that has weight 9 minus 1 is 8. Whereas this path, minus 5, minus 4, 3, minus 1 has minus 10 plus 3 is minus 7, which is shorter than minus 5. So b and d is a witness. And if we actually take a look at that path through this graph, going from a to b to c to d back to b we see that there's a negative weight cycle in this graph. b to c to d to b. And indeed, that's always the case for our witnesses. You can see a proof of that in the notes, and you can see in recitation a little space optimization to make us not have to construct this entire graph on the fly, but actually only use order V space while they're going. OK. So that's Bellman-Ford. Sorry for running a little late.","68.5828628540039","4","DPRSearchEngine","f9cVS_URPc0.en-j3PyPqV-e1s_11_mp4","f9cVS_URPc0.en-j3PyPqV-e1s","6.006","12"
"204","What is the time complexity of the procedure that involves finding all vertices reachable from witnesses and setting certain vertices to minus infinity?","  
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
  
 
   
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
                 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
  
 
  
  
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
  
  
 
 
 
 
 
 
 
 
 
  
 
  
    
   
 
 
 
  
 
 
   
   
 
 
 
 
 
 
 
 
 
 
  
   
   
 
 
 
   
 
 
 
 
 
 
 
   
Time Hierarchy Theorem (2/2) 
Goal: Exhibit ! ∈ TIME # $ 
but ! ∉ TIME & # $ / log # $ 
! = ,(.) where 
1) . runs in 0 # $ 
time 
2) . ensures that ,(.) ≠ ,(2) for every TM 2 
that runs in & # $ / log # $ 
time. 
Why do we lose a factor of 789 : ; ? 
. = “On input 3
. must halt within 0 # $ 
time. 
1. Compute #($). 
To do so, . counts the number of steps it uses 
2. If 3 ≠ 2 10∗ for some TM 2, reject. 
and stops if the limit is exceeded. The counter 
3. Simulate* 2 on 3 for # $ / log # $ 
steps. 
has size log # $ 
and is stored on the tape. 
It must be kept near the current head location. 
Accept if 2 rejects, 
Cost of moving it adds a 0 log # $ 
overhead 
Reject if 2 accepts or hasn’t halted.” 
factor. So to halt within 0 # $ 
time, . stops 
*Note: . can simulate 2 with a log factor 
when the counter reaches # $ / log # $ .
time overhead due to the step counter. 
11 
","68.50347900390625","5","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_11_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"204","What is the time complexity of the procedure that involves finding all vertices reachable from witnesses and setting certain vertices to minus infinity?"," 
 
    
 
 
 
 
 
 
 
 
 
     
 
 
 
 
 
     
 
 
  
 
 
 
     
 
 
  
 
     
 
 
  
 
     
 
 
  
 
 
 
  
  
 
 
   
 
 
 
   
 
 
Check-in 26.3 
P = NP ? 
a) YES. Deep learning will do !""# ∈ P, but we won’t understand how. 
b) NO. 
But we will never prove it.
c) NO. 
We will prove it but only after 100 years
d) NO. 
We will prove it in ' years, 20 ≤ ' ≤ 100
e) NO. 
We will prove it in ' years, 1 ≤ ' < 20
f) NO. 
One of us is writing up the proof now…
9 
Check-in 26.3 
","68.40769958496094","6","DPRSearchEngine","7ac944716e076209c3964e073929f42e_MIT18_404f20_lec26_9_pdf","7ac944716e076209c3964e073929f42e_MIT18_404f20_lec26","18.404J","26"
"204","What is the time complexity of the procedure that involves finding all vertices reachable from witnesses and setting certain vertices to minus infinity?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
Use our knowledge that !TM is undecidable to show other 
problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
10 
","68.3905029296875","7","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_10_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"204","What is the time complexity of the procedure that involves finding all vertices reachable from witnesses and setting certain vertices to minus infinity?"," 
 
 
  
 
 
 
  
 
 
  
 
 
  
 
 
  
 
 
 
 
  
 
  
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
  
   
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
NO.
Oracles and P versus NP 
Theorem: There is an oracle ! where P "" = NP "" 
Proof: Let ! = $%&' 
NP()*+ ⊆ NPSPACE = PSPACE ⊆ P()*+ 
Relevance to the P versus NP question 
Recall: We showed -%./0↑ ∉ PSPACE. 
Could we show 3!$ ∉ P using a similar method? 
Reason: Suppose YES. 
The Hierarchy Theorems are proved by a diagonalization. 
In this diagonalization, the TM 4 simulates some TM 5. 
If both TMs were oracle TMs 4"" and 5"" with the same oracle !, 
the simulation and the diagonalization would still work. 
Therefore, if we could prove P ≠ NP by a diagonalization, 
we would also prove that P "" ≠ NP "" for every oracle !. 
But that is false! 
9 
Check-in 22.3 
Which of these are known to be true? 
Check all that apply. 
P7""( 
P7""( 
(a) 
= 
(b) NP7""( = coNP7""( 
(c) MIN-FORMULA ∈ P()*+ 
NP()*+ = coNP()*+ 
(d) 
Check-in 22.3 
","68.3206787109375","8","DPRSearchEngine","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_9_pdf","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22","18.404J","22"
"204","What is the time complexity of the procedure that involves finding all vertices reachable from witnesses and setting certain vertices to minus infinity?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Monte Carlo Simulation  
A method of estimating the value of an unknown 
quantity using the principles of inferential statistics 
Inferential statistics 
◦ Population: a set of examples 
◦ Sample: a proper subset of a population 
◦ Key fact: a random sample tends to exhibit the same  
properties as the population from which it is drawn  
Exactly what we did with random walks 
6.0002 LECTURE 6 
4
","68.10453796386719","9","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_4_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"204","What is the time complexity of the procedure that involves finding all vertices reachable from witnesses and setting certain vertices to minus infinity?"," 
 
  
  
 
 
 
 
 
 
   
 
 
 
 
  
 
  
 
  
 
 
  
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
   
 
    
   
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
   
  
Time Hierarchy Theorem (1/2) 
Theorem: For any !: ℕ → ℕ where ! is time constructible 
there is a language % where % requires & ! ' 
time, i.e, 
1) % is decidable in & ! ' 
time, and 
2) % is not decidable in ( ! ' / log ! ' 
time 
- .
On other words, TIME (
⊆, TIME ! ' 
/01 - . 
Proof outline:  Give TM 3 where 
1) 3 runs in & ! ' 
time 
2) 3 ensures that 4(3) ≠ 4(8) for every TM 8 that runs in ( ! ' / log ! ' 
time . 
Let % = 4(3). 
10 
","68.08425903320312","10","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_10_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"205","What is the structure of a binary tree node in terms of pointers?","I'll call them left justified. And these two properties together is what I call a complete binary tree. Why is this interesting? Because I claim I can represent a tree like this as an array. I've narrowed things down enough that I can draw an array down here. And what I'm going to do is write these nodes in depth order. So I write A first, because that's step 0. Then B, C, that's step 1. Then, well, they're alphabetical. I made it that way. D, E, F, G is depth 2. And then H, I, J is step 3. This is very different from traversal order of a tree. Traversal order would have been H, D, I, B, J, E, A, F, C, G, OK? But this is what we might call depth order, do the lowest depth nodes first-- very different way to lay things out or to linearize our data. And this is what a heap is going to look like. So the cool thing is, between complete binary trees and arrays is a bijection. For every array, there's a unique complete binary tree. And for every complete binary tree, there's a unique array. Why? Because the complete constraint forces everything-- forces my hand. There's only-- if I give you a number n, there is one tree shape of size n, right? You just fill in the nodes top down until you get to the last level. And then you have to fill them in left to right. It's what you might call reading order for writing down nodes. And the array is telling you which keys go where. This is the first node you write down at the root, this is the next node you write down at the left child of the root, and so on. So here we have a binary tree represented as an array, or array representing a binary tree. The very specific binary tree, it has a clear advantage, which is it is guaranteed balance. No rotations necessary in heaps, because complete binary trees are always balanced. In fact, they have the best height they possibly could, which is ceiling of log n. Balanced, remember, just meant you were big O of log n. This is 1 times log n. So it's the best level of balance you could hope for. So somehow, I claim, we can maintain a complete binary tree for solving priority queues. This would not be possible if you were trying to solve the whole set interface. And that's kind of the cool thing about heaps, is that by just focusing on the subset of the set interface, we can do more. We can maintain this very strong property. And because we have this very strong property, we don't even need to store this tree. We're not going to store left and right pointers and parent pointers, we're just going to store the array.","75.71856689453125","1","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_8_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"205","What is the structure of a binary tree node in terms of pointers?","We're almost done. This will actually work. It's really quite awesome. But for it to work, we need something called subtree augmentation, which I'll talk about generally. And then, we'll apply it to size. So the idea with subtree augmentation is that each node in our binary tree can store a constant number of extra fields. Why not? And in particular, if these fields are of a particular type-- maybe I'll call them properties. I'm going to define a subtree property to be something that can be computed from the properties of the nodes' children. So I should say this is of a node. So children are node.left and node.right. You can also access constant amount of other stuff,","75.69938659667969","2","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_9_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"205","What is the structure of a binary tree node in terms of pointers?","It's basically-- it's a set type thing, where I can make a set of just a single element, I can take two sets, merge them together, make them their union, and then given an object, I say, which set am I part of, essentially by electing a leader within a set and saying, return me a pointer to that one. And so this can be useful in dynamically maintaining, say, the connected components in a dynamically changing graph supporting the query of, am I in the same component as this other guy? That could be a very useful thing to know about a graph as it's changing. So that's an application of this problem. And they get near-constant performance for a lot of these queries. It's not quite, but pretty close. OK, on the graph side, they solve","75.47856903076172","3","DPRSearchEngine","2NMtS1ecb3o.en-j3PyPqV-e1s_6_mp4","2NMtS1ecb3o.en-j3PyPqV-e1s","6.006","20"
"205","What is the structure of a binary tree node in terms of pointers?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","75.12533569335938","4","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"205","What is the structure of a binary tree node in terms of pointers?","so what is a binary tree let me draw an example and then define it more precisely mathematicians will call this a rooted binary tree because in case you've seen that in o42 say here is a picture","75.00080871582031","5","DPRSearchEngine","76dhtgZt38A.en_3_mp4","76dhtgZt38A.en","6.006","6"
"205","What is the structure of a binary tree node in terms of pointers?","If you think about it a little bit, this is exactly binary search on an array. It just happens to be on a tree instead. If you think of an array like this, what does binary search do? It first looks at the key in the middle. I'm going to draw that as the root. And then, it recurses either on the left chunk, which I will draw recursively, or on the right chunk. And so if you happen to have a perfect binary tree like this one, it is simulating exactly binary search in this array. But this we're going to be able to maintain dynamically-- not perfect any more, but close. Whereas this we could not maintain in sorted order. So this is like a generalization of binary search to work on trees instead of on arrays. And for this reason, set binary trees are called binary search trees, because they're the tree version of binary search. So there's many equivalent names. So binary search tree is another name for set binary tree. And the key thing that makes this algorithm work is the so-called binary search tree property, which is all the keys in the left subtree of a node are less than the root, or of that node, and that key is less than all the keys in the right subtree. And this is true recursively all the way down. And so that's how you prove that this algorithm is correct by this property. Why is this true? Because if we can maintain traversal order to be increasing key, then that's exactly what traversal order means. It tells you all the things in the left subtree come before the root, which come before all the things in the right subtree.","73.96736145019531","6","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_4_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"205","What is the structure of a binary tree node in terms of pointers?","You've taken, probably-- you've probably seen linked lists before at some point. But the main new part here is, we're going to actually analyze them and see how efficiently they implement all of these operations we might care about. First, review. What is a linked list? We store our items in a bunch of nodes. Each node has an item in it and a next field. So you can think of these as class objects with two class variables, the item and the next pointer. And we assemble those into this kind of structure where we store-- in the item fields, we're going to store the actual values that we want to represent in our sequence, x 0 through x n minus 1, in order. And then we're going to use the next pointers to link these all together in that order. So the next pointers are what actually give us the order. And in addition, we're going to keep track of what's called the head of the list. The data structure is going to be represented by a head. If you wanted to, you could also store length. This could be the data structure itself. And it's pointing to all of these types of data structures. Notice, we've just seen an array-based data structure, which is just a static array, and we've seen a pointer-based data structure. And we're relying on the fact that pointers can be stored in a single word, which means we can de-reference them-- we can see what's on the other side of the pointer-- in constant time in our word RAM model. In reality, each of these nodes is stored somewhere in the array of the computer. So maybe each one is two words long, so maybe one node is-- the first node is here. Maybe the second node is here. The third node is here. They're in some arbitrary order. We're using this fact, that we can allocate an array of size n in linear time-- in this case, we're going to have arrays of size 2. We can just say, oh, please give me a new array of size 2. And that will make us one of these nodes. And then we're storing pointers. Pointers are just indices into the giant memory array. They're just, what is the address of this little array? If you've ever wondered how pointers are implemented, they're just numbers that say where, in memory, is this thing over here? And in memory, they're in arbitrary order. This is really nice because it's easy to manipulate the order of a linked list without actually physically moving nodes around, whereas arrays are problematic. Maybe it's worth mentioning. Let's start analyzing things. So we care about these dynamic sequence operations. And we could try to apply it to the static array data structure, or we could try to implement these operations in a static array. It's possible, just not going to be very good. And we can try to implement it with linked lists. And it's also not going to be that great.","73.89666748046875","7","DPRSearchEngine","CHhwJjR0mZA.en-j3PyPqV-e1s_5_mp4","CHhwJjR0mZA.en-j3PyPqV-e1s","6.006","2"
"205","What is the structure of a binary tree node in terms of pointers?","But before we get there, I want to talk a little bit more-- at the very end of the last lecture, we talked about once you have these subtree operations-- so I can insert and delete in the subtree-- how do I actually use that to solve the problems that we care about in this class, which are sequence data structure and set data structure? So we talked mostly about the set data structure last time. So in general, we're going to define what traversal order we maintain by a binary tree. And so for a set, because for the set interface, we're interested in doing queries like find_next and find_previous, given a key, if it's not there, tell me the previous one or the next one, this is something we could do with binary search. And so the big, cool thing that binary trees let us do, if we let the traversal order always be all of the items stored in increasing key order, then we are effectively maintaining the items in order-- in the traversal order sense. Again, we're not explicitly maintaining them in order. But up here, we're maintaining a tree that represents items in key order. And so this lets us do a subtree_find operation-- which you could easily use to implement find, and find_previous, and so on-- as follows. We start at the root of the tree. So we can say, node equals root initially. And then we can recursively search for a key k as follows. We check, well, if the item at the root has a key that's bigger than k-- let me draw a little picture. So we're at some node here. This is a node. And it has left subtree and a right subtree. And there's some item with some key. So if the key we're looking for is less than the node's item, that means it's down here in the left subtree. And so we recurse on node.left. If they're equal, that means that this item is the item we're looking for. So we can just return it or the node, depending on what you're looking for. And if the key in here is greater than the key","73.74604797363281","8","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_3_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"205","What is the structure of a binary tree node in terms of pointers?","namely, random accessing. And if we stored the things that we're looking for, we have unique keys, and those keys are integers. Then, if I have an item with key K, if I store it at index K in my array, then I can find it and manipulate it in constant time.","73.67557525634766","9","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_2_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"205","What is the structure of a binary tree node in terms of pointers?","   
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
  
  
 
 
  
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
≤"" Example: 3$%& and '()*+, 
Defn: A Boolean formula - is in Conjunctive Normal Form (CNF) if it 
has the form - = / ∨1 ∨2 ∧ / ∨4 ∨2 ∨5 ∧⋯∧ (2 ∨5) 
clause 
clause 
literals 
Literal: a variable or a negated variable 
Clause: an OR (∨) of literals. 
CNF: an AND (∧) of clauses. 
3CNF:  a CNF with exactly 3 literals in each clause. 
3$%& = ­
- is a satisfiable 3CNF formula} 
Defn:  A 9-clique in a graph is a subset of k nodes all directly connected by edges. 
3-clique 
'()*+, = ;, 9 graph ; contains a 9-clique} 
Will show: 3$%& ≤"" '()*+, 
4-clique 
5-clique 
3 
","73.30309295654297","10","DPRSearchEngine","c1aca7046a69c913721e5eb910a5fb21_MIT18_404f20_lec15_3_pdf","c1aca7046a69c913721e5eb910a5fb21_MIT18_404f20_lec15","18.404J","15"
"206","How is a binary search tree's property utilized when deleting a node with a left child?"," &&%$3$%'9
class Digraph(object): 
 """"""edges is a dict mapping each node to a list of 
    its children""""” 
    def __init__(self): 
self.edges = {} 
    def addNode(self, node): 
if node in self.edges: 
 raise ValueError('Duplicate node') 
else: 
self.edges[node] = [] 
    def addEdge(self, edge): 
src = edge.getSource() 
dest = edge.getDestination() 
if not (src in self.edges and dest in self.edges): 
raise ValueError('Node not in graph') 
self.edges[src].append(dest) 
Q>KKKMN
LS
mapping each node 
list 
","77.48761749267578","1","DPRSearchEngine","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_18_pdf","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3","6.0002","3"
"206","How is a binary search tree's property utilized when deleting a node with a left child?","If you think about it a little bit, this is exactly binary search on an array. It just happens to be on a tree instead. If you think of an array like this, what does binary search do? It first looks at the key in the middle. I'm going to draw that as the root. And then, it recurses either on the left chunk, which I will draw recursively, or on the right chunk. And so if you happen to have a perfect binary tree like this one, it is simulating exactly binary search in this array. But this we're going to be able to maintain dynamically-- not perfect any more, but close. Whereas this we could not maintain in sorted order. So this is like a generalization of binary search to work on trees instead of on arrays. And for this reason, set binary trees are called binary search trees, because they're the tree version of binary search. So there's many equivalent names. So binary search tree is another name for set binary tree. And the key thing that makes this algorithm work is the so-called binary search tree property, which is all the keys in the left subtree of a node are less than the root, or of that node, and that key is less than all the keys in the right subtree. And this is true recursively all the way down. And so that's how you prove that this algorithm is correct by this property. Why is this true? Because if we can maintain traversal order to be increasing key, then that's exactly what traversal order means. It tells you all the things in the left subtree come before the root, which come before all the things in the right subtree.","76.47366333007812","2","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_4_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"206","How is a binary search tree's property utilized when deleting a node with a left child?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","76.44441223144531","3","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"206","How is a binary search tree's property utilized when deleting a node with a left child?"," 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 6: Binary Trees I 
Lecture 6: Binary Trees I 
Previously and New Goal 
Sequence 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
build(X) 
get at(i) 
set at(i,x) 
insert first(x) 
delete first() 
insert last(x) 
delete last() 
insert at(i, x) 
delete at(i) 
Array 
n 
1 
n 
n 
n 
Linked List 
n 
n 
1 
n 
n 
Dynamic Array 
n 
1 
n 
1(a) 
n 
Goal 
n 
log n 
log n 
log n 
log n 
Set 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
Direct Access Array 
u 
1 
1 
u 
u 
Hash Table 
n(e) 
1(e) 
1(a)(e) 
n 
n 
Goal 
n log n 
log n 
log n 
log n 
log n 
How? Binary Trees! 
• Pointer-based data structures (like Linked List) can achieve worst-case performance 
• Binary tree is pointer-based data structure with three pointers per node 
• Node representation: node.{item, parent, left, right} 
• Example: 
1 
2 
3 
4 
5 
________<A>_____ 
__<B>_____ 
<C> 
__<D> 
<E> 
<F> 
node 
| 
item 
| 
parent | 
left 
| 
right 
| 
<A> | 
A 
| 
-
| 
<B> | 
<C> | 
<B> 
B 
<A> 
<C> 
<D> 
| 
| 
| 
| 
| 
<C> | 
C 
| 
<A> | 
-
| 
-
| 
<D> | 
D 
| 
<B> | 
<F> | 
-
| 
<E> | 
E 
| 
<B> | 
-
| 
-
| 
<F> 
F 
<D> 
-
-
| 
| 
| 
| 
| 
","76.03202056884766","4","DPRSearchEngine","376714cc85c6c784d90eec9c575ec027_MIT6_006S20_lec6_1_pdf","376714cc85c6c784d90eec9c575ec027_MIT6_006S20_lec6","6.006","6"
"206","How is a binary search tree's property utilized when deleting a node with a left child?","We're almost done. This will actually work. It's really quite awesome. But for it to work, we need something called subtree augmentation, which I'll talk about generally. And then, we'll apply it to size. So the idea with subtree augmentation is that each node in our binary tree can store a constant number of extra fields. Why not? And in particular, if these fields are of a particular type-- maybe I'll call them properties. I'm going to define a subtree property to be something that can be computed from the properties of the nodes' children. So I should say this is of a node. So children are node.left and node.right. You can also access constant amount of other stuff,","75.95735931396484","5","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_9_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"206","How is a binary search tree's property utilized when deleting a node with a left child?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","75.33114624023438","6","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"206","How is a binary search tree's property utilized when deleting a node with a left child?","&

	
	
	/
def greedy(items, maxCost, keyFunction):
itemsCopy = sorted(items, key = keyFunction,
reverse = True)
result = []
totalValue, totalCost = 0.0, 0.0
for i in range(len(itemsCopy)):
if (totalCost+itemsCopy[i].getCost()) <= maxCost:
result.append(itemsCopy[i])
totalCost += itemsCopy[i].getCost()
totalValue += itemsCopy[i].getValue()
return (result, totalValue) 
	

2
	

","74.16761779785156","7","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_24_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"206","How is a binary search tree's property utilized when deleting a node with a left child?"," 
 
 
    
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Return to Closure Properties 
Recall Theorem: If !"", !$ are regular languages, so is !"" ∪!$ 
(The class of regular languages is closed under union) 
New Proof (sketch): Given DFAs &"" and &$ recognizing !"" and !$ 
&$
&"" 
ε 
ε 
& 
Construct NFA & recognizing !"" ∪!$ 
Nondeterminism 
parallelism 
vs 
guessing 
7 
","74.14217376708984","8","DPRSearchEngine","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_7_pdf","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2","18.404J","2"
"206","How is a binary search tree's property utilized when deleting a node with a left child?","sorry, delete_max, thank you. You can of course define all of these things for min instead of max. Everything works the same. I just have a hard time remembering which one we're doing. Just don't switch you can't use a max-heap to do delete_min. You can't use a min-heap to do delete_max, but you can use a min-heap to do delete_min. That's fine. So like I said, the only node we really know how to delete is the last leaf on the last level, which is the end of the array. Because that's what arrays can delete efficiently. And what we need to delete is the root item, because that's always the maximum one, which is at the first position in the array. So what do we do? Swap them, our usual trick. I think the cool thing about heaps is we never have to do rotations. We're only going to do swaps, which is something we had to do with trees also-- binary trees. Q[0] with Q of the last item-- great, done. Now we have the last item is the one we want to delete. So we do delete_last, or pop in Python, and boom, we've got-- we've now deleted the maximum item. Of course, we may have also messed up the max-heap property just like we did with insert. So with insert, we were adding a last leaf. Now, what we're doing is swapping the last leaf with the-- I'm pointing at the wrong picture. Let me go back to this tree. What we did is swap item J with A. So the problem is now-- and then we deleted this node. The problem is now that that root node has maybe a very small key. Because the key that's here now is whatever was down here, which is very low in the tree. So intuitively, that's a small value. This is supposed to be the maximum value, and we just put a small value in the root. So what do we do? Heapify down. We're going to take that item and somehow push it down to the tree until the-- down in the tree until max-heap property is satisfied. So this is going to be max_heapify_down. And we will start at position 0, which is the root. And max_heapify_down is going to be a recursive algorithm. So we'll start at some position i. And initially, that's the root. And what we're going to do is look at position i and its two children. So let's say we put a very small value up here, like 0. And let's say we have our children, 5 and 10. We don't know-- maybe I'll swap their order just to be more generic, because that looks like not quite a binary search tree, but we don't know their relative order. But one of them is greater than or equal to the other in some order. And so what would I like to do to fix this local picture? Yeah, I want to swap. And I could swap-- 0 is clearly in the wrong spot. It needs to go lower in the tree. I can swap 0 with 5 or 0 with 10. Which one? 10. I could draw the picture with 5, but it will not be happy. Why 10? We want to do it with the larger one, because then this edge will be happy, and also this edge will be happy. If I swapped 5 up there instead, the 5/10 edge would be unhappy. It wouldn't satisfy the max-heap property. So I can do one swap and fix max-heap property. Except that, again, 0 may be unhappy with its children. 0 was this one item that was in the wrong spot. And so it made it have to go farther down. But 5 will be-- 5 didn't even move. So it's happy. Everything in this subtree is good. What about the parent? Well, if you think about it, because everything was a correct heap before we added 0, or before we put 0 too high, all of these nodes will be greater than or equal to 10 on the ancestor path. And all of these nodes were less than or equal to 10 before, unless you're equal to 5. So that's still true. But you see, this tree is happy. This tree still may be unhappy. 0 still might need to push down farther. That's going to be the recursion. So we check down here. There's a base case, which is if i is a leaf, we're done. Because there's nothing below them. So we satisfy the max-heap property at i because there's no children. Otherwise, let's look at the leaf among the left-- sorry, left not leaf-- among the two children left and right of i. Right if i might not exist. Then ignore it. But among the two children that exist, find the one that has maximum key value, Q[j].key. That was 10 in our example. And then, if these items are out of order, if we do not satisfy-- so greater than would be satisfy. Less than Q[j] would be the opposite of the max-heap property here. If max-heap property is violated, then we fix it by swapping Q[i] with Q[j], and then we recurse on j-- call max_heapify_down of j. That's it. So pretty symmetric. Insert was a little bit simpler, because we only have one parent. Delete_min, because we're pushing down, we have two children. We have to pick one. But there's a clear choice-- the bigger one. And again, this algorithm-- this whole thing-- will take order h time, the height of the tree, which is log n, because our node just sort of bubbles down. At some point, it stops. When it stops, we know the max-heap property was satisfied there. And if you check along the way, by induction, all the other max-heap properties will be satisfied, because they were before. So almost forced what we could do here. The amazing thing is that you can actually maintain a complete binary tree that satisfies the max-heap property. But once you're told that, the algorithm kind of falls out. Because we have an array. The only thing we can do is insert and delete the last item. And so we've got to swap things to there in order-- or out of there in order to make that work. And then, the rest is just checking locally that you can fix the property. Cool. So that's almost it, not quite what we wanted. So we now have log n amortize insert and delete_max in our heap. We did not yet cover linear build. Right now, it's n log n if you insert n times. And we did not yet cover how to make this an in-place sorting algorithm. So let me sketch each of those. I think first is in-place. So how do we make this algorithm in-place? I guess I want that, but I don't need this. So we want to follow priority queue sort. Maybe I do want that. But I don't want to have to grow and shrink my array. I would just like to start with the array itself. So this is in place. So what we're going to do is say, OK, here's my array that I want to sort. That's given to me. That's the input to priority queue sort. And what I'd like is to build a priority queue out of it. Initially, it's empty. And then I want to insert the items one at a time, let's say. So in general, what I'm going to do is maintain that Q is some prefix of A. That's going to be my priority queue. It's going to live in this sub array-- this prefix. So how do I insert a new item? Well, I just increment. So to do an insert, the first step is increment size of Q. Then I will have taken the next item from A and injected into this Q. And conveniently, if we look at our insert code, which is here, the first thing we wanted to do was add an item at the end of the array. So we just did it without any actual work, just conceptual work. We just said, oh, our Q is one bigger. Boom! Now this is at the end of the array. no more amortization, in fact, because we're not ever resizing our array, we're just saying, oh, now Q is a little bit bigger of a prefix. It just absorb the next item of A. Similarly, delete_max is going to, at the end, decrement the size of Q. Why is that OK? Because at the end of our delete_max operation-- not quite at the end, but almost the end-- we deleted the last item from our array. So we just replaced that delete last with a decrement, and that's going to shrink the Q by 1. It has the exact same impact as leading the last item. But now, it's constant time, worst case not amortized. And the result is we never actually build a dynamic array. We just use a portion of A to do it. So what's going to happen is we're going to absorb all the items into the priority queue, and then start kicking them out. As we kick them out, we kick out the largest key item first, and we put it here, then the next largest, then the next largest, and so on. The minimum item is going to be here. And, boom, it's sorted. This is the whole reason I did max-heaps instead of min-heaps, is that in the end, this will be a upward sorted array with the max at the end. Because we always kick out items at the end. We delete the max first. So that is what's normally called heapsort. You can apply this same trick to insertion sort and selection sort, and you actually get the insertion sort and selection sort algorithms that we've seen which operate in prefixes of the array. Cool, so now we have-- we've achieved the y up there, which is n log n sorting algorithm that is in-place. So that was our main goal-- heapsort. Let me very quickly mention you can build a heap in linear time with a clever trick. So if you insert the items one at a time, that would correspond to inserting down the array. And every time I insert an item, I have to walk up the tree. So this would be the sum of the depth of each node. If you do that, you get n log n. This is the sum over i of log i. That turns out to be n log n. It's a log of n factorial. The cool trick is to, instead, imagine adding all the items at once and not heapifying anything, and then heapify up-- sorry, heapify down from the bottom up. So here we're heapifying up. Now, we're going to heapify down. And surprisingly, that's better. Because this is the sum of the heights of the nodes. And that turns out to be linear. It's not obvious. But intuitively, for a depth, this is 0, this is log n, and we've got a whole ton of leaves. So right at the leaf level, you can see, we're paying n log n, right? Because there are n of them, and each one costs log n. Down here, at the leaf level, we're paying constant. Because the height of the leaves are 1. Here, the height of the root is log n. And this is better. Now we're paying a small amount for the thing of which there are many. It's not quite a geometric series, but it turns out this is linear. So that's how you can do linear building heap. To come back to your question about sequence AVL trees, turns out you can get all of the same bounds as heaps, except for the in-place part, by taking a sequence AVL tree, storing the items in an arbitrary order, and augmenting by max, which is a crazy idea. But it also gives you a linear build time. And yeah, there's other fun stuff in your notes. But I'll stop there.","73.7177505493164","9","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_11_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"206","How is a binary search tree's property utilized when deleting a node with a left child?","§ The tree is built top down star<ng with the root  
§ The ﬁrst element is selected from the s<ll to be 
considered items 
◦ If there is room for that item in the knapsack, a node is 
constructed that reﬂects the consequence of choosing to 
take that item.  By conven<on, we draw that as the leS 
child 
◦ We also explore the consequences of not taking that 
item. This is the right child 
§ The process is then applied recursively to non-leaf 
children 
§ Finally, chose a node with the highest value that meets 
constraints 
Search Tree Implementa#on 
6.0002 LECTURE 2 
5 
","73.67427062988281","10","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_5_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"208","What is the main benefit of using binary heaps for sorting as discussed?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","74.82594299316406","1","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"208","What is the main benefit of using binary heaps for sorting as discussed?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","74.52660369873047","2","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"208","What is the main benefit of using binary heaps for sorting as discussed?","They take linear time for some of the operations. So the sorting algorithms are not efficient. But they're ones we've seen before, so it's neat to see how they fit in here. They had the-- selection sort and insertion sort had the advantage that they were in place. You just needed a constant number of pointers or indices beyond the array itself. So they're very space efficient. So that was a plus for them. But they take n squared time, so you should never use them, except for n, at most, 100 or something. AVL tree sort is great and then it gets n log n time, probably more complicated than merge sort and you could stick to merge sort. But neither merge sort nor set AVL tree sort are in place. And so the goal of today is to get the best of all those worlds in sorting to get n log n comparisons, which is optimal in the comparison model, but get it to be in place. And that's what we're going to get with binary heaps. We're going to design a data structure that happens to build a little bit faster-- as I mentioned, linear time building. So it's not representing a sorted order in the same way that AVL trees are. But it will be kind of tree-based. It will also be array-based. We're going to get logarithmic time for insert and delete_max. It happens to be amortized, because we use arrays. But the key thing is that it's an in-place data structure. It only consists of an array of the items. And so, when we plug it into our sorting algorithm-- priority queue sort or generic sorting algorithm-- not only do we get n log n performance, but we also get an in-place sorting algorithm. This will be our first and only-- to this class-- n log n in-place sorting algorithm. Cool. That's the goal.","74.5088119506836","3","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_5_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"208","What is the main benefit of using binary heaps for sorting as discussed?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 5: Linear Sorting 
Lecture 5: Linear Sorting 
Review 
• Comparison search lower bound: any decision tree with n nodes has height ≥dlg(n+1)e−1 
• Can do faster using random access indexing: an operation with linear branching factor! 
• Direct access array is fast, but may use a lot of space (Θ(u)) 
• Solve space problem by mapping (hashing) key space u down to m = Θ(n) 
• Hash tables give expected O(1) time operations, amortized if dynamic 
• Expectation input-independent: choose hash function randomly from universal hash family 
• Data structure overview! 
• Last time we achieved faster ﬁnd. Can we also achieve faster sort? 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
Direct Access Array 
u 
1 
1 
u 
u 
Hash Table 
n(e) 
1(e) 
1(a)(e) 
n 
n 
","72.3272705078125","4","DPRSearchEngine","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5_1_pdf","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5","6.006","5"
"208","What is the main benefit of using binary heaps for sorting as discussed?","[SQUEAKING][RUSTLING][CLICKING] JASON KU: Welcome, everybody, to our lecture 14 of 6.006. This is our last lecture on graph algorithms, in particular, the last lecture we'll have on weighted shortest paths. But we're going to talk about a slightly different problem today, different than single source shortest paths. We're going to be talking about all-pairs shortest paths. But first, let's review our single source shortest paths algorithms. We had BFS, DAG relaxation, Dijkstra, which we saw last time, which gets pretty close to linear. V log V plus E is pretty close to linear. It's much closer to linear than the general algorithm we have for solving single source shortest paths, namely, Bellman-Ford, which is a little bit more like quadratic. This is like the difference between-- for sparse graphs, this is like the difference between sorting, using insertion sort and n squared, and merge sort in N log N, for example. We're going to get actually quite a big bonus for large input sizes by using Dijkstra when we can. Today, we're going to be focusing","72.10968780517578","5","DPRSearchEngine","EmSmaW-ud6A.en-j3PyPqV-e1s_1_mp4","EmSmaW-ud6A.en-j3PyPqV-e1s","6.006","14"
"208","What is the main benefit of using binary heaps for sorting as discussed?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 4: Hashing 
Lecture 4: Hashing 
Review 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
• Idea! Want faster search and dynamic operations. Can we find(k) faster than Θ(log n)? 
• Answer is no (lower bound)! (But actually, yes...!?) 
Comparison Model 
• In this model, assume algorithm can only differentiate items via comparisons 
• Comparable items: black boxes only supporting comparisons between pairs 
• Comparisons are <, ≤, >, ≥, =, =6 , outputs are binary: True or False 
• Goal: Store a set of n comparable items, support find(k) operation 
• Running time is lower bounded by # comparisons performed, so count comparisons! 
Decision Tree 
• Any algorithm can be viewed as a decision tree of operations performed 
• An internal node represents a binary comparison, branching either True or False 
• For a comparison algorithm, the decision tree is binary (draw example) 
• A leaf represents algorithm termination, resulting in an algorithm output 
• A root-to-leaf path represents an execution of the algorithm on some input 
• Need at least one leaf for each algorithm output, so search requires ≥ n + 1 leaves 
","71.71497344970703","6","DPRSearchEngine","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_1_pdf","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4","6.006","4"
"208","What is the main benefit of using binary heaps for sorting as discussed?","I'll call them left justified. And these two properties together is what I call a complete binary tree. Why is this interesting? Because I claim I can represent a tree like this as an array. I've narrowed things down enough that I can draw an array down here. And what I'm going to do is write these nodes in depth order. So I write A first, because that's step 0. Then B, C, that's step 1. Then, well, they're alphabetical. I made it that way. D, E, F, G is depth 2. And then H, I, J is step 3. This is very different from traversal order of a tree. Traversal order would have been H, D, I, B, J, E, A, F, C, G, OK? But this is what we might call depth order, do the lowest depth nodes first-- very different way to lay things out or to linearize our data. And this is what a heap is going to look like. So the cool thing is, between complete binary trees and arrays is a bijection. For every array, there's a unique complete binary tree. And for every complete binary tree, there's a unique array. Why? Because the complete constraint forces everything-- forces my hand. There's only-- if I give you a number n, there is one tree shape of size n, right? You just fill in the nodes top down until you get to the last level. And then you have to fill them in left to right. It's what you might call reading order for writing down nodes. And the array is telling you which keys go where. This is the first node you write down at the root, this is the next node you write down at the left child of the root, and so on. So here we have a binary tree represented as an array, or array representing a binary tree. The very specific binary tree, it has a clear advantage, which is it is guaranteed balance. No rotations necessary in heaps, because complete binary trees are always balanced. In fact, they have the best height they possibly could, which is ceiling of log n. Balanced, remember, just meant you were big O of log n. This is 1 times log n. So it's the best level of balance you could hope for. So somehow, I claim, we can maintain a complete binary tree for solving priority queues. This would not be possible if you were trying to solve the whole set interface. And that's kind of the cool thing about heaps, is that by just focusing on the subset of the set interface, we can do more. We can maintain this very strong property. And because we have this very strong property, we don't even need to store this tree. We're not going to store left and right pointers and parent pointers, we're just going to store the array.","71.52525329589844","7","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_8_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"208","What is the main benefit of using binary heaps for sorting as discussed?","4 
Lecture 1: Introduction 
1 
def birthday_match(students): 
2 
’’’ 
3 
Find a pair of students with the same birthday 
4 
Input: 
tuple of student (name, bday) tuples 
5 
Output: tuple of student names or None 
6 
’’’ 
7 
n = len(students) 
# O(1) 
8 
record = StaticArray(n) 
# O(n) 
9 
for k in range(n): 
# n 
10 
(name1, bday1) = students[k] 
# O(1) 
11 
# Return pair if bday1 in record 
12 
for i in range(k): 
# k 
13 
(name2, bday2) = record.get_at(i) 
# O(1) 
14 
if bday1 == bday2: 
# O(1) 
15 
return (name1, name2) 
# O(1) 
16 
record.set_at(k, (name1, bday1)) 
# O(1) 
17 
return None 
# O(1) 
Example: Running Time Analysis 
• Two loops: outer k ∈{0, . . . , n − 1}, inner is i ∈{0, . . . , k}
P n−1
• Running time is O(n) + 
k=0 (O(1) + k · O(1)) = O(n2) 
• Quadratic in n is polynomial. Efﬁcient? Use different data structure for record! 
How to Solve an Algorithms Problem 
1. Reduce to a problem you already know (use data structure or algorithm) 
Search Problem (Data Structures) 
Sort Algorithms 
Static Array (L01) 
Insertion Sort (L03) 
Linked List (L02) 
Selection Sort (L03) 
Dynamic Array (L02) 
Merge Sort (L03) 
Sorted Array (L03) 
Counting Sort (L05) 
Direct-Access Array (L04) 
Radix Sort (L05) 
Hash Table (L04) 
AVL Sort (L07) 
Balanced Binary Tree (L06-L07) 
Heap Sort (L08) 
Binary Heap (L08) 
2. Design your own (recursive) algorithm 
• Brute Force 
• Decrease and Conquer 
• Divide and Conquer 
• Dynamic Programming (L15-L19) 
• Greedy / Incremental 
Shortest Path Algorithms 
Breadth First Search (L09) 
DAG Relaxation (L11) 
Depth First Search (L10) 
Topological Sort (L10) 
Bellman-Ford (L12) 
Dijkstra (L13) 
Johnson (L14) 
Floyd-Warshall (L18) 
","71.40350341796875","8","DPRSearchEngine","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_4_pdf","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1","6.006","1"
"208","What is the main benefit of using binary heaps for sorting as discussed?","found by combining optimal solutions to local subproblems. So for example, when x is greater than 1 we can solve fib x by solving fib x minus 1 and fib x minus 2 and adding those two things together. So there is optimal substructure-- you solve these two smaller problems independently of each other and then combine the solutions in a fast way. You also have to have something called overlapping subproblems. This is why the memo worked. Finding an optimal solution has to involve solving the same problem multiple times. Even if you have optimal substructure, if you don't see the same problem more than once-- creating a memo. Well, it'll work, you can still create the memo. You'll just never find anything in it when you look things up because you're solving each problem once. So you have to be solving the same problem multiple times and you have to be able to solve it by combining solutions to smaller problems. Now, we've seen things with optimal substructure before. In some sense, merge sort worked that way-- we were combining separate problems. Did merge sort have overlapping subproblems? No, because-- well, I guess, it might have if the list had the same element many, many times. But we would expect, mostly not. Because each time we're solving a different problem, because we have different lists that we're now sorting and merging. So it has half of it but not the other. Dynamic programming will not help us for sorting, cannot be used to improve merge sort. Oh, well, nothing is a silver bullet. What about the knapsack problem? Does it have these two properties? We can look at it in terms of these pictures. And it's pretty clear that it does have optimal substructure because we're taking the left branch and the right branch and choosing the winner. But what about overlapping subproblems? Are we ever solving, in this case, the same problem-- add two nodes? Well, do any of these nodes look identical? In this case, no. We could write a dynamic programming solution to the knapsack problem-- and we will-- and run it on this example, and we'd get the right answer. We would get zero speedup. Because at each node, if you can see, the problems are different. We have different things in the knapsack or different things to consider. Never do we have the same contents and the same things left to decide. So ""maybe"" was not a bad answer if that was the answer you gave to this question. But let's look at a different menu. This menu happens to have two beers in it. Now, if we look at what happens, do we see two nodes that are solving the same problem? The answer is what? Yes or no? I haven't drawn the whole tree here. Well, you'll notice the answer is yes.","71.34896087646484","9","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_11_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"208","What is the main benefit of using binary heaps for sorting as discussed?","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","71.25877380371094","10","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"209","What was the reason Bellman named the approach 'dynamic programming'?","Why did Bellman call dynamic programming dynamic programming? Mostly because it sounded cool, and he was trying to impress government agencies giving him grants. I mean, how can you argue with something as cool-sounding as dynamic programming? But there is some logic to it. Programming is a reference to an old form of this word, which means optimization. And generally, we're trying to optimize things. And instead of optimizing according to some static kind of approach or program, we're doing it dynamically. This is a reference to the local brute force we're doing to optimize at each stage. You can't tell, at the top, what you're going to do in the middle. And so it's kind of-- each subproblem is behaving differently. And so, in that sense, dynamic. And it sounds cool. All right. Then we'll go to all-pairs shortest paths. We'll see a new algorithm for that that's not asymptotically any better, but it's nice and simple, and another way to-- a cool way to see subproblem expansion. And then we'll look at a couple of sort of practical problems-- parenthesizing arithmetic expressions and a real-world problem, piano and guitar fingering, so assigning a fingering how to play a piece. And we're going to do that with our SRTBOT framework. Quick recollection of what that is. We define subproblems. And we saw how to do that for sequences. We try either prefixes, suffixes, or substrings. We prefer prefixes and suffixes because there's fewer of them. If there's more than one sequence, we take the product of those spaces. And then the idea we're going to stress today is, we can always add subproblems","75.51211547851562","1","DPRSearchEngine","TDo3r5M1LNo.en-j3PyPqV-e1s_2_mp4","TDo3r5M1LNo.en-j3PyPqV-e1s","6.006","17"
"209","What was the reason Bellman named the approach 'dynamic programming'?","4 
Lecture 15: Recursive Algorithms 
Dynamic Programming 
• Weird name coined by Richard Bellman 
– Wanted government funding, needed cool name to disguise doing mathematics! 
– Updating (dynamic) a plan or schedule (program) 
• Existence of recursive solution implies decomposable subproblems1 
• Recursive algorithm implies a graph of computation 
• Dynamic programming if subproblem dependencies overlap (DAG, in-degree > 1) 
• “Recurse but re-use” (Top down: record and lookup subproblem solutions) 
• “Careful brute force” (Bottom up: do each subproblem in order) 
• Often useful for counting/optimization problems: almost trivially correct recurrences 
How to Solve a Problem Recursively (SRT BOT) 
1. Subproblem deﬁnition 
subproblem x ∈ X 
• Describe the meaning of a subproblem in words, in terms of parameters 
• Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence 
• Often record partial state: add subproblems by incrementing some auxiliary variables 
2. Relate subproblem solutions recursively 
x(i) = f(x(j), . . .) for one or more j < i 
3. Topological order to argue relation is acyclic and subproblems form a DAG 
4. Base cases 
• State solutions for all (reachable) independent subproblems where relation breaks down 
5. Original problem 
• Show how to compute solution to original problem from solutions to subproblem(s) 
• Possibly use parent pointers to recover actual solution, not just objective function 
6. Time analysis 
P 
• 
work(x), or if work(x) = O(W ) for all x ∈ X, then |X| · O(W )
x∈X 
• work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time 
1This property often called optimal substructure. It is a property of recursion, not just dynamic programming 
","72.0738296508789","2","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_4_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"209","What was the reason Bellman named the approach 'dynamic programming'?","Some<mes a name is just a name 
 
“The 1950s were not good years for mathema<cal 
research… I felt I had to do something to shield Wilson 
and the Air Force from the fact that I was really doing 
mathema<cs... What <tle, what name, could I 
choose? ... It's impossible to use the word dynamic in a 
pejora<ve sense. Try thinking of some combina<on that 
will possibly give it a pejora<ve meaning. It's 
impossible. Thus, I thought dynamic programming was 
a good name. It was something not even a 
Congressman could object to. So I used it as an 
umbrella for my ac<vi<es. 
                 -- Richard Bellman 
Dynamic Programming? 
6.0002 LECTURE 2 
15 
","71.42425537109375","3","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_15_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"209","What was the reason Bellman named the approach 'dynamic programming'?","[SQUEAKING] [RUSTLING] [CLICKING] ERIK DEMAINE: All right. Welcome back to 006 and our dynamic programming quadruple of lectures. We are over halfway through, into lecture three of four. Today, we're going to follow up on this idea of problem constraints and expansion that was mentioned, especially, towards the end of last lecture. We saw an example of subproblem expansion by a factor of 2 in the two-player game with coins where we wanted to have two versions of the game, one where I go first and one where you go first. So this was expanding the number of such problems by a factor of 2. Today, we'll see a bunch more examples of this idea, including in one setting we've seen already, which is Bellman-Ford, which you can think of as a dynamic program. Maybe it's a good time to mention that Bellman invented dynamic programming in the '50s. Same Bellman in the Bellman-Ford algorithm. This was actually an independent discovery by both of them-- and other people. He invented dynamic programming, and then, a few years later, he applied it to solve the single-source shortest paths problem. We saw them in the other order. We saw single-source shortest paths first, because it was a little easier. And now we're seeing the general framework that this fits into.","71.23007202148438","4","DPRSearchEngine","TDo3r5M1LNo.en-j3PyPqV-e1s_1_mp4","TDo3r5M1LNo.en-j3PyPqV-e1s","6.006","17"
"209","What was the reason Bellman named the approach 'dynamic programming'?","A pretty small number. But the probability of 26 consecutive reds when the previous 25 rolls were red is what? No, that. AUDIENCE: Oh, I thought you meant it had been 26 times again. JOHN GUTTAG: No, if you had 25 reds and then you spun the wheel once more, the probability of it having 26 reds is now 0.5, because these are independent events. Unless of course the wheel is rigged, and we're assuming it's not. People have a hard time accepting this, and I know it seems funny. But I guarantee there will be some point in the next month or so when you will find yourself thinking this way, that something has to even out. I did so badly on the midterm, I will have to do better on the final. That was mean, I'm sorry. All right, speaking of means-- see? Professor Grimson not the only one who can make bad jokes. There is something-- it's not the gambler's fallacy-- that's often confused with it, and that's called regression to the mean. This term was coined in 1885 by Francis Galton in a paper, of which I've shown you a page from it here.","69.04537200927734","5","DPRSearchEngine","OgO1gpXSUzU.en-j3PyPqV-e1s_8_mp4","OgO1gpXSUzU.en-j3PyPqV-e1s","6.0002","6"
"209","What was the reason Bellman named the approach 'dynamic programming'?"," 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
  
 
 
 
 
 
 
   
  
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
  
  
 
 
 
  
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
Intro to Mathematical Logic 
Goal: A mathematical study of mathematical reasoning itself. 
Formally defines the language of mathematics, mathematical truth, and provability. 
Gödel’s First Incompleteness Theorem: 
In any reasonable formal system, some true statements are not provable. 
Proof: We use two properties of formal proofs: 
1) Soundness: If ! has a proof "" then ! is true. 
2) Checkability: The language "", ! "" is a proof of statement !} is decidable. 
Checkability implies the set of provable statements {〈!〉| ! has a proof} is T-recognizable. 
SImilarly, if we can always prove ', ( ∈ *TM when it is true, then *TM is T-recognizable (false!). 
Therefore, some true statements of the form ', ( ∈ *TM are unprovable. 
Next, we use the Recursion Theorem to give a specific example of a true but unprovable statement. 
11 
","67.79129028320312","6","DPRSearchEngine","779043ea724131d008eae652d703938f_MIT18_404f20_lec11_11_pdf","779043ea724131d008eae652d703938f_MIT18_404f20_lec11","18.404J","11"
"209","What was the reason Bellman named the approach 'dynamic programming'?"," 
 
 
 
  
 
 
  
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Intro to Complexity Theory 
Computability theory (1930s - 1950s): 
Is A decidable? 
Complexity theory (1960s - present): 
Is A decidable with restricted resources? 
(time/memory/…) 
Example: Let ! = a#b# $ ≥0 . 
Q: How many steps are needed to decide !? 
Depends on the input. 
We give an upper bound for all inputs of length '. 
Called “worst-case complexity”. 
2 
","67.3050308227539","7","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_2_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"209","What was the reason Bellman named the approach 'dynamic programming'?"," 
 
 
 
 
 
 
 
 
 
 
  
Other applications 
1. Computer viruses. 
2. A true but unprovable mathematical statement due to Kurt Gödel: 
“This statement is unprovable.” 
10 
","66.27320098876953","8","DPRSearchEngine","779043ea724131d008eae652d703938f_MIT18_404f20_lec11_10_pdf","779043ea724131d008eae652d703938f_MIT18_404f20_lec11","18.404J","11"
"209","What was the reason Bellman named the approach 'dynamic programming'?"," 
 
 
 
 
 
 
 
 
 
  
 
Simulation Models
A description of computations that provide useful
information about the possible behaviors of the system
being modeled
Descriptive, not prescriptive
Only an approximation to reality
“All models are wrong, but some are useful.” – George Box
6.0002 LECTURE 4 
24
","66.2612533569336","9","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_24_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"209","What was the reason Bellman named the approach 'dynamic programming'?","[SQUEAKING] [RUSTLING] [CLICKING] MICHAEL SIPSER: So welcome, everybody. Welcome back. Let's get started with today's lecture. Where were we? On Tuesday, we covered, the main topic was the recursion theorem, which allows programs to self-reference. And we saw some applications of that, too. So we gave a new proof that ATM is undecidable. We looked at this language of minimal Turing machine descriptions. And we had a short digression into mathematical logic, where we looked at how one shows that there are true, but unprovable, statements in any reasonable formal system. So today, we're going to shift gears entirely. And we're moving into the second half of the course, where we are beginning a study of computational complexity theory. And we'll say a little bit about that during the course of the lecture, of course. But the main things that we are going to cover in terms of content that you will need is defining the complexity classes and the class P. And we'll prove a few theorems along the way. But that's the main objective of today's lecture. Computability theory, which was the subject of the first half of the course, and which is what the midterm exam is going to cover, was a subject that was an active area of mathematical study in the first part of the 20th century. It really got-- it really dates back into the late 19th century, in fact, when people were trying to figure out how to formalize mathematical reasoning. But it really got going in the 1930s with the work of Godel, and Church, and Turing, who really formalized for the first time what we mean by algorithm. And that allowed the study of algorithms to really get started. And it had its impact, as I mentioned, on the actual design, building, and thinking about real computers. The main question, if you kind of boil the subject down to a single question, is some language decidable or not. In complexity theory, which got started kind of when computability theory more or less wrapped up as a subject, largely because they answered many of the questions that they-- they answered pretty much all of the questions that they were asking. So there really aren't interesting unsolved questions left in that field. And you really need mathematical questions to keep a subject alive, unsolved questions. So complexity theory got its start in the 1960s. And it continues on as an active area of research to the present day. And I guess if you could boil it down, it would be is a language decidable with some restriction on the resources, such as the amount of time, or memory, or some other-- or some other kinds of resources that you might provide, randomness, and so on? All of those are within the area of computational complexity","66.24244689941406","10","DPRSearchEngine","asjAc90L8rE.en-j3PyPqV-e1s_1_mp4","asjAc90L8rE.en-j3PyPqV-e1s","18.404J","12"
"210","What is the definition of a negative-weight cycle in a graph?","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","74.10920715332031","1","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"210","What is the definition of a negative-weight cycle in a graph?"," 
 
 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) 
General Unweighted 
BFS 
|V | + |E|
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Non-negative Dijkstra 
Bellman-Ford 
|V | log |V | + |E|
General Any 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 14: Johnson’s Algorithm 
Lecture 14: Johnson’s Algorithm 
Previously 
|V | · |E| 
All-Pairs Shortest Paths (APSP) 
• Input: directed graph G = (V, E) with weights w : E → Z 
• Output: δ(u, v) for all u, v ∈ V , or abort if G contains negative-weight cycle 
• Useful when understanding whole network, e.g., transportation, circuit layout, supply chains... 
• Just doing a SSSP algorithm |V | times is actually pretty good, since output has size O(|V |2) 
– |V | · O(|V | + |E|) with BFS if weights positive and bounded by O(|V | + |E|) 
– |V | · O(|V | + |E|) with DAG Relaxation if acyclic 
– |V | · O(|V | log |V | + |E|) with Dijkstra if weights non-negative or graph undirected 
– |V | · O(|V | · |E|) with Bellman-Ford (general) 
• Today: Solve APSP in any weighted graph in |V | · O(|V | log |V | + |E|) time 
","73.35150909423828","2","DPRSearchEngine","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14_1_pdf","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14","6.006","14"
"210","What is the definition of a negative-weight cycle in a graph?"," 
 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) Lecture 
General Unweighted 
BFS 
|V | + |E| L09 
L11 
L12 (Today!) 
L13 
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Any 
Bellman-Ford 
Dijkstra 
|V | · |E|
General Non-negative 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 12: Bellman-Ford 
Lecture 12: Bellman-Ford 
Previously 
• Weighted graphs, shortest-path weight, negative-weight cycles 
• Finding shortest-path tree from shortest-path weights in O(|V | + |E|) time 
• DAG Relaxation: algorithm to solve SSSP on a weighted DAG in O(|V | + |E|) time 
• SSSP for graph with negative weights 
– Compute δ(s, v) for all v ∈ V (−∞ if v reachable via negative-weight cycle) 
– If a negative-weight cycle reachable from s, return one 
Warmups 
• Exercise 1: Given undirected graph G, return whether G contains a negative-weight cycle 
• Solution: Return Yes if there is an edge with negative weight in G in O(|E|) time 
:O 
• So for this lecture, we restrict our discussion to directed graphs 
• Exercise 2: Given SSSP algorithm A that runs in O(|V |(|V | + |E|) time, 
show how to use it to solve SSSP in O(|V ||E|) time 
• Solution: Run BFS or DFS to ﬁnd the vertices reachable from s in O(|E|) time 
– Mark each vertex v not reachable from s with δ(s, v) = ∞ in O(|V |) time 
– Make graph G0 = (V 0, E0) with only vertices reachable from s in O(|V | + |E|) time 
– Run A from s in G0 . 
– G0 is connected, so |V 0| = O(|E0|) = O(|E|) so A runs in O(|V ||E|) time 
• Today, we will ﬁnd a SSSP algorithm with this running time that works for general graphs! 
|V | log |V | + |E| 
","73.07862091064453","3","DPRSearchEngine","2430d7903a5529451d80c17f89a41fe8_MIT6_006S20_lec12_1_pdf","2430d7903a5529451d80c17f89a41fe8_MIT6_006S20_lec12","6.006","12"
"210","What is the definition of a negative-weight cycle in a graph?","2 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) Lecture 
General Unweighted 
BFS 
|V | + |E| L09 
L11 (Today!) 
L12 
L13 
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Any 
Bellman-Ford 
Dijkstra 
|V | · |E|
General Non-negative 
Lecture 11: Weighted Shortest Paths 
Weighted Paths 
• The weight w(π) of a path π in a weighted graph is the sum of weights of edges in the path 
• The (weighted) shortest path from s ∈ V to t ∈ V is path of minimum weight from s to t 
• δ(s, t) = inf{w(π) | path π from s to t} is the shortest-path weight from s to t 
• (Often use “distance” for shortest-path weight in weighted graphs, not number of edges) 
• As with unweighted graphs: 
– δ(s, t) = ∞ if no path from s to t 
– Subpaths of shortest paths are shortest paths (or else could splice in a shorter path) 
• Why inﬁmum not minimum? Possible that no ﬁnite-length minimum-weight path exists 
• When? Can occur if there is a negative-weight cycle in the graph, Ex: (b, f, g, c, b) in G1 
• A negative-weight cycle is a path π starting and ending at same vertex with w(π) < 0 
• δ(s, t) = −∞ if there is a path from s to t through a vertex on a negative-weight cycle 
• If this occurs, don’t want a shortest path, but may want the negative-weight cycle 
Weighted Shortest Paths Algorithms 
• Next four lectures: algorithms to ﬁnd shortest-path weights in weighted graphs 
• (No parent pointers: can reconstruct shortest paths tree in linear time after. Next page!) 
• Already know one algorithm: Breadth-First Search! Runs in O(|V | + |E|) time when, e.g.: 
– graph has positive weights, and all weights are the same 
– graph has positive weights, and sum of all weights at most O(|V | + |E|) 
• For general weighted graphs, we don’t know how to solve SSSP in O(|V | + |E|) time 
• But if your graph is a Directed Acyclic Graph you can! 
|V | log |V | + |E| 
","72.08900451660156","4","DPRSearchEngine","aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11_2_pdf","aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11","6.006","11"
"210","What is the definition of a negative-weight cycle in a graph?"," 
 
 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) Lecture 
General Unweighted 
BFS 
|V | + |E| L09 
L11 
L12 
L13 (Today!) 
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Any 
Bellman-Ford 
Dijkstra 
|V | · |E|
General Non-negative 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 13: Dijkstra’s Algorithm 
Lecture 13: Dijkstra’s Algorithm 
Review 
• Single-Source Shortest Paths on weighted graphs 
• Previously: O(|V | + |E|)-time algorithms for small positive weights or DAGs 
• Last time: Bellman-Ford, O(|V ||E|)-time algorithm for general graphs with negative weights 
• Today: faster for general graphs with non-negative edge weights, i.e., for e ∈ E, w(e) ≥ 0 
|V | log |V | + |E| 
Non-negative Edge Weights 
• Idea! Generalize BFS approach to weighted graphs: 
– Grow a sphere centered at source s 
– Repeatedly explore closer vertices before further ones 
– But how to explore closer vertices if you don’t know distances beforehand? 
:( 
• Observation 1: If weights non-negative, monotonic distance increase along shortest paths 
– i.e., if vertex u appears on a shortest path from s to v, then δ(s, u) ≤ δ(s, v) 
– Let Vx ⊂ V be the subset of vertices reachable within distance ≤ x from s 
– If v ∈ Vx, then any shortest path from s to v only contains vertices from Vx 
– Perhaps grow Vx one vertex at a time! (but growing for every x is slow if weights large) 
• Observation 2: Can solve SSSP fast if given order of vertices in increasing distance from s 
– Remove edges that go against this order (since cannot participate in shortest paths) 
– May still have cycles if zero-weight edges: repeatedly collapse into single vertices 
– Compute δ(s, v) for each v ∈ V using DAG relaxation in O(|V | + |E|) time 
","71.62017822265625","5","DPRSearchEngine","d819e7f4568aced8d5b59e03db6c7b67_MIT6_006S20_lec13_1_pdf","d819e7f4568aced8d5b59e03db6c7b67_MIT6_006S20_lec13","6.006","13"
"210","What is the definition of a negative-weight cycle in a graph?","It's not really complicated. Instead of having a single source, we are essentially wanting to, given an input-- this is our weighted graph, where we've got a graph V, E, and we've got a weight function from the edges to the integers. This is our general weighted graph. We want our output to be something like, the shortest path distance from u to v for every u and v in our vortex set. That's what we want to return. Now, there's one caveat here that, if there's a negative weight cycle in our graph-- in other words, if any of these delta u, v's is minus infinity,","71.57674407958984","6","DPRSearchEngine","EmSmaW-ud6A.en-j3PyPqV-e1s_2_mp4","EmSmaW-ud6A.en-j3PyPqV-e1s","6.006","14"
"210","What is the definition of a negative-weight cycle in a graph?","And that's cycle detection. So there's a bit of an exercise left to the reader here. So the problem that we're looking for now is that we're given a directed graph. There's a G in graph, in case you're wondering. But now, we don't know if it's a DAG or not. And so the question that we're trying to ask is, does there exist a cycle in our directed acyclic graph? So we're just given our graph, and we want to know, can we do this? Let's think through the logic of this a bit. So what do we know? We know that if our graph were a DAG, then I could call DGS, get the ordering out, and then I guess flip its ordering backwards. So I could compute the reverse finishing order. And it would give me a topological order of my graph. So if I were a DAG, I would get a topological order when I call DFS. So let's say that I ran DFS. I got whatever ordering I got. And now I found an edge the points in the wrong direction. I can just double check my list of edges, and I find one that does not respect the relationship that I see in the second bullet point here. Can my graph be a DAG? No. Because if my graph were a DAG, the algorithm would work. I just proved it to you. Right? So if my graph were a DAG, then I could do reverse finishing order. And what I would get back is a topological order. So if I found a certificate that my order wasn't topological, something went wrong, and the only thing that could go wrong is that my graph isn't a DAG. Yeah. Isn't a DAG. In fact, sort of an exercise left to the reader and/or to your section-- do we still have section? I think we do, as of now-- is that this is an if and only if, meaning that the only time that you even have a topological ordering in your graph is if your graph is a DAG. This is a really easy fact to sanity check, by the way. This is not like, a particularly challenging problem. But you should think through it because it's a good exercise to make sure you understand the definitions, which is to say that if you have a topological order, your graph is a DAG. If you don't have a topological order, your graph isn't a DAG. So in other words, we secretly gave you an algorithm for checking if a graph is a DAG at all. Right? What could I do? I could compute reverse finishing order. Check if it obeys the relationship on the second bullet point here for every edge. And if it does, then we're in good shape. My graph is a DAG. If it doesn't, something went wrong. And the only thing that could have gone wrong is not being a DAG. OK. So in other words, secretly we just solved-- well, I guess the way that I've written it here, we've solved the cycle detection problem here, which is to say that, well, I have a cycle if and only if I'm not a DAG, which I can check using this technique. Of course, the word ""detection"" here probably means that I actually want to find that cycle, and I haven't told you how to do that yet. All we know how to do so far is say, like, somewhere in this graph there's a cycle. And that's not so good. So we can do one additional piece of information in the two minutes we have remaining to sort of complete our story here, which is to modify our algorithm ever so slightly to not only say thumbs up, thumbs down, is there a cycle in this graph, but also to actually return the vertices as a cycle. And here's the property that we're going to do that, which is following, which is that if G contains a cycle, right, then full DFS will traverse an edge from a vertex v to some ancestor of v. I guess we haven't carefully defined the term ""ancestor"" here. Essentially, if you think of the sort of the running of the DFS algorithm, then an ancestor is like something that appears in the recursive call tree before I got to v. OK. So how could we prove that? Well, let's take a cycle. And we'll give it a name. In particular, we'll say that it's a cycle from v0 v1 to vk. And then it's a cycle, so it goes back to v0. OK. And I can order this cycle any way I want. Notice that if I permute the vertices in this list in a cyclical way, meaning that I take the last few of them and stick them at the beginning of the list, it's still a cycle. That's the nice thing about cycles. So in particular, without loss of generality, we're going to assume that v0 is the first vertex visited by DFS. What does that mean? That means, like, when I do my DFS algorithm making all these recursive calls, the very first vertex to be touched by this technique is v0. OK. Well, now what's going to end up happening? Well, think about the recursive call tree starting at v0. By the time that completes, anything that's reachable from v0 is also going to be complete. Do you see that? So for instance, v0 somewhere in its call tree might call v2. And notice that v2 was not already visited. So in fact, it will. For v1 I got to call v2 and so on. And in particular, we're going to get all the way to vertex k. Right? So in other words, we're going to visit a vertex vk. And notice what's going to happen. So remember our algorithm. In fact, we should probably just put it up on the screen would be easier than talking about it a bunch. Well, vk is now going to iterate over every one of the neighbors of vk. And in particular, it's going to see vertex v0. Right? So we're going to see the edge from vk to v0, which is an edge kind of by definition because we took this to be a cycle here. But notice that's exactly the thing we set out to prove, namely that full DFS traverses an edge from a vertex to one of its ancestors. Here's a vertex k. Here's the ancestor v0. Why do we know that it's an ancestor? Well, because v0 was called in our call tree before any of these other guys. Right? So we wanted an algorithm that not only did cycle detection, but also actually gave me the cycle. What could I do? Well, it's essentially a small modification of what we already have. Right. So-- whoops. Right. If I want to compute topological order or whatever, I can just do DFS. And that'll tell me like, yay or nay, does there exist a cycle. If I want to actually find that cycle, all I have to do is check that topological order property at the same time that it traversed the graph during DFS. And the second that I find an edge that loops back, I'm done. And so that's our basic algorithm here. And this is a technique for actually just finding the cycle in a graph using the DFS algorithm.","71.43579864501953","7","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_20_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"210","What is the definition of a negative-weight cycle in a graph?","There's not a bound on the number of edges for a shortest path, because I could just keep going around that cycle as many times as I want and get a shorter path. And so we assign those distances to be minus infinity. So that's what we're going to do today in Bellman-Ford. In particular, what we're going to do is compute our shortest path distances, the shortest path waits for every vertex in our graph, setting the ones that are not reachable to infinity, and the ones that are reachable through a negative weight cycle to minus infinity, and all other ones we're going to set to a finite weight. And another thing that we might want is if there's a negative weight cycle in the graph, let's return one. So those are the two kinds of things that we're trying to solve in today's lecture. But before we do that, let's warm up with two short exercises. The first one, exercise 1, given an undirected graph, given undirected graph G, return whether G contains a negative weight cycle. Anyone have an idea of how we can solve this in linear time, actually? In fact, we can do it in order E. No-- yes, yes. Reachable from S. I guess-- let's just say a negative weight cycle at all. Not in the context of single-source shortest paths.","70.92120361328125","8","DPRSearchEngine","f9cVS_URPc0.en-j3PyPqV-e1s_3_mp4","f9cVS_URPc0.en-j3PyPqV-e1s","6.006","12"
"210","What is the definition of a negative-weight cycle in a graph?","cycles, we'd be done. I claim to you a stronger statement, that if the shortest path using at most V edges from s to v Is less than-- strictly less than delta of V minus 1-- this is all in the subscript here. Basically this is the shortest-path distance of any simple path, and possibly ones that also contain cycles, but definitely it includes all the simple paths. If there's a shorter path to my vertex that goes through more than V minus 1 edges, that this path can't be simple, because it goes through a vertex more than once. Otherwise it would be included in this distance set. So if this is the case, and I found a shorter path to V that uses v edges-- yeah, that use V edges, that path can't be simple, which means that path or some path there contains a negative weight cycle. So if this is true, then I know that the real shortest-path distance from S to V must be minus infinity. I'm going to call such a vertex a witness. If we can find a vertex that has this property-- I mean, I haven't shown you how to compute these things yet, but if I were able to find a vertex V-- and these are capital V's if you're having trouble. This V is different than this V, this is cardinality. If we can find such a vertex V, that certifies that there is a negative weight cycle in our graph. So I'm going to call V is a witness. OK. So, if this property is true, it's a witness and it definitely has this. Is it possible, you think-- I'm going to claim to you that it's possible that a vertex could have minus infinite distance but not have this property halt. I could probably give you an example-- I don't have one off the top of my head right now, but that's possible. You could imagine, there might be no path going to a vertex on a negative weight cycle that goes through V exactly V edges. It might go through more edges, a shorter one. So this equation would be inequality and would not certify that this is true. But I claim to you, if a vertex has this property, if it's its shortest path distances minus infinite, then it must be reachable from a witness. So that's the claim. If delta S, V is minus infinity, then V is reachable from a witness. Reachable from a vertex that has this property-- that has this property. And if it's reachable from something that has minus infinity shortest pathway, then I can take that path go to my reachable vertex, and that's also minus infinite path. OK. So how do we prove this? Well, let's consider-- let's I'm going to state a somewhat stronger statement that we'll prove instead. It suffices to prove that every negative weight cycle contains a witness. If we are to prove that, then every vertex with this property, every vertex with this property is reachable from a negative weight cycle by definition. So, if we can prove that every-- prove every negative weight cycle contains witness. If we can prove that every negative weight cycle contains a witness, then every vertex reachable from one of those witnesses-- in particular, reachable from the negative weight cycle-- has shortest distance minus infinity, and that should prove the claim. This thing has to be reachable from a negative weight cycle. And so if we prove negative weight cycles contain witnesses, then all of these vertices are reachable from a witness. OK, great, great. Confusing myself there for a second. OK. So let's consider a negative weight cycle. NG. Here's a directed negative weight cycle. Recall. This will be my negative weight cycle C. All of the sum of the edges in this thing, the weights has negative weight. And I'm going to have a little bit notation-- if I have a vertex V here, I'm going to say that its predecessor in the cycle, I'm just going to call it V prime. That's just some notation. All right. So, if I have computed these shortest-path distances to every vertex in my graph, shortest-path distance going through at most V vertices and the shortest path distance going through at most V minus 1 vertices, then I know the following thing holds. Delta V going from S to V for any vertex in my cycle can't be bigger than delta V minus 1 from S to U plus the weight-- sorry, not U-- V prime, its predecessor, plus the weight going from the predecessor to my vertex. Why is that? Why is that? Because this is the weight of some vertex-- this is the weight-- the shortest-path distance to my predecessor using one fewer edge. And so this in particular is the weight of some path that uses V edges. So if this is the shortest such path distance, this has to upper bound it at least-- at most. Yeah? AUDIENCE: Is that the triangle inequality? JASON KU: That is a statement of the triangle inequality, thank you. All right. So, yes, this is just by triangle inequality. OK. Now what we can say is, let's take this equation summed over all vertices in my cycle. So I'm just going to add summation here of all vertices in my cycle of this whole thing. I'm going to do that out a little bit neater. Summation of delta, not d. Delta V S, V. I guess I don't need this open parentheses. Equals-- or less than or equal to sum of V and C of delta V minus 1 V prime. And here, I'm summing over V and C, and this is just my notation for the predecessor. And then I'm going to sum over the weights in my cycle V and C. These are the sum of the weights in my cycle. Well, what do I know about this cycle? This is just the weight of C. The weight of C-- that's awful handwriting. C, what do I know about the weight of the cycle? It's negative. So, this is less than 0, which means that if I remove this, this needs to be a strict equality. But if the sum of all of these is strictly less than the sum of all these, we can't have none of the vertices in my graph satisfying-- not satisfying this property. If all of them are not witnesses, then this thing is bigger than this thing-- at least as big as this thing for every vertex in my cycle, which is a contradiction. So, the claim holds, if we have a negative infinite shortest-path distance, then V is reachable from a witness. So it suffices for us to find all the witnesses, find all the vertices reachable from the witnesses, and then mark them as minus infinity. Does that make sense? OK. So, now we finally are able to get to our algorithm. Bellman-Ford. And what I'm going to show you today is a little different than what is normally presented as Bellman-Ford. The original Bellman-Ford algorithm does something a little different. And because it does something a little different, which we'll talk about at the end, it's a little hairier to analyze. I'm going to show you a modification that is a little easier to analyze and has this nice property that we're going to be able to use the algorithm to give us a negative weight cycle if it exists. So, we're going to say this is maybe a modified Bellman-Ford.","69.82378387451172","9","DPRSearchEngine","f9cVS_URPc0.en-j3PyPqV-e1s_6_mp4","f9cVS_URPc0.en-j3PyPqV-e1s","6.006","12"
"210","What is the definition of a negative-weight cycle in a graph?","Here's the transformation I'm going to show you. I'm going to show you first with an example. Here's an example of a directed graph that does contain a negative weight cycle. Can anyone find it for me? bcd. Has weigh minus 4 plus 3 minus 1. It has a minus 2 total weight. So that's a negative weight cycle. So in order to take shortest paths from a, I will want to say at the end of my algorithm, this better be 0, and all of these better be minus infinity. So that's what I want in my algorithm. So what's my algorithm going to be? I'm going to make V plus 1 copies of this graph, and I'm going to kind of stretch it out. OK. So here, I have V 0, 1, 2, 3, 4-- there are four vertices in my graph. So this is 1, 2, 3, 4, 5 copies of my graph. I have a version of vertex a for each one of those copies, a version of vertex b for each of those copies, c and d, et cetera. So I have this nice grid of vertices. And I'm not going to put any edges within a layer, within a level. Because then-- I mean, this graph has cycles. And I don't want cycles in my graph. What I'm going to do instead is for every edge in my original graph-- for example, the edge from a to b, I'm going to connect it to the b in the next level. So a0 is connected to b1 with an edge weight of minus 5, just like in the original. And I'm going to do that for every edge in my graph, and I'm going to repeat that down all the way. In addition, I'm going to add zero-weight edge from a0 to a1 or from every vertex all the way down the line. These are all zero-weight edges corresponding to-- I'm not going to traverse an edge, I'm just going to stay at this vertex. That's going to allow us to simulate this at most k edges condition. Now if you take a look at paths in this graph from a0, our starting vertex, clearly none of the other vertices in that level are reachable from a0, just as we want. Because the shortest-path distance to any of these vertices using at most 0 edges should be infinite. I can't get there in 0 edges. But then any path in this graph using at most k edges is going to correspond to a path from a0 to a vertex in that level, the corresponding level. So for example, if I had a-- if I was looking for paths 2b using at most three edges, any path-- a path from a0 to b3 in this graph would correspond to a path in this graph that uses at most three edges. so Let's find such a path. So going from a0, b1, stay at b1-- stay at b, sorry. Yeah, that's a path using fewer than three edges-- or at most three edges. But there's another path here. Where is it? Going from a, a, a to b-- OK, that's not such an interesting one. That's the same path. So I might have more than one path in here corresponding to a path in there, but my claim is that any path in here corresponds to a path in here. So what's a path of length? 3, that's non-trivial. Yeah, a to c to d to b. So a to c to d to b. Yeah, that's a path. And basically, because I constructed this so that the edges always moved from level to level, as I traverse these edges, I always change levels. Yeah? AUDIENCE: But my original graph doesn't have these self-loops with 0 weight. JASON KU: Yes. My original graph doesn't have an edge from a to a. That's true. I'm using these edges to correspond to-- I'm deciding not to take an edge. It's not that I'm like doing any work here, I'm just staying there for a state. And that's what's going to allow me to get this at most edges. All right. So, this is the graph construct. Hopefully you understand that we made these V layers. This is V. And a vertex-- we made V copies of every vertex and connected them using edges in this way. OK. So, first step of Bellman-Ford is construct this graph. So, Bellman-Ford, construct G prime as described above. It has how many vertices? V times V plus 1. V times V plus 1 vertices. And how many edges? Well, I have one edge for outgoing edge for each vertex corresponding to just staying in the same place. So that's V squared vertices-- I mean edges. And then I have one edge-- for every edge in my graph, I have-- sorry. I have a V minus 1-- sorry. Just V. I have V edges for every edge in my graph. So that means-- so this is the number of vertices. And V times V plus V times E, this is V V plus E. All right, cool. So that's how many edges I have. So constructed in that way, it's a DAG. If we only have edges going to increasing levels, then this thing can't have cycles, because otherwise that would mean there would be an edge pointing backwards.","69.5596923828125","10","DPRSearchEngine","f9cVS_URPc0.en-j3PyPqV-e1s_8_mp4","f9cVS_URPc0.en-j3PyPqV-e1s","6.006","12"
"211","What is the significance of amortized analysis in the context of dynamic arrays, particularly for the insert_last operation?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","79.26303100585938","1","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"211","What is the significance of amortized analysis in the context of dynamic arrays, particularly for the insert_last operation?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","78.18802642822266","2","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"211","What is the significance of amortized analysis in the context of dynamic arrays, particularly for the insert_last operation?","I've been talking about-- build, insert, and delete_max. So we have set AVL trees there-- n log n build, log n insert, log n delete. So along the way to our heap, I want to mention two other data structures. One is a dynamic but unsorted array. And the other is a dynamic sorted array. These are simpler data structures we've talked about many times before. And they're useful kind of motivations for getting started, because a heap is going to be built on top of arrays instead of-- well, it's sort of a fusion between arrays and trees. So if I have an unsorted array, this is very easy to insert into, right? I just append to the end. This is what we called insert last. So insert is fast, constant amortized. We might have to resize the array, but so that's the amortized part. But delete max is slow. In an unsorted array, I don't know where the maximum is. So I have to scan through the whole array. So I scan through the array, identify that the max is somewhere in the middle, and then, if I want to delete it-- I want to delete that maximum element, well, in a dynamic array, all I can really do is delete the last element efficiently. So I could, for example, swap it with the last element. So I take this element and put it here, and then delete the last element in that array, which is pop in Python or delete_last in our world. So overall, this is linear time, which is bad. But I wanted to highlight exactly how it's done for a reason we'll get to in a moment. A sorted array is sort of the reverse. It's very easy to find the max. Where is it? At the end. delete_max, the maximum element is always the last element in a increasing sorted array. I guess that's constant amortized, because then I have to delete it, which may incur resizing. Insert, though, is going to be linear, because maybe I can binary search to find where the added item belongs. Let's say I just added this item here. I could binary search to find it, but then I'm going to have to do a big shift. So I might as well just swap repeatedly until I find the position where the added item x belongs. And now I've restored sorted order. That takes linear time, which is bad. And what we want is somehow the best of these two worlds. Insert is fast for array. Delete is fast for a sorted array. We can't get constant time for both. But we can get log n time for both. We already know how with set AVL trees. But we're going to see a different way to do it today. And the main motivation for a different way to do this is sorting. So I want to define a priority queue sort. So given any data structure that implements a priority queue interface, in particular insert and delete_max, I can make a sorting algorithm. What do I do? Insert all the items, delete all the items. But because when I delete them they come out largest first, I get them in reverse sorted order. Then I could reverse in linear time and I've sorted my items. So we can insert (x) for x in A, or (build(A)), and then repeatedly delete_max. How much time does this algorithm take? I'm going to introduce some notation here. It takes however long it takes to build n items, call that T sub build (n) plus-- sorry-- plus n times the time to do a delete_max. Or we can write this as n times time to do an insert, plus time to do a delete_max. So I'm using these T functions to just abstract what are the running times provided by my data structure that implements this interface. Interface says what's correct is, and these T functions give me my performance bounds. So if I plug in each of these data structures, I get a sorting algorithm. I get AVL sort, I get array sort, I get assorted array sort. What do those look like? It turns out many of these are familiar. So set AVLs take log n per operation. So we get an n log n sorting algorithm out of them, which is insert all of the items into the AVL tree. I don't want to use AVL build because that uses sort, and not allowed to sort in order to implement sort. But we saw how to insert into an AVL tree and keep the thing balanced. So that takes log n each. And then we can find the max, delete it, rebalance, and so on. Total time will be n log n. This is an algorithm we call AVL sort. It's a bit complicated, because AVL trees are complicated. But it gives us optimal comparison bound and log n. Now, what about array sort? So suppose I use an unsorted array. I insert the item. So if I insert the items-- so I'm doing all the insertions here before all the deletions. So what's going to happen is I just insert the items in the original array order. In other words, I just take the array. And then what I do is repeatedly extract the maximum item by searching for it, moving it to the end of the array, and then repeating that process. That sound familiar? That's selection sort from lecture three. So this-- arrays give us selection sort. This is a new way to think about what we were doing way back then. With a sorted array, what are we doing? We insert all the items. That's actually where all the work happens, because we maintain the sorted array. So we start with an empty array. It's sorted. We add an item. OK, it's still sorted. We add a second item, and we swap if we need to in order to sort. In general, when we add an item, we swap it to the left until it's sorted again. That is insertion sort. Kind of cool, this is a unifying framework for three sorting algorithms that we saw before. We didn't actually talk about AVL sort last time, but it was in the notes. And so that is the right part of this table.","77.58869934082031","3","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_4_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"211","What is the significance of amortized analysis in the context of dynamic arrays, particularly for the insert_last operation?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 5: Linear Sorting 
Lecture 5: Linear Sorting 
Review 
• Comparison search lower bound: any decision tree with n nodes has height ≥dlg(n+1)e−1 
• Can do faster using random access indexing: an operation with linear branching factor! 
• Direct access array is fast, but may use a lot of space (Θ(u)) 
• Solve space problem by mapping (hashing) key space u down to m = Θ(n) 
• Hash tables give expected O(1) time operations, amortized if dynamic 
• Expectation input-independent: choose hash function randomly from universal hash family 
• Data structure overview! 
• Last time we achieved faster ﬁnd. Can we also achieve faster sort? 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
Direct Access Array 
u 
1 
1 
u 
u 
Hash Table 
n(e) 
1(e) 
1(a)(e) 
n 
n 
","75.75505065917969","4","DPRSearchEngine","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5_1_pdf","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5","6.006","5"
"211","What is the significance of amortized analysis in the context of dynamic arrays, particularly for the insert_last operation?","What's the worst case performance of a hash table? If I have to look up something in a hash table, and I happen to choose a bad hash table-- hash function, what's the worst case here? What? n, right? It's worse than a sorted array, because potentially, I hashed everything that I was storing to the same index in my hash table, and to be able to distinguish between them, I can't do anything more than a linear search. I could store another set's data structure as my chain and do better that way. That's actually how Java does it. They store a data structure we're going to be talking about next week as the chains so that they can get, worst case, log n. But in general, that hash table is only good if we're allowing-- OK, I want this to be expected good, but in the worst case, if I really need that operation to be worst case-- I really can't afford linear time ever for an operation of that kind-- then I don't want to use a hash table. And so on your p set 2, everything we ask you for is worst case, so probably, you don't want to be using hash tables. OK? Yes? AUDIENCE: What does the subscript e mean? JASON KU: What does the subscript e mean? That's great. In this chart, I put a subscript on this is an expected runtime, or an A meaning this is an amortized runtime. At the end, we talked about how, if we had too many things in our hash table, then, as long as we didn't do it too often-- this is a little hand wavey argument, but the same kinds of ideas as the dynamic array-- if, whenever we got a linear-- we are more than a linear factor away from where we are trying-- basically, the fill factor we were trying to be, then we could just completely rebuild the hash table with the new hash function randomly chosen from our hash table with a new size, and we could get amortized bounds. And so that's what Python-- how Python implements dictionaries, or sets, or even objects when it's trying to map keys to different things. So that's hash tables. That's great. The key thing here is, well, actually, if your range of keys is small, or if you as a programmer have the ability to choose the keys that you identify your objects with, you can actually choose that range to be small, to be linear, to be small with respect to your items. And you don't need a hash table. You can just use a direct access array, because if you know your key space is small, that's great. So a lot of C programmers probably would like to do something like that, because they don't have access to-- maybe C++ programmers would have access to their hash table. Any questions on this stuff before we move on? Yeah? AUDIENCE: So why is [INAUDIBLE]? JASON KU: Why is it expected? When I'm building, I could insert-- I'm inserting these things from x 1 by 1 into my hash table. Each of those insert operations-- I'm looking up to see whether that-- an item with that key already exists in my hash table. And so I have to look down the chain to see where it is. However, if I happen to know that all of my keys are unique in my input, all the items I'm trying to store are unique, then I don't have to do that check and I can get worst case linear time. Does that make sense? All right. It's a subtlety, but that's a great question. OK, so today, instead of talking about searching, we're talking about sorting. Last week, we saw a few ways to do sort. Some of them were quadratic-- insertion sort and selection sort-- and then we had one that was n log n. And this thing, n log n, seemed pretty good, but can I do better? Can I do better? Well, what we're going to show at the beginning of this class is, in this comparison model, no. n log n is optimal. And we're going to go through the exact same line of reasoning that we had last week. So in the comparison model, what did we use when we were trying to make this argument that any comparison model algorithm was going to take at least log n time? What we did was we said, OK, I can think of any model in the comparison model-- any algorithm in the comparison model as kind of this-- some comparisons happen. They branch in a binary sense, but you could have it generalized to any constant branching factor. But for our purposes, binary's fine. And what we said was that there were at least n outputs-- really n plus 1, but-- at least order n outputs. And we showed that-- or we argued to you that the height of this tree had to be at least log n-- log the number of leaves. It had to be at least log the number of leaves. That was the height of the decision tree. And if this decision tree represented a search algorithm, I had to walk down and perform these comparisons in order, reach a leaf where I would output something. If the minimum height of any binary tree on a linear number of leaves is log n, then any algorithm in the comparison model also has to take log n time, because it has to do that many comparisons to differentiate between all possible outputs. Does that make sense? All right. So in the sort problem, how many possible outputs are there?","75.27951049804688","5","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_4_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"211","What is the significance of amortized analysis in the context of dynamic arrays, particularly for the insert_last operation?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 2: Data Structures 
Lecture 2: Data Structures 
Data Structure Interfaces 
• A data structure is a way to store data, with algorithms that support operations on the data 
• Collection of supported operations is called an interface (also API or ADT) 
• Interface is a speciﬁcation: what operations are supported (the problem!) 
• Data structure is a representation: how operations are supported (the solution!) 
• In this class, two main interfaces: Sequence and Set 
Sequence Interface (L02, L07) 
• Maintain a sequence of items (order is extrinsic) 
• Ex: (x0, x1, x2, . . . , xn−1) (zero indexing) 
• (use n to denote the number of items stored in the data structure) 
• Supports sequence operations: 
Container 
build(X) 
len() 
given an iterable X, build sequence from items in X 
return the number of stored items 
Static 
iter seq() 
get at(i) 
set at(i, x) 
return the stored items one-by-one in sequence order 
return the ith item 
replace the ith item with x 
Dynamic 
insert at(i, x) 
delete at(i) 
insert first(x) 
delete first() 
insert last(x) 
delete last() 
add x as the ith item 
remove and return the ith item 
add x as the ﬁrst item 
remove and return the ﬁrst item 
add x as the last item 
remove and return the last item 
• Special case interfaces: 
stack 
insert last(x) and delete last() 
queue 
insert last(x) and delete first() 
","74.78404235839844","6","DPRSearchEngine","79a07dc1cb47d76dae2ffedc701e3d2b_MIT6_006S20_lec2_1_pdf","79a07dc1cb47d76dae2ffedc701e3d2b_MIT6_006S20_lec2","6.006","2"
"211","What is the significance of amortized analysis in the context of dynamic arrays, particularly for the insert_last operation?","They take linear time for some of the operations. So the sorting algorithms are not efficient. But they're ones we've seen before, so it's neat to see how they fit in here. They had the-- selection sort and insertion sort had the advantage that they were in place. You just needed a constant number of pointers or indices beyond the array itself. So they're very space efficient. So that was a plus for them. But they take n squared time, so you should never use them, except for n, at most, 100 or something. AVL tree sort is great and then it gets n log n time, probably more complicated than merge sort and you could stick to merge sort. But neither merge sort nor set AVL tree sort are in place. And so the goal of today is to get the best of all those worlds in sorting to get n log n comparisons, which is optimal in the comparison model, but get it to be in place. And that's what we're going to get with binary heaps. We're going to design a data structure that happens to build a little bit faster-- as I mentioned, linear time building. So it's not representing a sorted order in the same way that AVL trees are. But it will be kind of tree-based. It will also be array-based. We're going to get logarithmic time for insert and delete_max. It happens to be amortized, because we use arrays. But the key thing is that it's an in-place data structure. It only consists of an array of the items. And so, when we plug it into our sorting algorithm-- priority queue sort or generic sorting algorithm-- not only do we get n log n performance, but we also get an in-place sorting algorithm. This will be our first and only-- to this class-- n log n in-place sorting algorithm. Cool. That's the goal.","74.1657485961914","7","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_5_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"211","What is the significance of amortized analysis in the context of dynamic arrays, particularly for the insert_last operation?","And this is a subset of the set interface. And subsets are interesting because, potentially, we can solve them better, faster, simpler, something. And so you'll recognize-- you should recognize all of these operations, except we didn't normally highlight the max operation. So here, we're interested in storing a bunch of items. They have keys which we think of as priorities. And we want to be able to identify the maximum priority item in our set and remove it. And so there's lots of motivations for this. Maybe you have a router, packets going into the router. They have different priorities assigned to them. You want to route the highest priority first. Or you have processes on your computer trying to run on your single threaded-- single core, and you've got to choose which one to run next. And you usually run higher priority processes first. Or you're trying to simulate a system where events happen at different times, and you want to process the next event ordered by time. All of these are examples of the priority queue interface. We'll even see applications within this class when we get to graph algorithms. But the main two things we want to be able to support are inserting an item, which includes a key, and leading the maximum item, and also returning it at the same time. We'll also talk some about being able to build the structure faster than just inserting it. But of course, we could implement build by starting empty and repeatedly inserting. And also the complexity of just finding the max without deleting it, this you could simulate with these two operations by deleting the max and then reinserting it, which works. But often, we can do faster. But the two key, main operations are insert and delete max. And we're going to see a few data structures to do this. Any suggestions among the data structures we've seen in this class? What should we use to solve priority queue interface? Many possible answers.","73.88734436035156","8","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_2_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"211","What is the significance of amortized analysis in the context of dynamic arrays, particularly for the insert_last operation?","Header for Decision Tree Implementa#on 
6.0002 LECTURE 2 
9 
def maxVal(toConsider, avail): 
    """"""Assumes toConsider a list of items,  
               avail a weight 
       Returns a tuple of the total value of a  
           solution to 0/1 knapsack problem and  
           the items of that solution""""” 
toConsider. Those items that nodes higher up in the tree 
(corresponding to earlier calls in the recursive call stack) 
have not yet considered 
 
avail. The amount of space still available  
","73.67507934570312","9","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_9_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"211","What is the significance of amortized analysis in the context of dynamic arrays, particularly for the insert_last operation?","2 
Lecture 8: Binary Heaps 
Priority Queue: Set AVL Tree 
• Set AVL trees support insert(x), find min(), find max(), delete min(), and 
delete max() in O(log n) time per operation 
• So priority queue sort runs in O(n log n) time 
– This is (essentially) AVL sort from Lecture 7 
• Can speed up find min() and find max() to O(1) time via subtree augmentation 
• But this data structure is complicated and resulting sort is not in-place 
• Is there a simpler data structure for just priority queue, and in-place O(n lg n) sort? 
YES, binary heap and heap sort 
• Essentially implement a Set data structure on top of a Sequence data structure (array), using 
what we learned about binary trees 
Priority Queue: Array 
• Store elements in an unordered dynamic array 
• insert(x): append x to end in amortized O(1) time 
• delete max(): ﬁnd max in O(n), swap max to the end and remove 
• insert is quick, but delete max is slow 
• Priority queue sort is selection sort! (plus some copying) 
Priority Queue: Sorted Array 
• Store elements in a sorted dynamic array 
• insert(x): append x to end, swap down to sorted position in O(n) time 
• delete max(): delete from end in O(1) amortized 
• delete max is quick, but insert is slow 
• Priority queue sort is insertion sort! (plus some copying) 
• Can we ﬁnd a compromise between these two array priority queue extremes? 
","73.57635498046875","10","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_2_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"212","What process involves exploring the entire graph using BFS or DFS for connected components?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","73.63518524169922","1","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"212","What process involves exploring the entire graph using BFS or DFS for connected components?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 10: Depth-First Search 
Lecture 10: Depth-First Search 
Previously 
• Graph deﬁnitions (directed/undirected, simple, neighbors, degree) 
• Graph representations (Set mapping vertices to adjacency lists) 
• Paths and simple paths, path length, distance, shortest path 
• Graph Path Problems 
– Single Pair Reachability(G,s,t) 
– Single Source Reachability(G,s) 
– Single Pair Shortest Path(G,s,t) 
– Single Source Shortest Paths(G,s) (SSSP) 
• Breadth-First Search (BFS) 
– algorithm that solves Single Source Shortest Paths 
– with appropriate data structures, runs in O(|V | + |E|) time (linear in input size) 
Examples 
G1 
a 
d 
b 
e 
c 
f 
G2 
a 
d 
b 
e 
c 
f 
","73.441162109375","2","DPRSearchEngine","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10_1_pdf","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10","6.006","10"
"212","What process involves exploring the entire graph using BFS or DFS for connected components?","And that's cycle detection. So there's a bit of an exercise left to the reader here. So the problem that we're looking for now is that we're given a directed graph. There's a G in graph, in case you're wondering. But now, we don't know if it's a DAG or not. And so the question that we're trying to ask is, does there exist a cycle in our directed acyclic graph? So we're just given our graph, and we want to know, can we do this? Let's think through the logic of this a bit. So what do we know? We know that if our graph were a DAG, then I could call DGS, get the ordering out, and then I guess flip its ordering backwards. So I could compute the reverse finishing order. And it would give me a topological order of my graph. So if I were a DAG, I would get a topological order when I call DFS. So let's say that I ran DFS. I got whatever ordering I got. And now I found an edge the points in the wrong direction. I can just double check my list of edges, and I find one that does not respect the relationship that I see in the second bullet point here. Can my graph be a DAG? No. Because if my graph were a DAG, the algorithm would work. I just proved it to you. Right? So if my graph were a DAG, then I could do reverse finishing order. And what I would get back is a topological order. So if I found a certificate that my order wasn't topological, something went wrong, and the only thing that could go wrong is that my graph isn't a DAG. Yeah. Isn't a DAG. In fact, sort of an exercise left to the reader and/or to your section-- do we still have section? I think we do, as of now-- is that this is an if and only if, meaning that the only time that you even have a topological ordering in your graph is if your graph is a DAG. This is a really easy fact to sanity check, by the way. This is not like, a particularly challenging problem. But you should think through it because it's a good exercise to make sure you understand the definitions, which is to say that if you have a topological order, your graph is a DAG. If you don't have a topological order, your graph isn't a DAG. So in other words, we secretly gave you an algorithm for checking if a graph is a DAG at all. Right? What could I do? I could compute reverse finishing order. Check if it obeys the relationship on the second bullet point here for every edge. And if it does, then we're in good shape. My graph is a DAG. If it doesn't, something went wrong. And the only thing that could have gone wrong is not being a DAG. OK. So in other words, secretly we just solved-- well, I guess the way that I've written it here, we've solved the cycle detection problem here, which is to say that, well, I have a cycle if and only if I'm not a DAG, which I can check using this technique. Of course, the word ""detection"" here probably means that I actually want to find that cycle, and I haven't told you how to do that yet. All we know how to do so far is say, like, somewhere in this graph there's a cycle. And that's not so good. So we can do one additional piece of information in the two minutes we have remaining to sort of complete our story here, which is to modify our algorithm ever so slightly to not only say thumbs up, thumbs down, is there a cycle in this graph, but also to actually return the vertices as a cycle. And here's the property that we're going to do that, which is following, which is that if G contains a cycle, right, then full DFS will traverse an edge from a vertex v to some ancestor of v. I guess we haven't carefully defined the term ""ancestor"" here. Essentially, if you think of the sort of the running of the DFS algorithm, then an ancestor is like something that appears in the recursive call tree before I got to v. OK. So how could we prove that? Well, let's take a cycle. And we'll give it a name. In particular, we'll say that it's a cycle from v0 v1 to vk. And then it's a cycle, so it goes back to v0. OK. And I can order this cycle any way I want. Notice that if I permute the vertices in this list in a cyclical way, meaning that I take the last few of them and stick them at the beginning of the list, it's still a cycle. That's the nice thing about cycles. So in particular, without loss of generality, we're going to assume that v0 is the first vertex visited by DFS. What does that mean? That means, like, when I do my DFS algorithm making all these recursive calls, the very first vertex to be touched by this technique is v0. OK. Well, now what's going to end up happening? Well, think about the recursive call tree starting at v0. By the time that completes, anything that's reachable from v0 is also going to be complete. Do you see that? So for instance, v0 somewhere in its call tree might call v2. And notice that v2 was not already visited. So in fact, it will. For v1 I got to call v2 and so on. And in particular, we're going to get all the way to vertex k. Right? So in other words, we're going to visit a vertex vk. And notice what's going to happen. So remember our algorithm. In fact, we should probably just put it up on the screen would be easier than talking about it a bunch. Well, vk is now going to iterate over every one of the neighbors of vk. And in particular, it's going to see vertex v0. Right? So we're going to see the edge from vk to v0, which is an edge kind of by definition because we took this to be a cycle here. But notice that's exactly the thing we set out to prove, namely that full DFS traverses an edge from a vertex to one of its ancestors. Here's a vertex k. Here's the ancestor v0. Why do we know that it's an ancestor? Well, because v0 was called in our call tree before any of these other guys. Right? So we wanted an algorithm that not only did cycle detection, but also actually gave me the cycle. What could I do? Well, it's essentially a small modification of what we already have. Right. So-- whoops. Right. If I want to compute topological order or whatever, I can just do DFS. And that'll tell me like, yay or nay, does there exist a cycle. If I want to actually find that cycle, all I have to do is check that topological order property at the same time that it traversed the graph during DFS. And the second that I find an edge that loops back, I'm done. And so that's our basic algorithm here. And this is a technique for actually just finding the cycle in a graph using the DFS algorithm.","72.34561920166016","3","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_20_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"212","What process involves exploring the entire graph using BFS or DFS for connected components?"," &&%$3$%'9
class Digraph(object): 
 """"""edges is a dict mapping each node to a list of 
    its children""""” 
    def __init__(self): 
self.edges = {} 
    def addNode(self, node): 
if node in self.edges: 
 raise ValueError('Duplicate node') 
else: 
self.edges[node] = [] 
    def addEdge(self, edge): 
src = edge.getSource() 
dest = edge.getDestination() 
if not (src in self.edges and dest in self.edges): 
raise ValueError('Node not in graph') 
self.edges[src].append(dest) 
Q>KKKMN
LS
mapping each node 
list 
","71.50334167480469","4","DPRSearchEngine","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_18_pdf","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3","6.0002","3"
"212","What process involves exploring the entire graph using BFS or DFS for connected components?","[SQUEAKING][RUSTLING][CLICKING] JASON KU: Welcome, everybody, to our lecture 14 of 6.006. This is our last lecture on graph algorithms, in particular, the last lecture we'll have on weighted shortest paths. But we're going to talk about a slightly different problem today, different than single source shortest paths. We're going to be talking about all-pairs shortest paths. But first, let's review our single source shortest paths algorithms. We had BFS, DAG relaxation, Dijkstra, which we saw last time, which gets pretty close to linear. V log V plus E is pretty close to linear. It's much closer to linear than the general algorithm we have for solving single source shortest paths, namely, Bellman-Ford, which is a little bit more like quadratic. This is like the difference between-- for sparse graphs, this is like the difference between sorting, using insertion sort and n squared, and merge sort in N log N, for example. We're going to get actually quite a big bonus for large input sizes by using Dijkstra when we can. Today, we're going to be focusing","70.97822570800781","5","DPRSearchEngine","EmSmaW-ud6A.en-j3PyPqV-e1s_1_mp4","EmSmaW-ud6A.en-j3PyPqV-e1s","6.006","14"
"212","What process involves exploring the entire graph using BFS or DFS for connected components?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 11: Weighted Shortest Paths 
Lecture 11: Weighted Shortest Paths 
Review 
• Single-Source Shortest Paths with BFS in O(|V | + |E|) time (return distance per vertex) 
• Single-Source Reachability with BFS or DFS in O(|E|) time (return only reachable vertices) 
• Connected components with Full-BFS or Full-DFS in O(|V | + |E|) time 
• Topological Sort of a DAG with Full-DFS in O(|V | + |E|) time 
• Previously: distance = number of edges in path Today: generalize meaning of distance 
Weighted Graphs 
• A weighted graph is a graph G = (V, E) together with a weight function w : E → Z 
• i.e., assigns each edge e = (u, v) ∈ E an integer weight: w(e) = w(u, v) 
• Many applications for edge weights in a graph: 
– distances in road network 
– latency in network connections 
– strength of a relationship in a social network 
• Two common ways to represent weights computationally: 
– Inside graph representation: store edge weight with each vertex in adjacency lists 
– Store separate Set data structure mapping each edge to its weight 
• We assume a representation that allows querying the weight of an edge in O(1) time 
Examples 
G1 
G2 
a 
e 
b 
f 
c 
g 
d 
h 
6 
8 
−2 
5 
9 
−5 
7 
3 
2 
−1 
−4 
1 
4 
a 
e 
b 
f 
c 
g 
d 
h 
6 
8 
−2 
5 
9 
−5 
7 
3 
2 
−1 
−4 
1 
4 
","69.65555572509766","6","DPRSearchEngine","aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11_1_pdf","aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11","6.006","11"
"212","What process involves exploring the entire graph using BFS or DFS for connected components?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","69.49241638183594","7","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"212","What process involves exploring the entire graph using BFS or DFS for connected components?","And dynamic programming is going to build on this template by adding one new idea called memoization, which is just the idea of reusing work that you've done before. And that's going to let us solve tons of problems. And let's see. I don't-- let's get into it. So we'll start out today with SRTBOT. So here is SRTBOT down the column here. This is a recursive algorithm design paradigm. And in general, what we're going to do is take the problem that we actually want to solve and split it up into lots of possible sub problems. And so the first part is to define what the heck are the subproblems. In general, we'll want some polynomial number of them. But it's pretty open-ended what these look like. And the hardest part, usually, in defining a recursive algorithm is figuring out what the sub problems should be. Usually they're related to the problem you want to solve. Often the problem you want to solve-- this is actually near the last step-- the original problem you're trying to solve is often one of these sub problems. And then you use the smaller sub problems in order to build up the final, original problem. But sometimes at the end, you need to take a bunch of subproblems and combine them into your original problem. You can think-- one analogy you can think of here is divide and conquer algorithms, which also had this kind of style. But more generally, we're going to relate different sub problem solutions with some recursive structure-- some recurrence relation. This is just a recursive algorithm that defines how to solve one problem in terms of smaller sub-problems for some notion of smaller. And this is given by the topological order. So if we think of the subproblems as a graph and we draw an edge between-- so the vertices of the graph are sub problems. The edges are the dependencies between those subproblems. Then what we'd like is the topological ordering, the topological sort problem we talked about in the context of DFS or DAG shortest paths. What we would like is that the subproblems and the calls-- the recursive calls between them in this recursive relation-- forms a DAG. We want it to be acyclic, otherwise you have an infinite loop in your recursive calls. If you have a cycle, you'll never terminate. And so to make sure that these dependencies between subproblems given by this recurrence relation is acyclic, one way to do that is to specify a topological order. Or you could prove it some other way. But often it's just a for loop to say, just do it in this order. Then of course any recursive structure needs base cases. So that's a useful step not to forget. We want to solve the original problem using these sub problems. And then we analyze a running time at the end. So six easy steps. Actually, the hardest ones are these two, which are interrelated. And what we're going to see over the next four lectures-- this is the first of four lectures on dynamic programming-- is lots of examples of applying this paradigm over and over together with the memoization idea, which we'll get to soon.","69.24616241455078","8","DPRSearchEngine","r4-cftqTcdI.en-j3PyPqV-e1s_2_mp4","r4-cftqTcdI.en-j3PyPqV-e1s","6.006","15"
"212","What process involves exploring the entire graph using BFS or DFS for connected components?","single source shortest paths in linear time. Last time we discussed another linear time algorithm, DAG relaxation. And today we're going to be talking about Bellman-Ford, which isn't limited to asymptotic graphs. In particular, there could be negative weight cycles in our graph. If it has cycles, if it has negative weights, the worry is that we could have negative weight cycles, in which case there-- if a negative weight cycle is reachable from our source, then the vertices in that cycle and anything reachable from that cycle will potentially","69.23736572265625","9","DPRSearchEngine","f9cVS_URPc0.en-j3PyPqV-e1s_2_mp4","f9cVS_URPc0.en-j3PyPqV-e1s","6.006","12"
"212","What process involves exploring the entire graph using BFS or DFS for connected components?","There are all the paths of length two. And the one thing I'm going to have to do is I'm going to have to keep track of the remaining options here in case I have to come down to them. Because if I didn't find it at the first level, then I come down here and look at things of length two. OK? So let's build that code. Breadth first search, or BFS, again, a graph, a start, and an end node, something that would just print things out as I go along. My initial path is just the start point. But now I've got to keep track of what are the paths that I have yet to explore? And so for that, I'm going to create something called a queue. And a queue is going to be a list of paths. Remember, a path is a list of nodes. A queue is going to be a list of paths. So the initial queue is just where I've started. And then, as long as I've got something still to explore and I haven't found a solution, I'm going to pop off the queue the oldest element, the thing at the beginning. That's my temporary path. I'll print out some information about it. And then I'll grab the last element of that path. That's the last point in that path. And I'll now explore. Is it the thing I'm looking for? In which case I'm done. I'll return the path. Otherwise, for each node that you can reach from that point, create a new path by adding that on the end of this path and add it into the queue at the end of the queue. So I'm going to keep looping around here until I either find a solution here, which I'll return. And if I get through all of it, I'm going to return none. And right there, there is that nice thing where once I find a solution, I know it's the shortest thing, I can stop. OK, let's look at an example of this. So I'm going to go back over to Python, where I've got a version of this. I'm going to comment that out. And down here in breadth first search, I've actually added a little piece of code that I don't have in the handout that's going to print out the queue as well so we can see what happens when we call this. So let's take a look at it. My initial call, there's one thing in the queue. It's just Boston. I started in Boston. So the current path is to start in Boston. I take that element off the queue, and I say what are the things I can reach from Boston? Oh, nice, I put two things in. I can get from Boston to Providence. I can get from Boston to New York. The top thing is gone off the queue. I popped it. I've replaced it with two things. Or I take this, and say, OK, from Boston to Providence, where can I get from Providence? Oh, I can get to New York. So I put that in the queue. This has gone off. That one is still there. And I do that because I haven't yet reached the thing I'm looking for, which was, I think, Phoenix I was trying to get to. And you could see at each stage, I'm taking the top thing off the queue, and asking for all the things that I can get to, and adding them to it. And notice, in some cases, it may be more than one. For example, which one do I want here? Right here, if I take Boston, New York to Chicago, from Chicago I can get to Denver. So there's one new path. I can also get to Phoenix. There's a second new path. Also notice how they are only growing slowly as I build them out. And in fact, if we go back, we can see that nicely by looking at what happens if we were to actually trace this along. So Boston to Phoenix, I start at Boston. Then I look at that and then that. Those are all the paths of length one. Having exhausted those, oh nice, I'm looking at paths of length two, and then paths of length three, and then paths the length four, until I found the one that I wanted. And here's one other way of looking at it. Breadth first says, I'll look at each path of length one. And then, oh yes, I avoid the loop. I look at each path of length two, then paths of length three, until I actually find the solution. Subtle difference, different performance. Depth first, I'm always following the next available edge until I get stuck and I backtrack. Breadth first, I'm always exploring the next equal length option. And I just have to keep track in that queue of the things I have left to do as I walk my way through. What about weighted shortest path? Well, as the mathematicians say, we leave this is an easy exercise for the reader. It's a little unfair. The idea would be, imagine on my edges, it's not just a step, but I have a weight. Flying to L.A. Is a little longer than flying from Boston to New York. What I'd like to do is do the same kind of optimization, but now just minimizing the sum of the weights on the edges, not the number of edges. As you might guess, depth first search is easily modified to do this. The cost now would simply be what's the sum of those weights? And again, I would have to search all possible options till I find a solution. Unfortunately, breadth first search can't easily be modified because the short weighted path may have many more than the minimum number of loops. And I'd have to think about how to adjust it to make that happen. But to pull it together, here's a new model-- graphs. Great way of representing networks, collections of entities with relationships between them. There are lots of nice graph optimization problems. And we've just shown you two examples of that. But we'll come back to more examples as we go along. And with that, we'll see you next time.","69.04756927490234","10","DPRSearchEngine","V_TulH374hw.en-qlPKC2UN_YU_9_mp4","V_TulH374hw.en-qlPKC2UN_YU","6.0002","3"
"213","What is the optimal strategy dynamic programming seeks to solve in the alternating coin game?","Alternating coin game-- this is a two player game. We're going to find the optimal strategy in this game. In general, you have a sequence of coins, and we have two players. They take turns. So given coins of value v0 to v n minus 1-- so it's a sequence. They're given in order-- in some order-- for example, 5, 10, 100, 25-- not necessarily sorted order. And the rules of the game are we're going to take turns. I'm going to take turns with you. I'm going to use I and you to refer to the two players. And so in each turn, either one-- whoever's turn it is, I get to-- we get to choose either the first coin or the last coin among the coins that remain. So at the beginning, I can choose 5 or 25. And I might think, oh, 25's really good. That's better than 5. I should choose that. But then, of course, you're going next, and you're going to choose 100, and you'll win the game. You'll get more of the total value of the coins. So in this is example, a better strategy is to take the 5, because then the 100 is still in the middle. And so once I take 5, you get to choose 10 or 25. At this point, you'd probably prefer 25, because that's better than 10. But whichever you choose, I can take the 100. And so I get 105 points, and you're going to get 35 points. OK-- good example for me. So that's easy for a simple example, but in general, there are exponentially many strategies here. At each step, either of us could go left or right-- choose is the leftmost or the rightmost. And we're going to give a dynamic programming algorithm that just solves this fast. I didn't mention-- so this algorithm is quadratic time, but it can be made n log n time. It's a fun exercise. Using a lot of the data structure augmentation stuff we've done, you can make this n log n. This algorithm, I think, is going to be n squared time. So I won't right the problem exactly, but I think you know the rules. Choose leftmost or rightmost coin, alternating moves. So I'd like to define some subproblems. And this is a problem that's very naturally a substring problem. If I just looked at suffixes, that would deal great with-- if I'm deleting coins from the left, but as soon as I delete-- and if I delete coins only from the right, that would give me prefixes. But I'll tell you now, there's no dynamic programming where the answer is suffixes and prefixes. You can do suffixes or prefixes, but if you need both, you almost certainly need substring, because as soon as I delete the first coin, and then maybe you take the second coin-- that's exactly the optimal strategy here-- now you have an arbitrary substring in the middle. But substrings are enough, because we're only leading from the ends. We'll look at substrings. So more precisely-- this is just the intuition-- we're going to define some generic x of i, j is going to be what is the maximum total value I can get from this game, if we play it on coins of value Vi to Vj. So that's a substring. So this is one way to write down the subproblems, and it's also a good way. You could write down a relation on this definition of subproblems. But I'm low on time. There's two ways to solve this problem. This is a reasonable way, exploiting that the game is zero-sum. But I'd like to change just a little bit to give you, I think, what's a cleaner way to solve the problem, which is to add a third coordinate to my subproblems. So now it's parameterized by three things. P here is-- only has two choices. It's me or you. And this gets at a point that's maybe not totally clear from this definition-- max total value that I can get from these-- this substring of coins. But this is not obviously what I need. So obviously, at the beginning, I want the whole string and I want to know what my maximum value is-- fine. And I go first in this game. I didn't specify, but I do. [INAUDIBLE] But as soon as I do a move-- as soon as I take the first coin, for example-- it's now your turn. And so I don't really want to know the maximum total value that I would get if I go first. I'd like to say, if player P goes first. I'd really like to know what happens in the case where you go first. So for some of the substrings, I want to know what happens when you go first, and for some of them, I want to know what happens when I go first, because as soon as I make a move, it's your turn. And so we're going to flip back and forth between P being me and P being you-- P-U. So you don't have to parameterize. There's a way to write the recurrence otherwise, but this is, I think, a lot more intuitive, because now we can do a very simple relation, which is as follows. So I'm going to split into two cases. One is x of i, j, me and the other is x of i, j, you. So x of i, j, me-- so I have some substring from i to j. What could I do? I could take the first coin or I could take the second coin. Which should I do? That's my question. What is my first move? Should I take the first coin or the second coin? So this is my question. What is the first move? There are exactly two possible answers to that question, so we can afford to just brute force them and take the max. If we're moving, we want the maximum number of points we can get-- maximum total value of the two choices. So if I take from the i side, the left side, that would be x sub i plus 1, j. Sorry. And now, crucially, we flip players, because then it's your turn. And if I take from the j side, that will make it j minus 1. This is what I accidentally wrote at the beginning of lecture. Also flip players. So either I shrink on the i side or I shrink on the j side. Oh, I should add on here the value of the coin that I get, and add on the value the coin that I took. This is an expression inside the max. That sum. And if I take the max those two options, that will give-- that is my local brute force the best choice of how many-- what are the total value of coins I will get out of the remainder, given that you start, plus this coin that I took right now in the first step, and for the two possible choices of what that coin is? OK, what remains is, how do we define this x of i, j, you. This is a little bit funnier, but it's conceptually similar. I'm going to write basically the same thing here, but with me, instead of you-- because again, it flips. This is, if you go first, then the very next move will be me. So this is just the symmetric formula here. I can even put the braces in-- so far, the same. Now, I don't put in the plus Vi and I don't put in the plus Vj here, because if you're moving, I don't get those points. So there's an asymmetry in this definition. You could define it in different ways, but this is the maximum total value that I would get if you start. So in your first move, you get some points, but I don't get any points out of that. So there's no plus Vi. There's no plus Vj. It's just you either choose the i-th coin or you choose the j-th coin, and then the coins that remain for me shrink accordingly. Now, you're kind of a pain in the ass. You're an adversary you're trying to minimize my score potentially because you're trying to maximize your score. This is a 0 sum game. So anything that you get I don't get. If you want to maximize your score, you're trying to minimize my score. These are symmetric things. And so if you think for a while, the right thing to put here is min. From our perspective, we're imagining what is the worst case that could happen, no matter what you do. And we don't have control over what you do, and so we'd really like to see, what score would I get if you chose the i-th coin? What score do you get if you chose the j-th coin? And then what we get is going to be the worst of those two possibilities. So when we get to choose, we're maximizing. And this is a general two player phenomenon that, when you choose, we end up minimizing, because that's the saddest thing that could happen to us. OK, this is one way to write a recurrence relation. We have, of course, all of SRTBOT to do, so the topological order here is in increasing length of substance. So the T is increasing j minus i. Start with empty strings. So base case is that x of i, i, me is Vi. So here I'm inclusive in both ends in this definition. So there is a coin I can take at the end. But if you move last and there's one coin left, then I don't get it, so it's 0. Then we have the original problem that is x i, j, me-- sorry-- x 0, n. That's the entire coin set, starting with me. That was the problem I wanted to do. And then the running time we get is the number of subproblems-- that's theta n squared, because we're doing substrings-- times the amount of non-recursive work I do here. That's just a max of two numbers. Very simple. Constant time. So this is quadratic. Let me show you an example. This is hard to draw, but what I've described here is called solution 2 in the notes. So here's our sequence-- 5, 10, 100, 25-- in both directions. And what we're interested in is all substrings. So over here I've written the choice for i. So we start at one of these, and if you start here, you can't end earlier than there. So that's why we're in the upper diagonal of this matrix. And then there's two versions of each problem-- the white version and the blue version just down and to the right of it. If you can't see what blue is, this is the version where you start. This is the version where I start. And I've labeled here all of the different numbers. Please admire, because this took a long time to draw. But in particular, we have 105 here, meaning that the maximum points I can get 105. And that's the case because, if we look over there, it is the max of these two incoming values plus the Vi that I get. So either I go to the left and I take that item or I go down and I take that item. So the option here is I went to the left and took-- well, that's going to be tricky to do in time. The claim is that the best answer here is to go here with the 100 and take the 5, because going down corresponds to removing the last item. If I went to the left, that corresponds to-- sorry-- the first item. If I went to the left, that corresponds to removing the last item, so my options are 10 plus 25, which is 35, versus 100 plus 5. 105 wins, so that's why there's a red edge here showing that was my better choice. And in general, if you follow these parent pointers back, it gives you the optimal strategy in what you should do. First, you should take the 5 is what this is saying, because we just clipped off the 5. We used to start here, and now we start here in this subinterval. Then our opponents, to be annoying, will take the 25-- doesn't actually matter, I think. Then we will take the 100, and then they take the 10, and it's game over. OK, all the numbers here are how many points we get-- doesn't say how many points the opponent gets. Of course, you could add that as well. It's just the total sum minus what we get. Now, let me come back to high level here.","72.87538146972656","1","DPRSearchEngine","KLBCUx1is2c.en-j3PyPqV-e1s_10_mp4","KLBCUx1is2c.en-j3PyPqV-e1s","6.006","16"
"213","What is the optimal strategy dynamic programming seeks to solve in the alternating coin game?"," 
 
 
  
 
 
 
    
 
 
    
 
        
 
        
 
 
    
 
        
 
 
 
 
        
 
 
 
              
 
    
 
 
 
  
 
 
 
 
    
 
 
        
 
 
 
Monte Carlo Simulation  
def playRoulette(game, numSpins, pocket, bet): 
totPocket = 0 
for i in range(numSpins): 
game.spin()  
totPocket += game.betPocket(pocket, bet)  
if toPrint: 
print(numSpins, 'spins of', game) 
print('Expected return betting', pocket, '=',\\ 
str(100*totPocket/numSpins) + '%\\n') 
return (totPocket/numSpins) 
game = FairRoulette() 
for numSpins in (100, 1000000): 
for i in range(3): 
playRoulette(game, numSpins, 2, 1, True) 
6.0002 LECTURE 6 
12
","71.21956634521484","2","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_12_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"213","What is the optimal strategy dynamic programming seeks to solve in the alternating coin game?"," 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
Computation History Method - recap 
Computation History Method is useful for showing the undecidability 
of problems involving testing for the existence of some object. 
!
Is there an integral solution (to the polynomial equation)?
""LBA 
Is there some accepted string (for the LBA)?
&'& 
Is there a match (for the given dominos)?
())CFG Is there some rejected string (for the CFG)?
In each case, the object is the computation history in some form.
12
","70.86439514160156","3","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_12_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"213","What is the optimal strategy dynamic programming seeks to solve in the alternating coin game?","7 
Lecture 18: Pseudopolynomial 
Main Features of Dynamic Programs 
• Review of examples from lecture 
• Subproblems: 
– Preﬁx/sufﬁxes: Bowling, LCS, LIS, Floyd–Warshall, Rod Cutting (coincidentally, re­
ally Integer subproblems), Subset Sum 
– Substrings: Alternating Coin Game, Arithmetic Parenthesization 
– Multiple sequences: LCS 
– Integers: Fibonacci, Rod Cutting, Subset Sum 
Pseudopolynomial: Fibonacci, Subset Sum 
* 
– Vertices: DAG shortest paths, Bellman–Ford, Floyd–Warshall 
• Subproblem constraints/expansion: 
– Nonexpansive constraint: LIS (include ﬁrst item) 
– 2× expansion: Alternating Coin Game (who goes ﬁrst?), Arithmetic Parenthesization 
(min/max) 
– Θ(1)× expansion: Piano Fingering (ﬁrst ﬁnger assignment) 
– Θ(n)× expansion: Bellman–Ford (# edges) 
• Relation: 
– Branching = # dependant subproblems in each subproblem 
– Θ(1) branching: Fibonacci, Bowling, LCS, Alternating Coin Game, Floyd–Warshall, 
Subset Sum 
– Θ(degree) branching (source of |E| in running time): DAG shortest paths, Bellman– 
Ford 
– Θ(n) branching: LIS, Arithmetic Parenthesization, Rod Cutting 
– Combine multiple solutions (not path in subproblem DAG): Fibonacci, Floyd– 
Warshall, Arithmetic Parenthesization 
• Original problem: 
– Combine multiple subproblems: DAG shortest paths, Bellman–Ford, Floyd–Warshall, 
LIS, Piano Fingering 
","68.9974365234375","4","DPRSearchEngine","mit6_006s20_lec18_7_pdf","mit6_006s20_lec18","6.006","18"
"213","What is the optimal strategy dynamic programming seeks to solve in the alternating coin game?","When I had all heads, there was no variability in my answer. I got the same answer all the time. And so there was no variability, and that intuitively-- and in fact, mathematically-- should make us feel confident that, OK, maybe that's really the way the world is. On the other hand, when almost half are heads and almost half are tails, there's a lot of variance. Right, it's hard to predict what the next one will be. And so we should have very little confidence that it isn't an accident that it happened to be 52-48 in one direction. So as the variance grows, we need larger samples to have the same amount of confidence. All right, let's look at that with a detailed example. We'll look at roulette in keeping with the theme of Monte Carlo simulation. This is a roulette wheel that could well be at Monte Carlo. There's no need to simulate roulette, by the way. It's a very simple game, but as we've seen with our earlier examples, it's nice when we're learning about simulations to simulate things where we actually can know what the actual answer is so that we can then understand our simulation better. For those of you who don't know how roulette is played-- is there anyone here who doesn't know how roulette is played? Good for you. You grew up virtuous. All right, so-- well all right. Maybe I won't go there. So you have a wheel that spins around, and in the middle are a bunch of pockets. Each pocket has a number and a color. You bet in advance on what number you think is going to come up, or what color you think is going to come up. Then somebody drops a ball in that wheel, gives it a spin. And through centrifugal force, the ball stays on the outside for a while. But as the wheel slows down and heads towards the middle, and eventually settles in one of those pockets. And you win or you lose. Now you can bet on it, and so let's look at an example of that. So here is a roulette game. I've called it fair roulette, because it's set up in such a way that in principle, if you bet, your expected value should be 0. You'll win some, you'll lose some, but it's fair in the sense that it's not either a negative or positive sum game. So as always, we have an underbar underbar in it. Well we're setting up the wheel with 36 pockets on it, so you can bet on the numbers 1 through 36. That's way range work, you'll recall. Initially, we don't know where the ball is, so we'll say it's none. And here's the key thing is, if you make a bet, this tells you what your odds are. That if you bet on a pocket and you win, you get len of pockets minus 1. So This is why it's a fair game, right? You bet $1. If you win, you get $36, your dollar plus $35 back. If you lose, you lose. All right, self dot spin will be random dot choice among the pockets. And then there is simply bet, where you just can choose an amount to bet and the pocket you want to bet on. I've simplified it. I'm not allowing you to bet here on colors. All right, so then we can play it. So here is play roulette. I've made game the class a parameter,","68.79467010498047","5","DPRSearchEngine","OgO1gpXSUzU.en-j3PyPqV-e1s_5_mp4","OgO1gpXSUzU.en-j3PyPqV-e1s","6.0002","6"
"213","What is the optimal strategy dynamic programming seeks to solve in the alternating coin game?"," 
 
 
   
 
 
 
   
   
      
 
 
 
 
 
 
  
 
Stochastic Processes  
An ongoing process where the next state might depend on 
both the previous states and some random element 
def rollDie(): 
"""""" returns an int between 1 and 6"""""" 
def rollDie(): 
"""""" returns a randomly chosen int 
between 1 and 6"""""" 
6.0002 LECTURE 4 
8
","68.6708755493164","6","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_8_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"213","What is the optimal strategy dynamic programming seeks to solve in the alternating coin game?","you might find one way or the other more intuitive. They're equivalent. So as long as you understand at least one of them, it's good. NP is just a class of decision problems. So I define P and EXP and R arbitrary. They can be problems with any kind of output. But NP only makes sense for decision problems. And it's going to look almost like the definition of P-- problem solvable in polynomial time. We've just restricted to decision problems. But we're going to allow a strange kind of computer or algorithm, which I like to call a lucky algorithm. And this is going to relate to the notion of guessing that we talked about for the last four lectures in dynamic programming. With dynamic programming, we said, oh, there are all these different choices I could make. What's the right choice? I don't know, so I'd like to make a guess. And what that meant in terms of a real algorithm is, we tried all of the possibilities, and then took the max or the OR or whatever over all those possibilities. And so we were-- but what we were simulating is something that I call a lucky algorithm, which can make guesses and always makes the right guess. This is a computer that is impossible to buy. It would be great if you could buy a computer that's lucky. But we don't know how to build such a computer. So what does this mean? So informally, it means your algorithm can make lucky guesses, and it always makes the right guess. And whereas in DP, we had to try all the options and spend time for all of them, the lucky algorithm only has to spend time on the lucky guess, on the correct guess. More formally, this is called a non-deterministic model of computation. And this N is the-- the N in non-determinism is the N for NP. So this is non-deterministic polynomial time. So algorithm can make guesses. And then in the end, it should output yes or no. Like say if you're exploring a maze, this algorithm could say, should I go left or go right? I'm going to guess whether to go left or go right. And let's say it guesses left. And so then it just goes left. And then it reaches another junction. It says, should I go left or right? And it'll say, I'll guess, and it'll say, guess right this time. And in the end, if I get to some dead end maybe and I say no, or if I get to the destination I'm trying to get to, I say yes. So that's a non-deterministic algorithm. And what does it mean to run that algorithm? What does it mean for the guesses to be lucky? Here's what it means. These guesses are guaranteed-- which way you end up going is guaranteed to lead you to a yes if there is one-- if possible. So in my maze analogy, if my destination is reachable from my source, then I'm guaranteed, whenever I guessed left or right, I will choose a path that leads me to my destination. Whereas, if the destination is in some disconnected part of the maze and I can't get there, then I don't know what the guesses do. It doesn't really matter. Because no matter what I do, I'll end up in a dead end and say no. That's the model. As long as you have an algorithm that always outputs yes or no in polynomial time-- because we're only talking about polynomial time, lucky algorithms-- if there's any way to get to a yes, then your machine will magically find it without having to spend any time to make these decisions. So it's a pretty magical computer, and it's not a computer that exists in real life. But it's a computer that's great to program on. It's very powerful. You could solve lots of things with it. Yeah. AUDIENCE: If you had this magical computer, it can guess whether it's yes or no, why doesn't it just answer the question? ERIK DEMAINE: Right. So what if we-- so a nice check is, does this make all problems trivial, all decision problems? Maybe I should say, well, I don't know whether the answer to the problem is yes or no, so I'll just guess yes or no. This is problematic because-- so I might say, it will guess A or B, and if I choose the A option, I will output yes, and if I choose the B option, I will output no. In this model, that algorithm will always output yes. Because what it's saying is, if there's any way to get to a yes answer, I will do that way. And so such an algorithm that tries to cheat and just guess the whole answer to the problem will actually end up always saying yes, which means it doesn't solve a very interesting problem. It only solves the problem, which is represented by the bit vector 1111111, where all the answers are yes. But good check. Yeah. AUDIENCE: Does there have to be a bound of a number of things it has to choose between when it [AUDIO OUT] ERIK DEMAINE: Yes. AUDIENCE: Does it have an exponential number of them? ERIK DEMAINE: Exponential number of choices is OK. I usually like to think of it, as you can only guess one bit at a time. But we're allowed polynomial time, so you're actually allowed to guess polynomial number of bits. At that point, you can guess over an exponential size space, but not more than exponential. So it's-- yeah, polynomial time let's say in the one-bit guessing model. What did I say? Makes guesses-- let's add binary here. Otherwise we get some other class, which I don't want. OK, let's do an example, a real example of such an algorithm","68.35091400146484","7","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_6_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"213","What is the optimal strategy dynamic programming seeks to solve in the alternating coin game?","2 
Lecture 20: Course Review 
Next Steps 
• (U) 6.046: Design & Analysis of Algorithms 
• (G) 6.851: Advanced Data Structures 
• (G) 6.854: Advanced Algorithms 
6.046 
• Extension of 6.006 
– Data Structures: Union-Find, Amortization via potential analysis 
– Graphs: Minimum Spanning Trees, Network Flows/Cuts 
– Algorithm Design (Paradigms): Divide & Conquer, Dynamic Programming, Greedy 
– Complexity: Reductions 
• Relax Problem (change deﬁnition of correct/efﬁcient) 
– Randomized Algorithms 
∗ 6.006 mostly deterministic (hashing) 
∗ Las Vegas: always correct, probably fast (like hashing) 
∗ Monte Carlo: always fast, probably correct 
∗ Can generally get faster randomized algorithms on structured data 
– Numerical Algorithms/Continuous Optimization 
∗ 6.006 only deals with integers 
∗ Approximate real numbers! Pay time for precision 
– Approximation Algorithms 
∗ Input optimization problem (min/max over weighted outputs) 
∗ Many optimization problems NP-hard 
∗ How close can we get to an optimal solution in polynomial time? 
• Change Model of Computation 
– Cache Models (memory hierarchy cost model) 
– Quantum Computer (exploiting quantum properties) 
– Parallel Processors (use multiple CPUs instead of just one) 
∗ Multicore, large shared memory 
∗ Distributed cores, message passing 
","68.20207214355469","8","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_2_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"213","What is the optimal strategy dynamic programming seeks to solve in the alternating coin game?","3 
Lecture 20: Course Review 
Future Courses 
Model 
Application 
• Computation / Complexity (6.045, 6.840, 6.841) 
• Biology (6.047) 
• Randomness (6.842) 
• Game Theory (6.853) 
• Quantum (6.845) 
• Cryptography (6.875) 
• Distributed / message passing (6.852) 
• Vision (6.819) 
• Multicore / shared memory (6.816, 6.846) 
• Graphics (6.837) 
• Graph and Matrix (6.890) 
• Geometry (6.850) 
• Constant Factors / Performance (6.172) 
• Folding (6.849) 
","67.81373596191406","9","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_3_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"213","What is the optimal strategy dynamic programming seeks to solve in the alternating coin game?","4 
Lecture 19: Complexity 
Examples of NP-complete Problems 
• Subset Sum from L18 (“weakly NP-complete” which is what allows a pseudopolynomial­
time algorithm, but no polynomial algorithm unless P = NP) 
• 3-Partition: given n integers, can you divide them into triples of equal sum? (“strongly 
NP-complete”: no pseudopolynomial-time algorithm unless P = NP) 
• Rectangle Packing: given n rectangles and a target rectangle whose area is the sum of the n 
rectangle areas, pack without overlap 
– Reduction from 3-Partition to Rectangle Packing: transform integer ai into 1 × ai rect-
P 
angle; set target rectangle to n/3 × ( 
i ai) /3 
• Jigsaw puzzles: given n pieces with possibly ambiguous tabs/pockets, ﬁt the pieces together 
– Reduction from Rectangle Packing: use uniquely matching tabs/pockets to force build­
ing rectangles and rectangular boundary; use one ambiguous tab/pocket for all other 
boundaries 
• Longest common subsequence of n strings 
• Longest simple path in a graph 
• Traveling Salesman Problem: shortest path that visits all vertices of a given graph (or deci­
sion version: is minimum weight ≤ d) 
• Shortest path amidst obstacles in 3D 
• 3-coloring given graph (but 2-coloring ∈ P) 
• Largest clique in a given graph 
• SAT: given a Boolean formula (made with AND, OR, NOT), is it every true? 
E.g., x AND NOT x is a NO input 
• Minesweeper, Sudoku, and most puzzles 
• Super Mario Bros., Legend of Zelda, Pok´emon, and most video games are NP-hard (many 
are harder) 
","67.40245056152344","10","DPRSearchEngine","fda666a4db1dc65b3d71be08115502bd_MIT6_006S20_lec19_4_pdf","fda666a4db1dc65b3d71be08115502bd_MIT6_006S20_lec19","6.006","19"
"214","What is the disadvantage of using static arrays for dynamic operations like insertions?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","76.20040893554688","1","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"214","What is the disadvantage of using static arrays for dynamic operations like insertions?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","75.9951171875","2","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"214","What is the disadvantage of using static arrays for dynamic operations like insertions?","sorry, delete_max, thank you. You can of course define all of these things for min instead of max. Everything works the same. I just have a hard time remembering which one we're doing. Just don't switch you can't use a max-heap to do delete_min. You can't use a min-heap to do delete_max, but you can use a min-heap to do delete_min. That's fine. So like I said, the only node we really know how to delete is the last leaf on the last level, which is the end of the array. Because that's what arrays can delete efficiently. And what we need to delete is the root item, because that's always the maximum one, which is at the first position in the array. So what do we do? Swap them, our usual trick. I think the cool thing about heaps is we never have to do rotations. We're only going to do swaps, which is something we had to do with trees also-- binary trees. Q[0] with Q of the last item-- great, done. Now we have the last item is the one we want to delete. So we do delete_last, or pop in Python, and boom, we've got-- we've now deleted the maximum item. Of course, we may have also messed up the max-heap property just like we did with insert. So with insert, we were adding a last leaf. Now, what we're doing is swapping the last leaf with the-- I'm pointing at the wrong picture. Let me go back to this tree. What we did is swap item J with A. So the problem is now-- and then we deleted this node. The problem is now that that root node has maybe a very small key. Because the key that's here now is whatever was down here, which is very low in the tree. So intuitively, that's a small value. This is supposed to be the maximum value, and we just put a small value in the root. So what do we do? Heapify down. We're going to take that item and somehow push it down to the tree until the-- down in the tree until max-heap property is satisfied. So this is going to be max_heapify_down. And we will start at position 0, which is the root. And max_heapify_down is going to be a recursive algorithm. So we'll start at some position i. And initially, that's the root. And what we're going to do is look at position i and its two children. So let's say we put a very small value up here, like 0. And let's say we have our children, 5 and 10. We don't know-- maybe I'll swap their order just to be more generic, because that looks like not quite a binary search tree, but we don't know their relative order. But one of them is greater than or equal to the other in some order. And so what would I like to do to fix this local picture? Yeah, I want to swap. And I could swap-- 0 is clearly in the wrong spot. It needs to go lower in the tree. I can swap 0 with 5 or 0 with 10. Which one? 10. I could draw the picture with 5, but it will not be happy. Why 10? We want to do it with the larger one, because then this edge will be happy, and also this edge will be happy. If I swapped 5 up there instead, the 5/10 edge would be unhappy. It wouldn't satisfy the max-heap property. So I can do one swap and fix max-heap property. Except that, again, 0 may be unhappy with its children. 0 was this one item that was in the wrong spot. And so it made it have to go farther down. But 5 will be-- 5 didn't even move. So it's happy. Everything in this subtree is good. What about the parent? Well, if you think about it, because everything was a correct heap before we added 0, or before we put 0 too high, all of these nodes will be greater than or equal to 10 on the ancestor path. And all of these nodes were less than or equal to 10 before, unless you're equal to 5. So that's still true. But you see, this tree is happy. This tree still may be unhappy. 0 still might need to push down farther. That's going to be the recursion. So we check down here. There's a base case, which is if i is a leaf, we're done. Because there's nothing below them. So we satisfy the max-heap property at i because there's no children. Otherwise, let's look at the leaf among the left-- sorry, left not leaf-- among the two children left and right of i. Right if i might not exist. Then ignore it. But among the two children that exist, find the one that has maximum key value, Q[j].key. That was 10 in our example. And then, if these items are out of order, if we do not satisfy-- so greater than would be satisfy. Less than Q[j] would be the opposite of the max-heap property here. If max-heap property is violated, then we fix it by swapping Q[i] with Q[j], and then we recurse on j-- call max_heapify_down of j. That's it. So pretty symmetric. Insert was a little bit simpler, because we only have one parent. Delete_min, because we're pushing down, we have two children. We have to pick one. But there's a clear choice-- the bigger one. And again, this algorithm-- this whole thing-- will take order h time, the height of the tree, which is log n, because our node just sort of bubbles down. At some point, it stops. When it stops, we know the max-heap property was satisfied there. And if you check along the way, by induction, all the other max-heap properties will be satisfied, because they were before. So almost forced what we could do here. The amazing thing is that you can actually maintain a complete binary tree that satisfies the max-heap property. But once you're told that, the algorithm kind of falls out. Because we have an array. The only thing we can do is insert and delete the last item. And so we've got to swap things to there in order-- or out of there in order to make that work. And then, the rest is just checking locally that you can fix the property. Cool. So that's almost it, not quite what we wanted. So we now have log n amortize insert and delete_max in our heap. We did not yet cover linear build. Right now, it's n log n if you insert n times. And we did not yet cover how to make this an in-place sorting algorithm. So let me sketch each of those. I think first is in-place. So how do we make this algorithm in-place? I guess I want that, but I don't need this. So we want to follow priority queue sort. Maybe I do want that. But I don't want to have to grow and shrink my array. I would just like to start with the array itself. So this is in place. So what we're going to do is say, OK, here's my array that I want to sort. That's given to me. That's the input to priority queue sort. And what I'd like is to build a priority queue out of it. Initially, it's empty. And then I want to insert the items one at a time, let's say. So in general, what I'm going to do is maintain that Q is some prefix of A. That's going to be my priority queue. It's going to live in this sub array-- this prefix. So how do I insert a new item? Well, I just increment. So to do an insert, the first step is increment size of Q. Then I will have taken the next item from A and injected into this Q. And conveniently, if we look at our insert code, which is here, the first thing we wanted to do was add an item at the end of the array. So we just did it without any actual work, just conceptual work. We just said, oh, our Q is one bigger. Boom! Now this is at the end of the array. no more amortization, in fact, because we're not ever resizing our array, we're just saying, oh, now Q is a little bit bigger of a prefix. It just absorb the next item of A. Similarly, delete_max is going to, at the end, decrement the size of Q. Why is that OK? Because at the end of our delete_max operation-- not quite at the end, but almost the end-- we deleted the last item from our array. So we just replaced that delete last with a decrement, and that's going to shrink the Q by 1. It has the exact same impact as leading the last item. But now, it's constant time, worst case not amortized. And the result is we never actually build a dynamic array. We just use a portion of A to do it. So what's going to happen is we're going to absorb all the items into the priority queue, and then start kicking them out. As we kick them out, we kick out the largest key item first, and we put it here, then the next largest, then the next largest, and so on. The minimum item is going to be here. And, boom, it's sorted. This is the whole reason I did max-heaps instead of min-heaps, is that in the end, this will be a upward sorted array with the max at the end. Because we always kick out items at the end. We delete the max first. So that is what's normally called heapsort. You can apply this same trick to insertion sort and selection sort, and you actually get the insertion sort and selection sort algorithms that we've seen which operate in prefixes of the array. Cool, so now we have-- we've achieved the y up there, which is n log n sorting algorithm that is in-place. So that was our main goal-- heapsort. Let me very quickly mention you can build a heap in linear time with a clever trick. So if you insert the items one at a time, that would correspond to inserting down the array. And every time I insert an item, I have to walk up the tree. So this would be the sum of the depth of each node. If you do that, you get n log n. This is the sum over i of log i. That turns out to be n log n. It's a log of n factorial. The cool trick is to, instead, imagine adding all the items at once and not heapifying anything, and then heapify up-- sorry, heapify down from the bottom up. So here we're heapifying up. Now, we're going to heapify down. And surprisingly, that's better. Because this is the sum of the heights of the nodes. And that turns out to be linear. It's not obvious. But intuitively, for a depth, this is 0, this is log n, and we've got a whole ton of leaves. So right at the leaf level, you can see, we're paying n log n, right? Because there are n of them, and each one costs log n. Down here, at the leaf level, we're paying constant. Because the height of the leaves are 1. Here, the height of the root is log n. And this is better. Now we're paying a small amount for the thing of which there are many. It's not quite a geometric series, but it turns out this is linear. So that's how you can do linear building heap. To come back to your question about sequence AVL trees, turns out you can get all of the same bounds as heaps, except for the in-place part, by taking a sequence AVL tree, storing the items in an arbitrary order, and augmenting by max, which is a crazy idea. But it also gives you a linear build time. And yeah, there's other fun stuff in your notes. But I'll stop there.","75.78025817871094","3","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_11_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"214","What is the disadvantage of using static arrays for dynamic operations like insertions?","What's the worst case performance of a hash table? If I have to look up something in a hash table, and I happen to choose a bad hash table-- hash function, what's the worst case here? What? n, right? It's worse than a sorted array, because potentially, I hashed everything that I was storing to the same index in my hash table, and to be able to distinguish between them, I can't do anything more than a linear search. I could store another set's data structure as my chain and do better that way. That's actually how Java does it. They store a data structure we're going to be talking about next week as the chains so that they can get, worst case, log n. But in general, that hash table is only good if we're allowing-- OK, I want this to be expected good, but in the worst case, if I really need that operation to be worst case-- I really can't afford linear time ever for an operation of that kind-- then I don't want to use a hash table. And so on your p set 2, everything we ask you for is worst case, so probably, you don't want to be using hash tables. OK? Yes? AUDIENCE: What does the subscript e mean? JASON KU: What does the subscript e mean? That's great. In this chart, I put a subscript on this is an expected runtime, or an A meaning this is an amortized runtime. At the end, we talked about how, if we had too many things in our hash table, then, as long as we didn't do it too often-- this is a little hand wavey argument, but the same kinds of ideas as the dynamic array-- if, whenever we got a linear-- we are more than a linear factor away from where we are trying-- basically, the fill factor we were trying to be, then we could just completely rebuild the hash table with the new hash function randomly chosen from our hash table with a new size, and we could get amortized bounds. And so that's what Python-- how Python implements dictionaries, or sets, or even objects when it's trying to map keys to different things. So that's hash tables. That's great. The key thing here is, well, actually, if your range of keys is small, or if you as a programmer have the ability to choose the keys that you identify your objects with, you can actually choose that range to be small, to be linear, to be small with respect to your items. And you don't need a hash table. You can just use a direct access array, because if you know your key space is small, that's great. So a lot of C programmers probably would like to do something like that, because they don't have access to-- maybe C++ programmers would have access to their hash table. Any questions on this stuff before we move on? Yeah? AUDIENCE: So why is [INAUDIBLE]? JASON KU: Why is it expected? When I'm building, I could insert-- I'm inserting these things from x 1 by 1 into my hash table. Each of those insert operations-- I'm looking up to see whether that-- an item with that key already exists in my hash table. And so I have to look down the chain to see where it is. However, if I happen to know that all of my keys are unique in my input, all the items I'm trying to store are unique, then I don't have to do that check and I can get worst case linear time. Does that make sense? All right. It's a subtlety, but that's a great question. OK, so today, instead of talking about searching, we're talking about sorting. Last week, we saw a few ways to do sort. Some of them were quadratic-- insertion sort and selection sort-- and then we had one that was n log n. And this thing, n log n, seemed pretty good, but can I do better? Can I do better? Well, what we're going to show at the beginning of this class is, in this comparison model, no. n log n is optimal. And we're going to go through the exact same line of reasoning that we had last week. So in the comparison model, what did we use when we were trying to make this argument that any comparison model algorithm was going to take at least log n time? What we did was we said, OK, I can think of any model in the comparison model-- any algorithm in the comparison model as kind of this-- some comparisons happen. They branch in a binary sense, but you could have it generalized to any constant branching factor. But for our purposes, binary's fine. And what we said was that there were at least n outputs-- really n plus 1, but-- at least order n outputs. And we showed that-- or we argued to you that the height of this tree had to be at least log n-- log the number of leaves. It had to be at least log the number of leaves. That was the height of the decision tree. And if this decision tree represented a search algorithm, I had to walk down and perform these comparisons in order, reach a leaf where I would output something. If the minimum height of any binary tree on a linear number of leaves is log n, then any algorithm in the comparison model also has to take log n time, because it has to do that many comparisons to differentiate between all possible outputs. Does that make sense? All right. So in the sort problem, how many possible outputs are there?","75.20109558105469","4","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_4_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"214","What is the disadvantage of using static arrays for dynamic operations like insertions?","I've been talking about-- build, insert, and delete_max. So we have set AVL trees there-- n log n build, log n insert, log n delete. So along the way to our heap, I want to mention two other data structures. One is a dynamic but unsorted array. And the other is a dynamic sorted array. These are simpler data structures we've talked about many times before. And they're useful kind of motivations for getting started, because a heap is going to be built on top of arrays instead of-- well, it's sort of a fusion between arrays and trees. So if I have an unsorted array, this is very easy to insert into, right? I just append to the end. This is what we called insert last. So insert is fast, constant amortized. We might have to resize the array, but so that's the amortized part. But delete max is slow. In an unsorted array, I don't know where the maximum is. So I have to scan through the whole array. So I scan through the array, identify that the max is somewhere in the middle, and then, if I want to delete it-- I want to delete that maximum element, well, in a dynamic array, all I can really do is delete the last element efficiently. So I could, for example, swap it with the last element. So I take this element and put it here, and then delete the last element in that array, which is pop in Python or delete_last in our world. So overall, this is linear time, which is bad. But I wanted to highlight exactly how it's done for a reason we'll get to in a moment. A sorted array is sort of the reverse. It's very easy to find the max. Where is it? At the end. delete_max, the maximum element is always the last element in a increasing sorted array. I guess that's constant amortized, because then I have to delete it, which may incur resizing. Insert, though, is going to be linear, because maybe I can binary search to find where the added item belongs. Let's say I just added this item here. I could binary search to find it, but then I'm going to have to do a big shift. So I might as well just swap repeatedly until I find the position where the added item x belongs. And now I've restored sorted order. That takes linear time, which is bad. And what we want is somehow the best of these two worlds. Insert is fast for array. Delete is fast for a sorted array. We can't get constant time for both. But we can get log n time for both. We already know how with set AVL trees. But we're going to see a different way to do it today. And the main motivation for a different way to do this is sorting. So I want to define a priority queue sort. So given any data structure that implements a priority queue interface, in particular insert and delete_max, I can make a sorting algorithm. What do I do? Insert all the items, delete all the items. But because when I delete them they come out largest first, I get them in reverse sorted order. Then I could reverse in linear time and I've sorted my items. So we can insert (x) for x in A, or (build(A)), and then repeatedly delete_max. How much time does this algorithm take? I'm going to introduce some notation here. It takes however long it takes to build n items, call that T sub build (n) plus-- sorry-- plus n times the time to do a delete_max. Or we can write this as n times time to do an insert, plus time to do a delete_max. So I'm using these T functions to just abstract what are the running times provided by my data structure that implements this interface. Interface says what's correct is, and these T functions give me my performance bounds. So if I plug in each of these data structures, I get a sorting algorithm. I get AVL sort, I get array sort, I get assorted array sort. What do those look like? It turns out many of these are familiar. So set AVLs take log n per operation. So we get an n log n sorting algorithm out of them, which is insert all of the items into the AVL tree. I don't want to use AVL build because that uses sort, and not allowed to sort in order to implement sort. But we saw how to insert into an AVL tree and keep the thing balanced. So that takes log n each. And then we can find the max, delete it, rebalance, and so on. Total time will be n log n. This is an algorithm we call AVL sort. It's a bit complicated, because AVL trees are complicated. But it gives us optimal comparison bound and log n. Now, what about array sort? So suppose I use an unsorted array. I insert the item. So if I insert the items-- so I'm doing all the insertions here before all the deletions. So what's going to happen is I just insert the items in the original array order. In other words, I just take the array. And then what I do is repeatedly extract the maximum item by searching for it, moving it to the end of the array, and then repeating that process. That sound familiar? That's selection sort from lecture three. So this-- arrays give us selection sort. This is a new way to think about what we were doing way back then. With a sorted array, what are we doing? We insert all the items. That's actually where all the work happens, because we maintain the sorted array. So we start with an empty array. It's sorted. We add an item. OK, it's still sorted. We add a second item, and we swap if we need to in order to sort. In general, when we add an item, we swap it to the left until it's sorted again. That is insertion sort. Kind of cool, this is a unifying framework for three sorting algorithms that we saw before. We didn't actually talk about AVL sort last time, but it was in the notes. And so that is the right part of this table.","74.2550048828125","5","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_4_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"214","What is the disadvantage of using static arrays for dynamic operations like insertions?","And this is a subset of the set interface. And subsets are interesting because, potentially, we can solve them better, faster, simpler, something. And so you'll recognize-- you should recognize all of these operations, except we didn't normally highlight the max operation. So here, we're interested in storing a bunch of items. They have keys which we think of as priorities. And we want to be able to identify the maximum priority item in our set and remove it. And so there's lots of motivations for this. Maybe you have a router, packets going into the router. They have different priorities assigned to them. You want to route the highest priority first. Or you have processes on your computer trying to run on your single threaded-- single core, and you've got to choose which one to run next. And you usually run higher priority processes first. Or you're trying to simulate a system where events happen at different times, and you want to process the next event ordered by time. All of these are examples of the priority queue interface. We'll even see applications within this class when we get to graph algorithms. But the main two things we want to be able to support are inserting an item, which includes a key, and leading the maximum item, and also returning it at the same time. We'll also talk some about being able to build the structure faster than just inserting it. But of course, we could implement build by starting empty and repeatedly inserting. And also the complexity of just finding the max without deleting it, this you could simulate with these two operations by deleting the max and then reinserting it, which works. But often, we can do faster. But the two key, main operations are insert and delete max. And we're going to see a few data structures to do this. Any suggestions among the data structures we've seen in this class? What should we use to solve priority queue interface? Many possible answers.","73.99400329589844","6","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_2_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"214","What is the disadvantage of using static arrays for dynamic operations like insertions?","4 
Lecture 1: Introduction 
1 
def birthday_match(students): 
2 
’’’ 
3 
Find a pair of students with the same birthday 
4 
Input: 
tuple of student (name, bday) tuples 
5 
Output: tuple of student names or None 
6 
’’’ 
7 
n = len(students) 
# O(1) 
8 
record = StaticArray(n) 
# O(n) 
9 
for k in range(n): 
# n 
10 
(name1, bday1) = students[k] 
# O(1) 
11 
# Return pair if bday1 in record 
12 
for i in range(k): 
# k 
13 
(name2, bday2) = record.get_at(i) 
# O(1) 
14 
if bday1 == bday2: 
# O(1) 
15 
return (name1, name2) 
# O(1) 
16 
record.set_at(k, (name1, bday1)) 
# O(1) 
17 
return None 
# O(1) 
Example: Running Time Analysis 
• Two loops: outer k ∈{0, . . . , n − 1}, inner is i ∈{0, . . . , k}
P n−1
• Running time is O(n) + 
k=0 (O(1) + k · O(1)) = O(n2) 
• Quadratic in n is polynomial. Efﬁcient? Use different data structure for record! 
How to Solve an Algorithms Problem 
1. Reduce to a problem you already know (use data structure or algorithm) 
Search Problem (Data Structures) 
Sort Algorithms 
Static Array (L01) 
Insertion Sort (L03) 
Linked List (L02) 
Selection Sort (L03) 
Dynamic Array (L02) 
Merge Sort (L03) 
Sorted Array (L03) 
Counting Sort (L05) 
Direct-Access Array (L04) 
Radix Sort (L05) 
Hash Table (L04) 
AVL Sort (L07) 
Balanced Binary Tree (L06-L07) 
Heap Sort (L08) 
Binary Heap (L08) 
2. Design your own (recursive) algorithm 
• Brute Force 
• Decrease and Conquer 
• Divide and Conquer 
• Dynamic Programming (L15-L19) 
• Greedy / Incremental 
Shortest Path Algorithms 
Breadth First Search (L09) 
DAG Relaxation (L11) 
Depth First Search (L10) 
Topological Sort (L10) 
Bellman-Ford (L12) 
Dijkstra (L13) 
Johnson (L14) 
Floyd-Warshall (L18) 
","73.70396423339844","7","DPRSearchEngine","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_4_pdf","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1","6.006","1"
"214","What is the disadvantage of using static arrays for dynamic operations like insertions?","2 
Lecture 8: Binary Heaps 
Priority Queue: Set AVL Tree 
• Set AVL trees support insert(x), find min(), find max(), delete min(), and 
delete max() in O(log n) time per operation 
• So priority queue sort runs in O(n log n) time 
– This is (essentially) AVL sort from Lecture 7 
• Can speed up find min() and find max() to O(1) time via subtree augmentation 
• But this data structure is complicated and resulting sort is not in-place 
• Is there a simpler data structure for just priority queue, and in-place O(n lg n) sort? 
YES, binary heap and heap sort 
• Essentially implement a Set data structure on top of a Sequence data structure (array), using 
what we learned about binary trees 
Priority Queue: Array 
• Store elements in an unordered dynamic array 
• insert(x): append x to end in amortized O(1) time 
• delete max(): ﬁnd max in O(n), swap max to the end and remove 
• insert is quick, but delete max is slow 
• Priority queue sort is selection sort! (plus some copying) 
Priority Queue: Sorted Array 
• Store elements in a sorted dynamic array 
• insert(x): append x to end, swap down to sorted position in O(n) time 
• delete max(): delete from end in O(1) amortized 
• delete max is quick, but insert is slow 
• Priority queue sort is insertion sort! (plus some copying) 
• Can we ﬁnd a compromise between these two array priority queue extremes? 
","73.64680480957031","8","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_2_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"214","What is the disadvantage of using static arrays for dynamic operations like insertions?","&

	
	
	/
def greedy(items, maxCost, keyFunction):
itemsCopy = sorted(items, key = keyFunction,
reverse = True)
result = []
totalValue, totalCost = 0.0, 0.0
for i in range(len(itemsCopy)):
if (totalCost+itemsCopy[i].getCost()) <= maxCost:
result.append(itemsCopy[i])
totalCost += itemsCopy[i].getCost()
totalValue += itemsCopy[i].getValue()
return (result, totalValue) 
	

2
	

","73.26422119140625","9","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_24_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"214","What is the disadvantage of using static arrays for dynamic operations like insertions?","   
  
 
 
   
 
 
 
 
 
 
 
   
 
 
 
 
 
 
   
 
   
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
!""#$ ∈ PSPACE 
Theorem: !""#$ ∈ PSPACE 
Proof: “On input 〈'〉 
1. If ' has no quantifiers, then ' has no variables 
so either ' = True or ' = False.  Output accordingly. 
2. If ' = ∃+ , then evaluate , with + = TRUE and + = FALSE recursively. 
Accept if either accepts. Reject if not. 
3. If ' = ∀+ , then evaluate , with + = TRUE and + = FALSE recursively. 
Accept if both accept. Reject if not.” 
Space analysis: 
Each recursive level uses constant space (to record the + value). 
The recursion depth is the number of quantifiers, at most . = | ' |. 
So !""#$ ∈ SPACE(.) 
6 
","73.1921615600586","10","DPRSearchEngine","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17_6_pdf","9b025394d997750b3cd765c7a074881f_MIT18_404f20_lec17","18.404J","17"
"215","Why are linked lists inefficient for random access operations?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","73.96321868896484","1","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"215","Why are linked lists inefficient for random access operations?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","72.11598205566406","2","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"215","Why are linked lists inefficient for random access operations?","2 
Lecture 20: Course Review 
Next Steps 
• (U) 6.046: Design & Analysis of Algorithms 
• (G) 6.851: Advanced Data Structures 
• (G) 6.854: Advanced Algorithms 
6.046 
• Extension of 6.006 
– Data Structures: Union-Find, Amortization via potential analysis 
– Graphs: Minimum Spanning Trees, Network Flows/Cuts 
– Algorithm Design (Paradigms): Divide & Conquer, Dynamic Programming, Greedy 
– Complexity: Reductions 
• Relax Problem (change deﬁnition of correct/efﬁcient) 
– Randomized Algorithms 
∗ 6.006 mostly deterministic (hashing) 
∗ Las Vegas: always correct, probably fast (like hashing) 
∗ Monte Carlo: always fast, probably correct 
∗ Can generally get faster randomized algorithms on structured data 
– Numerical Algorithms/Continuous Optimization 
∗ 6.006 only deals with integers 
∗ Approximate real numbers! Pay time for precision 
– Approximation Algorithms 
∗ Input optimization problem (min/max over weighted outputs) 
∗ Many optimization problems NP-hard 
∗ How close can we get to an optimal solution in polynomial time? 
• Change Model of Computation 
– Cache Models (memory hierarchy cost model) 
– Quantum Computer (exploiting quantum properties) 
– Parallel Processors (use multiple CPUs instead of just one) 
∗ Multicore, large shared memory 
∗ Distributed cores, message passing 
","71.66197204589844","3","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_2_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"215","Why are linked lists inefficient for random access operations?","What's the worst case performance of a hash table? If I have to look up something in a hash table, and I happen to choose a bad hash table-- hash function, what's the worst case here? What? n, right? It's worse than a sorted array, because potentially, I hashed everything that I was storing to the same index in my hash table, and to be able to distinguish between them, I can't do anything more than a linear search. I could store another set's data structure as my chain and do better that way. That's actually how Java does it. They store a data structure we're going to be talking about next week as the chains so that they can get, worst case, log n. But in general, that hash table is only good if we're allowing-- OK, I want this to be expected good, but in the worst case, if I really need that operation to be worst case-- I really can't afford linear time ever for an operation of that kind-- then I don't want to use a hash table. And so on your p set 2, everything we ask you for is worst case, so probably, you don't want to be using hash tables. OK? Yes? AUDIENCE: What does the subscript e mean? JASON KU: What does the subscript e mean? That's great. In this chart, I put a subscript on this is an expected runtime, or an A meaning this is an amortized runtime. At the end, we talked about how, if we had too many things in our hash table, then, as long as we didn't do it too often-- this is a little hand wavey argument, but the same kinds of ideas as the dynamic array-- if, whenever we got a linear-- we are more than a linear factor away from where we are trying-- basically, the fill factor we were trying to be, then we could just completely rebuild the hash table with the new hash function randomly chosen from our hash table with a new size, and we could get amortized bounds. And so that's what Python-- how Python implements dictionaries, or sets, or even objects when it's trying to map keys to different things. So that's hash tables. That's great. The key thing here is, well, actually, if your range of keys is small, or if you as a programmer have the ability to choose the keys that you identify your objects with, you can actually choose that range to be small, to be linear, to be small with respect to your items. And you don't need a hash table. You can just use a direct access array, because if you know your key space is small, that's great. So a lot of C programmers probably would like to do something like that, because they don't have access to-- maybe C++ programmers would have access to their hash table. Any questions on this stuff before we move on? Yeah? AUDIENCE: So why is [INAUDIBLE]? JASON KU: Why is it expected? When I'm building, I could insert-- I'm inserting these things from x 1 by 1 into my hash table. Each of those insert operations-- I'm looking up to see whether that-- an item with that key already exists in my hash table. And so I have to look down the chain to see where it is. However, if I happen to know that all of my keys are unique in my input, all the items I'm trying to store are unique, then I don't have to do that check and I can get worst case linear time. Does that make sense? All right. It's a subtlety, but that's a great question. OK, so today, instead of talking about searching, we're talking about sorting. Last week, we saw a few ways to do sort. Some of them were quadratic-- insertion sort and selection sort-- and then we had one that was n log n. And this thing, n log n, seemed pretty good, but can I do better? Can I do better? Well, what we're going to show at the beginning of this class is, in this comparison model, no. n log n is optimal. And we're going to go through the exact same line of reasoning that we had last week. So in the comparison model, what did we use when we were trying to make this argument that any comparison model algorithm was going to take at least log n time? What we did was we said, OK, I can think of any model in the comparison model-- any algorithm in the comparison model as kind of this-- some comparisons happen. They branch in a binary sense, but you could have it generalized to any constant branching factor. But for our purposes, binary's fine. And what we said was that there were at least n outputs-- really n plus 1, but-- at least order n outputs. And we showed that-- or we argued to you that the height of this tree had to be at least log n-- log the number of leaves. It had to be at least log the number of leaves. That was the height of the decision tree. And if this decision tree represented a search algorithm, I had to walk down and perform these comparisons in order, reach a leaf where I would output something. If the minimum height of any binary tree on a linear number of leaves is log n, then any algorithm in the comparison model also has to take log n time, because it has to do that many comparisons to differentiate between all possible outputs. Does that make sense? All right. So in the sort problem, how many possible outputs are there?","71.07572937011719","4","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_4_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"215","Why are linked lists inefficient for random access operations?"," 
 
 
 
 
 
Two Kinds of Drunks  
import random  
class UsualDrunk(Drunk):  
def takeStep(self):  
stepChoices = [(0,1), (0,-1), (1, 0), (-1, 0)]  
return random.choice(stepChoices)  
class MasochistDrunk(Drunk):  
def takeStep(self):  
stepChoices = [(0.0,1.1), (0.0,-0.9),  
(1.0, 0.0), (-1.0, 0.0)]  
return random.choice(stepChoices)  
Immutable or not? 
6.0002  LECTURE 5 
17 
","70.70526885986328","5","DPRSearchEngine","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_17_pdf","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5","6.0002","5"
"215","Why are linked lists inefficient for random access operations?","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","70.5354232788086","6","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"215","Why are linked lists inefficient for random access operations?"," 
 
 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) 
General Unweighted 
BFS 
|V | + |E|
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Non-negative Dijkstra 
Bellman-Ford 
|V | log |V | + |E|
General Any 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 14: Johnson’s Algorithm 
Lecture 14: Johnson’s Algorithm 
Previously 
|V | · |E| 
All-Pairs Shortest Paths (APSP) 
• Input: directed graph G = (V, E) with weights w : E → Z 
• Output: δ(u, v) for all u, v ∈ V , or abort if G contains negative-weight cycle 
• Useful when understanding whole network, e.g., transportation, circuit layout, supply chains... 
• Just doing a SSSP algorithm |V | times is actually pretty good, since output has size O(|V |2) 
– |V | · O(|V | + |E|) with BFS if weights positive and bounded by O(|V | + |E|) 
– |V | · O(|V | + |E|) with DAG Relaxation if acyclic 
– |V | · O(|V | log |V | + |E|) with Dijkstra if weights non-negative or graph undirected 
– |V | · O(|V | · |E|) with Bellman-Ford (general) 
• Today: Solve APSP in any weighted graph in |V | · O(|V | log |V | + |E|) time 
","70.35746765136719","7","DPRSearchEngine","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14_1_pdf","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14","6.006","14"
"215","Why are linked lists inefficient for random access operations?","single source shortest paths in linear time. Last time we discussed another linear time algorithm, DAG relaxation. And today we're going to be talking about Bellman-Ford, which isn't limited to asymptotic graphs. In particular, there could be negative weight cycles in our graph. If it has cycles, if it has negative weights, the worry is that we could have negative weight cycles, in which case there-- if a negative weight cycle is reachable from our source, then the vertices in that cycle and anything reachable from that cycle will potentially","70.0598373413086","8","DPRSearchEngine","f9cVS_URPc0.en-j3PyPqV-e1s_2_mp4","f9cVS_URPc0.en-j3PyPqV-e1s","6.006","12"
"215","Why are linked lists inefficient for random access operations?","namely, random accessing. And if we stored the things that we're looking for, we have unique keys, and those keys are integers. Then, if I have an item with key K, if I store it at index K in my array, then I can find it and manipulate it in constant time.","69.85254669189453","9","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_2_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"215","Why are linked lists inefficient for random access operations?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Clustering Algorithms  
§Hierarchical  clustering  
◦ Can select number  of clusters using dendogram 
◦ Deterministic 
◦ Flexible with respect to linkage criteria 
◦ Slow 
◦ Naïve algorithm n3 
◦ n2 algorithms exist for some linkage criteria 
§K-means a much faster greedy algorithm 
◦ Most useful when you know how many clusters  you want  
6.0002  LECTURE 12 
9 
","69.83526611328125","10","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_9_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"216","What modification can improve linked list operations at both ends?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","78.76293182373047","1","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"216","What modification can improve linked list operations at both ends?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","75.90380096435547","2","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"216","What modification can improve linked list operations at both ends?","[SQUEAKING][RUSTLING][CLICKING] JASON KU: Welcome, everybody, to our lecture 14 of 6.006. This is our last lecture on graph algorithms, in particular, the last lecture we'll have on weighted shortest paths. But we're going to talk about a slightly different problem today, different than single source shortest paths. We're going to be talking about all-pairs shortest paths. But first, let's review our single source shortest paths algorithms. We had BFS, DAG relaxation, Dijkstra, which we saw last time, which gets pretty close to linear. V log V plus E is pretty close to linear. It's much closer to linear than the general algorithm we have for solving single source shortest paths, namely, Bellman-Ford, which is a little bit more like quadratic. This is like the difference between-- for sparse graphs, this is like the difference between sorting, using insertion sort and n squared, and merge sort in N log N, for example. We're going to get actually quite a big bonus for large input sizes by using Dijkstra when we can. Today, we're going to be focusing","73.99858093261719","3","DPRSearchEngine","EmSmaW-ud6A.en-j3PyPqV-e1s_1_mp4","EmSmaW-ud6A.en-j3PyPqV-e1s","6.006","14"
"216","What modification can improve linked list operations at both ends?","sorry, delete_max, thank you. You can of course define all of these things for min instead of max. Everything works the same. I just have a hard time remembering which one we're doing. Just don't switch you can't use a max-heap to do delete_min. You can't use a min-heap to do delete_max, but you can use a min-heap to do delete_min. That's fine. So like I said, the only node we really know how to delete is the last leaf on the last level, which is the end of the array. Because that's what arrays can delete efficiently. And what we need to delete is the root item, because that's always the maximum one, which is at the first position in the array. So what do we do? Swap them, our usual trick. I think the cool thing about heaps is we never have to do rotations. We're only going to do swaps, which is something we had to do with trees also-- binary trees. Q[0] with Q of the last item-- great, done. Now we have the last item is the one we want to delete. So we do delete_last, or pop in Python, and boom, we've got-- we've now deleted the maximum item. Of course, we may have also messed up the max-heap property just like we did with insert. So with insert, we were adding a last leaf. Now, what we're doing is swapping the last leaf with the-- I'm pointing at the wrong picture. Let me go back to this tree. What we did is swap item J with A. So the problem is now-- and then we deleted this node. The problem is now that that root node has maybe a very small key. Because the key that's here now is whatever was down here, which is very low in the tree. So intuitively, that's a small value. This is supposed to be the maximum value, and we just put a small value in the root. So what do we do? Heapify down. We're going to take that item and somehow push it down to the tree until the-- down in the tree until max-heap property is satisfied. So this is going to be max_heapify_down. And we will start at position 0, which is the root. And max_heapify_down is going to be a recursive algorithm. So we'll start at some position i. And initially, that's the root. And what we're going to do is look at position i and its two children. So let's say we put a very small value up here, like 0. And let's say we have our children, 5 and 10. We don't know-- maybe I'll swap their order just to be more generic, because that looks like not quite a binary search tree, but we don't know their relative order. But one of them is greater than or equal to the other in some order. And so what would I like to do to fix this local picture? Yeah, I want to swap. And I could swap-- 0 is clearly in the wrong spot. It needs to go lower in the tree. I can swap 0 with 5 or 0 with 10. Which one? 10. I could draw the picture with 5, but it will not be happy. Why 10? We want to do it with the larger one, because then this edge will be happy, and also this edge will be happy. If I swapped 5 up there instead, the 5/10 edge would be unhappy. It wouldn't satisfy the max-heap property. So I can do one swap and fix max-heap property. Except that, again, 0 may be unhappy with its children. 0 was this one item that was in the wrong spot. And so it made it have to go farther down. But 5 will be-- 5 didn't even move. So it's happy. Everything in this subtree is good. What about the parent? Well, if you think about it, because everything was a correct heap before we added 0, or before we put 0 too high, all of these nodes will be greater than or equal to 10 on the ancestor path. And all of these nodes were less than or equal to 10 before, unless you're equal to 5. So that's still true. But you see, this tree is happy. This tree still may be unhappy. 0 still might need to push down farther. That's going to be the recursion. So we check down here. There's a base case, which is if i is a leaf, we're done. Because there's nothing below them. So we satisfy the max-heap property at i because there's no children. Otherwise, let's look at the leaf among the left-- sorry, left not leaf-- among the two children left and right of i. Right if i might not exist. Then ignore it. But among the two children that exist, find the one that has maximum key value, Q[j].key. That was 10 in our example. And then, if these items are out of order, if we do not satisfy-- so greater than would be satisfy. Less than Q[j] would be the opposite of the max-heap property here. If max-heap property is violated, then we fix it by swapping Q[i] with Q[j], and then we recurse on j-- call max_heapify_down of j. That's it. So pretty symmetric. Insert was a little bit simpler, because we only have one parent. Delete_min, because we're pushing down, we have two children. We have to pick one. But there's a clear choice-- the bigger one. And again, this algorithm-- this whole thing-- will take order h time, the height of the tree, which is log n, because our node just sort of bubbles down. At some point, it stops. When it stops, we know the max-heap property was satisfied there. And if you check along the way, by induction, all the other max-heap properties will be satisfied, because they were before. So almost forced what we could do here. The amazing thing is that you can actually maintain a complete binary tree that satisfies the max-heap property. But once you're told that, the algorithm kind of falls out. Because we have an array. The only thing we can do is insert and delete the last item. And so we've got to swap things to there in order-- or out of there in order to make that work. And then, the rest is just checking locally that you can fix the property. Cool. So that's almost it, not quite what we wanted. So we now have log n amortize insert and delete_max in our heap. We did not yet cover linear build. Right now, it's n log n if you insert n times. And we did not yet cover how to make this an in-place sorting algorithm. So let me sketch each of those. I think first is in-place. So how do we make this algorithm in-place? I guess I want that, but I don't need this. So we want to follow priority queue sort. Maybe I do want that. But I don't want to have to grow and shrink my array. I would just like to start with the array itself. So this is in place. So what we're going to do is say, OK, here's my array that I want to sort. That's given to me. That's the input to priority queue sort. And what I'd like is to build a priority queue out of it. Initially, it's empty. And then I want to insert the items one at a time, let's say. So in general, what I'm going to do is maintain that Q is some prefix of A. That's going to be my priority queue. It's going to live in this sub array-- this prefix. So how do I insert a new item? Well, I just increment. So to do an insert, the first step is increment size of Q. Then I will have taken the next item from A and injected into this Q. And conveniently, if we look at our insert code, which is here, the first thing we wanted to do was add an item at the end of the array. So we just did it without any actual work, just conceptual work. We just said, oh, our Q is one bigger. Boom! Now this is at the end of the array. no more amortization, in fact, because we're not ever resizing our array, we're just saying, oh, now Q is a little bit bigger of a prefix. It just absorb the next item of A. Similarly, delete_max is going to, at the end, decrement the size of Q. Why is that OK? Because at the end of our delete_max operation-- not quite at the end, but almost the end-- we deleted the last item from our array. So we just replaced that delete last with a decrement, and that's going to shrink the Q by 1. It has the exact same impact as leading the last item. But now, it's constant time, worst case not amortized. And the result is we never actually build a dynamic array. We just use a portion of A to do it. So what's going to happen is we're going to absorb all the items into the priority queue, and then start kicking them out. As we kick them out, we kick out the largest key item first, and we put it here, then the next largest, then the next largest, and so on. The minimum item is going to be here. And, boom, it's sorted. This is the whole reason I did max-heaps instead of min-heaps, is that in the end, this will be a upward sorted array with the max at the end. Because we always kick out items at the end. We delete the max first. So that is what's normally called heapsort. You can apply this same trick to insertion sort and selection sort, and you actually get the insertion sort and selection sort algorithms that we've seen which operate in prefixes of the array. Cool, so now we have-- we've achieved the y up there, which is n log n sorting algorithm that is in-place. So that was our main goal-- heapsort. Let me very quickly mention you can build a heap in linear time with a clever trick. So if you insert the items one at a time, that would correspond to inserting down the array. And every time I insert an item, I have to walk up the tree. So this would be the sum of the depth of each node. If you do that, you get n log n. This is the sum over i of log i. That turns out to be n log n. It's a log of n factorial. The cool trick is to, instead, imagine adding all the items at once and not heapifying anything, and then heapify up-- sorry, heapify down from the bottom up. So here we're heapifying up. Now, we're going to heapify down. And surprisingly, that's better. Because this is the sum of the heights of the nodes. And that turns out to be linear. It's not obvious. But intuitively, for a depth, this is 0, this is log n, and we've got a whole ton of leaves. So right at the leaf level, you can see, we're paying n log n, right? Because there are n of them, and each one costs log n. Down here, at the leaf level, we're paying constant. Because the height of the leaves are 1. Here, the height of the root is log n. And this is better. Now we're paying a small amount for the thing of which there are many. It's not quite a geometric series, but it turns out this is linear. So that's how you can do linear building heap. To come back to your question about sequence AVL trees, turns out you can get all of the same bounds as heaps, except for the in-place part, by taking a sequence AVL tree, storing the items in an arbitrary order, and augmenting by max, which is a crazy idea. But it also gives you a linear build time. And yeah, there's other fun stuff in your notes. But I'll stop there.","73.43551635742188","4","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_11_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"216","What modification can improve linked list operations at both ends?"," &&%$3$%'9
class Digraph(object): 
 """"""edges is a dict mapping each node to a list of 
    its children""""” 
    def __init__(self): 
self.edges = {} 
    def addNode(self, node): 
if node in self.edges: 
 raise ValueError('Duplicate node') 
else: 
self.edges[node] = [] 
    def addEdge(self, edge): 
src = edge.getSource() 
dest = edge.getDestination() 
if not (src in self.edges and dest in self.edges): 
raise ValueError('Node not in graph') 
self.edges[src].append(dest) 
Q>KKKMN
LS
mapping each node 
list 
","73.33403778076172","5","DPRSearchEngine","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_18_pdf","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3","6.0002","3"
"216","What modification can improve linked list operations at both ends?"," 
 
  
 
 
  
 
 
 
 
 
 
  
 
 
 
Interactive Proofs – Introduction 
Illustration: Graph isomorphism testing 
Defn: Undirected graphs ! and "" are isomorphic if they are identical except 
for a permutation (rearrangement) of the nodes. 
2 
","73.3261947631836","6","DPRSearchEngine","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25_2_pdf","fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25","18.404J","25"
"216","What modification can improve linked list operations at both ends?","&

	
	
	/
def greedy(items, maxCost, keyFunction):
itemsCopy = sorted(items, key = keyFunction,
reverse = True)
result = []
totalValue, totalCost = 0.0, 0.0
for i in range(len(itemsCopy)):
if (totalCost+itemsCopy[i].getCost()) <= maxCost:
result.append(itemsCopy[i])
totalCost += itemsCopy[i].getCost()
totalValue += itemsCopy[i].getValue()
return (result, totalValue) 
	

2
	

","73.3220443725586","7","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_24_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"216","What modification can improve linked list operations at both ends?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 2: Data Structures 
Lecture 2: Data Structures 
Data Structure Interfaces 
• A data structure is a way to store data, with algorithms that support operations on the data 
• Collection of supported operations is called an interface (also API or ADT) 
• Interface is a speciﬁcation: what operations are supported (the problem!) 
• Data structure is a representation: how operations are supported (the solution!) 
• In this class, two main interfaces: Sequence and Set 
Sequence Interface (L02, L07) 
• Maintain a sequence of items (order is extrinsic) 
• Ex: (x0, x1, x2, . . . , xn−1) (zero indexing) 
• (use n to denote the number of items stored in the data structure) 
• Supports sequence operations: 
Container 
build(X) 
len() 
given an iterable X, build sequence from items in X 
return the number of stored items 
Static 
iter seq() 
get at(i) 
set at(i, x) 
return the stored items one-by-one in sequence order 
return the ith item 
replace the ith item with x 
Dynamic 
insert at(i, x) 
delete at(i) 
insert first(x) 
delete first() 
insert last(x) 
delete last() 
add x as the ith item 
remove and return the ith item 
add x as the ﬁrst item 
remove and return the ﬁrst item 
add x as the last item 
remove and return the last item 
• Special case interfaces: 
stack 
insert last(x) and delete last() 
queue 
insert last(x) and delete first() 
","73.21435546875","8","DPRSearchEngine","79a07dc1cb47d76dae2ffedc701e3d2b_MIT6_006S20_lec2_1_pdf","79a07dc1cb47d76dae2ffedc701e3d2b_MIT6_006S20_lec2","6.006","2"
"216","What modification can improve linked list operations at both ends?","What's the worst case performance of a hash table? If I have to look up something in a hash table, and I happen to choose a bad hash table-- hash function, what's the worst case here? What? n, right? It's worse than a sorted array, because potentially, I hashed everything that I was storing to the same index in my hash table, and to be able to distinguish between them, I can't do anything more than a linear search. I could store another set's data structure as my chain and do better that way. That's actually how Java does it. They store a data structure we're going to be talking about next week as the chains so that they can get, worst case, log n. But in general, that hash table is only good if we're allowing-- OK, I want this to be expected good, but in the worst case, if I really need that operation to be worst case-- I really can't afford linear time ever for an operation of that kind-- then I don't want to use a hash table. And so on your p set 2, everything we ask you for is worst case, so probably, you don't want to be using hash tables. OK? Yes? AUDIENCE: What does the subscript e mean? JASON KU: What does the subscript e mean? That's great. In this chart, I put a subscript on this is an expected runtime, or an A meaning this is an amortized runtime. At the end, we talked about how, if we had too many things in our hash table, then, as long as we didn't do it too often-- this is a little hand wavey argument, but the same kinds of ideas as the dynamic array-- if, whenever we got a linear-- we are more than a linear factor away from where we are trying-- basically, the fill factor we were trying to be, then we could just completely rebuild the hash table with the new hash function randomly chosen from our hash table with a new size, and we could get amortized bounds. And so that's what Python-- how Python implements dictionaries, or sets, or even objects when it's trying to map keys to different things. So that's hash tables. That's great. The key thing here is, well, actually, if your range of keys is small, or if you as a programmer have the ability to choose the keys that you identify your objects with, you can actually choose that range to be small, to be linear, to be small with respect to your items. And you don't need a hash table. You can just use a direct access array, because if you know your key space is small, that's great. So a lot of C programmers probably would like to do something like that, because they don't have access to-- maybe C++ programmers would have access to their hash table. Any questions on this stuff before we move on? Yeah? AUDIENCE: So why is [INAUDIBLE]? JASON KU: Why is it expected? When I'm building, I could insert-- I'm inserting these things from x 1 by 1 into my hash table. Each of those insert operations-- I'm looking up to see whether that-- an item with that key already exists in my hash table. And so I have to look down the chain to see where it is. However, if I happen to know that all of my keys are unique in my input, all the items I'm trying to store are unique, then I don't have to do that check and I can get worst case linear time. Does that make sense? All right. It's a subtlety, but that's a great question. OK, so today, instead of talking about searching, we're talking about sorting. Last week, we saw a few ways to do sort. Some of them were quadratic-- insertion sort and selection sort-- and then we had one that was n log n. And this thing, n log n, seemed pretty good, but can I do better? Can I do better? Well, what we're going to show at the beginning of this class is, in this comparison model, no. n log n is optimal. And we're going to go through the exact same line of reasoning that we had last week. So in the comparison model, what did we use when we were trying to make this argument that any comparison model algorithm was going to take at least log n time? What we did was we said, OK, I can think of any model in the comparison model-- any algorithm in the comparison model as kind of this-- some comparisons happen. They branch in a binary sense, but you could have it generalized to any constant branching factor. But for our purposes, binary's fine. And what we said was that there were at least n outputs-- really n plus 1, but-- at least order n outputs. And we showed that-- or we argued to you that the height of this tree had to be at least log n-- log the number of leaves. It had to be at least log the number of leaves. That was the height of the decision tree. And if this decision tree represented a search algorithm, I had to walk down and perform these comparisons in order, reach a leaf where I would output something. If the minimum height of any binary tree on a linear number of leaves is log n, then any algorithm in the comparison model also has to take log n time, because it has to do that many comparisons to differentiate between all possible outputs. Does that make sense? All right. So in the sort problem, how many possible outputs are there?","72.92518615722656","9","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_4_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"216","What modification can improve linked list operations at both ends?"," &&
class Edge(object): 
    def __init__(self, src, dest): 
        """"""Assumes src and dest are nodes"""""" 
        self.src = src 
        self.dest = dest 
    def getSource(self): 
        return self.src 
    def getDestination(self): 
        return self.dest 
    def __str__(self): 
        return self.src.getName() + '->’\\ 
               + self.dest.getName() 
Q>KKKMN
LQ
","72.88333129882812","10","DPRSearchEngine","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_16_pdf","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3","6.0002","3"
"217","What defines a path in a graph, and how is the length of a path measured?","There are a few corollaries to that fact. So unless there are any questions about that, we'll get started with our new unit in 6.006 which is a graph theory. If you're wondering, there's a graph on the screen here. But of course, we'll fill in a little bit more information today throughout our lecture. When I was learning how to teach, which I'm still doing, actually my PhD advisor told me if you want somebody to learn something, you have to write it as big as possible. And so I'm really leaning into that approach today in our slides. So in any event, so today we're going to have our first lecture on graphs which I think will somewhat be a review for many of you guys. And if it's not, that's cool too. Because we'll start from the beginning and kind of build up all the notions that we need to understand and process graphs and hopefully by the end of lecture, have some style of algorithm for computing the shortest path from one vertex to all the other ones.","71.02363586425781","1","DPRSearchEngine","oFVYVzlvk9c.en-j3PyPqV-e1s_2_mp4","oFVYVzlvk9c.en-j3PyPqV-e1s","6.006","9"
"217","What defines a path in a graph, and how is the length of a path measured?","Longest path is maybe a problem we've talked about in problem session, because it's a DAG-- well, longest path is the same thing as shortest path, if you just negate all the weights. There are no weights in this picture, so if you just put negative 1 on all these edges and ask for the shortest path from the base to anywhere-- so single source shortest paths from this base-- then we would end up getting this path, which, if you look at it, is E-M-P-T-Y, empty. And so that shortest path is indeed the right answer. What I've drawn here is the shortest path tree. So also, if you wanted the longest increasing subsequence starting at A, then it is A-T-Y, just by following the red arrows here. And how do you get that? You just draw the parent pointers, just like we did before.","70.35089874267578","2","DPRSearchEngine","KLBCUx1is2c.en-j3PyPqV-e1s_8_mp4","KLBCUx1is2c.en-j3PyPqV-e1s","6.006","16"
"217","What defines a path in a graph, and how is the length of a path measured?","we started talking about paths. So a path is like a chain of vertices that can get me from one vertex to the other only following edges of my graph. There is a term that I think I forgot to define last time because it didn't really matter a ton, which is a simple path, which is just a path that doesn't have the same vertex more than once. And then, of course, there are many different questions you could ask about a graph that are basically different problems involving computing paths. So for instance, the shortest path between two vertices is sort of our canonical one in graph theory. Or you could ask questions about reachability and so on. So there's our basic review from our previous lecture. Does our course staff have any questions about things so far? Excellent. OK. And there's one additional piece of terminology that I fudged a little bit last time-- or rather, my co-instructor suggested a bit of an attitude adjustment. So I thought I'd better clarify really quick. There's this interesting phrase, linear time, which we all know and love in computer science theory. And this sort of implicit thing, especially in this course, is that when we say linear time, we mean in the size of the input. Right? And so if we have a linear time graph algorithm, well, how much space does it take to store a graph? Well, we need a list of vertices and a list of edges, if nothing else. So a reasonable way to interpret this phrase linear time is that it's an algorithm that looks like what we've shown on the screen. The times proportional to maybe the sum of the number of vertices and the number of edges. If that makes you uncomfortable like it does for me because one of these can kind of scale on the other, I think it's always fine to add more detail. Right? So if you want to say, linear in the sum of the number of vertices and edges, that's perfectly fine. But if you see this phrase, that's how you should interpret it. Hopefully that's a fair way to put it. Excellent. OK.","69.57441711425781","3","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_6_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"217","What defines a path in a graph, and how is the length of a path measured?","a very non-intuitive one, where we use some prefix of the vertices. But notice, it's prefixes again-- a number of the vertices from 1 up to v. And I took a prefix of those vertices. So I just solved the problem using prefix vertices 1 through k. So it's actually a familiar idea. If all you had seen are all dynamic programming examples of prefixes, suffixes, substrings, actually, it's pretty natural way to solve shortest paths-- maybe even more natural than this. Anyway, all right. Enough shortest paths. Let's solve two more problems that are more in our standard wheelhouse that will involve sequences of inputs, not graphs.","69.46380615234375","4","DPRSearchEngine","TDo3r5M1LNo.en-j3PyPqV-e1s_9_mp4","TDo3r5M1LNo.en-j3PyPqV-e1s","6.006","17"
"217","What defines a path in a graph, and how is the length of a path measured?","Minimum Spanning Tree-- so I'm trying to find a tree connecting all of the vertices in a connected component of my graph. And I'm trying to find-- in a weighted graph, I'm trying to find the spanning tree that has minimum total weight. So that's a problem-- a fundamental problem in weighted-graph algorithms. They've solved this via a greedy algorithm. And network flows and I guess cuts. So this is-- what is this? This is, I'm given a weighted graph. Basically, each of the weights correspond to a capacity. I could push water through along this edge. And I may be given a source vertex and a sink vertex. And I want to say, I want to shove water through the source vertex along the edges with their various capacities. And I'll get some amount of water on the other end in the source. So the question is, what's the most amount of water that I can push through this? Well, I could build that pipe network with the different things and just do this experimentally. I just stick a bunch of-- maybe-- I'm a mechanical engineer, so that maybe makes sense to me. But you want to be able to just look at those numbers and be able to tell me how much water can I push through. That's what the max flow in a network is talking about.","68.8908920288086","5","DPRSearchEngine","2NMtS1ecb3o.en-j3PyPqV-e1s_7_mp4","2NMtS1ecb3o.en-j3PyPqV-e1s","6.006","20"
"217","What defines a path in a graph, and how is the length of a path measured?","It's not really complicated. Instead of having a single source, we are essentially wanting to, given an input-- this is our weighted graph, where we've got a graph V, E, and we've got a weight function from the edges to the integers. This is our general weighted graph. We want our output to be something like, the shortest path distance from u to v for every u and v in our vortex set. That's what we want to return. Now, there's one caveat here that, if there's a negative weight cycle in our graph-- in other words, if any of these delta u, v's is minus infinity,","68.70071411132812","6","DPRSearchEngine","EmSmaW-ud6A.en-j3PyPqV-e1s_2_mp4","EmSmaW-ud6A.en-j3PyPqV-e1s","6.006","14"
"217","What defines a path in a graph, and how is the length of a path measured?","is to start introducing sort of the canonical problem that we all worry about on graphs which is computing paths, in particular shortest paths. So the first thing we should do is, of course, define what a path is on a graph. So we're going to talk about our graph like a road network. Let's think of maybe every node here as an intersection. So this is a roughly Kendall Square. See it's a square. But in any event, let's say that I want to find-- maybe a question one would be does there exist a way to get from vertex 1 to vertex 3. And then a better question to ask would be does there exists a short way to get from vertex 1 to vertex 3. Then of course, the first thing I have to do is to define my enemy. I have define what I'm looking for, which is a path. So a path is nothing more than a sequence of vertices in a graph where every pair of adjacent vertices in that sequence is an edge. I think this all aligns with our intuition of what a path is in a graph. So for instance, here's a path p equals v1, v2, v3. So notice that there's an edge from v1 to v2 and also an edge from v2 to v3. So it satisfies the assumptions set forth in our definition. What would not be a path in our graph-- would be like v1 comma v3, because there's no edge there. OK, so if we talk about paths, then there's a very natural notion which is the length. Length, I guess you could think of like the number of vertices in your path minus 1, or the number of edges that your path traverses. Those are the same thing. So for instance, the length of the path p here is 2. Does everybody see that? A very common coding bug that I encounter a lot is adding 1 to that number by accident. Because of course, there's one more vertex in your path than there are edges. OK, and there are many different-- there could be potentially more than one path between any pair of vertices. So let's say that I have an undirected graph that looks like the following. So it's just a square plus a diagonal. So here are nodes. So then a perfectly valid path from the lower left to the upper right would be to go one over and one up, but of course, there's a more efficient way to get from the lower left to the upper right, which is to go across the diagonal. And so when we talk about the shortest path, it's nothing more than the length of the path that has the fewest number of edges or vertices between any pair of vertices in my graph. OK, so this is our enemy. This is what we're after. It's computing the shortest path between vertices in a graph. And this is the thing that we'll be talking about quite a bit in this course. Because of course, it's a very practical matter. Like when I want to solve routing problems, I want to move packets out of my network, I'd prefer not to-- well, unless I'm doing Tor-- I would prefer them not to hit too many computers in between. Then maybe I want a computer shortest path. Or on a surface maybe I want to move information","68.63201904296875","7","DPRSearchEngine","oFVYVzlvk9c.en-j3PyPqV-e1s_9_mp4","oFVYVzlvk9c.en-j3PyPqV-e1s","6.006","9"
"217","What defines a path in a graph, and how is the length of a path measured?","notes because I figured we'd define what a graph is first before telling you what the implications are. But in any event, I think it's really not a big stretch of the imagination to say that graphs are literally everywhere in our everyday life, right. Any time that we come up with a network of stuff connected together, implicitly the right abstraction often in the back of our heads is to think about a graph. So some simple examples that I think would all come to mind for us would be like computer networks-- so the nodes or the vertices of your graph in that case, maybe are computers, and then the edges are roughly the cables connecting them together in my very coarse understanding of how networks work-- or maybe at a social network-- the nodes are people on your social network, and the edges are friend relationships or frenemy relationships or whatever. In fact, I think you could think of both directed and undirected versions of that particular network. In road networks, maybe I'm working for Google and I want to tell you the shortest path between your house and MIT. Of course, in order to do that and essentially behind the scenes, we're solving some version of computing the shortest path between two vertices in a graph. That's a tiny bit of a lie in the sense that there's a lot of structure in that problem that we're not going to leverage in this course. A road network is a very special type of graph, and if you take an advanced course maybe you'll say, well, if I know a little more about my graph I can do better than the general case we'll talk about here. But the basic algorithms that we'll talk about in 6.006 are certainly relevant in that case and are really the building blocks for what goes on in the tools that are used every day on your phone when you open Google Maps or Ways or whatever. And of course, there's many others. So for instance, an example that maybe is a little bit more subtle would be the set of states and transitions of a discrete thing. So think about like a Rubik's cube. So I could make a graph where the node is every configuration of my Rubik's cube, like every rotation. And then the edges are like can I get from this configuration to that one by making one simple transition, like one flip. I don't actually know the terminology in Rubik's cube, I have a feeling you do, for one rotation. Twist-- thank you. And of course, there are many other places. So for instance, in my day job here at MIT","68.56283569335938","8","DPRSearchEngine","oFVYVzlvk9c.en-j3PyPqV-e1s_4_mp4","oFVYVzlvk9c.en-j3PyPqV-e1s","6.006","9"
"217","What defines a path in a graph, and how is the length of a path measured?","Well, here's a histogram of one random sample of size 100. Looks pretty different, as you might expect. Its standard deviation is 10.4, its mean 17.7. So even though the figures look a little different, in fact, the means and standard deviations are pretty similar. If we look at the population mean and the sample mean-- and I'll try and be careful to use those terms-- they're not the same. But they're in the same ballpark. And the same is true of the two standard deviations. Well, that raises the question, did we get lucky or is something we should expect? If we draw 100 random examples, should we expect them to correspond to the population as a whole? And the answer is sometimes yeah and sometimes no. And that's one of the issues I want to explore today. So one way to see whether it's a happy accident is to try it 1,000 times. We can draw 1,000 samples of size 100 and plot the results. Again, I'm not going to go over the code. There's something in that code, as well, that we haven't seen before. And that's the ax.vline plotting command. V for vertical. It just, in this case, will draw a red line-- because I've said the color is r-- at population mean on the x-axis. So just a vertical line. So that'll just show us where the mean is. If we wanted to draw a horizontal line, we'd use ax.hline. Just showing you a couple of useful functions. When we try it 1,000 times, here's what it looks like. So here we see what we had originally, same picture I showed you before. And here's what we get when we look at the means of 100 samples. So this plot on the left looks a lot more like it's a normal distribution than the one on the right. Should that surprise us, or is there a reason we should have expected that to happen? Well, what's the answer? Someone tell me why we should have expected it. It's because of the central limit theorem, right? That's exactly what the central limit theorem promised us would happen. And, sure enough, it's pretty close to normal. So that's a good thing. And now if we look at it, we can see that the mean of the sample means is 16.3, and the standard deviation of the sample means is 0.94. So if we go back to what we saw here, we see that, actually, when we run it 1,000 times and look at the means, we get very close to what we had initially. So, indeed, it's not a happy accident. It's something we can in general expect. All right, what's the 95% confidence interval here? Well, it's going to be 16.28 plus or minus 1.96 times 0.94, the standard deviation of the sample means. And so it tells us that the confidence interval is, the mean high temperature, is somewhere between 14.5 and 18.1. Well, that's actually a pretty big range, right? It's sort of enough to where you wear a sweater or where you don't wear a sweater. So the good news is it includes the population mean. That's nice. But the bad news is it's pretty wide. Suppose we wanted it tighter bound. I said, all right, sure enough, the central limit theorem is going to tell me the mean of the means is going to give me a good estimate of the actual population mean. But I want it tighter bound. What can I do? Well, let's think about a couple of things we could try. Well, one thing we could think about is drawing more samples. Suppose instead of 1,000 samples, I'd taken 2,000 or 3,000 samples. We can ask the question, would that have given me a smaller standard deviation? For those of you who have not looked ahead, what do you think? Who thinks it will give you a smaller standard deviation? Who thinks it won't? And the rest of you have either looked ahead or refused to think. I prefer to believe you looked ahead. Well, we can run the experiment. You can go to the code. And you'll see that there is a constant of 1,000, which you can easily change to 2,000. And lo and behold, the standard deviation barely budges. It got a little bit bigger, as it happens, but that's kind of an accident. It just, more or less, doesn't change. And it won't change if I go to 3,000 or 4,000 or 5,000. It'll wiggle around. But it won't help much. What we can see is doing that more often is not going to help. Suppose we take larger samples? Is that going to help? Who thinks that will help? And who thinks it won't? OK. Well, we can again run the experiment. I did run the experiment. I changed the sample size from 100 to 200. And, again, you can run this if you want. And if you run it, you'll get a result-- maybe not exactly this, but something very similar-- that, indeed, as I increase the size of the sample rather than the number of the samples, the standard deviation drops fairly dramatically, in this case from 0.94 0.66. So that's a good thing. I now want to digress a little bit before we come back to this and look at how you can visualize this-- Because this is a technique you'll want to use as you write papers and things like that-- is how do we visualize the variability of the data? And it's usually done with something called an error bar. You've all seen these things here.","67.9295654296875","9","DPRSearchEngine","soZv_KKax3E.en-qlPKC2UN_YU_5_mp4","soZv_KKax3E.en-qlPKC2UN_YU","6.0002","8"
"217","What defines a path in a graph, and how is the length of a path measured?","[SQUEAKING] [RUSTLING] [CLICKING] JASON KU: Hi, everyone. Welcome to the 11th lecture of 6.006, our first lecture on weighted shortest paths. Until now, we've only been talking about graphs that-- where we measure distance in terms of the number of edges in a path. Today, we're going to generalize that notion. But I just want to go over what we've talked about in the last two lectures. In the last two lectures, we've talked about two algorithms, breadth-first search and depth-first search to solve a range of problems. Here's some of the problems that we've been solving. Single-source shortest paths, where distances are measured in number of edges in a path. And we used BFS to solve this problem, starting from a single source, usually a vertex s that we call. And we solve that in linear time. And we solve that in order v plus e. That's what we called linear time for a graph. For the special case of single-source reachability, here we had to return a shortest path distance for every vertex. And there was, at most, E things reachable from a vertex. So this is the bound we got. But in the special case for single-source reachability, when our output only has to list the vertices that are reachable from me, the number of things reachable in basically a spanning tree of the connected component of my source can almost be of order E. And so for all the little singleton vertices in my graph, I don't really care. So I can get this in order E, but that's kind of a little optimization.","67.84489440917969","10","DPRSearchEngine","5cF5Bgv59Sc.en-j3PyPqV-e1s_1_mp4","5cF5Bgv59Sc.en-j3PyPqV-e1s","6.006","11"
"218","What is the significance of ensuring that the parameter ai is only considered an option when ai is less than or equal to t in the subset sum dynamic programming approach?","  
 
  
 
 
  
 
  
 
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
  
 
 
   
-
Review: Probabilistic TMs and BPP 
coin flip step 
each choice has 
Defn: A probabilistic Turing machine (PTM) is a variant of a NTM 
where each computation step has 1 or 2 possible choices. 
deterministic 
step 
50% probability 
Defn: For ! ≥0 say PTM $  decides language % with error probability !  
if for every &, Pr[ $  gives the wrong answer about & ∈% ] ≤! . 
Defn: BPP = % some poly-time PTM decides % with error !  = +⁄,  } Check-in 24.1 
Actually using a probabilistic algorithm 
Amplification lemma: 2−. /01 2 
presupposes a source of randomness. 
Can we use a standard pseudo-random 
number generator (PRG) as the source? 
& ∈% 
& ∉% 
(a) Yes, but the result isn’t guaranteed.
(b) Yes, but it will run in exponential time.
Many 
Few 
Few 
Many 
(c) No, a TM cannot implement a PRG. 
accepting 
rejecting 
accepting 
rejecting 
(d) No, because that would show P = BPP.
2 
Check-in 24.1 
","75.85685729980469","1","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_2_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"218","What is the significance of ensuring that the parameter ai is only considered an option when ai is less than or equal to t in the subset sum dynamic programming approach?",";
/
def testGreedys(maxUnits):
print('Use greedy by value to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits, Food.getValue)
print('\\nUse greedy by cost to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits,
lambda x: 1/Food.getCost(x))
print('\\nUse greedy by density to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits, Food.density)
testGreedys(800)
	


4
","75.1224594116211","2","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_26_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"218","What is the significance of ensuring that the parameter ai is only considered an option when ai is less than or equal to t in the subset sum dynamic programming approach?",";
/
def testGreedy(items, constraint, keyFunction):
taken, val = greedy(items, constraint, keyFunction)
print('Total value of items taken =', val)
for item in taken:
print('   ', item)
	

'
","73.61088562011719","3","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_25_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"218","What is the significance of ensuring that the parameter ai is only considered an option when ai is less than or equal to t in the subset sum dynamic programming approach?"," 
  
 
 
  
  
 
 
 
 
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Probabilistic TMs 
Defn: A probabilistic Turing machine (PTM) is a variant of a NTM 
where each computation step has 1 or 2 possible choices. 
deterministic 
coin flip step ­
step 
each choice has 50% probability 
Pr[ branch ! ] = 2&' where ! has ( coin flips 
Pr[ "" accepts # ] = + Pr[ branch ! ] 
Pr[ "" rejects # ] = 1 − Pr[ "" accepts # ] 
b accepts 
computation tree 
for "" on # 
branch ! 
Defn: For 7 ≥0 say PTM "" decides language : with error probability 7 
if for every #, Pr[ "" gives the wrong answer about # ∈: ] ≤7 
i.e., # ∈: → Pr[ "" rejects # ] ≤7 
# ∉: → Pr[ "" accepts # ] ≤7. 
2 
","73.56226348876953","4","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_2_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"218","What is the significance of ensuring that the parameter ai is only considered an option when ai is less than or equal to t in the subset sum dynamic programming approach?"," 
 
 
   
 
 
 
   
   
      
 
 
 
 
 
 
  
 
Stochastic Processes  
An ongoing process where the next state might depend on 
both the previous states and some random element 
def rollDie(): 
"""""" returns an int between 1 and 6"""""" 
def rollDie(): 
"""""" returns a randomly chosen int 
between 1 and 6"""""" 
6.0002 LECTURE 4 
8
","73.23585510253906","5","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_8_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"218","What is the significance of ensuring that the parameter ai is only considered an option when ai is less than or equal to t in the subset sum dynamic programming approach?"," 
  
 
  
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
   
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
    
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
PDA – Formal Definition 
Defn: A Pushdown Automaton (PDA) is a 6-tuple ("", Σ, Γ, &, '0, )) 
Σ input alphabet 
Γ stack alphabet 
&: Q×Σ.×Γ. → 0(""×Γ.) 
Accept if some thread is in the accept state 
& ', a, c = 
45, d , 47, e 
at the end of the input string. 
Example: PDA for 9 = {;;ℛ| ; ∈ 0,1 ∗} Sample input: 
0 1 1 1 1 0 
1) Read and push input symbols. 
Nondeterministically either repeat or go to (2). 
The nondeterministic forks replicate the stack. 
2) Read input symbols and pop stack symbols, compare. 
If ever ≠ then thread rejects. 
This language requires nondeterminism. 
Our PDA model is nondeterministic. 
3) Enter accept state if stack is empty. (do in “software”) 
7 
","72.99893951416016","6","DPRSearchEngine","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_7_pdf","a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4","18.404J","4"
"218","What is the significance of ensuring that the parameter ai is only considered an option when ai is less than or equal to t in the subset sum dynamic programming approach?","Defn:  BPP = "" some poly-time PTM decides "" with error # = ⁄
% & }
Amplification lemma: If '% is a poly-time PTM with error #% < ⁄
% ) then, 
for any 0 < #) < ⁄
% ), there is an equivalent poly-time PTM ') with error #).  
Can strengthen to make #) < 2−,-./ 0 . 
Proof idea:  ') = “On input 1
1.  Run '% on 1 for 2 times and output the majority response.”
Details:  Calculation to obtain 2 and the improved error probability. 
Significance:  Can make the error probability so small it is negligible.
The Class BPP
3
","72.85967254638672","7","DPRSearchEngine","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_3_pdf","44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23","18.404J","23"
"218","What is the significance of ensuring that the parameter ai is only considered an option when ai is less than or equal to t in the subset sum dynamic programming approach?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","72.84947204589844","8","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"218","What is the significance of ensuring that the parameter ai is only considered an option when ai is less than or equal to t in the subset sum dynamic programming approach?"," 
 
  
  
  
 
 
  
       
   
 
 
 
 
 
 
  
 
 
 
  
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
  
 
 
 
  
 
 
   
 
 
   
 
 
 
 
   
 
 
 
 
 
 
 
 
    
 
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
  
 
TM – Formal Definition 
Defn: A Turing Machine (TM) is a 7-tuple ("", Σ, Γ, &, '(, 'acc , 'rej)
Σ input alphabet 
Γ tape alphabet (Σ ⊆Γ)
&: Q×Γ → ""×Γ× {L, R} 
(L = Left, R = Right) 
& ', a = (5, b, R) 
On input 6 a TM 7 may halt (enter 'acc or 'rej) 
Check-in 5.3 
or 7 may run forever (“loop”). 
This Turing machine model is deterministic. 
So 7 has 3 possible outcomes for each input 6: 
How would we change it to be nondeterministic? 
1. Accept 6 (enter 'acc ) 
a) Add a second transition function. 
2. Reject 6 by halting (enter 'rej ) 
b) Change & to be &: Q×Γ → 8( ""×Γ× {L, R} ) 
3. Reject 6 by looping (running forever) 
c) Change the tape alphabet Γ to be infinite. 
10 
Check-in 5.3 
","72.73773956298828","9","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_10_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"218","What is the significance of ensuring that the parameter ai is only considered an option when ai is less than or equal to t in the subset sum dynamic programming approach?"," 
 
 
 
 
 
   
  
 
  
 
 
   
 
 
  
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
  
 
 
 
 
 
 
Check-in 8.2 
Recall the Queue Automaton (QA) defined in Pset 2. 
It is similar to a PDA except that it is deterministic 
and it has a queue instead of a stack. 
Let !QA = { &, ( | & is a QA and & accepts (} 
Is !QA decidable? 
(a) Yes, because QA are similar to PDA and !PDA is decidable. 
(b) No, because “yes” would contradict results we now know. 
(c) We don’t have enough information to answer this question. 
8 
Check-in 8.2 
","72.68067169189453","10","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_8_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"219","What is the role of the changeable priority queue in Dijkstra's algorithm?","So what is the running time of Dijkstra? If I take a look at that algorithm over there-- well I guess let's switch these back up again. OK, so what does this do? We build once. Then we delete the minimum from the Q how many times? v times. We remove every vertex from our Q. Then for every possible edge, we may need to relax and decrease the key in our queue once for every outgoing edge. So the running time is B plus V times M plus E times D. OK. So how could we implement this priority queue? Well, if we use the stupidest priority queue in the world, here's a list of different implementations we could have for our priority queues. And when I say priority queue, I mean this priority queue. We're already implementing the changeable priority queue by linking it with a dictionary that's efficient If I just use an array, I can find the min in linear time, sure. And I don't have to update that array in any way. I mean, I can just keep the distances in my direct access array. I don't have to store a separate data structure. I just store the distances in my direct access array D, and so I can find it in constant time and I can update the values stored there. And then whenever I want the minimum, I can just loop through the whole thing. So that gives me a really fast decrease key,","75.37764739990234","1","DPRSearchEngine","NSHizBK9JD8.en-j3PyPqV-e1s_6_mp4","NSHizBK9JD8.en-j3PyPqV-e1s","6.006","13"
"219","What is the role of the changeable priority queue in Dijkstra's algorithm?","But the basic idea behind Dijkstra is the following idea. Relaxed edges from vertices in increasing distance from source. OK. This is the same kind of difficulty we had before when we were trying to generalize BFS. So how do we know what the next vertex is with increasing distance to s? Well, the second idea is find the next vertex efficiently using a data structure. And the data structure we're going to use is something I like to call a changeable priority queue. So this is a little different than a normal priority queue that we had at the end of our data structures unit. This changeable priority queue has three operations. We're going to say it's a queue. We can build it on an iterable set of items. Just stick x-- like n items in there. We can delete min from the queue. OK, this is the same now as the priority queue. It's this third operation that's going to be different. Decrease the key of an item that has id, id. OK, so this is a little strange. What the heck is this id? All right, with a change of priority queue, each of our items has two values instead of one value. It has a key, but it also-- on which the priority queue is leading the min item with the minimum key. But also, each item has an ID associated with it, a unique integer. So that when we perform this operation, decrease_key, it can find some item in our data structure with the given ID. And if it's contained there, it's going to change its key to some smaller value k. And don't worry about the edge cases here. We're always going to make sure this k is going to be smaller then whatever that key was to begin with. So this is really a kind of a funky operation. If I had a priority queue, not a changeable priority queue,","74.41492462158203","2","DPRSearchEngine","NSHizBK9JD8.en-j3PyPqV-e1s_2_mp4","NSHizBK9JD8.en-j3PyPqV-e1s","6.006","13"
"219","What is the role of the changeable priority queue in Dijkstra's algorithm?"," 
 
 
 
 
 
   
  
 
  
 
 
   
 
 
  
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
  
 
 
 
 
 
 
Check-in 8.2 
Recall the Queue Automaton (QA) defined in Pset 2. 
It is similar to a PDA except that it is deterministic 
and it has a queue instead of a stack. 
Let !QA = { &, ( | & is a QA and & accepts (} 
Is !QA decidable? 
(a) Yes, because QA are similar to PDA and !PDA is decidable. 
(b) No, because “yes” would contradict results we now know. 
(c) We don’t have enough information to answer this question. 
8 
Check-in 8.2 
","73.96395874023438","3","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_8_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"219","What is the role of the changeable priority queue in Dijkstra's algorithm?"," 
 
 
   
 
 
 
   
   
      
 
 
 
 
 
 
  
 
Stochastic Processes  
An ongoing process where the next state might depend on 
both the previous states and some random element 
def rollDie(): 
"""""" returns an int between 1 and 6"""""" 
def rollDie(): 
"""""" returns a randomly chosen int 
between 1 and 6"""""" 
6.0002 LECTURE 4 
8
","73.73883056640625","4","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_8_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"219","What is the role of the changeable priority queue in Dijkstra's algorithm?","to implement a change of priority queue, how could I do it? Well, a regular priority queue is already going to get me these two operations. It's just this one. I essentially need to find something by an ID and then update its key. So the idea how to implement this is going to be to use a regular priority queue. I'm going to call it Q prime. And I'm going to cross-link it with a dictionary D. So these are just regular priority queue on my items that has the key as defined above. But I'm going to cross-link it with a dictionary, a dictionary that maps IDs to their location in the priority queue. We've done this many times in the data structures section. We're trying to cross link to data structures to make a query on a different type of key to find its place in another data structure. So, if we had a priority a dictionary, we could do this stuff pretty fast. In particular, I'm going to assume that our IDs of our vertices are the integers between 0 and v minus 1. And so for my dictionary, I could get constant time looking up of that ID by using what data structure? AUDIENCE: Hash table. JASON KU: We could get-- OK, so we could get expected constant time if we used a hash table. But if we knew that our vertex IDs were just the numbers from 0 to v minus 1, we could get rid of that expected time by using a direct access array. Great. OK, so that's the assumption. And so really, the name of the game here is to choose a priority queue here that's going to make these things fast when we start to look at Dijkstra. OK, so we're going to use this data structure to keep track of our distance estimates","73.23025512695312","5","DPRSearchEngine","NSHizBK9JD8.en-j3PyPqV-e1s_3_mp4","NSHizBK9JD8.en-j3PyPqV-e1s","6.006","13"
"219","What is the role of the changeable priority queue in Dijkstra's algorithm?"," 
 
 
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
  
 
  
 
  
 
 
  
 
 
   
 
 
   
 
 
 
 
TMs and Encodings – review 
A TM has 3 possible outcomes for each input !: 
1. Accept ! (enter ""acc ) 
2. Reject ! by halting (enter ""rej ) 
3. Reject ! by looping (running forever) 
( is T-recognizable if ( = *(,) for some TM ,. 
( is T-decidable if ( = *(,) for some TM decider ,. 
halts on all inputs 
〈/0, /2, … , /4〉 encodes objects /0, /2, … , /4 as a single string. 
Notation for writing a TM , is 
, = “On input ! 
[English description of the algorithm]” 
2 
","73.22561645507812","6","DPRSearchEngine","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_2_pdf","78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7","18.404J","7"
"219","What is the role of the changeable priority queue in Dijkstra's algorithm?","And this is a subset of the set interface. And subsets are interesting because, potentially, we can solve them better, faster, simpler, something. And so you'll recognize-- you should recognize all of these operations, except we didn't normally highlight the max operation. So here, we're interested in storing a bunch of items. They have keys which we think of as priorities. And we want to be able to identify the maximum priority item in our set and remove it. And so there's lots of motivations for this. Maybe you have a router, packets going into the router. They have different priorities assigned to them. You want to route the highest priority first. Or you have processes on your computer trying to run on your single threaded-- single core, and you've got to choose which one to run next. And you usually run higher priority processes first. Or you're trying to simulate a system where events happen at different times, and you want to process the next event ordered by time. All of these are examples of the priority queue interface. We'll even see applications within this class when we get to graph algorithms. But the main two things we want to be able to support are inserting an item, which includes a key, and leading the maximum item, and also returning it at the same time. We'll also talk some about being able to build the structure faster than just inserting it. But of course, we could implement build by starting empty and repeatedly inserting. And also the complexity of just finding the max without deleting it, this you could simulate with these two operations by deleting the max and then reinserting it, which works. But often, we can do faster. But the two key, main operations are insert and delete max. And we're going to see a few data structures to do this. Any suggestions among the data structures we've seen in this class? What should we use to solve priority queue interface? Many possible answers.","72.67799377441406","7","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_2_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"219","What is the role of the changeable priority queue in Dijkstra's algorithm?","OK, so this is Dijkstra's algorithm. OK. Set-- so same initialization step. We're going to set-- this is a distance estimate d, not delta. We're going to want the d's be our delta is at the end of the algorithm. That's what we're going to have to prove. So we first set all of them to infinity, and then set d of s, s equal to 0. And here, we're never going to update it again, because our shortest distance is in a graph with non-negative edge weights certainly can't go below 0. All right. Now we build our-- build our changeable priority queue-- queue-- with an item-- I'm going to say an item is-- x is represented by a tuple of its ID, and then its key just for brevity here. With an item v, d of s, v. So I'm going to be storing in my changeable priority queue the vertex label and its shortest-path distance estimate d. And that's going to be the key, the minimum that I'm trying going to be querying on for each the v and V. So I'm going to build that thing. It's going to then have all of my vertices in my graph. Then while my changeable priority queue still has items, not empty, I'm going to delete some u, d s, u. So some item such that its distance is minimized from Q that has minimum distance. OK. So I'm going to I'm going to look at all the things in my priority queue. At the start it's just going to be s, because everything as shortest-path distance estimate infinite except for s. And so that's clearly the smallest. OK, so I'm going to remove that from my queue, and then I'm going to process it. How am I going to process it? It's the exact same kind of thing as DAG relaxation. I'm going to relax all its outgoing edges. So just for completeness for v in the outgoing adjacencies of u, I'm going to relax-- sorry. We have to check whether we can relax it. Basically if the shortest-path distance estimate to v is greater than going to u first and then crossing that edge, if going through that is better, this is violating our triangle inequality. And so we relax edge u, v, and by that we mean set this thing to be equal to that thing. That's what we meant by relax. And then we have one other thing to do. We have changed these distance estimates but our Q doesn't know that we change these things. We added these items in here. But it doesn't know that my distances have changed. So we to tell the Q to remember to change its key value associated with the item v. So decrease-- what is it? Decrease key vertex v in Q to the new d s, v, the one that I just decreased here. And I know that I decreased it because I said it to a smaller value. That makes sense. All right, so that's Dijkstra. Let's run it on an example. So here's an example. I have a directed graph. It does contain cycles. In particular, here are some cycles. I think those are the main ones. There are definitely cycles in this graph. But as you see, all of the weights are non-negative, in particular-- they're positive, actually. It's going to be just helpful in writing out this example. So let's run Dijkstra on this graph. First we initialize and we set the shortest-path distance. I'm going to label it in white here to all of the things. Then I'm going to, as I update it, I'm just going to cross them out and write a new number. So that's what it is at the start. That's initialization, that's after step 1. And then I stick things into my Q. What's in my Q? Here's my Q. It's everything. It's vertices s, a, b, c, d. I got five items in my Q. Really, it's the item pair with its shortest distance estimate, I'm just not going to rewrite that here. So the idea here is-- the while loop, OK. Q is not empty, great. We're going to delete the one with the smallest distance estimate, which is s, right, yeah. So I remove that, and then I relax edges out of s. So I relax edge here to a. That's better than the distance estimate-- 10 is better than the distance estimate infinite, so I'm going to change this to 10. And then here's another outgoing edge. 3 is better than infinite, so I'm going to change its delta to 3. OK. So now I go back in here and I change the distance estimates associated with my Q. Now, next step of the algorithm, s is done. I've processed everything distance 0 away. But I'm now going to use my priority queue to say which of my vertices has the shortest distance estimate now. So which one is it? a, b, or c, or d? Yeah, it's 3 and c. 3 is smaller than 10. So Q is going to magically delete c for me, tell me what that is, and now I'm going to process that. Now I've changed my boundary to this. And now I relax edges out of c. So here's an edge at a c, that's a 4. A 4 plus the 3 is smaller than 10, so I update it. 3 plus 8 is 11, that's smaller than infinite, so I update it, I relax. 3 plus 2 is smaller than infinite, so I relax that as well. Now of the things still left in my Q, I'm actually going to remove it from my Q instead of crossing it out, maybe that's better. Of the vertices still left in my Q, which has smallest distance? Yeah. d. d has 5, 7, or 11. 5 is the smallest. So I remove d from my cue and I relax edges from it. And now my boundary looks something like this. I relax edges out of it. 5 plus 5, that's 10. 10 is smaller than 11, so that's a 10. And that's the only outgoing edge from d. so I'm done. And then the last, 7 is smaller than 10, I relax edges out of a. a to b, 7 plus 2 is smaller than 10. And now I'm done. So what I did every time I removed s-- or I removed a vertex, I said its shortest-path distance to the small-- the last value I assigned to it. So this was then 3, and then a was 7, b was 9, and then d was 5. So that's Dijkstra in action. It seems like these are the shortest-path distances, but how do we prove that? Did it do the right thing? Well, let's find out.","72.58811950683594","8","DPRSearchEngine","NSHizBK9JD8.en-j3PyPqV-e1s_4_mp4","NSHizBK9JD8.en-j3PyPqV-e1s","6.006","13"
"219","What is the role of the changeable priority queue in Dijkstra's algorithm?","4 
Lecture 1: Introduction 
1 
def birthday_match(students): 
2 
’’’ 
3 
Find a pair of students with the same birthday 
4 
Input: 
tuple of student (name, bday) tuples 
5 
Output: tuple of student names or None 
6 
’’’ 
7 
n = len(students) 
# O(1) 
8 
record = StaticArray(n) 
# O(n) 
9 
for k in range(n): 
# n 
10 
(name1, bday1) = students[k] 
# O(1) 
11 
# Return pair if bday1 in record 
12 
for i in range(k): 
# k 
13 
(name2, bday2) = record.get_at(i) 
# O(1) 
14 
if bday1 == bday2: 
# O(1) 
15 
return (name1, name2) 
# O(1) 
16 
record.set_at(k, (name1, bday1)) 
# O(1) 
17 
return None 
# O(1) 
Example: Running Time Analysis 
• Two loops: outer k ∈{0, . . . , n − 1}, inner is i ∈{0, . . . , k}
P n−1
• Running time is O(n) + 
k=0 (O(1) + k · O(1)) = O(n2) 
• Quadratic in n is polynomial. Efﬁcient? Use different data structure for record! 
How to Solve an Algorithms Problem 
1. Reduce to a problem you already know (use data structure or algorithm) 
Search Problem (Data Structures) 
Sort Algorithms 
Static Array (L01) 
Insertion Sort (L03) 
Linked List (L02) 
Selection Sort (L03) 
Dynamic Array (L02) 
Merge Sort (L03) 
Sorted Array (L03) 
Counting Sort (L05) 
Direct-Access Array (L04) 
Radix Sort (L05) 
Hash Table (L04) 
AVL Sort (L07) 
Balanced Binary Tree (L06-L07) 
Heap Sort (L08) 
Binary Heap (L08) 
2. Design your own (recursive) algorithm 
• Brute Force 
• Decrease and Conquer 
• Divide and Conquer 
• Dynamic Programming (L15-L19) 
• Greedy / Incremental 
Shortest Path Algorithms 
Breadth First Search (L09) 
DAG Relaxation (L11) 
Depth First Search (L10) 
Topological Sort (L10) 
Bellman-Ford (L12) 
Dijkstra (L13) 
Johnson (L14) 
Floyd-Warshall (L18) 
","72.43375396728516","9","DPRSearchEngine","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_4_pdf","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1","6.006","1"
"219","What is the role of the changeable priority queue in Dijkstra's algorithm?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","72.42756652832031","10","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"220","How does Johnson's Algorithm ensure that shortest paths are maintained when reweighting edges in a graph?"," 
 
 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) 
General Unweighted 
BFS 
|V | + |E|
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Non-negative Dijkstra 
Bellman-Ford 
|V | log |V | + |E|
General Any 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 14: Johnson’s Algorithm 
Lecture 14: Johnson’s Algorithm 
Previously 
|V | · |E| 
All-Pairs Shortest Paths (APSP) 
• Input: directed graph G = (V, E) with weights w : E → Z 
• Output: δ(u, v) for all u, v ∈ V , or abort if G contains negative-weight cycle 
• Useful when understanding whole network, e.g., transportation, circuit layout, supply chains... 
• Just doing a SSSP algorithm |V | times is actually pretty good, since output has size O(|V |2) 
– |V | · O(|V | + |E|) with BFS if weights positive and bounded by O(|V | + |E|) 
– |V | · O(|V | + |E|) with DAG Relaxation if acyclic 
– |V | · O(|V | log |V | + |E|) with Dijkstra if weights non-negative or graph undirected 
– |V | · O(|V | · |E|) with Bellman-Ford (general) 
• Today: Solve APSP in any weighted graph in |V | · O(|V | log |V | + |E|) time 
","75.22888946533203","1","DPRSearchEngine","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14_1_pdf","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14","6.006","14"
"220","How does Johnson's Algorithm ensure that shortest paths are maintained when reweighting edges in a graph?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","73.47454833984375","2","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"220","How does Johnson's Algorithm ensure that shortest paths are maintained when reweighting edges in a graph?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","72.64969635009766","3","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"220","How does Johnson's Algorithm ensure that shortest paths are maintained when reweighting edges in a graph?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 11: Weighted Shortest Paths 
Lecture 11: Weighted Shortest Paths 
Review 
• Single-Source Shortest Paths with BFS in O(|V | + |E|) time (return distance per vertex) 
• Single-Source Reachability with BFS or DFS in O(|E|) time (return only reachable vertices) 
• Connected components with Full-BFS or Full-DFS in O(|V | + |E|) time 
• Topological Sort of a DAG with Full-DFS in O(|V | + |E|) time 
• Previously: distance = number of edges in path Today: generalize meaning of distance 
Weighted Graphs 
• A weighted graph is a graph G = (V, E) together with a weight function w : E → Z 
• i.e., assigns each edge e = (u, v) ∈ E an integer weight: w(e) = w(u, v) 
• Many applications for edge weights in a graph: 
– distances in road network 
– latency in network connections 
– strength of a relationship in a social network 
• Two common ways to represent weights computationally: 
– Inside graph representation: store edge weight with each vertex in adjacency lists 
– Store separate Set data structure mapping each edge to its weight 
• We assume a representation that allows querying the weight of an edge in O(1) time 
Examples 
G1 
G2 
a 
e 
b 
f 
c 
g 
d 
h 
6 
8 
−2 
5 
9 
−5 
7 
3 
2 
−1 
−4 
1 
4 
a 
e 
b 
f 
c 
g 
d 
h 
6 
8 
−2 
5 
9 
−5 
7 
3 
2 
−1 
−4 
1 
4 
","71.91471099853516","4","DPRSearchEngine","aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11_1_pdf","aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11","6.006","11"
"220","How does Johnson's Algorithm ensure that shortest paths are maintained when reweighting edges in a graph?","§ Time based on number of nodes generated 
§ Number of levels is number of items to choose from 
§ Number of nodes at level i is 2i 
§ So, if there are n items the number of nodes is 
◦ ∑𝑖=0↑𝑖=𝑛▒​2↑𝑖   
◦ I.e., O(​2↑𝑛+1 ) 
§ An obvious op<miza<on: don’t explore parts of tree 
that violate constraint (e.g., too many calories) 
◦ Doesn’t change complexity 
§ Does this mean that brute force is never useful? 
◦ Let’s give it a try 
Computa#onal Complexity 
6.0002 LECTURE 2 
8 
","71.89517974853516","5","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_8_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"220","How does Johnson's Algorithm ensure that shortest paths are maintained when reweighting edges in a graph?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","71.8645248413086","6","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"220","How does Johnson's Algorithm ensure that shortest paths are maintained when reweighting edges in a graph?","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","71.5274429321289","7","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"220","How does Johnson's Algorithm ensure that shortest paths are maintained when reweighting edges in a graph?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 10: Depth-First Search 
Lecture 10: Depth-First Search 
Previously 
• Graph deﬁnitions (directed/undirected, simple, neighbors, degree) 
• Graph representations (Set mapping vertices to adjacency lists) 
• Paths and simple paths, path length, distance, shortest path 
• Graph Path Problems 
– Single Pair Reachability(G,s,t) 
– Single Source Reachability(G,s) 
– Single Pair Shortest Path(G,s,t) 
– Single Source Shortest Paths(G,s) (SSSP) 
• Breadth-First Search (BFS) 
– algorithm that solves Single Source Shortest Paths 
– with appropriate data structures, runs in O(|V | + |E|) time (linear in input size) 
Examples 
G1 
a 
d 
b 
e 
c 
f 
G2 
a 
d 
b 
e 
c 
f 
","71.41238403320312","8","DPRSearchEngine","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10_1_pdf","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10","6.006","10"
"220","How does Johnson's Algorithm ensure that shortest paths are maintained when reweighting edges in a graph?","§ Given remaining weight, maximize value by choosing 
among remaining items 
§ Set of previously chosen items, or even value of that 
set, doesn’t mafer! 
What Problem is Solved at Each Node? 
6.0002 LECTURE 2 
26 
","71.31133270263672","9","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_26_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"220","How does Johnson's Algorithm ensure that shortest paths are maintained when reweighting edges in a graph?","[SQUEAKING][RUSTLING][CLICKING] JASON KU: Welcome, everybody, to our lecture 14 of 6.006. This is our last lecture on graph algorithms, in particular, the last lecture we'll have on weighted shortest paths. But we're going to talk about a slightly different problem today, different than single source shortest paths. We're going to be talking about all-pairs shortest paths. But first, let's review our single source shortest paths algorithms. We had BFS, DAG relaxation, Dijkstra, which we saw last time, which gets pretty close to linear. V log V plus E is pretty close to linear. It's much closer to linear than the general algorithm we have for solving single source shortest paths, namely, Bellman-Ford, which is a little bit more like quadratic. This is like the difference between-- for sparse graphs, this is like the difference between sorting, using insertion sort and n squared, and merge sort in N log N, for example. We're going to get actually quite a big bonus for large input sizes by using Dijkstra when we can. Today, we're going to be focusing","71.01925659179688","10","DPRSearchEngine","EmSmaW-ud6A.en-j3PyPqV-e1s_1_mp4","EmSmaW-ud6A.en-j3PyPqV-e1s","6.006","14"
"221","What does the process of 'relaxing an edge' achieve in a weighted shortest path algorithm?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","77.79852294921875","1","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"221","What does the process of 'relaxing an edge' achieve in a weighted shortest path algorithm?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","75.34317016601562","2","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"221","What does the process of 'relaxing an edge' achieve in a weighted shortest path algorithm?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 11: Weighted Shortest Paths 
Lecture 11: Weighted Shortest Paths 
Review 
• Single-Source Shortest Paths with BFS in O(|V | + |E|) time (return distance per vertex) 
• Single-Source Reachability with BFS or DFS in O(|E|) time (return only reachable vertices) 
• Connected components with Full-BFS or Full-DFS in O(|V | + |E|) time 
• Topological Sort of a DAG with Full-DFS in O(|V | + |E|) time 
• Previously: distance = number of edges in path Today: generalize meaning of distance 
Weighted Graphs 
• A weighted graph is a graph G = (V, E) together with a weight function w : E → Z 
• i.e., assigns each edge e = (u, v) ∈ E an integer weight: w(e) = w(u, v) 
• Many applications for edge weights in a graph: 
– distances in road network 
– latency in network connections 
– strength of a relationship in a social network 
• Two common ways to represent weights computationally: 
– Inside graph representation: store edge weight with each vertex in adjacency lists 
– Store separate Set data structure mapping each edge to its weight 
• We assume a representation that allows querying the weight of an edge in O(1) time 
Examples 
G1 
G2 
a 
e 
b 
f 
c 
g 
d 
h 
6 
8 
−2 
5 
9 
−5 
7 
3 
2 
−1 
−4 
1 
4 
a 
e 
b 
f 
c 
g 
d 
h 
6 
8 
−2 
5 
9 
−5 
7 
3 
2 
−1 
−4 
1 
4 
","74.7480697631836","3","DPRSearchEngine","aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11_1_pdf","aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11","6.006","11"
"221","What does the process of 'relaxing an edge' achieve in a weighted shortest path algorithm?"," 
 
 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) 
General Unweighted 
BFS 
|V | + |E|
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Non-negative Dijkstra 
Bellman-Ford 
|V | log |V | + |E|
General Any 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 14: Johnson’s Algorithm 
Lecture 14: Johnson’s Algorithm 
Previously 
|V | · |E| 
All-Pairs Shortest Paths (APSP) 
• Input: directed graph G = (V, E) with weights w : E → Z 
• Output: δ(u, v) for all u, v ∈ V , or abort if G contains negative-weight cycle 
• Useful when understanding whole network, e.g., transportation, circuit layout, supply chains... 
• Just doing a SSSP algorithm |V | times is actually pretty good, since output has size O(|V |2) 
– |V | · O(|V | + |E|) with BFS if weights positive and bounded by O(|V | + |E|) 
– |V | · O(|V | + |E|) with DAG Relaxation if acyclic 
– |V | · O(|V | log |V | + |E|) with Dijkstra if weights non-negative or graph undirected 
– |V | · O(|V | · |E|) with Bellman-Ford (general) 
• Today: Solve APSP in any weighted graph in |V | · O(|V | log |V | + |E|) time 
","73.30416870117188","4","DPRSearchEngine","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14_1_pdf","7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14","6.006","14"
"221","What does the process of 'relaxing an edge' achieve in a weighted shortest path algorithm?","[SQUEAKING] [RUSTLING] [CLICKING] JASON KU: Good morning, everyone. Welcome to the 13th lecture of 6.006. Just to recap from last time, we've been talking about shortest-- single source shortest paths on weighted graphs for the past two lectures. Previously we were only talking about unweighted graphs. And so far, up until today, we've talked about three ways to solve single source shortest paths on weighted graphs. Namely the first one used BFS. If you can kind of transform your graph into a linear-sized graph that's unweighted that corresponds to your weighted problem, essentially replacing each weighted edge with of weight w with w single edges. Now that's only good for positive weight things and if the sum of your weights are small. But if the sum of your weights is linear in the combinatorial size of your graph, V plus E, then we can get a linear time algorithm to solve weighted shortest paths using breadth-first search. Then we talked about how we could-- if we-- the problem with weighted shortest paths is if our weights were negative and there could exist cycles, then we could have negative weight cycles and that would be more difficult to handle, because then you have vertices where you have an unbounded number of edges you might have to go through for a shortest path. There might not be a finite length shortest path. But in the condition where we didn't have cycles in the graph-- of course, we couldn't have negative weight ones, so we were also able to do that in linear time by exploiting the fact that our vertices could be ordered in a topological order, and then we could kind of push shortest path information from the furthest one back to the ones forward. By relaxing edges forward. By maintaining this invariant that we had shortest paths as we were processing these things in topological order. Then last time, we were talking about general graphs, graphs that could contain cycles, and this is our most general algorithm, because if there are negative weight cycles, Bellman-Ford, which we talked about last time, can detect them. And in particular, for any vertex that had a finite weight shortest paths-- path, we could compute that shortest path for it, compute its distance. And for any one that is reachable from a negative weight cycle, not only could we mark it as minus infinity distance, but we could also find a negative weight cycle essentially by duplicating our graph to make it a DAG and being able to follow pointers back in this expanded DAG that had multiple layers. So that's what we've done up until now. We've gotten linear for some types of graphs. And we've gotten kind of quadratic V times E for general graphs, ones that could contain negative cycles. Now how bad is this? Well, if the graph is sparse, if the number of edges in our graph is on the order of V, then this is quadratic time and V, V squared. But if the graph is dense where we have quadratic-- like the complete graph where every edge is present, then we have quadratically many edges in our graph in V. And so this running time is V cubed. V cube's not great in terms of its running time. We would like something closer to linear. And so that's what we're going to do today. If we have this restriction where we have non-negative weights, we can have negative weight cycles. And this is a restriction that comes up a lot for many graphs you might encounter. A lot of times you don't have both positive and negative weight. I don't have a negative distance to my house. In any metric we have non-negative weights. So these things come up a lot, and we can actually do quite a bit better, since there are no negative weight cycles, we can get almost linear. It's not going to be quite V plus E as you see up here on the slide. We're going to get something very close. It's V plus the E, but on the V term, we have this logarithmic factor in V. Which remember for all intents and purposes, this log of that thing in real life is not going to be bigger than like a factor of 30 or something like that. Maybe 60. But it's a small number. And so this is actually pretty good performance. It's almost linear-- that's what I'm saying almost linear here, and that's what we're going to try to do today. So, how do we do this? Well, I'm going to make two observations here, first off. Our idea is going to be to generalize the notion of BFS. When we had BFS, we split up our graph-- to solve unweighted-- solve weighted shortest paths in BFS, we could take our positive edge weights, break them up into individual edges. But if the total weight of our edges was large, then we'd have a problem, because now we've expanded the size of our graph. This is the same issue that we had with something like radix sort where we don't want our algorithm to run in the size of the numbers in our input, we want our algorithm to run in the number of numbers in our input. This is the difference between N and U back when we were talking about data structures. Here, if the size of our weights are large compared to V and E, then doing this expansion is going to be difficult. But if we had, say, some graph-- this is my graph G, and we had a source vertex s, the idea here is going to still be to try to grow a frontier of increasing distance from my source and try to maintain all of the things within a certain distance from my source. So that's the idea, grow a sphere centered at my source, repeatedly explore closer vertices before I get to further ones. But how can I explore closer vertices if I don't know the distances beforehand? This is kind of-- seems like a circular logic. I'm going to use the distance to my things to compute the distances to my things. That doesn't work so well. So how do we do this? Well, the idea here is to gradually compute the distances-- compute the distances as we go so that we maintain this property. Now this property, this idea wouldn't work necessarily in the context of negative edge weights. Here, we have this growing frontier, this ball around my source. And as I grow my thing, these things are at further and further distance, because any edge from something back here as I'm growing my ball a certain distance, these things are outside that distance. We're kind of using a key observation here. Here's my observation 1. If weights greater than or equal to 0, then distances increase along shortest paths. Maybe weakly monotonically increase if there are zero-weight edges. But in general, if I had a path going from s to some v, and it's going through some vertex u, I have some shortest path. This is the shortest path from s to v, and it goes through some point u, some vertex u. Then this monotonicity more specifically means that the shortest path from s to u and the shortest path from s to v, which is this whole thing, how do these relate to each other? If this is along that path, then this has to be at least as large as the subpath. Because all of these-- the weight of this path cannot be negative. So that's the thing that Dijkstra's going to exploit. It essentially means that when I'm expanding this frontier of distance away from x, it's possible if I had negative weight, that this line-- if I had some very negative weight going from a vertex here to a vertex here, this vertex could be within this boundary. Maybe if this distance is x, this guy could be within x. The things that are within distance x of s might not be all contained. There could be a path from here to this other vertex width distance x. It doesn't have this property because I could decrease in distance along the path. So that's the first observation. Second observation, well, let's see if we can piggyback on DAG relaxation. I claim to you that we can solve single source shortest paths faster if we're given an order of vertices in increasing distance beforehand. Distance from s. So here's the idea. I'm not going to give you the distances to all these vertices. Instead I'm going to give you the order of the vertices in some increasing distance from s. So basically I'm saying, if I had some, I don't know, here's a graph. Let's see if I can remember. OK, and I'm going to put some edges on here. OK. And I'm going to call these vertices 0, 1, 2, 3, and 4. OK. So here's a graph. Maybe I put some edge weights on here. I'm going to say this one is 3, this one is 2, this one is 3, this is 1, this is 1, this is 0, and this is 0. So from vertex 1 to 2, that was the 2 for the labeling of that vertex. That edge is zero-weight. OK. So here's a weighted graph And I don't necessarily know-- I could use Bellman-Ford to find shortest paths from this vertex 0, but the idea here is I'm not going to give you shortest paths, I'm going to try to compute shortest paths, but I'm going to give you some additional information. I'm going to give you the order of their shortest path distance from the source. And I can just-- I'm going to eyeball this and say-- I'm going to change this slightly to make it a little bit more interesting. I'm going to say this is distance 4. OK. All right, so now what we have is the shortest path distance-- I'm just eyeballing this. The shortest distance to-- bad example. All right. So, these are the weights. Shortest-path distance to 3 is going to be 2, I'm going to say, through there. Shortest-path distance here is 2 also. Shortest-path distance here is also 2 because I can go through both of these 0's and it's not a problem. And then the shortest-path distance here is 2 to here and a 1/3 to there. So these are listed in increasing distance from my source. I had to compute those deltas to convince you that this was the right ordering, but this is a right ordering of these things. Now it's not the only right ordering, but it is a right ordering. OK, so I'm told-- I'm arguing to you that I could solve a single source shortest paths in linear time if I were to give you the vertices in increasing distance? How could I do that? Well, because of this first observation, I know that if these are increasing in distance, any edge going backwards with respect to this ordering can't participate in shortest paths with one exception. Anyone know what that exception is? No edge can go backwards in this ordering based on this observation except under what condition? Yeah? AUDIENCE: If the weight is 0? JASON KU: If the weight to 0, yeah. So if the weight to 0, just like this situation here, then I could go backwards in the ordering. See, it's problematic. The idea is I'm going to want to construct a DAG so that I can run DAG relaxation. Well, if I have a component here that has 0 weights, I can coalesce this thing down-- I can deal with this component separately. Let's worry about that separately. If we do, we can collapse this edge down into a single vertex and transform this graph so it does respect the ordering. So I'm going to transform this graph into a new graph. This is a graph-- contains vertex 2 and vertex 0, vertex 1 and 3 here, and vertex 4. OK, now we have-- and I'm only going to keep edges going forward in the-- I'm going to need to collapse this entire section down into one vertex. This doesn't quite work. OK. Let's ignore zero-weight edges for now. Let's assume these are-- all right, there's something broken here. If I have a cycle here-- right now I don't have a cycle of zero-weight. So what I could do is I could take this vertex and put it after both of these vertices. And now I would-- or I could rearrange the order of these three vertices where there's a path of length 0 and get a new ordering that still satisfies the property. And that's always the case because paths can't increase-- paths can't decrease in weight. I can rearrange the ordering of these things so that 3 comes first, 1 comes second, and 2 comes third of those three vertices. Yeah. So for every set of 0 edges, I can just flip the relationship if they have the same distance. In my input, I'm given vertices that have the same distance from the source. And so if those are the same distance from the source and they're connected by a zero-weight edge, it doesn't hurt me to flip their ordering. So I'm going to do that. So let's convert that into a graph with a different ordering. 0 3 now, 1 2. OK and I have this distance, this edge, this edge, this edge, this edge. This edge. What am I missing? 2 to 3. And here. I think I have all of those edges. Yeah? OK. Now I have the property that every edge that could participate in the shortest path are going forward in the ordering, because all of these are zero-weight. So we flip those around so they're going correct with respect to the ordering. And any edge going backwards that is positive weight certainly can't be used in any shortest path. So I'm just going to get rid of them. Yeah? What do I do if there's a zero-weight cycle? JASON KU: If there's a zero-weight cycle, I can just coalesce them all together down to a single vertex, because if I reach one of them, I can reach all of them. AUDIENCE: You're getting a topological ordering of-- JASON KU: Exactly. I'm computing-- so the idea here is we're trying to construct a DAG. I can construct this DAG in linear time. And then I can run DAG relaxation on this graph in linear time to get shortest paths. So that's an approach. If I knew the ordering of the vertices in increasing distance, then I could use DAG relaxation. So we're going to use both of these observations. That's how we're going to solve this single source shortage problem with non-negative weights using Dijkstra. So that's finally now where we're coming to. Sorry, I missed a case here when I was writing up my notes, and I tried to fix it live and hopefully you guys followed me. OK. Dijkstra's algorithm. Did I spell that right? Kind of. OK. What? Dijkstra. OK. Now Dijkstra was this Dutch computer scientist. This is him. Pretty famous, he wrote a monograph on why programming languages should start with 0 indexing as opposed to 1 indexing, so I like him. But in particular, he designed this very nice generalization of BFS for weighted graphs. But maybe I didn't spell this right because when he writes his name, he writes it with a Y with a dash over it. So in reality on a Dutch typewriter, you might have a character that looks like this, Y with a umlaut on top of it. But on modern-- on an English keyboard, this looks pretty similar to an IJ. So in a lot of manuscripts, we write it as D-I-- there's no J sound in Dijkstra. It's coming from this is Y here.","72.83784484863281","5","DPRSearchEngine","NSHizBK9JD8.en-j3PyPqV-e1s_1_mp4","NSHizBK9JD8.en-j3PyPqV-e1s","6.006","13"
"221","What does the process of 'relaxing an edge' achieve in a weighted shortest path algorithm?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 4: Hashing 
Lecture 4: Hashing 
Review 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
• Idea! Want faster search and dynamic operations. Can we find(k) faster than Θ(log n)? 
• Answer is no (lower bound)! (But actually, yes...!?) 
Comparison Model 
• In this model, assume algorithm can only differentiate items via comparisons 
• Comparable items: black boxes only supporting comparisons between pairs 
• Comparisons are <, ≤, >, ≥, =, =6 , outputs are binary: True or False 
• Goal: Store a set of n comparable items, support find(k) operation 
• Running time is lower bounded by # comparisons performed, so count comparisons! 
Decision Tree 
• Any algorithm can be viewed as a decision tree of operations performed 
• An internal node represents a binary comparison, branching either True or False 
• For a comparison algorithm, the decision tree is binary (draw example) 
• A leaf represents algorithm termination, resulting in an algorithm output 
• A root-to-leaf path represents an execution of the algorithm on some input 
• Need at least one leaf for each algorithm output, so search requires ≥ n + 1 leaves 
","72.64927673339844","6","DPRSearchEngine","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_1_pdf","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4","6.006","4"
"221","What does the process of 'relaxing an edge' achieve in a weighted shortest path algorithm?","OK, so this is Dijkstra's algorithm. OK. Set-- so same initialization step. We're going to set-- this is a distance estimate d, not delta. We're going to want the d's be our delta is at the end of the algorithm. That's what we're going to have to prove. So we first set all of them to infinity, and then set d of s, s equal to 0. And here, we're never going to update it again, because our shortest distance is in a graph with non-negative edge weights certainly can't go below 0. All right. Now we build our-- build our changeable priority queue-- queue-- with an item-- I'm going to say an item is-- x is represented by a tuple of its ID, and then its key just for brevity here. With an item v, d of s, v. So I'm going to be storing in my changeable priority queue the vertex label and its shortest-path distance estimate d. And that's going to be the key, the minimum that I'm trying going to be querying on for each the v and V. So I'm going to build that thing. It's going to then have all of my vertices in my graph. Then while my changeable priority queue still has items, not empty, I'm going to delete some u, d s, u. So some item such that its distance is minimized from Q that has minimum distance. OK. So I'm going to I'm going to look at all the things in my priority queue. At the start it's just going to be s, because everything as shortest-path distance estimate infinite except for s. And so that's clearly the smallest. OK, so I'm going to remove that from my queue, and then I'm going to process it. How am I going to process it? It's the exact same kind of thing as DAG relaxation. I'm going to relax all its outgoing edges. So just for completeness for v in the outgoing adjacencies of u, I'm going to relax-- sorry. We have to check whether we can relax it. Basically if the shortest-path distance estimate to v is greater than going to u first and then crossing that edge, if going through that is better, this is violating our triangle inequality. And so we relax edge u, v, and by that we mean set this thing to be equal to that thing. That's what we meant by relax. And then we have one other thing to do. We have changed these distance estimates but our Q doesn't know that we change these things. We added these items in here. But it doesn't know that my distances have changed. So we to tell the Q to remember to change its key value associated with the item v. So decrease-- what is it? Decrease key vertex v in Q to the new d s, v, the one that I just decreased here. And I know that I decreased it because I said it to a smaller value. That makes sense. All right, so that's Dijkstra. Let's run it on an example. So here's an example. I have a directed graph. It does contain cycles. In particular, here are some cycles. I think those are the main ones. There are definitely cycles in this graph. But as you see, all of the weights are non-negative, in particular-- they're positive, actually. It's going to be just helpful in writing out this example. So let's run Dijkstra on this graph. First we initialize and we set the shortest-path distance. I'm going to label it in white here to all of the things. Then I'm going to, as I update it, I'm just going to cross them out and write a new number. So that's what it is at the start. That's initialization, that's after step 1. And then I stick things into my Q. What's in my Q? Here's my Q. It's everything. It's vertices s, a, b, c, d. I got five items in my Q. Really, it's the item pair with its shortest distance estimate, I'm just not going to rewrite that here. So the idea here is-- the while loop, OK. Q is not empty, great. We're going to delete the one with the smallest distance estimate, which is s, right, yeah. So I remove that, and then I relax edges out of s. So I relax edge here to a. That's better than the distance estimate-- 10 is better than the distance estimate infinite, so I'm going to change this to 10. And then here's another outgoing edge. 3 is better than infinite, so I'm going to change its delta to 3. OK. So now I go back in here and I change the distance estimates associated with my Q. Now, next step of the algorithm, s is done. I've processed everything distance 0 away. But I'm now going to use my priority queue to say which of my vertices has the shortest distance estimate now. So which one is it? a, b, or c, or d? Yeah, it's 3 and c. 3 is smaller than 10. So Q is going to magically delete c for me, tell me what that is, and now I'm going to process that. Now I've changed my boundary to this. And now I relax edges out of c. So here's an edge at a c, that's a 4. A 4 plus the 3 is smaller than 10, so I update it. 3 plus 8 is 11, that's smaller than infinite, so I update it, I relax. 3 plus 2 is smaller than infinite, so I relax that as well. Now of the things still left in my Q, I'm actually going to remove it from my Q instead of crossing it out, maybe that's better. Of the vertices still left in my Q, which has smallest distance? Yeah. d. d has 5, 7, or 11. 5 is the smallest. So I remove d from my cue and I relax edges from it. And now my boundary looks something like this. I relax edges out of it. 5 plus 5, that's 10. 10 is smaller than 11, so that's a 10. And that's the only outgoing edge from d. so I'm done. And then the last, 7 is smaller than 10, I relax edges out of a. a to b, 7 plus 2 is smaller than 10. And now I'm done. So what I did every time I removed s-- or I removed a vertex, I said its shortest-path distance to the small-- the last value I assigned to it. So this was then 3, and then a was 7, b was 9, and then d was 5. So that's Dijkstra in action. It seems like these are the shortest-path distances, but how do we prove that? Did it do the right thing? Well, let's find out.","72.45053100585938","7","DPRSearchEngine","NSHizBK9JD8.en-j3PyPqV-e1s_4_mp4","NSHizBK9JD8.en-j3PyPqV-e1s","6.006","13"
"221","What does the process of 'relaxing an edge' achieve in a weighted shortest path algorithm?","It's not really complicated. Instead of having a single source, we are essentially wanting to, given an input-- this is our weighted graph, where we've got a graph V, E, and we've got a weight function from the edges to the integers. This is our general weighted graph. We want our output to be something like, the shortest path distance from u to v for every u and v in our vortex set. That's what we want to return. Now, there's one caveat here that, if there's a negative weight cycle in our graph-- in other words, if any of these delta u, v's is minus infinity,","72.39277648925781","8","DPRSearchEngine","EmSmaW-ud6A.en-j3PyPqV-e1s_2_mp4","EmSmaW-ud6A.en-j3PyPqV-e1s","6.006","14"
"221","What does the process of 'relaxing an edge' achieve in a weighted shortest path algorithm?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 10: Depth-First Search 
Lecture 10: Depth-First Search 
Previously 
• Graph deﬁnitions (directed/undirected, simple, neighbors, degree) 
• Graph representations (Set mapping vertices to adjacency lists) 
• Paths and simple paths, path length, distance, shortest path 
• Graph Path Problems 
– Single Pair Reachability(G,s,t) 
– Single Source Reachability(G,s) 
– Single Pair Shortest Path(G,s,t) 
– Single Source Shortest Paths(G,s) (SSSP) 
• Breadth-First Search (BFS) 
– algorithm that solves Single Source Shortest Paths 
– with appropriate data structures, runs in O(|V | + |E|) time (linear in input size) 
Examples 
G1 
a 
d 
b 
e 
c 
f 
G2 
a 
d 
b 
e 
c 
f 
","72.34153747558594","9","DPRSearchEngine","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10_1_pdf","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10","6.006","10"
"221","What does the process of 'relaxing an edge' achieve in a weighted shortest path algorithm?"," 
 
 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) Lecture 
General Unweighted 
BFS 
|V | + |E| L09 
L11 
L12 
L13 (Today!) 
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Any 
Bellman-Ford 
Dijkstra 
|V | · |E|
General Non-negative 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 13: Dijkstra’s Algorithm 
Lecture 13: Dijkstra’s Algorithm 
Review 
• Single-Source Shortest Paths on weighted graphs 
• Previously: O(|V | + |E|)-time algorithms for small positive weights or DAGs 
• Last time: Bellman-Ford, O(|V ||E|)-time algorithm for general graphs with negative weights 
• Today: faster for general graphs with non-negative edge weights, i.e., for e ∈ E, w(e) ≥ 0 
|V | log |V | + |E| 
Non-negative Edge Weights 
• Idea! Generalize BFS approach to weighted graphs: 
– Grow a sphere centered at source s 
– Repeatedly explore closer vertices before further ones 
– But how to explore closer vertices if you don’t know distances beforehand? 
:( 
• Observation 1: If weights non-negative, monotonic distance increase along shortest paths 
– i.e., if vertex u appears on a shortest path from s to v, then δ(s, u) ≤ δ(s, v) 
– Let Vx ⊂ V be the subset of vertices reachable within distance ≤ x from s 
– If v ∈ Vx, then any shortest path from s to v only contains vertices from Vx 
– Perhaps grow Vx one vertex at a time! (but growing for every x is slow if weights large) 
• Observation 2: Can solve SSSP fast if given order of vertices in increasing distance from s 
– Remove edges that go against this order (since cannot participate in shortest paths) 
– May still have cycles if zero-weight edges: repeatedly collapse into single vertices 
– Compute δ(s, v) for each v ∈ V using DAG relaxation in O(|V | + |E|) time 
","72.28557586669922","10","DPRSearchEngine","d819e7f4568aced8d5b59e03db6c7b67_MIT6_006S20_lec13_1_pdf","d819e7f4568aced8d5b59e03db6c7b67_MIT6_006S20_lec13","6.006","13"
"223","What is the process for dynamically maintaining connected components in a changing graph using sets?"," 
 
 
   
 
 
 
   
   
      
 
 
 
 
 
 
  
 
Stochastic Processes  
An ongoing process where the next state might depend on 
both the previous states and some random element 
def rollDie(): 
"""""" returns an int between 1 and 6"""""" 
def rollDie(): 
"""""" returns a randomly chosen int 
between 1 and 6"""""" 
6.0002 LECTURE 4 
8
","69.04471588134766","1","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_8_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"223","What is the process for dynamically maintaining connected components in a changing graph using sets?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","68.74690246582031","2","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"223","What is the process for dynamically maintaining connected components in a changing graph using sets?","It's basically-- it's a set type thing, where I can make a set of just a single element, I can take two sets, merge them together, make them their union, and then given an object, I say, which set am I part of, essentially by electing a leader within a set and saying, return me a pointer to that one. And so this can be useful in dynamically maintaining, say, the connected components in a dynamically changing graph supporting the query of, am I in the same component as this other guy? That could be a very useful thing to know about a graph as it's changing. So that's an application of this problem. And they get near-constant performance for a lot of these queries. It's not quite, but pretty close. OK, on the graph side, they solve","68.42803192138672","3","DPRSearchEngine","2NMtS1ecb3o.en-j3PyPqV-e1s_6_mp4","2NMtS1ecb3o.en-j3PyPqV-e1s","6.006","20"
"223","What is the process for dynamically maintaining connected components in a changing graph using sets?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","67.40756225585938","4","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"223","What is the process for dynamically maintaining connected components in a changing graph using sets?"," 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 7: Binary Trees II: AVL 
Lecture 7: Binary Trees II: AVL 
Last Time and Today’s Goal 
Sequence 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
build(X) 
get at(i) 
set at(i,x) 
insert first(x) 
delete first() 
insert last(x) 
delete last() 
insert at(i, x) 
delete at(i) 
Binary Tree 
n 
h 
h 
h 
h 
AVL Tree 
n 
log n 
log n 
log n 
log n 
Set 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Binary Tree 
n log n 
h 
h 
h 
h 
AVL Tree 
n log n 
log n 
log n 
log n 
log n 
Height Balance 
• How to maintain height h = O(log n) where n is number of nodes in tree? 
• A binary tree that maintains O(log n) height under dynamic operations is called balanced 
– There are many balancing schemes (Red-Black Trees, Splay Trees, 2-3 Trees, . . . ) 
– First proposed balancing scheme was the AVL Tree (Adelson-Velsky and Landis, 1962) 
Rotations 
• Need to reduce height of tree without changing its traversal order, so that we represent the 
same sequence of items 
• How to change the structure of a tree, while preserving traversal order? Rotations! 
1 
_____<D>__ 
rotate_right(<D>) 
__<B>_____ 
2 
__<B>__ 
<E> 
=> 
<A> 
__<D>__ 
3 
<A> 
<C> 
/ \\ 
/ \\ 
<C> 
<E> 
4 
/ \\ 
/ \\ 
/___\\ 
<= 
/___\\ 
/ \\ 
/ \\ 
5 
/___\\ /___\\ 
rotate_left(<B>) 
/___\\ /___\\ 
• A rotation relinks O(1) pointers to modify tree structure and maintains traversal order 
","66.59556579589844","5","DPRSearchEngine","a2c80596cf4a2b5fbc854afdd2f23dcb_MIT6_006S20_lec7_1_pdf","a2c80596cf4a2b5fbc854afdd2f23dcb_MIT6_006S20_lec7","6.006","7"
"223","What is the process for dynamically maintaining connected components in a changing graph using sets?"," 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Relationships among models 
Informal Defn: Two models of computation are polynomially related 
if each can simulate the other with a polynomial overhead: 
So ! "" time → !$("") time on the other model, for some '. 
All reasonable deterministic models are polynomially related. 
• 1-tape TMs 
• multi-tape TMs 
• multi-dimensional TMs 
• random access machine (RAM) 
• cellular automata 
9 
","65.64983367919922","6","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_9_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"223","What is the process for dynamically maintaining connected components in a changing graph using sets?","And we did adding and removing a leaf. That's not enough. We're going to need something else to let us guarantee logarithmic height. And that something else is called a rotation.","64.71533203125","7","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_15_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"223","What is the process for dynamically maintaining connected components in a changing graph using sets?"," 
 
 
    
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Return to Closure Properties 
Recall Theorem: If !"", !$ are regular languages, so is !"" ∪!$ 
(The class of regular languages is closed under union) 
New Proof (sketch): Given DFAs &"" and &$ recognizing !"" and !$ 
&$
&"" 
ε 
ε 
& 
Construct NFA & recognizing !"" ∪!$ 
Nondeterminism 
parallelism 
vs 
guessing 
7 
","64.64368438720703","8","DPRSearchEngine","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_7_pdf","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2","18.404J","2"
"223","What is the process for dynamically maintaining connected components in a changing graph using sets?"," 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
18.404/6.840 Lecture 2 
Last time: (Sipser §1.1) 
- Finite automata, regular languages 
- Regular operations ∪,∘,∗ 
- Regular expressions 
- Closure under ∪ 
Today: (Sipser §1.2 – §1.3) 
- Nondeterminism 
- Closure under ∘ and ∗ 
- Regular expressions → finite automata 
Goal: Show finite automata equivalent to regular expressions 
1 
","64.57131958007812","9","DPRSearchEngine","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_1_pdf","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2","18.404J","2"
"223","What is the process for dynamically maintaining connected components in a changing graph using sets?"," &&%$3$%'9
class Digraph(object): 
 """"""edges is a dict mapping each node to a list of 
    its children""""” 
    def __init__(self): 
self.edges = {} 
    def addNode(self, node): 
if node in self.edges: 
 raise ValueError('Duplicate node') 
else: 
self.edges[node] = [] 
    def addEdge(self, edge): 
src = edge.getSource() 
dest = edge.getDestination() 
if not (src in self.edges and dest in self.edges): 
raise ValueError('Node not in graph') 
self.edges[src].append(dest) 
Q>KKKMN
LS
mapping each node 
list 
","64.52547454833984","10","DPRSearchEngine","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_18_pdf","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3","6.0002","3"
"225","What are the two strategies for solving subproblems in dynamic programming?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 16: Dyn. Prog. Subproblems 
Lecture 16: Dyn. Prog. Subproblems 
Dynamic Programming Review 
• Recursion where subproblem dependencies overlap, forming DAG 
• “Recurse but re-use” (Top down: record and lookup subproblem solutions) 
• “Careful brute force” (Bottom up: do each subproblem in order) 
Dynamic Programming Steps (SRT BOT) 
1. Subproblem deﬁnition 
subproblem x 2 X 
• Describe the meaning of a subproblem in words, in terms of parameters 
• Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence 
• Often multiply possible subsets across multiple inputs 
• Often record partial state: add subproblems by incrementing some auxiliary variables 
2. Relate subproblem solutions recursively 
x(i) =  f(x(j), . . .) for one or more j < i  
• Identify a question about a subproblem solution that, if you knew the answer to, reduces 
the subproblem to smaller subproblem(s) 
• Locally brute-force all possible answers to the question 
3. Topological order to argue relation is acyclic and subproblems form a DAG 
4. Base cases 
• State solutions for all (reachable) independent subproblems where relation breaks down 
5. Original problem 
• Show how to compute solution to original problem from solutions to subproblem(s) 
• Possibly use parent pointers to recover actual solution, not just objective function 
6. Time analysis 
P 
• 
x2X work(x), or if work(x) =  O(W) for all x 2 X, then |X| · O(W) 
• work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time 
","72.6374740600586","1","DPRSearchEngine","28461a74f81101874a13d9679a40584d_MIT6_006S20_lec16_1_pdf","28461a74f81101874a13d9679a40584d_MIT6_006S20_lec16","6.006","16"
"225","What are the two strategies for solving subproblems in dynamic programming?","4 
Lecture 1: Introduction 
1 
def birthday_match(students): 
2 
’’’ 
3 
Find a pair of students with the same birthday 
4 
Input: 
tuple of student (name, bday) tuples 
5 
Output: tuple of student names or None 
6 
’’’ 
7 
n = len(students) 
# O(1) 
8 
record = StaticArray(n) 
# O(n) 
9 
for k in range(n): 
# n 
10 
(name1, bday1) = students[k] 
# O(1) 
11 
# Return pair if bday1 in record 
12 
for i in range(k): 
# k 
13 
(name2, bday2) = record.get_at(i) 
# O(1) 
14 
if bday1 == bday2: 
# O(1) 
15 
return (name1, name2) 
# O(1) 
16 
record.set_at(k, (name1, bday1)) 
# O(1) 
17 
return None 
# O(1) 
Example: Running Time Analysis 
• Two loops: outer k ∈{0, . . . , n − 1}, inner is i ∈{0, . . . , k}
P n−1
• Running time is O(n) + 
k=0 (O(1) + k · O(1)) = O(n2) 
• Quadratic in n is polynomial. Efﬁcient? Use different data structure for record! 
How to Solve an Algorithms Problem 
1. Reduce to a problem you already know (use data structure or algorithm) 
Search Problem (Data Structures) 
Sort Algorithms 
Static Array (L01) 
Insertion Sort (L03) 
Linked List (L02) 
Selection Sort (L03) 
Dynamic Array (L02) 
Merge Sort (L03) 
Sorted Array (L03) 
Counting Sort (L05) 
Direct-Access Array (L04) 
Radix Sort (L05) 
Hash Table (L04) 
AVL Sort (L07) 
Balanced Binary Tree (L06-L07) 
Heap Sort (L08) 
Binary Heap (L08) 
2. Design your own (recursive) algorithm 
• Brute Force 
• Decrease and Conquer 
• Divide and Conquer 
• Dynamic Programming (L15-L19) 
• Greedy / Incremental 
Shortest Path Algorithms 
Breadth First Search (L09) 
DAG Relaxation (L11) 
Depth First Search (L10) 
Topological Sort (L10) 
Bellman-Ford (L12) 
Dijkstra (L13) 
Johnson (L14) 
Floyd-Warshall (L18) 
","72.39976501464844","2","DPRSearchEngine","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_4_pdf","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1","6.006","1"
"225","What are the two strategies for solving subproblems in dynamic programming?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 10: Depth-First Search 
Lecture 10: Depth-First Search 
Previously 
• Graph deﬁnitions (directed/undirected, simple, neighbors, degree) 
• Graph representations (Set mapping vertices to adjacency lists) 
• Paths and simple paths, path length, distance, shortest path 
• Graph Path Problems 
– Single Pair Reachability(G,s,t) 
– Single Source Reachability(G,s) 
– Single Pair Shortest Path(G,s,t) 
– Single Source Shortest Paths(G,s) (SSSP) 
• Breadth-First Search (BFS) 
– algorithm that solves Single Source Shortest Paths 
– with appropriate data structures, runs in O(|V | + |E|) time (linear in input size) 
Examples 
G1 
a 
d 
b 
e 
c 
f 
G2 
a 
d 
b 
e 
c 
f 
","72.29576873779297","3","DPRSearchEngine","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10_1_pdf","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10","6.006","10"
"225","What are the two strategies for solving subproblems in dynamic programming?"," 
 
 
 
  
 
 
  
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Intro to Complexity Theory 
Computability theory (1930s - 1950s): 
Is A decidable? 
Complexity theory (1960s - present): 
Is A decidable with restricted resources? 
(time/memory/…) 
Example: Let ! = a#b# $ ≥0 . 
Q: How many steps are needed to decide !? 
Depends on the input. 
We give an upper bound for all inputs of length '. 
Called “worst-case complexity”. 
2 
","72.23190307617188","4","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_2_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"225","What are the two strategies for solving subproblems in dynamic programming?"," 
 
 
   
 
 
 
   
   
      
 
 
 
 
 
 
  
 
Stochastic Processes  
An ongoing process where the next state might depend on 
both the previous states and some random element 
def rollDie(): 
"""""" returns an int between 1 and 6"""""" 
def rollDie(): 
"""""" returns a randomly chosen int 
between 1 and 6"""""" 
6.0002 LECTURE 4 
8
","72.17156219482422","5","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_8_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"225","What are the two strategies for solving subproblems in dynamic programming?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","72.03750610351562","6","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"225","What are the two strategies for solving subproblems in dynamic programming?"," 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 18: Pseudopolynomial 
Lecture 18: Pseudopolynomial 
Dynamic Programming Steps (SRT BOT) 
1. Subproblem deﬁnition 
subproblem x ∈ X 
• Describe the meaning of a subproblem in words, in terms of parameters 
• Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence 
• Often multiply possible subsets across multiple inputs 
• Often record partial state: add subproblems by incrementing some auxiliary variables 
• Often smaller integers than a given integer (today’s focus) 
2. Relate subproblem solutions recursively 
x(i) = f(x(j), . . .) for one or more j < i 
• Identify a question about a subproblem solution that, if you knew the answer to, reduces 
the subproblem to smaller subproblem(s) 
• Locally brute-force all possible answers to the question 
3. Topological order to argue relation is acyclic and subproblems form a DAG 
4. Base cases 
• State solutions for all (reachable) independent subproblems where relation breaks down 
5. Original problem 
• Show how to compute solution to original problem from solutions to subproblem(s) 
• Possibly use parent pointers to recover actual solution, not just objective function 
6. Time analysis 
P 
• 
work(x), or if work(x) = O(W ) for all x ∈ X, then |X| · O(W )
x∈X 
• work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time 
","71.92646789550781","7","DPRSearchEngine","mit6_006s20_lec18_1_pdf","mit6_006s20_lec18","6.006","18"
"225","What are the two strategies for solving subproblems in dynamic programming?"," 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Relationships among models 
Informal Defn: Two models of computation are polynomially related 
if each can simulate the other with a polynomial overhead: 
So ! "" time → !$("") time on the other model, for some '. 
All reasonable deterministic models are polynomially related. 
• 1-tape TMs 
• multi-tape TMs 
• multi-dimensional TMs 
• random access machine (RAM) 
• cellular automata 
9 
","71.74939727783203","8","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_9_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"225","What are the two strategies for solving subproblems in dynamic programming?"," 
 
 
 
 
 
 
 
 
  
 
  
 
   
 
 
 
 
  
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Model Dependence 
Number of steps to decide ! = a#b# $ ≥0 depends on the model. 
• 1-tape TM: '() log )) 
• Multi-tape TM: '()) 
Computability theory: model independence (Church-Turing Thesis) 
Therefore model choice doesn’t matter. Mathematically nice. 
Complexity Theory: model dependence 
But dependence is low (polynomial) for reasonable deterministic models. 
We will focus on questions that do not depend on the model choice. 
So… we will continue to use the 1-tape TM as the basic model for complexity. 
6 
","71.54209899902344","9","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_6_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"225","What are the two strategies for solving subproblems in dynamic programming?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Monte Carlo Simulation  
A method of estimating the value of an unknown 
quantity using the principles of inferential statistics 
Inferential statistics 
◦ Population: a set of examples 
◦ Sample: a proper subset of a population 
◦ Key fact: a random sample tends to exhibit the same  
properties as the population from which it is drawn  
Exactly what we did with random walks 
6.0002 LECTURE 6 
4
","71.4537582397461","10","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_4_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"226","What is the purpose of the reweighting scheme in Johnson's algorithm?","§ 1. Enumerate all possible combina<ons of items. 
§ 2. Remove all of the combina<ons whose total units 
exceeds the allowed weight. 
§ 3. From the remaining combina<ons choose any one 
whose value is the largest. 
Brute Force Algorithm 
6.0002 LECTURE 2 
4 
","72.62108612060547","1","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_4_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"226","What is the purpose of the reweighting scheme in Johnson's algorithm?"," 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
   
 
    
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
Linearly Bounded Automata 
Defn: A linearly bounded automaton (LBA) is a 1-tape TM 
that cannot move its head off the input portion of the tape. 
LBA 
a a b a a b a 
Tape size adjusts to length of input. 
Let !LBA = &, ( LBA & accepts ( } 
Theorem:  !LBA is decidable 
Proof: (idea) If & on ( runs for long, it must be cycling. 
Decider for !LBA: 
Claim: For inputs of length ), an LBA can have 
.A−LBA = “On input &, ( 
only * ×)× Γ - different configurations. 
1.  Let ) = |(|. 
Therefore, if an LBA runs for longer, it must repeat some 
2. Run & on ( for * ×)× Γ - steps. 
configuration and thus will never halt. 
3. If has accepted, accept. 
4. If it has rejected or is still running, reject.” 
must be looping 
7 
","70.31069946289062","2","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_7_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"226","What is the purpose of the reweighting scheme in Johnson's algorithm?","It's not really complicated. Instead of having a single source, we are essentially wanting to, given an input-- this is our weighted graph, where we've got a graph V, E, and we've got a weight function from the edges to the integers. This is our general weighted graph. We want our output to be something like, the shortest path distance from u to v for every u and v in our vortex set. That's what we want to return. Now, there's one caveat here that, if there's a negative weight cycle in our graph-- in other words, if any of these delta u, v's is minus infinity,","69.80821990966797","3","DPRSearchEngine","EmSmaW-ud6A.en-j3PyPqV-e1s_2_mp4","EmSmaW-ud6A.en-j3PyPqV-e1s","6.006","14"
"226","What is the purpose of the reweighting scheme in Johnson's algorithm?","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","69.30587005615234","4","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"226","What is the purpose of the reweighting scheme in Johnson's algorithm?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
If we know that some problem (say !TM) is undecidable, 
we can use that to show other problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Recall Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
2 
","69.10253143310547","5","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_2_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"226","What is the purpose of the reweighting scheme in Johnson's algorithm?","§ Problem is exponen<al 
§ Have we overturned the laws of the universe? 
§ Is dynamic programming a miracle? 
§ No, but computa<onal complexity can be subtle 
§ Running <me of fastMaxVal is governed by number of 
dis<nct pairs, <toConsider, avail> 
◦Number of possible values of toConsider bounded 
by len(items)
◦Possible values of avail a bit harder to characterize 
◦Bounded by number of dis<nct sums of weights 
◦Covered in more detail in assigned reading 
How Can This Be? 
6.0002 LECTURE 2 
30 
","69.00869750976562","6","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_30_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"226","What is the purpose of the reweighting scheme in Johnson's algorithm?","§ Given remaining weight, maximize value by choosing 
among remaining items 
§ Set of previously chosen items, or even value of that 
set, doesn’t mafer! 
What Problem is Solved at Each Node? 
6.0002 LECTURE 2 
26 
","68.84041595458984","7","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_26_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"226","What is the purpose of the reweighting scheme in Johnson's algorithm?"," 
 
 
 
 
 
 
   
 
  
  
 
 
 
 
   
 
 
 
 
 
  
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
  
 
 
Revisit Hilbert’s 10th Problem 
Recall ! = 〈$〉 polynomial $ &', &), … , &+ = 0 has integer solution) 
Hilbert’s 10th problem (1900): Is ! decidable? 
Theorem (1971): No 
Proof: Show -TM is reducible to !. [would take entire semester] 
Do toy problem instead which has a similar proof method. 
Toy problem: The Post Correspondence Problem. 
Method: The Computation History Method. 
3 
","68.5837631225586","8","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_3_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"226","What is the purpose of the reweighting scheme in Johnson's algorithm?","4 
Lecture 1: Introduction 
1 
def birthday_match(students): 
2 
’’’ 
3 
Find a pair of students with the same birthday 
4 
Input: 
tuple of student (name, bday) tuples 
5 
Output: tuple of student names or None 
6 
’’’ 
7 
n = len(students) 
# O(1) 
8 
record = StaticArray(n) 
# O(n) 
9 
for k in range(n): 
# n 
10 
(name1, bday1) = students[k] 
# O(1) 
11 
# Return pair if bday1 in record 
12 
for i in range(k): 
# k 
13 
(name2, bday2) = record.get_at(i) 
# O(1) 
14 
if bday1 == bday2: 
# O(1) 
15 
return (name1, name2) 
# O(1) 
16 
record.set_at(k, (name1, bday1)) 
# O(1) 
17 
return None 
# O(1) 
Example: Running Time Analysis 
• Two loops: outer k ∈{0, . . . , n − 1}, inner is i ∈{0, . . . , k}
P n−1
• Running time is O(n) + 
k=0 (O(1) + k · O(1)) = O(n2) 
• Quadratic in n is polynomial. Efﬁcient? Use different data structure for record! 
How to Solve an Algorithms Problem 
1. Reduce to a problem you already know (use data structure or algorithm) 
Search Problem (Data Structures) 
Sort Algorithms 
Static Array (L01) 
Insertion Sort (L03) 
Linked List (L02) 
Selection Sort (L03) 
Dynamic Array (L02) 
Merge Sort (L03) 
Sorted Array (L03) 
Counting Sort (L05) 
Direct-Access Array (L04) 
Radix Sort (L05) 
Hash Table (L04) 
AVL Sort (L07) 
Balanced Binary Tree (L06-L07) 
Heap Sort (L08) 
Binary Heap (L08) 
2. Design your own (recursive) algorithm 
• Brute Force 
• Decrease and Conquer 
• Divide and Conquer 
• Dynamic Programming (L15-L19) 
• Greedy / Incremental 
Shortest Path Algorithms 
Breadth First Search (L09) 
DAG Relaxation (L11) 
Depth First Search (L10) 
Topological Sort (L10) 
Bellman-Ford (L12) 
Dijkstra (L13) 
Johnson (L14) 
Floyd-Warshall (L18) 
","68.29428100585938","9","DPRSearchEngine","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_4_pdf","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1","6.006","1"
"226","What is the purpose of the reweighting scheme in Johnson's algorithm?","def plotData(fileName): 
    xVals, yVals = getData(fileName) 
    xVals = pylab.array(xVals) 
    yVals = pylab.array(yVals) 
    xVals = xVals*9.81  #acc. due to gravity 
    pylab.plot(xVals, yVals, 'bo', 
label = 'Measured displacements') 
    labelPlot() 
	$
	&$	!	 	
	

8
","68.29255676269531","10","DPRSearchEngine","20a7e184a1a2b3c34a5055dc1f1dc066_MIT6_0002F16_lec9_8_pdf","20a7e184a1a2b3c34a5055dc1f1dc066_MIT6_0002F16_lec9","6.0002","9"
"227","What is a simplicial complex?"," 
 
 
 
 
 
 
 
 
   
 
 
  
 
 
 
 
 
 
 
  
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
Constructing !"",$: 3rd try 
!34, 35, 6 = ∃89:; !34, 3<=>, 6/2 ∧ !3<=>, 35, 6/2 
, , J
Check-in 18.3 
Would this construction still work if N were 
nondeterministic? 
(a) Yes. 
(b) No. 
∀(K ∈L) M
∀ 8B, 8C ∈ 
8E, 89:; , 89:;, 8F 
!3G, 3H, 6/2 
is equivalent to 
⋮ 
∀K K ∈L 
M
!"",$ = !3OPQRP, 3QSSTUP, V 
! 
defined as in Cook-Levin 
/
W = - . 
Size analysis: 
Each recursive level adds %('() to the QBF. 
Number of levels is log - ./ = % '( . 
→ Size is % 
'2( 
•
'(×'( = % 
9 
Check-in 18.3 
","67.43903350830078","1","DPRSearchEngine","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18_9_pdf","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18","18.404J","18"
"227","What is a simplicial complex?","Fairly simple data structures today. This is the beginning of several data structures we'll be talking about in the next few lectures. But before we actually start with one, let me tell you/remind remind you of the difference between an interface-- which you might call an API if you're a programmer, or an ADT if you're an ancient algorithms person like me-- versus a data structure. These are useful distinctions. The idea is that an interface says what you want to do. A data structure says how you do it. So you might call this a specification. And in the context of data structures, we're trying to store some data. So the interface will specify what data you can store, whereas the data structure will give you an actual representation and tell you how to store it. This is pretty boring. Just storing data is really easy. You just throw it in a file or something. What makes it interesting is having operations on that data. In the interface, you specify what the operations do, what operations are supported, and in some sense, what they mean. And the data structure actually gives you algorithms-- this is where the algorithms come in-- for how to support those operations. All right. In this class, we're going to focus on two main interfaces and various special of them. The idea is to separate what you want to do versus how to do it. Because-- you can think of this as the problem statement. Yesterday-- or, last class, Jason talked about problems and defined what a problem was versus algorithmic solutions to the problem. And this is the analogous notion for data structures, where we want to maintain some data according to various operations. The same problem can be solved by many different data structures. And we're going to see that. And different data structures are going to have different advantages. They might support some operations faster than others. And depending on what you actually use those data structures for, you choose the right data structure. But you can maintain the same interface. We're going to think about two data structures. One is called a set and one is called a sequence. These are highly loaded terms. Set means something to a mathematician. It means something else to a Python programmer. Sequence, similarly. I guess there's not a Python sequence data type built in. The idea is, we want to store n things. The things will be fairly arbitrary. Think of them as integers or strings. And on the one hand, we care about their values. And maybe we want to maintain them in sorted order and be able to search for a given value, which we'll call a key. And on the other hand, we care about representing a particular sequence that we care about. Maybe we want to represent the numbers 5, 2, 9, 7 in that order and store that. In Python, you could store that in a list, for example. And it will keep track of that order. And this is the first item, the second item, the last item. Today, we're going to be focusing on this sequence data structure, although at the end, I'll mention the interface for sets. But we're going to be actually solving sequences today. And in the next several lectures, we'll be bouncing back and forth between these. They're closely related. Pretty abstract at the moment. On the other hand, we're going to have two main-- let's call them data structure tools or approaches. One is arrays and the other is pointers-- pointer-based or linked data structures. You may have seen these. They're used a lot in programming, of course. But we're going to see both of these today. I'll come back to this sort of highlight in a moment. Let's jump into the sequence interface, which I conveniently have part of here. There's a few different levels of sequences that we might care about. I'm going to start with the static sequence interface. This is where the number of items doesn't change, though the actual items might. Here, we have n items. I'm going to label them x 0 to x n minus 1, as in Python. So the number of items is n. And the operations I want to support are build, length, iteration, get, and set. So what do these do? Build is how you get started. To build a data structure in this interface, you call build of x. Exactly how you specify x isn't too important, but the idea is, I give you some items in some order. In Python, this would be an iterable. I'm going to want to also know its length. And I want to make a new data structure of size and a new static sequence of size n that has those items in that order. So that's how you build one of these. Because somehow, we have to specify n to this data structure, because n is not going to be allowed to change. I'm going to give you a length method. Methods are the object-oriented way of thinking of operations that your interface supports. Length will just return this fixed value n. Iter sequence. This is the sense in which we want to maintain the order. I want to be able to output x 0 through x n minus 1 in the sequence order, in that specified order that they were built in or that it was changed to. This is going to iterate through all of the items. So it's going to take at least linear time to output that. But more interesting is, we can dynamically access anywhere in the middle of the sequence. We can get the ith item, x i, given the value i, and we can change x i to a given new item. OK. So that's called get_at and set_at. Pretty straightforward. This should remind you very closely of something-- a data structure. So this is an interface. This is something I might want to solve. But what is the obvious data structure that solves this problem? Yeah? AUDIENCE: A list. ERIK DEMAINE: A list. In Python, it's called a list. I prefer to call it an array, but to each their own. We're going to use ""list.""","67.3465805053711","2","DPRSearchEngine","CHhwJjR0mZA.en-j3PyPqV-e1s_2_mp4","CHhwJjR0mZA.en-j3PyPqV-e1s","6.006","2"
"227","What is a simplicial complex?","which, I think, most of us would agree was not a very big number. And let's look what's going on here. If you look at this, what in some sense seems really stupid about it? What is it doing that a rational person would not want to do if they could avoid it? It's bad enough to do something once. But to do the same thing over and over again is really wasteful. And if we look at this, we'll see, for example, that fib 4 is being computed here, and fib 4 is being computed here. Fib 3 is being considered here, and here, and here. And do you think we'll get a different answer for fib 3 in one place when we get it in the other place? You sure hope not. So you think, well, what should we do about this? How would we go about avoiding doing the same work over and over again? And there's kind of an obvious answer, and that answer is at the heart of dynamic programming. What's the answer? AUDIENCE: [INAUDIBLE] JOHN GUTTAG: Exactly. And I'm really happy that someone in the front row answered the question because I can throw it that far. You store the answer and then look it up when you need it. Because we know that we can look things up very quickly. Dictionary, despite what Eric said in his lecture, almost all the time works in constant time if you make it big enough, and it usually is in Python. We'll see later in the term how to do that trick. So you store it and then you'd never have to compute it again. And that's the basic trick behind dynamic programming. And it's something called memoization, as in you create a memo and you store it in the memo. So we see this here. Notice that what we're doing is trading time for space. It takes some space to store the old results, but negligible related to the time we save. So here's the trick. We're going to create a table to record what we've done. And then before computing fib of x, we'll check if the value has already been computed. If so, we just look it up and return it. Otherwise, we'll compute it-- it's the first time-- and store it in the table. Here is a fast implementation of Fibonacci that does that. It looks like the old one, except it's got an extra argument-- memo-- which is a dictionary. The first time we call it, the memo will be empty. It tries to return the value in the memo. If it's not there, an exception will get raised, we know that.","67.33917999267578","3","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_9_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"227","What is a simplicial complex?","And that's all. The point of this, and I don't think we've looked at this before, is this is not intended to be a useful class on its own. It's what we call a base class. The notion here is its only purpose is to be inherited. It's not supposed to be useful on itself, but it does give me something that will be used for the two subclasses. And we'll look at two subclasses.","67.0225830078125","4","DPRSearchEngine","6wUD_gp5WeE.en-qlPKC2UN_YU_6_mp4","6wUD_gp5WeE.en-qlPKC2UN_YU","6.0002","5"
"227","What is a simplicial complex?","Notation for encodings and TMs
Notation for encoding objects into strings
- If ! is some object (e.g., polynomial, automaton, graph, etc.), 
we write 〈!〉to be an encoding of that object into a string.  
- If !$, !&, … , !( is a list of objects then we write 〈!$, !&, … , !(〉
to be an encoding of them together into a single string. 
Notation for writing Turing machines
We will use high-level English descriptions of algorithms when we describe TMs, 
knowing that we could (in principle) convert those descriptions into states, 
transition function, etc.  Our notation for writing a TM ) is
) = “On input +
[English description of the algorithm]”
Check-in 6.3
If , and - are strings, would ,- be a good choice 
for their encoding 〈,, -〉into a single string?
a)
Yes.
b)
No. 
Check-in 6.3
8
","66.31114196777344","5","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_8_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"227","What is a simplicial complex?","Second half, Church-Turing thesis. So Church, this is going back into the bit of the history of the subject back to the 1930s. Back then people were interested in formulating the notion of what do we mean by algorithm. They didn't even call it algorithm. Some people call it procedure. Some people called it effective procedure. Some people called it effective calculation. But people had in their minds-- mathematicians have been dealing for centuries, thousands of years, with procedures for doing things. That's a very natural thing. And mathematical logicians, in particular Church and Turing, Turing somebody surely obviously you've heard of, Church maybe not. Church was Turing's thesis advisor, in fact. And they both were coming out of the mathematical logic field of mathematics and trying to use mathematical logic to formalize this intuitive notion of what we have had for centuries about what a procedure is, what is an algorithm. And back in those days, they came up with different ways of formalizing it. So here we had this notion of algorithm, which is kind of intuitive concept. Turing proposed Turing machine as a way of capturing that in a formal way, a mathematically precise way. Other people came up with other ways of doing it. And back then, it wasn't obvious that all of those different formulations would end up giving you equivalent concepts, equivalent notions. And in fact, they proved in fairly elaborate detail that the different methods that people came up with, there was the lambda calculus, there was rewriting systems, there were several methods that were proposed for formalizing this notion, and they all turned out to be equivalent to one another. Today that seems kind of obvious, even though I went to some effort to prove that just to give you a feeling for how those things go. If you have programs, if you have Pascal and Java, say, and thinking about what you can do mathematically in those-- I'm not talking about their ability to interface with Windows and so on, but just the mathematical capabilities. The capability of doing mathematical calculations or functions with a Pascal program or a Java program. It would be absurd to think there's some program that you can write in Java that you can't write in Pascal or Python. And the reason is we know you can compile Python into Java and you can compile Java back into Python. That tells you that the two systems, two programming languages are equivalent in power. That wasn't obvious from the get go to these folks. So they observed that all of the different efforts that came at formalizing algorithm, all were equivalent to one another. That was kind of a breakthrough moment when they realized that all of the ways that they've come up with, and once they got the idea, they realized all reasonable ways of doing it are always going to be equivalent. And so that suggested that they've really captured this notion of algorithm by any one of those methods, say a Turing machine. And that's what they took. You can't prove that, because algorithms are an intuitive notion. But the fact that we're able to capture that in a formal way, that's what we call today the Church-Turing thesis.","66.17588806152344","6","DPRSearchEngine","TTArY7ojshU.en-j3PyPqV-e1s_7_mp4","TTArY7ojshU.en-j3PyPqV-e1s","18.404J","6"
"227","What is a simplicial complex?","Conclusion:  !""# is NP-complete
$% &' &( &) ⋯&+
a
$, &(
⋯
⋯
$accept ⋯
˽    … ˽
23
23
Summary: 
For "" ∈NP, decided by NTM 5, 
we gave a reduction 6 from "" to !""#:
6: Σ∗→formulas
6 &
= 〈=>,@〉
& ∈"" iff  =>,@ is satisfiable.
=>,@ = =cell ∧=start ∧=move ∧=accept
The size of =>,@ is roughly the size of the tableau 
for 5 on &, so size is I 23×23 = I 2(3 .
Therefore 6 is computable in polynomial time.
8
","65.86825561523438","7","DPRSearchEngine","8212b19fc5a34f500ca6acf03a3a7d74_MIT18_404f20_lec16_8_pdf","8212b19fc5a34f500ca6acf03a3a7d74_MIT18_404f20_lec16","18.404J","16"
"227","What is a simplicial complex?","Satisfiability Problem
Defn: A Boolean formula ! has Boolean variables (TRUE/FALSE values) 
and Boolean operations AND (∧), OR (∨), and NOT (¬). 
Defn: ! is satisfiable if ! evaluates to TRUE for some assignment to its variables.
Sometimes we use 1 for True and 0 for False.
Example:  Let ! =
& ∨' ∧(& ∨')
(Notation:  & means ¬&)  
Then ! is satisfiable  (x=1, y=0)  
Defn:  *+, =
!
! is a satisfiable Boolean formula}
Theorem (Cook, Levin 1971):    *+, ∈P  →P = NP 
Proof method:  polynomial time (mapping) reducibility
Check-in 14.3
Check-in 14.3
Is  *+, ∈NP?
(a) Yes.
(b) No. 
(c) I don’t know.
(d) No one knows.
11
","65.76301574707031","8","DPRSearchEngine","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_11_pdf","45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14","18.404J","14"
"227","What is a simplicial complex?"," 
  
  
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
  
 
 
 
  
 
 
  
 
 
  
 
 
 
 
 
  
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
  
 
 
 
 
 
 
NO, would be circular reasoning.
〈1〉
A Self-Reproducing TM 
Theorem: There is a TM !""#$ which (on any input) halts 
with 〈!""#$〉 on the tape. 
Lemma: There is a computable function ': Σ∗ → Σ∗ 
such that ' , = 〈./〉 for every ,, where ./ is 
the TM ./ = “Print , on the tape and halt”. 
Proof: Straightforward. 
Proof of Theorem:  !""#$ has two parts, 0 and 1. 
0
1 
1 = .〈3〉 ? 
1 = “1. Compute '(tape contents) to get 0. 
0 = .〈2〉 
Compute 0 = .〈2〉 
.〈2〉 
from 1 on tape. 
〈01〉 = 〈!""#$〉 
!""#$ 
2. Combine with 1 to get 01 = !""#$. 
3. Halt with 〈!""#$〉 on tape.” 
Can implement in any programming language. 
4 
","65.70755004882812","9","DPRSearchEngine","779043ea724131d008eae652d703938f_MIT18_404f20_lec11_4_pdf","779043ea724131d008eae652d703938f_MIT18_404f20_lec11","18.404J","11"
"227","What is a simplicial complex?","power of a Turing machine. That's a question that I'm going to postpone to later, because you're asking if a Turing machine can simulate itself. And we'll talk about things like that, but that's in a few weeks from now, so I'll hold off on that one. Decidable languages-- somebody's asking me a good question about closure properties of the class of decidable languages. Are they closed under intersection, union, and so on? Yes. And the decidable languages are also closed under complement. That should be something you should think about. But yes, that is true. The recognizable languages, however, are closed under union and intersection, but they are not closed under complement. So that we will prove on Thursday's lecture. So another question is, could we have just run B on w in this-- in solving this problem, instead of using reduced-- converting it to a new Turing machine-- the B prime? Well, yes, we could have just done that. OK. I think we better move on. I don't want to get too bogged down here-- got a lot of questions there, so sorry if I'm not getting to all of the questions. OK. Or you can write to the TAs too, obviously. I'm sure you are.","65.66960144042969","10","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_7_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"228","What is the base case in the induction proof for the correctness of the birthday matching algorithm?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
If we know that some problem (say !TM) is undecidable, 
we can use that to show other problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Recall Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
2 
","74.03369140625","1","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_2_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"228","What is the base case in the induction proof for the correctness of the birthday matching algorithm?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 1: Introduction 
Lecture 1: Introduction 
The goal of this class is to teach you to solve computation problems, and to communicate that 
your solutions are correct and efﬁcient. 
Problem 
• Binary relation from problem inputs to correct outputs 
• Usually don’t specify every correct output for all inputs (too many!) 
• Provide a veriﬁable predicate (a property) that correct outputs must satisfy 
• 6.006 studies problems on large general input spaces 
• Not general: small input instance 
– Example: In this room, is there a pair of students with same birthday? 
• General: arbitrarily large inputs 
– Example: Given any set of n students, is there a pair of students with same birthday? 
– If birthday is just one of 365, for n > 365, answer always true by pigeon-hole 
– Assume resolution of possible birthdays exceeds n (include year, time, etc.) 
Algorithm 
• Procedure mapping each input to a single output (deterministic) 
• Algorithm solves a problem if it returns a correct output for every problem input 
• Example: An algorithm to solve birthday matching 
– Maintain a record of names and birthdays (initially empty) 
– Interview each student in some order 
∗ If birthday exists in record, return found pair! 
∗ Else add name and birthday to record 
– Return None if last student interviewed without success 
","73.59085845947266","2","DPRSearchEngine","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_1_pdf","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1","6.006","1"
"228","What is the base case in the induction proof for the correctness of the birthday matching algorithm?"," 
 
 
 
 
 
 
   
 
  
  
 
 
 
 
   
 
 
 
 
 
  
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
  
 
 
Revisit Hilbert’s 10th Problem 
Recall ! = 〈$〉 polynomial $ &', &), … , &+ = 0 has integer solution) 
Hilbert’s 10th problem (1900): Is ! decidable? 
Theorem (1971): No 
Proof: Show -TM is reducible to !. [would take entire semester] 
Do toy problem instead which has a similar proof method. 
Toy problem: The Post Correspondence Problem. 
Method: The Computation History Method. 
3 
","72.93721008300781","3","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_3_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"228","What is the base case in the induction proof for the correctness of the birthday matching algorithm?"," 
  
  
  
 
  
 
 
 
 
  
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
  
  
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
!""! is undecidable 
Recall !""! = ! ! has a match } 
Theorem: !""! is undecidable 
Proof: Show %TM is reducible to !""!. Uses the computation history method. 
()
Technical assumption: Match must start with 
. Can fix this assumption. 
*) 
Assume that TM + decides !""! 
Construct TM , deciding %TM 
, = “on input -, / 
1. Construct PCP instance !0,1 where a match corresponds to 
a computation history for - on /. 
2.  Use + to determine whether !0,1 has a match. 
3. Accept if yes. Reject if no.” 
9 
","72.82810974121094","4","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_9_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"228","What is the base case in the induction proof for the correctness of the birthday matching algorithm?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
Use our knowledge that !TM is undecidable to show other 
problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
10 
","72.64479064941406","5","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_10_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"228","What is the base case in the induction proof for the correctness of the birthday matching algorithm?"," 
 
 
  
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
Computation with Oracles 
Let ! be any language. 
Defn: A TM "" with oracle for !, written ""#, is a TM equipped 
with a “black box” that can answer queries “is $ ∈!?” for free. 
Example: A TM with an oracle for &!' can decide all ( ∈ NP in polynomial time. 
Defn: P# = ( ( is decidable in polynomial time with an oracle for !} 
Thus NP ⊆ P+#, 
NP = P+#,? Probably No because coNP ⊆ P+#, 
Defn: NP# = ( ( is decidable in nondeterministic polynomial time with an oracle for !} 
Recall MIN-FORMULA = 7 7 is a minimal Boolean formula } 
Example: MIN−FORMULA ∈ NP+#, 
“On input 7 
1. Guess shorter formula 9 
2.  Use &!' oracle to solve the coNP problem: 7 and 9 are equivalent 
3. Accept if 7 and 9 are equivalent. Reject if not.” 
8 
","72.27669525146484","6","DPRSearchEngine","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_8_pdf","50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22","18.404J","22"
"228","What is the base case in the induction proof for the correctness of the birthday matching algorithm?","4 
Lecture 1: Introduction 
1 
def birthday_match(students): 
2 
’’’ 
3 
Find a pair of students with the same birthday 
4 
Input: 
tuple of student (name, bday) tuples 
5 
Output: tuple of student names or None 
6 
’’’ 
7 
n = len(students) 
# O(1) 
8 
record = StaticArray(n) 
# O(n) 
9 
for k in range(n): 
# n 
10 
(name1, bday1) = students[k] 
# O(1) 
11 
# Return pair if bday1 in record 
12 
for i in range(k): 
# k 
13 
(name2, bday2) = record.get_at(i) 
# O(1) 
14 
if bday1 == bday2: 
# O(1) 
15 
return (name1, name2) 
# O(1) 
16 
record.set_at(k, (name1, bday1)) 
# O(1) 
17 
return None 
# O(1) 
Example: Running Time Analysis 
• Two loops: outer k ∈{0, . . . , n − 1}, inner is i ∈{0, . . . , k}
P n−1
• Running time is O(n) + 
k=0 (O(1) + k · O(1)) = O(n2) 
• Quadratic in n is polynomial. Efﬁcient? Use different data structure for record! 
How to Solve an Algorithms Problem 
1. Reduce to a problem you already know (use data structure or algorithm) 
Search Problem (Data Structures) 
Sort Algorithms 
Static Array (L01) 
Insertion Sort (L03) 
Linked List (L02) 
Selection Sort (L03) 
Dynamic Array (L02) 
Merge Sort (L03) 
Sorted Array (L03) 
Counting Sort (L05) 
Direct-Access Array (L04) 
Radix Sort (L05) 
Hash Table (L04) 
AVL Sort (L07) 
Balanced Binary Tree (L06-L07) 
Heap Sort (L08) 
Binary Heap (L08) 
2. Design your own (recursive) algorithm 
• Brute Force 
• Decrease and Conquer 
• Divide and Conquer 
• Dynamic Programming (L15-L19) 
• Greedy / Incremental 
Shortest Path Algorithms 
Breadth First Search (L09) 
DAG Relaxation (L11) 
Depth First Search (L10) 
Topological Sort (L10) 
Bellman-Ford (L12) 
Dijkstra (L13) 
Johnson (L14) 
Floyd-Warshall (L18) 
","72.03585815429688","7","DPRSearchEngine","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_4_pdf","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1","6.006","1"
"228","What is the base case in the induction proof for the correctness of the birthday matching algorithm?"," 
 
 
 
 
 
 
 
 
 
 
  
 
 
The Birthday Problem  
What’s the probability of at least two people in a  
group having the same birthday 
If there are 367 people in the group? 
What about smaller numbers? 
If we assume that each birthdate is equally likely  
366! 
◦ 1­

366𝑁∗ 366−𝑁 ! 
Without this assumption, VERY complicated 
shoutkey.com/niece 
6.0002 LECTURE 4 
18
","71.77091979980469","8","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_18_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"228","What is the base case in the induction proof for the correctness of the birthday matching algorithm?","  
 
 
 
  
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Recall: Acceptance Problem for TMs 
Let !TM = { &, ( | & is a TM and & accepts (} 
Today’s Theorem: !TM is not decidable 
Proof uses the diagonalization method, 
so we will introduce that first. 
2 
","71.74205017089844","9","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_2_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"228","What is the base case in the induction proof for the correctness of the birthday matching algorithm?"," 
 
 
    
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Return to Closure Properties 
Recall Theorem: If !"", !$ are regular languages, so is !"" ∪!$ 
(The class of regular languages is closed under union) 
New Proof (sketch): Given DFAs &"" and &$ recognizing !"" and !$ 
&$
&"" 
ε 
ε 
& 
Construct NFA & recognizing !"" ∪!$ 
Nondeterminism 
parallelism 
vs 
guessing 
7 
","71.71143341064453","10","DPRSearchEngine","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_7_pdf","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2","18.404J","2"
"229","What is the purpose of using asymptotic notation in algorithm analysis?","Notation for encodings and TMs
Notation for encoding objects into strings
- If ! is some object (e.g., polynomial, automaton, graph, etc.), 
we write 〈!〉to be an encoding of that object into a string.  
- If !$, !&, … , !( is a list of objects then we write 〈!$, !&, … , !(〉
to be an encoding of them together into a single string. 
Notation for writing Turing machines
We will use high-level English descriptions of algorithms when we describe TMs, 
knowing that we could (in principle) convert those descriptions into states, 
transition function, etc.  Our notation for writing a TM ) is
) = “On input +
[English description of the algorithm]”
Check-in 6.3
If , and - are strings, would ,- be a good choice 
for their encoding 〈,, -〉into a single string?
a)
Yes.
b)
No. 
Check-in 6.3
8
","73.84969329833984","1","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_8_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"229","What is the purpose of using asymptotic notation in algorithm analysis?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","73.26038360595703","2","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"229","What is the purpose of using asymptotic notation in algorithm analysis?","What's the worst case performance of a hash table? If I have to look up something in a hash table, and I happen to choose a bad hash table-- hash function, what's the worst case here? What? n, right? It's worse than a sorted array, because potentially, I hashed everything that I was storing to the same index in my hash table, and to be able to distinguish between them, I can't do anything more than a linear search. I could store another set's data structure as my chain and do better that way. That's actually how Java does it. They store a data structure we're going to be talking about next week as the chains so that they can get, worst case, log n. But in general, that hash table is only good if we're allowing-- OK, I want this to be expected good, but in the worst case, if I really need that operation to be worst case-- I really can't afford linear time ever for an operation of that kind-- then I don't want to use a hash table. And so on your p set 2, everything we ask you for is worst case, so probably, you don't want to be using hash tables. OK? Yes? AUDIENCE: What does the subscript e mean? JASON KU: What does the subscript e mean? That's great. In this chart, I put a subscript on this is an expected runtime, or an A meaning this is an amortized runtime. At the end, we talked about how, if we had too many things in our hash table, then, as long as we didn't do it too often-- this is a little hand wavey argument, but the same kinds of ideas as the dynamic array-- if, whenever we got a linear-- we are more than a linear factor away from where we are trying-- basically, the fill factor we were trying to be, then we could just completely rebuild the hash table with the new hash function randomly chosen from our hash table with a new size, and we could get amortized bounds. And so that's what Python-- how Python implements dictionaries, or sets, or even objects when it's trying to map keys to different things. So that's hash tables. That's great. The key thing here is, well, actually, if your range of keys is small, or if you as a programmer have the ability to choose the keys that you identify your objects with, you can actually choose that range to be small, to be linear, to be small with respect to your items. And you don't need a hash table. You can just use a direct access array, because if you know your key space is small, that's great. So a lot of C programmers probably would like to do something like that, because they don't have access to-- maybe C++ programmers would have access to their hash table. Any questions on this stuff before we move on? Yeah? AUDIENCE: So why is [INAUDIBLE]? JASON KU: Why is it expected? When I'm building, I could insert-- I'm inserting these things from x 1 by 1 into my hash table. Each of those insert operations-- I'm looking up to see whether that-- an item with that key already exists in my hash table. And so I have to look down the chain to see where it is. However, if I happen to know that all of my keys are unique in my input, all the items I'm trying to store are unique, then I don't have to do that check and I can get worst case linear time. Does that make sense? All right. It's a subtlety, but that's a great question. OK, so today, instead of talking about searching, we're talking about sorting. Last week, we saw a few ways to do sort. Some of them were quadratic-- insertion sort and selection sort-- and then we had one that was n log n. And this thing, n log n, seemed pretty good, but can I do better? Can I do better? Well, what we're going to show at the beginning of this class is, in this comparison model, no. n log n is optimal. And we're going to go through the exact same line of reasoning that we had last week. So in the comparison model, what did we use when we were trying to make this argument that any comparison model algorithm was going to take at least log n time? What we did was we said, OK, I can think of any model in the comparison model-- any algorithm in the comparison model as kind of this-- some comparisons happen. They branch in a binary sense, but you could have it generalized to any constant branching factor. But for our purposes, binary's fine. And what we said was that there were at least n outputs-- really n plus 1, but-- at least order n outputs. And we showed that-- or we argued to you that the height of this tree had to be at least log n-- log the number of leaves. It had to be at least log the number of leaves. That was the height of the decision tree. And if this decision tree represented a search algorithm, I had to walk down and perform these comparisons in order, reach a leaf where I would output something. If the minimum height of any binary tree on a linear number of leaves is log n, then any algorithm in the comparison model also has to take log n time, because it has to do that many comparisons to differentiate between all possible outputs. Does that make sense? All right. So in the sort problem, how many possible outputs are there?","71.12495422363281","3","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_4_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"229","What is the purpose of using asymptotic notation in algorithm analysis?","which, I think, most of us would agree was not a very big number. And let's look what's going on here. If you look at this, what in some sense seems really stupid about it? What is it doing that a rational person would not want to do if they could avoid it? It's bad enough to do something once. But to do the same thing over and over again is really wasteful. And if we look at this, we'll see, for example, that fib 4 is being computed here, and fib 4 is being computed here. Fib 3 is being considered here, and here, and here. And do you think we'll get a different answer for fib 3 in one place when we get it in the other place? You sure hope not. So you think, well, what should we do about this? How would we go about avoiding doing the same work over and over again? And there's kind of an obvious answer, and that answer is at the heart of dynamic programming. What's the answer? AUDIENCE: [INAUDIBLE] JOHN GUTTAG: Exactly. And I'm really happy that someone in the front row answered the question because I can throw it that far. You store the answer and then look it up when you need it. Because we know that we can look things up very quickly. Dictionary, despite what Eric said in his lecture, almost all the time works in constant time if you make it big enough, and it usually is in Python. We'll see later in the term how to do that trick. So you store it and then you'd never have to compute it again. And that's the basic trick behind dynamic programming. And it's something called memoization, as in you create a memo and you store it in the memo. So we see this here. Notice that what we're doing is trading time for space. It takes some space to store the old results, but negligible related to the time we save. So here's the trick. We're going to create a table to record what we've done. And then before computing fib of x, we'll check if the value has already been computed. If so, we just look it up and return it. Otherwise, we'll compute it-- it's the first time-- and store it in the table. Here is a fast implementation of Fibonacci that does that. It looks like the old one, except it's got an extra argument-- memo-- which is a dictionary. The first time we call it, the memo will be empty. It tries to return the value in the memo. If it's not there, an exception will get raised, we know that.","70.55465698242188","4","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_9_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"229","What is the purpose of using asymptotic notation in algorithm analysis?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","70.34659576416016","5","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"229","What is the purpose of using asymptotic notation in algorithm analysis?","All right. So let me define a new automaton that we're going to mainly use as just to provide an example for us today. I'm going to call this a linearly bounded automaton. And all it is is a Turing machine where the Turing machine is going to be restricted in where it can-- the tape is not going to be infinite anymore. The tape is just going to be big enough to hold the input. So the machine no longer has the ability to move into the portion of the tape to the right of the input because there is no tape out there. It just has the tape sitting here that contains the input, which the tape itself can vary in size. However big the input is, that's how big the tape is. So the tape adjusts to the length of the input. But once you've started the machine with some particular input, that's as big as the tape is. There's no more. The reason why it's called linearly bounded is because the amount of memory is a linear function of the size of the input because you can effectively get somewhat more memory by enlarging the tape alphabet, but that's going to be fixed for any given machine, so that's where the linearly comes from, if that's helpful. But if you don't get that, it's sort of a side remark. But what's important to me is that you understand what I mean by a Linearly Bounded Automaton, or an LBA. It's just like a Turing machine, but that portion of the tape that originally had blanks is just not there. As the machine tries to move its head off the right end of the input, it just sticks there just as if it tried to move its head off the left end of the input. Doesn't go anywhere. So now, we're going to ask the same kinds of questions about LBAs that we ask for other automa. So the acceptance problem. If I give you an input and some particular LBA and I want to know, does the LBA accept that input? Well, and now the question is, is that the decidable or not? So at first glance, you might think, well, an LBA is like a Turing machine, and the ATM problem is undecidable, so that might be a good first guess. And also, if you try to simulate them, if you try to figure out how you would go about simulating the machine, if given b and w, if you actually tried to simulate the machine to get the answer, so you run b on w, well, of course, if you run it for a while, and it eventually halts, either accepting or rejecting, then you know the answer and you're finished. But this machine might get into a loop. You know, nothing to prevent the machine from looping on that finite amount of-- on that limited amount of tape that it has. And then you might be in trouble. But in fact, that's not the case because when you start out with a limited amount of tape, if you run the machine for a long time and it's not halting, it's going and going and going, inevitably, it's going to have to repeat, get into exactly the same configuration that it did before because there's only a limited number of configurations that the machine has. And once it repeats a configuration, it's going to be repeating that configuration forever, and it's going to be in a loop. So this problem, in fact, is decidable because the idea is if b on w runs for a very long time and an amount that you can calculate, then you know it's got to be cycling. More than just looping. It's got to be repeating itself. And so therefore, once it starts repeating itself, it's going to be going forever. So and here is the actual calculation, which is something I'm sure you could do on your own, but just to spell it out. So if you have an input of length n that you're providing to b, so if w is of length n, the LBA can only go for this number of different-- it can only have this number of different configurations. The number of states times the number of head positions, which is n, the number of head positions on the tape, times the number of different tape contents. If the tape was only one long, this is the-- this is the size of the tape alphabet. So if the tape were two long, the tape had two cells on it, the number of possible tape contents would be the square of the alphabet. And if the tape is going to be n symbols long, it's going to be the tape alphabet size to the nth power. So therefore, if a Turing machine runs for longer, it's got to repeat some configuration, and it'll never hold. So the decider is going to be hopefully clear at this point. You're given b and w, so this is the decider for a LBA. It's going to run b on w for this number of steps. If it's accepted by then, then you accept, and if it hasn't, if it's rejected or it's still running, then you can reject. And you know, if it's still running at this point, it's never going to accept. All right. Any questions on this? OK, let's move on.","70.22998046875","6","DPRSearchEngine","MGqoLm2aAgc.en-j3PyPqV-e1s_7_mp4","MGqoLm2aAgc.en-j3PyPqV-e1s","18.404J","10"
"229","What is the purpose of using asymptotic notation in algorithm analysis?"," 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 18: Pseudopolynomial 
Lecture 18: Pseudopolynomial 
Dynamic Programming Steps (SRT BOT) 
1. Subproblem deﬁnition 
subproblem x ∈ X 
• Describe the meaning of a subproblem in words, in terms of parameters 
• Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence 
• Often multiply possible subsets across multiple inputs 
• Often record partial state: add subproblems by incrementing some auxiliary variables 
• Often smaller integers than a given integer (today’s focus) 
2. Relate subproblem solutions recursively 
x(i) = f(x(j), . . .) for one or more j < i 
• Identify a question about a subproblem solution that, if you knew the answer to, reduces 
the subproblem to smaller subproblem(s) 
• Locally brute-force all possible answers to the question 
3. Topological order to argue relation is acyclic and subproblems form a DAG 
4. Base cases 
• State solutions for all (reachable) independent subproblems where relation breaks down 
5. Original problem 
• Show how to compute solution to original problem from solutions to subproblem(s) 
• Possibly use parent pointers to recover actual solution, not just objective function 
6. Time analysis 
P 
• 
work(x), or if work(x) = O(W ) for all x ∈ X, then |X| · O(W )
x∈X 
• work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time 
","70.00286102294922","7","DPRSearchEngine","mit6_006s20_lec18_1_pdf","mit6_006s20_lec18","6.006","18"
"229","What is the purpose of using asymptotic notation in algorithm analysis?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 5: Linear Sorting 
Lecture 5: Linear Sorting 
Review 
• Comparison search lower bound: any decision tree with n nodes has height ≥dlg(n+1)e−1 
• Can do faster using random access indexing: an operation with linear branching factor! 
• Direct access array is fast, but may use a lot of space (Θ(u)) 
• Solve space problem by mapping (hashing) key space u down to m = Θ(n) 
• Hash tables give expected O(1) time operations, amortized if dynamic 
• Expectation input-independent: choose hash function randomly from universal hash family 
• Data structure overview! 
• Last time we achieved faster ﬁnd. Can we also achieve faster sort? 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
Direct Access Array 
u 
1 
1 
u 
u 
Hash Table 
n(e) 
1(e) 
1(a)(e) 
n 
n 
","69.95390319824219","8","DPRSearchEngine","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5_1_pdf","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5","6.006","5"
"229","What is the purpose of using asymptotic notation in algorithm analysis?","And a comparison model means-- is that the items, the objects I'm storing-- I can kind of think of them as black boxes. I don't get to touch these things, except the only way that I can distinguish between them is to say, given a key and an item, or two items, I can do a comparison on those keys. Are these keys the same? Is this key bigger than this one? Is it smaller than this one? Those are the only operations I get to do with them. Say, if the keys are numbers, I don't get to look at what number that is. I just get to take two keys and compare them. And actually, all of the search algorithms that we saw on Tuesday we're comparison sort algorithms. What you did was stepped through the program. At some point, you came to a branch and you looked at two keys, and you branched based on whether one key was bigger than another. That was a comparison. And then you move some stuff around, but that was the general paradigm. Those three sorting operations lived in this comparison model.","69.70465087890625","9","DPRSearchEngine","Nu8YGneFCWE.en-j3PyPqV-e1s_2_mp4","Nu8YGneFCWE.en-j3PyPqV-e1s","6.006","4"
"229","What is the purpose of using asymptotic notation in algorithm analysis?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","69.68064880371094","10","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"236","What does the variable 'n' represent in the process of evaluating a model with randomized sampling?","!	!	 	
 
Let D be the original data set 
    n be the number of random samples  
 
 
 usually n between 20% and 50% 
    k be number of trials 
 
testResults = [] 
for i in range(k) 
    randomly select n elements for testSet,  
       keep rest for training 
    model = buildModel(training) 
    testResults.append(test(model, testSet)) 
 
Average testResults 

	

;G
","80.63970184326172","1","DPRSearchEngine","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10_38_pdf","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10","6.0002","10"
"236","What does the variable 'n' represent in the process of evaluating a model with randomized sampling?"," 
 
Three Different Distributions  
random.random() 
random.gauss(0, 1) 
6.0002  LECTURE 8 
 
random.expovariate(0.5) 
28
","77.38678741455078","2","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_28_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"236","What does the variable 'n' represent in the process of evaluating a model with randomized sampling?","	
	! 
for f in range(numSubsets): 
    trainX,trainY,testX,testY = splitData(xVals, yVals) 
    for d in dimensions: 
        model = pylab.polyfit(trainX, trainY, d) 
        #estYVals = pylab.polyval(model, trainX) 
        estYVals = pylab.polyval(model, testX) 
        rSquares[d].append(rSquared(testY, estYVals)) 
 
print('Mean R-squares for test data') 
for d in dimensions: 
    mean = round(sum(rSquares[d])/len(rSquares[d]), 4) 
    sd = round(numpy.std(rSquares[d]), 4) 
    print('For dimensionality', d, 'mean =', mean, 
          'Std =', sd) 
	

?F
","76.30007934570312","3","DPRSearchEngine","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10_47_pdf","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10","6.0002","10"
"236","What does the variable 'n' represent in the process of evaluating a model with randomized sampling?","random.choice. It takes as an argument a sequence, in this case a list, and randomly chooses one member of the list. And it chooses it uniformly. It's a uniform distribution. And what that means is that it's equally probable that it will choose any number in that list each time you call it. We'll later look at distributions that are not uniform, not equally probable, where things are weighted. But here, it's quite simple, it's just uniform. And then we can test it using testRoll-- take some number of n and rolls the die that many times and creates a string telling us what we got. So let's consider running this on, say, testRoll of five. And we'll ask the question, if we run it, how probable is it that it's going to return a string of five 1's? How do we do that? Now, how many people here are either in 6.041 or would have taken 6.041? Raise your hand. Oh, good. So very few of you know probability. That helps. So how do we think about that question? Well, probability, to me at least, is all about counting, especially discrete probability, which is what we're looking at here. What you do is you start by counting the number of events that have the property of interest and the number of possible events and divide one by the other. So if we think about rolling a die five times, we can enumerate all of the possible outcomes of five rolls. So if we look at that, what are the outcomes? Well, I could get five 1's. I could get four 1's and a 2 or four 1's and 3, skip a few. The next one would be three 1's, a 2 and a 1, then a 2 and 2, and finally, at the end, all 6's. So remember, we looked before at when we're looking at optimization problems about binary numbers. And we said we can look at all the possible choices of items in the knapsack by a vector of 0's and 1's. We said, how many possible choices are there? Well, it depended on how many binary numbers you could get in that number of digits. Well, here we're doing the same thing, but instead of base 2, it's base 6. And so the number of possible outcomes of five rolls is quite high. How many of those are five 1's? Only one of them, right? So in order to get the probability of a five 1's, I divide 1 by 6 to the fifth. Does that makes sense to everybody? So in fact, we see it's highly unlikely. The probability of a five 1's is quite small. Now, suppose we were to ask about the probability of something else-- instead of five 1's, say 53421. It kind of looks more likely than that than five 1's in a row, but of course, it isn't, right? Any specific combination is equally probable. And there are a lot of them. So this is all the probability we're going to think about we could think about this way, as simply a matter of counting-- the number of possible events, the number of events that have the property of interest-- in this case being all 1's-- and then simple division. Given that framework, there were three basic facts about probability we're going to be using a lot of. So one, probabilities always range from 0 to 1. How do we know that? Well, we've got a fraction, right? And the denominator is all possible events. The numerator is the subset of that that's of interest. So it has to range from 0 to the denominator. And that tells us that the fraction has to range from 0 to 1. So 1 says it's always going to happen, 0 never. So if the probability of an event occurring is p, what's the probability of it not occurring? This follows from the first bullet. It's simply going to be 1 minus p. This is a trick that we'll find we'll use a lot. Because it's often the case when you want to compute the probability of something happening, it's easier to compute the probability of it not happening and subtract it from 1. And we'll see an example of that later today. Now, here's the biggie. When events are independent of each other, the probability of all of the events occurring is equal to the product of the probabilities of each of the events occurring. So if the probability of A is 0.5 and the probability of B","76.1346206665039","4","DPRSearchEngine","-1BnXEwHUok.en-qlPKC2UN_YU_4_mp4","-1BnXEwHUok.en-qlPKC2UN_YU","6.0002","4"
"236","What does the variable 'n' represent in the process of evaluating a model with randomized sampling?"," 
 
Looking at  Distributions 
def plotDistributions():  
uniform, normal, exp = [], [], []  
for i in range(100000):  
uniform.append(random.random())  
normal.append(random.gauss(0, 1))  
exp.append(random.expovariate(0.5))  
makeHist(uniform, 'Uniform', 'Value', 'Frequency')  
pylab.figure()  
makeHist(normal, 'Gaussian', 'Value', 'Frequency')  
pylab.figure()  
makeHist(exp, 'Exponential', 'Value', 'Frequency')  
6.0002  LECTURE 8 
 
27
","76.04804229736328","5","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_27_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"236","What does the variable 'n' represent in the process of evaluating a model with randomized sampling?",";
/
def testGreedys(maxUnits):
print('Use greedy by value to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits, Food.getValue)
print('\\nUse greedy by cost to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits,
lambda x: 1/Food.getCost(x))
print('\\nUse greedy by density to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits, Food.density)
testGreedys(800)
	


4
","76.01427459716797","6","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_26_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"236","What does the variable 'n' represent in the process of evaluating a model with randomized sampling?","I'm going to look at a bunch of different sample sizes, from 25 to 600, 50 trials each. So getHighs is just a function that returns the temperatures. I'm going to get the standard deviation of the whole population, then the standard error of the means and the sample standard deviations, both. And then I'm just going to go through and run it. So for size and sample size, I'm going to append the standard error of the mean. And remember, that uses the population standard deviation and the size of the sample. So I'll compute all the SEMs. And then I'm going to compute all the actual standard deviations, as well. And then we'll produce a bunch of plots-- or a plot, actually. All right, so let's see what that plot looks like.","75.97733306884766","7","DPRSearchEngine","soZv_KKax3E.en-qlPKC2UN_YU_10_mp4","soZv_KKax3E.en-qlPKC2UN_YU","6.0002","8"
"236","What does the variable 'n' represent in the process of evaluating a model with randomized sampling?"," 
 
 
 
 
  
 
 
  
 
Probability of Various Results  
Consider testRoll(5) 
How probable is the output 11111?  
6.0002 LECTURE 4 
10
","75.631591796875","8","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_10_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"236","What does the variable 'n' represent in the process of evaluating a model with randomized sampling?","-
numTrials = 1000000
numSpins = 200
game = FairRoulette()
means = []
for i in range(numTrials):
means.append(findPocketReturn(game, 1, numSpins,
False)[0])
pylab.hist(means, bins = 19,
weights = [1/len(means)]*len(means))
pylab.xlabel('Mean Return')
pylab.ylabel('Probability')
pylab.title('Expected Return Betting a Pocket 200 Times')
	


","75.38729858398438","9","DPRSearchEngine","3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7_17_pdf","3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7","6.0002","7"
"236","What does the variable 'n' represent in the process of evaluating a model with randomized sampling?","I'll take in a set of observed values, a set of predicted values, and I'll measure the error-- again, these are arrays. So I'm going to take the difference between the arrays. That's going to give me piecewise or pairwise that difference. I'll square it. That's going to give me at every point in the array the square of that distance. And then because it's an array, I can just use the built-in sum function to add them all up. So this is going to give me the-- if you like, the values up there. And then I'm going to play a little trick. I'm going to compute the mean error, which is that thing divided by the number of observations. Why would I do that? Well, because then I can compute this really simply. I could write a little loop to compute it. But in fact, I've already said what is that? If I take that sum and divide it by the number of samples, that's the variance. So that's really nice. Right here I can say, get the variance using the non-p version of the observed data. And because that has associated with it division by the number of samples, the ratio of the mean error to the variance is exactly the same as the ratio of that to that. Little trick. It lets me save doing a little bit of computation. So I can compute r squared values. So what does r squared actually tell us? What we're doing is we're trying to compare the estimation errors, the top part, with the variability in the original values, the bottom part. So r squared, as you're going to see there, it's intended to capture what portion of the variability in the data is accounted for by my model. My model's a really good fit. It should account for almost all of that data. So what we see then is if we do a fit with a linear regression, r squared is always going to be between zero and one. And I want to just show you some examples. If r squared is equal to one, this is great. It says the model explains all of the variability in the data. And you can see it if we go back here. How do we make r squared equal to one? We need this to be zero, which says that the variability in the data is perfectly predicted by my model. Every point lies exactly along the curve. That's great. Second option at the other extreme is if r squared is equal to zero, you basically got bupkis, which is a well-known technical term, meaning there's no relationship between the values predicted by the model and the actual data. That basically says that all of the variability here is exactly the same as all the variability in the data. The model doesn't capture anything, and it's making this one, which is making the whole thing zero. And then in between an r squared of about a half says you're capturing about half the variability. So what you would like is a system in which your fit is as close to an r squared value of one as possible because it says my model is capturing all the variability in the data really well. So two functions that will do this for us.","74.9817123413086","10","DPRSearchEngine","vIFKGFl1Cn8.en-qlPKC2UN_YU_16_mp4","vIFKGFl1Cn8.en-qlPKC2UN_YU","6.0002","9"
"238","Why are all dates not equally likely for birthdates in a demographic context?","What's the probability of at least two people in a group having the same birthday? There's a URL at the bottom. That's pointing to a Google form. I'd like please all of you who have a computing device to go to it and fill out your birthday. It's anonymous, so we won't know how old you are, don't worry. Actually, it's only the date. It's not the year. So suppose there were 367 people in the group, roughly the number of people who took the 6.0001 600 midterm. If they are 367 people, what's the probability of at least two of them sharing a birthday? One, by something called the pigeonhole principle. You got some number of holes. And if you have more pigeons than holes, two pigeons have to share a whole. What about smaller numbers? Well, if we make a simplifying assumption that each birthdate is equally likely, then there's actually a nice closed-form solution for it. Again, this is a question where it's easier to compute the opposite of what you're trying to do and subtract it from 1. And so this fraction is giving the probability of two people not sharing a birthday. The proof that this is right, it's a little bit elaborate. But you can trust me, it's accurate. But it's a formula, and it's not that complicated a formula. So numbers like 366 factorial are big. So let's approximate a solution. We'll right a simulation and see if we get the same answer that that formula gave us. So here's the code for that-- two arguments-- the number of people in the group and the number that we asking do they have the same birthday. So since I'm assuming for now that every birthday is equally likely, the possible dates range from 1 to 366, because some years have a February 29. I'll keep track of the number of people born in each date by starting with none. And then for p in the range of number of people, I'll make a random choice of the possible dates and increment that element of the list by 1. And then at the end, we can say, look at the maximum number of birthdays and see if it's greater than or equal to the number of same. So that tells us that. And then we can actually look at the birthday problem-- number of people, the number of same, and, as usual, the number of trials. So the number of hits is 0 for t in range number of trials. If sameDate is true, then we'll increment the number of hits by 1 and then as usual divide by the number of trials. And we'll try it for 10, 20, 40, and 100 people. And then just, we'll print the estimated probability","70.53448486328125","1","DPRSearchEngine","-1BnXEwHUok.en-qlPKC2UN_YU_9_mp4","-1BnXEwHUok.en-qlPKC2UN_YU","6.0002","4"
"238","Why are all dates not equally likely for birthdates in a demographic context?"," 
 
 
 
 
 
 
 
 
 
 
  
 
 
The Birthday Problem  
What’s the probability of at least two people in a  
group having the same birthday 
If there are 367 people in the group? 
What about smaller numbers? 
If we assume that each birthdate is equally likely  
366! 
◦ 1­

366𝑁∗ 366−𝑁 ! 
Without this assumption, VERY complicated 
shoutkey.com/niece 
6.0002 LECTURE 4 
18
","70.05860900878906","2","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_18_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"238","Why are all dates not equally likely for birthdates in a demographic context?"," 
  
 
  
 
 
 
    
 
 
    
 
        
 
            
 
 
    
 
           
 
 
    
 
 
          
 
          
 
    
 
    
 
 
    
 
          
 
 
 
Approximating Using a Simulation  
def birthdayProb(numPeople, numSame, numTrials): 
numHits = 0 
for t in range(numTrials): 
if sameDate(numPeople, numSame):  
numHits += 1  
return numHits/numTrials  
for numPeople in [10, 20, 40, 100]: 
print('For', numPeople,  
'est. prob. of a shared birthday is',  
birthdayProb(numPeople, 2, 10000))  
numerator = math.factorial(366) 
denom = (366**numPeople)*math.factorial(366-numPeople) 
print('Actual prob. for N = 100 =', 
1 - numerator/denom) 
Suppose we want the probability of 3 people sharing  
6.0002 LECTURE 4 
20
","68.50344848632812","3","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_20_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"238","Why are all dates not equally likely for birthdates in a demographic context?"," 
 
 
Does Population  Size Matter?  
6.0002  LECTURE 8 
 
30
","68.32672882080078","4","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_30_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"238","Why are all dates not equally likely for birthdates in a demographic context?","So now-- and don't worry about the exact details here-- but what I'm doing is simply adjusting the simulation to change the probability of each date getting chosen by same date. And then I can run the simulation model. And, again, with a very small change to code, I've modeled something that's mathematically enormously complex. I have no idea how to actually do this probability mathematically. But the code is, as you can see, quite straightforward. So let's go to that here. So what I'm going to do is comment this one out and uncomment this more complicated set of dates and see what we get. And again, it changes quite dramatically. You might remember, before it was around I think 0.6-something for 100, and now, it's 0.75. So getting away from the notion that birthdays are uniformly distributed to saying some birthdays are more common than others, again, dramatically changes the answer. And we can easily look at that. So that gets us to the big topic of simulation models.","67.68866729736328","5","DPRSearchEngine","-1BnXEwHUok.en-qlPKC2UN_YU_11_mp4","-1BnXEwHUok.en-qlPKC2UN_YU","6.0002","4"
"238","Why are all dates not equally likely for birthdates in a demographic context?"," 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Non-representative Sampling  
§“Convenience sampling” not usually random, e.g.,
◦Survivor  bias,  e.g.,  course evaluations at end of course or
grading final exam in 6.0002  on a strict curve
◦Non-response bias,  e.g.,  opinion polls conducted by mail
or  online
§When samples not random and independent, we can
still do things like computer means and standard 
deviations, but we should not draw conclusions from 
them using things like the empirical rule and central 
limit theorem. 
§Moral: Understand how data was collected, and
whether assumptions used in the analysis are satisfied. 
If not, be wary. 
6.0002  LECTURE 14 
22 
","67.57796478271484","6","DPRSearchEngine","b9d60f4ecb325e4648f9cf0379419338_MIT6_0002F16_lec14_22_pdf","b9d60f4ecb325e4648f9cf0379419338_MIT6_0002F16_lec14","6.0002","14"
"238","Why are all dates not equally likely for birthdates in a demographic context?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 1: Introduction 
Lecture 1: Introduction 
The goal of this class is to teach you to solve computation problems, and to communicate that 
your solutions are correct and efﬁcient. 
Problem 
• Binary relation from problem inputs to correct outputs 
• Usually don’t specify every correct output for all inputs (too many!) 
• Provide a veriﬁable predicate (a property) that correct outputs must satisfy 
• 6.006 studies problems on large general input spaces 
• Not general: small input instance 
– Example: In this room, is there a pair of students with same birthday? 
• General: arbitrarily large inputs 
– Example: Given any set of n students, is there a pair of students with same birthday? 
– If birthday is just one of 365, for n > 365, answer always true by pigeon-hole 
– Assume resolution of possible birthdays exceeds n (include year, time, etc.) 
Algorithm 
• Procedure mapping each input to a single output (deterministic) 
• Algorithm solves a problem if it returns a correct output for every problem input 
• Example: An algorithm to solve birthday matching 
– Maintain a record of names and birthdays (initially empty) 
– Interview each student in some order 
∗ If birthday exists in record, return found pair! 
∗ Else add name and birthday to record 
– Return None if last student interviewed without success 
","67.37342071533203","7","DPRSearchEngine","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_1_pdf","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1","6.006","1"
"238","Why are all dates not equally likely for birthdates in a demographic context?"," 
  
 
  
 
 
 
    
 
 
    
 
    
 
        
 
 
        
 
    
 
Approximating Using a Simulation  
def sameDate(numPeople, numSame): 
possibleDates = range(366) 
birthdays = [0]*366 
for p in range(numPeople): 
birthDate = random.choice(possibleDates) 
birthdays[birthDate] += 1 
return max(birthdays) >= numSame 
6.0002 LECTURE 4 
19
","67.25890350341797","8","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_19_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"238","Why are all dates not equally likely for birthdates in a demographic context?","that formula I showed you. I have not shown you, but I've imported a library called math, because it is a factorial implementation. It's way faster than the recursive one that we've seen before. Let's run it. And we'll see what we get. So for 10, the estimated probability is 0.11 now. So you can see, the estimates are really pretty good. Once again, we have this business that for 100, we're estimating 1, when the real answer is point many, many 9's. But again, this is sample probability. It just means in the number of trials we did, every 1 for 100 people, there was a shared birthday. This is a number that usually surprises people, as to why with 100 people the probability is so high. But we could work out the formula and see it. And as you can see, the estimates are pretty good from my simulation. Now, we're going to see why we did a simulation in the first place. Suppose we want the probability of three people sharing a birthday instead of two. It's pretty easy to see how we changed the simulation. I even made a parameter. I just changed the number 2 to number 3. The math, on the other hand, is ugly. Why is the math so much uglier for 3 than for 2? Because for 2, the complementary problem-- the number we're subtracting from 1-- is simply the question of, are all birthdays different? So did two people share a birthday is 1 minus or all does everybody have a different birthday. On the other hand, for 3 people, the complementary problem is a complicated disjunct-- a bunch of ors-- either all birthdays are distinct, or two people share a birthday and the rest are distinct, or there are two groups of two people sharing a birthday and everything is distinct. So you can see here, there's a lot of possibilities. And so it's 1 minus now a very complicated formula. And in fact, if you try and look how to do this, most people will tell you don't bother. Here's kind of a good approximation. But the math gets very hairy. In contrast, changing the simulation is dead easy. We can do that. Whoops. So if we come over here for the code, all I have to do is change this to 2 or 3. And I'm going to leave in this code, which is the wrong code, computing the actual probability now for 2 people sharing rather than 3, because I want to make it easy for you to see the difference between what happens when we look at 3 shared rather than 2 shared. And I get invalid syntax. That's not good. That's what happens when I type in real time. Why do I have invalid syntax? AUDIENCE: Line 56. JOHN GUTTAG: Pardon. AUDIENCE: Line 56. JOHN GUTTAG: One person, Anna. AUDIENCE: Line 56, there's a comma. JOHN GUTTAG: Oh. That's not a good line. So now, we see that if we get, say, to n equals 100, for 2, you'll remember, it was 0.99. But for 3, it's only 0.63. So we see going from two sharing to three sharing gets us a radically different answer, not surprisingly. But we also-- and the real thing I wanted you to see-- is how easy it was to answer this question with the simulation. And that's a primary reason we use simulations to get probabilistic questions rather than sitting down and the pencil and paper and doing fancy probability calculations, because it's often way easier to do a simulation. We can see that in spades if we look at the next question. Let's think about this assumption that all birthdays are equally likely. Well, as you can see, this is a chart of how common birthdates are in the US, a heat map. And you'll see, for example, that February 29 is quite an uncommon birthday. So we should probably treat that differently. Somewhat surprisingly, you'll see that July 4 is a very uncommon birthday as well. It's easy to understand why February 29. The only thing I can figure out for July 4 is obstetricians don't like working on holidays. And so they induce labor sometime around the 2nd or the 3rd, so they don't have to come to work on the 4th or the 5th. Sounds a horrible thought. But I can't think of any other explanation for this anomaly. You'll probably, if you look at it, see Christmas day is not so common either. So now, the question, which we can answer, since you've all fill out this form, is how exceptional are MIT students? We like to think that you're different in every respect. So are your birthdays distributed differently than other dates? Have we got that data? So now we'll go look at that. We should have a heat map for you guys. This one? AUDIENCE: Yep. I removed all the February 31. Thank you for those submissions. [LAUGHTER] JOHN GUTTAG: So here it is. And we can see that, well, they don't seem to be banded quite as much in the summer months, probably says more about your parents than it does about you. But you can see that, indeed, we do have-- wow, we have a day where there are five birthdays, that look like? Or no? AUDIENCE: February 12. JOHN GUTTAG: Wow. You want to raise your hand if you're born on February 12? [LAUGHTER] So you are exceptional in that you lie about when you're born. But if you hadn't lied, I think we would have still seen the probabilities would hold. How many people were there, do we know? AUDIENCE: 146 with 112 unique birthdays. JOHN GUTTAG: 146 people, 112 unique birthdays. So indeed, the probability does work. So we know you're exceptional in a funny way. Well, you can imagine how hard it would be to adjust the analytic model to account for a weird distribution of birthdates. But again, adjusting the simulation model is easy. I could have gone back to that heat map I showed you of birthdays in the US and gotten a separate probability for each day, but I was too lazy. And instead, what I observed was that we had a few days, like February 29, highly unlikely, and this band in the middle of people who were conceived in the late fall and early winter. So what I did is I duplicated some dates. So the 58th day of the year, February 29, occurs only once. The dates before that, I said, let's pretend they occur four times. What only matters here is not how often they occur but the relative frequency. And then the dates after that occur four times except for the dates in that band, which is going","67.11039733886719","9","DPRSearchEngine","-1BnXEwHUok.en-qlPKC2UN_YU_10_mp4","-1BnXEwHUok.en-qlPKC2UN_YU","6.0002","4"
"238","Why are all dates not equally likely for birthdates in a demographic context?"," 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
Probability Sampling  
§Each member of the population has a nonzero
probability of being included  in  a sample
§Simple random sampling: each member has an equal
chance of  being chosen
§Not always appropriate
◦Are MIT undergraduates nerds?
◦Consider a random sample of 100  students
6.0002  LECTURE 8 
 
4
","67.0561294555664","10","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_4_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"241","What are experimental devices used for?","Let's move now to Turing machines. This is where stuff is really going to start to get interesting-- hope it's been interesting all along, but maybe even more interesting.","65.26644897460938","1","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_15_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"241","What are experimental devices used for?","We could basically change something about our computer to be put in some other weird paradigm of solving problems with more power essentially, or you're","65.22602844238281","2","DPRSearchEngine","2NMtS1ecb3o.en-j3PyPqV-e1s_12_mp4","2NMtS1ecb3o.en-j3PyPqV-e1s","6.006","20"
"241","What are experimental devices used for?","OK, so today's topic is about self-reference, self-reproducing machines, and the broader topic called the recursion theorem. So let me introduce it with what I would call the self-reproduction paradox. And that is, suppose you have a factory, like a Tesla effect or a car manufacturing factory. See, there's a picture of the factory, and it's producing cars. All right? So we have a factory that makes cars. And what can we say about the relative complexity of the cars compared with the factory, in some informal sense? So I would argue that you would be reasonable to say that the complexity of the factory is going to have to be greater than the complexity of the cars that it makes. Because not only does the factory have to know how to make the cars, so it has to have all the instructions and whatever things that go into a car, it has to be included in at least some kind of-- it has to be, in some sense, represented in the factory. But the factory also has to have other stuff-- the robots, and the other manufacturing items, tools, and so on-- for making the cars. So the factory has to have all the complexity of a car incorporated plus other things as well. And for that reason, one could imagine that the factory's complexity is more than the car's complexity. But now, suppose you want to have a factory that makes factories-- so imagine here's the picture-- or in general, a machine that makes copies of itself. Well, that seems, at first glance, to be impossible. Because not only does the factory obviously have to have all of the instructions for what a factory is like, but it needs to have all of the extra things that it would need to do the manufacturing. And so for that reason, it seems like it's not possible to have a machine make copies of itself. I mean, you would run into the very same problem if I asked you to produce a program in your favorite language that prints out itself-- an exact copy of the same code. You can always write a program which is going to print out some string, like Hello, world. That's easy because you just put Hello, world into some kind of a variable or some sort of a table into the program and say print that table. But if you want the program to print out a copy of itself, you can't take the whole program and stick that into a table because the program is going to have to be bigger than the table. And so, you're going to end up with something impossible happening. Because the program-- an entire copy of the program can't fit inside the program. You just get the program inside itself, inside itself, inside itself, forever. And so, you end up with an infinite program that way. So if you just kind of naively approach the problem for how to make a program which is going to print out a copy of itself, it's not so easy to do. But hopefully, after today's lecture, you will see that it is possible and in fact, how to do it. And not only that is an idle bit of curiosity, but there are actually applications for why you might want to do that, mainly within mathematics and in computer science theory. But there's even a kind of a real-world application, if you will, in a way too. So we'll get to that at the end. So it seems, as I'm saying, impossible to have a self-reproducing machine. But we know that in the world, there are things that make copies of themselves-- living things. So it seems like a paradox. Cells can make copies exactly of themselves. All living things can make copies of themselves. So how do they manage to get around this paradox? Well, in fact, it is no paradox because it is possible to make a machine that self-reproduces, that makes copies of itself. And this has been known for many years. Probably, it goes back to Von Neumann who wrote a famous paper on self-reproducing machines. OK, so self-reproducing machines are, in fact, possible.","64.26136016845703","3","DPRSearchEngine","N-_XmLanPYg.en-j3PyPqV-e1s_2_mp4","N-_XmLanPYg.en-j3PyPqV-e1s","18.404J","11"
"241","What are experimental devices used for?"," 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
Output of Simulation  
Actual probability = 0.0001286 
Estimated Probability = 0.0 
Actual probability = 0.0001286 
Estimated Probability = 0.0 
How did I know that this is what would get printed?  
Why did simulation give me the wrong answer? 
Let’s try 1,000,000 trials  
6.0002 LECTURE 4 
16
","64.06444549560547","4","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_16_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"241","What are experimental devices used for?","Another great MIT company called Mobileye that does computer vision systems with a heavy machine learning component that is used in assistive driving and will be used in completely autonomous driving. It will do things like kick in your brakes if you're closing too fast on the car in front of you, which is going to be really bad for me because I drive like a Bostonian. And it would be kicking in constantly. Face recognition. Facebook uses this, many other systems do to both detect and recognize faces. IBM Watson-- cancer diagnosis. These are all just examples of machine learning being used everywhere. And it really is. I've only picked nine. So what is it? I'm going to make an obnoxious statement. You're now used to that. I'm going to claim that you could argue that almost every computer program learns something. But the level of learning really varies a lot. So if you think back to the first lecture in 60001, we showed you Newton's method for computing square roots. And you could argue, you'd have to stretch it, but you could argue that that method learns something about how to compute square roots. In fact, you could generalize it to roots of any order power. But it really didn't learn. I really had to program it. All right. Think about last week when we talked about linear regression. Now it starts to feel a little bit more like a learning algorithm. Because what did we do? We gave you a set of data points, mass displacement data points. And then we showed you how the computer could essentially fit a curve to that data point. And it was, in some sense, learning a model for that data that it could then use to predict behavior. In other situations. And that's getting closer to what we would like when we think about a machine learning algorithm. We'd like to have program that can learn from experience, something that it can then use to deduce new facts. Now it's been a problem in AI for a very long time. And I love this quote.","62.55799865722656","5","DPRSearchEngine","h0e2HAPTGF4.en_2_mp4","h0e2HAPTGF4.en","6.0002","11"
"241","What are experimental devices used for?","[SQUEAKING] [RUSTLING] [CLICKING] JASON KU: Hi, everybody. Welcome to the last lecture of 6.006. Last lecture, we talked about summing up this class and talking about future courses in the department that use this material. Just as a pointer to some of those classes, I have a little slide here I didn't get to at the last lecture, talking about what I was talking about at the end of the last lecture about different models-- different specialized classes on different aspects of 006 material-- for example, more graph stuff, different models of computation, randomness, complexity. All of these things have their own specialized classes in the department, as well as a lot of applications for this material in subjects like biology, cryptography, and in particular, for your instructors, the realm of graphics and geometry. All of your instructors this term happened to be geometers and be interested in geometry-related problems. Me in particular, I didn't start out in computer science. I started out in mechanical engineering. And the thing that was my passion coming into MIT was origami. Here's a couple of pieces that I designed-- origami pieces, one square sheet of paper without cutting. Here's a lobster, and here's a copyrighted dinosaur from a particular movie of the year that I designed it. When I was young, in high school, I started designing my own origami models. And what I didn't realize was, the procedures that I went about designing these models was actually algorithms. And I just didn't have the mathematical language to understand exactly what I was doing, but I could gain some intuition as an origami artist and design these things by using some of those algorithmic techniques. It wasn't until grad school, as a mechanical engineer, that I started talking with our other instructor here, Professor Demaine, about using algorithms and computer science to design not just origami, which we both do, but also folded structures that can be used for mechanical applications like space flight, deployable bridges in times when you can't-- you need a temporary bridge or shelter or something like that. Deployable structures where you might need to make folded structures-- transformable structures that can have different applications for different purposes-- need to reconfigure. The dream being that, we have these powerful devices in our pockets right now-- cell phones-- which are really powerful because we can reconfigure the bits in them to make software of all different kinds, right? There's an exponential number of different programs that we can write. And that's part of why you're here, is to write the next best one. Right? So that's how to make kind of a universal device at the electronic level. What if we could do that from a material standpoint? What if I could reprogram the matter in my phone so that, not only could I reprogram the app that's on your phone, but instead of having, say, the iPhone 10 or whatever that you have, and you want to go by the iPhone 11, instead, you download a software app that then reconfigures the matter in your phone-- it folds or reconfigures into the next generation iPhone. You don't have to throw away that old one. You can essentially recycle the material that you have to potentially save material, save cost, and be better for the environment, potentially. So I started moving into computer science because I found that it was a really good way to model the world and solve some really interesting problems about folding that I really enjoyed. The three of us today are going to spend some time talking a little bit about how we can use algorithms-- 6.006 material and beyond-- in our own research. And we're going to start off with Professor Demaine, and then Professor Solomon. ERIK DEMAINE: Thanks. So let me just jump in here to computational origami and geometric folding algorithms, sort of a broader umbrella for folding-related things, which is encapsulated by this class, 6.849, which is happening next fall. So you should all take it. 006 should be a reasonable background. And in general, we're interested in two kinds of problems. One-- the big one is origami design, or in general, folding design, where you have some specifications of what you would like to build. In this case I wanted to make a logo for 6.849. And I imagined extruding that text into third dimension. And then I wanted an algorithm to tell me how to fold that structure. And so there is an algorithm, which I'll talk about in a moment, that gives you a crease pattern. And then, currently, you fold it by hand. The dream is, we'll eventually have folding machines that do it all for us. And so that's the origami design, where you go from the target shape back to the crease pattern. The reverse direction is sort of foldability. If I gave you a structure like this and I wanted to know, does it fold? That's the problem we call foldability-- in general, class of problems. And sadly, most of those problems are NP-hard. Jason and I proved that foldability is hard for a general-- given a crease pattern like that, telling you whether folds into anything, it turns out to be NP-hard. So that's bad news. So we focus a lot on the design problem, because that actually tends to be easier. We can solve it with algorithms like that one you're seeing. A long time ago, we proved that you can fold everything. If I give you a square piece of paper and you take any polygon you want to make-- or maybe the paper's white on one side, black on the other, you want to fold some two-color pattern, like a zebra, or in general, some three-dimensional surface, like these guys, there is a way to fold it from a large enough square of paper. And it's actually really easy to prove that with an algorithm. I have the sketch of the two pages of proof that we go over in 6.849, but I'll just hand-wave a little bit. If you take a piece of paper, like my lecture notes here, the first thing you do is fold it down into a very long, narrow strip-- much longer and narrower than this one-- wasting most of the material. And then you take your strip, and you just figure out how to turn it in some general way, and then you just sort of zigzag back and forth along the surface. So it's very cool in that you can prove with an algorithm, and in a very short amount of time, to someone you can actually fold everything. Of course, it's a terrible folding, because in the very first step, we throw away all but epsilon of the material. But it's a starting point. That was back in the '90s-- late '90s-- one of the first results in computational origami. And in modern times, we look for better algorithms that are more efficient, that try to minimize the scale factor from, how big of a piece of paper do I start from to, how big of a model do I get? And one of the cool ways these days, which was invented by Tomohiro Tachi and then analyzed by the two of us-- it's called Origamizer. It's free software. You take a 3D model and you can-- it makes it into a pattern that you fold from a square. In this case, it uses 22% of the area, which is pretty good-- similar to these guys in terms of efficiency. But very, very different kind of folding than what you would get from more traditional origami design, which uses different algorithms, which I'm not going to talk about. But you should take the class. Jason gives a lecture in the class, so you can learn from him. But the vision is, we can take any sheet of material that can hold a crease, like this sheet of steel that Tomohiro is folding. It was cut by a big laser cutter at MIT. And this is him in this Data Center several years ago, folding it into a steel bunny. And so this is a totally new way to manufacture 3D objects. And you can make particularly interesting objects that either collapse flat for transportation or transform, like Jason was talking about. But I'm just giving you a flavor. I think the first paper we wrote together was on maze folding. So this is an example of folding a maze from a rectangle of paper. And you can all try this out. You just google for our Maze Folder. You can generate a random maze. And this 3D structure can be folded from this crease pattern. That's a really hard one, so maybe try something smaller. You can also write your favorite message and fold this maze-- extruded graph-- from this crease pattern. Might want to start with something smaller, but that's the general idea. And it's actually quite easy to prove this algorithmically, if you have a really good origamist like Jason on your team. What you do is design how to fold each type of vertex. This is just a graph on a grid. There are some constant number of different ways that each vertex could look. It could be degree 4. It could be degree 3, as a T. It could be degree 2, either a turn or a straight. And you design little gadgets, little crease patterns, that fold into each of those little structures. And if you can do it in a way that these boundaries are compatible, then to fold the whole thing, you just sort of gluon together those crease patterns. And that's how that software works. This was particularly interesting, because you can fold an arbitrarily complicated graph-- arbitrarily complicated maze, n by n, with a constant scale factor. As long as the height that you're extruding that maze is constant, then this is one family of shapes we know how to fold really well. In general, we're trying to understand, what makes this lobster a nice shape in that it can be represented with a not-too-large piece of paper. And we don't have general answers to that problem. I think that was a whirlwind tour of computational origami. I also play a lot in algorithmic sculpture. One of the leading edges in origami and origami math is understanding how curved creases work. And one of our favorite models is this one, where you fold concentric circles alternating mountain and valley, cut a circular hole out, and it folds into this kind of Pringle shape as a nice physics equilibrium thing. And then you can turn it into fun sculptures like this. These are done with my dad, Martin Demaine, who's also here at MIT, or this guy. This paper has been printed with a pattern according to getting burned by glass. And then it gets folded and then put inside glass, also. Made here at MIT. We use sculpture to try to explore and understand intuitively how curved creases work, and then we get better and better understanding of the mathematics of even-- we don't even know whether this surface exists, whether it's possible to fold in this way, although getting close to proving it. That was sort of in the top level of this hierarchy. Computational geometry is a bigger umbrella, which is represented by another class, 6.850, that's being taught this term. And then I talked about geometric folding within that branch. Let me briefly tell you about another world of geometry-- very different in terms of model of computation. Oh, I jumped ahead a little bit. Rewind. Let me show you one more fun demo, which-- if I find my scissors. If I take a rectangle of paper, and I fold it flat and make one straight cut, what shapes can I get? It's called the folding cut problem. It's hundreds of years old. Here, for example, I get a swan. Here, I get-- one straight cut. I unfold and get angelfish. Tough audience today. I've got to keep going. You've seen all of these before. This is this one is a particularly difficult one to fold-- to only fold. And to cut, yeah. OK. That works well. This is the MIT logo. Ooh, ah. AUDIENCE: Ooh, aah. MIT, yeah! ERIK DEMAINE: Yeah. Go, MIT. All right. That's actually the first problem I worked on in computational origami. It's a lot of fun. And there's a really interesting algorithm here, also, for computing the crease pattern, how to fold your piece of paper to align-- in fact, any graph you draw on a piece of paper, you can align all of those edges and nothing else. So you cut along the line and you get exactly what you want.","62.30823516845703","6","DPRSearchEngine","4nXw-f6NJ9s.en-j3PyPqV-e1s_1_mp4","4nXw-f6NJ9s.en-j3PyPqV-e1s","6.006","21"
"241","What are experimental devices used for?","  
 
 
 
 
  
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
Self-reproduction Paradox 
Suppose a Factory makes Cars 
- Complexity of Factory > Complexity of Car 
(because Factory needs instructions for Car + robots, tools, … ) 
Can a Factory make Factories? 
- Complexity of Factory > Complexity of Factory? 
- Seems impossible to have a self-reproducing machine 
But, living things self-reproduce 
How to resolve this paradox? 
© Source unknown. All rights reserved. This content is excluded from our Creative 
Commons license. For more information, see https://ocw.mit.edu/fairuse. 
Self-reproducing machines are possible! 
3 
","61.954288482666016","7","DPRSearchEngine","779043ea724131d008eae652d703938f_MIT18_404f20_lec11_3_pdf","779043ea724131d008eae652d703938f_MIT18_404f20_lec11","18.404J","11"
"241","What are experimental devices used for?","called the Turing machine. And that's really going to be the model of what we're going to stick with for the rest of the semester, because that's going to be our model of a general-purpose computer, the way you normally think about it. So let's-- we'll spend a little time introducing it. And then we we'll continue that discussion next time.","61.79732131958008","8","DPRSearchEngine","IycOPFmEQk8.en-j3PyPqV-e1s_13_mp4","IycOPFmEQk8.en-j3PyPqV-e1s","18.404J","5"
"241","What are experimental devices used for?","And it turned out, as you can see, he basically chose a word because it was the description that didn't mean anything. Because he was doing mathematics, and at the time he was being funded by a part of the Defense Department that didn't approve of mathematics. And he wanted to conceal that fact. And indeed at the time, the head of Defense Appropriations in the US Congress didn't much like mathematics. And he was afraid that he didn't want to have to go and testify and tell people he was doing math. So he just invented something that no one would know what it meant. And years of students spent time later trying to figure out what it actually did mean. Anyway, what's the basic idea? To understand it I want to temporarily abandon the knapsack problem and look at a much simpler problem-- Fibonacci numbers.","61.69438171386719","9","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_7_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"241","What are experimental devices used for?","  
 
 
 
 
 
 
 
 
 
 
Result of Running It  
Test k-means (k = 2) 
Cluster of size 118 with fraction of positives = 0.3305 
Cluster of size 132 with fraction of positives = 0.3333 
Like it? 
Try patients = getData(True)  
Test k-means (k = 2) 
Cluster of size 224 with fraction of positives = 0.2902 
Cluster of size 26 with fraction of positives = 0.6923 
Happy with sensitivity? 
6.0002  LECTURE 12 
32 
","61.67976760864258","10","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_32_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"244","What are the core concepts in graph-theoretic models?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Monte Carlo Simulation  
A method of estimating the value of an unknown 
quantity using the principles of inferential statistics 
Inferential statistics 
◦ Population: a set of examples 
◦ Sample: a proper subset of a population 
◦ Key fact: a random sample tends to exhibit the same  
properties as the population from which it is drawn  
Exactly what we did with random walks 
6.0002 LECTURE 6 
4
","76.31729125976562","1","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_4_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"244","What are the core concepts in graph-theoretic models?"," 
 
 
 
 
 
 
 
 
Machine  Learning Paradigm  
§Observe set of examples: training data 
§Infer something about process that generated that 
data 
§Use inference to make predictions about previously 
unseen data: test data 
§Supervised: given a set of feature/label pairs, find a 
rule that predicts the label associated with a previously 
unseen input 
§Unsupervised: given a set of feature vectors (without 
labels) group them into “natural clusters” 
6.0002  LECTURE 12 
3 
","75.53428649902344","2","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_3_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"244","What are the core concepts in graph-theoretic models?"," 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
Modeling the  World  
§Models  always  inaccurate
◦Provide abstractions of reality
§Deterministic models, e.g., graph theoretic
§Statistical models
◦Simulation models: Monte Carlo simulation
◦Models  based on sampling
◦Characterizing accuracy is critical
◦Central limit theorem
◦Empirical rule
◦Machine learning
◦Unsupervised and supervised
§Presentation of data
◦Plotting
◦Good and bad practices
6.0002  LECTURE 15 
21 
","74.23976135253906","3","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_18_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"244","What are the core concepts in graph-theoretic models?","3 
Lecture 20: Course Review 
Future Courses 
Model 
Application 
• Computation / Complexity (6.045, 6.840, 6.841) 
• Biology (6.047) 
• Randomness (6.842) 
• Game Theory (6.853) 
• Quantum (6.845) 
• Cryptography (6.875) 
• Distributed / message passing (6.852) 
• Vision (6.819) 
• Multicore / shared memory (6.816, 6.846) 
• Graphics (6.837) 
• Graph and Matrix (6.890) 
• Geometry (6.850) 
• Constant Factors / Performance (6.172) 
• Folding (6.849) 
","73.67019653320312","4","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_3_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"244","What are the core concepts in graph-theoretic models?","in general graphs, which we know as Bellman-Ford, but rephrased into the SRTBOT framework. So we defined this problem, in the Bellman-Ford lecture, delta sub k of s, v. Remember, this was the weight of a shortest path from s to v that is restricted to use, at most, k edges. This made the problem feasible. We ended up taking the product of the graph into all of these different subproblems, in fact.","73.66153717041016","5","DPRSearchEngine","TDo3r5M1LNo.en-j3PyPqV-e1s_4_mp4","TDo3r5M1LNo.en-j3PyPqV-e1s","6.006","17"
"244","What are the core concepts in graph-theoretic models?","There are a few corollaries to that fact. So unless there are any questions about that, we'll get started with our new unit in 6.006 which is a graph theory. If you're wondering, there's a graph on the screen here. But of course, we'll fill in a little bit more information today throughout our lecture. When I was learning how to teach, which I'm still doing, actually my PhD advisor told me if you want somebody to learn something, you have to write it as big as possible. And so I'm really leaning into that approach today in our slides. So in any event, so today we're going to have our first lecture on graphs which I think will somewhat be a review for many of you guys. And if it's not, that's cool too. Because we'll start from the beginning and kind of build up all the notions that we need to understand and process graphs and hopefully by the end of lecture, have some style of algorithm for computing the shortest path from one vertex to all the other ones.","72.89463806152344","6","DPRSearchEngine","oFVYVzlvk9c.en-j3PyPqV-e1s_2_mp4","oFVYVzlvk9c.en-j3PyPqV-e1s","6.006","9"
"244","What are the core concepts in graph-theoretic models?","I want to deal with. In each case, get a different training and test set, at random. And then, for each dimension, do the fit. There's polyfit on the training x and training y values in that dimension. Gives you back a model. I could just check to see how well the training set gets, but I really want to look at, given that model, how well does polyval predict the test set, right? The model will say, here's what I expect is the values. I'm going to compare that to the actual values that I saw from the training set, computing that r squared value and adding it in. And then the last of this just says, I'll run this through a set of examples. OK, here's what happens if I do that. I'm not going to run it, although the code will run it. Let me, again, remind you what I'm doing. I got a big set of data I'm going to pick out at random, subsets of it, build the model on one part, test it on the other part. And if I run it, I get a linear fit, quadratic fit, cubic fit, and a quartic fit. And here's the standard deviation of those samples. Remember, I've got multiple trials. I've got 10 trials, in this case. So this gives me the average over those trials. And this tells me how much they vary. What can I conclude from this? Well, I would argue that the linear fit's probably the winner here. Goes back to Einstein. I want the simplest possible model that accounts for it. And you can see it's got the highest r-squared value, which is already a good sign. It's got the smallest deviation across the trials, which says it's probably a pretty good fit. And it's the simplest model. So linear sounds like a pretty good fit. Now, why should we run multiple data sets to test this? I ran 10 trials of each one of these dimensions. Why bother with it? Well, notice that those deviations-- I'll go back to it here-- they're pretty good. They're about an order of magnitude less than the actual mean, which says they're pretty tight, but they're still reasonable size. And that suggests that, while there's good agreement, the deviations are large enough that you could see a range of variation across the trials. So in fact, if I had just run one trial, I could have been screwed. Sorry, oh-- sorry, pick your favorite [INAUDIBLE] here. [? Hose ?] is a Canadian expression, in case you haven't seen it. Here are the r-squared values for each trial of the linear fit. And you can see the mean comes up pretty well. But notice, if I'd only run one trial and I happened to get that one, oh, darn. That's a really low r-squared value. And we might have decided, in this case, a different conclusion, that the linear fit was not a good fit. So this is a way of saying, even in a random sampling, run multiple trials, because it lets you get statistics on those trials, as well as statistics within each trial. So with any trial, I'm doing a whole bunch of different random samples on measuring those values. And then, across those trials, I'm seeing what the deviation is. I'm going to hope my machine comes back, because what I want to do is then pull this together. What have we done? Something you're going to use. We've seen how you can use linear regression to fit a curve to data, 2D, 3D, 6D, however big the data set is. It gives us a mapping from the independent values to the dependent values. And that can then be used to predict values associated with the independent values that we haven't seen yet. That leads, naturally, to both a way to measure, which is r squared, but especially to see that we want to look at how well does that model actually predict new data, because that lets us select the simplest model we can that accounts for the data, but predicts new data in an effective way. And that complexity can either be based on theory, in the case of Hooke, or in more likely cases, by doing cross-validation to try and figure out which one is the simplest model that still does a good job of predicting out of data behavior. And with that, I'll see you next time.","72.67919158935547","7","DPRSearchEngine","fQvg-hh9dUw.en-qlPKC2UN_YU_21_mp4","fQvg-hh9dUw.en-qlPKC2UN_YU","6.0002","10"
"244","What are the core concepts in graph-theoretic models?","And actually graph theory, although we talk about it very differently, appears in that world constantly. Because of course, with sitting behind any 3D model on your computer is a giant network of triangles. This is called a triangulated surface-- like this torus we see here. And this is nothing more than a graph. And in fact, if you squint at the algorithms that we cover in six eight three eight, you'll see they're roughly just graph algorithms in disguise. In fact, if you take my graduate course one thing we'll do is we'll spend a lot of time doing differential geometry. And then we'll step back 10 feet and notice that exactly the algorithms we are using for computing curvature and bendiness on triangle meshes, just looks like a graph algorithm and can be applied to networks in exactly the same way. So it will be a nice kind of fun reveal there. And of course, there's one last kind of fun application. I actually was gone the last couple of days at a conference on political redistricting. And the funny thing is most of the discussion at that conference was about graph theory. And the reason for that is sort of a theme that shows up a lot in geometry world, which is if I take my state, in this case I think these are the voting precincts in some state or another, and I look at adjacency relationships, then maybe I put a node for every precinct and an edge any time that they share a boundary with one another. Well now I have a network. And maybe a region on my graph is like a connected piece of this network. And so anyway, this is one of these examples where graphs and networks and connectivity and so on just show up literally no matter where you go. They're totally unavoidable. And so that's what we'll be spending quite a bit of time on in this class here. Now you could easily take, I would argue, at least three entire courses on graph theory here at MIT, and you could easily build a PhD dissertation doing nothing more than really simple problems on graphs. Of course, in this class we're limited to just a few lectures out of many. So we're going to make a couple of assumptions both on the problems we want to solve, as well as in the graphs that we care about. So in particular, one simplifying assumption, which actually really doesn't affect","72.56254577636719","8","DPRSearchEngine","oFVYVzlvk9c.en-j3PyPqV-e1s_5_mp4","oFVYVzlvk9c.en-j3PyPqV-e1s","6.006","9"
"244","What are the core concepts in graph-theoretic models?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 10: Depth-First Search 
Lecture 10: Depth-First Search 
Previously 
• Graph deﬁnitions (directed/undirected, simple, neighbors, degree) 
• Graph representations (Set mapping vertices to adjacency lists) 
• Paths and simple paths, path length, distance, shortest path 
• Graph Path Problems 
– Single Pair Reachability(G,s,t) 
– Single Source Reachability(G,s) 
– Single Pair Shortest Path(G,s,t) 
– Single Source Shortest Paths(G,s) (SSSP) 
• Breadth-First Search (BFS) 
– algorithm that solves Single Source Shortest Paths 
– with appropriate data structures, runs in O(|V | + |E|) time (linear in input size) 
Examples 
G1 
a 
d 
b 
e 
c 
f 
G2 
a 
d 
b 
e 
c 
f 
","72.3069076538086","9","DPRSearchEngine","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10_1_pdf","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10","6.006","10"
"244","What are the core concepts in graph-theoretic models?","It's basically-- it's a set type thing, where I can make a set of just a single element, I can take two sets, merge them together, make them their union, and then given an object, I say, which set am I part of, essentially by electing a leader within a set and saying, return me a pointer to that one. And so this can be useful in dynamically maintaining, say, the connected components in a dynamically changing graph supporting the query of, am I in the same component as this other guy? That could be a very useful thing to know about a graph as it's changing. So that's an application of this problem. And they get near-constant performance for a lot of these queries. It's not quite, but pretty close. OK, on the graph side, they solve","72.22035217285156","10","DPRSearchEngine","2NMtS1ecb3o.en-j3PyPqV-e1s_6_mp4","2NMtS1ecb3o.en-j3PyPqV-e1s","6.006","20"
"245","What is polynomial regression in the context of fitting lines to data?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Monte Carlo Simulation  
A method of estimating the value of an unknown 
quantity using the principles of inferential statistics 
Inferential statistics 
◦ Population: a set of examples 
◦ Sample: a proper subset of a population 
◦ Key fact: a random sample tends to exhibit the same  
properties as the population from which it is drawn  
Exactly what we did with random walks 
6.0002 LECTURE 6 
4
","78.2567138671875","1","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_4_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"245","What is polynomial regression in the context of fitting lines to data?","So how do I decide which one's better other than eyeballing it? And then if I could fit a quadratic to it, what about other orders of polynomials? Maybe there's an even better fit out there. So how do I figure out what's the best way to do the fit? And that leads to the second big thing for this lecture. How good are these fits? What's the first big thing? The idea of linear regression, a way of finding fits of curves to data. But now I've got to decide how good are these. And I could ask this question two ways. One is just relative to each other, how do I measure which one's better other than looking at it by eye? And then the second part of it is in an absolute sense, how do I know where the best solution is? Is quadratic the best I could do? Or should I be doing something else to try and figure out a better solution, a better fit to the data? The relative fit. What are we doing here? We're fitting a curve, which is a function of the independent variable to the dependent variable. What does it mean by that? I've got a set of x values. I'm trying to predict what the y values should be, the displacement should be. I want to get a good fit to that. The idea is that given an independent value, it gives me an estimate of what it should be, and I really want to know which fit provides the better estimates. And since I was simply minimizing mean squared error, average square error, an obvious thing to do is just to use the goodness of fit by looking at that error. Why not just measure where am I on that surface and see which one does better? Or actually it would be two surfaces, one for a linear fit, one for a quadratic one. We'll do what we always do. Let's write a little bit of code. I can write something that's going to get the average, mean squared error.","78.13296508789062","2","DPRSearchEngine","vIFKGFl1Cn8.en-qlPKC2UN_YU_13_mp4","vIFKGFl1Cn8.en-qlPKC2UN_YU","6.0002","9"
"245","What is polynomial regression in the context of fitting lines to data?","I know you don't believe it, but it is because notice what it says, it says the r squared value for the line is horrible. It accounts for less than 0.05% of the data. You could say, OK, I can see that. I look at it. It does a lousy job. On the other hand, the quadratic is really pretty good. It's accounting for about 84% of the variability in the data. This is a nice high value. It's not one, but it's a nice high value. So this is now reinforcing what I already knew, but in a nice way. It's telling me that that r squared value tells me that the quadratic is a much better fit than the linear fit was. But then you say maybe, wait a minute. I could have done this by just comparing the fits themselves. I already saw that. Part of my goal is how do I know if I've got the best fit possible or not. So I'm going to do the same thing, but now I'm going to run it with another set of degrees. I'm going to go over here. I'm going to take exactly the same code. But let's try it with a quadratic, with a quartic, an order eight, and an order 16 fit. So I'm going to take different size polynomials. As a quick aside, this is why I want to use the PyLab kind of code because now I'm simply optimizing over a 16-dimensional space. Every point in that 16-dimensional space defines a 16th-degree polynomial. And I can still use linear regression, meaning walking down the gradient, to find the best solution. I'm going to run this. And I get out a set of values. Looks good. And let's go look at them.","77.66590118408203","3","DPRSearchEngine","vIFKGFl1Cn8.en-qlPKC2UN_YU_18_mp4","vIFKGFl1Cn8.en-qlPKC2UN_YU","6.0002","9"
"245","What is polynomial regression in the context of fitting lines to data?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","77.25227355957031","4","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"245","What is polynomial regression in the context of fitting lines to data?","in a space that has one access with values and the other access with b values. Every point in that plane defines a line for me. Now imagine a surface laid over this two dimensional space, where the value or the height of the surface is the value of that objective function at every point. Don't worry about computing it all, but just imagine I could do that. And by the way, one of the nice things about doing sum of squares is that surface always has a concave shape. And now the idea of linear regression is I'm going to start at some point on that surface. And I'm just going to walk downhill until I get to the bottom. There will always be one bottom, one point. And once I get to that point, that a and b value tell me the best line. So it's called linear regression because I'm linearly walking downhill on this space. Now I'm doing this for line with two parameters a,b, because it's easy to visualize. If you're a good mathematician even if you're not, you can generalize this to think about arbitrary dimensions. So a fourth order surface in a five dimensional space, for example, would solve a cubic example of this. That's the idea of linear regression. That's what we're going to use to actually figure out, to find the best solution.","75.73116302490234","5","DPRSearchEngine","fQvg-hh9dUw.en-qlPKC2UN_YU_3_mp4","fQvg-hh9dUw.en-qlPKC2UN_YU","6.0002","10"
"245","What is polynomial regression in the context of fitting lines to data?"," 
 
 
 
 
 
 
 
 
Supervised Learning  
Regression 
◦ Predict a real number associated with a feature vector  
◦ E.g., use linear regression to fit a curve to data 
Classification 
◦ Predict a discrete value (label) associated with a feature 
vector 
6.0002 LECTURE 13 
3 
","74.88359069824219","6","DPRSearchEngine","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13_3_pdf","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13","6.0002","13"
"245","What is polynomial regression in the context of fitting lines to data?","I gave you a set of data. In about 3 slides, I'm going to tell you where the data came from. But I give you a set of data. We could fit the best line to this using that linear regression idea. And again, last piece of reminder, I'm going to use polyfit from PiLab. It just solves that linear regression problem. And I give it a set of x values. I give a corresponding set of y values, need to be the same number in each case. And I give it a dimension. And in this case, one says, find the best fitting line. It will produce that and return it as a tuple, which I'll store under the name model 1. And I could plot it out. So just remind you, polyfit will find the best fitting n dimensional surface, n being that last parameter there, and return it. In a second, we're going to use polyval, which will say, given that model and a set of x values, predict what the y value should be. Apply them. OK, so I fit the line. What do you think? Good fit? Not so much, right? Pretty ugly. I mean, you can see it's probably the best-- or not probably. It is the best fitting line. It sort of accounts for the variation on either side of it. But it's not a very good fit. So then the question is, well why not try fitting a higher order model? So I could fit a quadratic. That is a second order model. y equals ax squared plus bx plus c. Run the same code. Block that out. And I get that. That's the linear model. There's the quadratic model. At least my [? i ?] our looks a lot better, right? It looks like it's following that data reasonably well. OK, I can fit a linear model. I can fit a quadratic model. What about higher order models? What about a fourth order model, an eighth order model, a 644th order model? How do I know which one is going to be best? So for that, I'm going to remind you of the last thing we used. And then we're going to start talking about how to use it further, which is if we try fitting higher order polynomials, do we get a better fit? And to do that, we need to measure what it means for the data to fit. If I don't have any other information. For example, if I don't have a theory that tells me this should be linear in the case afoot, then the best way to do it is to use what's called, the coefficient of determination, r-squared. It's a scale independent thing, which is good. By scale independent, I mean if I take all the data and stretch it out, this will still give me back the same value in terms of the fit. So it doesn't depend on the size of the data. And what it does is it basically tells me the a value between 0 and 1, how well does this model fit the data. So just to remind you, in this case, the y's are the measured values, the p's are the predicted values. That's what my model is saying, for each one of these cases. And mu down here is the mean or the average of the measured values. The way to think about this is this top expression here. Well, that's exactly what I'm trying to minimize, right? So it's giving me an estimate or a measure of the error in the estimates between what the model says and what I actually measure. And the denominator down here basically tells me how much does the data vary away from the mean value. Now here's the idea. If in fact, I can get this to 0, I can get a model that completely accounts for all the variation in the estimates, that's great. It says, the model has fit perfectly. And that means this is 0 so this r value or r squared value is 1. On the other hand, if this is equal to that, meaning that all of the variation in the estimates accounts for none of the variation in the data, then this is 1 and this goes to 0. So the idea is that an r-squared value is close to 1 is great. It says, the model is a good fit to the data. r-squared value is getting closer to 0, not so good.","74.70561218261719","7","DPRSearchEngine","fQvg-hh9dUw.en-qlPKC2UN_YU_4_mp4","fQvg-hh9dUw.en-qlPKC2UN_YU","6.0002","10"
"245","What is polynomial regression in the context of fitting lines to data?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","74.70159912109375","8","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"245","What is polynomial regression in the context of fitting lines to data?","polynomial, y equals ax plus b, as our model of the day. That means for every sample, I'm going to plug in x, and if I know a and b, it gives me the predicted value. I've already seen that's going to give me a good measure of the closeness of the fit. And the question is, how do I find a and b. My goal is find a and b such that when we use this polynomial to compute those y values, that sum squared difference is minimized. So the sum squared difference is my measure of fit. All I have to do is find a and b. And that's where linear regression comes in, and I want to just give you a visualization of this. If a line is described by ax plus b, then I can represent every possible line in a two-dimensional space. One axis is possible values for a. The other axis is possible values for b. So if you think about it, I take any point in that space. It gives me an a and a B value. That describes a line. Why should you care about that? Because I can put a two-dimensional surface over that space. In other words, for every a and b, that gives me a line, and I could, therefore, compute this function, given the observed values and the predicted values, and it would give me a value, which is the height of the surface in that space. If you're with me with the visualization, why is that nice? Because linear regression gives me a very easy way to find the lowest point on that surface, which is exactly the solution I want, because that's the best fitting line. And it's called linear regression not because we're solving for a line, but because of how you do that solution. If you think of this as being-- take a marble on this two-dimensional surface, you want to place the marble on it, you want to let it run down to the lowest point in the surface. And oh, yeah, I promised you why do we use sum squares, because if we used the sum of the squares, that surface always has only one minimum. So it's not a really funky, convoluted surface. It has exactly one minimum. It's called linear regression because the way to find it is to start at some point and walk downhill. I linearly regress or walk downhill along the gradient some distance, measure the new gradient, and do that until I get down to the lowest point in the surface. Could you write code to do it? Sure. Are we going to ask you to do it? No, because fortunately-- I was hoping to get a cheer out of that. Too bad. OK, maybe we will ask you to do it on the exam. What the hell. You could do it. In fact, you've seen a version of this. The typical algorithm for doing it is very similar to Newton's method that we used way back in the beginning of 60001 when we found square roots. You could write that kind of a solution, but the good news is that the nice people who wrote Python, or particularly PyLab, have given you code to do it. And we're going to take advantage of it. So in PyLab there is a built-in function called polyFit. It takes a collection of x values, takes a collection of equal length of y values-- they need to be the same length. I'm going to assume they're arrays. And it takes an integer n, which is the degree of fit, that I want to apply. And what polyFit will do is it will find the coefficients of a polynomial of that degree that provides the best least squares fit. So think of it as polyFit walking along that surface to find the best a and b that will come back. So if I give it a value of n equals one, it'll give me back the a and b that gives me the best line. If I get a value of n equal two, it gives me back a, b, and c that would fit an ax squared plus bx plus c parabola to best fit the data. And I could pick n to be any non-negative integer, and it would actually come up with a good fit. So let's use it.","74.6385498046875","9","DPRSearchEngine","vIFKGFl1Cn8.en-qlPKC2UN_YU_8_mp4","vIFKGFl1Cn8.en-qlPKC2UN_YU","6.0002","9"
"245","What is polynomial regression in the context of fitting lines to data?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
Regression to the Mean  
Following an extreme random event, the next random 
event is likely to be less extreme 
If you spin a fair roulette wheel 10 times and get 100% 
reds, that is an extreme event (probability = 1/1024) 
It is likely that in the next 10 spins, you will get fewer 
than 10 reds 
◦ But the expected number is only 5 
So, if you look at the average of the 20 spins, it will be 
closer to the expected mean of 50% reds than to the 
100% of the first 10 spins 
6.0002 LECTURE 6 
16
","74.16118621826172","10","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_16_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"248","What is one benefit of using simulations involving random walks?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Monte Carlo Simulation  
A method of estimating the value of an unknown 
quantity using the principles of inferential statistics 
Inferential statistics 
◦ Population: a set of examples 
◦ Sample: a proper subset of a population 
◦ Key fact: a random sample tends to exhibit the same  
properties as the population from which it is drawn  
Exactly what we did with random walks 
6.0002 LECTURE 6 
4
","74.03565216064453","1","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_4_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"248","What is one benefit of using simulations involving random walks?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
Why Random Walks?  
§Random walks are important in many
domains
◦Understanding the stock market (maybe)
◦Modeling diffusion processes
◦Etc.
§Good illustration of how to use
simulations  to understand things
§Excuse to cover some important
programming topics
◦Practice with classes
◦Practice with plotting
6.0002  LECTURE 5 
3 
","73.87965393066406","2","DPRSearchEngine","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_3_pdf","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5","6.0002","5"
"248","What is one benefit of using simulations involving random walks?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Why Random Walks?
Random walks are important in many
domains
◦Understanding the stock market (maybe)
◦Modeling diffusion processes
◦Etc.
Good illustration of how to use
simulations to understand things
Excuse to cover some important
programming topics
◦Practice with classes
◦More about plotting
6.0002 LECTURE 4 
26
","73.35345458984375","3","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_26_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"248","What is one benefit of using simulations involving random walks?"," 
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
Simulations Are Used a Lot
To model systems that are mathematically intractable
To extract useful intermediate results
Lend themselves to development by successive
refinement and “what if” questions
Start by simulating random walks
6.0002 LECTURE 4 
25
","73.32355499267578","4","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_25_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"248","What is one benefit of using simulations involving random walks?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","71.20278930664062","5","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"248","What is one benefit of using simulations involving random walks?","The idea is to walk through a number of trials, number trials equal to the size of the data set. And for each one, take the data set or a copy of it, and drop out one of the samples. So leave one out. Start off by leaving out the first one, then leaving out the second one, and then leaving out the third one. For each one of those training sets, build the model. For example, by using linear regression. And then test that model on that data point that you left out. So leave out the first one, build a model on all of the other ones, and then see how well that model predicts the first one. Leave out the second one, build a model using all of them but the second one, see how well it predicts the second one. And just average the result. Works when you don't have a really large data set, because it won't take too long. But it's a nice way of actually testing validation. If the data set's a lot bigger, you can still use the same idea. You can use what's called, k-fold. Divide the data set up into k equal sized chunks. Leave one of them out. Use the rest to build the model. And then use that model to predict that first chunk you left out. Leave out the second chunk, and keep doing it. Same idea, but now with groups of things rather than just leaving those single data points. All right, the other way you can deal with it, which has a nice effect to it, is to use what's called, repeated random sampling. OK, start out with some data set. And what I'm going to do here is I'm","70.98070526123047","6","DPRSearchEngine","fQvg-hh9dUw.en-qlPKC2UN_YU_18_mp4","fQvg-hh9dUw.en-qlPKC2UN_YU","6.0002","10"
"248","What is one benefit of using simulations involving random walks?"," 
 
 
 
 
 
Two Kinds of Drunks  
import random  
class UsualDrunk(Drunk):  
def takeStep(self):  
stepChoices = [(0,1), (0,-1), (1, 0), (-1, 0)]  
return random.choice(stepChoices)  
class MasochistDrunk(Drunk):  
def takeStep(self):  
stepChoices = [(0.0,1.1), (0.0,-0.9),  
(1.0, 0.0), (-1.0, 0.0)]  
return random.choice(stepChoices)  
Immutable or not? 
6.0002  LECTURE 5 
17 
","70.8389663696289","7","DPRSearchEngine","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_17_pdf","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5","6.0002","5"
"248","What is one benefit of using simulations involving random walks?"," 
 
 
   
 
 
 
   
   
      
 
 
 
 
 
 
  
 
Stochastic Processes  
An ongoing process where the next state might depend on 
both the previous states and some random element 
def rollDie(): 
"""""" returns an int between 1 and 6"""""" 
def rollDie(): 
"""""" returns a randomly chosen int 
between 1 and 6"""""" 
6.0002 LECTURE 4 
8
","70.68788146972656","8","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_8_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"248","What is one benefit of using simulations involving random walks?"," 
 
Looking at  Distributions 
def plotDistributions():  
uniform, normal, exp = [], [], []  
for i in range(100000):  
uniform.append(random.random())  
normal.append(random.gauss(0, 1))  
exp.append(random.expovariate(0.5))  
makeHist(uniform, 'Uniform', 'Value', 'Frequency')  
pylab.figure()  
makeHist(normal, 'Gaussian', 'Value', 'Frequency')  
pylab.figure()  
makeHist(exp, 'Exponential', 'Value', 'Frequency')  
6.0002  LECTURE 8 
 
27
","70.6174545288086","9","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_27_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"248","What is one benefit of using simulations involving random walks?"," 
 
 
  
 
 
 
    
 
 
    
 
        
 
        
 
 
    
 
        
 
 
 
 
        
 
 
 
              
 
    
 
 
 
  
 
 
 
 
    
 
 
        
 
 
 
Monte Carlo Simulation  
def playRoulette(game, numSpins, pocket, bet): 
totPocket = 0 
for i in range(numSpins): 
game.spin()  
totPocket += game.betPocket(pocket, bet)  
if toPrint: 
print(numSpins, 'spins of', game) 
print('Expected return betting', pocket, '=',\\ 
str(100*totPocket/numSpins) + '%\\n') 
return (totPocket/numSpins) 
game = FairRoulette() 
for numSpins in (100, 1000000): 
for i in range(3): 
playRoulette(game, numSpins, 2, 1, True) 
6.0002 LECTURE 6 
12
","70.52518463134766","10","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_12_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"249","Why is fair roulette considered a better bet than European or Las Vegas roulette?"," 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Results  
Simulate betting a pocket for 20 trials of 1000 spins each 
Exp. return for Fair Roulette = 3.68%, +/- 27.189% with 95% confidence 
Exp. return for European Roulette = -5.5%, +/- 35.042% with 95% confidence 
Exp. return for American Roulette = -4.24%, +/- 26.494% with 95% confidence 
Simulate betting a pocket for 20 trials of 100000 spins each 
Exp. return for Fair Roulette = 0.125%, +/- 3.999% with 95% confidence 
Exp. return for European Roulette = -3.313%, +/- 3.515% with 95% confidence 
Exp. return for American Roulette = -5.594%, +/- 4.287% with 95% confidence 
Simulate betting a pocket for 20 trials of 1000000 spins each 
Exp. return for Fair Roulette = 0.012%, +/- 0.846% with 95% confidence 
Exp. return for European Roulette = -2.679%, +/- 0.948% with 95% confidence 
Exp. return for American Roulette = -5.176%, +/- 1.214% with 95% confidence 
6.0002 LECTURE 6 
26
","74.19230651855469","1","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_26_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"249","Why is fair roulette considered a better bet than European or Las Vegas roulette?"," 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Comparing the Games  
Simulate 20 trials of 1000 spins each  
Exp. return for Fair Roulette = 6.56%  
Exp. return for European Roulette = -2.26%  
Exp. return for American Roulette = -8.92%  
Simulate 20 trials of 10000 spins each  
Exp. return for Fair Roulette = -1.234%  
Exp. return for European Roulette = -4.168%  
Exp. return for American Roulette = -5.752%  
Simulate 20 trials of 100000 spins each  
Exp. return for Fair Roulette = 0.8144%  
Exp. return for European Roulette = -2.6506%  
Exp. return for American Roulette = -5.113%  
Simulate 20 trials of 1000000 spins each  
Exp. return for Fair Roulette = -0.0723%  
Exp. return for European Roulette = -2.7329%  
6.0002 LECTURE 6 
Exp. return for American Roulette = -5.212% 
19
","73.59339141845703","2","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_19_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"249","Why is fair roulette considered a better bet than European or Las Vegas roulette?"," 
  
 
  
 
 
    
 
 
        
 
        
 
    
 
        
 
 
 
    
 
        
 
        
 
    
 
        
 
Two Subclasses of Roulette  
class EuRoulette(FairRoulette): 
def __init__(self): 
FairRoulette.__init__(self) 
self.pockets.append('0') 
def __str__(self): 
return 'European Roulette' 
class AmRoulette(EuRoulette): 
def __init__(self): 
EuRoulette.__init__(self) 
self.pockets.append('00') 
def __str__(self): 
return 'American Roulette' 
6.0002 LECTURE 6 
18
","73.13347625732422","3","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_18_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"249","Why is fair roulette considered a better bet than European or Las Vegas roulette?"," 
 
 
  
 
 
 
 
 
 
 
    
 
 
 
 
    
 
 
 
          
 
    
 
        
 
 
 
                                         
 
 
        
 
 
        
 
                                          
 
                                          
 
        
 
 
              
 
               
 
 
 
               
 
Applying Empirical Rule  
resultDict = {}  
games = (FairRoulette, EuRoulette, AmRoulette)  
for G in games:  
resultDict[G().__str__()] = [] 
for numSpins in (100, 1000, 10000): 
print('\\nSimulate betting a pocket for', numTrials, 
'trials of', numSpins, 'spins each') 
for G in games: 
pocketReturns = findPocketReturn(G(), 20, 
numSpins, False) 
mean, std = getMeanAndStd(pocketReturns) 
resultDict[G().__str__()].append((numSpins, 
100*mean, 
100*std)) 
print('Exp. return for', G(), '=', 
str(round(100*mean, 3)) 
+ '%,', '+/- ' + str(round(100*1.96*std, 3)) 
+ '% with 95% confidence') 
6.0002 LECTURE 6 
25
","70.48966979980469","4","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_25_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"249","Why is fair roulette considered a better bet than European or Las Vegas roulette?"," 
 
 
  
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
100 and 1M Spins of the Wheel  
100 spins of Fair Roulette 
Expected return betting 2 = -100.0% 
100 spins of Fair Roulette 
Expected return betting 2 = 44.0% 
100 spins of Fair Roulette 
Expected return betting 2 = -28.0% 
1000000 spins of Fair Roulette 
Expected return betting 2 = -0.046% 
1000000 spins of Fair Roulette 
Expected return betting 2 = 0.602% 
1000000 spins of Fair Roulette 
Expected return betting 2 = 0.7964% 
6.0002 LECTURE 6 
13
","70.45450592041016","5","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_13_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"249","Why is fair roulette considered a better bet than European or Las Vegas roulette?","100,000, and a million. And what do we see as we look at this? Well, right away we can see that fair roulette is usually a much better bet than either of the other two. That even with only 1,000 spins the return is negative. And as we get more and more as I got to a million, it starts to look much more like closer to 0. And these, we have reason to believe at least, are much closer to true expectation saying that, while you break even in fair roulette, you'll lose 2.7% in Europe and over 5% in Las Vegas, or soon in Massachusetts. All right, we're sampling, right? That's why the results will change, and if I ran a different simulation with a different seed I'd get different numbers. Whenever you're sampling, you can't be guaranteed to get perfect accuracy. It's always possible you get a weird sample. That's not to say that you won't get exactly the right answer. I might have spun the wheel twice and happened to get the exact right answer of the return. Actually not twice, because the math doesn't work out, but 35 times and gotten exactly the right answer. But that's not the point. We need to be able to differentiate between what happens to be true and what we actually know, in a rigorous sense, is true. Or maybe don't know it, but have real good reason to believe it's true. So it's not just a question of faith. And that gets us to what's in some sense the fundamental question of all computational statistics, is how many samples do we need to look at before we can have real, justifiable confidence in our answer? As we've just seen-- not just, a few minutes ago-- with the coins, our intuition tells us that it depends upon the variability in the underlying possibilities. So let's look at that more carefully. We have to look at the variation in the data. So let's look at first something called variance.","70.21980285644531","6","DPRSearchEngine","OgO1gpXSUzU.en-j3PyPqV-e1s_11_mp4","OgO1gpXSUzU.en-j3PyPqV-e1s","6.0002","6"
"249","Why is fair roulette considered a better bet than European or Las Vegas roulette?","When I had all heads, there was no variability in my answer. I got the same answer all the time. And so there was no variability, and that intuitively-- and in fact, mathematically-- should make us feel confident that, OK, maybe that's really the way the world is. On the other hand, when almost half are heads and almost half are tails, there's a lot of variance. Right, it's hard to predict what the next one will be. And so we should have very little confidence that it isn't an accident that it happened to be 52-48 in one direction. So as the variance grows, we need larger samples to have the same amount of confidence. All right, let's look at that with a detailed example. We'll look at roulette in keeping with the theme of Monte Carlo simulation. This is a roulette wheel that could well be at Monte Carlo. There's no need to simulate roulette, by the way. It's a very simple game, but as we've seen with our earlier examples, it's nice when we're learning about simulations to simulate things where we actually can know what the actual answer is so that we can then understand our simulation better. For those of you who don't know how roulette is played-- is there anyone here who doesn't know how roulette is played? Good for you. You grew up virtuous. All right, so-- well all right. Maybe I won't go there. So you have a wheel that spins around, and in the middle are a bunch of pockets. Each pocket has a number and a color. You bet in advance on what number you think is going to come up, or what color you think is going to come up. Then somebody drops a ball in that wheel, gives it a spin. And through centrifugal force, the ball stays on the outside for a while. But as the wheel slows down and heads towards the middle, and eventually settles in one of those pockets. And you win or you lose. Now you can bet on it, and so let's look at an example of that. So here is a roulette game. I've called it fair roulette, because it's set up in such a way that in principle, if you bet, your expected value should be 0. You'll win some, you'll lose some, but it's fair in the sense that it's not either a negative or positive sum game. So as always, we have an underbar underbar in it. Well we're setting up the wheel with 36 pockets on it, so you can bet on the numbers 1 through 36. That's way range work, you'll recall. Initially, we don't know where the ball is, so we'll say it's none. And here's the key thing is, if you make a bet, this tells you what your odds are. That if you bet on a pocket and you win, you get len of pockets minus 1. So This is why it's a fair game, right? You bet $1. If you win, you get $36, your dollar plus $35 back. If you lose, you lose. All right, self dot spin will be random dot choice among the pockets. And then there is simply bet, where you just can choose an amount to bet and the pocket you want to bet on. I've simplified it. I'm not allowing you to bet here on colors. All right, so then we can play it. So here is play roulette. I've made game the class a parameter,","69.45463562011719","7","DPRSearchEngine","OgO1gpXSUzU.en-j3PyPqV-e1s_5_mp4","OgO1gpXSUzU.en-j3PyPqV-e1s","6.0002","6"
"249","Why is fair roulette considered a better bet than European or Las Vegas roulette?","I would never show that to high school students, or GREs to you guys. But you can see that they are amazingly well-distributed along a normal distribution. On down here, this is plotting percent change in oil prices. And again, we see something very close to a normal distribution. And here is just looking at heights of men and women. And again, they clearly look very normal. So it's really quite impressive how often they occur. But not everything is normal. So we saw that the empirical rule works for normal distributions. I won't say I proved it for you. I illustrated it for you with a bunch of examples. But are the outcomes of the spins of a roulette wheel normal? No. They're totally uniform, right? Everything is equally probable-- a 4, a 6, an 11, a 13, double-0 if you're in Las Vegas. They're all equally probable. So if I plotted those, I'd basically just get a straight line with everything at 1 over however many pockets there are. So in that case, why does the empirical rule work? We saw that we were doing some estimates about returns and we used the empirical rule, we checked it and, by George, it was telling us the truth. And the reason is because we're not reasoning about a single spin of the wheel but about the mean of a set of spins. So if you think about it, what we were reasoning about was the return of betting. If we look at one spin-- well, let's say we bet $1. The return is either minus 1 because we've lost our dollar. Or if we get lucky and our pocket happens to come up, it was 36, I think, or 35. I forget which, OK? But that's all. So if we plotted a histogram, we would see a huge peak at minus 1 and a little bump here at 36 and nothing in the middle. Clearly, not a normal distribution. But what we're reasoning about is not the return of a single spin but the return of many spins. If we played 1,000 spins, what is our expected return? As soon as we end up reasoning, not about a single event but about the mean of something, we can imply something","68.69121551513672","8","DPRSearchEngine","rUxP7TM8-wo.en-qlPKC2UN_YU_6_mp4","rUxP7TM8-wo.en-qlPKC2UN_YU","6.0002","7"
"249","Why is fair roulette considered a better bet than European or Las Vegas roulette?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Confidence Levels and Intervals  
Instead of estimating an unknown parameter by a single 
value (e.g., the mean of a set of trials), a confidence interval 
provides a range that is likely to contain the unknown value 
and a confidence that the unknown value lays within that 
range 
ϮϴϪή ̜ῄ̪̜̆ ̍̆ Οή̪̪ϭ̆Ϡ Β ̙̍Πϼή̪ ϭͼϼ ̪ϭ̅ή̠ ϭ̆ E̜̙̍ͅήΒ̆ 
roulette is -3.3%. The margin of error is +/- 3.5% with a 95% 
level of confidenceϨϯ 
What does this mean? 
If I were to conduct an infinite number of trials of 10k bets 
each, 
◦ My expected average return would be -3.3% 
◦ My return would be between roughly -6.8% and +0.2%  95% of 
the time 
6.0002 LECTURE 6 
23
","68.5462417602539","9","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_23_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"249","Why is fair roulette considered a better bet than European or Las Vegas roulette?","So when I simulated betting a pocket for 20 trials, we see that the-- of 1,000 spins each, for 1,000 spins the expected return for fair roulette happened to be 3.68%. A bit high. But you'll notice the confidence interval plus or minus 27 includes the actual answer, which is 0. And we have very large confidence intervals for the other two games. If you go way down to the bottom where I've spun, spun the wheel many more times, what we'll see is that my expected return for fair roulette is much closer to 0 than it was here. But more importantly, my confidence interval is much smaller, 0.8. So now I really have constrained it pretty well. Similarly, for the other two games you will see-- maybe it's more accurate, maybe it's less accurate, but importantly the confidence interval is smaller. So I have good reason to believe that the mean I'm computing is close to the true mean, because my confidence interval has shrunk. So that's the really important concept here, is that we don't just guess-- compute the value in the simulation. We use, in this case, the empirical rule to tell us how much faith we should have in that value. All right, the empirical rule doesn't always work. There are a couple of assumptions. One is that the mean estimation error is 0. What is that saying? That I'm just as likely to guess high as gas low. In most experiments of this sort, most simulations, that's a very fair assumption. There's no reason to guess I'd be systematically off in one direction or another. It's different when you use this in a laboratory experiment, where in fact, depending upon your laboratory technique, there may be a bias in your results in one direction. So we have to assume that there's no bias in our errors. And we have to assume that the distribution of errors","68.43545532226562","10","DPRSearchEngine","OgO1gpXSUzU.en-j3PyPqV-e1s_15_mp4","OgO1gpXSUzU.en-j3PyPqV-e1s","6.0002","6"
"256","What differentiates supervised from unsupervised machine learning in terms of the input data and the goal of the model?"," 
 
 
 
 
 
 
 
 
Machine  Learning Paradigm  
§Observe set of examples: training data 
§Infer something about process that generated that 
data 
§Use inference to make predictions about previously 
unseen data: test data 
§Supervised: given a set of feature/label pairs, find a 
rule that predicts the label associated with a previously 
unseen input 
§Unsupervised: given a set of feature vectors (without 
labels) group them into “natural clusters” 
6.0002  LECTURE 12 
3 
","79.23925018310547","1","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_3_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"256","What differentiates supervised from unsupervised machine learning in terms of the input data and the goal of the model?"," 
 
 
 
 
 
 
 
 
Supervised Learning  
Regression 
◦ Predict a real number associated with a feature vector  
◦ E.g., use linear regression to fit a curve to data 
Classification 
◦ Predict a discrete value (label) associated with a feature 
vector 
6.0002 LECTURE 13 
3 
","77.35502624511719","2","DPRSearchEngine","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13_3_pdf","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13","6.0002","13"
"256","What differentiates supervised from unsupervised machine learning in terms of the input data and the goal of the model?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","72.81059265136719","3","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"256","What differentiates supervised from unsupervised machine learning in terms of the input data and the goal of the model?"," 
 
 
 
 
 
Two Kinds of Drunks  
import random  
class UsualDrunk(Drunk):  
def takeStep(self):  
stepChoices = [(0,1), (0,-1), (1, 0), (-1, 0)]  
return random.choice(stepChoices)  
class MasochistDrunk(Drunk):  
def takeStep(self):  
stepChoices = [(0.0,1.1), (0.0,-0.9),  
(1.0, 0.0), (-1.0, 0.0)]  
return random.choice(stepChoices)  
Immutable or not? 
6.0002  LECTURE 5 
17 
","71.82803344726562","4","DPRSearchEngine","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_17_pdf","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5","6.0002","5"
"256","What differentiates supervised from unsupervised machine learning in terms of the input data and the goal of the model?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","71.50794982910156","5","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"256","What differentiates supervised from unsupervised machine learning in terms of the input data and the goal of the model?"," 
 
 
 
 
 
 
 
 
  
 
  
 
   
 
 
 
 
  
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Model Dependence 
Number of steps to decide ! = a#b# $ ≥0 depends on the model. 
• 1-tape TM: '() log )) 
• Multi-tape TM: '()) 
Computability theory: model independence (Church-Turing Thesis) 
Therefore model choice doesn’t matter. Mathematically nice. 
Complexity Theory: model dependence 
But dependence is low (polynomial) for reasonable deterministic models. 
We will focus on questions that do not depend on the model choice. 
So… we will continue to use the 1-tape TM as the basic model for complexity. 
6 
","71.04683685302734","6","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_6_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"256","What differentiates supervised from unsupervised machine learning in terms of the input data and the goal of the model?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Monte Carlo Simulation  
A method of estimating the value of an unknown 
quantity using the principles of inferential statistics 
Inferential statistics 
◦ Population: a set of examples 
◦ Sample: a proper subset of a population 
◦ Key fact: a random sample tends to exhibit the same  
properties as the population from which it is drawn  
Exactly what we did with random walks 
6.0002 LECTURE 6 
4
","71.03113555908203","7","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_4_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"256","What differentiates supervised from unsupervised machine learning in terms of the input data and the goal of the model?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 10: Depth-First Search 
Lecture 10: Depth-First Search 
Previously 
• Graph deﬁnitions (directed/undirected, simple, neighbors, degree) 
• Graph representations (Set mapping vertices to adjacency lists) 
• Paths and simple paths, path length, distance, shortest path 
• Graph Path Problems 
– Single Pair Reachability(G,s,t) 
– Single Source Reachability(G,s) 
– Single Pair Shortest Path(G,s,t) 
– Single Source Shortest Paths(G,s) (SSSP) 
• Breadth-First Search (BFS) 
– algorithm that solves Single Source Shortest Paths 
– with appropriate data structures, runs in O(|V | + |E|) time (linear in input size) 
Examples 
G1 
a 
d 
b 
e 
c 
f 
G2 
a 
d 
b 
e 
c 
f 
","70.84346008300781","8","DPRSearchEngine","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10_1_pdf","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10","6.006","10"
"256","What differentiates supervised from unsupervised machine learning in terms of the input data and the goal of the model?"," 
 
 
Class LogisticRegression  
fit(sequence of feature vectors, sequence of labels) 
Returns object of type LogisticRegression 
coef_ 
Returns weights of features 
predict_proba(feature vector) 
Returns probabilities of labels 
6.0002 LECTURE 13 
22 
","70.8373031616211","9","DPRSearchEngine","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13_22_pdf","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13","6.0002","13"
"256","What differentiates supervised from unsupervised machine learning in terms of the input data and the goal of the model?",";
/
def testGreedy(items, constraint, keyFunction):
taken, val = greedy(items, constraint, keyFunction)
print('Total value of items taken =', val)
for item in taken:
print('   ', item)
	

'
","70.54642486572266","10","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_25_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"257","Why is it important to fix the values of mu and sigma when integrating over values of x using the Gaussian function?","That gives us all the different integration methods. I'm not going to show you the code for Gaussian since I showed it to you a couple of minutes ago. But I wanted you to remember that it takes three arguments, x, mu, and sigma. Because when we get down here to the integration, we'll pass at the function Gaussian and then the values that we want to integrate over. So those will be the values that x can take upon. And that will change as we go from mu minus the number of standard deviations times sigma to mu plus the number of standard deviations times sigma. And then, this is the optional fourth argument, the tuple, mu, and sigma. Why do I need to pass that in? Because Gaussian is a ternary argument, or a function that takes three values. And I'm going to integrate over values of x so I have to fix mu and sigma to constants, which is what I'm doing down here. And then I'll take the zeroth value, which is its estimate of the integral. All right, so that's the new thing. The rest of the code is all stuff you've seen. For t and range number of trials, I'm going to choose a random mu between minus 10 and 10 and a random sigma between 1 and 10. It doesn't matter what those constants are. And then for the number of standard deviations in 1, 1.96, and 3, I'm going to integrate Gaussian over that range. And then we're just going to see how many of them fall within that range. In some sense, what we're doing is we're checking the empirical rule. We're saying, take the Gaussian. I don't care what mu and sigma are. It doesn't matter. The empirical rule will still hold, I think. But we're just checking it here, OK? Well, here are the results. So from mu equals 9 and sigma equals 6, I happened to choose those, we'll see the fracture within 1, fraction within 1.96 and 3. And so for these random mus and sigmas, you can see that all of them-- and you can set them to whatever you want when you get your hand them the code. Essentially, what we have is, whoops, the empirical rule actually works. One of those beautiful cases where you can test the theory and see that the theory really is sound. So there we go. So why am I making such a big deal of normal distributions? They have lots of nice mathematical properties, some of which we've already talked about. But all of that would be irrelevant if we didn't see them. The good news is they're all over the place. I've just taken a few here.","75.97674560546875","1","DPRSearchEngine","rUxP7TM8-wo.en-qlPKC2UN_YU_5_mp4","rUxP7TM8-wo.en-qlPKC2UN_YU","6.0002","7"
"257","Why is it important to fix the values of mu and sigma when integrating over values of x using the Gaussian function?","And second, that the distribution of errors will be normally distributed. I didn't probably mention at the time, but we often call this distribution Gaussian after the astronomer Carl Gauss. And it looks like that. Normal distributions are very easy to generate in Python. I have a little example here of generating, not a real normal distribution, but a discrete approximation of one. And the thing to really notice about it here is this line random.gauss. So that's a built in function of the random library. The first argument is the mean. And the second argument is the standard deviation or a mu and sigma as they're usually called. Every time I call that, I will get a different-- or usually a different random value drawn from a Gaussian with the mean, in this case of 0 and a standard deviation of 100. I'm then going to produce a plot of those so you can see what it looks like. And I'm going to do that using some things we haven't seen before. So first of all, we've seen histograms.","75.18229675292969","2","DPRSearchEngine","rUxP7TM8-wo.en-qlPKC2UN_YU_2_mp4","rUxP7TM8-wo.en-qlPKC2UN_YU","6.0002","7"
"257","Why is it important to fix the values of mu and sigma when integrating over values of x using the Gaussian function?","is that the variance of the sample means will be close to the variance of the population divided by the sample size. And we're going to use that to compute something called the standard error-- formerly the standard error of the mean. People often just call it the standard error. And I will be, alas, inconsistent. I sometimes call it one, sometimes the other. It's an incredibly simple formula. It says the standard error is going to be equal to sigma, where sigma is the population standard deviation divided by the square root of n, which is going to be the size of the sample. And then there's just this very small function that implements it. So we can compute this thing called the standard error of the mean in a very straightforward way. We can compute it. But does it work? What do I mean by work? I mean, what's the relationship of the standard error to the standard deviation? Because, remember, that was our goal, was to understand the standard deviation so we could use the empirical rule. Well, let's test the standard error of the mean.","74.91767883300781","3","DPRSearchEngine","soZv_KKax3E.en-qlPKC2UN_YU_9_mp4","soZv_KKax3E.en-qlPKC2UN_YU","6.0002","8"
"257","Why is it important to fix the values of mu and sigma when integrating over values of x using the Gaussian function?","So let me show you what this does, and then we're going to use it. The y's are measured values. Those are my samples I got from my experiment. The p's are the predicted values. That is, for this curve, here's what I predict those values should be. So the top here is basically measuring as we saw before the sum squared error in those pieces. Mu down here is the average, or mean, of the measured values. It's the average of the y's. So what I've got here is in the numerator-- this is basically the error in the estimates from my curve fit. And in the denominator I've got the amount of variation in the data itself. This is telling me how much does the data change from just being a constant value, and this is telling me how much do my errors vary around it. That ratio is scale independent because it's a ratio. So even if I increase all of the values by some amount, that's going to divide out, which is kind of nice. So I could compute that, and there it is.","72.90257263183594","4","DPRSearchEngine","vIFKGFl1Cn8.en-qlPKC2UN_YU_15_mp4","vIFKGFl1Cn8.en-qlPKC2UN_YU","6.0002","9"
"257","Why is it important to fix the values of mu and sigma when integrating over values of x using the Gaussian function?","()(
import scipy.integrate
def gaussian(x, mu, sigma)
…
def checkEmpirical(numTrials):
for t in range(numTrials):
mu = random.randint(-10, 10)
sigma = random.randint(1, 10)
print('For mu =', mu, 'and sigma =', sigma)
for numStd in (1, 1.96, 3):
area = scipy.integrate.quad(gaussian,
mu-numStd*sigma,
mu+numStd*sigma,
(mu, sigma))[0]
print(' Fraction within', numStd,
'std =', round(area, 4))
	

9
","71.04855346679688","5","DPRSearchEngine","3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7_9_pdf","3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7","6.0002","7"
"257","Why is it important to fix the values of mu and sigma when integrating over values of x using the Gaussian function?","looking formula which defines a PDF for a normal distribution. And here's some code that's as straight forward an implementation as one could imagine of this formula, OK. So that now is a value that, given a mu and a sigma and an x, gives me the x associated with that mu and sigma, OK? And you'll notice there's nothing random about this. All right, it is giving me the value. Now, let's go down here. And I'm going to, for a set of x's, get the set of y's corresponding to that and then plot it. I'm going to set mu to 0 and sigma to 1, the so-called standard normal distribution. And I'm going to look at the distribution from minus 4 to 4. Nothing magic about that other than, as you'll see, it's kind of a place where it asymptotes near 0. So while x is less than 4, I'll get the x-value, I'll get the y-value corresponding to that x by calling Gaussian, increment x by 0.05 and do that until I'm done. And then simply, I'll plot the x-values against the y-values and throw a title on it using pylab.title. All right, code make sense? Well, this is where I got that beautiful picture we've looked at before. When I plotted here, it looks, actually quite smooth. It's not, it's really connecting a bunch of tiny little lines but I made the points close enough together that it looks at least here smooth at this resolution. So we know what the values on the x-axis are. Those are the values I happen to want to look at, from minus 4 to 4. What are the values on the y-axis? We kind of would like to interpret them as probabilities, right? But we could be pretty suspicious about that and then if we take this one point that's up here, we say the probability of that single point is 0.4. Well, that doesn't make any sense because, in fact, we know the probability of any particular point is 0 in some sense, right? So furthermore, if I chose a different value for sigma, I can actually get this to go bigger than 1 on the y-axis. So if you take sigma to be say, 0.1-- I think the y-axis goes up to something like 40. So we know we don't have probabilities in the range 40. So if these aren't probabilities, what are they? What are the y values? Well, not too surprising since I claimed this was a probability density function, they're densities. Well, what's a density? This makes sense. I'll say it and then I'll try and explain it. It's a derivative of the cumulative distribution function. Now, why are we talking about derivatives in the first place? Well, remember what we're trying to say. If we want to ask, what's the probability of a value falling between here and here, we claim that that was going to be the area under this curve, the integral. Well, as you know from 18.01, there's a very clear relationship between derivatives and integrals. And so if we interpret each of these points as a derivative, in some sense the slope here, then we can look at this as the area just by integrating under there. So to interpret a PDF, we always do it mathematically. Actually, I do it just by looking at it. But the only really interesting mathematical questions to ask have to do with area. Once we have the area, we can, then, talk about the probabilities of some value falling within a region of the curve. So what's interesting here is not the numbers per se on the y-axis but the shape of the curve, because those numbers have to be related to the numbers on the x-axis, dx, dy right? We're looking at derivatives. All right, so now, we have to talk about integration. I promise you'll only hear about it for another few minutes then we'll leave the topic. So I mentioned before SciPy as a library that contains a lot of useful mathematical functions. One of them is integrate.quad. Well, the integrate part is obvious. It means integration. Quad is telling you the algorithm it's choosing to do the integration. All of these integrals are going to be actual approximations to the real integral. SciPy is not doing some clever mathematics to get an analytical solution. It's using a numerical technique to approximate the integral. And the one here happens to be called quadrature, it doesn't matter. All right, you can pass it up to four arguments. You must pass it to function to be integrated, that makes sense. A number representing the lower limit of the integration-- you need to give it that. A number representing the upper limit-- you need to give it that. And then the fourth argument is a tuple supplying all values for the arguments, except the first of the function you are integrating. I'll show you an example of that on the next slide. And we'll see that it returns a tuple, an approximation to the result, what it thinks the integral is, and an estimate of how much error there might be in that one. We'll ignore the error for the moment. All right, let's look at the code.","70.88080596923828","6","DPRSearchEngine","rUxP7TM8-wo.en-qlPKC2UN_YU_4_mp4","rUxP7TM8-wo.en-qlPKC2UN_YU","6.0002","7"
"257","Why is it important to fix the values of mu and sigma when integrating over values of x using the Gaussian function?","Quite different, right? We've looked at uniform and we've looked at Gaussian before. And here we see an exponential, which basically decays and will asymptote towards zero, never quite getting there. But as you can see, it is certainly not very symmetric around the mean. All right, so let's see what happens. If we run the experiment on these three distributions, each of 100,000 point examples, and look at different sample sizes, we actually see that the difference between the standard deviation and the sample standard","70.6781005859375","7","DPRSearchEngine","soZv_KKax3E.en-qlPKC2UN_YU_13_mp4","soZv_KKax3E.en-qlPKC2UN_YU","6.0002","8"
"257","Why is it important to fix the values of mu and sigma when integrating over values of x using the Gaussian function?","0.5 times 0.4. You guys can figure that out. I think that's 0.2. So you'd expect that, that it should be much smaller than either of the first two probabilities. This is the most common rule, it's something we use all the time in probabilities, the so-called multiplicative law. We have to be careful about it, however, in that it only holds if the events are actually","69.75663757324219","8","DPRSearchEngine","-1BnXEwHUok.en-qlPKC2UN_YU_5_mp4","-1BnXEwHUok.en-qlPKC2UN_YU","6.0002","4"
"257","Why is it important to fix the values of mu and sigma when integrating over values of x using the Gaussian function?","So how do I decide which one's better other than eyeballing it? And then if I could fit a quadratic to it, what about other orders of polynomials? Maybe there's an even better fit out there. So how do I figure out what's the best way to do the fit? And that leads to the second big thing for this lecture. How good are these fits? What's the first big thing? The idea of linear regression, a way of finding fits of curves to data. But now I've got to decide how good are these. And I could ask this question two ways. One is just relative to each other, how do I measure which one's better other than looking at it by eye? And then the second part of it is in an absolute sense, how do I know where the best solution is? Is quadratic the best I could do? Or should I be doing something else to try and figure out a better solution, a better fit to the data? The relative fit. What are we doing here? We're fitting a curve, which is a function of the independent variable to the dependent variable. What does it mean by that? I've got a set of x values. I'm trying to predict what the y values should be, the displacement should be. I want to get a good fit to that. The idea is that given an independent value, it gives me an estimate of what it should be, and I really want to know which fit provides the better estimates. And since I was simply minimizing mean squared error, average square error, an obvious thing to do is just to use the goodness of fit by looking at that error. Why not just measure where am I on that surface and see which one does better? Or actually it would be two surfaces, one for a linear fit, one for a quadratic one. We'll do what we always do. Let's write a little bit of code. I can write something that's going to get the average, mean squared error.","69.66657257080078","9","DPRSearchEngine","vIFKGFl1Cn8.en-qlPKC2UN_YU_13_mp4","vIFKGFl1Cn8.en-qlPKC2UN_YU","6.0002","9"
"257","Why is it important to fix the values of mu and sigma when integrating over values of x using the Gaussian function?","And we'll come back to this in just a second. But this is a normal distribution, called the Gaussian. Under those two assumptions the empirical rule will always hold. All right, let's talk about distributions, since I just introduced one. We've been using a probability distribution. And this captures the notion of the relative frequency with which some random variable takes on different values.","68.73115539550781","10","DPRSearchEngine","OgO1gpXSUzU.en-j3PyPqV-e1s_16_mp4","OgO1gpXSUzU.en-j3PyPqV-e1s","6.0002","6"
"260","What is the purpose of the wormholes dictionary in the OddField class?","Not odd numbers, but odd as in strange. So it's going to be a subclass of field. We're going to have a parameter that tells us how many worm holes it has. A default value of 1,000. And we'll see how we use xRange and yRange shortly. So what are the first thing we do? Well, we'll call Field _init to initialize the field in the usual way. And then we're going to create a dictionary of wormholes. So for w in the range number of worm holes, I'm going to choose a random x and a random y in xRange minus xRange to plus xRange, minus yRange to yRange. So this is going to be where the worm holes are located. And then for each of those, I'm going to get a random location where you're, in some sense, teleported to if you enter the wormhole. So here we're using random to get random integers. We've seen that before. And so the new location will be the location of the new x and the new y, and we're going to update this dictionary of wormholes to say that paired with the location x, y is newLoc. Now when we move the drunk, and again this is just changing-- we're overriding moveDrunk, so we're overriding one","77.14949035644531","1","DPRSearchEngine","6wUD_gp5WeE.en-qlPKC2UN_YU_17_mp4","6wUD_gp5WeE.en-qlPKC2UN_YU","6.0002","5"
"260","What is the purpose of the wormholes dictionary in the OddField class?"," 
 
 
 
 
 
 
A  Subclass of Field, part 2  
def moveDrunk(self, drunk):  
Field.moveDrunk(self, drunk)  
x = self.drunks[drunk].getX()  
y = self.drunks[drunk].getY()  
if (x, y) in self.wormholes:  
self.drunks[drunk] = self.wormholes[(x, y)]  
6.0002  LECTURE 5 
37 
","75.53071594238281","2","DPRSearchEngine","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_37_pdf","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5","6.0002","5"
"260","What is the purpose of the wormholes dictionary in the OddField class?"," 
 
 
 
 
A  Subclass of Field, part 1  
class OddField(Field):  
def __init__(self, numHoles = 1000,  
xRange = 100, yRange = 100):  
Field.__init__(self)  
self.wormholes = {}  
for w in range(numHoles):  
x = random.randint(-xRange, xRange)  
y = random.randint(-yRange, yRange)  
newX = random.randint(-xRange, xRange)  
newY = random.randint(-yRange, yRange)  
newLoc = Location(newX, newY)  
self.wormholes[(x, y)] = newLoc  
6.0002  LECTURE 5 
36 
","74.43251037597656","3","DPRSearchEngine","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_36_pdf","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5","6.0002","5"
"260","What is the purpose of the wormholes dictionary in the OddField class?","[SQUEAKING] [RUSTLING] [CLICKING] ERIK DEMAINE: All right, welcome back to 006. Today we start a totally new section of the class. Up till now, we've mostly been showing you really cool and powerful algorithms, sorting algorithms, graph algorithms, data structures, trees, lots of good stuff that you can apply to solve tons of algorithmic problems, either by reducing to the data structures that we showed you, or reducing to graph problems that we showed you, or by modifying those algorithms a bit. Today we're going to start a new section on algorithmic design-- how to, from scratch, come up with a polynomial time algorithm to solve a problem. And in particular, we're going to talk about a algorithmic design paradigm called dynamic programming, which is extremely powerful. It's probably the most powerful algorithmic design paradigm. Very general. Can solve lots of problems. It's a particular type of recursive algorithm design. And in general, this class-- all of algorithms-- is about recursive algorithm design at some level, because we want to write constant-sized pieces of code that solve problems of arbitrary size. We have some problem size n and we're trying to write 100 lines of code or whatever, some constant amount that doesn't depend on the problem size. We have one algorithm that solves all instances of the problem. And so we have to write code that is recursive or uses loops or somehow reuses the instructions that we give the computer. And you may know you can convert any algorithm based on loops into an algorithm using recursion. And we're going to take the recursive view today, in particular because it fits very well with our proof-by-induction technique, which we've used throughout this class, but also because it gives us some structure on how different subproblems relate in something called a subproblem graph, that we'll be talking about today. And so we're going to start out with, in general, how do we design recursive algorithms? That's sort of the overall, encompassing everything. We have thought very hard to come up with a cool acronym for this paradigm which we invented called SRTBOT-- thanks, Jason. And so we'll talk-- it's not actually for sorting. It's just an acronym for sub-problems, relations, topological order, base case, original problem, and time. But it's an acronym that will help you remember all the steps you need in order to specify","71.95455169677734","4","DPRSearchEngine","r4-cftqTcdI.en-j3PyPqV-e1s_1_mp4","r4-cftqTcdI.en-j3PyPqV-e1s","6.006","15"
"260","What is the purpose of the wormholes dictionary in the OddField class?"," 
  
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
New in  Code  
§numpy.std is function in the numpy module that
returns the standard deviation
§random.sample(population, sampleSize) returns a list
containing sampleSize randomly chosen distinct
elements of population
◦Sampling without replacement
6.0002  LECTURE 8 
 
8
","71.0768814086914","5","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_8_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"260","What is the purpose of the wormholes dictionary in the OddField class?"," 
 
 
Fields with Wormholes  
6.0002  LECTURE 5 
35 
","70.74917602539062","6","DPRSearchEngine","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_35_pdf","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5","6.0002","5"
"260","What is the purpose of the wormholes dictionary in the OddField class?","The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation, or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. PROFESSOR: Hello, everybody. Before we start the material, a couple of announcements. As usual, there's some reading assignments, and you might be surprised to see something from Chapter 5 suddenly popping up. But this is my relentless attempt to introduce more Python. We'll see one new concept later today, list comprehension. Today we're going to look at classification. And you remember last, on Monday, we looked at unsupervised learning. Today we're looking at supervised learning. It can usually be divided into two categories. Regression, where you try and predict some real number associated with the feature vector, and this is something we've already done really, back when we looked at curve fitting, linear regression in particular. It was exactly building a model that, given some features, would predict a point. In this case, it was pretty simple. It was given x predict y. You can imagine generalizing that to multi dimensions.","70.26886749267578","7","DPRSearchEngine","eg8DJYwdMyg.en-qlPKC2UN_YU_1_mp4","eg8DJYwdMyg.en-qlPKC2UN_YU","6.0002","13"
"260","What is the purpose of the wormholes dictionary in the OddField class?","[SQUEAKING] [RUSTLING] [CLICKING] ERIK DEMAINE: All right, welcome back to 006 Data Structures. Today, we're going to cover a different kind of tree-like data structure called a heap-- a binary heap. It's going to let us solve sorting problem in a new way. Let me first remind you of a portion-- the problem we're going to be solving today is called priority queue. This is the interface. We'll see several data structures,","70.12872314453125","8","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_1_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"260","What is the purpose of the wormholes dictionary in the OddField class?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 3: Sorting 
Lecture 3: Sorting 
Set Interface (L03-L08) 
Container 
build(X) 
len() 
given an iterable X, build set from items in X 
return the number of stored items 
Static 
find(k) 
return the stored item with key k 
Dynamic 
insert(x) 
delete(k) 
add x to set (replace item with key x.key if one already exists) 
remove and return the stored item with key k 
Order 
iter ord() 
find min() 
find max() 
find next(k) 
find prev(k) 
return the stored items one-by-one in key order 
return the stored item with smallest key 
return the stored item with largest key 
return the stored item with smallest key larger than k 
return the stored item with largest key smaller than k 
• Storing items in an array in arbitrary order can implement a (not so efﬁcient) set 
• Stored items sorted increasing by key allows: 
– faster ﬁnd min/max (at ﬁrst and last index of array) 
– faster ﬁnds via binary search: O(log n) 
Set 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
Data Structure 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
• But how to construct a sorted array efﬁciently? 
","69.70735168457031","9","DPRSearchEngine","6d1ae5278d02bbecb5c4428928b24194_MIT6_006S20_lec3_1_pdf","6d1ae5278d02bbecb5c4428928b24194_MIT6_006S20_lec3","6.006","3"
"260","What is the purpose of the wormholes dictionary in the OddField class?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","69.62548828125","10","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"263","How do sample size and variance affect the confidence in an estimate?"," 
 
 
  
 
 
 
 
 
 
 
 
 
  
 
  
 
Why the Difference in Confidence?  
Confidence in our estimate depends upon two things  
Size of sample (e.g., 100 versus 2) 
Variance of sample (e.g., all heads versus 52 heads) 
As the variance grows, we need larger samples to have 
the same degree of confidence 
6.0002 LECTURE 6 
9
","76.41486358642578","1","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_9_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"263","How do sample size and variance affect the confidence in an estimate?"," 
 
 
 
 
Lecture: Sampling and 
Standard Error 
6.0002  LECTURE 8 
 
1
","75.64479064941406","2","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_1_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"263","How do sample size and variance affect the confidence in an estimate?"," 
 
Looking at  Distributions 
def plotDistributions():  
uniform, normal, exp = [], [], []  
for i in range(100000):  
uniform.append(random.random())  
normal.append(random.gauss(0, 1))  
exp.append(random.expovariate(0.5))  
makeHist(uniform, 'Uniform', 'Value', 'Frequency')  
pylab.figure()  
makeHist(normal, 'Gaussian', 'Value', 'Frequency')  
pylab.figure()  
makeHist(exp, 'Exponential', 'Value', 'Frequency')  
6.0002  LECTURE 8 
 
27
","73.72090148925781","3","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_27_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"263","How do sample size and variance affect the confidence in an estimate?","Standard deviation simply the square root of the 
variance
Outliers can have a big effect
Standard deviation should always be considered 
relative to mean
Quantifying Variation in Data
6.0002 LECTURE 6
 
1
(X) 
(x )2
X xX
21
","73.60107421875","4","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_21_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"263","How do sample size and variance affect the confidence in an estimate?","!	!	 	
 
Let D be the original data set 
    n be the number of random samples  
 
 
 usually n between 20% and 50% 
    k be number of trials 
 
testResults = [] 
for i in range(k) 
    randomly select n elements for testSet,  
       keep rest for training 
    model = buildModel(training) 
    testResults.append(test(model, testSet)) 
 
Average testResults 

	

;G
","73.29193878173828","5","DPRSearchEngine","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10_38_pdf","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10","6.0002","10"
"263","How do sample size and variance affect the confidence in an estimate?"," 
 
Three Different Distributions  
random.random() 
random.gauss(0, 1) 
6.0002  LECTURE 8 
 
random.expovariate(0.5) 
28
","73.05361938476562","6","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_28_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"263","How do sample size and variance affect the confidence in an estimate?"," 
 
 
 
 
  
 
 
  
 
Probability of Various Results  
Consider testRoll(5) 
How probable is the output 11111?  
6.0002 LECTURE 4 
10
","72.53577423095703","7","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_10_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"263","How do sample size and variance affect the confidence in an estimate?"," 
 
 
 
 
Sample Size and Standard Deviation  
6.0002  LECTURE 8 
 
18
","72.4847412109375","8","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_18_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"263","How do sample size and variance affect the confidence in an estimate?","I'm going to look at a bunch of different sample sizes, from 25 to 600, 50 trials each. So getHighs is just a function that returns the temperatures. I'm going to get the standard deviation of the whole population, then the standard error of the means and the sample standard deviations, both. And then I'm just going to go through and run it. So for size and sample size, I'm going to append the standard error of the mean. And remember, that uses the population standard deviation and the size of the sample. So I'll compute all the SEMs. And then I'm going to compute all the actual standard deviations, as well. And then we'll produce a bunch of plots-- or a plot, actually. All right, so let's see what that plot looks like.","72.4679946899414","9","DPRSearchEngine","soZv_KKax3E.en-qlPKC2UN_YU_10_mp4","soZv_KKax3E.en-qlPKC2UN_YU","6.0002","8"
"263","How do sample size and variance affect the confidence in an estimate?"," 
  
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
New in  Code  
§numpy.std is function in the numpy module that
returns the standard deviation
§random.sample(population, sampleSize) returns a list
containing sampleSize randomly chosen distinct
elements of population
◦Sampling without replacement
6.0002  LECTURE 8 
 
8
","72.20240783691406","10","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_8_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"264","How does the function rollDie simulate a random process, and what is the expected outcome when testRoll is executed with n=10?","  
 
 
  
 
 
  
 
 
    
 
 
 
 
    
 
  
 
    
 
    
 
        
 
 
 
    
 
Implementing a Random Process  
import random 
def rollDie(): 
""""""returns a random int between 1 and 6"""""" 
return random.choice([1,2,3,4,5,6]) 
def testRoll(n = 10): 
result = '' 
for i in range(n): 
result = result + str(rollDie()) 
print(result) 
6.0002 LECTURE 4 
9
","82.99484252929688","1","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_9_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"264","How does the function rollDie simulate a random process, and what is the expected outcome when testRoll is executed with n=10?"," 
 
 
   
 
 
 
   
   
      
 
 
 
 
 
 
  
 
Stochastic Processes  
An ongoing process where the next state might depend on 
both the previous states and some random element 
def rollDie(): 
"""""" returns an int between 1 and 6"""""" 
def rollDie(): 
"""""" returns a randomly chosen int 
between 1 and 6"""""" 
6.0002 LECTURE 4 
8
","78.20597839355469","2","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_8_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"264","How does the function rollDie simulate a random process, and what is the expected outcome when testRoll is executed with n=10?","random.choice. It takes as an argument a sequence, in this case a list, and randomly chooses one member of the list. And it chooses it uniformly. It's a uniform distribution. And what that means is that it's equally probable that it will choose any number in that list each time you call it. We'll later look at distributions that are not uniform, not equally probable, where things are weighted. But here, it's quite simple, it's just uniform. And then we can test it using testRoll-- take some number of n and rolls the die that many times and creates a string telling us what we got. So let's consider running this on, say, testRoll of five. And we'll ask the question, if we run it, how probable is it that it's going to return a string of five 1's? How do we do that? Now, how many people here are either in 6.041 or would have taken 6.041? Raise your hand. Oh, good. So very few of you know probability. That helps. So how do we think about that question? Well, probability, to me at least, is all about counting, especially discrete probability, which is what we're looking at here. What you do is you start by counting the number of events that have the property of interest and the number of possible events and divide one by the other. So if we think about rolling a die five times, we can enumerate all of the possible outcomes of five rolls. So if we look at that, what are the outcomes? Well, I could get five 1's. I could get four 1's and a 2 or four 1's and 3, skip a few. The next one would be three 1's, a 2 and a 1, then a 2 and 2, and finally, at the end, all 6's. So remember, we looked before at when we're looking at optimization problems about binary numbers. And we said we can look at all the possible choices of items in the knapsack by a vector of 0's and 1's. We said, how many possible choices are there? Well, it depended on how many binary numbers you could get in that number of digits. Well, here we're doing the same thing, but instead of base 2, it's base 6. And so the number of possible outcomes of five rolls is quite high. How many of those are five 1's? Only one of them, right? So in order to get the probability of a five 1's, I divide 1 by 6 to the fifth. Does that makes sense to everybody? So in fact, we see it's highly unlikely. The probability of a five 1's is quite small. Now, suppose we were to ask about the probability of something else-- instead of five 1's, say 53421. It kind of looks more likely than that than five 1's in a row, but of course, it isn't, right? Any specific combination is equally probable. And there are a lot of them. So this is all the probability we're going to think about we could think about this way, as simply a matter of counting-- the number of possible events, the number of events that have the property of interest-- in this case being all 1's-- and then simple division. Given that framework, there were three basic facts about probability we're going to be using a lot of. So one, probabilities always range from 0 to 1. How do we know that? Well, we've got a fraction, right? And the denominator is all possible events. The numerator is the subset of that that's of interest. So it has to range from 0 to the denominator. And that tells us that the fraction has to range from 0 to 1. So 1 says it's always going to happen, 0 never. So if the probability of an event occurring is p, what's the probability of it not occurring? This follows from the first bullet. It's simply going to be 1 minus p. This is a trick that we'll find we'll use a lot. Because it's often the case when you want to compute the probability of something happening, it's easier to compute the probability of it not happening and subtract it from 1. And we'll see an example of that later today. Now, here's the biggie. When events are independent of each other, the probability of all of the events occurring is equal to the product of the probabilities of each of the events occurring. So if the probability of A is 0.5 and the probability of B","77.83636474609375","3","DPRSearchEngine","-1BnXEwHUok.en-qlPKC2UN_YU_4_mp4","-1BnXEwHUok.en-qlPKC2UN_YU","6.0002","4"
"264","How does the function rollDie simulate a random process, and what is the expected outcome when testRoll is executed with n=10?","!	!	 	
 
Let D be the original data set 
    n be the number of random samples  
 
 
 usually n between 20% and 50% 
    k be number of trials 
 
testResults = [] 
for i in range(k) 
    randomly select n elements for testSet,  
       keep rest for training 
    model = buildModel(training) 
    testResults.append(test(model, testSet)) 
 
Average testResults 

	

;G
","77.73423767089844","4","DPRSearchEngine","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10_38_pdf","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10","6.0002","10"
"264","How does the function rollDie simulate a random process, and what is the expected outcome when testRoll is executed with n=10?","  
 
 
  
 
 
 
    
 
    
 
 
        
 
        
 
            
 
        
 
            
  
    
 
          
 
    
 
 
    
 
          
 
 
 
 
A Simulation of Die Rolling  
def runSim(goal, numTrials, txt): 
total = 0 
for i in range(numTrials): 
result = '' 
for j in range(len(goal)): 
result += str(rollDie()) 
if result == goal: 
total += 1 
print('Actual probability of', txt, '=', 
round(1/(6**len(goal)), 8)) 
estProbability = round(total/numTrials, 8) 
print('Estimated Probability of', txt, '=', 
round(estProbability, 8)) 
runSim('11111', 1000, '11111') 
6.0002 LECTURE 4 
15
","77.1715087890625","5","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_15_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"264","How does the function rollDie simulate a random process, and what is the expected outcome when testRoll is executed with n=10?","So here, rather than rolling the die, I've written a program to do it. We've already seen the code for rolling a die. And so to run this simulation, typically what we're doing here is I'm giving you the goal-- for example, are we going to get five 1's-- the number of trials-- each trial, in this case, will be say of length 5-- so I'm going to roll the same die five times say 1,000 different times, and then just some text as to what I'm going to print. Almost all the simulations we look at are going to start with lines that look a lot like that. We're going to initialize some variable. And then we're going to run some number of trials. So in this case, we're going to get from the length of the goal-- so if the goal is five 1's, then we're going to roll the dice five times; if it's 10 runs, we'll roll it 10 times. So this is essentially one trial, one attempt. And then we'll check the result. And if it has the property we want-- in this case, it's equal to the goal-- then we're going to increment the total, which we initialized up here by 1. So we'll keep track with just the counting-- the number of trials that actually meet the goal. And then when we're done, what we're going to do is divide the number that met the goal by the number of trials-- exactly the counting argument we just looked at. And then we'll print the result. Almost every simulation we look at is going to have this structure. There'll be an outer loop, which is the number of trials. And then inside-- maybe it'll have a loop, or maybe it won't-- will be a single trial. We'll sum up the results. And then we'll divide by the number of trials. Let's run it. So a couple of things are going to go on here. If you look at the code as we've looked at it before, what you're seeing is I'm computing the estimated probability by the simulation. And I'm comparing it to the actual probability, which we've already seen how to compute. So if you look at it, there are a couple of things to look at. The estimated probability is pretty close to the actual probability but not the same. So let's go back to the PowerPoint. Here are the results. And there are at least two questions raised by this result. First of all, how did I know that this is what would get printed? Remember, this is random. How did I know that the estimate-- well, there's nothing random about the actual probability. But how did I know that the estimated probability would be 0? And why did it print it twice? Because I messed up the PowerPoint. Any rate, so how do I know what would get printed? Well a confession-- random.choice is not actually random. In fact, nothing we can do in a computer is actually random. You can prove that it's impossible to build a computer that actually generates truly random numbers. What they do instead is generate numbers that called pseudorandom. How do they do that? They have an algorithm that given one number generates the next number in a sequence. And they start that algorithm with a seed.","76.1950454711914","6","DPRSearchEngine","-1BnXEwHUok.en-qlPKC2UN_YU_7_mp4","-1BnXEwHUok.en-qlPKC2UN_YU","6.0002","4"
"264","How does the function rollDie simulate a random process, and what is the expected outcome when testRoll is executed with n=10?"," 
	 	
def splitData(xVals, yVals): 
    toTrain = random.sample(range(len(xVals)), 
                            len(xVals)//2) 
    trainX, trainY, testX, testY = [],[],[],[] 
    for i in range(len(xVals)): 
        if i in toTrain: 
            trainX.append(xVals[i]) 
            trainY.append(yVals[i]) 
        else: 
            testX.append(xVals[i]) 
            testY.append(yVals[i]) 
    return trainX, trainY, testX, testY 
	

?
","76.16334533691406","7","DPRSearchEngine","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10_46_pdf","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10","6.0002","10"
"264","How does the function rollDie simulate a random process, and what is the expected outcome when testRoll is executed with n=10?"," 
 
 
  
 
 
 
    
 
 
    
 
        
 
        
 
 
    
 
        
 
 
 
 
        
 
 
 
              
 
    
 
 
 
  
 
 
 
 
    
 
 
        
 
 
 
Monte Carlo Simulation  
def playRoulette(game, numSpins, pocket, bet): 
totPocket = 0 
for i in range(numSpins): 
game.spin()  
totPocket += game.betPocket(pocket, bet)  
if toPrint: 
print(numSpins, 'spins of', game) 
print('Expected return betting', pocket, '=',\\ 
str(100*totPocket/numSpins) + '%\\n') 
return (totPocket/numSpins) 
game = FairRoulette() 
for numSpins in (100, 1000000): 
for i in range(3): 
playRoulette(game, numSpins, 2, 1, True) 
6.0002 LECTURE 6 
12
","76.15970611572266","8","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_12_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"264","How does the function rollDie simulate a random process, and what is the expected outcome when testRoll is executed with n=10?","	
	! 
for f in range(numSubsets): 
    trainX,trainY,testX,testY = splitData(xVals, yVals) 
    for d in dimensions: 
        model = pylab.polyfit(trainX, trainY, d) 
        #estYVals = pylab.polyval(model, trainX) 
        estYVals = pylab.polyval(model, testX) 
        rSquares[d].append(rSquared(testY, estYVals)) 
 
print('Mean R-squares for test data') 
for d in dimensions: 
    mean = round(sum(rSquares[d])/len(rSquares[d]), 4) 
    sd = round(numpy.std(rSquares[d]), 4) 
    print('For dimensionality', d, 'mean =', mean, 
          'Std =', sd) 
	

?F
","75.4986343383789","9","DPRSearchEngine","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10_47_pdf","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10","6.0002","10"
"264","How does the function rollDie simulate a random process, and what is the expected outcome when testRoll is executed with n=10?"," 
 
 
  
 
 
 
 
 
 
 
    
 
 
 
 
    
 
 
 
          
 
    
 
        
 
 
 
                                         
 
 
        
 
 
        
 
                                          
 
                                          
 
        
 
 
              
 
               
 
 
 
               
 
Applying Empirical Rule  
resultDict = {}  
games = (FairRoulette, EuRoulette, AmRoulette)  
for G in games:  
resultDict[G().__str__()] = [] 
for numSpins in (100, 1000, 10000): 
print('\\nSimulate betting a pocket for', numTrials, 
'trials of', numSpins, 'spins each') 
for G in games: 
pocketReturns = findPocketReturn(G(), 20, 
numSpins, False) 
mean, std = getMeanAndStd(pocketReturns) 
resultDict[G().__str__()].append((numSpins, 
100*mean, 
100*std)) 
print('Exp. return for', G(), '=', 
str(round(100*mean, 3)) 
+ '%,', '+/- ' + str(round(100*1.96*std, 3)) 
+ '% with 95% confidence') 
6.0002 LECTURE 6 
25
","75.18612670898438","10","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_25_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"266","Why might a 16th order polynomial model not be suitable for explaining a physical process, despite its high accuracy in fitting data points?","A pretty small number. But the probability of 26 consecutive reds when the previous 25 rolls were red is what? No, that. AUDIENCE: Oh, I thought you meant it had been 26 times again. JOHN GUTTAG: No, if you had 25 reds and then you spun the wheel once more, the probability of it having 26 reds is now 0.5, because these are independent events. Unless of course the wheel is rigged, and we're assuming it's not. People have a hard time accepting this, and I know it seems funny. But I guarantee there will be some point in the next month or so when you will find yourself thinking this way, that something has to even out. I did so badly on the midterm, I will have to do better on the final. That was mean, I'm sorry. All right, speaking of means-- see? Professor Grimson not the only one who can make bad jokes. There is something-- it's not the gambler's fallacy-- that's often confused with it, and that's called regression to the mean. This term was coined in 1885 by Francis Galton in a paper, of which I've shown you a page from it here.","74.34814453125","1","DPRSearchEngine","OgO1gpXSUzU.en-j3PyPqV-e1s_8_mp4","OgO1gpXSUzU.en-j3PyPqV-e1s","6.0002","6"
"266","Why might a 16th order polynomial model not be suitable for explaining a physical process, despite its high accuracy in fitting data points?","is much better than the second order model. And that's why, in this case, I would want to use that first order model. So take home message. And then we're going to amplify this. If I pick an overly complex model, I have the danger of overfitting to the training data, overfitting meaning that I'm not only fitting the underlying process, I'm fitting the noise. I get an order 16 model is the best fit when it's in fact, in order 2 model that was generating it. That increases the risk that it's not going to do well with the data, not what I'd like. I want to be able to predict what's going to go on well here. On the other hand. So that would say, boy, just stick with the simplest possible model. But there's a trade off here. And we already saw that when I tried to fit a line to a data that was basically quadratic. I didn't get a good fit. So I'd want to find the balance. An insufficiently complex model won't explain the data well. An overly complex model will overfit the training data. So I'd like to find the place where the model is as simple as possible, but still explains the data. And I can't resist the quote from Einstein that captures it pretty well, ""everything should be made as simple as possible, but not simpler."" In the case of where I started, it should be fit to a quadratic, because it's the right fit. But don't fit more than that, because it's getting overly complex Now how might we go about finding the right model? We're not going to dwell on this but here is a standard way in which you might do it. Start with a low order model. Again, take that data. Fit a linear model to it. Look at not only the r-squared value, but see how well it accounts for new data. Increase the order of the model. Repeat the process. And keep doing that until you find a point at which a model does a good job both on the training data and on predicting new data. An after it starts to fall off, that gives you a point where you might say there's a good sized model. In the case of this data, whether I would have stopped at a quadratic or I might have used a cubic or a quartic depends on the values. But I certainly wouldn't have gone much beyond that. And this is one way, if you don't have a theory to drive you, to think about, how do I actually fit the model the way I would like. Let's go back to where we started. We still have one more big topic to do, and we still have a few minutes left. But let's go back to where we started Hooke's law. There was the data from measuring displacements of a spring, as I added different weights to the bottom of the spring. And there's the linear fit. It's not bad. There's the quadratic fit. And it's certainly got a better r-squared value, though. That could be just fitting to the noise. But you actually can see, I think, that that green curve probably does a better job of fitting the data. Well, wait a minute. Even though the quadratic fit is tighter here, Hooke says, this is linear. So what's going on? Well, this is another place where you want to think about your model. And I'll remind you, in case you don't remember your physics, unless we believe that Hooke was wrong, this should tell us something. And in particular, Hooke's law says, the model holds until you reach the elastic limit of the spring. You stretch a slinky too far, it never springs back. You go beyond that elastic limit. And that's probably what's happening right up there. Through here, it's following that linear relationship. Up at this point, I've essentially broken the spring. The elastic limit doesn't hold anymore. And so really, in this case, I should probably fit different models to different segments. And there's a much better fit. Linear through the first part and another later line once I hit that elastic limit. How might I find this? Well, you could imagine a little search process in which you try and find where's the best place along here to break the data into two sets, fit linear segments to both, and get really good fits for both examples. And I raise it because that's the kind of thing you've also seen before. You could imagine writing code to do that search to find that good fit. OK, that gives you a sense, then, of why you want to be careful about overfitting, why you want to not just look at the coefficient of determination, but see how well does this predict behavior on new data sets. Now suppose I don't have a theory, like Hooke, to guide me. Can I still figure out what's a good model to fit to the data? And the answer is, you bet. We're going to use cross-validation to guide the choice of the model complexity. And I want to show you two examples. If the data set's small, we can use what's called leave one out cross-validation. I'll give you a definition of that in a second. If the data sets bigger than that, we can use k-fold cross-validation. I'll give you a definition that a second. Or just what's called, repeated random sampling. But we can use this same idea of validating new data to try and figure out whether the model is a good model or not. Leave one out cross-validation. This is as written in pseudocode, but the idea is pretty simple. I'm given a dataset.","73.85796356201172","2","DPRSearchEngine","fQvg-hh9dUw.en-qlPKC2UN_YU_17_mp4","fQvg-hh9dUw.en-qlPKC2UN_YU","6.0002","10"
"266","Why might a 16th order polynomial model not be suitable for explaining a physical process, despite its high accuracy in fitting data points?","I know you don't believe it, but it is because notice what it says, it says the r squared value for the line is horrible. It accounts for less than 0.05% of the data. You could say, OK, I can see that. I look at it. It does a lousy job. On the other hand, the quadratic is really pretty good. It's accounting for about 84% of the variability in the data. This is a nice high value. It's not one, but it's a nice high value. So this is now reinforcing what I already knew, but in a nice way. It's telling me that that r squared value tells me that the quadratic is a much better fit than the linear fit was. But then you say maybe, wait a minute. I could have done this by just comparing the fits themselves. I already saw that. Part of my goal is how do I know if I've got the best fit possible or not. So I'm going to do the same thing, but now I'm going to run it with another set of degrees. I'm going to go over here. I'm going to take exactly the same code. But let's try it with a quadratic, with a quartic, an order eight, and an order 16 fit. So I'm going to take different size polynomials. As a quick aside, this is why I want to use the PyLab kind of code because now I'm simply optimizing over a 16-dimensional space. Every point in that 16-dimensional space defines a 16th-degree polynomial. And I can still use linear regression, meaning walking down the gradient, to find the best solution. I'm going to run this. And I get out a set of values. Looks good. And let's go look at them.","73.71043395996094","3","DPRSearchEngine","vIFKGFl1Cn8.en-qlPKC2UN_YU_18_mp4","vIFKGFl1Cn8.en-qlPKC2UN_YU","6.0002","9"
"266","Why might a 16th order polynomial model not be suitable for explaining a physical process, despite its high accuracy in fitting data points?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","72.78182220458984","4","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"266","Why might a 16th order polynomial model not be suitable for explaining a physical process, despite its high accuracy in fitting data points?","I want to deal with. In each case, get a different training and test set, at random. And then, for each dimension, do the fit. There's polyfit on the training x and training y values in that dimension. Gives you back a model. I could just check to see how well the training set gets, but I really want to look at, given that model, how well does polyval predict the test set, right? The model will say, here's what I expect is the values. I'm going to compare that to the actual values that I saw from the training set, computing that r squared value and adding it in. And then the last of this just says, I'll run this through a set of examples. OK, here's what happens if I do that. I'm not going to run it, although the code will run it. Let me, again, remind you what I'm doing. I got a big set of data I'm going to pick out at random, subsets of it, build the model on one part, test it on the other part. And if I run it, I get a linear fit, quadratic fit, cubic fit, and a quartic fit. And here's the standard deviation of those samples. Remember, I've got multiple trials. I've got 10 trials, in this case. So this gives me the average over those trials. And this tells me how much they vary. What can I conclude from this? Well, I would argue that the linear fit's probably the winner here. Goes back to Einstein. I want the simplest possible model that accounts for it. And you can see it's got the highest r-squared value, which is already a good sign. It's got the smallest deviation across the trials, which says it's probably a pretty good fit. And it's the simplest model. So linear sounds like a pretty good fit. Now, why should we run multiple data sets to test this? I ran 10 trials of each one of these dimensions. Why bother with it? Well, notice that those deviations-- I'll go back to it here-- they're pretty good. They're about an order of magnitude less than the actual mean, which says they're pretty tight, but they're still reasonable size. And that suggests that, while there's good agreement, the deviations are large enough that you could see a range of variation across the trials. So in fact, if I had just run one trial, I could have been screwed. Sorry, oh-- sorry, pick your favorite [INAUDIBLE] here. [? Hose ?] is a Canadian expression, in case you haven't seen it. Here are the r-squared values for each trial of the linear fit. And you can see the mean comes up pretty well. But notice, if I'd only run one trial and I happened to get that one, oh, darn. That's a really low r-squared value. And we might have decided, in this case, a different conclusion, that the linear fit was not a good fit. So this is a way of saying, even in a random sampling, run multiple trials, because it lets you get statistics on those trials, as well as statistics within each trial. So with any trial, I'm doing a whole bunch of different random samples on measuring those values. And then, across those trials, I'm seeing what the deviation is. I'm going to hope my machine comes back, because what I want to do is then pull this together. What have we done? Something you're going to use. We've seen how you can use linear regression to fit a curve to data, 2D, 3D, 6D, however big the data set is. It gives us a mapping from the independent values to the dependent values. And that can then be used to predict values associated with the independent values that we haven't seen yet. That leads, naturally, to both a way to measure, which is r squared, but especially to see that we want to look at how well does that model actually predict new data, because that lets us select the simplest model we can that accounts for the data, but predicts new data in an effective way. And that complexity can either be based on theory, in the case of Hooke, or in more likely cases, by doing cross-validation to try and figure out which one is the simplest model that still does a good job of predicting out of data behavior. And with that, I'll see you next time.","72.5290298461914","5","DPRSearchEngine","fQvg-hh9dUw.en-qlPKC2UN_YU_21_mp4","fQvg-hh9dUw.en-qlPKC2UN_YU","6.0002","10"
"266","Why might a 16th order polynomial model not be suitable for explaining a physical process, despite its high accuracy in fitting data points?","So how do I decide which one's better other than eyeballing it? And then if I could fit a quadratic to it, what about other orders of polynomials? Maybe there's an even better fit out there. So how do I figure out what's the best way to do the fit? And that leads to the second big thing for this lecture. How good are these fits? What's the first big thing? The idea of linear regression, a way of finding fits of curves to data. But now I've got to decide how good are these. And I could ask this question two ways. One is just relative to each other, how do I measure which one's better other than looking at it by eye? And then the second part of it is in an absolute sense, how do I know where the best solution is? Is quadratic the best I could do? Or should I be doing something else to try and figure out a better solution, a better fit to the data? The relative fit. What are we doing here? We're fitting a curve, which is a function of the independent variable to the dependent variable. What does it mean by that? I've got a set of x values. I'm trying to predict what the y values should be, the displacement should be. I want to get a good fit to that. The idea is that given an independent value, it gives me an estimate of what it should be, and I really want to know which fit provides the better estimates. And since I was simply minimizing mean squared error, average square error, an obvious thing to do is just to use the goodness of fit by looking at that error. Why not just measure where am I on that surface and see which one does better? Or actually it would be two surfaces, one for a linear fit, one for a quadratic one. We'll do what we always do. Let's write a little bit of code. I can write something that's going to get the average, mean squared error.","72.16217041015625","6","DPRSearchEngine","vIFKGFl1Cn8.en-qlPKC2UN_YU_13_mp4","vIFKGFl1Cn8.en-qlPKC2UN_YU","6.0002","9"
"266","Why might a 16th order polynomial model not be suitable for explaining a physical process, despite its high accuracy in fitting data points?","simply measures the difference between them, squares them, adds them all up in a little loop here and returns that divided by the number of samples I have. So it gives me the average squared error. And I could do it for that first model I built, which was for a linear fit, and I could do it for the second model I built, which is a quadratic fit. And if I run it, I get those values. Looks pretty good. You knew by eye that the quadratic was a better fit. And look, this says it's about six times better, that the residual error is six times smaller with the quadratic model than it is the linear model. But with that, I still have a problem, which is-- OK, so it's useful for comparing two models. But is 1524 a good number? Certainly better than 9,000-something or other. But how do I know that 1524 is a good number? How do I know there isn't a better fit out there somewhere? Well, good news is we're going to be able to measure that. It's hard to know because there's no bound on the values. And more importantly, this is not scale independent. What do I mean by that? If I take all of the values and multiply them by some factor, I would still fit the same models to them. They would just scale. But that measure would increase by that amount. So I could make the error as big or as small as I want by just changing the size of the values. That doesn't make any sense. I'd like a way to measure goodness of fit that is scale independent and that tells me for any fit how close it comes to being the perfect fit to the data. And so for that, we're going to use something called the coefficient of determination","71.86254119873047","7","DPRSearchEngine","vIFKGFl1Cn8.en-qlPKC2UN_YU_14_mp4","vIFKGFl1Cn8.en-qlPKC2UN_YU","6.0002","9"
"266","Why might a 16th order polynomial model not be suitable for explaining a physical process, despite its high accuracy in fitting data points?","§ Problem is exponen<al 
§ Have we overturned the laws of the universe? 
§ Is dynamic programming a miracle? 
§ No, but computa<onal complexity can be subtle 
§ Running <me of fastMaxVal is governed by number of 
dis<nct pairs, <toConsider, avail> 
◦Number of possible values of toConsider bounded 
by len(items)
◦Possible values of avail a bit harder to characterize 
◦Bounded by number of dis<nct sums of weights 
◦Covered in more detail in assigned reading 
How Can This Be? 
6.0002 LECTURE 2 
30 
","71.82122039794922","8","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_30_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"266","Why might a 16th order polynomial model not be suitable for explaining a physical process, despite its high accuracy in fitting data points?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","71.34492492675781","9","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"266","Why might a 16th order polynomial model not be suitable for explaining a physical process, despite its high accuracy in fitting data points?","we're not going to put the drunk in. We're going to raise a value error, ""Duplicate drunk."" Otherwise we're going to set the value of drunkenness mapping to loc. Now you see, by the way, why I wanted drunks to be immutable. Because they have to be hashable so I can use them as a key in a dictionary. So it was not an idle question whether they were immutable. It was an important question. I can get the location of a drunk. If the drunk is not in there, then I'll raise a different value error, ""Drunk not in field."" Otherwise I'll return the location associated with that drunk. And finally, we're going to have moveDrunk.","71.20655822753906","10","DPRSearchEngine","6wUD_gp5WeE.en-qlPKC2UN_YU_9_mp4","6wUD_gp5WeE.en-qlPKC2UN_YU","6.0002","5"
"267","Why is having a small training error not sufficient for a great model?"," 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
Modeling the  World  
§Models  always  inaccurate
◦Provide abstractions of reality
§Deterministic models, e.g., graph theoretic
§Statistical models
◦Simulation models: Monte Carlo simulation
◦Models  based on sampling
◦Characterizing accuracy is critical
◦Central limit theorem
◦Empirical rule
◦Machine learning
◦Unsupervised and supervised
§Presentation of data
◦Plotting
◦Good and bad practices
6.0002  LECTURE 15 
21 
","67.20829772949219","1","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_18_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"267","Why is having a small training error not sufficient for a great model?"," 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
   
 
 
 
 
   
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
  
 
 
  
 
  
 
  
Turing machine model – review 
head 
˽ ˽ . . .
a
b
a
b
b
Finite 
read/write input tape 
control 
On input ! a TM "" may halt (enter #acc or #rej) 
) is T-recognizable if ) = +("") for some TM "". 
or loop (run forever). 
) is T-decidable if ) = +("") for some TM decider "". 
So "" has 3 possible outcomes for each input !: 
halts on all inputs 
1. Accept ! (enter #acc ) 
Turing machines model general-purpose computation. 
2. Reject ! by halting (enter #rej ) 
Q: Why pick this model? 
3. Reject ! by looping (running forever) 
A: Choice of model doesn't matter. 
All reasonable models are equivalent in power. 
Virtues of TMs: simplicity, familiarity. 
2 
","66.53777313232422","2","DPRSearchEngine","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_2_pdf","7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6","18.404J","6"
"267","Why is having a small training error not sufficient for a great model?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Monte Carlo Simulation  
A method of estimating the value of an unknown 
quantity using the principles of inferential statistics 
Inferential statistics 
◦ Population: a set of examples 
◦ Sample: a proper subset of a population 
◦ Key fact: a random sample tends to exhibit the same  
properties as the population from which it is drawn  
Exactly what we did with random walks 
6.0002 LECTURE 6 
4
","66.24099731445312","3","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_4_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"267","Why is having a small training error not sufficient for a great model?"," 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Looking at F eature Weights  
model.classes_  =  ['Died' 'Survived'] 
For  label Survived 
Be wary of reading too 
C1 = 1.66761946545 
much into the weights 
C2 = 0.460354552452 
Features are often 
C3 = -0.50338282535 
correlated 
age = -0.0314481062387 
male gender  = -2.39514860929 
L1 regression tends to drive one variable to zero 
L2 (default) regression spreads weights across variables 
6.0002  LECTURE 14 
4 
","66.22728729248047","4","DPRSearchEngine","b9d60f4ecb325e4648f9cf0379419338_MIT6_0002F16_lec14_4_pdf","b9d60f4ecb325e4648f9cf0379419338_MIT6_0002F16_lec14","6.0002","14"
"267","Why is having a small training error not sufficient for a great model?"," 
 
 
 
 
 
 
  
 
 
 
    
 
 
                    
 
 
                    
 
    
 
    
 
        
 
 
        
 
    
 
Another Win for Simulation
Adjusting analytic model a pain
Adjusting simulation model easy
def sameDate(numPeople, numSame): 
possibleDates = 4*list(range(0, 57)) + [58]\\ 
+ 4*list(range(59, 366))\\
+ 4*list(range(180, 270))
birthdays = [0]*366 
for p in range(numPeople): 
birthDate = random.choice(possibleDates) 
birthdays[birthDate] += 1 
return max(birthdays) >= numSame 
6.0002 LECTURE 4 
23
","66.11383056640625","5","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_23_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"267","Why is having a small training error not sufficient for a great model?"," 
 
 
 
 
 
 
 
 
 
  
 
Simulation Models
A description of computations that provide useful
information about the possible behaviors of the system
being modeled
Descriptive, not prescriptive
Only an approximation to reality
“All models are wrong, but some are useful.” – George Box
6.0002 LECTURE 4 
24
","66.11203002929688","6","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_24_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"267","Why is having a small training error not sufficient for a great model?"," 
 
 
  
  
 
  
 
The World is Hard to Understand  
Uncertainty is uncomfortable 
But certainty is usually unjustified  
6.0002 LECTURE 4 
3
","65.87663269042969","7","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_3_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"267","Why is having a small training error not sufficient for a great model?"," 
 
  
  
  
 
 
  
       
   
 
 
 
 
 
 
  
 
 
 
  
 
  
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
  
 
 
 
  
 
 
   
 
 
   
 
 
 
 
   
 
 
 
 
 
 
 
 
    
 
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
  
 
TM – Formal Definition 
Defn: A Turing Machine (TM) is a 7-tuple ("", Σ, Γ, &, '(, 'acc , 'rej)
Σ input alphabet 
Γ tape alphabet (Σ ⊆Γ)
&: Q×Γ → ""×Γ× {L, R} 
(L = Left, R = Right) 
& ', a = (5, b, R) 
On input 6 a TM 7 may halt (enter 'acc or 'rej) 
Check-in 5.3 
or 7 may run forever (“loop”). 
This Turing machine model is deterministic. 
So 7 has 3 possible outcomes for each input 6: 
How would we change it to be nondeterministic? 
1. Accept 6 (enter 'acc ) 
a) Add a second transition function. 
2. Reject 6 by halting (enter 'rej ) 
b) Change & to be &: Q×Γ → 8( ""×Γ× {L, R} ) 
3. Reject 6 by looping (running forever) 
c) Change the tape alphabet Γ to be infinite. 
10 
Check-in 5.3 
","65.72943115234375","8","DPRSearchEngine","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_10_pdf","18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5","18.404J","5"
"267","Why is having a small training error not sufficient for a great model?"," 
 
 
  
 
 
 
    
 
 
    
 
        
 
        
 
 
    
 
        
 
 
 
 
        
 
 
 
              
 
    
 
 
 
  
 
 
 
 
    
 
 
        
 
 
 
Monte Carlo Simulation  
def playRoulette(game, numSpins, pocket, bet): 
totPocket = 0 
for i in range(numSpins): 
game.spin()  
totPocket += game.betPocket(pocket, bet)  
if toPrint: 
print(numSpins, 'spins of', game) 
print('Expected return betting', pocket, '=',\\ 
str(100*totPocket/numSpins) + '%\\n') 
return (totPocket/numSpins) 
game = FairRoulette() 
for numSpins in (100, 1000000): 
for i in range(3): 
playRoulette(game, numSpins, 2, 1, True) 
6.0002 LECTURE 6 
12
","65.72880554199219","9","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_12_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"267","Why is having a small training error not sufficient for a great model?"," 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
Output of Simulation  
Actual probability = 0.0001286 
Estimated Probability = 0.0 
Actual probability = 0.0001286 
Estimated Probability = 0.0 
How did I know that this is what would get printed?  
Why did simulation give me the wrong answer? 
Let’s try 1,000,000 trials  
6.0002 LECTURE 4 
16
","65.66482543945312","10","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_16_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"268","What does the simulation reveal about the relationship between the number of steps taken in a random walk and the distance traveled by the drunk?"," 
 
 
 
 
 
 
  
 
  
  
 
 
 
 
 
 
 
 
 
 
Visualizing the Trend  
§Simulate walks of multiple lengths for each kind of
drunk 
§Plot distance at end of each length walk for each kind
of drunk 
6.0002  LECTURE 5 
28 
","72.74131774902344","1","DPRSearchEngine","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_28_pdf","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5","6.0002","5"
"268","What does the simulation reveal about the relationship between the number of steps taken in a random walk and the distance traveled by the drunk?","almost the same, except the choices are slightly different. If he chooses to head north, he doesn't go one step. He goes 1.1 steps north. And if he chooses to go south, he only goes 9/10 of a step. So what we're seeing here is what's called a biased random walk. And the bias here is the direction of the walk that he's moving either up or down. Pretty simple. How about just for to test things out, we'll ask the question is this an immutable or a mutable type? Are drunks mutable or immutable? This is a deep philosophical question. But if we ignore the philosophical underpinnings of that question, what about the two types here? Who thinks it's immutable? Who thinks it's mutable? Why do you think it's mutable? What's getting changed? The answer is nothing. It gets created, and then it's returning the step, but it's not actually changing the drunk. So so far we have two things that are immutable, drunks and locations. Let's look at fields. Fields are a little bit more complicated. So field will be a dictionary, and the dictionary is going to map a drunk to his or her location in the field. So we can add a drunk at some location, and we're going to check.","72.11384582519531","2","DPRSearchEngine","6wUD_gp5WeE.en-qlPKC2UN_YU_8_mp4","6wUD_gp5WeE.en-qlPKC2UN_YU","6.0002","5"
"268","What does the simulation reveal about the relationship between the number of steps taken in a random walk and the distance traveled by the drunk?","So Field.moveDrunk will take a self and a drunk. It's going to get the x value, the y value, and if that is in the wormholes, it's going to move the drunk to the location associated with that wormhole. So we move a drunk, and if the drunk ends up being in the wormhole, he gets transported. So we're using Field.moveDrunk. So notice that we're using the moveDrunk of the superclass, even though we're overriding it here. Because we've overridden it here, I have to say Field. to indicate I want the one from the superclass, not the subclass. And then we're doing something peculiar after the move. So interestingly here, I've taken, I think, a usual drunk and plotted the usual drunk on a walk of 500 steps. One walk, and shown all the places the drunk visited. So we've seen three kinds of plots, one showing how far the drunk would get at different length walks, one showing all the places the drunk would end up with many walks of the same length, and here a single walk, all the places the drunk visits. And as you can see, the wormholes produce a profound effect, in this case, on where the drunks end up. And again, you have the code. You can run this yourself and simulate it and see what you go. And I think I've set random.Seed to zero in each of the simulations in the code, but you should play with it, change it, to just see that you'll actually get different results with different seeds. Let me summarize here, and say the point of going through these random walks is not the simulations themselves, but how we built them. That we started by defining the classes. We then built functions corresponding to one trial, multiple trials, and reported the results. And then made a set of incremental changes to the simulation so that we could investigate different questions. So we started with a simple simulation with just the usual drunk and the simple field, and we noticed it didn't work. How did we know it? Well, not because when we did the full simulation we had great insight. I probably could have fooled 1/2 of you and convinced you that that was a reasonable answer. But as soon as we went and did the sanity check, where we knew the answer, we could know something was wrong. And then we went and we fixed it. And then we went and we elaborated it at a step of a time. I first got a more sophistic-- I shouldn't say sophisticated. A different kind of drunk. And then we went to a different kind of field. Finally, we spent time showing how to use plots to get an insight. And in the remaining few minutes of the class, I want to go back and show you some of the plotting commands. To show you how these plots were produced. So one of the things I did, since I knew I was going to be producing a lot of different plots, I decided I would actually not spend time worrying about what kind of markers-- those are the things like the triangles and the plus sign-- or what colors for each one individually, but instead I'd set up a styleIterator that would just return a bunch of different styles. So once and for all, I could define n styles, and then when I want to plot a new kind of drunk, I would just call the styleIterator to get the next style. So this is a fairly common kind of paradigm to say that I just want to do this once and for all. I don't want to have to go through each time I do this. So what do the styles look like? Let me just get this window. Oh. So here it is. I said there were going to be three styles that I'm going to iterate through. Style one is going to be an m, I guess that's maroon with a line, a blue with a dashed line, and green with a line with a comma and a minus sign. So these are called the styles. And you can control the marker, if you have a marker. You can control the line. You can control the color. Also you can control the size. You can give the sizes of all these things. What you'll see when you look at the code is I don't like the default styles things, because when they show up on the screen, they're too small. So there's something called rcParams. Those of you who are Unix hackers can maybe guess where that name came from. And I've just said a bunch of things, like that my default line width will be four points. The size for the titles will be 20. You can put titles on the graphs. Various kinds of things. Again, once and for all trying to set some of these parameters so they get used over and over again. And then finally down here, you'll see that I did things like you want to put titles on the slides. So on the graph. So here's the location at end of walk. Title is just a string. You want to label your x and y-axis, so I've labeled them here. And here I've said where I want the legend to appear in the lower center. I've also set the y-limits and the x-limits on the axis, because I wanted a little extra room. Otherwise, by default it will put points right on the axes, which I find hard to read. Anyway, the point here is not that you understand all of this instantaneously. The point I want to communicate is that it's very flexible. And so if you decide you don't like the way a plot looks and you want to change it, and you know what you want it to look like, there's almost surely a way to make it do that. So don't despair. You can look at the references I gave earlier and figure that out. Next lecture we're going to move on. No more random walks. We'll look at simulating other things, and in particular, we'll look at the question of how believable is a simulation? See you Wednesday if the world has not come to an end.","70.63862609863281","3","DPRSearchEngine","6wUD_gp5WeE.en-qlPKC2UN_YU_18_mp4","6wUD_gp5WeE.en-qlPKC2UN_YU","6.0002","5"
"268","What does the simulation reveal about the relationship between the number of steps taken in a random walk and the distance traveled by the drunk?","assume that the drunk is there after one step. Took one step to the east. Well, after two steps, those are all the possible places he could be. So on average, how far is the drunk from the origin? Well, if we look, he could either be two steps away, if he took another step east, zero steps away, if he took a step west, or what do we see for the top two? Well, the top and the bottom one, we can go back and use the Pythagorean theorem. c squared equals a squared plus b squared. And that will tell us that it'll be the square root of a squared plus b squared. And that will tell us how far away the upper two are, and then we can just average them and get a distance. And as we can see, on average, the drunk will be a little bit further away after two steps than after one step. Well how about after 100,000 steps? It would be a little bit tedious to go through the case analysis I just did. There are a lot of cases after 100,000 steps. So we end up resorting to a simulation. So we'll structure it exactly the same way we've been structuring our other simulations. We're going to simulate one walk of k steps, n such walks, and then report the average distance from the origin of the n walks. Before we do that, in line with the software engineering theme of the course, we'll start by defining some useful abstractions. There are three of them I want to look at. Location, the field that the drunk is in, and the drunk him or herself.","70.1023941040039","4","DPRSearchEngine","6wUD_gp5WeE.en-qlPKC2UN_YU_4_mp4","6wUD_gp5WeE.en-qlPKC2UN_YU","6.0002","5"
"268","What does the simulation reveal about the relationship between the number of steps taken in a random walk and the distance traveled by the drunk?","If the drunk is there, I'm going to get the distance on x and the distance in y by calling drunk.takeStep. So we saw takeStep for a drunk didn't move the drunk anywhere, because the drunks were immutable, but returned new locations. A new x and new values. And then I'm going to use that to move the drunk in the field. So I'll set self.drunk, so drunk to move x distance and y distance. So it's very simple, but having built this set of classes, we can now actually write the simulation. Oh. What about our classes? Are they mutable or immutable? Not classes. What about fields? Any votes for mutable? Yeah, exactly. Because you can see I'm mutating it right here. I'm changing the value of the dictionary. And in fact, every time I add a drunk to the field, I'm changing the value of the dictionary, which is to say mutating the field. So I'll have a bunch of locations, which are immutable objects. Makes sense that a location is immutable. A bunch of drunks, and the thing I'm going to change is where the drunks are in the field. I said we'd start by simulating a single walk.","69.87641143798828","5","DPRSearchEngine","6wUD_gp5WeE.en-qlPKC2UN_YU_10_mp4","6wUD_gp5WeE.en-qlPKC2UN_YU","6.0002","5"
"268","What does the simulation reveal about the relationship between the number of steps taken in a random walk and the distance traveled by the drunk?","will take some number of steps in the field. And you can see this. It's very simple. I just have a loop. Drunk takes some number of random steps, and I'm going to return the distance from the start to the final location of the drunk. So how far is the drunk from the origin? I then need to simulate multiple walks. Notice here that I've got the number of steps, the number of trials, and dClass stands for class of the drunk. And that's because I want to use the same function to simulate as many different kinds of drunks as I care about. We've only seen two here, the masochistic drunk and the usual drunk, but you can imagine many other kinds as well. So let's do it. So here I'm going to simulate a walk for one drunk, Homer.","69.3659896850586","6","DPRSearchEngine","6wUD_gp5WeE.en-qlPKC2UN_YU_11_mp4","6wUD_gp5WeE.en-qlPKC2UN_YU","6.0002","5"
"268","What does the simulation reveal about the relationship between the number of steps taken in a random walk and the distance traveled by the drunk?"," 
 
 
 
And the Masochistic Drunk?  
random.seed(0)  
simAll((UsualDrunk, MasochistDrunk),  
(1000, 10000), 100)  
UsualDrunk random walk of 1000 steps  
Mean = 26.828  
Max = 66.3 Min = 4.2  
UsualDrunk random walk of 10000 steps  
Mean = 90.073  
Max = 210.6 Min = 7.2  
MasochistDrunk random walk of 1000 steps  
Mean = 58.425  
Max = 133.3 Min = 6.7  
MasochistDrunk random walk of 10000 steps  
Mean = 515.575  
Max = 694.6 Min = 377.7  
6.0002  LECTURE 5 
27 
","69.21849822998047","7","DPRSearchEngine","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_27_pdf","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5","6.0002","5"
"268","What does the simulation reveal about the relationship between the number of steps taken in a random walk and the distance traveled by the drunk?","  
 
 
Simulating a Single Walk  
def walk(f, d, numSteps):  
""""""Assumes: f a Field, d a Drunk in f, and  
numSteps an int >= 0.  
Moves d numSteps times; returns the distance  
between the final location and the location  
at the start of the walk.""""""  
start = f.getLoc(d)  
for s in range(numSteps):  
f.moveDrunk(d)  
return start.distFrom(f.getLoc(d))  
6.0002  LECTURE 5 
20 
","68.90619659423828","8","DPRSearchEngine","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_20_pdf","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5","6.0002","5"
"268","What does the simulation reveal about the relationship between the number of steps taken in a random walk and the distance traveled by the drunk?"," 
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
Simulations Are Used a Lot
To model systems that are mathematically intractable
To extract useful intermediate results
Lend themselves to development by successive
refinement and “what if” questions
Start by simulating random walks
6.0002 LECTURE 4 
25
","68.86763000488281","9","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_25_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"268","What does the simulation reveal about the relationship between the number of steps taken in a random walk and the distance traveled by the drunk?","So you can see, sure enough, the usual drunk, this fuschia line is progressing very slowly and the masochistic drunk, considerably faster. I looked at these, and after looking at those two, I tried to figure out whether there was some mathematical explanation of what was going on, and decided, well, it looked to me like the usual drunk was moving at about the square root of the number of steps. Not so odd to think about it, if you go back to old Pythagoras here. And sure enough, when I plot, and I ran this simulation up to 100,000 steps. When I plot the square root of the number of steps, it's not identical, but it's pretty darn close. Seems to be moving just a tad faster than the square root, but not much. But who knows exactly? But pretty good. And then the masochistic drunk seems to be moving at a rate of numSteps times 0.05. A less intuitive answer than the square root. Why do you think it might be doing that? Well, what we notice is that-- and we'll look at this-- maybe there's not much difference between what the masochistic drunk and the usual drunk do on the x-axis, east and west. In fact, they shouldn't be. But there should be a difference on the y-axis, because every time, 1/4 of the time, the drunk is taking a step north of 1.1 units, and 1/4 of the time, he's taking a step south of 0.9 units. And so 1/2 the time, the steps are diverging by a small fraction. And if we think about it, 0.1 1/2 the time. We divide it. We get 0.05. So at least we need to do some more analysis, but the data is pretty compelling here that it's a very good fit. Well, let's look at the ending location.","68.71895599365234","10","DPRSearchEngine","6wUD_gp5WeE.en-qlPKC2UN_YU_15_mp4","6wUD_gp5WeE.en-qlPKC2UN_YU","6.0002","5"
"269","What are the three main steps of a brute force algorithm for solving a problem by enumerating item combinations and selecting the optimal one?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","72.1624526977539","1","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"269","What are the three main steps of a brute force algorithm for solving a problem by enumerating item combinations and selecting the optimal one?","§ 1. Enumerate all possible combina<ons of items. 
§ 2. Remove all of the combina<ons whose total units 
exceeds the allowed weight. 
§ 3. From the remaining combina<ons choose any one 
whose value is the largest. 
Brute Force Algorithm 
6.0002 LECTURE 2 
4 
","70.72625732421875","2","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_4_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"269","What are the three main steps of a brute force algorithm for solving a problem by enumerating item combinations and selecting the optimal one?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","70.28402709960938","3","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"269","What are the three main steps of a brute force algorithm for solving a problem by enumerating item combinations and selecting the optimal one?","namely, random accessing. And if we stored the things that we're looking for, we have unique keys, and those keys are integers. Then, if I have an item with key K, if I store it at index K in my array, then I can find it and manipulate it in constant time.","69.8506088256836","4","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_2_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"269","What are the three main steps of a brute force algorithm for solving a problem by enumerating item combinations and selecting the optimal one?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","69.69869995117188","5","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"269","What are the three main steps of a brute force algorithm for solving a problem by enumerating item combinations and selecting the optimal one?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 4: Hashing 
Lecture 4: Hashing 
Review 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
• Idea! Want faster search and dynamic operations. Can we find(k) faster than Θ(log n)? 
• Answer is no (lower bound)! (But actually, yes...!?) 
Comparison Model 
• In this model, assume algorithm can only differentiate items via comparisons 
• Comparable items: black boxes only supporting comparisons between pairs 
• Comparisons are <, ≤, >, ≥, =, =6 , outputs are binary: True or False 
• Goal: Store a set of n comparable items, support find(k) operation 
• Running time is lower bounded by # comparisons performed, so count comparisons! 
Decision Tree 
• Any algorithm can be viewed as a decision tree of operations performed 
• An internal node represents a binary comparison, branching either True or False 
• For a comparison algorithm, the decision tree is binary (draw example) 
• A leaf represents algorithm termination, resulting in an algorithm output 
• A root-to-leaf path represents an execution of the algorithm on some input 
• Need at least one leaf for each algorithm output, so search requires ≥ n + 1 leaves 
","69.2154541015625","6","DPRSearchEngine","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_1_pdf","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4","6.006","4"
"269","What are the three main steps of a brute force algorithm for solving a problem by enumerating item combinations and selecting the optimal one?","§ Time based on number of nodes generated 
§ Number of levels is number of items to choose from 
§ Number of nodes at level i is 2i 
§ So, if there are n items the number of nodes is 
◦ ∑𝑖=0↑𝑖=𝑛▒​2↑𝑖   
◦ I.e., O(​2↑𝑛+1 ) 
§ An obvious op<miza<on: don’t explore parts of tree 
that violate constraint (e.g., too many calories) 
◦ Doesn’t change complexity 
§ Does this mean that brute force is never useful? 
◦ Let’s give it a try 
Computa#onal Complexity 
6.0002 LECTURE 2 
8 
","69.21296691894531","7","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_8_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"269","What are the three main steps of a brute force algorithm for solving a problem by enumerating item combinations and selecting the optimal one?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
The Reducibility Method 
If we know that some problem (say !TM) is undecidable, 
we can use that to show other problems are undecidable. 
Defn: $!%&TM = (, * ( halts on input *} 
Recall Theorem: $!%&TM is undecidable 
Proof by contradiction, showing that !TM is reducible to $!%&TM: 
Assume that $!%&TM is decidable and show that !TM is decidable (false!). 
Let TM , decide $!%&TM. 
Construct TM - deciding !TM. 
- = “On input (, * 
1.  Use , to test if ( on * halts. If not, reject. 
2. Simulate ( on * until it halts (as guaranteed by ,). 
3.  If ( has accepted then accept. 
If ( has rejected then reject. 
TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 
2 
","68.87447357177734","8","DPRSearchEngine","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_2_pdf","dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9","18.404J","9"
"269","What are the three main steps of a brute force algorithm for solving a problem by enumerating item combinations and selecting the optimal one?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 5: Linear Sorting 
Lecture 5: Linear Sorting 
Review 
• Comparison search lower bound: any decision tree with n nodes has height ≥dlg(n+1)e−1 
• Can do faster using random access indexing: an operation with linear branching factor! 
• Direct access array is fast, but may use a lot of space (Θ(u)) 
• Solve space problem by mapping (hashing) key space u down to m = Θ(n) 
• Hash tables give expected O(1) time operations, amortized if dynamic 
• Expectation input-independent: choose hash function randomly from universal hash family 
• Data structure overview! 
• Last time we achieved faster ﬁnd. Can we also achieve faster sort? 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
Direct Access Array 
u 
1 
1 
u 
u 
Hash Table 
n(e) 
1(e) 
1(a)(e) 
n 
n 
","68.41783142089844","9","DPRSearchEngine","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5_1_pdf","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5","6.006","5"
"269","What are the three main steps of a brute force algorithm for solving a problem by enumerating item combinations and selecting the optimal one?","Header for Decision Tree Implementa#on 
6.0002 LECTURE 2 
9 
def maxVal(toConsider, avail): 
    """"""Assumes toConsider a list of items,  
               avail a weight 
       Returns a tuple of the total value of a  
           solution to 0/1 knapsack problem and  
           the items of that solution""""” 
toConsider. Those items that nodes higher up in the tree 
(corresponding to earlier calls in the recursive call stack) 
have not yet considered 
 
avail. The amount of space still available  
","68.29595184326172","10","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_9_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"270","Why is normalizing the variability of clusters by their size not always ideal in clustering?"," 
 
 
 
 
Clustering  Is  an Optimization Problem  
§Why not divide variability by size of cluster? 
◦ Big and bad worse than small and bad 
§Is optimization problem finding a C that minimizes 
dissimilarity(C)? 
◦ No, otherwise could put each example in its own 
cluster 
§Need a constraint, e.g., 
◦ Minimum distance between clusters 
◦ Number of clusters 
6.0002  LECTURE 12 
4 
","74.65449523925781","1","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_4_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"270","Why is normalizing the variability of clusters by their size not always ideal in clustering?"," 
 
 
 
  
 
 
 
 
 
 
 
Stratified Sampling  
§Stratified sampling
◦Partition population into subgroups
◦Take a simple random sample from each subgroup
6.0002  LECTURE 8 
 
5
","71.76090240478516","2","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_5_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"270","Why is normalizing the variability of clusters by their size not always ideal in clustering?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Clustering Algorithms  
§Hierarchical  clustering  
◦ Can select number  of clusters using dendogram 
◦ Deterministic 
◦ Flexible with respect to linkage criteria 
◦ Slow 
◦ Naïve algorithm n3 
◦ n2 algorithms exist for some linkage criteria 
§K-means a much faster greedy algorithm 
◦ Most useful when you know how many clusters  you want  
6.0002  LECTURE 12 
9 
","70.69900512695312","3","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_9_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"270","Why is normalizing the variability of clusters by their size not always ideal in clustering?","Variability is exactly what we saw in the formula. And then just for fun, so you could see this, I used an iterator here. I don't know that any of you have used the yield statement in Python. I recommend it. It's very convenient. One of the nice things about Python is almost anything that's built in, you can make your own version of it. And so once I've done this, if c is a cluster, I can now write something like for c in big C, and this will make it work just like iterating over a list. Right, so this makes it possible to iterate over it. If you haven't read about yield, you probably should read the probably about two paragraphs in the textbook explaining how it works, but it's very convenient. Dissimilarity we've already seen.","69.85057830810547","4","DPRSearchEngine","esmzYhuFnds.en-qlPKC2UN_YU_10_mp4","esmzYhuFnds.en-qlPKC2UN_YU","6.0002","12"
"270","Why is normalizing the variability of clusters by their size not always ideal in clustering?","   
 
 
 
 
How  Likely Is it Just Bad Luck?  
A variant of cherry picking called  
multiple hypothesis testing 
6.0002  LECTURE 15 
14 
","69.09565734863281","5","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_13_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"270","Why is normalizing the variability of clusters by their size not always ideal in clustering?"," 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Stratified Sampling  
§When there are small subgroups that should be
represented
§When it is important that subgroups be represented
proportionally to their size in  the population
§Can be used to reduced the needed size of sample
◦Variability of subgroups less than of entire
population
§Requires care to do properly
§Well stick to simple random samples
6.0002  LECTURE 8 
 
6
","68.97612762451172","6","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_6_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"270","Why is normalizing the variability of clusters by their size not always ideal in clustering?","The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high-quality educational resources for free. To make a donation, or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. JOHN GUTTAG: I'm a little reluctant to say good afternoon, given the weather, but I'll say it anyway. I guess now we all do know that we live in Boston. And I should say, I hope none of you were affected too much by the fire yesterday in Cambridge, but that seems to have been a pretty disastrous event for some. Anyway, here's the reading. This is a chapter in the book on clustering, a topic that Professor Grimson introduced last week. And I'm going to try and finish up with respect to this course today, though not with respect to everything there is to know about clustering. Quickly just reviewing where we were. We're in the unit of a course on machine learning, and we always follow the same paradigm. We observe some set of examples, which we call the training data. We try and infer something about the process that created those examples. And then we use inference techniques, different kinds of techniques, to make predictions about previously unseen data. We call that the test data. As Professor Grimson said, you can think of two broad classes. Supervised, where we have a set of examples and some label associated with the example-- Democrat, Republican, smart, dumb, whatever you want to associate with them-- and then we try and infer the labels. Or unsupervised, where we're given a set of feature vectors without labels, and then we attempt to group them into natural clusters. That's going to be today's topic, clustering. So clustering is an optimization problem. As we'll see later, supervised machine learning is also an optimization problem. Clustering's a rather simple one. We're going to start first with the notion of variability. So this little c is a single cluster, and we're going to talk about the variability in that cluster of the sum of the distance between the mean of the cluster and each example in the cluster. And then we square it. OK? Pretty straightforward. For the moment, we can just assume that we're using Euclidean distance as our distance metric. Minkowski with p equals two. So variability should look pretty similar to something we've seen before, right? It's not quite variance, right, but it's very close. In a minute, we'll look at why it's different. And then we can look at the dissimilarity of a set of clusters, a group of clusters, which I'm writing as capital C, and that's just the sum of all the variabilities. Now, if I had divided variability by the size of the cluster, what would I have? Something we've seen before. What would that be? Somebody? Isn't that just the variance? So the question is, why am I not doing that? If up til now, we always wanted to talk about variance, why suddenly am I not doing it? Why do I define this notion of variability instead of good old variance? Any thoughts? What am I accomplishing by not dividing by the size of the cluster? Or what would happen if I did divide by the size of the cluster? Yes. AUDIENCE: You normalize it? JOHN GUTTAG: Absolutely. I'd normalize it. That's exactly what it would be doing. And what might be good or bad about normalizing it? What does it essentially mean to normalize? It means that the penalty for a big cluster with a lot of variance in it is no higher than the penalty of a tiny little cluster with a lot of variance in it. By not normalizing, what I'm saying is I want to penalize big, highly-diverse clusters more than small, highly-diverse clusters. OK? And if you think about it, that probably makes sense. Big and bad is worse than small and bad. All right, so now we define the objective function. And can we say that the optimization problem we want to solve by clustering is simply finding a capital C that minimizes dissimilarity? Is that a reasonable definition? Well, hint-- no. What foolish thing could we do that would optimize that objective function? Yeah. AUDIENCE: You could have the same number of clusters as points? JOHN GUTTAG: Yeah. I can have the same number of clusters as points, assign each point to its own cluster, whoops. Ooh, almost a relay. The dissimilarity of each cluster would be 0. The variability would be 0, so the dissimilarity would be 0, and I just solved the problem. Well, that's clearly not a very useful thing to do. So, well, what do you think we do to get around that? Yeah. AUDIENCE: We apply a constraint? JOHN GUTTAG: We apply a constraint. Exactly. And so we have to pick some constraint. What would be a suitable constraint, for example? Well, maybe we'd say, OK, the clusters have to have some minimum distance between them. Or-- and this is the constraint we'll be using today-- we could constrain the number of clusters. Say, all right, I only want to have at most five clusters. Do the best you can to minimize dissimilarity, but you're not allowed to use more than five clusters. That's the most common constraint that gets placed in the problem. All right, we're going to look at two algorithms. Maybe I should say two methods, because there are multiple implementations of these methods. The first is called hierarchical clustering, and the second is called k-means. There should be an S on the word mean there. Sorry about that. All right, let's look at hierarchical clustering first.","68.36337280273438","7","DPRSearchEngine","esmzYhuFnds.en-qlPKC2UN_YU_1_mp4","esmzYhuFnds.en-qlPKC2UN_YU","6.0002","12"
"270","Why is normalizing the variability of clusters by their size not always ideal in clustering?"," 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
An Example  
§Many patients with 4 features each  
◦ Heart rate in beats per  minute 
◦ Number  of past heart attacks 
◦ Age 
◦ ST elevation (binary) 
§Outcome (death) based on features 
◦ Probabilistic,  not deterministic 
◦ E.g.,  older  people with multiple heart attacks at higher  
risk 
§Cluster, and examine purity of clusters relative to 
outcomes 
6.0002  LECTURE 12 
23 
","68.25186920166016","8","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_23_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"270","Why is normalizing the variability of clusters by their size not always ideal in clustering?"," 
 
 
Two Popular Methods  
§Hierarchical clustering  
§K-means clustering 
6.0002  LECTURE 12 
5 
","67.73612976074219","9","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_5_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"270","Why is normalizing the variability of clusters by their size not always ideal in clustering?"," 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Looking at F eature Weights  
model.classes_  =  ['Died' 'Survived'] 
For  label Survived 
Be wary of reading too 
C1 = 1.66761946545 
much into the weights 
C2 = 0.460354552452 
Features are often 
C3 = -0.50338282535 
correlated 
age = -0.0314481062387 
male gender  = -2.39514860929 
L1 regression tends to drive one variable to zero 
L2 (default) regression spreads weights across variables 
6.0002  LECTURE 14 
4 
","67.3390121459961","10","DPRSearchEngine","b9d60f4ecb325e4648f9cf0379419338_MIT6_0002F16_lec14_4_pdf","b9d60f4ecb325e4648f9cf0379419338_MIT6_0002F16_lec14","6.0002","14"
"272","How does the search tree method ensure the selection of the optimal set of items for the knapsack problem?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","74.40811157226562","1","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"272","How does the search tree method ensure the selection of the optimal set of items for the knapsack problem?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","72.26664733886719","2","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"272","How does the search tree method ensure the selection of the optimal set of items for the knapsack problem?","Header for Decision Tree Implementa#on 
6.0002 LECTURE 2 
9 
def maxVal(toConsider, avail): 
    """"""Assumes toConsider a list of items,  
               avail a weight 
       Returns a tuple of the total value of a  
           solution to 0/1 knapsack problem and  
           the items of that solution""""” 
toConsider. Those items that nodes higher up in the tree 
(corresponding to earlier calls in the recursive call stack) 
have not yet considered 
 
avail. The amount of space still available  
","71.92046356201172","3","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_9_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"272","How does the search tree method ensure the selection of the optimal set of items for the knapsack problem?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 4: Hashing 
Lecture 4: Hashing 
Review 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
• Idea! Want faster search and dynamic operations. Can we find(k) faster than Θ(log n)? 
• Answer is no (lower bound)! (But actually, yes...!?) 
Comparison Model 
• In this model, assume algorithm can only differentiate items via comparisons 
• Comparable items: black boxes only supporting comparisons between pairs 
• Comparisons are <, ≤, >, ≥, =, =6 , outputs are binary: True or False 
• Goal: Store a set of n comparable items, support find(k) operation 
• Running time is lower bounded by # comparisons performed, so count comparisons! 
Decision Tree 
• Any algorithm can be viewed as a decision tree of operations performed 
• An internal node represents a binary comparison, branching either True or False 
• For a comparison algorithm, the decision tree is binary (draw example) 
• A leaf represents algorithm termination, resulting in an algorithm output 
• A root-to-leaf path represents an execution of the algorithm on some input 
• Need at least one leaf for each algorithm output, so search requires ≥ n + 1 leaves 
","71.45427703857422","4","DPRSearchEngine","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_1_pdf","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4","6.006","4"
"272","How does the search tree method ensure the selection of the optimal set of items for the knapsack problem?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 5: Linear Sorting 
Lecture 5: Linear Sorting 
Review 
• Comparison search lower bound: any decision tree with n nodes has height ≥dlg(n+1)e−1 
• Can do faster using random access indexing: an operation with linear branching factor! 
• Direct access array is fast, but may use a lot of space (Θ(u)) 
• Solve space problem by mapping (hashing) key space u down to m = Θ(n) 
• Hash tables give expected O(1) time operations, amortized if dynamic 
• Expectation input-independent: choose hash function randomly from universal hash family 
• Data structure overview! 
• Last time we achieved faster ﬁnd. Can we also achieve faster sort? 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
Direct Access Array 
u 
1 
1 
u 
u 
Hash Table 
n(e) 
1(e) 
1(a)(e) 
n 
n 
","70.59005737304688","5","DPRSearchEngine","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5_1_pdf","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5","6.006","5"
"272","How does the search tree method ensure the selection of the optimal set of items for the knapsack problem?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","70.40684509277344","6","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"272","How does the search tree method ensure the selection of the optimal set of items for the knapsack problem?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Clustering Algorithms  
§Hierarchical  clustering  
◦ Can select number  of clusters using dendogram 
◦ Deterministic 
◦ Flexible with respect to linkage criteria 
◦ Slow 
◦ Naïve algorithm n3 
◦ n2 algorithms exist for some linkage criteria 
§K-means a much faster greedy algorithm 
◦ Most useful when you know how many clusters  you want  
6.0002  LECTURE 12 
9 
","69.99129486083984","7","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_9_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"272","How does the search tree method ensure the selection of the optimal set of items for the knapsack problem?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 10: Depth-First Search 
Lecture 10: Depth-First Search 
Previously 
• Graph deﬁnitions (directed/undirected, simple, neighbors, degree) 
• Graph representations (Set mapping vertices to adjacency lists) 
• Paths and simple paths, path length, distance, shortest path 
• Graph Path Problems 
– Single Pair Reachability(G,s,t) 
– Single Source Reachability(G,s) 
– Single Pair Shortest Path(G,s,t) 
– Single Source Shortest Paths(G,s) (SSSP) 
• Breadth-First Search (BFS) 
– algorithm that solves Single Source Shortest Paths 
– with appropriate data structures, runs in O(|V | + |E|) time (linear in input size) 
Examples 
G1 
a 
d 
b 
e 
c 
f 
G2 
a 
d 
b 
e 
c 
f 
","69.45850372314453","8","DPRSearchEngine","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10_1_pdf","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10","6.006","10"
"272","How does the search tree method ensure the selection of the optimal set of items for the knapsack problem?","namely, random accessing. And if we stored the things that we're looking for, we have unique keys, and those keys are integers. Then, if I have an item with key K, if I store it at index K in my array, then I can find it and manipulate it in constant time.","69.41585540771484","9","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_2_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"272","How does the search tree method ensure the selection of the optimal set of items for the knapsack problem?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","69.25809478759766","10","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"274","What are the main components of an optimization model, and how do they interact with each other in the context of the knapsack problem?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","79.68229675292969","1","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"274","What are the main components of an optimization model, and how do they interact with each other in the context of the knapsack problem?","The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. PROFESSOR: Welcome back. Over the last couple of lectures, we've been looking at optimization models. And the idea was how do I find a way to optimize an objective function-- it could be minimize it or maximize it-- relative to a set of constraints? And we saw, or Professor Guttag showed you, one of the ways that naturally falls out is by looking at trees, decision trees, where you pass your way through a tree trying to figure out how to optimize that model. So today, we're going to generalize those trees into another whole broad class of models called graph theoretic or graph models. And we're going to use those to again look at how do we can do optimization on those kinds of models. Just to remind you, there is a great piece of information in the text. There's the reading for today. And these will, of course, be in the slides that you can download. So let's take a second just to reset again what are we trying to do? Generally, we're trying to build computational models. So what does that mean? The same way we could do a physical experiment, or a social experiment, or model, if you like, a physical system and a social system, to both try and gather data and analyze it or to do predictions. We want to do the same thing computationally. We'd like to be able to build models in code that we can then run to predict effects, which we then might test with an actual physical experiment. And we've seen, for example, how you could take just the informal problem of choosing what to eat and turning it into an optimization problem-- in this case, it was a version of something we called a knapsack problem-- and how you could then use that to find code to solve it. And you've already seen two different general methods. You've seen greedy algorithms that just try and do the best thing at each stage. And you saw dynamic programming as an elegant solution to finding better ways to optimize this. We're going to now look at broadening the class of models to talk about graphs. So, obvious question is, what's a graph? And a graph has two elements, two components. It has a set of nodes, sometimes called vertices. Those nodes probably are going to have some information associated with them. It could be as simple as it's a name. It could be more complicated. A node might represent a student record-- the grades. And a graph might talk about putting together all of the grades for a class. Associated with that, we can't just-- well, I should say, we could just have nodes, but that's kind of boring. We want to know what are the connections between the elements in my system? And so the second thing we're going to have is what we call edges, sometimes called arcs. And an edge will connect a pair of nodes. We're going to see two different ways in which we could build graphs using edges. The first one, the simple one, is an edge is going to be undirected. And actually, I should show this to you. So there is the idea of just nodes. Those nodes, as I said, might have information in them, just labels or names. They might have other information in them. When I want to connect them up, the connections could be undirected. If you want to think of it this way, it goes both ways. An edge connects two nodes together, and that allows sharing of information between both of them. In some cases, we're going to see that we actually want to use what we call a directed graph, sometimes called a digraph, in which case the edge has a direction from a source to a destination, or sometimes from a parent to a child. And in this case, the information can only flow from the source to the child. Now in the case I've drawn here, it looks like there's only ever a single directed edge between nodes. I could, in fact, have them going both directions, from source to destination and a separate directed edge coming from the destination back to the source. And we'll see some examples of that. But I'm going to have edges. Final thing is, those edges could just be connections. But in some cases, we're going to put information on the edges, for example, weights. The weight might tell me how much effort is it going to take me to go from a source to a destination. And one of the things you're going to see as I want to think about how do I pass through this graph, finding a path from one place to another, for example, minimizing the cost associated with passing through the edges? Or how do I simply find a connection between two nodes in this graph? So graphs, composed of vertices or nodes, they're composed of edges or arcs. So why might we want them? Well, we're going to see-- and you can probably already guess-- there are lots of really useful relationships between entities. I might want to take a European vacation. After November 8, I might really want to take a European vacation. So I'd like to know, what are the possible ways by rail I can get from Paris to London? Well, I could pull out the schedule and look at it. But you could imagine, I hope, thinking about this as a graph. The nodes would be cities. The links would be rail links between them. And then, one of the things I might like to know is, first of all, can I get from Paris to London? And then secondly, what's the fastest way to do it or the cheapest way to do it? So I'd like to explore that. Second example, as you can see on the list, drug discovery, modeling of complex molecule in terms of the relationships between the pieces inside of it and then asking questions like, what kind of energy would it take to convert this molecule into a different molecule? And how might I think about that as a graph problem? Third and obvious one, ancestral relationships, family trees. In most families, almost all families, they really are trees not graphs. Hopefully you don't come from a family that has strange loops in them. But family trees are-- I know, I'm in trouble here today. Aren't I? Family trees-- stay with me-- are a great demonstration of relationships because there its directional edges. Right? Parents have children. Those children have children. And like I say, it comes in a natural way of thinking about traversing things in that tree. And in fact, trees are a special case of a graph. You've already seen decision trees in the last lecture. But basically, a special kind of directed graph is a tree. And the property of the tree is, as it says there, any pair of nodes are connected, if they are connected, by only a single path. There are no loops. There are no ways to go from one node, find a set of things that brings you back to that node. You can only have a single path to those points. And Professor Guttag used this, for example, to talk about solving the knapsack problem. A decision trees is a really nice way of finding that solution. Now, I drew it this way. In computer science, we mostly use Australian trees. They're upside down. The roots are at the top. The leaves are at the bottom, because we want to think about starting at the beginning of the tree, which is typically something we call the root and traversing it. But however you use it, trees are going to be a useful way of actually thinking about representing particular kinds of graphs. OK. So, when I talk in a second about how to build graphs, well let's spend just a second about saying, so why are they useful? And if you think about it, the world is full of lots of networks that are based on relationships that could be captured by a graph. We use them all the time. Some of you are using them right now-- computer networks. You want to send an email message from your machine to your friend at Stanford. That's going to get routed through a set of links to get there. So the network set up by a series of routers that pass it along, sending something requires an algorithm that figures out the best way to actually move that around. There's a great local company started by an MIT professor called Akamai that thinks about how do you move web content around on the web? Again, it's a nice computer network problem. I've already talked about this. We're going to do some other examples. Transportation networks-- here, if you think about it, obvious thing is make the nodes cities. Make the edges roads between them. And now questions are, can I get to San Jose, if you like old songs? And what's the best way to get to San Jose, even if you don't like old songs? A network problem-- how do I analyze it? Financial networks-- moving money around-- easily modeled by a graph. Traditional networks-- sewer, water, electrical, anything that distributes content, if you like, and the different kind of content in this way around. You want to model that in terms of how you think about flows in those networks. How do I maximize distribution of water in an appropriate way, given I've got certain capacities on different pipes, which would mean those edges in the graph would have different weights? And you get the idea-- political networks, criminal networks, social networks. One of the things we're going to see with graphs is that they can capture interesting relationships. So here's an example. It's from that little web site you can see there. You're welcome to go look at it. And this is a graph analyzing The Wizard of Oz. And what's been done here is the size of the node reflects the number of scenes in which a character shares dialog. So you can see, obviously Dorothy is the biggest node there. The edges represent shared dialog, so you can see who talks to whom in this graph. And then, this group has done another thing, which I'm going to mention. We're not going to solve today, which is you can also do analysis on the graphs. And in fact, the color here has done something called a min-flow or max-cut problem, which is it's tried to identify which clusters in the graph tend to have a lot of interactions within that cluster but not very many with other clusters. And you can kind of see. There's some nice things here, right, if you can read it. This is all the people in Kansas. This is Glenda and the Munchkins in that part of Oz. There's another little cluster over here that I can't read and a little cluster over there. And then the big cluster down here. But you can analyze the graph to pull out pieces on it. You can also notice, by the way, the book is probably misnamed. It's called The Wizard of Oz. But notice, there's the wizard, who actually doesn't have a lot of interaction with the other people in this story. It's OK, literary choice. But the graph is representing interactions. And I could imagine searching that graph to try and figure out things about what goes on in The Wizard of Oz. OK. So why are they useful? We're going to see that not only do graphs capture relationships in these connected networks, but they're going to support inference. They're going to be able to reason about them. And I want to set that up. And then we'll actually look at how might we build a graph. And so here are some ways in which I might want to do inference. Given a graph, I might say, is there a sequence of edges, of links, between two elements? Is there a way to get from A to B? What are the sequence of edges I would use to get there? A more interesting question is, can I find the least expensive path, also known as the shortest path? If I want to get from Paris to London, I might like to do it in the least amount of time. What are the set of choices I want to make to get there? A third graph problem used a lot is called the graph partition problem. Everything I've shown so far-- actually not quite. The first example didn't have it. You might think of all the nodes having some connection to every other node. But that may not be true. There may actually be graphs where I've got a set of connected elements and another component with no connections between them. Can I find those? That's called the graph partition problem. How do I separate the graph out into connected sets of elements? And then the one that we just showed called the min-cut max-flow problem, is is there an efficient way to separate out the highly connected elements, the things that interact a lot, and separate out how many of those kinds of subgraphs, if you like, are there inside of my graph? All right, let me show you a motivation for graphs. And then we'll build them. I use graph theory everyday. I'm a math nut. It's OK, but I use graph theory everyday. You may as well, if you commute. Because I use it to figure out how to get from my home in Lexington down here to Cambridge. And I use a nice little system called Waze It's a great way of doing this, which does graph theory inside of it. So how do I get to my office? Well, I'm going to model the road system using a directed graph, a digraph. Directed graph because streets can be one way. And so I may only have a single direction there. And the idea is, I'm going to simply let my nodes or my vertices be points where I have intersections. They're places where I can make a choice or places where I have terminals, things I'm going to end up in. The edges would just be the connections between points, the roads on which I can drive. Some Boston drivers have a different kind of digraph in which they don't care whether that road is drivable or not. They just go on it. You may have seen some of these. But I want to keep my graphs as real roads that I can drive on. And I'm not going to go against the ""One Way"" sign. Each edge will have a weight. Here I actually have some choices. All right, the obvious one, the one that Waze probably uses, is something like what's the expected time between a source and a destination node? How long do I expect it to take me to get from this point to that? And then, as you can see, I'm going to try and find overall what's the best way to get around it. You could pick just distance. What's the distance between the two? And while there there's a relationship here, it's not direct because it will depend on traffic on it. Or you could take something even funkier like what's the average speed of travel between the source and destination node? And once I've got the graph, then I'm going to solve an optimization problem. What's the shortest weight between my house and my office that gets me into work? You can make a choice here. As I said, a commercial system like Waze uses this one. My wife and I actually have arguments about commuting because she's a firm believer in the second one, just shortest distance. I actually like the third one because I get anxious when I'm driving. And so as long as I feel like I'm making progress, I like it. So even though I may be serpentining all the way through the back roads of Cambridge, if I'm driving fast, I feel like I'm getting there. So I like optimizing this bottom one down there. And if you see me on the road, you'll know why I say that, and then get out of the way. Thinking about navigation through systems actually gives us a little bit of history because, in fact, the very first reported use of graph theory was exactly this problem. Early 1700s, it's called the Bridges of Koenigsberg. Koenigsberg is a city that has a set of islands and rivers in it. There are seven bridges that connect up those islands. And the question that was posed is, is it possible to take a walk that traverses each of the seven bridges exactly once? So could you take a walk where you go over each bridge exactly once? I'm showing you this because it lets us think about how to in fact capture things in a model. This problem was solved by a great Swiss mathematician, Leonhard Euler. And here's what he said. Make each island a node. Each bridge is just an undirected edge. And notice in doing that, he's abstracted away irrelevant details. You don't care what the size of the island is. You don't care how long the bridges are. You simply want to think about what are the connections here? And then you can ask a question. In this graph, is it possible to find a way to walk through it so that you go through each edge exactly once? And as Euler showed, the answer is no. And if you're curious, go look it up on Wikipedia. There's a nice, elegant solution to why that's the case. But here's what we're going to do. We're going to use those graphs to think about these kinds of problems. And in fact, the example I'm going to show you are going to be shortest path problems. So with that, let's turn to actually building a graph and then thinking about how we're going to use it. So we're going to start by constructing graphs. And then what we're going to do is show how we can build search algorithms on top of those graphs. And I hope that that flicker is going to go away here soon. Here we go. So to build a graph-- actually, I shouldn't have put this slide up so fast. I've got lots of choices here. If I'm thinking about maps, one way to build a graph would really to just be build something with latitude and longitude on it. But as we've already seen, we'd like to extract things away from the graphs. And so a natural choice is to say, let's represent the nodes in the graph just as objects. I'm going to use classes for these. So here's my definition of a node. It's pretty straightforward. I'm going to assume that the only information for now I store in a node is just a name, which I'm going to assume is a string. So I've got a class definition for node. It inherits from the base Python object class. I need ways to create instances of nodes, so I've got an init function. And I'm simply going to store inside each instance, in other words, inside of self, under the variable name, whatever I passed in as the name of that node. Of course, if I've got ways to create things with a name, I need to get them back out. So I've got a way of selecting it back out. If I ask an instance of a node, what's your name? By calling getName it will return that value. And to print things out, I'm just going to print out the name. This is pretty straightforward. And this, of course, lets me now create as many nodes as I would like. Edges? Well, an edge connects up two nodes. So again, I can do a fairly straightforward construction of a class. Again, it's going to inherit from the base Python object. To create an instance of an edge, I'm going to make an assumption, an important one which we're going to come back to. And the assumption is that the arguments passed in, source and destination, are nodes-- not names-- the nodes themselves, the actual instances of the object class. And what will I do? Inside of the edge, I'm going to set internal variables. For each instance of the edge, source and destination are going to point to those nodes, to those objects that I created out of the node class. Next two things are straightforward. I can get those things back out.","75.57923889160156","2","DPRSearchEngine","V_TulH374hw.en-qlPKC2UN_YU_1_mp4","V_TulH374hw.en-qlPKC2UN_YU","6.0002","3"
"274","What are the main components of an optimization model, and how do they interact with each other in the context of the knapsack problem?","So let's talk first about optimization models. An optimization model is a very simple thing. We start with an objective function that's either to be maximized or minimized. So for, example, if I'm going from New York to Boston, I might want to find a route by car or plane or train that minimizes the total travel time. So my objective function would be the number of minutes spent in transit getting from a to b. We then often have to layer on top of that objective function a set of constraints, sometimes empty, that we have to obey. So maybe the fastest way to get from New York to Boston is to take a plane, but I only have $100 to spend. So that option is off the table. So I have the constraints there on the amount of money I can spend. Or maybe I have to be in Boston before 5:00 PM and while the bus would get me there for $15, it won't get me there before 5:00. And so maybe what I'm left with is driving, something like that. So objective function, something you're either minimizing or maximizing, and a set of constraints that eliminate some solutions. And as we'll see, there's an asymmetry here. We handle these two things differently. We use these things all the time. I commute to work using Waze, which essentially is solving-- not very well, I believe-- an optimization problem to minimize my time from home to here. When you travel, maybe you log into various advisory programs that try and optimize things for you. They're all over the place. Today you really can't avoid using optimization algorithm as you get through life. Pretty abstract. Let's talk about a specific optimization problem called the knapsack problem. The first time I talked about the knapsack problem I neglected to show a picture of a knapsack, and I was 10 minutes into it before I realized most of the class had no idea what a knapsack was. It's what we old people used to call a backpack, and they used to look more like that than they look today. So the knapsack problem involves-- usually it's told in terms of a burglar who breaks into a house and wants to steal a bunch of stuff but has a knapsack that will only hold a finite amount of stuff that he or she wishes to steal. And so the burglar has to solve the optimization problem of stealing the stuff with the most value while obeying the constraint that it all has to fit in the knapsack. So we have an objective function. I'll get the most for this when I fence it. And a constraint, it has to fit in my backpack. And you can guess which of these might be the most valuable items here. So here is in words, written words what I just said orally. There's more stuff than you can carry, and you have to choose which stuff to take and which to leave behind. I should point out that there are two variants of it. There's the 0/1 knapsack problem and the continuous. The 0/1 would be illustrated by something like this. So the 0/1 knapsack problem means you either take the object or you don't. I take that whole gold bar or I take none of it. The continuous or so-called fractional knapsack problem says I can take pieces of it. So maybe if I take in my gold bar and shaved it into gold dust, I then can say, well, the whole thing won't fit in, but I can fit in a path, part of it. The continuous knapsack problem is really boring. It's easy to solve. How do you think you would solve the continuous problem? Suppose you had over here a pile of gold and a pile of silver and a pile of raisins, and you wanted to maximize your value. Well, you'd fill up your knapsack with gold until you either ran out of gold or ran out of space. If you haven't run out of space, you'll now put silver in until you run out of space. If you still haven't run out of space, well, then you'll take as many raisins as you can fit in. But you can solve it with what's called a greedy algorithm, and we'll talk much more about this as we go forward. Where you take the best thing first as long as you can and then you move on to the next thing. As we'll see, the 0/1 knapsack problem is much more complicated because once you make a decision, it will affect the future decisions. Let's look at an example, and I should probably warn you, if you're hungry, this is not going to be a fun lecture. So here is my least favorite because I always want to eat more than I'm supposed to eat. So the point is typically knapsack problems are not physical knapsacks but some conceptual idea. So let's say that I'm allowed 1,500 calories of food, and these are my options. I have to go about deciding, looking at this food-- and it's interesting, again, there's things showing up on your screen that are not showing up on my screen, but they're harmless, things like how my mouse works. Anyway, so I'm trying to take some fraction of this food, and it can't add up to more than 1,500 calories. The problem might be that once I take something that's 1,485 calories, I can't take anything else, or maybe 1,200 calories and everything else is more than 300. So once I take one thing, it constrains possible solutions. A greedy algorithm, as we'll see, is not guaranteed to give me the best answer. Let's look at a formalization of it. So each item is represented by a pair, the value of the item and the weight of the item. And let's assume the knapsack can accommodate items with the total weight of no more than w. I apologize for the short variable names, but they're easier to fit on a slide. Finally, we're going to have a vector l of length n representing the set of available items. This is assuming we have n items to choose from. So each element of the vector represents an item. So those are the items we have. And then another vector v is going to indicate whether or not an item was taken. So essentially I'm going to use a binary number to represent the set of items I choose to take. For item three say, if bit three is zero I'm not taking the item. If bit three is one, then I am taking the item. So it just shows I can now very nicely represent what I've done by a single vector of zeros and ones. Let me pause for a second. Does anyone have any questions about this setup? It's important to get this setup because what we're going to see now depends upon that setting in your head. So I've kind of used mathematics to describe the backpack problem. And that's typically the way we deal with these optimization problems. We start with some informal description, and then we translate them into a mathematical representation. So here it is. We're going to try and find a vector v that maximizes the sum of V sub i times I sub i. Now, remember I sub i is the value of the item. V sub i is either zero or one So if I didn't take the item, I'm multiplying its value by zero. So it contributes nothing to the sum. If I did take the item, I'm multiplying its value by one. So the value of the item gets added to the sum. So that tells me the value of V. And I want to get the most valuable V I can get subject to the constraint that if I look at the item's dot weight and multiply it by V, the sum of the weights is no greater than w. So I'm playing the same trick with the values of multiplying each one by zero or one, and that's my constraint. Make sense? All right, so now we have the problem formalized. How do we solve it? Well, the most obvious solution is brute force. I enumerate all possible combinations of items; that is to say, I generate all subsets of the items that are available-- I don't know why it says subjects here, but we should have said items. Let me fix that. This is called the power set. So the power set of a set includes the empty subset. It includes the set that includes everything and everything in between. So subsets of size one, subsets of size two, et cetera. So now I've generated all possible sets of items. I can now go through and sum up the weights and remove all those sets that weigh more than I'm allowed. And then from the remaining combinations, choose any one whose value is the largest. I say choose any one because there could be ties, in which case I don't care which I choose. So it's pretty obvious that this is going to give you a correct answer. You're considering all possibilities and choosing a winner. Unfortunately, it's usually not very practical. What we see here is that's what the power set is if you have 100 vec. Not very practical, right, even for a fast computer generating that many possibilities is going to take a rather long time. So kind of disappointing. We look at it and say, well, we got a brute force algorithm. It will solve the problem, but it'll take too long. We can't actually do it. 100 is a pretty small number, right. We often end up solving optimization problems where n is something closer to 1,000, sometimes even a million. Clearly, brute force isn't going to work. So that raises the next question, are we just being stupid? Is there a better algorithm that I should have showed you? I shouldn't say we. Am I just being stupid? Is there a better algorithm that would have given us the answer? The sad answer to that is no for the knapsack problem. And indeed many optimization problems are inherently exponential. What that means is there is no algorithm that provides an exact solution to this problem whose worst case running time is not exponential in the number of items. It is an exponentially hard problem. There is no really good solution. But that should not make you sad because while there's no perfect solution, we're going to look at a couple of really very good solutions that will make this poor woman a happier person. So let's start with the greedy algorithm. I already talked to you about greedy algorithms. So it could hardly be simpler. We say while the knapsack is not full, put the best available item into the knapsack. When it's full, we're done. You do need to ask a question. What does best mean? Is the best item the most valuable? Is it the least expensive in terms of, say, the fewest calories, in my case? Or is it the highest ratio of value to units? Now, maybe I think a calorie in a glass of beer is worth more than a calorie in a bar of chocolate, maybe vice versa.","74.54731750488281","3","DPRSearchEngine","C1lhuz6pZC0.en-qlPKC2UN_YU_2_mp4","C1lhuz6pZC0.en-qlPKC2UN_YU","6.0002","1"
"274","What are the main components of an optimization model, and how do they interact with each other in the context of the knapsack problem?","Many problems of practical importance can be formulated as optimization problems. Greedy algorithms often provide an adequate though often not optimal solution. Even though finding an optimal solution is, in theory, exponentially hard, dynamic programming really often yields great results. It always gives you a correct result and it's sometimes, in fact, most of the times gives it to you very quickly. Finally, in the PowerPoint, you'll find an interesting optimization problem","72.99358367919922","4","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_15_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"274","What are the main components of an optimization model, and how do they interact with each other in the context of the knapsack problem?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","72.85685729980469","5","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"274","What are the main components of an optimization model, and how do they interact with each other in the context of the knapsack problem?","found by combining optimal solutions to local subproblems. So for example, when x is greater than 1 we can solve fib x by solving fib x minus 1 and fib x minus 2 and adding those two things together. So there is optimal substructure-- you solve these two smaller problems independently of each other and then combine the solutions in a fast way. You also have to have something called overlapping subproblems. This is why the memo worked. Finding an optimal solution has to involve solving the same problem multiple times. Even if you have optimal substructure, if you don't see the same problem more than once-- creating a memo. Well, it'll work, you can still create the memo. You'll just never find anything in it when you look things up because you're solving each problem once. So you have to be solving the same problem multiple times and you have to be able to solve it by combining solutions to smaller problems. Now, we've seen things with optimal substructure before. In some sense, merge sort worked that way-- we were combining separate problems. Did merge sort have overlapping subproblems? No, because-- well, I guess, it might have if the list had the same element many, many times. But we would expect, mostly not. Because each time we're solving a different problem, because we have different lists that we're now sorting and merging. So it has half of it but not the other. Dynamic programming will not help us for sorting, cannot be used to improve merge sort. Oh, well, nothing is a silver bullet. What about the knapsack problem? Does it have these two properties? We can look at it in terms of these pictures. And it's pretty clear that it does have optimal substructure because we're taking the left branch and the right branch and choosing the winner. But what about overlapping subproblems? Are we ever solving, in this case, the same problem-- add two nodes? Well, do any of these nodes look identical? In this case, no. We could write a dynamic programming solution to the knapsack problem-- and we will-- and run it on this example, and we'd get the right answer. We would get zero speedup. Because at each node, if you can see, the problems are different. We have different things in the knapsack or different things to consider. Never do we have the same contents and the same things left to decide. So ""maybe"" was not a bad answer if that was the answer you gave to this question. But let's look at a different menu. This menu happens to have two beers in it. Now, if we look at what happens, do we see two nodes that are solving the same problem? The answer is what? Yes or no? I haven't drawn the whole tree here. Well, you'll notice the answer is yes.","71.09779357910156","6","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_11_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"274","What are the main components of an optimization model, and how do they interact with each other in the context of the knapsack problem?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 10: Depth-First Search 
Lecture 10: Depth-First Search 
Previously 
• Graph deﬁnitions (directed/undirected, simple, neighbors, degree) 
• Graph representations (Set mapping vertices to adjacency lists) 
• Paths and simple paths, path length, distance, shortest path 
• Graph Path Problems 
– Single Pair Reachability(G,s,t) 
– Single Source Reachability(G,s) 
– Single Pair Shortest Path(G,s,t) 
– Single Source Shortest Paths(G,s) (SSSP) 
• Breadth-First Search (BFS) 
– algorithm that solves Single Source Shortest Paths 
– with appropriate data structures, runs in O(|V | + |E|) time (linear in input size) 
Examples 
G1 
a 
d 
b 
e 
c 
f 
G2 
a 
d 
b 
e 
c 
f 
","70.7818832397461","7","DPRSearchEngine","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10_1_pdf","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10","6.006","10"
"274","What are the main components of an optimization model, and how do they interact with each other in the context of the knapsack problem?","provides information about the possible behaviors of a system. I say possible behaviors, because I'm particularly interested in stochastic systems. They're descriptive not prescriptive in the sense that they describe the possible outcomes. They don't tell you how to achieve possible outcomes. This is different from what we've looked at earlier in the course, where we looked at optimization models. So an optimization model is prescriptive. It tells you how to achieve an effect, how to get the most value out of your knapsack, how to find the shortest path from A to B in a graph. In contrast, a simulation model says, if I do this, here's what happens. It doesn't tell you how to make something happened. So it's very different, and it's why we need both, why we need optimization models and we need simulation models. We have to remember that a simulation model is only an approximation to reality. I put in an approximation to the distribution of birthdates, but it wasn't quite right. And as the very famous statistician George Box said, ""all models are wrong, but some are actually very useful."" In the next lecture, we'll look at a useful class of models. When do we use simulations? Typically, as we've just shown, to model systems that are mathematically intractable, like the birthday problem we just looked at. In other situations, to extract intermediate results-- something happens along the way to the answer. And as I hope you've seen that simulations are used because we can play what if games by successively refining it. We started with a simple simulation that assumed that we only asked the question of, do two people share a birthday. We showed how we could change it to ask do three people share a birthday. We then saw that we could change it to assume a different distribution of birthdates in the group. And so we can start with something simple. And we get it ever more complexed to answer questions what if. We're going to start in the next lecture by producing a simulation of a random walk. And with that, I'll stop. And see you guys soon.","70.68184661865234","8","DPRSearchEngine","-1BnXEwHUok.en-qlPKC2UN_YU_12_mp4","-1BnXEwHUok.en-qlPKC2UN_YU","6.0002","4"
"274","What are the main components of an optimization model, and how do they interact with each other in the context of the knapsack problem?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 4: Hashing 
Lecture 4: Hashing 
Review 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
• Idea! Want faster search and dynamic operations. Can we find(k) faster than Θ(log n)? 
• Answer is no (lower bound)! (But actually, yes...!?) 
Comparison Model 
• In this model, assume algorithm can only differentiate items via comparisons 
• Comparable items: black boxes only supporting comparisons between pairs 
• Comparisons are <, ≤, >, ≥, =, =6 , outputs are binary: True or False 
• Goal: Store a set of n comparable items, support find(k) operation 
• Running time is lower bounded by # comparisons performed, so count comparisons! 
Decision Tree 
• Any algorithm can be viewed as a decision tree of operations performed 
• An internal node represents a binary comparison, branching either True or False 
• For a comparison algorithm, the decision tree is binary (draw example) 
• A leaf represents algorithm termination, resulting in an algorithm output 
• A root-to-leaf path represents an execution of the algorithm on some input 
• Need at least one leaf for each algorithm output, so search requires ≥ n + 1 leaves 
","70.63959503173828","9","DPRSearchEngine","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_1_pdf","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4","6.006","4"
"274","What are the main components of an optimization model, and how do they interact with each other in the context of the knapsack problem?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","70.57835388183594","10","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"275","What can be concluded if the confidence intervals of different subpopulations do not overlap?"," 
 
   
 
   
 
   
 
   
  
 
 
Summary Statistics  
§Summary statistics for groups identical
◦Mean x  = 9.0
◦Mean y = 7.5
◦Variance of x = 10.0
◦Variance of y = 3.75
◦Linear  regression model: y = 0.5x + 3
§Are four data sets really similar?
6.0002  LECTURE 14 
14 
","71.56529235839844","1","DPRSearchEngine","b9d60f4ecb325e4648f9cf0379419338_MIT6_0002F16_lec14_14_pdf","b9d60f4ecb325e4648f9cf0379419338_MIT6_0002F16_lec14","6.0002","14"
"275","What can be concluded if the confidence intervals of different subpopulations do not overlap?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Monte Carlo Simulation  
A method of estimating the value of an unknown 
quantity using the principles of inferential statistics 
Inferential statistics 
◦ Population: a set of examples 
◦ Sample: a proper subset of a population 
◦ Key fact: a random sample tends to exhibit the same  
properties as the population from which it is drawn  
Exactly what we did with random walks 
6.0002 LECTURE 6 
4
","70.44922637939453","2","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_4_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"275","What can be concluded if the confidence intervals of different subpopulations do not overlap?"," 
 
 
  
 
 
 
 
 
 
 
 
 
  
 
  
 
Why the Difference in Confidence?  
Confidence in our estimate depends upon two things  
Size of sample (e.g., 100 versus 2) 
Variance of sample (e.g., all heads versus 52 heads) 
As the variance grows, we need larger samples to have 
the same degree of confidence 
6.0002 LECTURE 6 
9
","70.28279113769531","3","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_9_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"275","What can be concluded if the confidence intervals of different subpopulations do not overlap?"," 
 
 
 
 
  
 
 
  
 
Probability of Various Results  
Consider testRoll(5) 
How probable is the output 11111?  
6.0002 LECTURE 4 
10
","69.89302825927734","4","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_10_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"275","What can be concluded if the confidence intervals of different subpopulations do not overlap?"," 
  
 
  
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Means  and Standard Deviations  
§Population mean = 16.3
§Sample mean = 17.1
§Standard deviation of population = 9.44
§Standard deviation  of sample = 10.4
§A  happy accident, or something we should expect?
§Let’s try  it 1000 times and plot the results
6.0002  LECTURE 8 
 
11
","69.67652893066406","5","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_11_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"275","What can be concluded if the confidence intervals of different subpopulations do not overlap?","I'm going to look at a bunch of different sample sizes, from 25 to 600, 50 trials each. So getHighs is just a function that returns the temperatures. I'm going to get the standard deviation of the whole population, then the standard error of the means and the sample standard deviations, both. And then I'm just going to go through and run it. So for size and sample size, I'm going to append the standard error of the mean. And remember, that uses the population standard deviation and the size of the sample. So I'll compute all the SEMs. And then I'm going to compute all the actual standard deviations, as well. And then we'll produce a bunch of plots-- or a plot, actually. All right, so let's see what that plot looks like.","69.23809814453125","6","DPRSearchEngine","soZv_KKax3E.en-qlPKC2UN_YU_10_mp4","soZv_KKax3E.en-qlPKC2UN_YU","6.0002","8"
"275","What can be concluded if the confidence intervals of different subpopulations do not overlap?"," 
 
Looking at  Distributions 
def plotDistributions():  
uniform, normal, exp = [], [], []  
for i in range(100000):  
uniform.append(random.random())  
normal.append(random.gauss(0, 1))  
exp.append(random.expovariate(0.5))  
makeHist(uniform, 'Uniform', 'Value', 'Frequency')  
pylab.figure()  
makeHist(normal, 'Gaussian', 'Value', 'Frequency')  
pylab.figure()  
makeHist(exp, 'Exponential', 'Value', 'Frequency')  
6.0002  LECTURE 8 
 
27
","68.6998291015625","7","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_27_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"275","What can be concluded if the confidence intervals of different subpopulations do not overlap?","Well, here's a histogram of one random sample of size 100. Looks pretty different, as you might expect. Its standard deviation is 10.4, its mean 17.7. So even though the figures look a little different, in fact, the means and standard deviations are pretty similar. If we look at the population mean and the sample mean-- and I'll try and be careful to use those terms-- they're not the same. But they're in the same ballpark. And the same is true of the two standard deviations. Well, that raises the question, did we get lucky or is something we should expect? If we draw 100 random examples, should we expect them to correspond to the population as a whole? And the answer is sometimes yeah and sometimes no. And that's one of the issues I want to explore today. So one way to see whether it's a happy accident is to try it 1,000 times. We can draw 1,000 samples of size 100 and plot the results. Again, I'm not going to go over the code. There's something in that code, as well, that we haven't seen before. And that's the ax.vline plotting command. V for vertical. It just, in this case, will draw a red line-- because I've said the color is r-- at population mean on the x-axis. So just a vertical line. So that'll just show us where the mean is. If we wanted to draw a horizontal line, we'd use ax.hline. Just showing you a couple of useful functions. When we try it 1,000 times, here's what it looks like. So here we see what we had originally, same picture I showed you before. And here's what we get when we look at the means of 100 samples. So this plot on the left looks a lot more like it's a normal distribution than the one on the right. Should that surprise us, or is there a reason we should have expected that to happen? Well, what's the answer? Someone tell me why we should have expected it. It's because of the central limit theorem, right? That's exactly what the central limit theorem promised us would happen. And, sure enough, it's pretty close to normal. So that's a good thing. And now if we look at it, we can see that the mean of the sample means is 16.3, and the standard deviation of the sample means is 0.94. So if we go back to what we saw here, we see that, actually, when we run it 1,000 times and look at the means, we get very close to what we had initially. So, indeed, it's not a happy accident. It's something we can in general expect. All right, what's the 95% confidence interval here? Well, it's going to be 16.28 plus or minus 1.96 times 0.94, the standard deviation of the sample means. And so it tells us that the confidence interval is, the mean high temperature, is somewhere between 14.5 and 18.1. Well, that's actually a pretty big range, right? It's sort of enough to where you wear a sweater or where you don't wear a sweater. So the good news is it includes the population mean. That's nice. But the bad news is it's pretty wide. Suppose we wanted it tighter bound. I said, all right, sure enough, the central limit theorem is going to tell me the mean of the means is going to give me a good estimate of the actual population mean. But I want it tighter bound. What can I do? Well, let's think about a couple of things we could try. Well, one thing we could think about is drawing more samples. Suppose instead of 1,000 samples, I'd taken 2,000 or 3,000 samples. We can ask the question, would that have given me a smaller standard deviation? For those of you who have not looked ahead, what do you think? Who thinks it will give you a smaller standard deviation? Who thinks it won't? And the rest of you have either looked ahead or refused to think. I prefer to believe you looked ahead. Well, we can run the experiment. You can go to the code. And you'll see that there is a constant of 1,000, which you can easily change to 2,000. And lo and behold, the standard deviation barely budges. It got a little bit bigger, as it happens, but that's kind of an accident. It just, more or less, doesn't change. And it won't change if I go to 3,000 or 4,000 or 5,000. It'll wiggle around. But it won't help much. What we can see is doing that more often is not going to help. Suppose we take larger samples? Is that going to help? Who thinks that will help? And who thinks it won't? OK. Well, we can again run the experiment. I did run the experiment. I changed the sample size from 100 to 200. And, again, you can run this if you want. And if you run it, you'll get a result-- maybe not exactly this, but something very similar-- that, indeed, as I increase the size of the sample rather than the number of the samples, the standard deviation drops fairly dramatically, in this case from 0.94 0.66. So that's a good thing. I now want to digress a little bit before we come back to this and look at how you can visualize this-- Because this is a technique you'll want to use as you write papers and things like that-- is how do we visualize the variability of the data? And it's usually done with something called an error bar. You've all seen these things here.","67.57328033447266","8","DPRSearchEngine","soZv_KKax3E.en-qlPKC2UN_YU_5_mp4","soZv_KKax3E.en-qlPKC2UN_YU","6.0002","8"
"275","What can be concluded if the confidence intervals of different subpopulations do not overlap?"," 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
Probability Is About Counting  
Count the number of possible events 
Count the number of events that have the property of 
interest 
Divide one by the other 
Probability of 11111? 
◦ 11111, 11112, 11113, /, 11121, 11122, /, 66666 
◦ 1/(6**5) 
◦ ~0.0001286 
6.0002 LECTURE 4 
11
","67.27958679199219","9","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_11_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"275","What can be concluded if the confidence intervals of different subpopulations do not overlap?","!	!	 	
 
Let D be the original data set 
    n be the number of random samples  
 
 
 usually n between 20% and 50% 
    k be number of trials 
 
testResults = [] 
for i in range(k) 
    randomly select n elements for testSet,  
       keep rest for training 
    model = buildModel(training) 
    testResults.append(test(model, testSet)) 
 
Average testResults 

	

;G
","67.17850494384766","10","DPRSearchEngine","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10_38_pdf","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10","6.0002","10"
"279","What factors can affect the accuracy of the sample standard deviation as an approximation of the population standard deviation?","Standard deviation simply the square root of the 
variance
Outliers can have a big effect
Standard deviation should always be considered 
relative to mean
Quantifying Variation in Data
6.0002 LECTURE 6
 
1
(X) 
(x )2
X xX
21
","78.94717407226562","1","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_21_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"279","What factors can affect the accuracy of the sample standard deviation as an approximation of the population standard deviation?"," 
 
 
 
 
 
 
 
 
 
 
Standard Error  of the Mean  
σ
SE = 
n
But, we don’t 
know  standard 
deviation  of 
population 
How might we  
approximate it?  
6.0002  LECTURE 8 
 
24
","78.13587951660156","2","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_24_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"279","What factors can affect the accuracy of the sample standard deviation as an approximation of the population standard deviation?","is that the variance of the sample means will be close to the variance of the population divided by the sample size. And we're going to use that to compute something called the standard error-- formerly the standard error of the mean. People often just call it the standard error. And I will be, alas, inconsistent. I sometimes call it one, sometimes the other. It's an incredibly simple formula. It says the standard error is going to be equal to sigma, where sigma is the population standard deviation divided by the square root of n, which is going to be the size of the sample. And then there's just this very small function that implements it. So we can compute this thing called the standard error of the mean in a very straightforward way. We can compute it. But does it work? What do I mean by work? I mean, what's the relationship of the standard error to the standard deviation? Because, remember, that was our goal, was to understand the standard deviation so we could use the empirical rule. Well, let's test the standard error of the mean.","77.176513671875","3","DPRSearchEngine","soZv_KKax3E.en-qlPKC2UN_YU_9_mp4","soZv_KKax3E.en-qlPKC2UN_YU","6.0002","8"
"279","What factors can affect the accuracy of the sample standard deviation as an approximation of the population standard deviation?"," 
  
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
New in  Code  
§numpy.std is function in the numpy module that
returns the standard deviation
§random.sample(population, sampleSize) returns a list
containing sampleSize randomly chosen distinct
elements of population
◦Sampling without replacement
6.0002  LECTURE 8 
 
8
","76.65105438232422","4","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_8_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"279","What factors can affect the accuracy of the sample standard deviation as an approximation of the population standard deviation?"," 
  
 
  
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Means  and Standard Deviations  
§Population mean = 16.3
§Sample mean = 17.1
§Standard deviation of population = 9.44
§Standard deviation  of sample = 10.4
§A  happy accident, or something we should expect?
§Let’s try  it 1000 times and plot the results
6.0002  LECTURE 8 
 
11
","76.00695037841797","5","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_11_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"279","What factors can affect the accuracy of the sample standard deviation as an approximation of the population standard deviation?"," 
 
 
 
 
Lecture: Sampling and 
Standard Error 
6.0002  LECTURE 8 
 
1
","75.16387176513672","6","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_1_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"279","What factors can affect the accuracy of the sample standard deviation as an approximation of the population standard deviation?","Quite different, right? We've looked at uniform and we've looked at Gaussian before. And here we see an exponential, which basically decays and will asymptote towards zero, never quite getting there. But as you can see, it is certainly not very symmetric around the mean. All right, so let's see what happens. If we run the experiment on these three distributions, each of 100,000 point examples, and look at different sample sizes, we actually see that the difference between the standard deviation and the sample standard","75.11711883544922","7","DPRSearchEngine","soZv_KKax3E.en-qlPKC2UN_YU_13_mp4","soZv_KKax3E.en-qlPKC2UN_YU","6.0002","8"
"279","What factors can affect the accuracy of the sample standard deviation as an approximation of the population standard deviation?"," 
 
 
 
 
Sample Size and Standard Deviation  
6.0002  LECTURE 8 
 
18
","75.00354766845703","8","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_18_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"279","What factors can affect the accuracy of the sample standard deviation as an approximation of the population standard deviation?","  
 
 
 
 
Standard Error  of the Mean  
σ
SE = 
n
def sem(popSD, sampleSize):  
return popSD/sampleSize**0.5  
§Does it work?
6.0002  LECTURE 8 
 
22
","74.9979476928711","9","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_22_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"279","What factors can affect the accuracy of the sample standard deviation as an approximation of the population standard deviation?"," 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Non-representative Sampling  
§“Convenience sampling” not usually random, e.g.,
◦Survivor  bias,  e.g.,  course evaluations at end of course or
grading final exam in 6.0002  on a strict curve
◦Non-response bias,  e.g.,  opinion polls conducted by mail
or  online
§When samples not random and independent, we can
still do things like computer means and standard 
deviations, but we should not draw conclusions from 
them using things like the empirical rule and central 
limit theorem. 
§Moral: Understand how data was collected, and
whether assumptions used in the analysis are satisfied. 
If not, be wary. 
6.0002  LECTURE 14 
22 
","74.85830688476562","10","DPRSearchEngine","b9d60f4ecb325e4648f9cf0379419338_MIT6_0002F16_lec14_22_pdf","b9d60f4ecb325e4648f9cf0379419338_MIT6_0002F16_lec14","6.0002","14"
"282","What is a probability distribution and what does it capture?"," 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
Probability Is About Counting  
Count the number of possible events 
Count the number of events that have the property of 
interest 
Divide one by the other 
Probability of 11111? 
◦ 11111, 11112, 11113, /, 11121, 11122, /, 66666 
◦ 1/(6**5) 
◦ ~0.0001286 
6.0002 LECTURE 4 
11
","78.6164779663086","1","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_11_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"282","What is a probability distribution and what does it capture?","And we'll come back to this in just a second. But this is a normal distribution, called the Gaussian. Under those two assumptions the empirical rule will always hold. All right, let's talk about distributions, since I just introduced one. We've been using a probability distribution. And this captures the notion of the relative frequency with which some random variable takes on different values.","76.26518249511719","2","DPRSearchEngine","OgO1gpXSUzU.en-j3PyPqV-e1s_16_mp4","OgO1gpXSUzU.en-j3PyPqV-e1s","6.0002","6"
"282","What is a probability distribution and what does it capture?","random.choice. It takes as an argument a sequence, in this case a list, and randomly chooses one member of the list. And it chooses it uniformly. It's a uniform distribution. And what that means is that it's equally probable that it will choose any number in that list each time you call it. We'll later look at distributions that are not uniform, not equally probable, where things are weighted. But here, it's quite simple, it's just uniform. And then we can test it using testRoll-- take some number of n and rolls the die that many times and creates a string telling us what we got. So let's consider running this on, say, testRoll of five. And we'll ask the question, if we run it, how probable is it that it's going to return a string of five 1's? How do we do that? Now, how many people here are either in 6.041 or would have taken 6.041? Raise your hand. Oh, good. So very few of you know probability. That helps. So how do we think about that question? Well, probability, to me at least, is all about counting, especially discrete probability, which is what we're looking at here. What you do is you start by counting the number of events that have the property of interest and the number of possible events and divide one by the other. So if we think about rolling a die five times, we can enumerate all of the possible outcomes of five rolls. So if we look at that, what are the outcomes? Well, I could get five 1's. I could get four 1's and a 2 or four 1's and 3, skip a few. The next one would be three 1's, a 2 and a 1, then a 2 and 2, and finally, at the end, all 6's. So remember, we looked before at when we're looking at optimization problems about binary numbers. And we said we can look at all the possible choices of items in the knapsack by a vector of 0's and 1's. We said, how many possible choices are there? Well, it depended on how many binary numbers you could get in that number of digits. Well, here we're doing the same thing, but instead of base 2, it's base 6. And so the number of possible outcomes of five rolls is quite high. How many of those are five 1's? Only one of them, right? So in order to get the probability of a five 1's, I divide 1 by 6 to the fifth. Does that makes sense to everybody? So in fact, we see it's highly unlikely. The probability of a five 1's is quite small. Now, suppose we were to ask about the probability of something else-- instead of five 1's, say 53421. It kind of looks more likely than that than five 1's in a row, but of course, it isn't, right? Any specific combination is equally probable. And there are a lot of them. So this is all the probability we're going to think about we could think about this way, as simply a matter of counting-- the number of possible events, the number of events that have the property of interest-- in this case being all 1's-- and then simple division. Given that framework, there were three basic facts about probability we're going to be using a lot of. So one, probabilities always range from 0 to 1. How do we know that? Well, we've got a fraction, right? And the denominator is all possible events. The numerator is the subset of that that's of interest. So it has to range from 0 to the denominator. And that tells us that the fraction has to range from 0 to 1. So 1 says it's always going to happen, 0 never. So if the probability of an event occurring is p, what's the probability of it not occurring? This follows from the first bullet. It's simply going to be 1 minus p. This is a trick that we'll find we'll use a lot. Because it's often the case when you want to compute the probability of something happening, it's easier to compute the probability of it not happening and subtract it from 1. And we'll see an example of that later today. Now, here's the biggie. When events are independent of each other, the probability of all of the events occurring is equal to the product of the probabilities of each of the events occurring. So if the probability of A is 0.5 and the probability of B","74.95712280273438","3","DPRSearchEngine","-1BnXEwHUok.en-qlPKC2UN_YU_4_mp4","-1BnXEwHUok.en-qlPKC2UN_YU","6.0002","4"
"282","What is a probability distribution and what does it capture?"," 
 
Looking at  Distributions 
def plotDistributions():  
uniform, normal, exp = [], [], []  
for i in range(100000):  
uniform.append(random.random())  
normal.append(random.gauss(0, 1))  
exp.append(random.expovariate(0.5))  
makeHist(uniform, 'Uniform', 'Value', 'Frequency')  
pylab.figure()  
makeHist(normal, 'Gaussian', 'Value', 'Frequency')  
pylab.figure()  
makeHist(exp, 'Exponential', 'Value', 'Frequency')  
6.0002  LECTURE 8 
 
27
","73.42325592041016","4","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_27_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"282","What is a probability distribution and what does it capture?","-
numTrials = 1000000
numSpins = 200
game = FairRoulette()
means = []
for i in range(numTrials):
means.append(findPocketReturn(game, 1, numSpins,
False)[0])
pylab.hist(means, bins = 19,
weights = [1/len(means)]*len(means))
pylab.xlabel('Mean Return')
pylab.ylabel('Probability')
pylab.title('Expected Return Betting a Pocket 200 Times')
	


","72.52545166015625","5","DPRSearchEngine","3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7_17_pdf","3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7","6.0002","7"
"282","What is a probability distribution and what does it capture?","And here it is. It's actually for something so important, very simple. It says that given a sufficiently large sample-- and I love terms like sufficiently large but we'll later put a little meat on that-- the following three things are true. The means of the samples in a set of samples, the so-called sample means will be approximately normally distributed. So that says if I take a sample-- and remember, a sample will have multiple examples. So just to remind people. A population is a set of examples. A sample is a subset of the population. So it too is a set of examples, typically. If this set is sufficiently large-- certainly 1 is not sufficiently large-- then it will be the case that the mean of the means-- so I take the mean of each sample and then I can now plot all of those means and so take the mean of those, right-- and they'll be normally distributed. Furthermore, this distribution will have a mean that is close to the mean of the population. The mean of the means will be close to the mean of the population. And the variance of the sample means will be close to the variance of the population divided by the sample size. This is really amazing that this is true and dramatically useful. So to get some insight, let's check it. To do that, postulate that we have this kind of miraculous die. So instead of a die that when you roll it you get a number 1, 2, 3, 4, 5, or 6, this particular die is continuous. It gives you a real number between 0 and 5, or maybe it's between 1 and 6, OK? So it's a continuous die. What we're going to do is roll it a lot of times. We're going to say, how many die? And then, how many times are we going to roll that number of die? So the number of die will be the sample size-- number of dice will be the sample size. And then we'll take a bunch of samples which I'm calling number of rolls. And then we'll plot it and I'm just choosing some bins and some colors and some style and various other things just to show you how we use the keyword arguments. Actually, I said the number of rolls is the number of trials. But it isn't quite that because I'm going to get the number of trials by dividing the number of rolls by the number of dice. So if I have more dice, I get to have fewer samples, more dice per sample, all right? Then we'll just do it. So it will be between 0 and 5 because random.random returns a number between 0 and 1 and I'm multiplying it by 5. And then we'll look at the means and we'll plot it all. Again, we're playing games with weights just to make the plot a little easier to read. And here's what we get. If we roll one die, the mean is very close to 2.5. Well, that's certainly what you'd expect, right? It's some random number between 0 and 5. 2.5 is a pretty good guess as to what it should average. And it has a standard deviation of 1.44. And that's a little harder to guess that that's what it would be. But you could figure it out with a little math or as I did here with the simulation. But now, if I roll 50 dice, well, again, the mean is close to 2.5. It's what you'd expect, right? I roll 50 die, I get the mean value of those 50. But look how much smaller the standard deviation is. More importantly, what we see here is that if we look at the value, the probability is flat for all possible values between 0 and 5 for a single die. But if we look at the distribution for the means, it's not quite Gaussian but it's pretty close. Why is it not Gaussian? Well, I didn't do it an infinite number of times. Did it quite a few, but not an infinite number. Enough that you didn't want to sit here while it ran. But you can see the amazing thing here that when I go from looking at 1 to looking at the mean of 50, suddenly I have a normal distribution. And that means that I can bring to bear on the problem the Central Limit Theorem. We can try it for roulette. Again I'm not going to make you sit through a million trials of 200 spins each. I'll do it only for fair roulette. And again, this is a very simple simulation, and we'll see what we get. And what we see is it's not quite normal, again, but it definitely has that shape. Now, it's going to be a little bit strange because I can't lose more than one, if I'm betting one. So it will never be quite normal because it's going to be truncated down on the left side, whereas the tail can be arbitrarily long. So again, mathematically it can't be normal but it's close enough in the main region, where most of the values lie, that we can get away with applying the empirical rule and looking at answers. And indeed as we saw, it does work. So what's the moral here? It doesn't matter what the shape of the distribution of the original values happen to be. If we're trying to estimate the mean using samples that are sufficiently large, the CLT will allow us to use the empirical rule when computing confidence intervals. Even if we go back and look at this anomaly over in the left, what do you think would happen if I, instead of had 200, have, say, 1,000? What's the probability of the average return being minus 1 of 1,000 bets? Much smaller than for 100 bets. To lose 1,000 times in a row is pretty unlikely. So to get all the way to the left is going to be less likely, and, therefore, the thing will start looking more and more normal as the samples get bigger. All right, and so we can use the CLT to justify using the empirical rule when we compute confidence intervals. All right, I want to look at one more example in detail. This is kind of an interesting one. You might think that randomness is of no use for, say, finding the value of pi because there's nothing random about that. Similarly, you might think that randomness was of no use in integrating a function, but in fact, the way those numerical algorithms work is they use randomness. What you're about to see is that randomness, and indeed things related to Monte Carlo simulations, can be enormously useful, even when you're computing something that is inherently not random like the value of pi here. And we won't ask you to remember that many digits on the quiz and the exam. All right, so what's pi? Well, people have known about pi for thousands and thousands of years. And what people knew was that there was some constant, we'll call it pi. It wasn't always called that. Such that it was equal to the circumference of a circle divided by the diameter, and furthermore, the area was going to be pi r squared. People knew that way back to the Babylonians and the Egyptians. What they didn't know is what that value was. The earliest known estimate of pi was by the Egyptians, on something called the Rhind Papyrus pictured here.","72.27922058105469","6","DPRSearchEngine","rUxP7TM8-wo.en-qlPKC2UN_YU_7_mp4","rUxP7TM8-wo.en-qlPKC2UN_YU","6.0002","7"
"282","What is a probability distribution and what does it capture?","And it does give me an excuse to cover some important topics related to programming. You'll remember that one of the subtexts of the course is while I'm covering a lot of what you might think of as abstract material, we're using it as an excuse to teach more about programming and software engineering. A little practice with classes and subclassing, and we're going to also look at producing plots. So the first random walk I want to look at is actually not a diffusion process or the stock market, but an actual walk. So imagine that you've got a field which has somehow","71.34573364257812","7","DPRSearchEngine","6wUD_gp5WeE.en-qlPKC2UN_YU_2_mp4","6wUD_gp5WeE.en-qlPKC2UN_YU","6.0002","5"
"282","What is a probability distribution and what does it capture?","The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high-quality educational resources for free. To make a donation, or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. JOHN GUTTAG: I'm a little reluctant to say good afternoon, given the weather, but I'll say it anyway. I guess now we all do know that we live in Boston. And I should say, I hope none of you were affected too much by the fire yesterday in Cambridge, but that seems to have been a pretty disastrous event for some. Anyway, here's the reading. This is a chapter in the book on clustering, a topic that Professor Grimson introduced last week. And I'm going to try and finish up with respect to this course today, though not with respect to everything there is to know about clustering. Quickly just reviewing where we were. We're in the unit of a course on machine learning, and we always follow the same paradigm. We observe some set of examples, which we call the training data. We try and infer something about the process that created those examples. And then we use inference techniques, different kinds of techniques, to make predictions about previously unseen data. We call that the test data. As Professor Grimson said, you can think of two broad classes. Supervised, where we have a set of examples and some label associated with the example-- Democrat, Republican, smart, dumb, whatever you want to associate with them-- and then we try and infer the labels. Or unsupervised, where we're given a set of feature vectors without labels, and then we attempt to group them into natural clusters. That's going to be today's topic, clustering. So clustering is an optimization problem. As we'll see later, supervised machine learning is also an optimization problem. Clustering's a rather simple one. We're going to start first with the notion of variability. So this little c is a single cluster, and we're going to talk about the variability in that cluster of the sum of the distance between the mean of the cluster and each example in the cluster. And then we square it. OK? Pretty straightforward. For the moment, we can just assume that we're using Euclidean distance as our distance metric. Minkowski with p equals two. So variability should look pretty similar to something we've seen before, right? It's not quite variance, right, but it's very close. In a minute, we'll look at why it's different. And then we can look at the dissimilarity of a set of clusters, a group of clusters, which I'm writing as capital C, and that's just the sum of all the variabilities. Now, if I had divided variability by the size of the cluster, what would I have? Something we've seen before. What would that be? Somebody? Isn't that just the variance? So the question is, why am I not doing that? If up til now, we always wanted to talk about variance, why suddenly am I not doing it? Why do I define this notion of variability instead of good old variance? Any thoughts? What am I accomplishing by not dividing by the size of the cluster? Or what would happen if I did divide by the size of the cluster? Yes. AUDIENCE: You normalize it? JOHN GUTTAG: Absolutely. I'd normalize it. That's exactly what it would be doing. And what might be good or bad about normalizing it? What does it essentially mean to normalize? It means that the penalty for a big cluster with a lot of variance in it is no higher than the penalty of a tiny little cluster with a lot of variance in it. By not normalizing, what I'm saying is I want to penalize big, highly-diverse clusters more than small, highly-diverse clusters. OK? And if you think about it, that probably makes sense. Big and bad is worse than small and bad. All right, so now we define the objective function. And can we say that the optimization problem we want to solve by clustering is simply finding a capital C that minimizes dissimilarity? Is that a reasonable definition? Well, hint-- no. What foolish thing could we do that would optimize that objective function? Yeah. AUDIENCE: You could have the same number of clusters as points? JOHN GUTTAG: Yeah. I can have the same number of clusters as points, assign each point to its own cluster, whoops. Ooh, almost a relay. The dissimilarity of each cluster would be 0. The variability would be 0, so the dissimilarity would be 0, and I just solved the problem. Well, that's clearly not a very useful thing to do. So, well, what do you think we do to get around that? Yeah. AUDIENCE: We apply a constraint? JOHN GUTTAG: We apply a constraint. Exactly. And so we have to pick some constraint. What would be a suitable constraint, for example? Well, maybe we'd say, OK, the clusters have to have some minimum distance between them. Or-- and this is the constraint we'll be using today-- we could constrain the number of clusters. Say, all right, I only want to have at most five clusters. Do the best you can to minimize dissimilarity, but you're not allowed to use more than five clusters. That's the most common constraint that gets placed in the problem. All right, we're going to look at two algorithms. Maybe I should say two methods, because there are multiple implementations of these methods. The first is called hierarchical clustering, and the second is called k-means. There should be an S on the word mean there. Sorry about that. All right, let's look at hierarchical clustering first.","70.84321594238281","8","DPRSearchEngine","esmzYhuFnds.en-qlPKC2UN_YU_1_mp4","esmzYhuFnds.en-qlPKC2UN_YU","6.0002","12"
"282","What is a probability distribution and what does it capture?","of x, my e.getfeatures for e in test set, so that will give me the features associated with each element in the test set. I could obviously have written a for loop to do the same thing, but this was just a little cooler. Then we get model.predict for each of these. Model.predict_proba is nice in that I don't have to predict it for one example at a time. I can pass it as set of examples, and what I get back is a list of predictions, so that's just convenient. And then setting these to 0, and for I in range len of probs, here a probability of 0.5. What's that's saying is what I get out of logistic regression is a probability of something having a label. I then have to build a classifier, give a threshold. And here what I've said, if the probability of it being true is over a 0.5, call it true. So if the probability of survival is over 0.5, call it survived. If it's below, call it not survived. We'll later see that, again, setting that probability is itself an interesting thing, but the default in most systems is half, for obvious reasons. I get my probabilities for each feature vector, and then for I in ranged lens of probabilities, I'm just testing whether the predicted label is the same as the actual label, and updating true positives, false positives, true negatives, and false negatives accordingly. So far, so good?","69.8475570678711","9","DPRSearchEngine","eg8DJYwdMyg.en-qlPKC2UN_YU_9_mp4","eg8DJYwdMyg.en-qlPKC2UN_YU","6.0002","13"
"282","What is a probability distribution and what does it capture?","provides information about the possible behaviors of a system. I say possible behaviors, because I'm particularly interested in stochastic systems. They're descriptive not prescriptive in the sense that they describe the possible outcomes. They don't tell you how to achieve possible outcomes. This is different from what we've looked at earlier in the course, where we looked at optimization models. So an optimization model is prescriptive. It tells you how to achieve an effect, how to get the most value out of your knapsack, how to find the shortest path from A to B in a graph. In contrast, a simulation model says, if I do this, here's what happens. It doesn't tell you how to make something happened. So it's very different, and it's why we need both, why we need optimization models and we need simulation models. We have to remember that a simulation model is only an approximation to reality. I put in an approximation to the distribution of birthdates, but it wasn't quite right. And as the very famous statistician George Box said, ""all models are wrong, but some are actually very useful."" In the next lecture, we'll look at a useful class of models. When do we use simulations? Typically, as we've just shown, to model systems that are mathematically intractable, like the birthday problem we just looked at. In other situations, to extract intermediate results-- something happens along the way to the answer. And as I hope you've seen that simulations are used because we can play what if games by successively refining it. We started with a simple simulation that assumed that we only asked the question of, do two people share a birthday. We showed how we could change it to ask do three people share a birthday. We then saw that we could change it to assume a different distribution of birthdates in the group. And so we can start with something simple. And we get it ever more complexed to answer questions what if. We're going to start in the next lecture by producing a simulation of a random walk. And with that, I'll stop. And see you guys soon.","69.84581756591797","10","DPRSearchEngine","-1BnXEwHUok.en-qlPKC2UN_YU_12_mp4","-1BnXEwHUok.en-qlPKC2UN_YU","6.0002","4"
"283","What is the purpose of the density method in the Food class?"," 
 
 
Does Population  Size Matter?  
6.0002  LECTURE 8 
 
30
","70.04859924316406","1","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_30_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"283","What is the purpose of the density method in the Food class?","7
class Food(object):
def __init__(self, n, v, w):
self.name = n
self.value = v
self.calories = w
def getValue(self):
return self.value
def getCost(self):
return self.calories
def density(self):
return self.getValue()/self.getCost()
def __str__(self):
return self.name + ': <' + str(self.value)\\
+ ', ' + str(self.calories) + '>'
	


","69.75878143310547","2","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_21_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"283","What is the purpose of the density method in the Food class?"," 
 
 
 
  
 
 
 
 
 
 
 
Stratified Sampling  
§Stratified sampling
◦Partition population into subgroups
◦Take a simple random sample from each subgroup
6.0002  LECTURE 8 
 
5
","67.4759521484375","3","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_5_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"283","What is the purpose of the density method in the Food class?"," 
 
 
 
 
Lecture: Sampling and 
Standard Error 
6.0002  LECTURE 8 
 
1
","66.54448699951172","4","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_1_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"283","What is the purpose of the density method in the Food class?"," 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
Law of Large Numbers  
In repeated independent tests with the same actual 
probability p of a particular outcome in each test, the 
chance that the fraction of times that outcome occurs 
differs from p converges to zero as the number of trials 
goes to infinity 
Does this imply that if 
deviations from expected 
behavior occur, these 
deviations are likely to be 
evened out by opposite 
deviations in the future? 
6.0002 LECTURE 6 
14
","66.28240203857422","5","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_14_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"283","What is the purpose of the density method in the Food class?",";
/
def testGreedys(maxUnits):
print('Use greedy by value to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits, Food.getValue)
print('\\nUse greedy by cost to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits,
lambda x: 1/Food.getCost(x))
print('\\nUse greedy by density to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits, Food.density)
testGreedys(800)
	


4
","66.03092956542969","6","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_26_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"283","What is the purpose of the density method in the Food class?"," 
 
 
 
 
 
Does Distribution  Matter?  
6.0002  LECTURE 8 
 
Skew, a  measure 
of  the asymmetry 
of  a probability  
distribution, 
matters 
29
","65.88001251220703","7","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_29_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"283","What is the purpose of the density method in the Food class?",";
/
def testGreedys(foods, maxUnits):
print('Use greedy by value to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits, Food.getValue)
print('\\nUse greedy by cost to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits,
lambda x: 1/Food.getCost(x))
print('\\nUse greedy by density to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits, Food.density)
names = ['wine', 'beer', 'pizza', 'burger', 'fries',
'cola', 'apple', 'donut', 'cake']
values = [89,90,95,100,90,79,50,10]
calories = [123,154,258,354,365,150,95,195]
foods = buildMenu(names, values, calories)
testGreedys(foods, 750)
)
	

:
","65.71760559082031","8","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_28_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"283","What is the purpose of the density method in the Food class?","And here it is. It's actually for something so important, very simple. It says that given a sufficiently large sample-- and I love terms like sufficiently large but we'll later put a little meat on that-- the following three things are true. The means of the samples in a set of samples, the so-called sample means will be approximately normally distributed. So that says if I take a sample-- and remember, a sample will have multiple examples. So just to remind people. A population is a set of examples. A sample is a subset of the population. So it too is a set of examples, typically. If this set is sufficiently large-- certainly 1 is not sufficiently large-- then it will be the case that the mean of the means-- so I take the mean of each sample and then I can now plot all of those means and so take the mean of those, right-- and they'll be normally distributed. Furthermore, this distribution will have a mean that is close to the mean of the population. The mean of the means will be close to the mean of the population. And the variance of the sample means will be close to the variance of the population divided by the sample size. This is really amazing that this is true and dramatically useful. So to get some insight, let's check it. To do that, postulate that we have this kind of miraculous die. So instead of a die that when you roll it you get a number 1, 2, 3, 4, 5, or 6, this particular die is continuous. It gives you a real number between 0 and 5, or maybe it's between 1 and 6, OK? So it's a continuous die. What we're going to do is roll it a lot of times. We're going to say, how many die? And then, how many times are we going to roll that number of die? So the number of die will be the sample size-- number of dice will be the sample size. And then we'll take a bunch of samples which I'm calling number of rolls. And then we'll plot it and I'm just choosing some bins and some colors and some style and various other things just to show you how we use the keyword arguments. Actually, I said the number of rolls is the number of trials. But it isn't quite that because I'm going to get the number of trials by dividing the number of rolls by the number of dice. So if I have more dice, I get to have fewer samples, more dice per sample, all right? Then we'll just do it. So it will be between 0 and 5 because random.random returns a number between 0 and 1 and I'm multiplying it by 5. And then we'll look at the means and we'll plot it all. Again, we're playing games with weights just to make the plot a little easier to read. And here's what we get. If we roll one die, the mean is very close to 2.5. Well, that's certainly what you'd expect, right? It's some random number between 0 and 5. 2.5 is a pretty good guess as to what it should average. And it has a standard deviation of 1.44. And that's a little harder to guess that that's what it would be. But you could figure it out with a little math or as I did here with the simulation. But now, if I roll 50 dice, well, again, the mean is close to 2.5. It's what you'd expect, right? I roll 50 die, I get the mean value of those 50. But look how much smaller the standard deviation is. More importantly, what we see here is that if we look at the value, the probability is flat for all possible values between 0 and 5 for a single die. But if we look at the distribution for the means, it's not quite Gaussian but it's pretty close. Why is it not Gaussian? Well, I didn't do it an infinite number of times. Did it quite a few, but not an infinite number. Enough that you didn't want to sit here while it ran. But you can see the amazing thing here that when I go from looking at 1 to looking at the mean of 50, suddenly I have a normal distribution. And that means that I can bring to bear on the problem the Central Limit Theorem. We can try it for roulette. Again I'm not going to make you sit through a million trials of 200 spins each. I'll do it only for fair roulette. And again, this is a very simple simulation, and we'll see what we get. And what we see is it's not quite normal, again, but it definitely has that shape. Now, it's going to be a little bit strange because I can't lose more than one, if I'm betting one. So it will never be quite normal because it's going to be truncated down on the left side, whereas the tail can be arbitrarily long. So again, mathematically it can't be normal but it's close enough in the main region, where most of the values lie, that we can get away with applying the empirical rule and looking at answers. And indeed as we saw, it does work. So what's the moral here? It doesn't matter what the shape of the distribution of the original values happen to be. If we're trying to estimate the mean using samples that are sufficiently large, the CLT will allow us to use the empirical rule when computing confidence intervals. Even if we go back and look at this anomaly over in the left, what do you think would happen if I, instead of had 200, have, say, 1,000? What's the probability of the average return being minus 1 of 1,000 bets? Much smaller than for 100 bets. To lose 1,000 times in a row is pretty unlikely. So to get all the way to the left is going to be less likely, and, therefore, the thing will start looking more and more normal as the samples get bigger. All right, and so we can use the CLT to justify using the empirical rule when we compute confidence intervals. All right, I want to look at one more example in detail. This is kind of an interesting one. You might think that randomness is of no use for, say, finding the value of pi because there's nothing random about that. Similarly, you might think that randomness was of no use in integrating a function, but in fact, the way those numerical algorithms work is they use randomness. What you're about to see is that randomness, and indeed things related to Monte Carlo simulations, can be enormously useful, even when you're computing something that is inherently not random like the value of pi here. And we won't ask you to remember that many digits on the quiz and the exam. All right, so what's pi? Well, people have known about pi for thousands and thousands of years. And what people knew was that there was some constant, we'll call it pi. It wasn't always called that. Such that it was equal to the circumference of a circle divided by the diameter, and furthermore, the area was going to be pi r squared. People knew that way back to the Babylonians and the Egyptians. What they didn't know is what that value was. The earliest known estimate of pi was by the Egyptians, on something called the Rhind Papyrus pictured here.","65.61029815673828","9","DPRSearchEngine","rUxP7TM8-wo.en-qlPKC2UN_YU_7_mp4","rUxP7TM8-wo.en-qlPKC2UN_YU","6.0002","7"
"283","What is the purpose of the density method in the Food class?","  
 
Histogram of Entire  Population  
6.0002  LECTURE 8 
 
σ =  ~9.4 
9
","65.42269134521484","10","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_9_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"284","What is an optimization problem?","Many problems of practical importance can be formulated as optimization problems. Greedy algorithms often provide an adequate though often not optimal solution. Even though finding an optimal solution is, in theory, exponentially hard, dynamic programming really often yields great results. It always gives you a correct result and it's sometimes, in fact, most of the times gives it to you very quickly. Finally, in the PowerPoint, you'll find an interesting optimization problem","78.6780014038086","1","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_15_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"284","What is an optimization problem?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","77.14096069335938","2","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"284","What is an optimization problem?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","70.76708984375","3","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"284","What is an optimization problem?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","70.58856964111328","4","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"284","What is an optimization problem?","And that's cycle detection. So there's a bit of an exercise left to the reader here. So the problem that we're looking for now is that we're given a directed graph. There's a G in graph, in case you're wondering. But now, we don't know if it's a DAG or not. And so the question that we're trying to ask is, does there exist a cycle in our directed acyclic graph? So we're just given our graph, and we want to know, can we do this? Let's think through the logic of this a bit. So what do we know? We know that if our graph were a DAG, then I could call DGS, get the ordering out, and then I guess flip its ordering backwards. So I could compute the reverse finishing order. And it would give me a topological order of my graph. So if I were a DAG, I would get a topological order when I call DFS. So let's say that I ran DFS. I got whatever ordering I got. And now I found an edge the points in the wrong direction. I can just double check my list of edges, and I find one that does not respect the relationship that I see in the second bullet point here. Can my graph be a DAG? No. Because if my graph were a DAG, the algorithm would work. I just proved it to you. Right? So if my graph were a DAG, then I could do reverse finishing order. And what I would get back is a topological order. So if I found a certificate that my order wasn't topological, something went wrong, and the only thing that could go wrong is that my graph isn't a DAG. Yeah. Isn't a DAG. In fact, sort of an exercise left to the reader and/or to your section-- do we still have section? I think we do, as of now-- is that this is an if and only if, meaning that the only time that you even have a topological ordering in your graph is if your graph is a DAG. This is a really easy fact to sanity check, by the way. This is not like, a particularly challenging problem. But you should think through it because it's a good exercise to make sure you understand the definitions, which is to say that if you have a topological order, your graph is a DAG. If you don't have a topological order, your graph isn't a DAG. So in other words, we secretly gave you an algorithm for checking if a graph is a DAG at all. Right? What could I do? I could compute reverse finishing order. Check if it obeys the relationship on the second bullet point here for every edge. And if it does, then we're in good shape. My graph is a DAG. If it doesn't, something went wrong. And the only thing that could have gone wrong is not being a DAG. OK. So in other words, secretly we just solved-- well, I guess the way that I've written it here, we've solved the cycle detection problem here, which is to say that, well, I have a cycle if and only if I'm not a DAG, which I can check using this technique. Of course, the word ""detection"" here probably means that I actually want to find that cycle, and I haven't told you how to do that yet. All we know how to do so far is say, like, somewhere in this graph there's a cycle. And that's not so good. So we can do one additional piece of information in the two minutes we have remaining to sort of complete our story here, which is to modify our algorithm ever so slightly to not only say thumbs up, thumbs down, is there a cycle in this graph, but also to actually return the vertices as a cycle. And here's the property that we're going to do that, which is following, which is that if G contains a cycle, right, then full DFS will traverse an edge from a vertex v to some ancestor of v. I guess we haven't carefully defined the term ""ancestor"" here. Essentially, if you think of the sort of the running of the DFS algorithm, then an ancestor is like something that appears in the recursive call tree before I got to v. OK. So how could we prove that? Well, let's take a cycle. And we'll give it a name. In particular, we'll say that it's a cycle from v0 v1 to vk. And then it's a cycle, so it goes back to v0. OK. And I can order this cycle any way I want. Notice that if I permute the vertices in this list in a cyclical way, meaning that I take the last few of them and stick them at the beginning of the list, it's still a cycle. That's the nice thing about cycles. So in particular, without loss of generality, we're going to assume that v0 is the first vertex visited by DFS. What does that mean? That means, like, when I do my DFS algorithm making all these recursive calls, the very first vertex to be touched by this technique is v0. OK. Well, now what's going to end up happening? Well, think about the recursive call tree starting at v0. By the time that completes, anything that's reachable from v0 is also going to be complete. Do you see that? So for instance, v0 somewhere in its call tree might call v2. And notice that v2 was not already visited. So in fact, it will. For v1 I got to call v2 and so on. And in particular, we're going to get all the way to vertex k. Right? So in other words, we're going to visit a vertex vk. And notice what's going to happen. So remember our algorithm. In fact, we should probably just put it up on the screen would be easier than talking about it a bunch. Well, vk is now going to iterate over every one of the neighbors of vk. And in particular, it's going to see vertex v0. Right? So we're going to see the edge from vk to v0, which is an edge kind of by definition because we took this to be a cycle here. But notice that's exactly the thing we set out to prove, namely that full DFS traverses an edge from a vertex to one of its ancestors. Here's a vertex k. Here's the ancestor v0. Why do we know that it's an ancestor? Well, because v0 was called in our call tree before any of these other guys. Right? So we wanted an algorithm that not only did cycle detection, but also actually gave me the cycle. What could I do? Well, it's essentially a small modification of what we already have. Right. So-- whoops. Right. If I want to compute topological order or whatever, I can just do DFS. And that'll tell me like, yay or nay, does there exist a cycle. If I want to actually find that cycle, all I have to do is check that topological order property at the same time that it traversed the graph during DFS. And the second that I find an edge that loops back, I'm done. And so that's our basic algorithm here. And this is a technique for actually just finding the cycle in a graph using the DFS algorithm.","70.58386993408203","5","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_20_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"284","What is an optimization problem?"," 
 
 
 
  
 
 
  
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Intro to Complexity Theory 
Computability theory (1930s - 1950s): 
Is A decidable? 
Complexity theory (1960s - present): 
Is A decidable with restricted resources? 
(time/memory/…) 
Example: Let ! = a#b# $ ≥0 . 
Q: How many steps are needed to decide !? 
Depends on the input. 
We give an upper bound for all inputs of length '. 
Called “worst-case complexity”. 
2 
","70.33383178710938","6","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_2_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"284","What is an optimization problem?","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","69.79954528808594","7","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"284","What is an optimization problem?","you might find one way or the other more intuitive. They're equivalent. So as long as you understand at least one of them, it's good. NP is just a class of decision problems. So I define P and EXP and R arbitrary. They can be problems with any kind of output. But NP only makes sense for decision problems. And it's going to look almost like the definition of P-- problem solvable in polynomial time. We've just restricted to decision problems. But we're going to allow a strange kind of computer or algorithm, which I like to call a lucky algorithm. And this is going to relate to the notion of guessing that we talked about for the last four lectures in dynamic programming. With dynamic programming, we said, oh, there are all these different choices I could make. What's the right choice? I don't know, so I'd like to make a guess. And what that meant in terms of a real algorithm is, we tried all of the possibilities, and then took the max or the OR or whatever over all those possibilities. And so we were-- but what we were simulating is something that I call a lucky algorithm, which can make guesses and always makes the right guess. This is a computer that is impossible to buy. It would be great if you could buy a computer that's lucky. But we don't know how to build such a computer. So what does this mean? So informally, it means your algorithm can make lucky guesses, and it always makes the right guess. And whereas in DP, we had to try all the options and spend time for all of them, the lucky algorithm only has to spend time on the lucky guess, on the correct guess. More formally, this is called a non-deterministic model of computation. And this N is the-- the N in non-determinism is the N for NP. So this is non-deterministic polynomial time. So algorithm can make guesses. And then in the end, it should output yes or no. Like say if you're exploring a maze, this algorithm could say, should I go left or go right? I'm going to guess whether to go left or go right. And let's say it guesses left. And so then it just goes left. And then it reaches another junction. It says, should I go left or right? And it'll say, I'll guess, and it'll say, guess right this time. And in the end, if I get to some dead end maybe and I say no, or if I get to the destination I'm trying to get to, I say yes. So that's a non-deterministic algorithm. And what does it mean to run that algorithm? What does it mean for the guesses to be lucky? Here's what it means. These guesses are guaranteed-- which way you end up going is guaranteed to lead you to a yes if there is one-- if possible. So in my maze analogy, if my destination is reachable from my source, then I'm guaranteed, whenever I guessed left or right, I will choose a path that leads me to my destination. Whereas, if the destination is in some disconnected part of the maze and I can't get there, then I don't know what the guesses do. It doesn't really matter. Because no matter what I do, I'll end up in a dead end and say no. That's the model. As long as you have an algorithm that always outputs yes or no in polynomial time-- because we're only talking about polynomial time, lucky algorithms-- if there's any way to get to a yes, then your machine will magically find it without having to spend any time to make these decisions. So it's a pretty magical computer, and it's not a computer that exists in real life. But it's a computer that's great to program on. It's very powerful. You could solve lots of things with it. Yeah. AUDIENCE: If you had this magical computer, it can guess whether it's yes or no, why doesn't it just answer the question? ERIK DEMAINE: Right. So what if we-- so a nice check is, does this make all problems trivial, all decision problems? Maybe I should say, well, I don't know whether the answer to the problem is yes or no, so I'll just guess yes or no. This is problematic because-- so I might say, it will guess A or B, and if I choose the A option, I will output yes, and if I choose the B option, I will output no. In this model, that algorithm will always output yes. Because what it's saying is, if there's any way to get to a yes answer, I will do that way. And so such an algorithm that tries to cheat and just guess the whole answer to the problem will actually end up always saying yes, which means it doesn't solve a very interesting problem. It only solves the problem, which is represented by the bit vector 1111111, where all the answers are yes. But good check. Yeah. AUDIENCE: Does there have to be a bound of a number of things it has to choose between when it [AUDIO OUT] ERIK DEMAINE: Yes. AUDIENCE: Does it have an exponential number of them? ERIK DEMAINE: Exponential number of choices is OK. I usually like to think of it, as you can only guess one bit at a time. But we're allowed polynomial time, so you're actually allowed to guess polynomial number of bits. At that point, you can guess over an exponential size space, but not more than exponential. So it's-- yeah, polynomial time let's say in the one-bit guessing model. What did I say? Makes guesses-- let's add binary here. Otherwise we get some other class, which I don't want. OK, let's do an example, a real example of such an algorithm","69.7860107421875","8","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_6_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"284","What is an optimization problem?","There's not a bound on the number of edges for a shortest path, because I could just keep going around that cycle as many times as I want and get a shorter path. And so we assign those distances to be minus infinity. So that's what we're going to do today in Bellman-Ford. In particular, what we're going to do is compute our shortest path distances, the shortest path waits for every vertex in our graph, setting the ones that are not reachable to infinity, and the ones that are reachable through a negative weight cycle to minus infinity, and all other ones we're going to set to a finite weight. And another thing that we might want is if there's a negative weight cycle in the graph, let's return one. So those are the two kinds of things that we're trying to solve in today's lecture. But before we do that, let's warm up with two short exercises. The first one, exercise 1, given an undirected graph, given undirected graph G, return whether G contains a negative weight cycle. Anyone have an idea of how we can solve this in linear time, actually? In fact, we can do it in order E. No-- yes, yes. Reachable from S. I guess-- let's just say a negative weight cycle at all. Not in the context of single-source shortest paths.","69.76846313476562","9","DPRSearchEngine","f9cVS_URPc0.en-j3PyPqV-e1s_3_mp4","f9cVS_URPc0.en-j3PyPqV-e1s","6.006","12"
"284","What is an optimization problem?","§ Time based on number of nodes generated 
§ Number of levels is number of items to choose from 
§ Number of nodes at level i is 2i 
§ So, if there are n items the number of nodes is 
◦ ∑𝑖=0↑𝑖=𝑛▒​2↑𝑖   
◦ I.e., O(​2↑𝑛+1 ) 
§ An obvious op<miza<on: don’t explore parts of tree 
that violate constraint (e.g., too many calories) 
◦ Doesn’t change complexity 
§ Does this mean that brute force is never useful? 
◦ Let’s give it a try 
Computa#onal Complexity 
6.0002 LECTURE 2 
8 
","69.73678588867188","10","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_8_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"285","How do greedy algorithms perform in solving optimization problems?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","79.92112731933594","1","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"285","How do greedy algorithms perform in solving optimization problems?","Many problems of practical importance can be formulated as optimization problems. Greedy algorithms often provide an adequate though often not optimal solution. Even though finding an optimal solution is, in theory, exponentially hard, dynamic programming really often yields great results. It always gives you a correct result and it's sometimes, in fact, most of the times gives it to you very quickly. Finally, in the PowerPoint, you'll find an interesting optimization problem","78.56182861328125","2","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_15_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"285","How do greedy algorithms perform in solving optimization problems?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","76.57591247558594","3","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"285","How do greedy algorithms perform in solving optimization problems?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","74.91646575927734","4","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"285","How do greedy algorithms perform in solving optimization problems?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Clustering Algorithms  
§Hierarchical  clustering  
◦ Can select number  of clusters using dendogram 
◦ Deterministic 
◦ Flexible with respect to linkage criteria 
◦ Slow 
◦ Naïve algorithm n3 
◦ n2 algorithms exist for some linkage criteria 
§K-means a much faster greedy algorithm 
◦ Most useful when you know how many clusters  you want  
6.0002  LECTURE 12 
9 
","74.57987976074219","5","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_9_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"285","How do greedy algorithms perform in solving optimization problems?","The Pros and Cons of Greedy 
§ Easy to implement 
§ Computa<onally eﬃcient 
§ But does not always yield the best solu<on 
◦ Don’t even know how good the approxima<on is 
6.0002 LECTURE 2 
3 
Ques<on 1 
","74.3547134399414","6","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_3_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"285","How do greedy algorithms perform in solving optimization problems?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","72.73857879638672","7","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"285","How do greedy algorithms perform in solving optimization problems?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 4: Hashing 
Lecture 4: Hashing 
Review 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
• Idea! Want faster search and dynamic operations. Can we find(k) faster than Θ(log n)? 
• Answer is no (lower bound)! (But actually, yes...!?) 
Comparison Model 
• In this model, assume algorithm can only differentiate items via comparisons 
• Comparable items: black boxes only supporting comparisons between pairs 
• Comparisons are <, ≤, >, ≥, =, =6 , outputs are binary: True or False 
• Goal: Store a set of n comparable items, support find(k) operation 
• Running time is lower bounded by # comparisons performed, so count comparisons! 
Decision Tree 
• Any algorithm can be viewed as a decision tree of operations performed 
• An internal node represents a binary comparison, branching either True or False 
• For a comparison algorithm, the decision tree is binary (draw example) 
• A leaf represents algorithm termination, resulting in an algorithm output 
• A root-to-leaf path represents an execution of the algorithm on some input 
• Need at least one leaf for each algorithm output, so search requires ≥ n + 1 leaves 
","72.58181762695312","8","DPRSearchEngine","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_1_pdf","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4","6.006","4"
"285","How do greedy algorithms perform in solving optimization problems?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 5: Linear Sorting 
Lecture 5: Linear Sorting 
Review 
• Comparison search lower bound: any decision tree with n nodes has height ≥dlg(n+1)e−1 
• Can do faster using random access indexing: an operation with linear branching factor! 
• Direct access array is fast, but may use a lot of space (Θ(u)) 
• Solve space problem by mapping (hashing) key space u down to m = Θ(n) 
• Hash tables give expected O(1) time operations, amortized if dynamic 
• Expectation input-independent: choose hash function randomly from universal hash family 
• Data structure overview! 
• Last time we achieved faster ﬁnd. Can we also achieve faster sort? 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
Direct Access Array 
u 
1 
1 
u 
u 
Hash Table 
n(e) 
1(e) 
1(a)(e) 
n 
n 
","72.03572845458984","9","DPRSearchEngine","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5_1_pdf","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5","6.006","5"
"285","How do greedy algorithms perform in solving optimization problems?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 10: Depth-First Search 
Lecture 10: Depth-First Search 
Previously 
• Graph deﬁnitions (directed/undirected, simple, neighbors, degree) 
• Graph representations (Set mapping vertices to adjacency lists) 
• Paths and simple paths, path length, distance, shortest path 
• Graph Path Problems 
– Single Pair Reachability(G,s,t) 
– Single Source Reachability(G,s) 
– Single Pair Shortest Path(G,s,t) 
– Single Source Shortest Paths(G,s) (SSSP) 
• Breadth-First Search (BFS) 
– algorithm that solves Single Source Shortest Paths 
– with appropriate data structures, runs in O(|V | + |E|) time (linear in input size) 
Examples 
G1 
a 
d 
b 
e 
c 
f 
G2 
a 
d 
b 
e 
c 
f 
","71.14927673339844","10","DPRSearchEngine","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10_1_pdf","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10","6.006","10"
"286","Why is dynamic programming beneficial in optimization problems?","Many problems of practical importance can be formulated as optimization problems. Greedy algorithms often provide an adequate though often not optimal solution. Even though finding an optimal solution is, in theory, exponentially hard, dynamic programming really often yields great results. It always gives you a correct result and it's sometimes, in fact, most of the times gives it to you very quickly. Finally, in the PowerPoint, you'll find an interesting optimization problem","78.48751068115234","1","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_15_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"286","Why is dynamic programming beneficial in optimization problems?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","76.68927001953125","2","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"286","Why is dynamic programming beneficial in optimization problems?","Dynamic programming, while it was, in some sense, related to this graph material-- I'm constructing a graph-- I have to construct that graph. There's a creative process in trying to construct that graph. I don't give you a set of vertices. Usually what I give you are a set of-- a sequence or something like that. And you have to construct vertices, subproblems, that will be able to be related in a recursive way so you can solve the problem. This is a very much more difficult thing than these other things, I think, because there's a lot more creativity in this. In the same way that just applying-- reducing to the graph algorithms we have is fairly easy. But actually doing some graph transformations to change the shape of the graph so that you can apply these algorithms, that's a harder thing to do. The difficulty with these two sets of materials is very similar. Figuring out what the graph should be, figuring out what the subproblems should be and how they relate, is really the entire part of the-- the entire difficulty with solving problems recursively. And we've only given you a taste of solving problems recursively. In future classes, like 6.046, which is the follow-on to this one in the undergraduate curriculum, this is all about introduction to algorithms. The next one's about design and analysis of algorithms. It's quite a bit more difficult, because we've mostly left it to you to use the things that we gave you or make your own algorithms based on this very nice cookbook-like framework that you can plug in a recursive algorithm to. Now actually, that cookbook is super nice for any way of looking at a problem recursively, but while in dynamic programming, the inductive hypothesis of combining your subproblems is almost trivial, in other types of recursive algorithms, that's not necessarily the case. Especially when instead of looking at all possible choices, for example, in a greedy algorithm where you're just looking at one of the choices, the locally best thing, and recursing forward, you're not doing all the work. You're not locally brute-forcing. Your locally picking an optimal thing locally and hoping that will lead you to good thing. That's a much harder algorithmic paradigm to operate under. And so that's more like the material that you'll be talking about in 6.046. So that's 006, a very quick overview of the content of this class. And we really like the structure of how this class is laid out, because it gives you a fundamental idea of the things people use to store information on a computer and a sense of how you solve problems computationally and how to argue that they're correct and efficient. That's really what this problem-- this course is about. And if you feel like you enjoy this kind of stuff, that's where you go to take 6.046. And 6.046 was actually the first algorithms class I ever took here at MIT, as a grad student actually. This was hard for me. It's actually hard to look at these problems, these types, and think in a computational way, especially having not taken this class, 6.006. So hopefully you guys are all in a better position than I was when I took it. There's two ways I like to think of the content in 6.046. One is kind of just as an extension of 006. It's the natural follow-on to the things that we do in this class. They still talk about data structures. This isn't the core part of 046, but they do touch on data structures for more complicated-- that have more complicated analyses involved in them. It's really about-- usually in 046, stating what the algorithm is doing is not so hard. Basically, giving you the algorithm, number one here, is not so difficult, to state what's happening in the algorithm. But the number two and number three here, arguing that that thing is correct and arguing that thing is efficient, that's where the complexity comes in in 046. The analysis part is quite a bit more complicated in 046 than in 006. So they solve a problem called union-find and give a much-- we talked a little bit about amortization. This goes into a much better-- a much more formal way of proving things run in amortized time. So this is basically amortization via what we call a potential analysis. It's basically making that notion that we talked about when we were talking about dynamic arrays of, we're not doing this expensive thing too often. Basically what we do is we keep track of the cost of all sequence of operations and prove that the average cost is small. That's kind of what this potential analysis is doing. It's a little bit more formal process for making that argument a little more formal. Right. OK. So then on the graph side, this is kind of an extension of quiz 1-type material.","73.76165008544922","3","DPRSearchEngine","2NMtS1ecb3o.en-j3PyPqV-e1s_5_mp4","2NMtS1ecb3o.en-j3PyPqV-e1s","6.006","20"
"286","Why is dynamic programming beneficial in optimization problems?","Why did Bellman call dynamic programming dynamic programming? Mostly because it sounded cool, and he was trying to impress government agencies giving him grants. I mean, how can you argue with something as cool-sounding as dynamic programming? But there is some logic to it. Programming is a reference to an old form of this word, which means optimization. And generally, we're trying to optimize things. And instead of optimizing according to some static kind of approach or program, we're doing it dynamically. This is a reference to the local brute force we're doing to optimize at each stage. You can't tell, at the top, what you're going to do in the middle. And so it's kind of-- each subproblem is behaving differently. And so, in that sense, dynamic. And it sounds cool. All right. Then we'll go to all-pairs shortest paths. We'll see a new algorithm for that that's not asymptotically any better, but it's nice and simple, and another way to-- a cool way to see subproblem expansion. And then we'll look at a couple of sort of practical problems-- parenthesizing arithmetic expressions and a real-world problem, piano and guitar fingering, so assigning a fingering how to play a piece. And we're going to do that with our SRTBOT framework. Quick recollection of what that is. We define subproblems. And we saw how to do that for sequences. We try either prefixes, suffixes, or substrings. We prefer prefixes and suffixes because there's fewer of them. If there's more than one sequence, we take the product of those spaces. And then the idea we're going to stress today is, we can always add subproblems","72.79463195800781","4","DPRSearchEngine","TDo3r5M1LNo.en-j3PyPqV-e1s_2_mp4","TDo3r5M1LNo.en-j3PyPqV-e1s","6.006","17"
"286","Why is dynamic programming beneficial in optimization problems?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","72.23079681396484","5","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"286","Why is dynamic programming beneficial in optimization problems?"," 
 
 
 
  
 
 
  
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Intro to Complexity Theory 
Computability theory (1930s - 1950s): 
Is A decidable? 
Complexity theory (1960s - present): 
Is A decidable with restricted resources? 
(time/memory/…) 
Example: Let ! = a#b# $ ≥0 . 
Q: How many steps are needed to decide !? 
Depends on the input. 
We give an upper bound for all inputs of length '. 
Called “worst-case complexity”. 
2 
","71.76570129394531","6","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_2_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"286","Why is dynamic programming beneficial in optimization problems?"," 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
Modeling the  World  
§Models  always  inaccurate
◦Provide abstractions of reality
§Deterministic models, e.g., graph theoretic
§Statistical models
◦Simulation models: Monte Carlo simulation
◦Models  based on sampling
◦Characterizing accuracy is critical
◦Central limit theorem
◦Empirical rule
◦Machine learning
◦Unsupervised and supervised
§Presentation of data
◦Plotting
◦Good and bad practices
6.0002  LECTURE 15 
21 
","71.57405090332031","7","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_18_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"286","Why is dynamic programming beneficial in optimization problems?","§ Problem is exponen<al 
§ Have we overturned the laws of the universe? 
§ Is dynamic programming a miracle? 
§ No, but computa<onal complexity can be subtle 
§ Running <me of fastMaxVal is governed by number of 
dis<nct pairs, <toConsider, avail> 
◦Number of possible values of toConsider bounded 
by len(items)
◦Possible values of avail a bit harder to characterize 
◦Bounded by number of dis<nct sums of weights 
◦Covered in more detail in assigned reading 
How Can This Be? 
6.0002 LECTURE 2 
30 
","70.952880859375","8","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_30_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"286","Why is dynamic programming beneficial in optimization problems?","4 
Lecture 15: Recursive Algorithms 
Dynamic Programming 
• Weird name coined by Richard Bellman 
– Wanted government funding, needed cool name to disguise doing mathematics! 
– Updating (dynamic) a plan or schedule (program) 
• Existence of recursive solution implies decomposable subproblems1 
• Recursive algorithm implies a graph of computation 
• Dynamic programming if subproblem dependencies overlap (DAG, in-degree > 1) 
• “Recurse but re-use” (Top down: record and lookup subproblem solutions) 
• “Careful brute force” (Bottom up: do each subproblem in order) 
• Often useful for counting/optimization problems: almost trivially correct recurrences 
How to Solve a Problem Recursively (SRT BOT) 
1. Subproblem deﬁnition 
subproblem x ∈ X 
• Describe the meaning of a subproblem in words, in terms of parameters 
• Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence 
• Often record partial state: add subproblems by incrementing some auxiliary variables 
2. Relate subproblem solutions recursively 
x(i) = f(x(j), . . .) for one or more j < i 
3. Topological order to argue relation is acyclic and subproblems form a DAG 
4. Base cases 
• State solutions for all (reachable) independent subproblems where relation breaks down 
5. Original problem 
• Show how to compute solution to original problem from solutions to subproblem(s) 
• Possibly use parent pointers to recover actual solution, not just objective function 
6. Time analysis 
P 
• 
work(x), or if work(x) = O(W ) for all x ∈ X, then |X| · O(W )
x∈X 
• work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time 
1This property often called optimal substructure. It is a property of recursion, not just dynamic programming 
","70.83932495117188","9","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_4_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"286","Why is dynamic programming beneficial in optimization problems?","And dynamic programming is going to build on this template by adding one new idea called memoization, which is just the idea of reusing work that you've done before. And that's going to let us solve tons of problems. And let's see. I don't-- let's get into it. So we'll start out today with SRTBOT. So here is SRTBOT down the column here. This is a recursive algorithm design paradigm. And in general, what we're going to do is take the problem that we actually want to solve and split it up into lots of possible sub problems. And so the first part is to define what the heck are the subproblems. In general, we'll want some polynomial number of them. But it's pretty open-ended what these look like. And the hardest part, usually, in defining a recursive algorithm is figuring out what the sub problems should be. Usually they're related to the problem you want to solve. Often the problem you want to solve-- this is actually near the last step-- the original problem you're trying to solve is often one of these sub problems. And then you use the smaller sub problems in order to build up the final, original problem. But sometimes at the end, you need to take a bunch of subproblems and combine them into your original problem. You can think-- one analogy you can think of here is divide and conquer algorithms, which also had this kind of style. But more generally, we're going to relate different sub problem solutions with some recursive structure-- some recurrence relation. This is just a recursive algorithm that defines how to solve one problem in terms of smaller sub-problems for some notion of smaller. And this is given by the topological order. So if we think of the subproblems as a graph and we draw an edge between-- so the vertices of the graph are sub problems. The edges are the dependencies between those subproblems. Then what we'd like is the topological ordering, the topological sort problem we talked about in the context of DFS or DAG shortest paths. What we would like is that the subproblems and the calls-- the recursive calls between them in this recursive relation-- forms a DAG. We want it to be acyclic, otherwise you have an infinite loop in your recursive calls. If you have a cycle, you'll never terminate. And so to make sure that these dependencies between subproblems given by this recurrence relation is acyclic, one way to do that is to specify a topological order. Or you could prove it some other way. But often it's just a for loop to say, just do it in this order. Then of course any recursive structure needs base cases. So that's a useful step not to forget. We want to solve the original problem using these sub problems. And then we analyze a running time at the end. So six easy steps. Actually, the hardest ones are these two, which are interrelated. And what we're going to see over the next four lectures-- this is the first of four lectures on dynamic programming-- is lots of examples of applying this paradigm over and over together with the memoization idea, which we'll get to soon.","70.63334655761719","10","DPRSearchEngine","r4-cftqTcdI.en-j3PyPqV-e1s_2_mp4","r4-cftqTcdI.en-j3PyPqV-e1s","6.006","15"
"287","What is the purpose of creating a table for storing computed values in optimization problems?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","75.39434814453125","1","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"287","What is the purpose of creating a table for storing computed values in optimization problems?","Many problems of practical importance can be formulated as optimization problems. Greedy algorithms often provide an adequate though often not optimal solution. Even though finding an optimal solution is, in theory, exponentially hard, dynamic programming really often yields great results. It always gives you a correct result and it's sometimes, in fact, most of the times gives it to you very quickly. Finally, in the PowerPoint, you'll find an interesting optimization problem","73.82176971435547","2","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_15_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"287","What is the purpose of creating a table for storing computed values in optimization problems?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","73.55608367919922","3","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"287","What is the purpose of creating a table for storing computed values in optimization problems?","which, I think, most of us would agree was not a very big number. And let's look what's going on here. If you look at this, what in some sense seems really stupid about it? What is it doing that a rational person would not want to do if they could avoid it? It's bad enough to do something once. But to do the same thing over and over again is really wasteful. And if we look at this, we'll see, for example, that fib 4 is being computed here, and fib 4 is being computed here. Fib 3 is being considered here, and here, and here. And do you think we'll get a different answer for fib 3 in one place when we get it in the other place? You sure hope not. So you think, well, what should we do about this? How would we go about avoiding doing the same work over and over again? And there's kind of an obvious answer, and that answer is at the heart of dynamic programming. What's the answer? AUDIENCE: [INAUDIBLE] JOHN GUTTAG: Exactly. And I'm really happy that someone in the front row answered the question because I can throw it that far. You store the answer and then look it up when you need it. Because we know that we can look things up very quickly. Dictionary, despite what Eric said in his lecture, almost all the time works in constant time if you make it big enough, and it usually is in Python. We'll see later in the term how to do that trick. So you store it and then you'd never have to compute it again. And that's the basic trick behind dynamic programming. And it's something called memoization, as in you create a memo and you store it in the memo. So we see this here. Notice that what we're doing is trading time for space. It takes some space to store the old results, but negligible related to the time we save. So here's the trick. We're going to create a table to record what we've done. And then before computing fib of x, we'll check if the value has already been computed. If so, we just look it up and return it. Otherwise, we'll compute it-- it's the first time-- and store it in the table. Here is a fast implementation of Fibonacci that does that. It looks like the old one, except it's got an extra argument-- memo-- which is a dictionary. The first time we call it, the memo will be empty. It tries to return the value in the memo. If it's not there, an exception will get raised, we know that.","73.19259643554688","4","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_9_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"287","What is the purpose of creating a table for storing computed values in optimization problems?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Monte Carlo Simulation  
A method of estimating the value of an unknown 
quantity using the principles of inferential statistics 
Inferential statistics 
◦ Population: a set of examples 
◦ Sample: a proper subset of a population 
◦ Key fact: a random sample tends to exhibit the same  
properties as the population from which it is drawn  
Exactly what we did with random walks 
6.0002 LECTURE 6 
4
","73.19011688232422","5","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_4_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"287","What is the purpose of creating a table for storing computed values in optimization problems?","So what we're going to do, because we're in place, basically we have to have an array storing our end items. That's sort of the definition of in-place, just using n slots of memory exactly the size of the number of items in our structure. But we're obviously not going to use a regular unsorted array or a regular sorted array. We're going to use array just as sort of the underlying technology for how things are stored. But we'd really like logarithmic performance, which should make you think tree. Only way to get a log is the binary tree, more or less. So somehow, we want to embed a tree into an array. Let me grab an example.","72.85281372070312","6","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_6_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"287","What is the purpose of creating a table for storing computed values in optimization problems?","The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. PROFESSOR: Welcome back. Over the last couple of lectures, we've been looking at optimization models. And the idea was how do I find a way to optimize an objective function-- it could be minimize it or maximize it-- relative to a set of constraints? And we saw, or Professor Guttag showed you, one of the ways that naturally falls out is by looking at trees, decision trees, where you pass your way through a tree trying to figure out how to optimize that model. So today, we're going to generalize those trees into another whole broad class of models called graph theoretic or graph models. And we're going to use those to again look at how do we can do optimization on those kinds of models. Just to remind you, there is a great piece of information in the text. There's the reading for today. And these will, of course, be in the slides that you can download. So let's take a second just to reset again what are we trying to do? Generally, we're trying to build computational models. So what does that mean? The same way we could do a physical experiment, or a social experiment, or model, if you like, a physical system and a social system, to both try and gather data and analyze it or to do predictions. We want to do the same thing computationally. We'd like to be able to build models in code that we can then run to predict effects, which we then might test with an actual physical experiment. And we've seen, for example, how you could take just the informal problem of choosing what to eat and turning it into an optimization problem-- in this case, it was a version of something we called a knapsack problem-- and how you could then use that to find code to solve it. And you've already seen two different general methods. You've seen greedy algorithms that just try and do the best thing at each stage. And you saw dynamic programming as an elegant solution to finding better ways to optimize this. We're going to now look at broadening the class of models to talk about graphs. So, obvious question is, what's a graph? And a graph has two elements, two components. It has a set of nodes, sometimes called vertices. Those nodes probably are going to have some information associated with them. It could be as simple as it's a name. It could be more complicated. A node might represent a student record-- the grades. And a graph might talk about putting together all of the grades for a class. Associated with that, we can't just-- well, I should say, we could just have nodes, but that's kind of boring. We want to know what are the connections between the elements in my system? And so the second thing we're going to have is what we call edges, sometimes called arcs. And an edge will connect a pair of nodes. We're going to see two different ways in which we could build graphs using edges. The first one, the simple one, is an edge is going to be undirected. And actually, I should show this to you. So there is the idea of just nodes. Those nodes, as I said, might have information in them, just labels or names. They might have other information in them. When I want to connect them up, the connections could be undirected. If you want to think of it this way, it goes both ways. An edge connects two nodes together, and that allows sharing of information between both of them. In some cases, we're going to see that we actually want to use what we call a directed graph, sometimes called a digraph, in which case the edge has a direction from a source to a destination, or sometimes from a parent to a child. And in this case, the information can only flow from the source to the child. Now in the case I've drawn here, it looks like there's only ever a single directed edge between nodes. I could, in fact, have them going both directions, from source to destination and a separate directed edge coming from the destination back to the source. And we'll see some examples of that. But I'm going to have edges. Final thing is, those edges could just be connections. But in some cases, we're going to put information on the edges, for example, weights. The weight might tell me how much effort is it going to take me to go from a source to a destination. And one of the things you're going to see as I want to think about how do I pass through this graph, finding a path from one place to another, for example, minimizing the cost associated with passing through the edges? Or how do I simply find a connection between two nodes in this graph? So graphs, composed of vertices or nodes, they're composed of edges or arcs. So why might we want them? Well, we're going to see-- and you can probably already guess-- there are lots of really useful relationships between entities. I might want to take a European vacation. After November 8, I might really want to take a European vacation. So I'd like to know, what are the possible ways by rail I can get from Paris to London? Well, I could pull out the schedule and look at it. But you could imagine, I hope, thinking about this as a graph. The nodes would be cities. The links would be rail links between them. And then, one of the things I might like to know is, first of all, can I get from Paris to London? And then secondly, what's the fastest way to do it or the cheapest way to do it? So I'd like to explore that. Second example, as you can see on the list, drug discovery, modeling of complex molecule in terms of the relationships between the pieces inside of it and then asking questions like, what kind of energy would it take to convert this molecule into a different molecule? And how might I think about that as a graph problem? Third and obvious one, ancestral relationships, family trees. In most families, almost all families, they really are trees not graphs. Hopefully you don't come from a family that has strange loops in them. But family trees are-- I know, I'm in trouble here today. Aren't I? Family trees-- stay with me-- are a great demonstration of relationships because there its directional edges. Right? Parents have children. Those children have children. And like I say, it comes in a natural way of thinking about traversing things in that tree. And in fact, trees are a special case of a graph. You've already seen decision trees in the last lecture. But basically, a special kind of directed graph is a tree. And the property of the tree is, as it says there, any pair of nodes are connected, if they are connected, by only a single path. There are no loops. There are no ways to go from one node, find a set of things that brings you back to that node. You can only have a single path to those points. And Professor Guttag used this, for example, to talk about solving the knapsack problem. A decision trees is a really nice way of finding that solution. Now, I drew it this way. In computer science, we mostly use Australian trees. They're upside down. The roots are at the top. The leaves are at the bottom, because we want to think about starting at the beginning of the tree, which is typically something we call the root and traversing it. But however you use it, trees are going to be a useful way of actually thinking about representing particular kinds of graphs. OK. So, when I talk in a second about how to build graphs, well let's spend just a second about saying, so why are they useful? And if you think about it, the world is full of lots of networks that are based on relationships that could be captured by a graph. We use them all the time. Some of you are using them right now-- computer networks. You want to send an email message from your machine to your friend at Stanford. That's going to get routed through a set of links to get there. So the network set up by a series of routers that pass it along, sending something requires an algorithm that figures out the best way to actually move that around. There's a great local company started by an MIT professor called Akamai that thinks about how do you move web content around on the web? Again, it's a nice computer network problem. I've already talked about this. We're going to do some other examples. Transportation networks-- here, if you think about it, obvious thing is make the nodes cities. Make the edges roads between them. And now questions are, can I get to San Jose, if you like old songs? And what's the best way to get to San Jose, even if you don't like old songs? A network problem-- how do I analyze it? Financial networks-- moving money around-- easily modeled by a graph. Traditional networks-- sewer, water, electrical, anything that distributes content, if you like, and the different kind of content in this way around. You want to model that in terms of how you think about flows in those networks. How do I maximize distribution of water in an appropriate way, given I've got certain capacities on different pipes, which would mean those edges in the graph would have different weights? And you get the idea-- political networks, criminal networks, social networks. One of the things we're going to see with graphs is that they can capture interesting relationships. So here's an example. It's from that little web site you can see there. You're welcome to go look at it. And this is a graph analyzing The Wizard of Oz. And what's been done here is the size of the node reflects the number of scenes in which a character shares dialog. So you can see, obviously Dorothy is the biggest node there. The edges represent shared dialog, so you can see who talks to whom in this graph. And then, this group has done another thing, which I'm going to mention. We're not going to solve today, which is you can also do analysis on the graphs. And in fact, the color here has done something called a min-flow or max-cut problem, which is it's tried to identify which clusters in the graph tend to have a lot of interactions within that cluster but not very many with other clusters. And you can kind of see. There's some nice things here, right, if you can read it. This is all the people in Kansas. This is Glenda and the Munchkins in that part of Oz. There's another little cluster over here that I can't read and a little cluster over there. And then the big cluster down here. But you can analyze the graph to pull out pieces on it. You can also notice, by the way, the book is probably misnamed. It's called The Wizard of Oz. But notice, there's the wizard, who actually doesn't have a lot of interaction with the other people in this story. It's OK, literary choice. But the graph is representing interactions. And I could imagine searching that graph to try and figure out things about what goes on in The Wizard of Oz. OK. So why are they useful? We're going to see that not only do graphs capture relationships in these connected networks, but they're going to support inference. They're going to be able to reason about them. And I want to set that up. And then we'll actually look at how might we build a graph. And so here are some ways in which I might want to do inference. Given a graph, I might say, is there a sequence of edges, of links, between two elements? Is there a way to get from A to B? What are the sequence of edges I would use to get there? A more interesting question is, can I find the least expensive path, also known as the shortest path? If I want to get from Paris to London, I might like to do it in the least amount of time. What are the set of choices I want to make to get there? A third graph problem used a lot is called the graph partition problem. Everything I've shown so far-- actually not quite. The first example didn't have it. You might think of all the nodes having some connection to every other node. But that may not be true. There may actually be graphs where I've got a set of connected elements and another component with no connections between them. Can I find those? That's called the graph partition problem. How do I separate the graph out into connected sets of elements? And then the one that we just showed called the min-cut max-flow problem, is is there an efficient way to separate out the highly connected elements, the things that interact a lot, and separate out how many of those kinds of subgraphs, if you like, are there inside of my graph? All right, let me show you a motivation for graphs. And then we'll build them. I use graph theory everyday. I'm a math nut. It's OK, but I use graph theory everyday. You may as well, if you commute. Because I use it to figure out how to get from my home in Lexington down here to Cambridge. And I use a nice little system called Waze It's a great way of doing this, which does graph theory inside of it. So how do I get to my office? Well, I'm going to model the road system using a directed graph, a digraph. Directed graph because streets can be one way. And so I may only have a single direction there. And the idea is, I'm going to simply let my nodes or my vertices be points where I have intersections. They're places where I can make a choice or places where I have terminals, things I'm going to end up in. The edges would just be the connections between points, the roads on which I can drive. Some Boston drivers have a different kind of digraph in which they don't care whether that road is drivable or not. They just go on it. You may have seen some of these. But I want to keep my graphs as real roads that I can drive on. And I'm not going to go against the ""One Way"" sign. Each edge will have a weight. Here I actually have some choices. All right, the obvious one, the one that Waze probably uses, is something like what's the expected time between a source and a destination node? How long do I expect it to take me to get from this point to that? And then, as you can see, I'm going to try and find overall what's the best way to get around it. You could pick just distance. What's the distance between the two? And while there there's a relationship here, it's not direct because it will depend on traffic on it. Or you could take something even funkier like what's the average speed of travel between the source and destination node? And once I've got the graph, then I'm going to solve an optimization problem. What's the shortest weight between my house and my office that gets me into work? You can make a choice here. As I said, a commercial system like Waze uses this one. My wife and I actually have arguments about commuting because she's a firm believer in the second one, just shortest distance. I actually like the third one because I get anxious when I'm driving. And so as long as I feel like I'm making progress, I like it. So even though I may be serpentining all the way through the back roads of Cambridge, if I'm driving fast, I feel like I'm getting there. So I like optimizing this bottom one down there. And if you see me on the road, you'll know why I say that, and then get out of the way. Thinking about navigation through systems actually gives us a little bit of history because, in fact, the very first reported use of graph theory was exactly this problem. Early 1700s, it's called the Bridges of Koenigsberg. Koenigsberg is a city that has a set of islands and rivers in it. There are seven bridges that connect up those islands. And the question that was posed is, is it possible to take a walk that traverses each of the seven bridges exactly once? So could you take a walk where you go over each bridge exactly once? I'm showing you this because it lets us think about how to in fact capture things in a model. This problem was solved by a great Swiss mathematician, Leonhard Euler. And here's what he said. Make each island a node. Each bridge is just an undirected edge. And notice in doing that, he's abstracted away irrelevant details. You don't care what the size of the island is. You don't care how long the bridges are. You simply want to think about what are the connections here? And then you can ask a question. In this graph, is it possible to find a way to walk through it so that you go through each edge exactly once? And as Euler showed, the answer is no. And if you're curious, go look it up on Wikipedia. There's a nice, elegant solution to why that's the case. But here's what we're going to do. We're going to use those graphs to think about these kinds of problems. And in fact, the example I'm going to show you are going to be shortest path problems. So with that, let's turn to actually building a graph and then thinking about how we're going to use it. So we're going to start by constructing graphs. And then what we're going to do is show how we can build search algorithms on top of those graphs. And I hope that that flicker is going to go away here soon. Here we go. So to build a graph-- actually, I shouldn't have put this slide up so fast. I've got lots of choices here. If I'm thinking about maps, one way to build a graph would really to just be build something with latitude and longitude on it. But as we've already seen, we'd like to extract things away from the graphs. And so a natural choice is to say, let's represent the nodes in the graph just as objects. I'm going to use classes for these. So here's my definition of a node. It's pretty straightforward. I'm going to assume that the only information for now I store in a node is just a name, which I'm going to assume is a string. So I've got a class definition for node. It inherits from the base Python object class. I need ways to create instances of nodes, so I've got an init function. And I'm simply going to store inside each instance, in other words, inside of self, under the variable name, whatever I passed in as the name of that node. Of course, if I've got ways to create things with a name, I need to get them back out. So I've got a way of selecting it back out. If I ask an instance of a node, what's your name? By calling getName it will return that value. And to print things out, I'm just going to print out the name. This is pretty straightforward. And this, of course, lets me now create as many nodes as I would like. Edges? Well, an edge connects up two nodes. So again, I can do a fairly straightforward construction of a class. Again, it's going to inherit from the base Python object. To create an instance of an edge, I'm going to make an assumption, an important one which we're going to come back to. And the assumption is that the arguments passed in, source and destination, are nodes-- not names-- the nodes themselves, the actual instances of the object class. And what will I do? Inside of the edge, I'm going to set internal variables. For each instance of the edge, source and destination are going to point to those nodes, to those objects that I created out of the node class. Next two things are straightforward. I can get those things back out.","72.43221282958984","7","DPRSearchEngine","V_TulH374hw.en-qlPKC2UN_YU_1_mp4","V_TulH374hw.en-qlPKC2UN_YU","6.0002","3"
"287","What is the purpose of creating a table for storing computed values in optimization problems?","What's the worst case performance of a hash table? If I have to look up something in a hash table, and I happen to choose a bad hash table-- hash function, what's the worst case here? What? n, right? It's worse than a sorted array, because potentially, I hashed everything that I was storing to the same index in my hash table, and to be able to distinguish between them, I can't do anything more than a linear search. I could store another set's data structure as my chain and do better that way. That's actually how Java does it. They store a data structure we're going to be talking about next week as the chains so that they can get, worst case, log n. But in general, that hash table is only good if we're allowing-- OK, I want this to be expected good, but in the worst case, if I really need that operation to be worst case-- I really can't afford linear time ever for an operation of that kind-- then I don't want to use a hash table. And so on your p set 2, everything we ask you for is worst case, so probably, you don't want to be using hash tables. OK? Yes? AUDIENCE: What does the subscript e mean? JASON KU: What does the subscript e mean? That's great. In this chart, I put a subscript on this is an expected runtime, or an A meaning this is an amortized runtime. At the end, we talked about how, if we had too many things in our hash table, then, as long as we didn't do it too often-- this is a little hand wavey argument, but the same kinds of ideas as the dynamic array-- if, whenever we got a linear-- we are more than a linear factor away from where we are trying-- basically, the fill factor we were trying to be, then we could just completely rebuild the hash table with the new hash function randomly chosen from our hash table with a new size, and we could get amortized bounds. And so that's what Python-- how Python implements dictionaries, or sets, or even objects when it's trying to map keys to different things. So that's hash tables. That's great. The key thing here is, well, actually, if your range of keys is small, or if you as a programmer have the ability to choose the keys that you identify your objects with, you can actually choose that range to be small, to be linear, to be small with respect to your items. And you don't need a hash table. You can just use a direct access array, because if you know your key space is small, that's great. So a lot of C programmers probably would like to do something like that, because they don't have access to-- maybe C++ programmers would have access to their hash table. Any questions on this stuff before we move on? Yeah? AUDIENCE: So why is [INAUDIBLE]? JASON KU: Why is it expected? When I'm building, I could insert-- I'm inserting these things from x 1 by 1 into my hash table. Each of those insert operations-- I'm looking up to see whether that-- an item with that key already exists in my hash table. And so I have to look down the chain to see where it is. However, if I happen to know that all of my keys are unique in my input, all the items I'm trying to store are unique, then I don't have to do that check and I can get worst case linear time. Does that make sense? All right. It's a subtlety, but that's a great question. OK, so today, instead of talking about searching, we're talking about sorting. Last week, we saw a few ways to do sort. Some of them were quadratic-- insertion sort and selection sort-- and then we had one that was n log n. And this thing, n log n, seemed pretty good, but can I do better? Can I do better? Well, what we're going to show at the beginning of this class is, in this comparison model, no. n log n is optimal. And we're going to go through the exact same line of reasoning that we had last week. So in the comparison model, what did we use when we were trying to make this argument that any comparison model algorithm was going to take at least log n time? What we did was we said, OK, I can think of any model in the comparison model-- any algorithm in the comparison model as kind of this-- some comparisons happen. They branch in a binary sense, but you could have it generalized to any constant branching factor. But for our purposes, binary's fine. And what we said was that there were at least n outputs-- really n plus 1, but-- at least order n outputs. And we showed that-- or we argued to you that the height of this tree had to be at least log n-- log the number of leaves. It had to be at least log the number of leaves. That was the height of the decision tree. And if this decision tree represented a search algorithm, I had to walk down and perform these comparisons in order, reach a leaf where I would output something. If the minimum height of any binary tree on a linear number of leaves is log n, then any algorithm in the comparison model also has to take log n time, because it has to do that many comparisons to differentiate between all possible outputs. Does that make sense? All right. So in the sort problem, how many possible outputs are there?","72.18465423583984","8","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_4_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"287","What is the purpose of creating a table for storing computed values in optimization problems?","we're not going to put the drunk in. We're going to raise a value error, ""Duplicate drunk."" Otherwise we're going to set the value of drunkenness mapping to loc. Now you see, by the way, why I wanted drunks to be immutable. Because they have to be hashable so I can use them as a key in a dictionary. So it was not an idle question whether they were immutable. It was an important question. I can get the location of a drunk. If the drunk is not in there, then I'll raise a different value error, ""Drunk not in field."" Otherwise I'll return the location associated with that drunk. And finally, we're going to have moveDrunk.","71.99958038330078","9","DPRSearchEngine","6wUD_gp5WeE.en-qlPKC2UN_YU_9_mp4","6wUD_gp5WeE.en-qlPKC2UN_YU","6.0002","5"
"287","What is the purpose of creating a table for storing computed values in optimization problems?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","71.87588500976562","10","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"288","What advantage does using an array have over a list when performing mathematical operations on data?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","76.66870880126953","1","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"288","What advantage does using an array have over a list when performing mathematical operations on data?","to this interface problem-- the natural solution-- is what I'll call a static array. Jason mentioned these in lecture one. It's a little tricky because there are no static arrays in Python. There are only dynamic arrays, which is something we will get to. But I want to talk about, what is a static array, really? And this relates to our notion of-- our model of computation, Jason also talked about, which we call the word RAM, remember? The idea, in word RAM, is that your memory is an array of w-bit words. This is a bit circular. I'm going to define an array in terms of the word RAM, which is defined in terms of arrays. But I think you know the idea. So we have a big memory which goes off to infinity, maybe. It's divided into words. Each word here is w bits long. This is word 0, word 1, word 2. And you can access this array randomly-- random access memory. So I can give you the number 5 and get 0 1, 2, 3, 4, 5, the fifth word in this RAM. That's how actual memories work. You can access any of them equally quickly. OK, so that's memory. And so what we want to do is, when we say an array, we want this to be a consecutive chunk of memory. Let me get color. Let's say I have an array of size 4 and it lives here. Jason can't spell, but I can't count. So I think that's four. We've got-- so the array starts here and it ends over here. It's of size 4. And it's consecutive, which means, if I want to access the array at position-- at index i, then this is the same thing as accessing my memory array at position-- wherever the array starts, which I'll call the address of the array-- in Python, this is ID of array-- plus i. OK. This is just simple offset arithmetic. If I want to know the 0th item of the array, it's right here, where it starts. The first item is one after that. The second item is one after that. So as long as I store my array consecutively in memory, I can access the array in constant time. I can do get_at and set_at as quickly as I can randomly access the memory and get value-- or set a value-- which we're assuming is constant time. My array access is constant time. This is what allows a static array to actually solve this problem in constant time per get_at and set_at operation. This may seem simple, but we're really going to need this model and really rely on this model increasingly as we get to more interesting data structures. This is the first time we're actually needing it. Let's see. Length is also constant time. We're just going to store that number n, along with its address. And build is going to take linear time. Iteration will take linear time. Pretty straightforward. I guess one thing here, when defining build, I need to introduce a little bit more of our model of computation, which is, how do you create an array in the beginning? I claim I could do it in linear time, but that's just part of the model. This is called the memory allocation model. There are a few possible choices here, but the cleanest one is just to assume that you can allocate an array of size n in theta n time. So it takes linear time to make an array of size n. You could imagine this being constant. It doesn't really matter much. But it does take work. And in particular, if you just allocate some chunk of memory, you have no idea whether it's initialized. So initializing that array to 0s will cost linear time. It won't really matter, constant versus linear, but a nice side effect of this model is that space-- if you're just allocating arrays, the amount of space you use is, at most, the amount of time you use. Or, I guess, big O of that. So that's a nice feature. It's pretty weird if you imagine-- it's unrealistic to imagine you can allocate an array that's infinite size and then just use a few items out of it. That won't give you a good data structure. So we'll assume it costs to allocate memory. OK, great. We solved the sequence problem. Very simple, kind of boring. These are optimal running times. Now, let's make it interesting-- make sure I didn't miss anything--","76.33604431152344","2","DPRSearchEngine","CHhwJjR0mZA.en-j3PyPqV-e1s_3_mp4","CHhwJjR0mZA.en-j3PyPqV-e1s","6.006","2"
"288","What advantage does using an array have over a list when performing mathematical operations on data?","That's what we called a direct access array. A direct access array-- really not different than a regular array, except how are you using it when we were talking about sequences is we are giving extrinsic semantics to the slots where we are storing these things. Basically, I could put any item in any slot. Where it was in my array had nothing to do with what those things were. Here we are imposing intrinsic semantics on my array that, if I have an item with key K, it must be at index K. That's the thing that we're taking advantage of here. And then we can use this nice, powerful linear branching random access operation to find that thing in constant time, because that's our model of computation. OK, then what was the problem with this direct access array? Anyone shout it out. Space-- right. So we had to instantiate a direct access array that was the size of the space of our keys. In general, my index location is-- could go from 0 to some positive number. If I a very large positive numbers, if I was sorting-- if I was searching among your MIT IDs, I'd have to have a direct access array that was that spanned that space of possible keys you could have. And that could be much larger than n. And so the rest of the time we talked about how to fix that space problem. We can reduce the space by taking that larger key space from 0 to u, which could be very large, and map it down to a small space. Now, in general, if I give you a fixed hash function there, that's not going to be good in-- for all inputs. If your inputs are very well distributed over the key space, then it is good, but in general, there would be hash functions with some inputs that will be bad. That's what we argued. And so for the rest of the time there, we talked about hash families, choosing a hash function randomly from among a large set of hash functions, which had a property that, if I chose this thing randomly and you, generating your input, didn't know which random numbers I was picking, the expectation over my random choice-- me-- I'm the one running the algorithm, not you giving me the input-- that random choice-- my algorithm actually behaves really well in expectation. In particular, I got constant time for finding, inserting, and deleting into this data structure, in expectation. We did a little proof of-- that the chain links where we stored collisions in our hash function-- in our hash table-- sorry-- those wouldn't be very long, and so if they were constant, then I don't have to search more than a constant number of things when I go to an-- a hashed index location. Does everyone remember what we talked about last week? I didn't show you this chart at the end, but I'm showing it to you now. Essentially, what we had was we have a bunch of different ways to deal with this set interface. And last week, we talked about the sorted array, and then we talked about this direct access array and this hash table, which do better for these dictionary-- the find, and insert, and delete operations--","76.22476196289062","3","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_3_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"288","What advantage does using an array have over a list when performing mathematical operations on data?","They take linear time for some of the operations. So the sorting algorithms are not efficient. But they're ones we've seen before, so it's neat to see how they fit in here. They had the-- selection sort and insertion sort had the advantage that they were in place. You just needed a constant number of pointers or indices beyond the array itself. So they're very space efficient. So that was a plus for them. But they take n squared time, so you should never use them, except for n, at most, 100 or something. AVL tree sort is great and then it gets n log n time, probably more complicated than merge sort and you could stick to merge sort. But neither merge sort nor set AVL tree sort are in place. And so the goal of today is to get the best of all those worlds in sorting to get n log n comparisons, which is optimal in the comparison model, but get it to be in place. And that's what we're going to get with binary heaps. We're going to design a data structure that happens to build a little bit faster-- as I mentioned, linear time building. So it's not representing a sorted order in the same way that AVL trees are. But it will be kind of tree-based. It will also be array-based. We're going to get logarithmic time for insert and delete_max. It happens to be amortized, because we use arrays. But the key thing is that it's an in-place data structure. It only consists of an array of the items. And so, when we plug it into our sorting algorithm-- priority queue sort or generic sorting algorithm-- not only do we get n log n performance, but we also get an in-place sorting algorithm. This will be our first and only-- to this class-- n log n in-place sorting algorithm. Cool. That's the goal.","75.67369842529297","4","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_5_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"288","What advantage does using an array have over a list when performing mathematical operations on data?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","75.37275695800781","5","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"288","What advantage does using an array have over a list when performing mathematical operations on data?","namely, random accessing. And if we stored the things that we're looking for, we have unique keys, and those keys are integers. Then, if I have an item with key K, if I store it at index K in my array, then I can find it and manipulate it in constant time.","75.0433578491211","6","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_2_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"288","What advantage does using an array have over a list when performing mathematical operations on data?","which, I think, most of us would agree was not a very big number. And let's look what's going on here. If you look at this, what in some sense seems really stupid about it? What is it doing that a rational person would not want to do if they could avoid it? It's bad enough to do something once. But to do the same thing over and over again is really wasteful. And if we look at this, we'll see, for example, that fib 4 is being computed here, and fib 4 is being computed here. Fib 3 is being considered here, and here, and here. And do you think we'll get a different answer for fib 3 in one place when we get it in the other place? You sure hope not. So you think, well, what should we do about this? How would we go about avoiding doing the same work over and over again? And there's kind of an obvious answer, and that answer is at the heart of dynamic programming. What's the answer? AUDIENCE: [INAUDIBLE] JOHN GUTTAG: Exactly. And I'm really happy that someone in the front row answered the question because I can throw it that far. You store the answer and then look it up when you need it. Because we know that we can look things up very quickly. Dictionary, despite what Eric said in his lecture, almost all the time works in constant time if you make it big enough, and it usually is in Python. We'll see later in the term how to do that trick. So you store it and then you'd never have to compute it again. And that's the basic trick behind dynamic programming. And it's something called memoization, as in you create a memo and you store it in the memo. So we see this here. Notice that what we're doing is trading time for space. It takes some space to store the old results, but negligible related to the time we save. So here's the trick. We're going to create a table to record what we've done. And then before computing fib of x, we'll check if the value has already been computed. If so, we just look it up and return it. Otherwise, we'll compute it-- it's the first time-- and store it in the table. Here is a fast implementation of Fibonacci that does that. It looks like the old one, except it's got an extra argument-- memo-- which is a dictionary. The first time we call it, the memo will be empty. It tries to return the value in the memo. If it's not there, an exception will get raised, we know that.","74.27394104003906","7","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_9_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"288","What advantage does using an array have over a list when performing mathematical operations on data?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","74.0875244140625","8","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"288","What advantage does using an array have over a list when performing mathematical operations on data?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 5: Linear Sorting 
Lecture 5: Linear Sorting 
Review 
• Comparison search lower bound: any decision tree with n nodes has height ≥dlg(n+1)e−1 
• Can do faster using random access indexing: an operation with linear branching factor! 
• Direct access array is fast, but may use a lot of space (Θ(u)) 
• Solve space problem by mapping (hashing) key space u down to m = Θ(n) 
• Hash tables give expected O(1) time operations, amortized if dynamic 
• Expectation input-independent: choose hash function randomly from universal hash family 
• Data structure overview! 
• Last time we achieved faster ﬁnd. Can we also achieve faster sort? 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
Direct Access Array 
u 
1 
1 
u 
u 
Hash Table 
n(e) 
1(e) 
1(a)(e) 
n 
n 
","73.95985412597656","9","DPRSearchEngine","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5_1_pdf","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5","6.006","5"
"288","What advantage does using an array have over a list when performing mathematical operations on data?"," 
 
 
 
 
  
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Constructing !"",$: 1st try 
% on & 
Recall: A tableau for % on & represents 
a computation history for % on & 
when % accepts &. 
Rows of that tableau are configurations. 
% runs in space 45, its tableau has: 
- 45 columns (max size of a configuration)
-8
- 6
rows (max number of steps) 
Constructing !"",$. Try Cook-Levin method. 
Then !"",$ will be as big as tableau. 
-8
But that is exponential: 45×6 
.
Too big! • 
7 
Tableau for % on &
'( &) &* &+ ⋯&-
a
'. &*
⋯
⋯
'accept ⋯
˽   … ˽
45
6(-8)
","73.81913757324219","10","DPRSearchEngine","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18_7_pdf","88f789664d3236a64481714fc911d119_MIT18_404f20_lec18","18.404J","18"
"289","Why is random sampling generally easier to achieve in simulations compared to in the field?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Monte Carlo Simulation  
A method of estimating the value of an unknown 
quantity using the principles of inferential statistics 
Inferential statistics 
◦ Population: a set of examples 
◦ Sample: a proper subset of a population 
◦ Key fact: a random sample tends to exhibit the same  
properties as the population from which it is drawn  
Exactly what we did with random walks 
6.0002 LECTURE 6 
4
","72.92012023925781","1","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_4_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"289","Why is random sampling generally easier to achieve in simulations compared to in the field?"," 
 
Looking at  Distributions 
def plotDistributions():  
uniform, normal, exp = [], [], []  
for i in range(100000):  
uniform.append(random.random())  
normal.append(random.gauss(0, 1))  
exp.append(random.expovariate(0.5))  
makeHist(uniform, 'Uniform', 'Value', 'Frequency')  
pylab.figure()  
makeHist(normal, 'Gaussian', 'Value', 'Frequency')  
pylab.figure()  
makeHist(exp, 'Exponential', 'Value', 'Frequency')  
6.0002  LECTURE 8 
 
27
","72.45677185058594","2","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_27_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"289","Why is random sampling generally easier to achieve in simulations compared to in the field?"," 
 
 
 
 
Stochastic  Thinking  
§The world is (predictably) non-deterministic
§Thinking in terms of probabilities is often useful
§Randomness is a powerful tool for building
computations that model the world 
§Random computations useful even when for problems
that do not involve randomness 
◦E.g.,  integration
6.0002  LECTURE 15 
20 
","72.07933807373047","3","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_17_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"289","Why is random sampling generally easier to achieve in simulations compared to in the field?","   
 
 
 
 
How  Likely Is it Just Bad Luck?  
A variant of cherry picking called  
multiple hypothesis testing 
6.0002  LECTURE 15 
14 
","71.63436126708984","4","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_13_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"289","Why is random sampling generally easier to achieve in simulations compared to in the field?"," 
 
 
 
 
Lecture: Sampling and 
Standard Error 
6.0002  LECTURE 8 
 
1
","71.54612731933594","5","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_1_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"289","Why is random sampling generally easier to achieve in simulations compared to in the field?"," 
 
 
 
 
 
 
Sampling  
§All statistical techniques are based upon the
assumption that by sampling a subset of a population 
we can infer things about the population as a whole 
§As we have seen,  if random sampling is used, one can
make meaningful mathematical statements about the 
expected relation of the sample to the entire 
population 
§Easy to get random samples in simulations
§Not so easy in the field, where some examples are
more convenient to acquire than others 
6.0002  LECTURE 14 
21 
","71.42127990722656","6","DPRSearchEngine","b9d60f4ecb325e4648f9cf0379419338_MIT6_0002F16_lec14_21_pdf","b9d60f4ecb325e4648f9cf0379419338_MIT6_0002F16_lec14","6.0002","14"
"289","Why is random sampling generally easier to achieve in simulations compared to in the field?","!	!	 	
 
Let D be the original data set 
    n be the number of random samples  
 
 
 usually n between 20% and 50% 
    k be number of trials 
 
testResults = [] 
for i in range(k) 
    randomly select n elements for testSet,  
       keep rest for training 
    model = buildModel(training) 
    testResults.append(test(model, testSet)) 
 
Average testResults 

	

;G
","71.27857208251953","7","DPRSearchEngine","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10_38_pdf","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10","6.0002","10"
"289","Why is random sampling generally easier to achieve in simulations compared to in the field?","random.choice. It takes as an argument a sequence, in this case a list, and randomly chooses one member of the list. And it chooses it uniformly. It's a uniform distribution. And what that means is that it's equally probable that it will choose any number in that list each time you call it. We'll later look at distributions that are not uniform, not equally probable, where things are weighted. But here, it's quite simple, it's just uniform. And then we can test it using testRoll-- take some number of n and rolls the die that many times and creates a string telling us what we got. So let's consider running this on, say, testRoll of five. And we'll ask the question, if we run it, how probable is it that it's going to return a string of five 1's? How do we do that? Now, how many people here are either in 6.041 or would have taken 6.041? Raise your hand. Oh, good. So very few of you know probability. That helps. So how do we think about that question? Well, probability, to me at least, is all about counting, especially discrete probability, which is what we're looking at here. What you do is you start by counting the number of events that have the property of interest and the number of possible events and divide one by the other. So if we think about rolling a die five times, we can enumerate all of the possible outcomes of five rolls. So if we look at that, what are the outcomes? Well, I could get five 1's. I could get four 1's and a 2 or four 1's and 3, skip a few. The next one would be three 1's, a 2 and a 1, then a 2 and 2, and finally, at the end, all 6's. So remember, we looked before at when we're looking at optimization problems about binary numbers. And we said we can look at all the possible choices of items in the knapsack by a vector of 0's and 1's. We said, how many possible choices are there? Well, it depended on how many binary numbers you could get in that number of digits. Well, here we're doing the same thing, but instead of base 2, it's base 6. And so the number of possible outcomes of five rolls is quite high. How many of those are five 1's? Only one of them, right? So in order to get the probability of a five 1's, I divide 1 by 6 to the fifth. Does that makes sense to everybody? So in fact, we see it's highly unlikely. The probability of a five 1's is quite small. Now, suppose we were to ask about the probability of something else-- instead of five 1's, say 53421. It kind of looks more likely than that than five 1's in a row, but of course, it isn't, right? Any specific combination is equally probable. And there are a lot of them. So this is all the probability we're going to think about we could think about this way, as simply a matter of counting-- the number of possible events, the number of events that have the property of interest-- in this case being all 1's-- and then simple division. Given that framework, there were three basic facts about probability we're going to be using a lot of. So one, probabilities always range from 0 to 1. How do we know that? Well, we've got a fraction, right? And the denominator is all possible events. The numerator is the subset of that that's of interest. So it has to range from 0 to the denominator. And that tells us that the fraction has to range from 0 to 1. So 1 says it's always going to happen, 0 never. So if the probability of an event occurring is p, what's the probability of it not occurring? This follows from the first bullet. It's simply going to be 1 minus p. This is a trick that we'll find we'll use a lot. Because it's often the case when you want to compute the probability of something happening, it's easier to compute the probability of it not happening and subtract it from 1. And we'll see an example of that later today. Now, here's the biggie. When events are independent of each other, the probability of all of the events occurring is equal to the product of the probabilities of each of the events occurring. So if the probability of A is 0.5 and the probability of B","71.14753723144531","8","DPRSearchEngine","-1BnXEwHUok.en-qlPKC2UN_YU_4_mp4","-1BnXEwHUok.en-qlPKC2UN_YU","6.0002","4"
"289","Why is random sampling generally easier to achieve in simulations compared to in the field?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
Why Random Walks?  
§Random walks are important in many
domains
◦Understanding the stock market (maybe)
◦Modeling diffusion processes
◦Etc.
§Good illustration of how to use
simulations  to understand things
§Excuse to cover some important
programming topics
◦Practice with classes
◦Practice with plotting
6.0002  LECTURE 5 
3 
","71.09336853027344","9","DPRSearchEngine","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_3_pdf","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5","6.0002","5"
"289","Why is random sampling generally easier to achieve in simulations compared to in the field?","So when I simulated betting a pocket for 20 trials, we see that the-- of 1,000 spins each, for 1,000 spins the expected return for fair roulette happened to be 3.68%. A bit high. But you'll notice the confidence interval plus or minus 27 includes the actual answer, which is 0. And we have very large confidence intervals for the other two games. If you go way down to the bottom where I've spun, spun the wheel many more times, what we'll see is that my expected return for fair roulette is much closer to 0 than it was here. But more importantly, my confidence interval is much smaller, 0.8. So now I really have constrained it pretty well. Similarly, for the other two games you will see-- maybe it's more accurate, maybe it's less accurate, but importantly the confidence interval is smaller. So I have good reason to believe that the mean I'm computing is close to the true mean, because my confidence interval has shrunk. So that's the really important concept here, is that we don't just guess-- compute the value in the simulation. We use, in this case, the empirical rule to tell us how much faith we should have in that value. All right, the empirical rule doesn't always work. There are a couple of assumptions. One is that the mean estimation error is 0. What is that saying? That I'm just as likely to guess high as gas low. In most experiments of this sort, most simulations, that's a very fair assumption. There's no reason to guess I'd be systematically off in one direction or another. It's different when you use this in a laboratory experiment, where in fact, depending upon your laboratory technique, there may be a bias in your results in one direction. So we have to assume that there's no bias in our errors. And we have to assume that the distribution of errors","71.01752471923828","10","DPRSearchEngine","OgO1gpXSUzU.en-j3PyPqV-e1s_15_mp4","OgO1gpXSUzU.en-j3PyPqV-e1s","6.0002","6"
"290","What does an adjacency matrix represent in a directed graph?","I want to print out what an edge looks like, I'm going to ask that it print out the name of the source, and then an arrow, and then the name of the destination. So notice what I do there. Given an instance of an edge, I can print it. And it will get the source or the node associated with source inside this instance, get for that the getName method, and then call it. Notice the open-close paren there to actually call it. What does that do? It says, inside the edge I've got something that points to a node. I get that node. I take the method associated with it. And I call it. That returns the string. And then I glue that together with the arrow. I do the same thing on the destination. And I just print it out. Pretty straightforward, hopefully. OK, now I have to make a decision about the graph. I'm going to start with digraphs, directed graphs. And I need to think about how I might represent the graph. I can create nodes. I can create edges, but I've got to bring them all together. So I'll remind you, a digraph is a directed graph. The edges pass in only one direction. And here's one way I could do it. Given all the sources and all the destinations, I could just create a big matrix called an adjacency matrix. The rows would be all the sources. The columns would be all the destinations. And then in a particular spot in the matrix, if there is an edge between a source and a destination, I'd just put a one. Otherwise I'd put a zero. Note, by the way, because it's a directed graph, it's not symmetric. There might be a one between S and D, but not between D and S, unless there are edges both ways. This would be a perfectly reasonable way to represent a graph, but not the most convenient one. I'd have to go into the matrix to look things up. It may also not be a very efficient way of representing things. For example, if there are very few edges in the graph, I could have a huge matrix with mostly zeros. And that's not the most effective way to do it. So I'm going to use an alternative called an adjacency list. And the idea here is, for every node in the graph. I'm going to associate with it a list of destinations. That is, for a node, what are the places I can reach with a single edge? OK, so let's see what that does if we want to build it. And yes, there's a lot of code here, but it's pretty easy to look through I hope. Here's the choice I'm going to make. Again, what's a graph? It's a set of nodes. It's a set of edges. I'm going to have a way of putting nodes into the graph. And I'm going to choose to, when I put a node into the graph, to store it as a key in a dictionary. OK? When I initialize the graph, I'm just going to set this internal variable, edges, to be an empty dictionary. And the second part of it is, when I add an edge to the graph between two nodes from a source to a destination, I'm going to take that point in the dictionary associated with the source. It's a key. And associated with it, I'm going to just have a list of the nodes I can reach from edges from that source. So notice what happens here. If I want to add a node, remember, it's a node not an edge-- I'll first check to make sure that it's not already in the dictionary. That little loop is basic, or that if is saying, if it's in this set of keys, it will return true. And I'm going to complain. I'm trying to copy a node or duplicate a node. Otherwise, notice what I do. When I put a node into the dictionary, I go into that dictionary, edges. I create an entry with the key that is the node. And the value I put in there is initially an empty list. I'm going to say one more piece carefully. It's a node not a name. And that's OK in Python. It is literally the key is the node itself. It's an object, which is what I'd like. All right, what if I want to add an edge? Well, an edge is going to go from a source to a destination node. So, I'm going to get out from the edge the source piece. I'm going to get out from the edge the destination piece by calling those methods. Again, notice the open-close paren, which takes the method and actually calls it. Because remember, an edge was an object itself. Given those, I'll check to make sure that they are both in the dictionary. That is, I've already added them to the graph. I can't make a connection between things that aren't in the graph. And then notice the nice little thing I do.","72.0956802368164","1","DPRSearchEngine","V_TulH374hw.en-qlPKC2UN_YU_2_mp4","V_TulH374hw.en-qlPKC2UN_YU","6.0002","3"
"290","What does an adjacency matrix represent in a directed graph?","that we've already seen in 6006? AUDIENCE: A tree. JUSTIN SOLOMON: A tree. At least if we orient all all the edges kind of pointing downward in the tree. Yeah. Otherwise, it gets kind of debatable over whether it's a DAG or not. If there's no direction to the edges, then somehow the definition just doesn't apply. OK. So in processing directed acyclic graphs, there's a really useful thing that you can do that's going to show up in this class apparently quite a bit, which is kind of interesting to me, I'm curious to see what that looks like, which is to compute a topological order on the graph. We're at topologies here.","71.48980712890625","2","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_16_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"290","What does an adjacency matrix represent in a directed graph?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","69.58194732666016","3","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"290","What does an adjacency matrix represent in a directed graph?","Longest path is maybe a problem we've talked about in problem session, because it's a DAG-- well, longest path is the same thing as shortest path, if you just negate all the weights. There are no weights in this picture, so if you just put negative 1 on all these edges and ask for the shortest path from the base to anywhere-- so single source shortest paths from this base-- then we would end up getting this path, which, if you look at it, is E-M-P-T-Y, empty. And so that shortest path is indeed the right answer. What I've drawn here is the shortest path tree. So also, if you wanted the longest increasing subsequence starting at A, then it is A-T-Y, just by following the red arrows here. And how do you get that? You just draw the parent pointers, just like we did before.","68.93727111816406","4","DPRSearchEngine","KLBCUx1is2c.en-j3PyPqV-e1s_8_mp4","KLBCUx1is2c.en-j3PyPqV-e1s","6.006","16"
"290","What does an adjacency matrix represent in a directed graph?","And that's cycle detection. So there's a bit of an exercise left to the reader here. So the problem that we're looking for now is that we're given a directed graph. There's a G in graph, in case you're wondering. But now, we don't know if it's a DAG or not. And so the question that we're trying to ask is, does there exist a cycle in our directed acyclic graph? So we're just given our graph, and we want to know, can we do this? Let's think through the logic of this a bit. So what do we know? We know that if our graph were a DAG, then I could call DGS, get the ordering out, and then I guess flip its ordering backwards. So I could compute the reverse finishing order. And it would give me a topological order of my graph. So if I were a DAG, I would get a topological order when I call DFS. So let's say that I ran DFS. I got whatever ordering I got. And now I found an edge the points in the wrong direction. I can just double check my list of edges, and I find one that does not respect the relationship that I see in the second bullet point here. Can my graph be a DAG? No. Because if my graph were a DAG, the algorithm would work. I just proved it to you. Right? So if my graph were a DAG, then I could do reverse finishing order. And what I would get back is a topological order. So if I found a certificate that my order wasn't topological, something went wrong, and the only thing that could go wrong is that my graph isn't a DAG. Yeah. Isn't a DAG. In fact, sort of an exercise left to the reader and/or to your section-- do we still have section? I think we do, as of now-- is that this is an if and only if, meaning that the only time that you even have a topological ordering in your graph is if your graph is a DAG. This is a really easy fact to sanity check, by the way. This is not like, a particularly challenging problem. But you should think through it because it's a good exercise to make sure you understand the definitions, which is to say that if you have a topological order, your graph is a DAG. If you don't have a topological order, your graph isn't a DAG. So in other words, we secretly gave you an algorithm for checking if a graph is a DAG at all. Right? What could I do? I could compute reverse finishing order. Check if it obeys the relationship on the second bullet point here for every edge. And if it does, then we're in good shape. My graph is a DAG. If it doesn't, something went wrong. And the only thing that could have gone wrong is not being a DAG. OK. So in other words, secretly we just solved-- well, I guess the way that I've written it here, we've solved the cycle detection problem here, which is to say that, well, I have a cycle if and only if I'm not a DAG, which I can check using this technique. Of course, the word ""detection"" here probably means that I actually want to find that cycle, and I haven't told you how to do that yet. All we know how to do so far is say, like, somewhere in this graph there's a cycle. And that's not so good. So we can do one additional piece of information in the two minutes we have remaining to sort of complete our story here, which is to modify our algorithm ever so slightly to not only say thumbs up, thumbs down, is there a cycle in this graph, but also to actually return the vertices as a cycle. And here's the property that we're going to do that, which is following, which is that if G contains a cycle, right, then full DFS will traverse an edge from a vertex v to some ancestor of v. I guess we haven't carefully defined the term ""ancestor"" here. Essentially, if you think of the sort of the running of the DFS algorithm, then an ancestor is like something that appears in the recursive call tree before I got to v. OK. So how could we prove that? Well, let's take a cycle. And we'll give it a name. In particular, we'll say that it's a cycle from v0 v1 to vk. And then it's a cycle, so it goes back to v0. OK. And I can order this cycle any way I want. Notice that if I permute the vertices in this list in a cyclical way, meaning that I take the last few of them and stick them at the beginning of the list, it's still a cycle. That's the nice thing about cycles. So in particular, without loss of generality, we're going to assume that v0 is the first vertex visited by DFS. What does that mean? That means, like, when I do my DFS algorithm making all these recursive calls, the very first vertex to be touched by this technique is v0. OK. Well, now what's going to end up happening? Well, think about the recursive call tree starting at v0. By the time that completes, anything that's reachable from v0 is also going to be complete. Do you see that? So for instance, v0 somewhere in its call tree might call v2. And notice that v2 was not already visited. So in fact, it will. For v1 I got to call v2 and so on. And in particular, we're going to get all the way to vertex k. Right? So in other words, we're going to visit a vertex vk. And notice what's going to happen. So remember our algorithm. In fact, we should probably just put it up on the screen would be easier than talking about it a bunch. Well, vk is now going to iterate over every one of the neighbors of vk. And in particular, it's going to see vertex v0. Right? So we're going to see the edge from vk to v0, which is an edge kind of by definition because we took this to be a cycle here. But notice that's exactly the thing we set out to prove, namely that full DFS traverses an edge from a vertex to one of its ancestors. Here's a vertex k. Here's the ancestor v0. Why do we know that it's an ancestor? Well, because v0 was called in our call tree before any of these other guys. Right? So we wanted an algorithm that not only did cycle detection, but also actually gave me the cycle. What could I do? Well, it's essentially a small modification of what we already have. Right. So-- whoops. Right. If I want to compute topological order or whatever, I can just do DFS. And that'll tell me like, yay or nay, does there exist a cycle. If I want to actually find that cycle, all I have to do is check that topological order property at the same time that it traversed the graph during DFS. And the second that I find an edge that loops back, I'm done. And so that's our basic algorithm here. And this is a technique for actually just finding the cycle in a graph using the DFS algorithm.","68.92575073242188","5","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_20_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"290","What does an adjacency matrix represent in a directed graph?","What's the worst case performance of a hash table? If I have to look up something in a hash table, and I happen to choose a bad hash table-- hash function, what's the worst case here? What? n, right? It's worse than a sorted array, because potentially, I hashed everything that I was storing to the same index in my hash table, and to be able to distinguish between them, I can't do anything more than a linear search. I could store another set's data structure as my chain and do better that way. That's actually how Java does it. They store a data structure we're going to be talking about next week as the chains so that they can get, worst case, log n. But in general, that hash table is only good if we're allowing-- OK, I want this to be expected good, but in the worst case, if I really need that operation to be worst case-- I really can't afford linear time ever for an operation of that kind-- then I don't want to use a hash table. And so on your p set 2, everything we ask you for is worst case, so probably, you don't want to be using hash tables. OK? Yes? AUDIENCE: What does the subscript e mean? JASON KU: What does the subscript e mean? That's great. In this chart, I put a subscript on this is an expected runtime, or an A meaning this is an amortized runtime. At the end, we talked about how, if we had too many things in our hash table, then, as long as we didn't do it too often-- this is a little hand wavey argument, but the same kinds of ideas as the dynamic array-- if, whenever we got a linear-- we are more than a linear factor away from where we are trying-- basically, the fill factor we were trying to be, then we could just completely rebuild the hash table with the new hash function randomly chosen from our hash table with a new size, and we could get amortized bounds. And so that's what Python-- how Python implements dictionaries, or sets, or even objects when it's trying to map keys to different things. So that's hash tables. That's great. The key thing here is, well, actually, if your range of keys is small, or if you as a programmer have the ability to choose the keys that you identify your objects with, you can actually choose that range to be small, to be linear, to be small with respect to your items. And you don't need a hash table. You can just use a direct access array, because if you know your key space is small, that's great. So a lot of C programmers probably would like to do something like that, because they don't have access to-- maybe C++ programmers would have access to their hash table. Any questions on this stuff before we move on? Yeah? AUDIENCE: So why is [INAUDIBLE]? JASON KU: Why is it expected? When I'm building, I could insert-- I'm inserting these things from x 1 by 1 into my hash table. Each of those insert operations-- I'm looking up to see whether that-- an item with that key already exists in my hash table. And so I have to look down the chain to see where it is. However, if I happen to know that all of my keys are unique in my input, all the items I'm trying to store are unique, then I don't have to do that check and I can get worst case linear time. Does that make sense? All right. It's a subtlety, but that's a great question. OK, so today, instead of talking about searching, we're talking about sorting. Last week, we saw a few ways to do sort. Some of them were quadratic-- insertion sort and selection sort-- and then we had one that was n log n. And this thing, n log n, seemed pretty good, but can I do better? Can I do better? Well, what we're going to show at the beginning of this class is, in this comparison model, no. n log n is optimal. And we're going to go through the exact same line of reasoning that we had last week. So in the comparison model, what did we use when we were trying to make this argument that any comparison model algorithm was going to take at least log n time? What we did was we said, OK, I can think of any model in the comparison model-- any algorithm in the comparison model as kind of this-- some comparisons happen. They branch in a binary sense, but you could have it generalized to any constant branching factor. But for our purposes, binary's fine. And what we said was that there were at least n outputs-- really n plus 1, but-- at least order n outputs. And we showed that-- or we argued to you that the height of this tree had to be at least log n-- log the number of leaves. It had to be at least log the number of leaves. That was the height of the decision tree. And if this decision tree represented a search algorithm, I had to walk down and perform these comparisons in order, reach a leaf where I would output something. If the minimum height of any binary tree on a linear number of leaves is log n, then any algorithm in the comparison model also has to take log n time, because it has to do that many comparisons to differentiate between all possible outputs. Does that make sense? All right. So in the sort problem, how many possible outputs are there?","68.59172821044922","6","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_4_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"290","What does an adjacency matrix represent in a directed graph?","OK, so this is Dijkstra's algorithm. OK. Set-- so same initialization step. We're going to set-- this is a distance estimate d, not delta. We're going to want the d's be our delta is at the end of the algorithm. That's what we're going to have to prove. So we first set all of them to infinity, and then set d of s, s equal to 0. And here, we're never going to update it again, because our shortest distance is in a graph with non-negative edge weights certainly can't go below 0. All right. Now we build our-- build our changeable priority queue-- queue-- with an item-- I'm going to say an item is-- x is represented by a tuple of its ID, and then its key just for brevity here. With an item v, d of s, v. So I'm going to be storing in my changeable priority queue the vertex label and its shortest-path distance estimate d. And that's going to be the key, the minimum that I'm trying going to be querying on for each the v and V. So I'm going to build that thing. It's going to then have all of my vertices in my graph. Then while my changeable priority queue still has items, not empty, I'm going to delete some u, d s, u. So some item such that its distance is minimized from Q that has minimum distance. OK. So I'm going to I'm going to look at all the things in my priority queue. At the start it's just going to be s, because everything as shortest-path distance estimate infinite except for s. And so that's clearly the smallest. OK, so I'm going to remove that from my queue, and then I'm going to process it. How am I going to process it? It's the exact same kind of thing as DAG relaxation. I'm going to relax all its outgoing edges. So just for completeness for v in the outgoing adjacencies of u, I'm going to relax-- sorry. We have to check whether we can relax it. Basically if the shortest-path distance estimate to v is greater than going to u first and then crossing that edge, if going through that is better, this is violating our triangle inequality. And so we relax edge u, v, and by that we mean set this thing to be equal to that thing. That's what we meant by relax. And then we have one other thing to do. We have changed these distance estimates but our Q doesn't know that we change these things. We added these items in here. But it doesn't know that my distances have changed. So we to tell the Q to remember to change its key value associated with the item v. So decrease-- what is it? Decrease key vertex v in Q to the new d s, v, the one that I just decreased here. And I know that I decreased it because I said it to a smaller value. That makes sense. All right, so that's Dijkstra. Let's run it on an example. So here's an example. I have a directed graph. It does contain cycles. In particular, here are some cycles. I think those are the main ones. There are definitely cycles in this graph. But as you see, all of the weights are non-negative, in particular-- they're positive, actually. It's going to be just helpful in writing out this example. So let's run Dijkstra on this graph. First we initialize and we set the shortest-path distance. I'm going to label it in white here to all of the things. Then I'm going to, as I update it, I'm just going to cross them out and write a new number. So that's what it is at the start. That's initialization, that's after step 1. And then I stick things into my Q. What's in my Q? Here's my Q. It's everything. It's vertices s, a, b, c, d. I got five items in my Q. Really, it's the item pair with its shortest distance estimate, I'm just not going to rewrite that here. So the idea here is-- the while loop, OK. Q is not empty, great. We're going to delete the one with the smallest distance estimate, which is s, right, yeah. So I remove that, and then I relax edges out of s. So I relax edge here to a. That's better than the distance estimate-- 10 is better than the distance estimate infinite, so I'm going to change this to 10. And then here's another outgoing edge. 3 is better than infinite, so I'm going to change its delta to 3. OK. So now I go back in here and I change the distance estimates associated with my Q. Now, next step of the algorithm, s is done. I've processed everything distance 0 away. But I'm now going to use my priority queue to say which of my vertices has the shortest distance estimate now. So which one is it? a, b, or c, or d? Yeah, it's 3 and c. 3 is smaller than 10. So Q is going to magically delete c for me, tell me what that is, and now I'm going to process that. Now I've changed my boundary to this. And now I relax edges out of c. So here's an edge at a c, that's a 4. A 4 plus the 3 is smaller than 10, so I update it. 3 plus 8 is 11, that's smaller than infinite, so I update it, I relax. 3 plus 2 is smaller than infinite, so I relax that as well. Now of the things still left in my Q, I'm actually going to remove it from my Q instead of crossing it out, maybe that's better. Of the vertices still left in my Q, which has smallest distance? Yeah. d. d has 5, 7, or 11. 5 is the smallest. So I remove d from my cue and I relax edges from it. And now my boundary looks something like this. I relax edges out of it. 5 plus 5, that's 10. 10 is smaller than 11, so that's a 10. And that's the only outgoing edge from d. so I'm done. And then the last, 7 is smaller than 10, I relax edges out of a. a to b, 7 plus 2 is smaller than 10. And now I'm done. So what I did every time I removed s-- or I removed a vertex, I said its shortest-path distance to the small-- the last value I assigned to it. So this was then 3, and then a was 7, b was 9, and then d was 5. So that's Dijkstra in action. It seems like these are the shortest-path distances, but how do we prove that? Did it do the right thing? Well, let's find out.","67.96894073486328","7","DPRSearchEngine","NSHizBK9JD8.en-j3PyPqV-e1s_4_mp4","NSHizBK9JD8.en-j3PyPqV-e1s","6.006","13"
"290","What does an adjacency matrix represent in a directed graph?","is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.","67.86862182617188","8","DPRSearchEngine","JbafQJx1CIA.en-j3PyPqV-e1s_2_mp4","JbafQJx1CIA.en-j3PyPqV-e1s","6.006","19"
"290","What does an adjacency matrix represent in a directed graph?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 9: Breadth-First Search 
Lecture 9: Breadth-First Search 
New Unit: Graphs! 
• Quiz 1 next week covers lectures L01 - L08 on Data Structures and Sorting 
• Today, start new unit, lectures L09 - L14 on Graph Algorithms 
Graph Applications 
• Why? Graphs are everywhere! 
• any network system has direct connection to graphs 
• e.g., road networks, computer networks, social networks 
• the state space of any discrete system can be represented by a transition graph 
• e.g., puzzle & games like Chess, Tetris, Rubik’s cube 
• e.g., application workﬂows, speciﬁcations 
Graph Deﬁnitions 
G1 
0 
1 
2 
3 
G2 
0 
1 
2 
G3 
a 
b 
s 
c 
d 
e 
f 
g 
• Graph G = (V, E) is a set of vertices V and a set of pairs of vertices E ⊆ V × V . 
• Directed edges are ordered pairs, e.g., (u, v) for u, v ∈ V 
• Undirected edges are unordered pairs, e.g., {u, v} for u, v ∈ V 
i.e., (u, v) and (v, u) 
• In this class, we assume all graphs are simple: 
– edges are distinct, e.g., (u, v) only occurs once in E (though (v, u) may appear), and 
– edges are pairs of distinct vertices, e.g., u =6 v for all (u, v) ∈ E 
 

|V |
|V |
– Simple implies |E| = O(|V |2), since |E| ≤ 
for undirected, ≤ 2 
for directed 
2
2 
","67.7959213256836","9","DPRSearchEngine","196a95604877d326c6586e60477b59d4_MIT6_006S20_lec9_1_pdf","196a95604877d326c6586e60477b59d4_MIT6_006S20_lec9","6.006","9"
"290","What does an adjacency matrix represent in a directed graph?"," 
 
 
 
 
 
   
  
 
  
 
 
   
 
 
  
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
  
 
 
 
 
 
 
Check-in 8.2 
Recall the Queue Automaton (QA) defined in Pset 2. 
It is similar to a PDA except that it is deterministic 
and it has a queue instead of a stack. 
Let !QA = { &, ( | & is a QA and & accepts (} 
Is !QA decidable? 
(a) Yes, because QA are similar to PDA and !PDA is decidable. 
(b) No, because “yes” would contradict results we now know. 
(c) We don’t have enough information to answer this question. 
8 
Check-in 8.2 
","67.63032531738281","10","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_8_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"291","How does an adjacency list represent the edges of a node?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","70.34295654296875","1","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"291","How does an adjacency list represent the edges of a node?","I want to print out what an edge looks like, I'm going to ask that it print out the name of the source, and then an arrow, and then the name of the destination. So notice what I do there. Given an instance of an edge, I can print it. And it will get the source or the node associated with source inside this instance, get for that the getName method, and then call it. Notice the open-close paren there to actually call it. What does that do? It says, inside the edge I've got something that points to a node. I get that node. I take the method associated with it. And I call it. That returns the string. And then I glue that together with the arrow. I do the same thing on the destination. And I just print it out. Pretty straightforward, hopefully. OK, now I have to make a decision about the graph. I'm going to start with digraphs, directed graphs. And I need to think about how I might represent the graph. I can create nodes. I can create edges, but I've got to bring them all together. So I'll remind you, a digraph is a directed graph. The edges pass in only one direction. And here's one way I could do it. Given all the sources and all the destinations, I could just create a big matrix called an adjacency matrix. The rows would be all the sources. The columns would be all the destinations. And then in a particular spot in the matrix, if there is an edge between a source and a destination, I'd just put a one. Otherwise I'd put a zero. Note, by the way, because it's a directed graph, it's not symmetric. There might be a one between S and D, but not between D and S, unless there are edges both ways. This would be a perfectly reasonable way to represent a graph, but not the most convenient one. I'd have to go into the matrix to look things up. It may also not be a very efficient way of representing things. For example, if there are very few edges in the graph, I could have a huge matrix with mostly zeros. And that's not the most effective way to do it. So I'm going to use an alternative called an adjacency list. And the idea here is, for every node in the graph. I'm going to associate with it a list of destinations. That is, for a node, what are the places I can reach with a single edge? OK, so let's see what that does if we want to build it. And yes, there's a lot of code here, but it's pretty easy to look through I hope. Here's the choice I'm going to make. Again, what's a graph? It's a set of nodes. It's a set of edges. I'm going to have a way of putting nodes into the graph. And I'm going to choose to, when I put a node into the graph, to store it as a key in a dictionary. OK? When I initialize the graph, I'm just going to set this internal variable, edges, to be an empty dictionary. And the second part of it is, when I add an edge to the graph between two nodes from a source to a destination, I'm going to take that point in the dictionary associated with the source. It's a key. And associated with it, I'm going to just have a list of the nodes I can reach from edges from that source. So notice what happens here. If I want to add a node, remember, it's a node not an edge-- I'll first check to make sure that it's not already in the dictionary. That little loop is basic, or that if is saying, if it's in this set of keys, it will return true. And I'm going to complain. I'm trying to copy a node or duplicate a node. Otherwise, notice what I do. When I put a node into the dictionary, I go into that dictionary, edges. I create an entry with the key that is the node. And the value I put in there is initially an empty list. I'm going to say one more piece carefully. It's a node not a name. And that's OK in Python. It is literally the key is the node itself. It's an object, which is what I'd like. All right, what if I want to add an edge? Well, an edge is going to go from a source to a destination node. So, I'm going to get out from the edge the source piece. I'm going to get out from the edge the destination piece by calling those methods. Again, notice the open-close paren, which takes the method and actually calls it. Because remember, an edge was an object itself. Given those, I'll check to make sure that they are both in the dictionary. That is, I've already added them to the graph. I can't make a connection between things that aren't in the graph. And then notice the nice little thing I do.","69.7925033569336","2","DPRSearchEngine","V_TulH374hw.en-qlPKC2UN_YU_2_mp4","V_TulH374hw.en-qlPKC2UN_YU","6.0002","3"
"291","How does an adjacency list represent the edges of a node?","4 
Lecture 1: Introduction 
1 
def birthday_match(students): 
2 
’’’ 
3 
Find a pair of students with the same birthday 
4 
Input: 
tuple of student (name, bday) tuples 
5 
Output: tuple of student names or None 
6 
’’’ 
7 
n = len(students) 
# O(1) 
8 
record = StaticArray(n) 
# O(n) 
9 
for k in range(n): 
# n 
10 
(name1, bday1) = students[k] 
# O(1) 
11 
# Return pair if bday1 in record 
12 
for i in range(k): 
# k 
13 
(name2, bday2) = record.get_at(i) 
# O(1) 
14 
if bday1 == bday2: 
# O(1) 
15 
return (name1, name2) 
# O(1) 
16 
record.set_at(k, (name1, bday1)) 
# O(1) 
17 
return None 
# O(1) 
Example: Running Time Analysis 
• Two loops: outer k ∈{0, . . . , n − 1}, inner is i ∈{0, . . . , k}
P n−1
• Running time is O(n) + 
k=0 (O(1) + k · O(1)) = O(n2) 
• Quadratic in n is polynomial. Efﬁcient? Use different data structure for record! 
How to Solve an Algorithms Problem 
1. Reduce to a problem you already know (use data structure or algorithm) 
Search Problem (Data Structures) 
Sort Algorithms 
Static Array (L01) 
Insertion Sort (L03) 
Linked List (L02) 
Selection Sort (L03) 
Dynamic Array (L02) 
Merge Sort (L03) 
Sorted Array (L03) 
Counting Sort (L05) 
Direct-Access Array (L04) 
Radix Sort (L05) 
Hash Table (L04) 
AVL Sort (L07) 
Balanced Binary Tree (L06-L07) 
Heap Sort (L08) 
Binary Heap (L08) 
2. Design your own (recursive) algorithm 
• Brute Force 
• Decrease and Conquer 
• Divide and Conquer 
• Dynamic Programming (L15-L19) 
• Greedy / Incremental 
Shortest Path Algorithms 
Breadth First Search (L09) 
DAG Relaxation (L11) 
Depth First Search (L10) 
Topological Sort (L10) 
Bellman-Ford (L12) 
Dijkstra (L13) 
Johnson (L14) 
Floyd-Warshall (L18) 
","69.73292541503906","3","DPRSearchEngine","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_4_pdf","477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1","6.006","1"
"291","How does an adjacency list represent the edges of a node?"," &&%$3$%'9
class Digraph(object): 
 """"""edges is a dict mapping each node to a list of 
    its children""""” 
    def __init__(self): 
self.edges = {} 
    def addNode(self, node): 
if node in self.edges: 
 raise ValueError('Duplicate node') 
else: 
self.edges[node] = [] 
    def addEdge(self, edge): 
src = edge.getSource() 
dest = edge.getDestination() 
if not (src in self.edges and dest in self.edges): 
raise ValueError('Node not in graph') 
self.edges[src].append(dest) 
Q>KKKMN
LS
mapping each node 
list 
","69.62059783935547","4","DPRSearchEngine","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_18_pdf","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3","6.0002","3"
"291","How does an adjacency list represent the edges of a node?","that we've already seen in 6006? AUDIENCE: A tree. JUSTIN SOLOMON: A tree. At least if we orient all all the edges kind of pointing downward in the tree. Yeah. Otherwise, it gets kind of debatable over whether it's a DAG or not. If there's no direction to the edges, then somehow the definition just doesn't apply. OK. So in processing directed acyclic graphs, there's a really useful thing that you can do that's going to show up in this class apparently quite a bit, which is kind of interesting to me, I'm curious to see what that looks like, which is to compute a topological order on the graph. We're at topologies here.","69.54328918457031","5","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_16_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"291","How does an adjacency list represent the edges of a node?","OK, so this is Dijkstra's algorithm. OK. Set-- so same initialization step. We're going to set-- this is a distance estimate d, not delta. We're going to want the d's be our delta is at the end of the algorithm. That's what we're going to have to prove. So we first set all of them to infinity, and then set d of s, s equal to 0. And here, we're never going to update it again, because our shortest distance is in a graph with non-negative edge weights certainly can't go below 0. All right. Now we build our-- build our changeable priority queue-- queue-- with an item-- I'm going to say an item is-- x is represented by a tuple of its ID, and then its key just for brevity here. With an item v, d of s, v. So I'm going to be storing in my changeable priority queue the vertex label and its shortest-path distance estimate d. And that's going to be the key, the minimum that I'm trying going to be querying on for each the v and V. So I'm going to build that thing. It's going to then have all of my vertices in my graph. Then while my changeable priority queue still has items, not empty, I'm going to delete some u, d s, u. So some item such that its distance is minimized from Q that has minimum distance. OK. So I'm going to I'm going to look at all the things in my priority queue. At the start it's just going to be s, because everything as shortest-path distance estimate infinite except for s. And so that's clearly the smallest. OK, so I'm going to remove that from my queue, and then I'm going to process it. How am I going to process it? It's the exact same kind of thing as DAG relaxation. I'm going to relax all its outgoing edges. So just for completeness for v in the outgoing adjacencies of u, I'm going to relax-- sorry. We have to check whether we can relax it. Basically if the shortest-path distance estimate to v is greater than going to u first and then crossing that edge, if going through that is better, this is violating our triangle inequality. And so we relax edge u, v, and by that we mean set this thing to be equal to that thing. That's what we meant by relax. And then we have one other thing to do. We have changed these distance estimates but our Q doesn't know that we change these things. We added these items in here. But it doesn't know that my distances have changed. So we to tell the Q to remember to change its key value associated with the item v. So decrease-- what is it? Decrease key vertex v in Q to the new d s, v, the one that I just decreased here. And I know that I decreased it because I said it to a smaller value. That makes sense. All right, so that's Dijkstra. Let's run it on an example. So here's an example. I have a directed graph. It does contain cycles. In particular, here are some cycles. I think those are the main ones. There are definitely cycles in this graph. But as you see, all of the weights are non-negative, in particular-- they're positive, actually. It's going to be just helpful in writing out this example. So let's run Dijkstra on this graph. First we initialize and we set the shortest-path distance. I'm going to label it in white here to all of the things. Then I'm going to, as I update it, I'm just going to cross them out and write a new number. So that's what it is at the start. That's initialization, that's after step 1. And then I stick things into my Q. What's in my Q? Here's my Q. It's everything. It's vertices s, a, b, c, d. I got five items in my Q. Really, it's the item pair with its shortest distance estimate, I'm just not going to rewrite that here. So the idea here is-- the while loop, OK. Q is not empty, great. We're going to delete the one with the smallest distance estimate, which is s, right, yeah. So I remove that, and then I relax edges out of s. So I relax edge here to a. That's better than the distance estimate-- 10 is better than the distance estimate infinite, so I'm going to change this to 10. And then here's another outgoing edge. 3 is better than infinite, so I'm going to change its delta to 3. OK. So now I go back in here and I change the distance estimates associated with my Q. Now, next step of the algorithm, s is done. I've processed everything distance 0 away. But I'm now going to use my priority queue to say which of my vertices has the shortest distance estimate now. So which one is it? a, b, or c, or d? Yeah, it's 3 and c. 3 is smaller than 10. So Q is going to magically delete c for me, tell me what that is, and now I'm going to process that. Now I've changed my boundary to this. And now I relax edges out of c. So here's an edge at a c, that's a 4. A 4 plus the 3 is smaller than 10, so I update it. 3 plus 8 is 11, that's smaller than infinite, so I update it, I relax. 3 plus 2 is smaller than infinite, so I relax that as well. Now of the things still left in my Q, I'm actually going to remove it from my Q instead of crossing it out, maybe that's better. Of the vertices still left in my Q, which has smallest distance? Yeah. d. d has 5, 7, or 11. 5 is the smallest. So I remove d from my cue and I relax edges from it. And now my boundary looks something like this. I relax edges out of it. 5 plus 5, that's 10. 10 is smaller than 11, so that's a 10. And that's the only outgoing edge from d. so I'm done. And then the last, 7 is smaller than 10, I relax edges out of a. a to b, 7 plus 2 is smaller than 10. And now I'm done. So what I did every time I removed s-- or I removed a vertex, I said its shortest-path distance to the small-- the last value I assigned to it. So this was then 3, and then a was 7, b was 9, and then d was 5. So that's Dijkstra in action. It seems like these are the shortest-path distances, but how do we prove that? Did it do the right thing? Well, let's find out.","69.14940643310547","6","DPRSearchEngine","NSHizBK9JD8.en-j3PyPqV-e1s_4_mp4","NSHizBK9JD8.en-j3PyPqV-e1s","6.006","13"
"291","How does an adjacency list represent the edges of a node?","Longest path is maybe a problem we've talked about in problem session, because it's a DAG-- well, longest path is the same thing as shortest path, if you just negate all the weights. There are no weights in this picture, so if you just put negative 1 on all these edges and ask for the shortest path from the base to anywhere-- so single source shortest paths from this base-- then we would end up getting this path, which, if you look at it, is E-M-P-T-Y, empty. And so that shortest path is indeed the right answer. What I've drawn here is the shortest path tree. So also, if you wanted the longest increasing subsequence starting at A, then it is A-T-Y, just by following the red arrows here. And how do you get that? You just draw the parent pointers, just like we did before.","68.79105377197266","7","DPRSearchEngine","KLBCUx1is2c.en-j3PyPqV-e1s_8_mp4","KLBCUx1is2c.en-j3PyPqV-e1s","6.006","16"
"291","How does an adjacency list represent the edges of a node?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","68.69731140136719","8","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"291","How does an adjacency list represent the edges of a node?","What's the worst case performance of a hash table? If I have to look up something in a hash table, and I happen to choose a bad hash table-- hash function, what's the worst case here? What? n, right? It's worse than a sorted array, because potentially, I hashed everything that I was storing to the same index in my hash table, and to be able to distinguish between them, I can't do anything more than a linear search. I could store another set's data structure as my chain and do better that way. That's actually how Java does it. They store a data structure we're going to be talking about next week as the chains so that they can get, worst case, log n. But in general, that hash table is only good if we're allowing-- OK, I want this to be expected good, but in the worst case, if I really need that operation to be worst case-- I really can't afford linear time ever for an operation of that kind-- then I don't want to use a hash table. And so on your p set 2, everything we ask you for is worst case, so probably, you don't want to be using hash tables. OK? Yes? AUDIENCE: What does the subscript e mean? JASON KU: What does the subscript e mean? That's great. In this chart, I put a subscript on this is an expected runtime, or an A meaning this is an amortized runtime. At the end, we talked about how, if we had too many things in our hash table, then, as long as we didn't do it too often-- this is a little hand wavey argument, but the same kinds of ideas as the dynamic array-- if, whenever we got a linear-- we are more than a linear factor away from where we are trying-- basically, the fill factor we were trying to be, then we could just completely rebuild the hash table with the new hash function randomly chosen from our hash table with a new size, and we could get amortized bounds. And so that's what Python-- how Python implements dictionaries, or sets, or even objects when it's trying to map keys to different things. So that's hash tables. That's great. The key thing here is, well, actually, if your range of keys is small, or if you as a programmer have the ability to choose the keys that you identify your objects with, you can actually choose that range to be small, to be linear, to be small with respect to your items. And you don't need a hash table. You can just use a direct access array, because if you know your key space is small, that's great. So a lot of C programmers probably would like to do something like that, because they don't have access to-- maybe C++ programmers would have access to their hash table. Any questions on this stuff before we move on? Yeah? AUDIENCE: So why is [INAUDIBLE]? JASON KU: Why is it expected? When I'm building, I could insert-- I'm inserting these things from x 1 by 1 into my hash table. Each of those insert operations-- I'm looking up to see whether that-- an item with that key already exists in my hash table. And so I have to look down the chain to see where it is. However, if I happen to know that all of my keys are unique in my input, all the items I'm trying to store are unique, then I don't have to do that check and I can get worst case linear time. Does that make sense? All right. It's a subtlety, but that's a great question. OK, so today, instead of talking about searching, we're talking about sorting. Last week, we saw a few ways to do sort. Some of them were quadratic-- insertion sort and selection sort-- and then we had one that was n log n. And this thing, n log n, seemed pretty good, but can I do better? Can I do better? Well, what we're going to show at the beginning of this class is, in this comparison model, no. n log n is optimal. And we're going to go through the exact same line of reasoning that we had last week. So in the comparison model, what did we use when we were trying to make this argument that any comparison model algorithm was going to take at least log n time? What we did was we said, OK, I can think of any model in the comparison model-- any algorithm in the comparison model as kind of this-- some comparisons happen. They branch in a binary sense, but you could have it generalized to any constant branching factor. But for our purposes, binary's fine. And what we said was that there were at least n outputs-- really n plus 1, but-- at least order n outputs. And we showed that-- or we argued to you that the height of this tree had to be at least log n-- log the number of leaves. It had to be at least log the number of leaves. That was the height of the decision tree. And if this decision tree represented a search algorithm, I had to walk down and perform these comparisons in order, reach a leaf where I would output something. If the minimum height of any binary tree on a linear number of leaves is log n, then any algorithm in the comparison model also has to take log n time, because it has to do that many comparisons to differentiate between all possible outputs. Does that make sense? All right. So in the sort problem, how many possible outputs are there?","68.5462646484375","9","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_4_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"291","How does an adjacency list represent the edges of a node?","So what is the running time of Dijkstra? If I take a look at that algorithm over there-- well I guess let's switch these back up again. OK, so what does this do? We build once. Then we delete the minimum from the Q how many times? v times. We remove every vertex from our Q. Then for every possible edge, we may need to relax and decrease the key in our queue once for every outgoing edge. So the running time is B plus V times M plus E times D. OK. So how could we implement this priority queue? Well, if we use the stupidest priority queue in the world, here's a list of different implementations we could have for our priority queues. And when I say priority queue, I mean this priority queue. We're already implementing the changeable priority queue by linking it with a dictionary that's efficient If I just use an array, I can find the min in linear time, sure. And I don't have to update that array in any way. I mean, I can just keep the distances in my direct access array. I don't have to store a separate data structure. I just store the distances in my direct access array D, and so I can find it in constant time and I can update the values stored there. And then whenever I want the minimum, I can just loop through the whole thing. So that gives me a really fast decrease key,","68.299560546875","10","DPRSearchEngine","NSHizBK9JD8.en-j3PyPqV-e1s_6_mp4","NSHizBK9JD8.en-j3PyPqV-e1s","6.006","13"
"293","What is a 'digraph'?","OK. So I present to you the beginning and end of our sorting lecture, which is the world's simplest sorting algorithm. I call it permutation sort. I think it's very easy to prove correctness for this particular technique. So in permutation sort, what can I do? Well, I know that if I have an input that's a list of numbers, there exists a permutation of that list of numbers that is sorted by definition because a sort is a permutation of your original list. So what's a very simple sorting algorithm? Well, list every possible permutation, and then just double check which one's in the right order. So there's two key pieces to this particular technique, if we want to analyze it. I don't see a reason to belabor it too much. But one is that we have to enumerate the permutations. Now, if I have a list of n numbers, how many different permutations of n numbers are there? Yes? AUDIENCE: n factorial. JUSTIN: n factorial. So just by virtue of calling this permutation's function, I know that I incur at least n factorial time. It might be worse. It might be that like actually listing permutations takes a lot of time for some reason, like every permutation itself takes order n time. But at the very least, each one of these things looks like n factorial. I warned you my handwriting is terrible. So that's what this omega thing is doing, if I recall properly. And then secondarily, well, we've got to check if that particular permutation is sorted. How are we going to do that? There's a very easy way to check if a list is sorted. I'm going to do maybe for i equals 1 to n minus 1. Notice not a Python coder. It's going to look different. Then check, is Bi less than or equal to Bi plus 1? And so if this relationship is true for every single i-- that's supposed to be a question mark. This was less than or equal to with a question mark over it. There's my special notation. So if I get all the way to the end of this for loop and this is true everywhere, then my list is sorted and life is good. So how long does this algorithm take? Well, it's staring you right in the face because you have an algorithm, which is looping from 1 to n minus 1. So this step incurs order n time because theta of n time because it's got to go all the way to the end of the list. So when I put these things together, permutation sort-- well, remember that this check if sorted happens for every single permutation. So at the end of the day, our algorithm takes at least n factorial times n time. It's a great example of something that's even worse than n factorial, which somehow in my head is like the worst possible algorithm. So do you think that Python implements permutation sort? I certainly hope not. Yes? AUDIENCE: [INAUDIBLE] JUSTIN: Right. So the question was, why is it omega and not big O? Which is a fabulous question in this course. So here's the basic issue. I haven't given you an algorithm for how to compute the set of permutations for a list of numbers. I just called some magic function that I made up. But I know that that algorithm takes at least n factorial time in some sense. Or if nothing else, the list of permutations is n factorial big because that's all the stuff has to compute. So I haven't told you how to solve this problem. But I'm convinced that it's at least this amount of time. So remember that omega means lower bound. So when I put it all together, in some sense-- OK, this isn't satisfying in the sense that I didn't give you precisely the runtime of this algorithm. But hopefully, I've convinced you that it's super useless. Yeah, OK.","71.1070785522461","1","DPRSearchEngine","oS9aPzUNG-s.en-j3PyPqV-e1s_14_mp4","oS9aPzUNG-s.en-j3PyPqV-e1s","6.006","3"
"293","What is a 'digraph'?","I want to print out what an edge looks like, I'm going to ask that it print out the name of the source, and then an arrow, and then the name of the destination. So notice what I do there. Given an instance of an edge, I can print it. And it will get the source or the node associated with source inside this instance, get for that the getName method, and then call it. Notice the open-close paren there to actually call it. What does that do? It says, inside the edge I've got something that points to a node. I get that node. I take the method associated with it. And I call it. That returns the string. And then I glue that together with the arrow. I do the same thing on the destination. And I just print it out. Pretty straightforward, hopefully. OK, now I have to make a decision about the graph. I'm going to start with digraphs, directed graphs. And I need to think about how I might represent the graph. I can create nodes. I can create edges, but I've got to bring them all together. So I'll remind you, a digraph is a directed graph. The edges pass in only one direction. And here's one way I could do it. Given all the sources and all the destinations, I could just create a big matrix called an adjacency matrix. The rows would be all the sources. The columns would be all the destinations. And then in a particular spot in the matrix, if there is an edge between a source and a destination, I'd just put a one. Otherwise I'd put a zero. Note, by the way, because it's a directed graph, it's not symmetric. There might be a one between S and D, but not between D and S, unless there are edges both ways. This would be a perfectly reasonable way to represent a graph, but not the most convenient one. I'd have to go into the matrix to look things up. It may also not be a very efficient way of representing things. For example, if there are very few edges in the graph, I could have a huge matrix with mostly zeros. And that's not the most effective way to do it. So I'm going to use an alternative called an adjacency list. And the idea here is, for every node in the graph. I'm going to associate with it a list of destinations. That is, for a node, what are the places I can reach with a single edge? OK, so let's see what that does if we want to build it. And yes, there's a lot of code here, but it's pretty easy to look through I hope. Here's the choice I'm going to make. Again, what's a graph? It's a set of nodes. It's a set of edges. I'm going to have a way of putting nodes into the graph. And I'm going to choose to, when I put a node into the graph, to store it as a key in a dictionary. OK? When I initialize the graph, I'm just going to set this internal variable, edges, to be an empty dictionary. And the second part of it is, when I add an edge to the graph between two nodes from a source to a destination, I'm going to take that point in the dictionary associated with the source. It's a key. And associated with it, I'm going to just have a list of the nodes I can reach from edges from that source. So notice what happens here. If I want to add a node, remember, it's a node not an edge-- I'll first check to make sure that it's not already in the dictionary. That little loop is basic, or that if is saying, if it's in this set of keys, it will return true. And I'm going to complain. I'm trying to copy a node or duplicate a node. Otherwise, notice what I do. When I put a node into the dictionary, I go into that dictionary, edges. I create an entry with the key that is the node. And the value I put in there is initially an empty list. I'm going to say one more piece carefully. It's a node not a name. And that's OK in Python. It is literally the key is the node itself. It's an object, which is what I'd like. All right, what if I want to add an edge? Well, an edge is going to go from a source to a destination node. So, I'm going to get out from the edge the source piece. I'm going to get out from the edge the destination piece by calling those methods. Again, notice the open-close paren, which takes the method and actually calls it. Because remember, an edge was an object itself. Given those, I'll check to make sure that they are both in the dictionary. That is, I've already added them to the graph. I can't make a connection between things that aren't in the graph. And then notice the nice little thing I do.","70.82453918457031","2","DPRSearchEngine","V_TulH374hw.en-qlPKC2UN_YU_2_mp4","V_TulH374hw.en-qlPKC2UN_YU","6.0002","3"
"293","What is a 'digraph'?","to this interface problem-- the natural solution-- is what I'll call a static array. Jason mentioned these in lecture one. It's a little tricky because there are no static arrays in Python. There are only dynamic arrays, which is something we will get to. But I want to talk about, what is a static array, really? And this relates to our notion of-- our model of computation, Jason also talked about, which we call the word RAM, remember? The idea, in word RAM, is that your memory is an array of w-bit words. This is a bit circular. I'm going to define an array in terms of the word RAM, which is defined in terms of arrays. But I think you know the idea. So we have a big memory which goes off to infinity, maybe. It's divided into words. Each word here is w bits long. This is word 0, word 1, word 2. And you can access this array randomly-- random access memory. So I can give you the number 5 and get 0 1, 2, 3, 4, 5, the fifth word in this RAM. That's how actual memories work. You can access any of them equally quickly. OK, so that's memory. And so what we want to do is, when we say an array, we want this to be a consecutive chunk of memory. Let me get color. Let's say I have an array of size 4 and it lives here. Jason can't spell, but I can't count. So I think that's four. We've got-- so the array starts here and it ends over here. It's of size 4. And it's consecutive, which means, if I want to access the array at position-- at index i, then this is the same thing as accessing my memory array at position-- wherever the array starts, which I'll call the address of the array-- in Python, this is ID of array-- plus i. OK. This is just simple offset arithmetic. If I want to know the 0th item of the array, it's right here, where it starts. The first item is one after that. The second item is one after that. So as long as I store my array consecutively in memory, I can access the array in constant time. I can do get_at and set_at as quickly as I can randomly access the memory and get value-- or set a value-- which we're assuming is constant time. My array access is constant time. This is what allows a static array to actually solve this problem in constant time per get_at and set_at operation. This may seem simple, but we're really going to need this model and really rely on this model increasingly as we get to more interesting data structures. This is the first time we're actually needing it. Let's see. Length is also constant time. We're just going to store that number n, along with its address. And build is going to take linear time. Iteration will take linear time. Pretty straightforward. I guess one thing here, when defining build, I need to introduce a little bit more of our model of computation, which is, how do you create an array in the beginning? I claim I could do it in linear time, but that's just part of the model. This is called the memory allocation model. There are a few possible choices here, but the cleanest one is just to assume that you can allocate an array of size n in theta n time. So it takes linear time to make an array of size n. You could imagine this being constant. It doesn't really matter much. But it does take work. And in particular, if you just allocate some chunk of memory, you have no idea whether it's initialized. So initializing that array to 0s will cost linear time. It won't really matter, constant versus linear, but a nice side effect of this model is that space-- if you're just allocating arrays, the amount of space you use is, at most, the amount of time you use. Or, I guess, big O of that. So that's a nice feature. It's pretty weird if you imagine-- it's unrealistic to imagine you can allocate an array that's infinite size and then just use a few items out of it. That won't give you a good data structure. So we'll assume it costs to allocate memory. OK, great. We solved the sequence problem. Very simple, kind of boring. These are optimal running times. Now, let's make it interesting-- make sure I didn't miss anything--","70.82134246826172","3","DPRSearchEngine","CHhwJjR0mZA.en-j3PyPqV-e1s_3_mp4","CHhwJjR0mZA.en-j3PyPqV-e1s","6.006","2"
"293","What is a 'digraph'?","this is the hard stuff. Here is the bad start, which is challenging enough. Even this little piece is going to be a little bit challenging to describe. Just rewriting from the previous slide. So we're trying to make R1, which is generating all the strings except the rejecting computation history for M on w. It's in those three parts. Right now I'm describing the bad start piece. So that's going to describe all strings that don't start with this C1. So let me write that out here. This is going to generate all strings that don't start with C start or C1, which is as specified. Looks like this. So any string that doesn't start with these symbols, doesn't start exactly like this, should be described by bad start, that regular expression. So that, in itself, is going to be further subdivided. And the reason for that is not that hard to understand. I'm going to-- bad start is going to accomplish its goal by saying, well, anything that doesn't start this way either doesn't start with a q0, or doesn't or doesn't have a w1 in the next place, or doesn't have a w2 in the next place. Or somewhere along the way, it has a wrong symbol. Each one of these guys is going to be about one of those symbols being wrong in some particular place. So I'm going to show you what those look like. So right now, I'm going to focus my attention on describing all strings except for this one. All strings that start with something except for this one. So just remember, delta is the alphabet for the competition histories. And some notation here, delta sub epsilon, we've seen this before, is you're going to add in epsilon as an allowed thing for delta. So it's all the symbols, or epsilon, now thought of as a set here. And furthermore, it's going to be convenient to talk about all of the symbols in delta, except for some symbol. So like at the very beginning, q0. I want to talk about all of the symbols except for q0 symbol. Because that's what I'm going to be using to start off R bad-start. It's going to be anything except for q0. So let's just see how that looks. So here is S0, the very first part of our bad start. It's going to say-- I'm trying to color the active ingredient here in the pink color. So delta, with q0 removed, followed by anything. So this little regular expression here describes all strings that don't start with a q0, as I'm indicating over here. All strings that don't start with a q0 is what as S0 describes. You have to understand that, because it's just going to build up from there. So what do we want to say for S1? What's going to be all strings that don't have w1 in the second place? So I'm going to write that over here. S1 is anything in the first place-- I mean, if the first place was wrong, S0 took care of it. So I'm just going to keep my life simple. All I want to do is describe all of the places where the second symbol is wrong. Namely, it's not w1. So anything in the first place, something besides w1 in the next place, and then anything at all afterward. Those are all strings that don't have-- [AUDIO CUTS] So I'll write it over here like that. Now S2 similarly is going to d since I have exponentiation, let's use that for convenience. Delta delta, or just delta squared. So anything in the first two places, then not w2, and then the next place, and then anything. So that's going to capture this part. So this is what these S's do, and you can sort of get the idea. So dot, dot, dot. This Sn is going to describe everything except for wn in that location, which is going to be the n plus first location, actually. And now I have to continue on doing that for the blanks. So now, if you think with me, let's just take a look how that could go. The next symbol, which is skipping over the n plus 1 that I've already taken care of, I want to say it's not a blank symbol in this very first location after the input. So again, I'm describing these non-- these strings which are not the start configuration. It could fail because there's not a blank where there's supposed to be a blank. Suppose I do that for each one of these guys. That would work. But. But what? Think. This is actually not going to be a good solution for us. Because there are exponentially many blanks over here. This is a hugely long configuration. And so there's exponentially many blanks. If I do it this way, I'm going to end up with an exponentially large regular expression. And that's not doable in polynomial time. So I have a more complicated way of getting the same effect. Which is-- I don't really expect you to fully parse through this right now, in real time in lecture, but let me try to help you. What I'm going to do is skip over these first initial n plus 1 places, and then a variable number of places, which is indicated by the next piece here. And the way that works is-- these are all strings of length n plus 1 through the end of the configuration. And to understand that, it's almost a little too technical to even try, but let's see. If I put delta to the 7, that's all strings of length 7. But if I put delta sub epsilon to the 7, if you think about what that means, that's all strings of length between 0 and 7. Because I can either have it as epsilon as my variable or a symbol from delta. And so that's what I'm doing over here. I'm getting a variable length space, spacer of deltas, that are going to then end up at a certain location-- I'm going to say at that place. Then I have a non-blank. Because all I need to do is describe the strings that fail to have a blank somewhere in this range. So we've got to sort have a variable spacer out to that spot, where that missing blank might be. So that's what this describes. If you didn't get that, don't worry. That is a technical point and you can try to think about it offline. And then at the very end, I'm going to describe what happens. Describe the strings that fail to have a hashtag in that location. It's how I describe all strings that don't start right. That's a lot of work, just to do that little piece. Fortunately, the next two pieces are easier, surprisingly.","70.44258880615234","4","DPRSearchEngine","N32bnUliSzo.en-j3PyPqV-e1s_7_mp4","N32bnUliSzo.en-j3PyPqV-e1s","18.404J","22"
"293","What is a 'digraph'?","called edit distance-- this is a simplest, cleanest version, where I give you two sequences-- I have an example here. So for example, it could be a sequence of letters. So my first sequence spells hieroglyphology-- study of hieroglyphs. And second sequence spells Michelangelo. And what I'd like is a subsequence. So remember, substring has to be some continuous range, some interval. Subsequence-- you can take any subset of the letters in your sequence or any subset of the items in your sequence. So you can have blanks in between. You can skip over items. And so what we want is the longest sequence that is a subsequence of both the first string, the first sequence, and the second string. And if you stare at this long enough, the longest common subsequence-- I don't think it's unique, but there is a longest common sequence, which is hello hiding in there. And that is a longest common subsequence. So given that input, the goal is to compute hello, or whatever the longest common subsequence is. So we're given-- write this down carefully-- given two sequences. Let me name them A and B. We want to find the longest sequence L that's a subsequence both A and B. So that's the problem definition, and we're going to see how to solve it using dynamic programming. And whereas, in the bowling problem, we just had a single sequence of numbers-- the values of the bowling pins-- here we have two sequences. And so we need a new trick. Before, we said, OK, if our subproblems-- or sorry-- if our input consists of a single sequence, we'll try prefixes, suffixes, or substrings. Now we've got two sequences, so somehow we need to combine multiple inputs together.","70.22216796875","5","DPRSearchEngine","KLBCUx1is2c.en-j3PyPqV-e1s_2_mp4","KLBCUx1is2c.en-j3PyPqV-e1s","6.006","16"
"293","What is a 'digraph'?","So how could I use a direct access array to sort faster? Any ideas? Yeah? AUDIENCE: Could you just literally insert [INAUDIBLE] into a direct access array? JASON KU: Uh-huh. AUDIENCE: And then you look at that array and how to sort it. JASON KU: OK. So what your colleague is saying is exactly correct. It's something that I like to call direct access array sort. We won't really call it that, because there's something more general that we'll talk about in just a second. But what your colleague was saying is, instantiate a big direct access array-- direct access array sort. I'm instantiating this big direct access array of the space of my keys, and what your colleague was saying was I take each one of the items in my-- the things that I'm trying to sort, I look at each one of their keys, and I stick it in the direct accessory exactly where it needs to go, in constant time. That's great. Now, I gave you this caveat that all the keys were unique, so I don't have to deal with collisions here. But then, after I'm done with this, all of these things are now in sorted order, and what I can do is I can just walk down this list. A lot of these cells are empty, potentially. Some of the keys might not be there, but what I can do is just walk down this list, pick off every item that does exist, stick them in an array-- I'm done. Stick a key into here and then-- all right. Make direct access array. Store items-- item x in index x.key. Walk down direct access array, and return items seen in order. Does that make sense to everybody? All right, how long does this step take? Building a direct access array order u-- OK, so this is order u-- how long does this take? How many items you have to insert? Order n, or just n-- and how long does it take to insert each one of these things into my direct access array? Worst case constant time-- so this is n times worst case constant time-- great. How long does this last one take? Anyone? O of u also-- right, because I'm walking down the entire length of u. So this algorithm takes, in total, n plus u time. This is great. u is bigger than n, because we assumed distinct keys. But if u is on the order of n, then we now have linear time sorting algorithm. Yes? What's up? AUDIENCE: [INAUDIBLE] JASON KU: I'm sorry. You have to speak up.","69.79753875732422","6","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_6_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"293","What is a 'digraph'?","I just go into the dictionary, edges, and look up the value associated with that node. It gives me back the list. I've got all the things I can reach from that particular node. If I want to know if a node is in the graph, I just search over the keys of the dictionary. They'll either return true or false. If I want to get a node by its name, which is going to be probably more convenient than trying to keep track of all the nodes, well I could pass in a name as a string. And what will I do? I'll just search over all the keys in the dictionary, using the getName method associated with it-- there's the call-- then checking to see if it's the thing I'm looking for. And if it is, I'll return M. I'll return the node itself. What about this thing here? It might bother you a little bit. Wait a minute. That raise, isn't it always going to throw an error? No, because I'm going to go through this loop first. And if I actually find a node, that return is going to pop me out of the call and return the node. So I'll only ever get to this if in fact I couldn't find anything here. And so it's an appropriate way to simply raise the error to say, if I get to this point, couldn't find it, raise an error to say the node's not there. The last piece looks a little funky, Although you may have seen this. I like to print out information about a graph. And I made a choice, which is, I'm going to print out all of the links in the graph. So I'm going to set up a string initially here that's empty. And then I'm going to loop over every key in the dictionary, every node in the graph. And for each one, I'm going to look at all the destinations. So notice, I take the dictionary, I look up the things at that point. That's a list. I loop over that. And I'm just going to add in to result, the name of the source, an arrow, and the name of the destination followed by a carriage return. I'll show you an example in a second. But I'm simply walking down the graph, saying for each source, what can it reach? I'll print them all out. And then I'll return everything but the last element. I'm going to throw away the last carriage return because I don't really need it. So let me show you an example here, trusting that my Python has come up the way I wanted it to. So I'm going to load that in, ignore that for the moment. And I'm going to set g to-- I've got something we're going to come back to in a second that actually creates a graph. And if I print out g, it prints out, in this case, all of the links from source to destination, each one on a new line. OK. So I can create the graphs. That was digraphs. Suppose I actually want to get a graph. Well, I'm going to make it as a subclass of digraph. And in particular, the only thing I'm going to do is I'm going to shadow the addEdge method of digraphs. So if you think about it, it's so I make a graph. If I ask it to add edges, it's going to use this version of addEdge. And what am I going to do? I know in a graph, I could have both directions work. So, given an edge that I want to add into this graph,","69.28094482421875","7","DPRSearchEngine","V_TulH374hw.en-qlPKC2UN_YU_4_mp4","V_TulH374hw.en-qlPKC2UN_YU","6.0002","3"
"293","What is a 'digraph'?"," 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
   
 
 
 
 
Write “Hello World”
Hello World
Write this sentence
Write this sentence
Write the following twice, the second time in quotes “Hello World”
Hello World “Hello World”
Cheating: TMs don’t have this self-reference primitive.
English Implementation 
Check-in 11.1 
Implementations of the Recursion Theorem have two parts, 
a Template and an Action. In the TM and English implementations, 
which is the Action part? 
(a) A and the upper phrase 
(b) A and the lower phrase 
(c) B and the upper phrase 
(d) B and the lower phrase. 
Write the following twice, the second time in quotes 
“Write the following twice, the second time in quotes” 
Write the following twice, the second time in quotes 
“Write the following twice, the second time in quotes” 
& 
% 
' 〈)〉 
Compute & = ' 〈)〉 
from % on tape. 
!""#$ 
Note on Pset Problem 6: Don’t need to worry about quoting. 
5 
Check-in 11.1 
&% 
","68.84252166748047","8","DPRSearchEngine","779043ea724131d008eae652d703938f_MIT18_404f20_lec11_5_pdf","779043ea724131d008eae652d703938f_MIT18_404f20_lec11","18.404J","11"
"293","What is a 'digraph'?","so a push out of tabaton operates like a finite like a non-deterministic finite diameter as we'll see push down automata for out for us are always going to be allowed to be non-deterministic so we're not going to be studying the push on automata that are restricted to be only deterministic um uh i'll say more about that in a second but like they operate like an nfa except they can write uh or read symbols from the top of the stack and when they write they're adding the symbol on pushing down that stack and when they're reading they're removing symbols from the stack and thereby lifting up the stack okay we give them special names so those of you who have seen stacks already this is you know i'm sure old hat for you uh but i'm sure now everyone has have seen stacks before so uh the special name for writing onto a stack is called a push operation so that you're pushing a new symbol down on the top of the stack and it pushes everything down whereas when you're reading a symbol and removing it from the top of the stack that's called a pop so that's reading and removing we we always think of those as going together writing and editing and reading and removing are combined i mean you might wonder why can't i just read it and leave it alone and not just have remove it you uh no you can get that effect by reading it and then uh which removes it and then putting it back if you really want it to stay there but the way we're setting it up is that reading comes with removing writing comes with adding okay and they're called pushing and popping okay so let's do an example um so we have here a push down automaton for a language we'll call d it's a we've seen that language before it's this uh it was um actually we use the same uh letter for it the strings of zeros followed by ones where the numbers are the same of the two so zero to the k one to the k we couldn't do that with a finite automaton we will be able to do that with a push down automaton um and here i uh um i thought i wrote down the input here but okay so the basic idea is i'm going to give you a uh an input now and the pushdown of the tombiton is supposed to test whether that input is in the language whether it's of this form um now it has the ability to use the stack because you know it's going to have to count how many zeros it has and so the way it's going to do it is you know i have a bunch of zeros hopefully and then a bunch of ones and you want to see that they're uh of the same number it's going to take the zeros and store them on the stack until it sees a one and then one's going to start to read the ones and it's going to remove the zeros matching them off one to one with the ones that it's seen okay so um you initially first read the zeros and push them onto the stack until you read a one and then you read the ones uh while popping zeros from the stack and you enter the accept state if the stack is empty just like with a finite automaton the except entering the accept state only counts when you're at the end of the input okay so um without me needing to say anything it's really saying you enter the accept state if the stack is empty at the end of the input string but that's kind of implicit because it only takes effect at the end of the input string if you enter an accept state alone in the middle somewhere it doesn't matter it doesn't affect anything um okay uh with that we're going to take a little break and then we'll be back uh shortly to look at push down automata again in a more uh with a more formal definition um let me put that's going to be five minutes so if i can figure out how to get my timer screen up here yes and we will uh the camera when the candle burns down to nothing we will return and continue okay our candle has burned down and has gone out i think i never actually watched to see what would happen at the end uh so um we're good to go let's continue um uh good and let me put myself back in there all righty um [Music] so we were doing push down automata and we just did that example of zero to the k1 to the k now that you have a stack we can do uh all sorts of fancy things that fina tamara could not do just with their limited memory okay so let's take a look at how we define push down automata um [Music] so now uh push down automata is actually going to be a six tuple so it's a little bit got some fancier stuff here to deal with not too much but a little bit um and uh so it has uh let's look at these a little bit more carefully since there's some novelty here we have the uh input alphabet just as we had before uh sigma but we also have gamma which is the alphabet for uh using the stack now um you might ask why don't we just use the same alphabet well it's really a matter of convenience um that we would like to be able to have other symbols that uh could include the input alphabet but could include other things as well so it just gives you more flexibility in terms of what you're going to be writing on the stack um okay the transition function more complicated uh so i think i don't know if i'm going to even say what the other things are but you know these are the accepting states this is the starting state so that's um the same as before but the transition function is is a much different animal here in a push-down automaton so let's just try to uh unpack that and understand what it's saying the transition function tells us how the machine operates how it goes from state to state how it's going to read the input how it reads from the stack and what it might write on the stack too because that's going to all happen under program control so um what this means here is that you know when the machine is in a particular state um reading a particular input symbol let's ignore the empty string uh subscript for the monument so it's in a particular state reading a particular input symbol and with a certain stack symbol appearing at the top of the stack so that's all information that's available to the controller of this pushdown automaton the transition function the current state the next input symbol and the symbol at the top of the stack and once we have that we know what new state we can go into and what new symbol we can write on the top of the stack okay so that's what the uh um right-hand side of this function specification means so this is where uh kind of the input to the function this is going to be the output of the function state entry and a new symbol to appear on the stack so this is the popping symbol this is the pushing symbol so now there are two things that bear explanation here first of all now this is this is a power set so this is going to be representing as we did before um a non-deterministic machine we may have several possibilities and we're going to represent that as a set of possibilities for the machine that it could go to at any point i will give an example of how a push down automaton uses its non-determinism in a minute the other thing is is these epsilons so we have to understand why they are there and we remember we had them for the nfas corresponding to when the nfa had an epsilon transition an empty transition so it could go along that transition without reading any input so this is going to play the same role here so if you have um instead of an input symbol from sigma appearing in this um uh part of the you know uh for the for the transition function instead you have an you have an epsilon appearing that means that the transition that that move of the machine can happen without reading any input symbol just like for the nfa's or if you have an epsilon appearing for the stack symbol that means you can make that transition without reading any stack symbol so any whatever's sitting on the top of the stack it doesn't matter the machine can make that move and it won't read anything either we're not going to pop anything it's just going to uh be proceeding without looking at the stack at all or it might have both of them which case it's going to go from one state to another state without looking at the input or at the top of the stack so um that's what the possibility of epsilon means for the um for the transition function in the in those places the epsilon appearing over here means something a little different but very similar what that means is that um [Music] we won't write anything on the top of the stack that's going to be we will go to a new state but without doing any writing so we'll leave the stack alone um so here means we're not going to read anything if it's in this position in this position means we're not going to write anything okay so all of those things are valid and legal from the perspective of you know constructing a push-down automaton and i've kind of illustrated here you know just with a little bit of an example if you have delta that applies to some state q reading an input symbol a and popping a c from the top of the stack then you might have let's say in this case two possibilities that you might end up going to you might end up going to states r1 or to states r2 and in the former case you'll end up writing a d pushing a d onto this top of the stack and in the latter case you would be pushing an e onto the top of the stack okay so this is i'm trying to help you look at this notation you can you know you know i hope this is clear to you um i'm sure for some of you it's too slow but others of you i'm trying to help along but if you're really struggling with this notation at this point you know you really have to going to have to dig in and make sure you follow it because it's only going to get harder from there i'm going to stop being uh going over these these kinds of points and if you're still struggling you can't get it this is not the right class for you i'll just i'll be honest um because we're just gonna be","68.61383056640625","9","DPRSearchEngine","m9eHViDPAJQ.en_9_mp4","m9eHViDPAJQ.en","18.404J","4"
"293","What is a 'digraph'?","OK, so now let's talk about some more the computation, so strings and languages. A string is just a finite sequence of symbols from the alphabet. This class is not going to talk about infinite strings. All of our strings are going to be finite. There's other mathematical theories of automata and so on that talk about infinite inputs and infinite strings. We're not going to talk about that. Maybe rarely, we'll make it very clear, we'll talk about an infinite string, but that's going to be an exception. And a language is a set of strings. That's the traditional way that people in this subject refer to a set of strings. They call it a language-- really because the subject had its roots in linguistics, actually. And they were talking about-- they're trying to understand languages, human languages. So this is just a historical fact, and that's the terminology that's stuck. OK, so two special string-- a special string and a special language. The empty string is the string of length 0. This is a totally legitimate string that you are going to run into now and then. And there's the empty language, which is the set with no strings. These are not the same. They're not even of the same type of object. So don't confuse them with one another. I mean, you can have a set, a language, which has just one element, which is the empty string. That is not the empty set. That is a set-- that is not the empty language. That is a language that has one element in it, namely, the empty string. So those are separate things. OK, so here's a little bit of a mouthful here on the slide, defining what it means for an automaton to accept its input-- accepts its input string w. And we can define that formally. And it's a little technical looking, it's really not that bad. So if you have your input string w, which you can write as a sequence of symbols in the alphabet-- w1, w2, dot dot dot, wn, so like 01001. I'm just writing it out symbol by symbol here. So what does it mean for the machine to accept that input? So that means that there's a sequence of states in the machine, sequence of states of members of Q. So a sequence from Q, these are the states of the machine that satisfy these three properties down here. First of all-- and I'm thinking about the sequence that the machine goes through as it's processing the input w. So when does it accept w? If that sequence has the feature that it starts at the start state, each state legally follows the previous state according to the transition function. So that says the i-th member of the sequence is obtained by looking at the previous one-- the i minus first member of that sequence, the i minus first state in that sequence-- and then looking at what happens when you take the i-th input symbol. So as you look at the previous state and the next input symbol, you should get the next state. That's all that this is saying. And this should happen for each one of these guys. And lastly, for this to be accepted, the very last member here, where we ended up at the end of the input-- so you only care about this at the end of the input-- you have to be in an accepting state. So you can mathematically capture this notion of going along this path. And that's what-- I'm just trying to illustrate that we could describe all this very formally-- I'm not saying that's the best way to think about it all the time-- but that it can be done. And I think that's something worth appreciating. OK. So now in terms of, again, getting back-- we've said this once already, but in terms of the languages that the machine recognizes, it's the collection of strings that the machine accepts. Every machine accepts-- it might accept many strings, but it always recognizes one particular language, even if the machine accepts no strings-- then it recognizes the empty language. So a machine always recognizes one language, but it may have many, many strings that it's accepting. And we call that language the language of the machine. And we say that M recognizes that language. These three things mean the same thing. OK? And now important definition-- I try to reserve the most important things or the highlighted things to be in this light blue color, if you can see that. We say a language is a regular language if there's some finite automaton that recognizes it. OK? So there are going to be some languages that have associated to them finite automata that actually solve those languages, that recognize those languages. But there might be other languages-- and we'll see examples-- where you just can't solve them. You can't recognize them with a finite automaton. Those languages will not be regular languages. The regular ones are the ones that you can do with a finite automaton. That's the traditional terminology.","68.51180267333984","10","DPRSearchEngine","9syvZr-9xwk.en-j3PyPqV-e1s_7_mp4","9syvZr-9xwk.en-j3PyPqV-e1s","18.404J","1"
"294","How are nodes initially stored in the graph according to the description?","So what we're going to do, because we're in place, basically we have to have an array storing our end items. That's sort of the definition of in-place, just using n slots of memory exactly the size of the number of items in our structure. But we're obviously not going to use a regular unsorted array or a regular sorted array. We're going to use array just as sort of the underlying technology for how things are stored. But we'd really like logarithmic performance, which should make you think tree. Only way to get a log is the binary tree, more or less. So somehow, we want to embed a tree into an array. Let me grab an example.","70.66232299804688","1","DPRSearchEngine","Xnpo1atN-Iw.en-j3PyPqV-e1s_6_mp4","Xnpo1atN-Iw.en-j3PyPqV-e1s","6.006","8"
"294","How are nodes initially stored in the graph according to the description?","namely, random accessing. And if we stored the things that we're looking for, we have unique keys, and those keys are integers. Then, if I have an item with key K, if I store it at index K in my array, then I can find it and manipulate it in constant time.","70.07069396972656","2","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_2_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"294","How are nodes initially stored in the graph according to the description?","It's basically-- it's a set type thing, where I can make a set of just a single element, I can take two sets, merge them together, make them their union, and then given an object, I say, which set am I part of, essentially by electing a leader within a set and saying, return me a pointer to that one. And so this can be useful in dynamically maintaining, say, the connected components in a dynamically changing graph supporting the query of, am I in the same component as this other guy? That could be a very useful thing to know about a graph as it's changing. So that's an application of this problem. And they get near-constant performance for a lot of these queries. It's not quite, but pretty close. OK, on the graph side, they solve","69.96940612792969","3","DPRSearchEngine","2NMtS1ecb3o.en-j3PyPqV-e1s_6_mp4","2NMtS1ecb3o.en-j3PyPqV-e1s","6.006","20"
"294","How are nodes initially stored in the graph according to the description?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","69.88127899169922","4","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"294","How are nodes initially stored in the graph according to the description?"," 
 
 
 
 
 
 
 
 
Machine  Learning Paradigm  
§Observe set of examples: training data 
§Infer something about process that generated that 
data 
§Use inference to make predictions about previously 
unseen data: test data 
§Supervised: given a set of feature/label pairs, find a 
rule that predicts the label associated with a previously 
unseen input 
§Unsupervised: given a set of feature vectors (without 
labels) group them into “natural clusters” 
6.0002  LECTURE 12 
3 
","69.58561706542969","5","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_3_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"294","How are nodes initially stored in the graph according to the description?"," 
 
  
  
 
 
 
 
 
 
   
 
 
 
 
  
 
  
 
  
 
 
  
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
   
 
    
   
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
   
  
Time Hierarchy Theorem (1/2) 
Theorem: For any !: ℕ → ℕ where ! is time constructible 
there is a language % where % requires & ! ' 
time, i.e, 
1) % is decidable in & ! ' 
time, and 
2) % is not decidable in ( ! ' / log ! ' 
time 
- .
On other words, TIME (
⊆, TIME ! ' 
/01 - . 
Proof outline:  Give TM 3 where 
1) 3 runs in & ! ' 
time 
2) 3 ensures that 4(3) ≠ 4(8) for every TM 8 that runs in ( ! ' / log ! ' 
time . 
Let % = 4(3). 
10 
","68.6624984741211","6","DPRSearchEngine","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21_10_pdf","985c567f01d3ad47d737c3b33eb678ea_MIT18_404f20_lec21","18.404J","21"
"294","How are nodes initially stored in the graph according to the description?","We're almost done. This will actually work. It's really quite awesome. But for it to work, we need something called subtree augmentation, which I'll talk about generally. And then, we'll apply it to size. So the idea with subtree augmentation is that each node in our binary tree can store a constant number of extra fields. Why not? And in particular, if these fields are of a particular type-- maybe I'll call them properties. I'm going to define a subtree property to be something that can be computed from the properties of the nodes' children. So I should say this is of a node. So children are node.left and node.right. You can also access constant amount of other stuff,","68.56298065185547","7","DPRSearchEngine","U1JYwHcFfso.en-j3PyPqV-e1s_9_mp4","U1JYwHcFfso.en-j3PyPqV-e1s","6.006","7"
"294","How are nodes initially stored in the graph according to the description?"," 
 
 
   
 
 
 
   
   
      
 
 
 
 
 
 
  
 
Stochastic Processes  
An ongoing process where the next state might depend on 
both the previous states and some random element 
def rollDie(): 
"""""" returns an int between 1 and 6"""""" 
def rollDie(): 
"""""" returns a randomly chosen int 
between 1 and 6"""""" 
6.0002 LECTURE 4 
8
","68.54554748535156","8","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_8_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"294","How are nodes initially stored in the graph according to the description?","§ Time based on number of nodes generated 
§ Number of levels is number of items to choose from 
§ Number of nodes at level i is 2i 
§ So, if there are n items the number of nodes is 
◦ ∑𝑖=0↑𝑖=𝑛▒​2↑𝑖   
◦ I.e., O(​2↑𝑛+1 ) 
§ An obvious op<miza<on: don’t explore parts of tree 
that violate constraint (e.g., too many calories) 
◦ Doesn’t change complexity 
§ Does this mean that brute force is never useful? 
◦ Let’s give it a try 
Computa#onal Complexity 
6.0002 LECTURE 2 
8 
","68.5013198852539","9","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_8_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"294","How are nodes initially stored in the graph according to the description?","You've taken, probably-- you've probably seen linked lists before at some point. But the main new part here is, we're going to actually analyze them and see how efficiently they implement all of these operations we might care about. First, review. What is a linked list? We store our items in a bunch of nodes. Each node has an item in it and a next field. So you can think of these as class objects with two class variables, the item and the next pointer. And we assemble those into this kind of structure where we store-- in the item fields, we're going to store the actual values that we want to represent in our sequence, x 0 through x n minus 1, in order. And then we're going to use the next pointers to link these all together in that order. So the next pointers are what actually give us the order. And in addition, we're going to keep track of what's called the head of the list. The data structure is going to be represented by a head. If you wanted to, you could also store length. This could be the data structure itself. And it's pointing to all of these types of data structures. Notice, we've just seen an array-based data structure, which is just a static array, and we've seen a pointer-based data structure. And we're relying on the fact that pointers can be stored in a single word, which means we can de-reference them-- we can see what's on the other side of the pointer-- in constant time in our word RAM model. In reality, each of these nodes is stored somewhere in the array of the computer. So maybe each one is two words long, so maybe one node is-- the first node is here. Maybe the second node is here. The third node is here. They're in some arbitrary order. We're using this fact, that we can allocate an array of size n in linear time-- in this case, we're going to have arrays of size 2. We can just say, oh, please give me a new array of size 2. And that will make us one of these nodes. And then we're storing pointers. Pointers are just indices into the giant memory array. They're just, what is the address of this little array? If you've ever wondered how pointers are implemented, they're just numbers that say where, in memory, is this thing over here? And in memory, they're in arbitrary order. This is really nice because it's easy to manipulate the order of a linked list without actually physically moving nodes around, whereas arrays are problematic. Maybe it's worth mentioning. Let's start analyzing things. So we care about these dynamic sequence operations. And we could try to apply it to the static array data structure, or we could try to implement these operations in a static array. It's possible, just not going to be very good. And we can try to implement it with linked lists. And it's also not going to be that great.","68.33928680419922","10","DPRSearchEngine","CHhwJjR0mZA.en-j3PyPqV-e1s_5_mp4","CHhwJjR0mZA.en-j3PyPqV-e1s","6.006","2"
"296","What is the purpose of using weights in the histogram plot of the Gaussian distribution?","And second, that the distribution of errors will be normally distributed. I didn't probably mention at the time, but we often call this distribution Gaussian after the astronomer Carl Gauss. And it looks like that. Normal distributions are very easy to generate in Python. I have a little example here of generating, not a real normal distribution, but a discrete approximation of one. And the thing to really notice about it here is this line random.gauss. So that's a built in function of the random library. The first argument is the mean. And the second argument is the standard deviation or a mu and sigma as they're usually called. Every time I call that, I will get a different-- or usually a different random value drawn from a Gaussian with the mean, in this case of 0 and a standard deviation of 100. I'm then going to produce a plot of those so you can see what it looks like. And I'm going to do that using some things we haven't seen before. So first of all, we've seen histograms.","72.21097564697266","1","DPRSearchEngine","rUxP7TM8-wo.en-qlPKC2UN_YU_2_mp4","rUxP7TM8-wo.en-qlPKC2UN_YU","6.0002","7"
"296","What is the purpose of using weights in the histogram plot of the Gaussian distribution?","And we'll come back to this in just a second. But this is a normal distribution, called the Gaussian. Under those two assumptions the empirical rule will always hold. All right, let's talk about distributions, since I just introduced one. We've been using a probability distribution. And this captures the notion of the relative frequency with which some random variable takes on different values.","69.8200454711914","2","DPRSearchEngine","OgO1gpXSUzU.en-j3PyPqV-e1s_16_mp4","OgO1gpXSUzU.en-j3PyPqV-e1s","6.0002","6"
"296","What is the purpose of using weights in the histogram plot of the Gaussian distribution?","There's my data, and I actually have done this in some ways the wrong order. These are my independent measures, different masses. I'm going to plot those along the x-axis, the horizontal axis. These are the dependent things. These are the things I'm measuring. I'm going to plot those along the y-axis. So I really should have put them in the other order. So just cross your eyes and make this column go over to that column, and we'll be in good shape. Let's plot this. So here's a little file. Having stored those away in a file, I'm just going to read them in, get data. Just going to do the obvious thing of read in these things and return two tuples or lists, one for the x values-- or if you like, again going back to it, this set of values, and one for the y values. Now I'm going to play a little trick that you may have seen before that's going to be handy to me. I'm going to actually call this function out","68.65403747558594","3","DPRSearchEngine","vIFKGFl1Cn8.en-qlPKC2UN_YU_4_mp4","vIFKGFl1Cn8.en-qlPKC2UN_YU","6.0002","9"
"296","What is the purpose of using weights in the histogram plot of the Gaussian distribution?","I'm going to look at a bunch of different sample sizes, from 25 to 600, 50 trials each. So getHighs is just a function that returns the temperatures. I'm going to get the standard deviation of the whole population, then the standard error of the means and the sample standard deviations, both. And then I'm just going to go through and run it. So for size and sample size, I'm going to append the standard error of the mean. And remember, that uses the population standard deviation and the size of the sample. So I'll compute all the SEMs. And then I'm going to compute all the actual standard deviations, as well. And then we'll produce a bunch of plots-- or a plot, actually. All right, so let's see what that plot looks like.","68.52274322509766","4","DPRSearchEngine","soZv_KKax3E.en-qlPKC2UN_YU_10_mp4","soZv_KKax3E.en-qlPKC2UN_YU","6.0002","8"
"296","What is the purpose of using weights in the histogram plot of the Gaussian distribution?","So let me show you what this does, and then we're going to use it. The y's are measured values. Those are my samples I got from my experiment. The p's are the predicted values. That is, for this curve, here's what I predict those values should be. So the top here is basically measuring as we saw before the sum squared error in those pieces. Mu down here is the average, or mean, of the measured values. It's the average of the y's. So what I've got here is in the numerator-- this is basically the error in the estimates from my curve fit. And in the denominator I've got the amount of variation in the data itself. This is telling me how much does the data change from just being a constant value, and this is telling me how much do my errors vary around it. That ratio is scale independent because it's a ratio. So even if I increase all of the values by some amount, that's going to divide out, which is kind of nice. So I could compute that, and there it is.","68.37696075439453","5","DPRSearchEngine","vIFKGFl1Cn8.en-qlPKC2UN_YU_15_mp4","vIFKGFl1Cn8.en-qlPKC2UN_YU","6.0002","9"
"296","What is the purpose of using weights in the histogram plot of the Gaussian distribution?"," 
 
Looking at  Distributions 
def plotDistributions():  
uniform, normal, exp = [], [], []  
for i in range(100000):  
uniform.append(random.random())  
normal.append(random.gauss(0, 1))  
exp.append(random.expovariate(0.5))  
makeHist(uniform, 'Uniform', 'Value', 'Frequency')  
pylab.figure()  
makeHist(normal, 'Gaussian', 'Value', 'Frequency')  
pylab.figure()  
makeHist(exp, 'Exponential', 'Value', 'Frequency')  
6.0002  LECTURE 8 
 
27
","68.15013122558594","6","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_27_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"296","What is the purpose of using weights in the histogram plot of the Gaussian distribution?","Well, here's a histogram of one random sample of size 100. Looks pretty different, as you might expect. Its standard deviation is 10.4, its mean 17.7. So even though the figures look a little different, in fact, the means and standard deviations are pretty similar. If we look at the population mean and the sample mean-- and I'll try and be careful to use those terms-- they're not the same. But they're in the same ballpark. And the same is true of the two standard deviations. Well, that raises the question, did we get lucky or is something we should expect? If we draw 100 random examples, should we expect them to correspond to the population as a whole? And the answer is sometimes yeah and sometimes no. And that's one of the issues I want to explore today. So one way to see whether it's a happy accident is to try it 1,000 times. We can draw 1,000 samples of size 100 and plot the results. Again, I'm not going to go over the code. There's something in that code, as well, that we haven't seen before. And that's the ax.vline plotting command. V for vertical. It just, in this case, will draw a red line-- because I've said the color is r-- at population mean on the x-axis. So just a vertical line. So that'll just show us where the mean is. If we wanted to draw a horizontal line, we'd use ax.hline. Just showing you a couple of useful functions. When we try it 1,000 times, here's what it looks like. So here we see what we had originally, same picture I showed you before. And here's what we get when we look at the means of 100 samples. So this plot on the left looks a lot more like it's a normal distribution than the one on the right. Should that surprise us, or is there a reason we should have expected that to happen? Well, what's the answer? Someone tell me why we should have expected it. It's because of the central limit theorem, right? That's exactly what the central limit theorem promised us would happen. And, sure enough, it's pretty close to normal. So that's a good thing. And now if we look at it, we can see that the mean of the sample means is 16.3, and the standard deviation of the sample means is 0.94. So if we go back to what we saw here, we see that, actually, when we run it 1,000 times and look at the means, we get very close to what we had initially. So, indeed, it's not a happy accident. It's something we can in general expect. All right, what's the 95% confidence interval here? Well, it's going to be 16.28 plus or minus 1.96 times 0.94, the standard deviation of the sample means. And so it tells us that the confidence interval is, the mean high temperature, is somewhere between 14.5 and 18.1. Well, that's actually a pretty big range, right? It's sort of enough to where you wear a sweater or where you don't wear a sweater. So the good news is it includes the population mean. That's nice. But the bad news is it's pretty wide. Suppose we wanted it tighter bound. I said, all right, sure enough, the central limit theorem is going to tell me the mean of the means is going to give me a good estimate of the actual population mean. But I want it tighter bound. What can I do? Well, let's think about a couple of things we could try. Well, one thing we could think about is drawing more samples. Suppose instead of 1,000 samples, I'd taken 2,000 or 3,000 samples. We can ask the question, would that have given me a smaller standard deviation? For those of you who have not looked ahead, what do you think? Who thinks it will give you a smaller standard deviation? Who thinks it won't? And the rest of you have either looked ahead or refused to think. I prefer to believe you looked ahead. Well, we can run the experiment. You can go to the code. And you'll see that there is a constant of 1,000, which you can easily change to 2,000. And lo and behold, the standard deviation barely budges. It got a little bit bigger, as it happens, but that's kind of an accident. It just, more or less, doesn't change. And it won't change if I go to 3,000 or 4,000 or 5,000. It'll wiggle around. But it won't help much. What we can see is doing that more often is not going to help. Suppose we take larger samples? Is that going to help? Who thinks that will help? And who thinks it won't? OK. Well, we can again run the experiment. I did run the experiment. I changed the sample size from 100 to 200. And, again, you can run this if you want. And if you run it, you'll get a result-- maybe not exactly this, but something very similar-- that, indeed, as I increase the size of the sample rather than the number of the samples, the standard deviation drops fairly dramatically, in this case from 0.94 0.66. So that's a good thing. I now want to digress a little bit before we come back to this and look at how you can visualize this-- Because this is a technique you'll want to use as you write papers and things like that-- is how do we visualize the variability of the data? And it's usually done with something called an error bar. You've all seen these things here.","67.853271484375","7","DPRSearchEngine","soZv_KKax3E.en-qlPKC2UN_YU_5_mp4","soZv_KKax3E.en-qlPKC2UN_YU","6.0002","8"
"296","What is the purpose of using weights in the histogram plot of the Gaussian distribution?","Bins tells us how many bins we want in the histogram. I said we want 100. The default is 10. Dist is the values it will use for it. And then this is something we haven't seen before, weights. Weights is a keyword argument. So normally when we produce a histogram, we take all of the values, the minimum to the maximum, and in this case, we would divide them into 100 bins, because I said, bins equals 100. So the first bin might be, well, let's say we only had values ranging from 0 to 100. The first bin would be all the 0's, all the 1's up to all the 99's. And it weights each value in the bin by 1. So if the bin had 10 values falling in it, the y-axis would be a 10. If the bin had 50 values falling in it, the y-axis would go up to 50. You can tell it how much you want to weight each bin, the elements in the bins. And say, no, I don't want them each to count as 1, I want them to count as a half or a quarter, and that will change the y-axis. So that's what I've done here. What I've said is I've created a list and I want to say for each of the bins-- in this case I'm going to weigh each of them the same way-- the weight is going to be 1 over the number of samples. I'm multiplying it by the len of dist, that will be how many items I have. And that will tell me how much each one is being weighted. So for example, if I have, say, 1,000 items, I could give 1,000 values and say, I want this item weighted by 1, and I want this item over here weighted by 12 or a half. We rarely do that. Usually, what we want is to give each item the same weight. So why would I want it not to be weighted at just one? Because I want my y-axis to be more easily interpreted, and essentially give me the fraction of the values that fell in that bin. And that's what I'm doing here. The other new thing I'm doing here is the plotting commands, including pylab.hist, many of them return values. Usually, I just ignore that value when we just say pylab.plot or pylab.hist. Here I am taking the value. The value in this case for a histogram is a tuple of length 2. The first element is a list or an array, giving me how many items are in each bin. And the second is the patches used to produce the beautiful pictures we're use to seeing. So here what I'm going to do is take this value so that I can do this at the end. Now, why would I want to look at the fraction within approximately 200 of the mean? What is that going to correspond to in this case? Well, if I divide 200 by 2 I get 100. Which happens to be the standard deviation. So in this case, what I'm going to be looking at is what fraction of the values fall within two standard deviations of the mean? Kind of a check on the empirical rule, right? All right, when I run the code I get this. So it is a discrete approximation to the probability density function. You'll notice, unlike the previous picture I showed you which was nice and smooth, this is jaggedy. You would expect it to be. And again, you can see it's very nice that the peak is what we said the mean should be, 0. And then it falls off. And indeed, slightly more than 95% fall within two standard deviations of the mean. I'm not even surprised that it's a little bit more than 95% because, remember the magic number is 1.96, not 2. But since this is only a finite sample, I only want it to be around 95. I'm not going to worry too much whether it's bigger or smaller. All right? So random.gauss does a nice job of giving us Gaussian values. We plotted them and now you can see that I've got the relative frequency. That's why I see fractions in the y-axis rather than counts. And that would be because of the way I use the weights command. All right, let's return to PDFs. So as we said last time, distributions can be defined by Probability Density Functions, and that gives us the probability of some random variable lying between two values. It defines a curve where the values in the x-axis lie between the minimum and maximum values of the variable. And it's the area under the curve-- and we'll come back to this-- between those two points that give us the probability of an example falling in that range. So now let's look at it for a normal distribution.","67.76949310302734","8","DPRSearchEngine","rUxP7TM8-wo.en-qlPKC2UN_YU_3_mp4","rUxP7TM8-wo.en-qlPKC2UN_YU","6.0002","7"
"296","What is the purpose of using weights in the histogram plot of the Gaussian distribution?","on the right. And I guess if I look at it, it looks like logistic regression did a little bit better. That's not guaranteed, but it often does outperform because it's more subtle in what it does, in being able to assign different weights to different variables. It's a little bit better. That's probably a good thing, but there's another reason that's really important that people prefer logistic regression, is it provides","67.18903350830078","9","DPRSearchEngine","eg8DJYwdMyg.en-qlPKC2UN_YU_11_mp4","eg8DJYwdMyg.en-qlPKC2UN_YU","6.0002","13"
"296","What is the purpose of using weights in the histogram plot of the Gaussian distribution?","is that the variance of the sample means will be close to the variance of the population divided by the sample size. And we're going to use that to compute something called the standard error-- formerly the standard error of the mean. People often just call it the standard error. And I will be, alas, inconsistent. I sometimes call it one, sometimes the other. It's an incredibly simple formula. It says the standard error is going to be equal to sigma, where sigma is the population standard deviation divided by the square root of n, which is going to be the size of the sample. And then there's just this very small function that implements it. So we can compute this thing called the standard error of the mean in a very straightforward way. We can compute it. But does it work? What do I mean by work? I mean, what's the relationship of the standard error to the standard deviation? Because, remember, that was our goal, was to understand the standard deviation so we could use the empirical rule. Well, let's test the standard error of the mean.","67.05810546875","10","DPRSearchEngine","soZv_KKax3E.en-qlPKC2UN_YU_9_mp4","soZv_KKax3E.en-qlPKC2UN_YU","6.0002","8"
"298","How does the depth-first search algorithm avoid loops when searching for a path?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","76.1063232421875","1","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"298","How does the depth-first search algorithm avoid loops when searching for a path?","search-- BFS, for those in the know. Breadth-first search is an algorithm. And the reason we use the word breadth is because it's kind of, remember, we talked about level sets last time because we talked about breadth-first search in the context of computing shortest paths. And in particular, we have our source node all the way on the left-hand side. And then breadth-first search constructed all the nodes that were distance 1 away. Right. That's the first level set, and then all the distance 2 away, and then all the distance 3 away, and so on. So in particular, the level set L3 isn't visited until we're completely done with level set L2.","75.09264373779297","2","DPRSearchEngine","IBfWDYSffUU.en-j3PyPqV-e1s_7_mp4","IBfWDYSffUU.en-j3PyPqV-e1s","6.006","10"
"298","How does the depth-first search algorithm avoid loops when searching for a path?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","75.08702087402344","3","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"298","How does the depth-first search algorithm avoid loops when searching for a path?","§ Time based on number of nodes generated 
§ Number of levels is number of items to choose from 
§ Number of nodes at level i is 2i 
§ So, if there are n items the number of nodes is 
◦ ∑𝑖=0↑𝑖=𝑛▒​2↑𝑖   
◦ I.e., O(​2↑𝑛+1 ) 
§ An obvious op<miza<on: don’t explore parts of tree 
that violate constraint (e.g., too many calories) 
◦ Doesn’t change complexity 
§ Does this mean that brute force is never useful? 
◦ Let’s give it a try 
Computa#onal Complexity 
6.0002 LECTURE 2 
8 
","74.85310363769531","4","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_8_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"298","How does the depth-first search algorithm avoid loops when searching for a path?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 10: Depth-First Search 
Lecture 10: Depth-First Search 
Previously 
• Graph deﬁnitions (directed/undirected, simple, neighbors, degree) 
• Graph representations (Set mapping vertices to adjacency lists) 
• Paths and simple paths, path length, distance, shortest path 
• Graph Path Problems 
– Single Pair Reachability(G,s,t) 
– Single Source Reachability(G,s) 
– Single Pair Shortest Path(G,s,t) 
– Single Source Shortest Paths(G,s) (SSSP) 
• Breadth-First Search (BFS) 
– algorithm that solves Single Source Shortest Paths 
– with appropriate data structures, runs in O(|V | + |E|) time (linear in input size) 
Examples 
G1 
a 
d 
b 
e 
c 
f 
G2 
a 
d 
b 
e 
c 
f 
","73.94026947021484","5","DPRSearchEngine","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10_1_pdf","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10","6.006","10"
"298","How does the depth-first search algorithm avoid loops when searching for a path?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","73.91327667236328","6","DPRSearchEngine","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf","aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20","6.006","20"
"298","How does the depth-first search algorithm avoid loops when searching for a path?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 4: Hashing 
Lecture 4: Hashing 
Review 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
• Idea! Want faster search and dynamic operations. Can we find(k) faster than Θ(log n)? 
• Answer is no (lower bound)! (But actually, yes...!?) 
Comparison Model 
• In this model, assume algorithm can only differentiate items via comparisons 
• Comparable items: black boxes only supporting comparisons between pairs 
• Comparisons are <, ≤, >, ≥, =, =6 , outputs are binary: True or False 
• Goal: Store a set of n comparable items, support find(k) operation 
• Running time is lower bounded by # comparisons performed, so count comparisons! 
Decision Tree 
• Any algorithm can be viewed as a decision tree of operations performed 
• An internal node represents a binary comparison, branching either True or False 
• For a comparison algorithm, the decision tree is binary (draw example) 
• A leaf represents algorithm termination, resulting in an algorithm output 
• A root-to-leaf path represents an execution of the algorithm on some input 
• Need at least one leaf for each algorithm output, so search requires ≥ n + 1 leaves 
","72.37047576904297","7","DPRSearchEngine","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_1_pdf","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4","6.006","4"
"298","How does the depth-first search algorithm avoid loops when searching for a path?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Clustering Algorithms  
§Hierarchical  clustering  
◦ Can select number  of clusters using dendogram 
◦ Deterministic 
◦ Flexible with respect to linkage criteria 
◦ Slow 
◦ Naïve algorithm n3 
◦ n2 algorithms exist for some linkage criteria 
§K-means a much faster greedy algorithm 
◦ Most useful when you know how many clusters  you want  
6.0002  LECTURE 12 
9 
","72.17439270019531","8","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_9_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"298","How does the depth-first search algorithm avoid loops when searching for a path?"," 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
   
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
   
 
    
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
Linearly Bounded Automata 
Defn: A linearly bounded automaton (LBA) is a 1-tape TM 
that cannot move its head off the input portion of the tape. 
LBA 
a a b a a b a 
Tape size adjusts to length of input. 
Let !LBA = &, ( LBA & accepts ( } 
Theorem:  !LBA is decidable 
Proof: (idea) If & on ( runs for long, it must be cycling. 
Decider for !LBA: 
Claim: For inputs of length ), an LBA can have 
.A−LBA = “On input &, ( 
only * ×)× Γ - different configurations. 
1.  Let ) = |(|. 
Therefore, if an LBA runs for longer, it must repeat some 
2. Run & on ( for * ×)× Γ - steps. 
configuration and thus will never halt. 
3. If has accepted, accept. 
4. If it has rejected or is still running, reject.” 
must be looping 
7 
","71.28225708007812","9","DPRSearchEngine","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_7_pdf","a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10","18.404J","10"
"298","How does the depth-first search algorithm avoid loops when searching for a path?"," 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
Issues with k-means  
§Choosing the “wrong” k can lead to strange results  
◦ Consider  k = 3 
§Result can depend upon initial centroids 
◦ Number  of iterations 
◦ Even final result 
◦ Greedy algorithm can find different local optimas 
6.0002  LECTURE 12 
18 
","71.18490600585938","10","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_18_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"299","How does the function getTempData process a CSV file to extract temperature data?","!		 	
def getTempData(): 
    inFile = open('temperatures.csv') 
    data = [] 
    for l in inFile: 
        data.append(tempDatum(l)) 
    return data 
	

?
","78.34613037109375","1","DPRSearchEngine","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10_41_pdf","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10","6.0002","10"
"299","How does the function getTempData process a CSV file to extract temperature data?"," &&
class Edge(object): 
    def __init__(self, src, dest): 
        """"""Assumes src and dest are nodes"""""" 
        self.src = src 
        self.dest = dest 
    def getSource(self): 
        return self.src 
    def getDestination(self): 
        return self.dest 
    def __str__(self): 
        return self.src.getName() + '->’\\ 
               + self.dest.getName() 
Q>KKKMN
LQ
","73.36380004882812","2","DPRSearchEngine","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_16_pdf","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3","6.0002","3"
"299","How does the function getTempData process a CSV file to extract temperature data?","&

	
	
	/
def greedy(items, maxCost, keyFunction):
itemsCopy = sorted(items, key = keyFunction,
reverse = True)
result = []
totalValue, totalCost = 0.0, 0.0
for i in range(len(itemsCopy)):
if (totalCost+itemsCopy[i].getCost()) <= maxCost:
result.append(itemsCopy[i])
totalCost += itemsCopy[i].getCost()
totalValue += itemsCopy[i].getValue()
return (result, totalValue) 
	

2
	

","72.8576889038086","3","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_24_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"299","How does the function getTempData process a CSV file to extract temperature data?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","71.09986114501953","4","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"299","How does the function getTempData process a CSV file to extract temperature data?","
7:
/
def greedy(items, maxCost, keyFunction):
""""""Assumes items a list, maxCost >= 0,
keyFunction maps elements of items to numbers""""""
itemsCopy = sorted(items, key = keyFunction,
reverse = True)
result = []
totalValue, totalCost = 0.0, 0.0
for i in range(len(itemsCopy)):
if (totalCost+itemsCopy[i].getCost()) <= maxCost:
result.append(itemsCopy[i])
totalCost += itemsCopy[i].getCost()
totalValue += itemsCopy[i].getValue()
return (result, totalValue) 
	

&
","70.7969970703125","5","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_23_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"299","How does the function getTempData process a CSV file to extract temperature data?"," &&%$3$%'9
class Digraph(object): 
 """"""edges is a dict mapping each node to a list of 
    its children""""” 
    def __init__(self): 
self.edges = {} 
    def addNode(self, node): 
if node in self.edges: 
 raise ValueError('Duplicate node') 
else: 
self.edges[node] = [] 
    def addEdge(self, edge): 
src = edge.getSource() 
dest = edge.getDestination() 
if not (src in self.edges and dest in self.edges): 
raise ValueError('Node not in graph') 
self.edges[src].append(dest) 
Q>KKKMN
LS
mapping each node 
list 
","69.5715103149414","6","DPRSearchEngine","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_18_pdf","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3","6.0002","3"
"299","How does the function getTempData process a CSV file to extract temperature data?",";
/
def testGreedys(maxUnits):
print('Use greedy by value to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits, Food.getValue)
print('\\nUse greedy by cost to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits,
lambda x: 1/Food.getCost(x))
print('\\nUse greedy by density to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits, Food.density)
testGreedys(800)
	


4
","69.20043182373047","7","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_26_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"299","How does the function getTempData process a CSV file to extract temperature data?"," &&%$3$%':
    def childrenOf(self, node): 
return self.edges[node] 
    def hasNode(self, node): 
return node in self.edges 
    def getNode(self, name): 
for n in self.edges: 
if n.getName() == name: 
return n 
raise NameError(name) 
    def __str__(self): 
result = '' 
for src in self.edges: 
for dest in self.edges[src]: 
result = result + src.getName() + '->'\\ 
+ dest.getName() + '\\n'
return result[:-1] #omit final newline 
Q>KKKMN
LT
","68.81868743896484","8","DPRSearchEngine","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_19_pdf","69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3","6.0002","3"
"299","How does the function getTempData process a CSV file to extract temperature data?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","68.68268585205078","9","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"299","How does the function getTempData process a CSV file to extract temperature data?"," ! 
dist, numSamples = [], 1000000
for i in range(numSamples):
dist.append(random.gauss(0, 100))
weights = [1/numSamples]*len(dist)
v = pylab.hist(dist, bins = 100,
weights = [1/numSamples]*len(dist))
pylab.xlabel('x')
pylab.ylabel('Relative Frequency')
print('Fraction within ~200 of mean =',
sum(v[0][30:70]))
	

""
","67.98197174072266","10","DPRSearchEngine","3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7_3_pdf","3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7","6.0002","7"
"302","How many total calls to the fibonacci function occur in the recursive computation of fib(6)?","Recursive Implementa#on of Fibonnaci 
6.0002 LECTURE 2 
16 
def fib(n): 
    if n == 0 or n == 1: 
return 1 
    else: 
return fib(n - 1) + fib(n - 2) 
fib(120) = 8,670,007,398,507,948,658,051,921 
 
","72.0924301147461","1","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_16_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"302","How many total calls to the fibonacci function occur in the recursive computation of fib(6)?","Call Tree for Recursive Fibonnaci(6) = 13 
6.0002 LECTURE 2 
17 
ﬁb(6) 
ﬁb(5) 
ﬁb(4) 
ﬁb(3) 
ﬁb(2) 
ﬁb(1) 
ﬁb(0) 
ﬁb(1) 
ﬁb(2) 
ﬁb(1) 
ﬁb(0) 
ﬁb(3) 
ﬁb(2) 
ﬁb(1) 
ﬁb(0) 
ﬁb(1) 
ﬁb(4) 
ﬁb(3) 
ﬁb(2) 
ﬁb(1) 
ﬁb(0) 
ﬁb(1) 
ﬁb(2) 
ﬁb(1) 
ﬁb(0) 
","70.77664184570312","2","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_17_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"302","How many total calls to the fibonacci function occur in the recursive computation of fib(6)?","This column is what we would get with the original recursive implementation where we didn't use a memo. And it was therefore 2 to the length of items. And as you can see, it gets really big or, as we say at the end, huge. But the number of calls grows incredibly slowly for the dynamic programming solution. In the beginning it's worth Oh, well. But by the time we get to the last number I wrote, we're looking at 43,000 versus some really big number I don't know how to pronounce-- 18 somethings. Incredible improvement in performance. And then at the end, it's a number we couldn't fit on the slide, even in tiny font. And yet, only 703,000 calls. How can this be? We know the problem is inherently exponential. Have we overturned the laws of the universe? Is dynamic programming a miracle in the liturgical sense? No. But the thing I want you to carry away is that computational complexity can be a very subtle notion. The running time of fastMaxVal is governed by the number of distinct pairs that we might be able to use as keys in the memo-- toConsider and available. The number of possible values of toConsider is small. It's bounded by the length of the items. If I have a 100 items, it's 0, 1, 2, up to a 100. The possible values of available weight is harder to characterize. But it's bounded by the number of distinct sums of weights you can get. If I start with 750 calories left, what are the possibilities? Well, in fact, in this case, maybe we can take only 750 because we're using with units. So it's small. But it's actually smaller than that because it has to do with the combinations of ways I can add up the units I have. I know this is complicated. It's not worth my going through the details in the lectures. It's covered in considerable detail in the assigned reading. Quickly summarizing lectures 1 and 2,","68.83466339111328","3","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_14_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"302","How many total calls to the fibonacci function occur in the recursive computation of fib(6)?","Need Not Have Copies of Items 
6.0002 LECTURE 2 
24 
Item 
Value 
Calories 
a 
6 
3 
b 
7 
3 
c 
8 
2 
d 
9 
5 
","67.58041381835938","4","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_24_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"302","How many total calls to the fibonacci function occur in the recursive computation of fib(6)?","Performance 
6.0002 LECTURE 2 
29 
len(items) 
2**len(items) 
Number of calls 
2 
4 
7 
4 
16 
25 
8 
256 
427 
16 
65,536 
5,191 
32 
4,294,967,296 
22,701 
64 
18,446,744,073,709 42,569 
,551,616 
128 
Big 
83,319 
256 
Really Big 
176,614 
512 
Ridiculously big 
351,230 
1024 
Absolutely huge 
703,802 
","66.820068359375","5","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_29_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"302","How many total calls to the fibonacci function occur in the recursive computation of fib(6)?","That was very limiting, actually. That's a restriction. With 64 bits, what's my limitation on memory that I can address-- byte addressable? Turns out to be something like 20 exabytes-- to put this in context, all data that Google stores on their servers, on all drives throughout the world-- it's about 10.","66.1515121459961","6","DPRSearchEngine","ZA-tUyM_y7s.en-j3PyPqV-e1s_9_mp4","ZA-tUyM_y7s.en-j3PyPqV-e1s","6.006","1"
"302","How many total calls to the fibonacci function occur in the recursive computation of fib(6)?","Actually, what a modern computer is addressed in is bytes, collections of 8 bits. So there's an address I have for every 8 bits in memory-- consecutive 8 bits in memory. And so if I want to pull something in into the CPU, I give it an address. It'll take some chunk, and bring it into the CPU, operate on it, and spit it back. How big is that chunk? This goes to the answer that you were asking, which-- or saying, which is it's some sequence of some fixed number of bits, which we call a word. A word is how big of a chunk that the CPU can take in from memory at a time and operate on. In your computers, how big is that word size? 64 bits-- that's how much I can operate on at a time. When I was growing up, when I was your age, my word size was 32 bits. And that actually was a problem for my computer, because in order for me to be able to read to address in memory, I need to be able to store that address in my CPU, in a word. But if I have 32 bits, how many different addresses can I address? I have a limitation on the memory addresses I can address, right? So how many different memory addresses can I address with 32 bits? 2 to the 32, right? That makes sense. Well, if you do that calculation out, how big of a hard disk can I have to access? It's about 4 gigabytes. So in my day, all the hard drives were limited to being partitioned-- even if you had a bigger than 4 gigabyte hard drive, I had to partition it into these 4 gigabyte chunks, which","66.14239501953125","7","DPRSearchEngine","ZA-tUyM_y7s.en-j3PyPqV-e1s_8_mp4","ZA-tUyM_y7s.en-j3PyPqV-e1s","6.006","1"
"302","How many total calls to the fibonacci function occur in the recursive computation of fib(6)?","The “Roll-over” Op#miza#on Problem 
6.0002 LECTURE 2 
32 
Score = ((60 – (a+b+c+d+e))*F + a*ps1 + b*ps2 + c*ps3 + d*ps4 + e*ps5 
Objec<ve: 
 Given values for F, ps1, ps2, ps3, ps4, ps5 
 Find values for a, b, c, d, e that maximize score 
Constraints: 
        a, b, c, d, e are each 10 or 0 
 a + b + c + d + e ≥ 20 
","65.76248168945312","8","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_32_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"302","How many total calls to the fibonacci function occur in the recursive computation of fib(6)?","we can turn this into code. We define f of i. And it says am I in a base case? If so, return this. Otherwise, do this recursive call. That's our recursive algorithm. But we're going to do a little more now. And first we're going to check whether this sub problem that we're trying to solve has already been solved. And if so, we return that storage solution. That's the easy case, but it might not exist. And then we'll compute it in the usual way. So what the code then would look like to define f of i is first we check is i in our data structure. This is usually called the memo. So we say, is this sub-problem-- is i in my memo data structure? If so just return memo of i. Done. No recursion necessary. Otherwise, check if I'm a base case. If so, done. Otherwise, recurse. So recursively call f of i minus 1 and f of i minus 2. And in this recursion, we can see that after we call f of i minus 1, in fact, it will have already computed f of i minus 2. So while this call is recursive, this one will immediately terminate because i minus 2 will already be in the memo table. And so if you think about what happens, in fact, we'll just have recursion down the left branch of this thing. And all the right branches will be free. We can just look things up in the memo table. So what is the overall running time? For Fibonacci, this should be order n. Why is it order n? This is number of additions. Come back to that in a second. In general, the way to analyze an algorithm like this that uses memoization is we just count how many different sub-problems are there? Because once we solve the sub-problem, we will never solve it again. That's the whole idea of a memo table. So we will solve each sub-problem at most once. And so we just need to count, how much time does it take to solve every sub-problem? And here you can see it's constant. Either it's a base case and it takes constant time or we recursively call these things. But those are different sub-problems. So we're going to count those later. And then the work that's actually done by this recurrence is a single addition. So in fact, it's n additions. To compute fn would be exactly n additions. So it turns out to be very nice closed form in this case. It should be exactly n sub problems to compute f of n because we started as dot at 1. And each one has one additional-- I guess not the base case. Maybe n minus 2. OK. Definitely order n. Now, there's this one subtlety which-- let's forget about dynamic programming for a moment","65.44493103027344","9","DPRSearchEngine","r4-cftqTcdI.en-j3PyPqV-e1s_7_mp4","r4-cftqTcdI.en-j3PyPqV-e1s","6.006","15"
"302","How many total calls to the fibonacci function occur in the recursive computation of fib(6)?","2 
Lecture 15: Recursive Algorithms 
Merge Sort in SRT BOT Framework 
• Merge sorting an array A of n elements can be expressed in SRT BOT as follows: 
– Subproblems: S(i, j) = sorted array on elements of A[i : j] for 0 ≤ i ≤ j ≤ n 
– Relation: 
S(i, j) = merge(S(i, m), S(m, j)) where m = b(i + j)/2c 
– Topo. order: 
Increasing j − i 
– Base cases: 
S(i, i + 1) = [A[i]] 
– Original: 
S(0, n) 
– Time: 
T (n) = 2 T (n/2) + O(n) = O(n lg n) 
• In this case, subproblem DAG is a tree (divide & conquer) 
Fibonacci Numbers 
• Suppose we want to compute the nth Fibonacci number Fn 
• Subproblems: F (i) = the ith Fibonacci number Fi for i ∈{0, 1, . . . , n} 
• Relation: 
F (i) = F (i − 1) + F (i − 2) (deﬁnition of Fibonacci numbers) 
• Topo. order: 
Increasing i 
• Base cases: 
F (0) = 0, F (1) = 1 
• Original prob.: F (n) 
1 
def fib(n): 
2 
if n < 2: return n 
# base case 
3 
return fib(n - 1) + fib(n - 2) 
# recurrence 
• Divide and conquer implies a tree of recursive calls (draw tree) 
• Time: T (n) = T (n − 1) + T (n − 2) + O(1) > 2T (n − 2), T (n) = Ω(2n/2) exponential... :( 
• Subproblem F (k) computed more than once! (F (n − k) times) 
• Can we avoid this waste? 
","65.28539276123047","10","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_2_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"303","What can lead to a misleading interpretation of data when examining graphical representations, and why is it important to investigate the definitions behind the labels used in such representations?"," 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
Modeling the  World  
§Models  always  inaccurate
◦Provide abstractions of reality
§Deterministic models, e.g., graph theoretic
§Statistical models
◦Simulation models: Monte Carlo simulation
◦Models  based on sampling
◦Characterizing accuracy is critical
◦Central limit theorem
◦Empirical rule
◦Machine learning
◦Unsupervised and supervised
§Presentation of data
◦Plotting
◦Good and bad practices
6.0002  LECTURE 15 
21 
","72.73837280273438","1","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_18_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"303","What can lead to a misleading interpretation of data when examining graphical representations, and why is it important to investigate the definitions behind the labels used in such representations?","It has an accuracy of about 0.6. I could use this idea to try and generalize to say could I come up with a better model. And you're going to see that next time. There could be other ways in which I measure this. And I want to use this as the last example. Another good measure we use is called PPV, Positive Predictive Value which is how many true positives do I come up with out of all the things I labeled positively. And in this solid model, in the dashed line, I can get values about 0.57. The complex model on the training data is better. And then the testing data is even stronger. And finally, two other examples are called sensitivity and specificity. Sensitivity basically tells you what percentage did I correctly find. And specificity said what percentage did I correctly reject. And I show you this because this is where the trade-off comes in. If sensitivity is how many did I correctly label out of those that I both correctly labeled and incorrectly labeled as being negative, how many them did I correctly label as being the kind that I want? I can make sensitivity 1. Label everything is the thing I'm looking for. Great. Everything is correct. But the specificity will be 0. Because I'll have a bunch of things incorrectly labeled. I could make the specificity 1, reject everything. Say nothing as an instance. True negatives goes to 1, and I'm in a great place there, but my sensitivity goes to 0. I've got a trade-off. As I think about the machine learning algorithm I'm using and my choice of that classifier, I'm going to see a trade off where I can increase specificity at the cost of sensitivity or vice versa. And you'll see a nice technique called ROC or Receiver Operator Curve that gives you a sense of how you want to deal with that. And with that, we'll see you next time. We'll take your question off line if you don't mind, because I've run over time. But we'll see you next time where Professor Guttag will show you examples of this.","70.51188659667969","2","DPRSearchEngine","h0e2HAPTGF4.en_19_mp4","h0e2HAPTGF4.en","6.0002","11"
"303","What can lead to a misleading interpretation of data when examining graphical representations, and why is it important to investigate the definitions behind the labels used in such representations?","says, ""if you can't prove what you want to prove, demonstrate something else and pretend they are the same thing. In the daze that follows the collision of statistics with the human mind, hardly anyone will notice the difference."" And indeed, empirically, he seems to be right. So let's look at some examples. Here's one I like. This is from another famous statistician called Anscombe. And he invented this thing called Anscombe's Quartet. I take my hat off now. It's too hot in here. A bunch of numbers, 11 x, y pairs. I know you don't want to look at the numbers, so here are some statistics about them. Each of those pairs has the same mean value for x, the same mean for y, the same variance for x, the same variance for y. And then I went and I fit a linear regression model to it. And lo and behold, I got the same equation for everyone, y equals 0.5x plus 3. So that raises the question, if we go back, is there really much difference between these pairs of x and y? Are they really similar? And the answer is, that's what they look like if you plot them. So even though statistically they appear to be kind of the same, they could hardly be more different, right? Those are not the same distributions. So there's an important moral here, which is that statistics about data is not the same thing as the data itself. And this seems obvious, but it's amazing how easy it is to forget it. The number of papers I've read where I see a bunch of statistics about the data but don't see the data is enormous. And it's easy to lose track of the fact that the statistics don't tell the whole story. So the answer is the old Chinese proverb, a picture is worth a thousand words, I urge you, the first thing you should do when you get a data set, is plot it. If it's got too many points to plot all the points, subsample it and plot of subsample. Use some visualization tool to look at the data itself. Now, that said, pictures are wonderful. But you can lie with pictures. So here's an interesting chart. These are grades in 6.0001 by gender. So the males are blue and the females are pink. Sorry for being such a traditionalist. And as you can see, the women did way better than the men. Now, I know for some of you this is confirmation bias. You say, of course. Others say, impossible, But in fact, if you look carefully, you'll see that's not what this chart says at all. Because if you look at the axis here, you'll see that actually there's not much difference. Here's what I get if I plot it from 0 to 5. Yeah, the women did a little bit better. But that's not a statistically-significant difference. And by the way, when I plotted it last year for 6.0002, the blue was about that much higher than the pink. Don't read much into either of them. But the trick was here, I took the y-axis and ran it from 3.9 to 4.05. I cleverly chose my baseline in such a way to make the difference look much bigger than it is. Here I did the honest thing of put the baseline at 0 and run it to 5. Because that's the range of grades at MIT. And so when you look at a chart, it's important to keep in mind that you need to look at the axis labels and the scales.","69.16020965576172","3","DPRSearchEngine","K2SC-WPdT6k.en-qlPKC2UN_YU_6_mp4","K2SC-WPdT6k.en-qlPKC2UN_YU","6.0002","14"
"303","What can lead to a misleading interpretation of data when examining graphical representations, and why is it important to investigate the definitions behind the labels used in such representations?"," 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Non-representative Sampling  
§“Convenience sampling” not usually random, e.g.,
◦Survivor  bias,  e.g.,  course evaluations at end of course or
grading final exam in 6.0002  on a strict curve
◦Non-response bias,  e.g.,  opinion polls conducted by mail
or  online
§When samples not random and independent, we can
still do things like computer means and standard 
deviations, but we should not draw conclusions from 
them using things like the empirical rule and central 
limit theorem. 
§Moral: Understand how data was collected, and
whether assumptions used in the analysis are satisfied. 
If not, be wary. 
6.0002  LECTURE 14 
22 
","68.97808074951172","4","DPRSearchEngine","b9d60f4ecb325e4648f9cf0379419338_MIT6_0002F16_lec14_22_pdf","b9d60f4ecb325e4648f9cf0379419338_MIT6_0002F16_lec14","6.0002","14"
"303","What can lead to a misleading interpretation of data when examining graphical representations, and why is it important to investigate the definitions behind the labels used in such representations?","It's the name of a class, and here are three methods of that class. Fit, which takes a sequence of feature vectors and a sequence of labels and returns an object of type logistic regression. So this is the place where the optimization is done. Now all the examples I'm going to show you, these two sequences will be-- well all right. So think of this as the sequence of feature vectors, one per passenger, and the labels associated with those. So this and this have to be the same length. That produces an object of this type, and then I can ask for the coefficients, which will return the weight of each variable, each feature. And then I can make a prediction, given a feature vector returned the probabilities of different labels. Let's look at it as an example. So first let's build the model.","68.83660888671875","5","DPRSearchEngine","eg8DJYwdMyg.en-qlPKC2UN_YU_6_mp4","eg8DJYwdMyg.en-qlPKC2UN_YU","6.0002","13"
"303","What can lead to a misleading interpretation of data when examining graphical representations, and why is it important to investigate the definitions behind the labels used in such representations?"," 
 
 
 
 
 
 
 
 
Machine  Learning Paradigm  
§Observe set of examples: training data 
§Infer something about process that generated that 
data 
§Use inference to make predictions about previously 
unseen data: test data 
§Supervised: given a set of feature/label pairs, find a 
rule that predicts the label associated with a previously 
unseen input 
§Unsupervised: given a set of feature vectors (without 
labels) group them into “natural clusters” 
6.0002  LECTURE 12 
3 
","68.42459106445312","6","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_3_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"303","What can lead to a misleading interpretation of data when examining graphical representations, and why is it important to investigate the definitions behind the labels used in such representations?","data, and I just said whether we're going to print something. You'll notice from this slide I've elighted the printed stuff. We'll come back in a later slide and look at what's in there. But for now I want to focus on actually building the model. I need to create two vectors, two lists in this case, the feature vectors and the labels. For e in examples, featurevectors.a ppend(e.getfeatures e.getfeatures e.getlabel. Couldn't be much simpler than that. Then, just because it wouldn't fit on a line on my slide, I've created this identifier called logistic regression, which is sklearn.linearmo del.logisticregression. So this is the thing I imported, and this is a class, and now I'll get a model by first creating an instance of the class, logistic regression. Here I'm getting an instance, and then I'll call dot fit with that instance, passing it feature vecs and labels. I now have built a logistic regression model, which is simply a set of weights for each of the variables. This makes sense? Now we're going to apply the model, and I think this is the last piece of Python I'm going to introduce this semester, in case you're tired of learning about Python. And this is at least list comprehension. This is how I'm going to build my set of test feature vectors.","68.09288024902344","7","DPRSearchEngine","eg8DJYwdMyg.en-qlPKC2UN_YU_7_mp4","eg8DJYwdMyg.en-qlPKC2UN_YU","6.0002","13"
"303","What can lead to a misleading interpretation of data when examining graphical representations, and why is it important to investigate the definitions behind the labels used in such representations?","A pretty small number. But the probability of 26 consecutive reds when the previous 25 rolls were red is what? No, that. AUDIENCE: Oh, I thought you meant it had been 26 times again. JOHN GUTTAG: No, if you had 25 reds and then you spun the wheel once more, the probability of it having 26 reds is now 0.5, because these are independent events. Unless of course the wheel is rigged, and we're assuming it's not. People have a hard time accepting this, and I know it seems funny. But I guarantee there will be some point in the next month or so when you will find yourself thinking this way, that something has to even out. I did so badly on the midterm, I will have to do better on the final. That was mean, I'm sorry. All right, speaking of means-- see? Professor Grimson not the only one who can make bad jokes. There is something-- it's not the gambler's fallacy-- that's often confused with it, and that's called regression to the mean. This term was coined in 1885 by Francis Galton in a paper, of which I've shown you a page from it here.","67.68710327148438","8","DPRSearchEngine","OgO1gpXSUzU.en-j3PyPqV-e1s_8_mp4","OgO1gpXSUzU.en-j3PyPqV-e1s","6.0002","6"
"303","What can lead to a misleading interpretation of data when examining graphical representations, and why is it important to investigate the definitions behind the labels used in such representations?"," 
 
 
Class LogisticRegression  
fit(sequence of feature vectors, sequence of labels) 
Returns object of type LogisticRegression 
coef_ 
Returns weights of features 
predict_proba(feature vector) 
Returns probabilities of labels 
6.0002 LECTURE 13 
22 
","67.64111328125","9","DPRSearchEngine","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13_22_pdf","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13","6.0002","13"
"303","What can lead to a misleading interpretation of data when examining graphical representations, and why is it important to investigate the definitions behind the labels used in such representations?","provides information about the possible behaviors of a system. I say possible behaviors, because I'm particularly interested in stochastic systems. They're descriptive not prescriptive in the sense that they describe the possible outcomes. They don't tell you how to achieve possible outcomes. This is different from what we've looked at earlier in the course, where we looked at optimization models. So an optimization model is prescriptive. It tells you how to achieve an effect, how to get the most value out of your knapsack, how to find the shortest path from A to B in a graph. In contrast, a simulation model says, if I do this, here's what happens. It doesn't tell you how to make something happened. So it's very different, and it's why we need both, why we need optimization models and we need simulation models. We have to remember that a simulation model is only an approximation to reality. I put in an approximation to the distribution of birthdates, but it wasn't quite right. And as the very famous statistician George Box said, ""all models are wrong, but some are actually very useful."" In the next lecture, we'll look at a useful class of models. When do we use simulations? Typically, as we've just shown, to model systems that are mathematically intractable, like the birthday problem we just looked at. In other situations, to extract intermediate results-- something happens along the way to the answer. And as I hope you've seen that simulations are used because we can play what if games by successively refining it. We started with a simple simulation that assumed that we only asked the question of, do two people share a birthday. We showed how we could change it to ask do three people share a birthday. We then saw that we could change it to assume a different distribution of birthdates in the group. And so we can start with something simple. And we get it ever more complexed to answer questions what if. We're going to start in the next lecture by producing a simulation of a random walk. And with that, I'll stop. And see you guys soon.","67.58255004882812","10","DPRSearchEngine","-1BnXEwHUok.en-qlPKC2UN_YU_12_mp4","-1BnXEwHUok.en-qlPKC2UN_YU","6.0002","4"
"308","What is the danger of choosing an overly complex model when fitting data?"," 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
Modeling the  World  
§Models  always  inaccurate
◦Provide abstractions of reality
§Deterministic models, e.g., graph theoretic
§Statistical models
◦Simulation models: Monte Carlo simulation
◦Models  based on sampling
◦Characterizing accuracy is critical
◦Central limit theorem
◦Empirical rule
◦Machine learning
◦Unsupervised and supervised
§Presentation of data
◦Plotting
◦Good and bad practices
6.0002  LECTURE 15 
21 
","71.30686950683594","1","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_18_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"308","What is the danger of choosing an overly complex model when fitting data?","What's the worst case performance of a hash table? If I have to look up something in a hash table, and I happen to choose a bad hash table-- hash function, what's the worst case here? What? n, right? It's worse than a sorted array, because potentially, I hashed everything that I was storing to the same index in my hash table, and to be able to distinguish between them, I can't do anything more than a linear search. I could store another set's data structure as my chain and do better that way. That's actually how Java does it. They store a data structure we're going to be talking about next week as the chains so that they can get, worst case, log n. But in general, that hash table is only good if we're allowing-- OK, I want this to be expected good, but in the worst case, if I really need that operation to be worst case-- I really can't afford linear time ever for an operation of that kind-- then I don't want to use a hash table. And so on your p set 2, everything we ask you for is worst case, so probably, you don't want to be using hash tables. OK? Yes? AUDIENCE: What does the subscript e mean? JASON KU: What does the subscript e mean? That's great. In this chart, I put a subscript on this is an expected runtime, or an A meaning this is an amortized runtime. At the end, we talked about how, if we had too many things in our hash table, then, as long as we didn't do it too often-- this is a little hand wavey argument, but the same kinds of ideas as the dynamic array-- if, whenever we got a linear-- we are more than a linear factor away from where we are trying-- basically, the fill factor we were trying to be, then we could just completely rebuild the hash table with the new hash function randomly chosen from our hash table with a new size, and we could get amortized bounds. And so that's what Python-- how Python implements dictionaries, or sets, or even objects when it's trying to map keys to different things. So that's hash tables. That's great. The key thing here is, well, actually, if your range of keys is small, or if you as a programmer have the ability to choose the keys that you identify your objects with, you can actually choose that range to be small, to be linear, to be small with respect to your items. And you don't need a hash table. You can just use a direct access array, because if you know your key space is small, that's great. So a lot of C programmers probably would like to do something like that, because they don't have access to-- maybe C++ programmers would have access to their hash table. Any questions on this stuff before we move on? Yeah? AUDIENCE: So why is [INAUDIBLE]? JASON KU: Why is it expected? When I'm building, I could insert-- I'm inserting these things from x 1 by 1 into my hash table. Each of those insert operations-- I'm looking up to see whether that-- an item with that key already exists in my hash table. And so I have to look down the chain to see where it is. However, if I happen to know that all of my keys are unique in my input, all the items I'm trying to store are unique, then I don't have to do that check and I can get worst case linear time. Does that make sense? All right. It's a subtlety, but that's a great question. OK, so today, instead of talking about searching, we're talking about sorting. Last week, we saw a few ways to do sort. Some of them were quadratic-- insertion sort and selection sort-- and then we had one that was n log n. And this thing, n log n, seemed pretty good, but can I do better? Can I do better? Well, what we're going to show at the beginning of this class is, in this comparison model, no. n log n is optimal. And we're going to go through the exact same line of reasoning that we had last week. So in the comparison model, what did we use when we were trying to make this argument that any comparison model algorithm was going to take at least log n time? What we did was we said, OK, I can think of any model in the comparison model-- any algorithm in the comparison model as kind of this-- some comparisons happen. They branch in a binary sense, but you could have it generalized to any constant branching factor. But for our purposes, binary's fine. And what we said was that there were at least n outputs-- really n plus 1, but-- at least order n outputs. And we showed that-- or we argued to you that the height of this tree had to be at least log n-- log the number of leaves. It had to be at least log the number of leaves. That was the height of the decision tree. And if this decision tree represented a search algorithm, I had to walk down and perform these comparisons in order, reach a leaf where I would output something. If the minimum height of any binary tree on a linear number of leaves is log n, then any algorithm in the comparison model also has to take log n time, because it has to do that many comparisons to differentiate between all possible outputs. Does that make sense? All right. So in the sort problem, how many possible outputs are there?","68.07146453857422","2","DPRSearchEngine","yndgIDO0zQQ.en-j3PyPqV-e1s_4_mp4","yndgIDO0zQQ.en-j3PyPqV-e1s","6.006","5"
"308","What is the danger of choosing an overly complex model when fitting data?"," 
 
 
 
 
Stochastic  Thinking  
§The world is (predictably) non-deterministic
§Thinking in terms of probabilities is often useful
§Randomness is a powerful tool for building
computations that model the world 
§Random computations useful even when for problems
that do not involve randomness 
◦E.g.,  integration
6.0002  LECTURE 15 
20 
","67.98181915283203","3","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_17_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"308","What is the danger of choosing an overly complex model when fitting data?"," 
 
 
 
 
 
 
 
 
  
 
  
 
   
 
 
 
 
  
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Model Dependence 
Number of steps to decide ! = a#b# $ ≥0 depends on the model. 
• 1-tape TM: '() log )) 
• Multi-tape TM: '()) 
Computability theory: model independence (Church-Turing Thesis) 
Therefore model choice doesn’t matter. Mathematically nice. 
Complexity Theory: model dependence 
But dependence is low (polynomial) for reasonable deterministic models. 
We will focus on questions that do not depend on the model choice. 
So… we will continue to use the 1-tape TM as the basic model for complexity. 
6 
","67.92949676513672","4","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_6_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"308","What is the danger of choosing an overly complex model when fitting data?"," 
 
 
 
 
Lecture: Sampling and 
Standard Error 
6.0002  LECTURE 8 
 
1
","67.90219116210938","5","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_1_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"308","What is the danger of choosing an overly complex model when fitting data?","§ Problem is exponen<al 
§ Have we overturned the laws of the universe? 
§ Is dynamic programming a miracle? 
§ No, but computa<onal complexity can be subtle 
§ Running <me of fastMaxVal is governed by number of 
dis<nct pairs, <toConsider, avail> 
◦Number of possible values of toConsider bounded 
by len(items)
◦Possible values of avail a bit harder to characterize 
◦Bounded by number of dis<nct sums of weights 
◦Covered in more detail in assigned reading 
How Can This Be? 
6.0002 LECTURE 2 
30 
","67.7730941772461","6","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_30_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"308","What is the danger of choosing an overly complex model when fitting data?"," 
 
 
 
  
 
 
  
 
  
  
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Intro to Complexity Theory 
Computability theory (1930s - 1950s): 
Is A decidable? 
Complexity theory (1960s - present): 
Is A decidable with restricted resources? 
(time/memory/…) 
Example: Let ! = a#b# $ ≥0 . 
Q: How many steps are needed to decide !? 
Depends on the input. 
We give an upper bound for all inputs of length '. 
Called “worst-case complexity”. 
2 
","67.76095581054688","7","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_2_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"308","What is the danger of choosing an overly complex model when fitting data?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","67.60005950927734","8","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"308","What is the danger of choosing an overly complex model when fitting data?"," 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
18.404/6.840 Lecture 8 
Last time: 
- Decision procedures for automata and grammars
!DFA , !NFA , &DFA , &'DFA , !CFG , &CFG are decidable 
!TM is T-recognizable 
Today: (Sipser §4.2) 
- !TM is undecidable 
- The diagonalization method 
- !TM is T-unrecognizable 
- The reducibility method 
- Other undecidable languages 
1 
","67.58834075927734","9","DPRSearchEngine","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_1_pdf","3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8","18.404J","8"
"308","What is the danger of choosing an overly complex model when fitting data?"," 
 
 
 
 
 
 
 
 
  
 
 
  
 
Sampling Space of Possible Outcomes  
Never possible to guarantee perfect accuracy through 
sampling 
Not to say that an estimate is not precisely correct 
Key question: 
◦ How many samples do we need to look at before we can 
have justified confidence on our answer? 
Depends upon variability in underlying distribution 
6.0002 LECTURE 6 
20
","67.55199432373047","10","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_20_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"311","What is the basic process for predicting the label of a new example using the distance matrix method in classification?"," 
 
 
 
 
 
 
Using Distance Matrix for Classification  
Simplest approach is probably nearest neighbor  
Remember training data 
When predicting the label of a new example 
◦ Find the nearest example in the training data 
◦ Predict the label associated with that example 
X 
6.0002 LECTURE 13 
6 
","71.23318481445312","1","DPRSearchEngine","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13_6_pdf","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13","6.0002","13"
"311","What is the basic process for predicting the label of a new example using the distance matrix method in classification?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","70.52322387695312","2","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"311","What is the basic process for predicting the label of a new example using the distance matrix method in classification?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Monte Carlo Simulation  
A method of estimating the value of an unknown 
quantity using the principles of inferential statistics 
Inferential statistics 
◦ Population: a set of examples 
◦ Sample: a proper subset of a population 
◦ Key fact: a random sample tends to exhibit the same  
properties as the population from which it is drawn  
Exactly what we did with random walks 
6.0002 LECTURE 6 
4
","69.39360046386719","3","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_4_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"311","What is the basic process for predicting the label of a new example using the distance matrix method in classification?"," 
 
 
    
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Return to Closure Properties 
Recall Theorem: If !"", !$ are regular languages, so is !"" ∪!$ 
(The class of regular languages is closed under union) 
New Proof (sketch): Given DFAs &"" and &$ recognizing !"" and !$ 
&$
&"" 
ε 
ε 
& 
Construct NFA & recognizing !"" ∪!$ 
Nondeterminism 
parallelism 
vs 
guessing 
7 
","68.97845458984375","4","DPRSearchEngine","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_7_pdf","d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2","18.404J","2"
"311","What is the basic process for predicting the label of a new example using the distance matrix method in classification?","Distance Matrix  
Label  
R  
R  
R  
~R  
~R  
~R  
6.0002 LECTURE 13 
7 
","68.6427230834961","5","DPRSearchEngine","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13_7_pdf","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13","6.0002","13"
"311","What is the basic process for predicting the label of a new example using the distance matrix method in classification?","And a comparison model means-- is that the items, the objects I'm storing-- I can kind of think of them as black boxes. I don't get to touch these things, except the only way that I can distinguish between them is to say, given a key and an item, or two items, I can do a comparison on those keys. Are these keys the same? Is this key bigger than this one? Is it smaller than this one? Those are the only operations I get to do with them. Say, if the keys are numbers, I don't get to look at what number that is. I just get to take two keys and compare them. And actually, all of the search algorithms that we saw on Tuesday we're comparison sort algorithms. What you did was stepped through the program. At some point, you came to a branch and you looked at two keys, and you branched based on whether one key was bigger than another. That was a comparison. And then you move some stuff around, but that was the general paradigm. Those three sorting operations lived in this comparison model.","68.56455993652344","6","DPRSearchEngine","Nu8YGneFCWE.en-j3PyPqV-e1s_2_mp4","Nu8YGneFCWE.en-j3PyPqV-e1s","6.006","4"
"311","What is the basic process for predicting the label of a new example using the distance matrix method in classification?"," 
 
 
Class LogisticRegression  
fit(sequence of feature vectors, sequence of labels) 
Returns object of type LogisticRegression 
coef_ 
Returns weights of features 
predict_proba(feature vector) 
Returns probabilities of labels 
6.0002 LECTURE 13 
22 
","68.46217346191406","7","DPRSearchEngine","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13_22_pdf","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13","6.0002","13"
"311","What is the basic process for predicting the label of a new example using the distance matrix method in classification?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 4: Hashing 
Lecture 4: Hashing 
Review 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
• Idea! Want faster search and dynamic operations. Can we find(k) faster than Θ(log n)? 
• Answer is no (lower bound)! (But actually, yes...!?) 
Comparison Model 
• In this model, assume algorithm can only differentiate items via comparisons 
• Comparable items: black boxes only supporting comparisons between pairs 
• Comparisons are <, ≤, >, ≥, =, =6 , outputs are binary: True or False 
• Goal: Store a set of n comparable items, support find(k) operation 
• Running time is lower bounded by # comparisons performed, so count comparisons! 
Decision Tree 
• Any algorithm can be viewed as a decision tree of operations performed 
• An internal node represents a binary comparison, branching either True or False 
• For a comparison algorithm, the decision tree is binary (draw example) 
• A leaf represents algorithm termination, resulting in an algorithm output 
• A root-to-leaf path represents an execution of the algorithm on some input 
• Need at least one leaf for each algorithm output, so search requires ≥ n + 1 leaves 
","68.21025085449219","8","DPRSearchEngine","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_1_pdf","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4","6.006","4"
"311","What is the basic process for predicting the label of a new example using the distance matrix method in classification?","!	!	 	
 
Let D be the original data set 
    n be the number of random samples  
 
 
 usually n between 20% and 50% 
    k be number of trials 
 
testResults = [] 
for i in range(k) 
    randomly select n elements for testSet,  
       keep rest for training 
    model = buildModel(training) 
    testResults.append(test(model, testSet)) 
 
Average testResults 

	

;G
","68.01315307617188","9","DPRSearchEngine","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10_38_pdf","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10","6.0002","10"
"311","What is the basic process for predicting the label of a new example using the distance matrix method in classification?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","67.97891998291016","10","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"312","How might we approximate the standard deviation of a population if it is unknown?"," 
 
 
 
 
 
 
 
 
 
 
Standard Error  of the Mean  
σ
SE = 
n
But, we don’t 
know  standard 
deviation  of 
population 
How might we  
approximate it?  
6.0002  LECTURE 8 
 
24
","78.27531433105469","1","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_24_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"312","How might we approximate the standard deviation of a population if it is unknown?"," 
  
 
  
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Means  and Standard Deviations  
§Population mean = 16.3
§Sample mean = 17.1
§Standard deviation of population = 9.44
§Standard deviation  of sample = 10.4
§A  happy accident, or something we should expect?
§Let’s try  it 1000 times and plot the results
6.0002  LECTURE 8 
 
11
","77.29818725585938","2","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_11_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"312","How might we approximate the standard deviation of a population if it is unknown?","I'm going to look at a bunch of different sample sizes, from 25 to 600, 50 trials each. So getHighs is just a function that returns the temperatures. I'm going to get the standard deviation of the whole population, then the standard error of the means and the sample standard deviations, both. And then I'm just going to go through and run it. So for size and sample size, I'm going to append the standard error of the mean. And remember, that uses the population standard deviation and the size of the sample. So I'll compute all the SEMs. And then I'm going to compute all the actual standard deviations, as well. And then we'll produce a bunch of plots-- or a plot, actually. All right, so let's see what that plot looks like.","75.4717788696289","3","DPRSearchEngine","soZv_KKax3E.en-qlPKC2UN_YU_10_mp4","soZv_KKax3E.en-qlPKC2UN_YU","6.0002","8"
"312","How might we approximate the standard deviation of a population if it is unknown?","Quite different, right? We've looked at uniform and we've looked at Gaussian before. And here we see an exponential, which basically decays and will asymptote towards zero, never quite getting there. But as you can see, it is certainly not very symmetric around the mean. All right, so let's see what happens. If we run the experiment on these three distributions, each of 100,000 point examples, and look at different sample sizes, we actually see that the difference between the standard deviation and the sample standard","75.44512176513672","4","DPRSearchEngine","soZv_KKax3E.en-qlPKC2UN_YU_13_mp4","soZv_KKax3E.en-qlPKC2UN_YU","6.0002","8"
"312","How might we approximate the standard deviation of a population if it is unknown?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Monte Carlo Simulation  
A method of estimating the value of an unknown 
quantity using the principles of inferential statistics 
Inferential statistics 
◦ Population: a set of examples 
◦ Sample: a proper subset of a population 
◦ Key fact: a random sample tends to exhibit the same  
properties as the population from which it is drawn  
Exactly what we did with random walks 
6.0002 LECTURE 6 
4
","74.15655517578125","5","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_4_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"312","How might we approximate the standard deviation of a population if it is unknown?","is that the variance of the sample means will be close to the variance of the population divided by the sample size. And we're going to use that to compute something called the standard error-- formerly the standard error of the mean. People often just call it the standard error. And I will be, alas, inconsistent. I sometimes call it one, sometimes the other. It's an incredibly simple formula. It says the standard error is going to be equal to sigma, where sigma is the population standard deviation divided by the square root of n, which is going to be the size of the sample. And then there's just this very small function that implements it. So we can compute this thing called the standard error of the mean in a very straightforward way. We can compute it. But does it work? What do I mean by work? I mean, what's the relationship of the standard error to the standard deviation? Because, remember, that was our goal, was to understand the standard deviation so we could use the empirical rule. Well, let's test the standard error of the mean.","73.98794555664062","6","DPRSearchEngine","soZv_KKax3E.en-qlPKC2UN_YU_9_mp4","soZv_KKax3E.en-qlPKC2UN_YU","6.0002","8"
"312","How might we approximate the standard deviation of a population if it is unknown?","Standard deviation simply the square root of the 
variance
Outliers can have a big effect
Standard deviation should always be considered 
relative to mean
Quantifying Variation in Data
6.0002 LECTURE 6
 
1
(X) 
(x )2
X xX
21
","72.90789794921875","7","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_21_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"312","How might we approximate the standard deviation of a population if it is unknown?","I'm pretty far off. I'm off by 14% here. And I think that's 25. But when the sample sizes is larger, say 600, I'm off by about 2%. So what we see, at least for this data set of temperatures-- if the sample size is large enough, the sample standard deviation is a pretty good approximation of the population standard deviation. Well. Now we should ask the question, what good is this? Well, as I said, once the sample reaches a reasonable size-- and we see here, reasonable is probably somewhere around 500-- it becomes a good approximation. But is it true only for this example? The fact that it happened to work for high temperatures in the US doesn't mean that it will always be true. So there are at least two things we should consider to asking the question, when will this be true, when won't it be true. One is, does the distribution of the population matter? So here we saw, in our very first plot, the distribution of the high temperatures. And it was kind of symmetric around a point-- not perfectly. But not everything looks that way, right? So we should say, well, suppose we have a different distribution. Would that change this conclusion? And the other thing we should ask is, well, suppose we had a different sized population. Suppose instead of 400,000 temperatures I had 20 million temperatures. Would I need more than 600 samples for the two things to be about the same? Well, let's explore both of those questions. First, let's look at the distributions. And we'll look at three common distributions-- a uniform distribution, a normal distribution, and an exponential distribution. And we'll look at each of them for, what is this, 100,000 points. So we know we can generate a uniform distribution by calling random.random. Gives me a uniform distribution of real numbers between 0 and 1. We know that we can generate our normal distribution by calling random.gauss. In this case, I'm looking at it between the mean of 0 and a standard deviation of 1. But as we saw in the last lecture, the shape will be the same, independent of these values. And, finally, an exponential distribution, which we get by calling random.expovariate. Very And this number, 0.5, is something called lambda, which has to do with how quickly the exponential either decays or goes up, depending upon which direction. And I'm not going to give you the formula for it at the moment. But we'll look at the pictures. And we'll plot each of these discrete approximations to these distributions.","72.76151275634766","8","DPRSearchEngine","soZv_KKax3E.en-qlPKC2UN_YU_12_mp4","soZv_KKax3E.en-qlPKC2UN_YU","6.0002","8"
"312","How might we approximate the standard deviation of a population if it is unknown?","Well, here's a histogram of one random sample of size 100. Looks pretty different, as you might expect. Its standard deviation is 10.4, its mean 17.7. So even though the figures look a little different, in fact, the means and standard deviations are pretty similar. If we look at the population mean and the sample mean-- and I'll try and be careful to use those terms-- they're not the same. But they're in the same ballpark. And the same is true of the two standard deviations. Well, that raises the question, did we get lucky or is something we should expect? If we draw 100 random examples, should we expect them to correspond to the population as a whole? And the answer is sometimes yeah and sometimes no. And that's one of the issues I want to explore today. So one way to see whether it's a happy accident is to try it 1,000 times. We can draw 1,000 samples of size 100 and plot the results. Again, I'm not going to go over the code. There's something in that code, as well, that we haven't seen before. And that's the ax.vline plotting command. V for vertical. It just, in this case, will draw a red line-- because I've said the color is r-- at population mean on the x-axis. So just a vertical line. So that'll just show us where the mean is. If we wanted to draw a horizontal line, we'd use ax.hline. Just showing you a couple of useful functions. When we try it 1,000 times, here's what it looks like. So here we see what we had originally, same picture I showed you before. And here's what we get when we look at the means of 100 samples. So this plot on the left looks a lot more like it's a normal distribution than the one on the right. Should that surprise us, or is there a reason we should have expected that to happen? Well, what's the answer? Someone tell me why we should have expected it. It's because of the central limit theorem, right? That's exactly what the central limit theorem promised us would happen. And, sure enough, it's pretty close to normal. So that's a good thing. And now if we look at it, we can see that the mean of the sample means is 16.3, and the standard deviation of the sample means is 0.94. So if we go back to what we saw here, we see that, actually, when we run it 1,000 times and look at the means, we get very close to what we had initially. So, indeed, it's not a happy accident. It's something we can in general expect. All right, what's the 95% confidence interval here? Well, it's going to be 16.28 plus or minus 1.96 times 0.94, the standard deviation of the sample means. And so it tells us that the confidence interval is, the mean high temperature, is somewhere between 14.5 and 18.1. Well, that's actually a pretty big range, right? It's sort of enough to where you wear a sweater or where you don't wear a sweater. So the good news is it includes the population mean. That's nice. But the bad news is it's pretty wide. Suppose we wanted it tighter bound. I said, all right, sure enough, the central limit theorem is going to tell me the mean of the means is going to give me a good estimate of the actual population mean. But I want it tighter bound. What can I do? Well, let's think about a couple of things we could try. Well, one thing we could think about is drawing more samples. Suppose instead of 1,000 samples, I'd taken 2,000 or 3,000 samples. We can ask the question, would that have given me a smaller standard deviation? For those of you who have not looked ahead, what do you think? Who thinks it will give you a smaller standard deviation? Who thinks it won't? And the rest of you have either looked ahead or refused to think. I prefer to believe you looked ahead. Well, we can run the experiment. You can go to the code. And you'll see that there is a constant of 1,000, which you can easily change to 2,000. And lo and behold, the standard deviation barely budges. It got a little bit bigger, as it happens, but that's kind of an accident. It just, more or less, doesn't change. And it won't change if I go to 3,000 or 4,000 or 5,000. It'll wiggle around. But it won't help much. What we can see is doing that more often is not going to help. Suppose we take larger samples? Is that going to help? Who thinks that will help? And who thinks it won't? OK. Well, we can again run the experiment. I did run the experiment. I changed the sample size from 100 to 200. And, again, you can run this if you want. And if you run it, you'll get a result-- maybe not exactly this, but something very similar-- that, indeed, as I increase the size of the sample rather than the number of the samples, the standard deviation drops fairly dramatically, in this case from 0.94 0.66. So that's a good thing. I now want to digress a little bit before we come back to this and look at how you can visualize this-- Because this is a technique you'll want to use as you write papers and things like that-- is how do we visualize the variability of the data? And it's usually done with something called an error bar. You've all seen these things here.","72.20059204101562","9","DPRSearchEngine","soZv_KKax3E.en-qlPKC2UN_YU_5_mp4","soZv_KKax3E.en-qlPKC2UN_YU","6.0002","8"
"312","How might we approximate the standard deviation of a population if it is unknown?"," 
 
 
Does Population  Size Matter?  
6.0002  LECTURE 8 
 
30
","72.15672302246094","10","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_30_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"313","Why might having overlap between clusters not necessarily be an issue in clustering algorithms?"," 
 
 
 
 
Clustering  Is  an Optimization Problem  
§Why not divide variability by size of cluster? 
◦ Big and bad worse than small and bad 
§Is optimization problem finding a C that minimizes 
dissimilarity(C)? 
◦ No, otherwise could put each example in its own 
cluster 
§Need a constraint, e.g., 
◦ Minimum distance between clusters 
◦ Number of clusters 
6.0002  LECTURE 12 
4 
","75.33289337158203","1","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_4_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"313","Why might having overlap between clusters not necessarily be an issue in clustering algorithms?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","72.86991119384766","2","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"313","Why might having overlap between clusters not necessarily be an issue in clustering algorithms?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","72.84881591796875","3","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"313","Why might having overlap between clusters not necessarily be an issue in clustering algorithms?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Clustering Algorithms  
§Hierarchical  clustering  
◦ Can select number  of clusters using dendogram 
◦ Deterministic 
◦ Flexible with respect to linkage criteria 
◦ Slow 
◦ Naïve algorithm n3 
◦ n2 algorithms exist for some linkage criteria 
§K-means a much faster greedy algorithm 
◦ Most useful when you know how many clusters  you want  
6.0002  LECTURE 12 
9 
","72.14044189453125","4","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_9_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"313","Why might having overlap between clusters not necessarily be an issue in clustering algorithms?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 8: Binary Heaps 
Lecture 8: Binary Heaps 
Priority Queue Interface 
• Keep track of many items, quickly access/remove the most important 
– Example: router with limited bandwidth, must prioritize certain kinds of messages 
– Example: process scheduling in operating system kernels 
– Example: discrete-event simulation (when is next occurring event?) 
– Example: graph algorithms (later in the course) 
• Order items by key = priority so Set interface (not Sequence interface) 
• Optimized for a particular subset of Set operations: 
build(X) 
build priority queue from iterable X 
insert(x) 
add item x to data structure 
delete max() 
remove and return stored item with largest key 
find max() 
return stored item with largest key 
• (Usually optimized for max or min, not both) 
• Focus on insert and delete max operations: build can repeatedly insert; 
find max() can insert(delete min()) 
Priority Queue Sort 
• Any priority queue data structure translates into a sorting algorithm: 
– build(A), e.g., insert items one by one in input order 
– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order 
• All the hard work happens inside the data structure 
• Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max 
• Many sorting algorithms we’ve seen can be viewed as priority queue sort: 
Priority Queue 
Operations O(·) 
Priority Queue Sort 
Data Structure 
build(A) 
insert(x) 
delete max() 
Time 
In-place? 
Dynamic Array 
n 
1(a) 
n 
2
n
Y 
Sorted Dynamic Array 
n log n 
n 
1(a) 
2
n
Y 
Set AVL Tree 
n log n 
log n 
log n 
n log n 
N 
Goal 
n 
log n(a) 
log n(a) 
n log n 
Y 
Selection Sort 
Insertion Sort 
AVL Sort 
Heap Sort 
","71.94750213623047","5","DPRSearchEngine","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_1_pdf","40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8","6.006","8"
"313","Why might having overlap between clusters not necessarily be an issue in clustering algorithms?"," 
 
 
 
 
 
 
  
 
  
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
Hiearchical Clustering 
1. Start by assigning each item to a cluster,  so that if 
you have N items,  you now have N clusters,  each 
containing just one item. 
2. Find the closest (most similar) pair  of clusters and 
merge them into a single cluster,  so that now you have 
one fewer  cluster. 
3. Continue the process until all items are clustered  
into a single cluster  of size N.  
What does distance mean?  
6.0002  LECTURE 12 
6 
","71.89918518066406","6","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_6_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"313","Why might having overlap between clusters not necessarily be an issue in clustering algorithms?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 4: Hashing 
Lecture 4: Hashing 
Review 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
• Idea! Want faster search and dynamic operations. Can we find(k) faster than Θ(log n)? 
• Answer is no (lower bound)! (But actually, yes...!?) 
Comparison Model 
• In this model, assume algorithm can only differentiate items via comparisons 
• Comparable items: black boxes only supporting comparisons between pairs 
• Comparisons are <, ≤, >, ≥, =, =6 , outputs are binary: True or False 
• Goal: Store a set of n comparable items, support find(k) operation 
• Running time is lower bounded by # comparisons performed, so count comparisons! 
Decision Tree 
• Any algorithm can be viewed as a decision tree of operations performed 
• An internal node represents a binary comparison, branching either True or False 
• For a comparison algorithm, the decision tree is binary (draw example) 
• A leaf represents algorithm termination, resulting in an algorithm output 
• A root-to-leaf path represents an execution of the algorithm on some input 
• Need at least one leaf for each algorithm output, so search requires ≥ n + 1 leaves 
","71.765380859375","7","DPRSearchEngine","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_1_pdf","ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4","6.006","4"
"313","Why might having overlap between clusters not necessarily be an issue in clustering algorithms?","found by combining optimal solutions to local subproblems. So for example, when x is greater than 1 we can solve fib x by solving fib x minus 1 and fib x minus 2 and adding those two things together. So there is optimal substructure-- you solve these two smaller problems independently of each other and then combine the solutions in a fast way. You also have to have something called overlapping subproblems. This is why the memo worked. Finding an optimal solution has to involve solving the same problem multiple times. Even if you have optimal substructure, if you don't see the same problem more than once-- creating a memo. Well, it'll work, you can still create the memo. You'll just never find anything in it when you look things up because you're solving each problem once. So you have to be solving the same problem multiple times and you have to be able to solve it by combining solutions to smaller problems. Now, we've seen things with optimal substructure before. In some sense, merge sort worked that way-- we were combining separate problems. Did merge sort have overlapping subproblems? No, because-- well, I guess, it might have if the list had the same element many, many times. But we would expect, mostly not. Because each time we're solving a different problem, because we have different lists that we're now sorting and merging. So it has half of it but not the other. Dynamic programming will not help us for sorting, cannot be used to improve merge sort. Oh, well, nothing is a silver bullet. What about the knapsack problem? Does it have these two properties? We can look at it in terms of these pictures. And it's pretty clear that it does have optimal substructure because we're taking the left branch and the right branch and choosing the winner. But what about overlapping subproblems? Are we ever solving, in this case, the same problem-- add two nodes? Well, do any of these nodes look identical? In this case, no. We could write a dynamic programming solution to the knapsack problem-- and we will-- and run it on this example, and we'd get the right answer. We would get zero speedup. Because at each node, if you can see, the problems are different. We have different things in the knapsack or different things to consider. Never do we have the same contents and the same things left to decide. So ""maybe"" was not a bad answer if that was the answer you gave to this question. But let's look at a different menu. This menu happens to have two beers in it. Now, if we look at what happens, do we see two nodes that are solving the same problem? The answer is what? Yes or no? I haven't drawn the whole tree here. Well, you'll notice the answer is yes.","71.19154357910156","8","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_11_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"313","Why might having overlap between clusters not necessarily be an issue in clustering algorithms?"," 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 5: Linear Sorting 
Lecture 5: Linear Sorting 
Review 
• Comparison search lower bound: any decision tree with n nodes has height ≥dlg(n+1)e−1 
• Can do faster using random access indexing: an operation with linear branching factor! 
• Direct access array is fast, but may use a lot of space (Θ(u)) 
• Solve space problem by mapping (hashing) key space u down to m = Θ(n) 
• Hash tables give expected O(1) time operations, amortized if dynamic 
• Expectation input-independent: choose hash function randomly from universal hash family 
• Data structure overview! 
• Last time we achieved faster ﬁnd. Can we also achieve faster sort? 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
Direct Access Array 
u 
1 
1 
u 
u 
Hash Table 
n(e) 
1(e) 
1(a)(e) 
n 
n 
","70.95671844482422","9","DPRSearchEngine","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5_1_pdf","78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5","6.006","5"
"313","Why might having overlap between clusters not necessarily be an issue in clustering algorithms?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 10: Depth-First Search 
Lecture 10: Depth-First Search 
Previously 
• Graph deﬁnitions (directed/undirected, simple, neighbors, degree) 
• Graph representations (Set mapping vertices to adjacency lists) 
• Paths and simple paths, path length, distance, shortest path 
• Graph Path Problems 
– Single Pair Reachability(G,s,t) 
– Single Source Reachability(G,s) 
– Single Pair Shortest Path(G,s,t) 
– Single Source Shortest Paths(G,s) (SSSP) 
• Breadth-First Search (BFS) 
– algorithm that solves Single Source Shortest Paths 
– with appropriate data structures, runs in O(|V | + |E|) time (linear in input size) 
Examples 
G1 
a 
d 
b 
e 
c 
f 
G2 
a 
d 
b 
e 
c 
f 
","70.70152282714844","10","DPRSearchEngine","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10_1_pdf","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10","6.006","10"
"315","What are some examples of how machine learning is used in real-world applications?","Many problems of practical importance can be formulated as optimization problems. Greedy algorithms often provide an adequate though often not optimal solution. Even though finding an optimal solution is, in theory, exponentially hard, dynamic programming really often yields great results. It always gives you a correct result and it's sometimes, in fact, most of the times gives it to you very quickly. Finally, in the PowerPoint, you'll find an interesting optimization problem","77.19206237792969","1","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_15_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"315","What are some examples of how machine learning is used in real-world applications?"," 
 
 
 
 
 
 
 
 
Machine  Learning Paradigm  
§Observe set of examples: training data 
§Infer something about process that generated that 
data 
§Use inference to make predictions about previously 
unseen data: test data 
§Supervised: given a set of feature/label pairs, find a 
rule that predicts the label associated with a previously 
unseen input 
§Unsupervised: given a set of feature vectors (without 
labels) group them into “natural clusters” 
6.0002  LECTURE 12 
3 
","75.6383285522461","2","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_3_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"315","What are some examples of how machine learning is used in real-world applications?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Monte Carlo Simulation  
A method of estimating the value of an unknown 
quantity using the principles of inferential statistics 
Inferential statistics 
◦ Population: a set of examples 
◦ Sample: a proper subset of a population 
◦ Key fact: a random sample tends to exhibit the same  
properties as the population from which it is drawn  
Exactly what we did with random walks 
6.0002 LECTURE 6 
4
","75.22976684570312","3","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_4_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"315","What are some examples of how machine learning is used in real-world applications?"," 
 
 
  
 
 
 
    
 
 
    
 
        
 
        
 
 
    
 
        
 
 
 
 
        
 
 
 
              
 
    
 
 
 
  
 
 
 
 
    
 
 
        
 
 
 
Monte Carlo Simulation  
def playRoulette(game, numSpins, pocket, bet): 
totPocket = 0 
for i in range(numSpins): 
game.spin()  
totPocket += game.betPocket(pocket, bet)  
if toPrint: 
print(numSpins, 'spins of', game) 
print('Expected return betting', pocket, '=',\\ 
str(100*totPocket/numSpins) + '%\\n') 
return (totPocket/numSpins) 
game = FairRoulette() 
for numSpins in (100, 1000000): 
for i in range(3): 
playRoulette(game, numSpins, 2, 1, True) 
6.0002 LECTURE 6 
12
","74.34187316894531","4","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_12_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"315","What are some examples of how machine learning is used in real-world applications?"," 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
Modeling the  World  
§Models  always  inaccurate
◦Provide abstractions of reality
§Deterministic models, e.g., graph theoretic
§Statistical models
◦Simulation models: Monte Carlo simulation
◦Models  based on sampling
◦Characterizing accuracy is critical
◦Central limit theorem
◦Empirical rule
◦Machine learning
◦Unsupervised and supervised
§Presentation of data
◦Plotting
◦Good and bad practices
6.0002  LECTURE 15 
21 
","74.21202850341797","5","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_18_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"315","What are some examples of how machine learning is used in real-world applications?","OK, so today's topic is about self-reference, self-reproducing machines, and the broader topic called the recursion theorem. So let me introduce it with what I would call the self-reproduction paradox. And that is, suppose you have a factory, like a Tesla effect or a car manufacturing factory. See, there's a picture of the factory, and it's producing cars. All right? So we have a factory that makes cars. And what can we say about the relative complexity of the cars compared with the factory, in some informal sense? So I would argue that you would be reasonable to say that the complexity of the factory is going to have to be greater than the complexity of the cars that it makes. Because not only does the factory have to know how to make the cars, so it has to have all the instructions and whatever things that go into a car, it has to be included in at least some kind of-- it has to be, in some sense, represented in the factory. But the factory also has to have other stuff-- the robots, and the other manufacturing items, tools, and so on-- for making the cars. So the factory has to have all the complexity of a car incorporated plus other things as well. And for that reason, one could imagine that the factory's complexity is more than the car's complexity. But now, suppose you want to have a factory that makes factories-- so imagine here's the picture-- or in general, a machine that makes copies of itself. Well, that seems, at first glance, to be impossible. Because not only does the factory obviously have to have all of the instructions for what a factory is like, but it needs to have all of the extra things that it would need to do the manufacturing. And so for that reason, it seems like it's not possible to have a machine make copies of itself. I mean, you would run into the very same problem if I asked you to produce a program in your favorite language that prints out itself-- an exact copy of the same code. You can always write a program which is going to print out some string, like Hello, world. That's easy because you just put Hello, world into some kind of a variable or some sort of a table into the program and say print that table. But if you want the program to print out a copy of itself, you can't take the whole program and stick that into a table because the program is going to have to be bigger than the table. And so, you're going to end up with something impossible happening. Because the program-- an entire copy of the program can't fit inside the program. You just get the program inside itself, inside itself, inside itself, forever. And so, you end up with an infinite program that way. So if you just kind of naively approach the problem for how to make a program which is going to print out a copy of itself, it's not so easy to do. But hopefully, after today's lecture, you will see that it is possible and in fact, how to do it. And not only that is an idle bit of curiosity, but there are actually applications for why you might want to do that, mainly within mathematics and in computer science theory. But there's even a kind of a real-world application, if you will, in a way too. So we'll get to that at the end. So it seems, as I'm saying, impossible to have a self-reproducing machine. But we know that in the world, there are things that make copies of themselves-- living things. So it seems like a paradox. Cells can make copies exactly of themselves. All living things can make copies of themselves. So how do they manage to get around this paradox? Well, in fact, it is no paradox because it is possible to make a machine that self-reproduces, that makes copies of itself. And this has been known for many years. Probably, it goes back to Von Neumann who wrote a famous paper on self-reproducing machines. OK, so self-reproducing machines are, in fact, possible.","74.02352142333984","6","DPRSearchEngine","N-_XmLanPYg.en-j3PyPqV-e1s_2_mp4","N-_XmLanPYg.en-j3PyPqV-e1s","18.404J","11"
"315","What are some examples of how machine learning is used in real-world applications?"," 
 
 
 
 
 
 
 
 
 
 
 
Optimization Problems  
§Many problems can be formulated in terms of
◦Objective function
◦Set of constraints
§Greedy algorithms often useful
◦But may not find optimal solution
§Many optimization problems inherently exponential
◦But dynamic programming often works
◦And memoization a  generally  useful  technique
§Examples: knapsack problems, graph problems, curve
fitting, clustering 
6.0002  LECTURE 15 
19 
","73.99552154541016","7","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_16_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"315","What are some examples of how machine learning is used in real-world applications?","§ Problem is exponen<al 
§ Have we overturned the laws of the universe? 
§ Is dynamic programming a miracle? 
§ No, but computa<onal complexity can be subtle 
§ Running <me of fastMaxVal is governed by number of 
dis<nct pairs, <toConsider, avail> 
◦Number of possible values of toConsider bounded 
by len(items)
◦Possible values of avail a bit harder to characterize 
◦Bounded by number of dis<nct sums of weights 
◦Covered in more detail in assigned reading 
How Can This Be? 
6.0002 LECTURE 2 
30 
","73.61199951171875","8","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_30_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"315","What are some examples of how machine learning is used in real-world applications?"," 
 
 
 
 
 
 
 
 
Supervised Learning  
Regression 
◦ Predict a real number associated with a feature vector  
◦ E.g., use linear regression to fit a curve to data 
Classification 
◦ Predict a discrete value (label) associated with a feature 
vector 
6.0002 LECTURE 13 
3 
","73.51239013671875","9","DPRSearchEngine","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13_3_pdf","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13","6.0002","13"
"315","What are some examples of how machine learning is used in real-world applications?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 15: Recursive Algorithms 
Lecture 15: Recursive Algorithms 
How to Solve an Algorithms Problem (Review) 
• Reduce to a problem you already know (use data structure or algorithm) 
Search Data Structures 
Sort Algorithms 
Graph Algorithms 
Array 
Insertion Sort 
Breadth First Search 
Linked List 
Selection Sort 
DAG Relaxation (DFS + Topo) 
Dynamic Array 
Merge Sort 
Dijkstra 
Sorted Array 
Counting Sort 
Bellman-Ford 
Direct-Access Array 
Radix Sort 
Johnson 
Hash Table 
AVL Sort 
AVL Tree 
Heap Sort 
Binary Heap 
• Design your own recursive algorithm 
– Constant-sized program to solve arbitrary input 
– Need looping or recursion, analyze by induction 
– Recursive function call: vertex in a graph, directed edge from A → B if B calls A 
– Dependency graph of recursive calls must be acyclic (if can terminate) 
– Classify based on shape of graph 
Class 
Graph 
Brute Force 
Decrease & Conquer 
Divide & Conquer 
Dynamic Programming 
Star 
Chain 
Tree 
DAG 
Greedy/Incremental 
Subgraph 
– Hard part is thinking inductively to construct recurrence on subproblems 
– How to solve a problem recursively (SRT BOT) 
1. Subproblem deﬁnition 
2. Relate subproblem solutions recursively 
3. Topological order on subproblems (⇒ subproblem DAG) 
4. Base cases of relation 
5. Original problem solution via subproblem(s) 
6. Time analysis 
","73.48075866699219","10","DPRSearchEngine","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_1_pdf","9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15","6.006","15"
"317","What does the coefficient of determination, r-squared, indicate about a model's fit to the data?"," 
 
 
Class LogisticRegression  
fit(sequence of feature vectors, sequence of labels) 
Returns object of type LogisticRegression 
coef_ 
Returns weights of features 
predict_proba(feature vector) 
Returns probabilities of labels 
6.0002 LECTURE 13 
22 
","72.6572265625","1","DPRSearchEngine","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13_22_pdf","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13","6.0002","13"
"317","What does the coefficient of determination, r-squared, indicate about a model's fit to the data?","I want to deal with. In each case, get a different training and test set, at random. And then, for each dimension, do the fit. There's polyfit on the training x and training y values in that dimension. Gives you back a model. I could just check to see how well the training set gets, but I really want to look at, given that model, how well does polyval predict the test set, right? The model will say, here's what I expect is the values. I'm going to compare that to the actual values that I saw from the training set, computing that r squared value and adding it in. And then the last of this just says, I'll run this through a set of examples. OK, here's what happens if I do that. I'm not going to run it, although the code will run it. Let me, again, remind you what I'm doing. I got a big set of data I'm going to pick out at random, subsets of it, build the model on one part, test it on the other part. And if I run it, I get a linear fit, quadratic fit, cubic fit, and a quartic fit. And here's the standard deviation of those samples. Remember, I've got multiple trials. I've got 10 trials, in this case. So this gives me the average over those trials. And this tells me how much they vary. What can I conclude from this? Well, I would argue that the linear fit's probably the winner here. Goes back to Einstein. I want the simplest possible model that accounts for it. And you can see it's got the highest r-squared value, which is already a good sign. It's got the smallest deviation across the trials, which says it's probably a pretty good fit. And it's the simplest model. So linear sounds like a pretty good fit. Now, why should we run multiple data sets to test this? I ran 10 trials of each one of these dimensions. Why bother with it? Well, notice that those deviations-- I'll go back to it here-- they're pretty good. They're about an order of magnitude less than the actual mean, which says they're pretty tight, but they're still reasonable size. And that suggests that, while there's good agreement, the deviations are large enough that you could see a range of variation across the trials. So in fact, if I had just run one trial, I could have been screwed. Sorry, oh-- sorry, pick your favorite [INAUDIBLE] here. [? Hose ?] is a Canadian expression, in case you haven't seen it. Here are the r-squared values for each trial of the linear fit. And you can see the mean comes up pretty well. But notice, if I'd only run one trial and I happened to get that one, oh, darn. That's a really low r-squared value. And we might have decided, in this case, a different conclusion, that the linear fit was not a good fit. So this is a way of saying, even in a random sampling, run multiple trials, because it lets you get statistics on those trials, as well as statistics within each trial. So with any trial, I'm doing a whole bunch of different random samples on measuring those values. And then, across those trials, I'm seeing what the deviation is. I'm going to hope my machine comes back, because what I want to do is then pull this together. What have we done? Something you're going to use. We've seen how you can use linear regression to fit a curve to data, 2D, 3D, 6D, however big the data set is. It gives us a mapping from the independent values to the dependent values. And that can then be used to predict values associated with the independent values that we haven't seen yet. That leads, naturally, to both a way to measure, which is r squared, but especially to see that we want to look at how well does that model actually predict new data, because that lets us select the simplest model we can that accounts for the data, but predicts new data in an effective way. And that complexity can either be based on theory, in the case of Hooke, or in more likely cases, by doing cross-validation to try and figure out which one is the simplest model that still does a good job of predicting out of data behavior. And with that, I'll see you next time.","72.65107727050781","2","DPRSearchEngine","fQvg-hh9dUw.en-qlPKC2UN_YU_21_mp4","fQvg-hh9dUw.en-qlPKC2UN_YU","6.0002","10"
"317","What does the coefficient of determination, r-squared, indicate about a model's fit to the data?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Logistic Regression 
Analogous to linear regression 
Designed explicitly for predicting probability of an event 
◦ Dependent variable can only take on a finite set of values  
◦ Usually 0 or 1 
Finds weights for each feature 
◦ Positive implies variable positively correlated with  
outcome  
◦ Negative implies variable negatively correlated with  
outcome  
◦ Absolute magnitude related to strength of the correlation  
Optimization problem a bit complex, key is use of a log
function—won’t make you look at it 
6.0002 LECTURE 13 
21 
","72.52767944335938","3","DPRSearchEngine","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13_21_pdf","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13","6.0002","13"
"317","What does the coefficient of determination, r-squared, indicate about a model's fit to the data?","is that the variance of the sample means will be close to the variance of the population divided by the sample size. And we're going to use that to compute something called the standard error-- formerly the standard error of the mean. People often just call it the standard error. And I will be, alas, inconsistent. I sometimes call it one, sometimes the other. It's an incredibly simple formula. It says the standard error is going to be equal to sigma, where sigma is the population standard deviation divided by the square root of n, which is going to be the size of the sample. And then there's just this very small function that implements it. So we can compute this thing called the standard error of the mean in a very straightforward way. We can compute it. But does it work? What do I mean by work? I mean, what's the relationship of the standard error to the standard deviation? Because, remember, that was our goal, was to understand the standard deviation so we could use the empirical rule. Well, let's test the standard error of the mean.","72.15632629394531","4","DPRSearchEngine","soZv_KKax3E.en-qlPKC2UN_YU_9_mp4","soZv_KKax3E.en-qlPKC2UN_YU","6.0002","8"
"317","What does the coefficient of determination, r-squared, indicate about a model's fit to the data?","A pretty small number. But the probability of 26 consecutive reds when the previous 25 rolls were red is what? No, that. AUDIENCE: Oh, I thought you meant it had been 26 times again. JOHN GUTTAG: No, if you had 25 reds and then you spun the wheel once more, the probability of it having 26 reds is now 0.5, because these are independent events. Unless of course the wheel is rigged, and we're assuming it's not. People have a hard time accepting this, and I know it seems funny. But I guarantee there will be some point in the next month or so when you will find yourself thinking this way, that something has to even out. I did so badly on the midterm, I will have to do better on the final. That was mean, I'm sorry. All right, speaking of means-- see? Professor Grimson not the only one who can make bad jokes. There is something-- it's not the gambler's fallacy-- that's often confused with it, and that's called regression to the mean. This term was coined in 1885 by Francis Galton in a paper, of which I've shown you a page from it here.","72.06394958496094","5","DPRSearchEngine","OgO1gpXSUzU.en-j3PyPqV-e1s_8_mp4","OgO1gpXSUzU.en-j3PyPqV-e1s","6.0002","6"
"317","What does the coefficient of determination, r-squared, indicate about a model's fit to the data?","!	!	 	
 
Let D be the original data set 
    n be the number of random samples  
 
 
 usually n between 20% and 50% 
    k be number of trials 
 
testResults = [] 
for i in range(k) 
    randomly select n elements for testSet,  
       keep rest for training 
    model = buildModel(training) 
    testResults.append(test(model, testSet)) 
 
Average testResults 

	

;G
","72.0498275756836","6","DPRSearchEngine","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10_38_pdf","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10","6.0002","10"
"317","What does the coefficient of determination, r-squared, indicate about a model's fit to the data?","I'm going to look at a bunch of different sample sizes, from 25 to 600, 50 trials each. So getHighs is just a function that returns the temperatures. I'm going to get the standard deviation of the whole population, then the standard error of the means and the sample standard deviations, both. And then I'm just going to go through and run it. So for size and sample size, I'm going to append the standard error of the mean. And remember, that uses the population standard deviation and the size of the sample. So I'll compute all the SEMs. And then I'm going to compute all the actual standard deviations, as well. And then we'll produce a bunch of plots-- or a plot, actually. All right, so let's see what that plot looks like.","71.66629028320312","7","DPRSearchEngine","soZv_KKax3E.en-qlPKC2UN_YU_10_mp4","soZv_KKax3E.en-qlPKC2UN_YU","6.0002","8"
"317","What does the coefficient of determination, r-squared, indicate about a model's fit to the data?"," 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
Law of Large Numbers  
In repeated independent tests with the same actual 
probability p of a particular outcome in each test, the 
chance that the fraction of times that outcome occurs 
differs from p converges to zero as the number of trials 
goes to infinity 
Does this imply that if 
deviations from expected 
behavior occur, these 
deviations are likely to be 
evened out by opposite 
deviations in the future? 
6.0002 LECTURE 6 
14
","71.66069030761719","8","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_14_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"317","What does the coefficient of determination, r-squared, indicate about a model's fit to the data?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
Regression to the Mean  
Following an extreme random event, the next random 
event is likely to be less extreme 
If you spin a fair roulette wheel 10 times and get 100% 
reds, that is an extreme event (probability = 1/1024) 
It is likely that in the next 10 spins, you will get fewer 
than 10 reds 
◦ But the expected number is only 5 
So, if you look at the average of the 20 spins, it will be 
closer to the expected mean of 50% reds than to the 
100% of the first 10 spins 
6.0002 LECTURE 6 
16
","71.51018524169922","9","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_16_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"317","What does the coefficient of determination, r-squared, indicate about a model's fit to the data?","I'll take in a set of observed values, a set of predicted values, and I'll measure the error-- again, these are arrays. So I'm going to take the difference between the arrays. That's going to give me piecewise or pairwise that difference. I'll square it. That's going to give me at every point in the array the square of that distance. And then because it's an array, I can just use the built-in sum function to add them all up. So this is going to give me the-- if you like, the values up there. And then I'm going to play a little trick. I'm going to compute the mean error, which is that thing divided by the number of observations. Why would I do that? Well, because then I can compute this really simply. I could write a little loop to compute it. But in fact, I've already said what is that? If I take that sum and divide it by the number of samples, that's the variance. So that's really nice. Right here I can say, get the variance using the non-p version of the observed data. And because that has associated with it division by the number of samples, the ratio of the mean error to the variance is exactly the same as the ratio of that to that. Little trick. It lets me save doing a little bit of computation. So I can compute r squared values. So what does r squared actually tell us? What we're doing is we're trying to compare the estimation errors, the top part, with the variability in the original values, the bottom part. So r squared, as you're going to see there, it's intended to capture what portion of the variability in the data is accounted for by my model. My model's a really good fit. It should account for almost all of that data. So what we see then is if we do a fit with a linear regression, r squared is always going to be between zero and one. And I want to just show you some examples. If r squared is equal to one, this is great. It says the model explains all of the variability in the data. And you can see it if we go back here. How do we make r squared equal to one? We need this to be zero, which says that the variability in the data is perfectly predicted by my model. Every point lies exactly along the curve. That's great. Second option at the other extreme is if r squared is equal to zero, you basically got bupkis, which is a well-known technical term, meaning there's no relationship between the values predicted by the model and the actual data. That basically says that all of the variability here is exactly the same as all the variability in the data. The model doesn't capture anything, and it's making this one, which is making the whole thing zero. And then in between an r squared of about a half says you're capturing about half the variability. So what you would like is a system in which your fit is as close to an r squared value of one as possible because it says my model is capturing all the variability in the data really well. So two functions that will do this for us.","71.30603790283203","10","DPRSearchEngine","vIFKGFl1Cn8.en-qlPKC2UN_YU_16_mp4","vIFKGFl1Cn8.en-qlPKC2UN_YU","6.0002","9"
"319","What are features in the context of machine learning?"," 
 
 
 
 
 
 
 
 
Machine  Learning Paradigm  
§Observe set of examples: training data 
§Infer something about process that generated that 
data 
§Use inference to make predictions about previously 
unseen data: test data 
§Supervised: given a set of feature/label pairs, find a 
rule that predicts the label associated with a previously 
unseen input 
§Unsupervised: given a set of feature vectors (without 
labels) group them into “natural clusters” 
6.0002  LECTURE 12 
3 
","81.24137878417969","1","DPRSearchEngine","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_3_pdf","367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12","6.0002","12"
"319","What are features in the context of machine learning?","The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation, or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. PROFESSOR: Hello, everybody. Before we start the material, a couple of announcements. As usual, there's some reading assignments, and you might be surprised to see something from Chapter 5 suddenly popping up. But this is my relentless attempt to introduce more Python. We'll see one new concept later today, list comprehension. Today we're going to look at classification. And you remember last, on Monday, we looked at unsupervised learning. Today we're looking at supervised learning. It can usually be divided into two categories. Regression, where you try and predict some real number associated with the feature vector, and this is something we've already done really, back when we looked at curve fitting, linear regression in particular. It was exactly building a model that, given some features, would predict a point. In this case, it was pretty simple. It was given x predict y. You can imagine generalizing that to multi dimensions.","77.11659240722656","2","DPRSearchEngine","eg8DJYwdMyg.en-qlPKC2UN_YU_1_mp4","eg8DJYwdMyg.en-qlPKC2UN_YU","6.0002","13"
"319","What are features in the context of machine learning?"," 
 
 
Class LogisticRegression  
fit(sequence of feature vectors, sequence of labels) 
Returns object of type LogisticRegression 
coef_ 
Returns weights of features 
predict_proba(feature vector) 
Returns probabilities of labels 
6.0002 LECTURE 13 
22 
","76.44476318359375","3","DPRSearchEngine","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13_22_pdf","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13","6.0002","13"
"319","What are features in the context of machine learning?"," 
 
 
 
 
 
 
 
 
Supervised Learning  
Regression 
◦ Predict a real number associated with a feature vector  
◦ E.g., use linear regression to fit a curve to data 
Classification 
◦ Predict a discrete value (label) associated with a feature 
vector 
6.0002 LECTURE 13 
3 
","76.41639709472656","4","DPRSearchEngine","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13_3_pdf","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13","6.0002","13"
"319","What are features in the context of machine learning?"," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 10: Depth-First Search 
Lecture 10: Depth-First Search 
Previously 
• Graph deﬁnitions (directed/undirected, simple, neighbors, degree) 
• Graph representations (Set mapping vertices to adjacency lists) 
• Paths and simple paths, path length, distance, shortest path 
• Graph Path Problems 
– Single Pair Reachability(G,s,t) 
– Single Source Reachability(G,s) 
– Single Pair Shortest Path(G,s,t) 
– Single Source Shortest Paths(G,s) (SSSP) 
• Breadth-First Search (BFS) 
– algorithm that solves Single Source Shortest Paths 
– with appropriate data structures, runs in O(|V | + |E|) time (linear in input size) 
Examples 
G1 
a 
d 
b 
e 
c 
f 
G2 
a 
d 
b 
e 
c 
f 
","75.65247344970703","5","DPRSearchEngine","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10_1_pdf","f3e349e0eb3288592289d2c81e0c4f4d_MIT6_006S20_lec10","6.006","10"
"319","What are features in the context of machine learning?","And we'll look at what happens when we scale and when we don't scale. And that's why my getData function has this parameter to scale. It either creates a set of examples with the attributes as initially or scaled. And then there's k-means. It's exactly the algorithm I showed you with one little wrinkle, which is this part. You don't want to end up with empty clusters. If I tell you I want four clusters, I don't mean I want three with examples and one that's empty, right? Because then I really don't have four clusters. And so this is one of multiple ways to avoid having empty clusters. Basically what I did here is say, well, I'm going to try a lot of different initial conditions. If one of them is so unlucky to give me an empty cluster, I'm just going to skip it and go on to the next one by raising a value error, empty cluster. And if you look at the code, you'll see how this value error is used. And then try k-means. We'll call k-means numTrial times, each one getting a different set of initial centroids, and return the result with the lowest dissimilarity.","75.56584930419922","6","DPRSearchEngine","esmzYhuFnds.en-qlPKC2UN_YU_13_mp4","esmzYhuFnds.en-qlPKC2UN_YU","6.0002","12"
"319","What are features in the context of machine learning?","Now, this description here-- notice that I've labeled this as a set interface. This is not a set data structure. And the way to remember that is that I haven't told you how I've actually implemented this. I haven't told you that I'm going to behind the scenes have an array of information, and look inside of it, and that's how I'm going to implement find min or find max with a for loop or whatever. All I'm telling you is that a set is a thing that implements these operations. And behind the scenes, my computer does what it does. Now, it might sound abstract. But it's more or less what you guys do when you write code in Python. I think in Python what we're calling a set is maybe a dictionary. I'm a Matlab Coder. I'm sorry. I'm a numerical analysis kind of guy. But essentially, one of the beautiful things about coding in these high level programming languages is that they take care of these ugly details. And what you're left with is just the high level interfacing with this object","75.45854949951172","7","DPRSearchEngine","oS9aPzUNG-s.en-j3PyPqV-e1s_6_mp4","oS9aPzUNG-s.en-j3PyPqV-e1s","6.006","3"
"319","What are features in the context of machine learning?","Header for Decision Tree Implementa#on 
6.0002 LECTURE 2 
9 
def maxVal(toConsider, avail): 
    """"""Assumes toConsider a list of items,  
               avail a weight 
       Returns a tuple of the total value of a  
           solution to 0/1 knapsack problem and  
           the items of that solution""""” 
toConsider. Those items that nodes higher up in the tree 
(corresponding to earlier calls in the recursive call stack) 
have not yet considered 
 
avail. The amount of space still available  
","75.40328216552734","8","DPRSearchEngine","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_9_pdf","3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2","6.0002","2"
"319","What are features in the context of machine learning?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 16: Dyn. Prog. Subproblems 
Lecture 16: Dyn. Prog. Subproblems 
Dynamic Programming Review 
• Recursion where subproblem dependencies overlap, forming DAG 
• “Recurse but re-use” (Top down: record and lookup subproblem solutions) 
• “Careful brute force” (Bottom up: do each subproblem in order) 
Dynamic Programming Steps (SRT BOT) 
1. Subproblem deﬁnition 
subproblem x 2 X 
• Describe the meaning of a subproblem in words, in terms of parameters 
• Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence 
• Often multiply possible subsets across multiple inputs 
• Often record partial state: add subproblems by incrementing some auxiliary variables 
2. Relate subproblem solutions recursively 
x(i) =  f(x(j), . . .) for one or more j < i  
• Identify a question about a subproblem solution that, if you knew the answer to, reduces 
the subproblem to smaller subproblem(s) 
• Locally brute-force all possible answers to the question 
3. Topological order to argue relation is acyclic and subproblems form a DAG 
4. Base cases 
• State solutions for all (reachable) independent subproblems where relation breaks down 
5. Original problem 
• Show how to compute solution to original problem from solutions to subproblem(s) 
• Possibly use parent pointers to recover actual solution, not just objective function 
6. Time analysis 
P 
• 
x2X work(x), or if work(x) =  O(W) for all x 2 X, then |X| · O(W) 
• work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time 
","75.37316131591797","9","DPRSearchEngine","28461a74f81101874a13d9679a40584d_MIT6_006S20_lec16_1_pdf","28461a74f81101874a13d9679a40584d_MIT6_006S20_lec16","6.006","16"
"319","What are features in the context of machine learning?","if an English description is possible for a Turing machine? Well, you can always write down an English description for any machine. It's-- might be very technical looking, but if you can write it down in a formal way as states and transitions, then you can simply write down an English description, which would just be, follow those states. OK, let's move on. OK, this is going to be our first example of a algorithm that's going to answer a question about automata. And it's a very simple problem. It's a very simple problem to solve, because we want to start out easy. The name of the problem is the acceptance problem for deterministic finite automata, acceptance problem for DFAs. And I'm going to express it, as I always do, as a language.","75.21153259277344","10","DPRSearchEngine","4MgN6uxd4i4.en-j3PyPqV-e1s_4_mp4","4MgN6uxd4i4.en-j3PyPqV-e1s","18.404J","7"
"321","What do the varying expected returns from 100 spins and 1,000,000 spins of Fair Roulette indicate about the nature of Monte Carlo simulations?"," 
 
 
  
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
100 and 1M Spins of the Wheel  
100 spins of Fair Roulette 
Expected return betting 2 = -100.0% 
100 spins of Fair Roulette 
Expected return betting 2 = 44.0% 
100 spins of Fair Roulette 
Expected return betting 2 = -28.0% 
1000000 spins of Fair Roulette 
Expected return betting 2 = -0.046% 
1000000 spins of Fair Roulette 
Expected return betting 2 = 0.602% 
1000000 spins of Fair Roulette 
Expected return betting 2 = 0.7964% 
6.0002 LECTURE 6 
13
","82.95648193359375","1","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_13_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"321","What do the varying expected returns from 100 spins and 1,000,000 spins of Fair Roulette indicate about the nature of Monte Carlo simulations?"," 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Results  
Simulate betting a pocket for 20 trials of 1000 spins each 
Exp. return for Fair Roulette = 3.68%, +/- 27.189% with 95% confidence 
Exp. return for European Roulette = -5.5%, +/- 35.042% with 95% confidence 
Exp. return for American Roulette = -4.24%, +/- 26.494% with 95% confidence 
Simulate betting a pocket for 20 trials of 100000 spins each 
Exp. return for Fair Roulette = 0.125%, +/- 3.999% with 95% confidence 
Exp. return for European Roulette = -3.313%, +/- 3.515% with 95% confidence 
Exp. return for American Roulette = -5.594%, +/- 4.287% with 95% confidence 
Simulate betting a pocket for 20 trials of 1000000 spins each 
Exp. return for Fair Roulette = 0.012%, +/- 0.846% with 95% confidence 
Exp. return for European Roulette = -2.679%, +/- 0.948% with 95% confidence 
Exp. return for American Roulette = -5.176%, +/- 1.214% with 95% confidence 
6.0002 LECTURE 6 
26
","81.99482727050781","2","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_26_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"321","What do the varying expected returns from 100 spins and 1,000,000 spins of Fair Roulette indicate about the nature of Monte Carlo simulations?","So when I simulated betting a pocket for 20 trials, we see that the-- of 1,000 spins each, for 1,000 spins the expected return for fair roulette happened to be 3.68%. A bit high. But you'll notice the confidence interval plus or minus 27 includes the actual answer, which is 0. And we have very large confidence intervals for the other two games. If you go way down to the bottom where I've spun, spun the wheel many more times, what we'll see is that my expected return for fair roulette is much closer to 0 than it was here. But more importantly, my confidence interval is much smaller, 0.8. So now I really have constrained it pretty well. Similarly, for the other two games you will see-- maybe it's more accurate, maybe it's less accurate, but importantly the confidence interval is smaller. So I have good reason to believe that the mean I'm computing is close to the true mean, because my confidence interval has shrunk. So that's the really important concept here, is that we don't just guess-- compute the value in the simulation. We use, in this case, the empirical rule to tell us how much faith we should have in that value. All right, the empirical rule doesn't always work. There are a couple of assumptions. One is that the mean estimation error is 0. What is that saying? That I'm just as likely to guess high as gas low. In most experiments of this sort, most simulations, that's a very fair assumption. There's no reason to guess I'd be systematically off in one direction or another. It's different when you use this in a laboratory experiment, where in fact, depending upon your laboratory technique, there may be a bias in your results in one direction. So we have to assume that there's no bias in our errors. And we have to assume that the distribution of errors","80.55531311035156","3","DPRSearchEngine","OgO1gpXSUzU.en-j3PyPqV-e1s_15_mp4","OgO1gpXSUzU.en-j3PyPqV-e1s","6.0002","6"
"321","What do the varying expected returns from 100 spins and 1,000,000 spins of Fair Roulette indicate about the nature of Monte Carlo simulations?"," 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Comparing the Games  
Simulate 20 trials of 1000 spins each  
Exp. return for Fair Roulette = 6.56%  
Exp. return for European Roulette = -2.26%  
Exp. return for American Roulette = -8.92%  
Simulate 20 trials of 10000 spins each  
Exp. return for Fair Roulette = -1.234%  
Exp. return for European Roulette = -4.168%  
Exp. return for American Roulette = -5.752%  
Simulate 20 trials of 100000 spins each  
Exp. return for Fair Roulette = 0.8144%  
Exp. return for European Roulette = -2.6506%  
Exp. return for American Roulette = -5.113%  
Simulate 20 trials of 1000000 spins each  
Exp. return for Fair Roulette = -0.0723%  
Exp. return for European Roulette = -2.7329%  
6.0002 LECTURE 6 
Exp. return for American Roulette = -5.212% 
19
","79.75969696044922","4","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_19_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"321","What do the varying expected returns from 100 spins and 1,000,000 spins of Fair Roulette indicate about the nature of Monte Carlo simulations?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
Regression to the Mean  
Following an extreme random event, the next random 
event is likely to be less extreme 
If you spin a fair roulette wheel 10 times and get 100% 
reds, that is an extreme event (probability = 1/1024) 
It is likely that in the next 10 spins, you will get fewer 
than 10 reds 
◦ But the expected number is only 5 
So, if you look at the average of the 20 spins, it will be 
closer to the expected mean of 50% reds than to the 
100% of the first 10 spins 
6.0002 LECTURE 6 
16
","79.36079406738281","5","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_16_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"321","What do the varying expected returns from 100 spins and 1,000,000 spins of Fair Roulette indicate about the nature of Monte Carlo simulations?","100,000, and a million. And what do we see as we look at this? Well, right away we can see that fair roulette is usually a much better bet than either of the other two. That even with only 1,000 spins the return is negative. And as we get more and more as I got to a million, it starts to look much more like closer to 0. And these, we have reason to believe at least, are much closer to true expectation saying that, while you break even in fair roulette, you'll lose 2.7% in Europe and over 5% in Las Vegas, or soon in Massachusetts. All right, we're sampling, right? That's why the results will change, and if I ran a different simulation with a different seed I'd get different numbers. Whenever you're sampling, you can't be guaranteed to get perfect accuracy. It's always possible you get a weird sample. That's not to say that you won't get exactly the right answer. I might have spun the wheel twice and happened to get the exact right answer of the return. Actually not twice, because the math doesn't work out, but 35 times and gotten exactly the right answer. But that's not the point. We need to be able to differentiate between what happens to be true and what we actually know, in a rigorous sense, is true. Or maybe don't know it, but have real good reason to believe it's true. So it's not just a question of faith. And that gets us to what's in some sense the fundamental question of all computational statistics, is how many samples do we need to look at before we can have real, justifiable confidence in our answer? As we've just seen-- not just, a few minutes ago-- with the coins, our intuition tells us that it depends upon the variability in the underlying possibilities. So let's look at that more carefully. We have to look at the variation in the data. So let's look at first something called variance.","79.25962829589844","6","DPRSearchEngine","OgO1gpXSUzU.en-j3PyPqV-e1s_11_mp4","OgO1gpXSUzU.en-j3PyPqV-e1s","6.0002","6"
"321","What do the varying expected returns from 100 spins and 1,000,000 spins of Fair Roulette indicate about the nature of Monte Carlo simulations?"," 
 
 
  
 
 
 
    
 
 
    
 
        
 
        
 
 
    
 
        
 
 
 
 
        
 
 
 
              
 
    
 
 
 
  
 
 
 
 
    
 
 
        
 
 
 
Monte Carlo Simulation  
def playRoulette(game, numSpins, pocket, bet): 
totPocket = 0 
for i in range(numSpins): 
game.spin()  
totPocket += game.betPocket(pocket, bet)  
if toPrint: 
print(numSpins, 'spins of', game) 
print('Expected return betting', pocket, '=',\\ 
str(100*totPocket/numSpins) + '%\\n') 
return (totPocket/numSpins) 
game = FairRoulette() 
for numSpins in (100, 1000000): 
for i in range(3): 
playRoulette(game, numSpins, 2, 1, True) 
6.0002 LECTURE 6 
12
","79.09468078613281","7","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_12_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"321","What do the varying expected returns from 100 spins and 1,000,000 spins of Fair Roulette indicate about the nature of Monte Carlo simulations?"," 
 
 
  
 
 
 
 
 
 
 
    
 
 
 
 
    
 
 
 
          
 
    
 
        
 
 
 
                                         
 
 
        
 
 
        
 
                                          
 
                                          
 
        
 
 
              
 
               
 
 
 
               
 
Applying Empirical Rule  
resultDict = {}  
games = (FairRoulette, EuRoulette, AmRoulette)  
for G in games:  
resultDict[G().__str__()] = [] 
for numSpins in (100, 1000, 10000): 
print('\\nSimulate betting a pocket for', numTrials, 
'trials of', numSpins, 'spins each') 
for G in games: 
pocketReturns = findPocketReturn(G(), 20, 
numSpins, False) 
mean, std = getMeanAndStd(pocketReturns) 
resultDict[G().__str__()].append((numSpins, 
100*mean, 
100*std)) 
print('Exp. return for', G(), '=', 
str(round(100*mean, 3)) 
+ '%,', '+/- ' + str(round(100*1.96*std, 3)) 
+ '% with 95% confidence') 
6.0002 LECTURE 6 
25
","77.08230590820312","8","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_25_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"321","What do the varying expected returns from 100 spins and 1,000,000 spins of Fair Roulette indicate about the nature of Monte Carlo simulations?","what this table says is if somebody's parents are both taller than average, it's likely that the child will be smaller than the parents. Conversely, if the parents are shorter than average, it's likely that the child will be taller than average. Now you can think about this in terms of genetics and stuff. That's not what he did. He just looked at a bunch of data, and the data actually supported this. And this led him to this notion of regression to the mean. And here's what it is, and here's the way in which it is subtly different from the gambler's fallacy. What he said here is, following an extreme event-- parents being unusually tall-- the next random event is likely to be less extreme. He didn't know much about genetics, and he kind of assumed the height of people were random. But we'll ignore that. OK, but the idea is here that it will be less extreme. So let's look at it in roulette. If I spin a fair roulette wheel 10 times and get 10 reds, that's an extreme event. Right, here's a probability of basically 1.1024. Now the gambler's fallacy says, if I were to spin it another 10 times, it would need to even out. As in I should get more blacks than you would usually get to make up for these excess reds. What regression to the mean says is different. It says, it's likely that in the next 10 spins, you will get fewer than 10 reds. You will get a less extreme event. Now it doesn't have to be 10. If I'd gotten 7 reds instead of 5, you'd consider that extreme, and you would bet that the next 10 would have fewer than 7. But you wouldn't bet that it would have fewer than 5. Because of this, if you now look at the average of the 20 spins, it will be closer to the mean of 50% reds than you got from the extreme first spins. So that's why it's called regression to the mean. The more samples you take, the more likely you'll get to the mean. Yes? AUDIENCE: So, roulette wheel spins are supposed to be independent. JOHN GUTTAG: Yes. AUDIENCE: So it seems like the second 10-- JOHN GUTTAG: Pardon? AUDIENCE: It seems like the second 10 times that you spin it. Like that shouldn't have to [INAUDIBLE].. JOHN GUTTAG: Has nothing to do with the first one. AUDIENCE: But you said it's likely [INAUDIBLE].. JOHN GUTTAG: Right, because you have an extreme event, which was unlikely. And now if you have another event, it's likely to be closer to the average than the extreme was to the average. Precisely because it is independent. That makes sense to everybody? Yeah? AUDIENCE: Isn't that the same as the gambler's fallacy, then? By saying that, because this was super unlikely, the next one [INAUDIBLE]. JOHN GUTTAG: No, the gambler's fallacy here-- and it's a good question, and indeed people often do get these things confused. The gambler's fallacy would say that the second 10 spins would-- we would expect to have fewer than 5 reds, because you're trying to even out the unusual number of reds in the first Spin Whereas here we're not saying we would have fewer than 5. We're saying we'd probably have fewer than 10. That it'll be closer to the mean, not that it would be below the mean. Whereas the gambler's fallacy would say it should be below that mean to quote, even out, the first 10. Does that makes sense? OK, great questions. Thank you. All right, now you may not know this, but casinos are not in the business of being fair. And the way they don't do that is in Europe, they're not all red and black. They sneak in one green. And so now if you bet red, well sometimes it isn't always red or black. And furthermore, there is this 0. They index from 0 rather than from one, and so you don't get a full payoff. In American roulette, they manage to sneak in two greens. They have a 0 in a double 0. Tilting the odds even more in favor of the casino. So we can do that in our simulation. We'll look at European roulette as a subclass of fair roulette. I've just added this extra pocket, 0. And notice I have not changed the odds. So what you get if you get your number is no higher, but you're a little bit less likely to get it because we snuck in that 0.","75.03821563720703","9","DPRSearchEngine","OgO1gpXSUzU.en-j3PyPqV-e1s_9_mp4","OgO1gpXSUzU.en-j3PyPqV-e1s","6.0002","6"
"321","What do the varying expected returns from 100 spins and 1,000,000 spins of Fair Roulette indicate about the nature of Monte Carlo simulations?","I would never show that to high school students, or GREs to you guys. But you can see that they are amazingly well-distributed along a normal distribution. On down here, this is plotting percent change in oil prices. And again, we see something very close to a normal distribution. And here is just looking at heights of men and women. And again, they clearly look very normal. So it's really quite impressive how often they occur. But not everything is normal. So we saw that the empirical rule works for normal distributions. I won't say I proved it for you. I illustrated it for you with a bunch of examples. But are the outcomes of the spins of a roulette wheel normal? No. They're totally uniform, right? Everything is equally probable-- a 4, a 6, an 11, a 13, double-0 if you're in Las Vegas. They're all equally probable. So if I plotted those, I'd basically just get a straight line with everything at 1 over however many pockets there are. So in that case, why does the empirical rule work? We saw that we were doing some estimates about returns and we used the empirical rule, we checked it and, by George, it was telling us the truth. And the reason is because we're not reasoning about a single spin of the wheel but about the mean of a set of spins. So if you think about it, what we were reasoning about was the return of betting. If we look at one spin-- well, let's say we bet $1. The return is either minus 1 because we've lost our dollar. Or if we get lucky and our pocket happens to come up, it was 36, I think, or 35. I forget which, OK? But that's all. So if we plotted a histogram, we would see a huge peak at minus 1 and a little bump here at 36 and nothing in the middle. Clearly, not a normal distribution. But what we're reasoning about is not the return of a single spin but the return of many spins. If we played 1,000 spins, what is our expected return? As soon as we end up reasoning, not about a single event but about the mean of something, we can imply something","74.95161437988281","10","DPRSearchEngine","rUxP7TM8-wo.en-qlPKC2UN_YU_6_mp4","rUxP7TM8-wo.en-qlPKC2UN_YU","6.0002","7"
"327","What are the two main methodologies for characterizing the believability of statistical results and how are they implemented?"," 
 
Looking at  Distributions 
def plotDistributions():  
uniform, normal, exp = [], [], []  
for i in range(100000):  
uniform.append(random.random())  
normal.append(random.gauss(0, 1))  
exp.append(random.expovariate(0.5))  
makeHist(uniform, 'Uniform', 'Value', 'Frequency')  
pylab.figure()  
makeHist(normal, 'Gaussian', 'Value', 'Frequency')  
pylab.figure()  
makeHist(exp, 'Exponential', 'Value', 'Frequency')  
6.0002  LECTURE 8 
 
27
","72.53726196289062","1","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_27_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"327","What are the two main methodologies for characterizing the believability of statistical results and how are they implemented?"," 
 
 
 
 
  
 
 
  
 
Probability of Various Results  
Consider testRoll(5) 
How probable is the output 11111?  
6.0002 LECTURE 4 
10
","70.7039794921875","2","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_10_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"327","What are the two main methodologies for characterizing the believability of statistical results and how are they implemented?","I'm going to look at a bunch of different sample sizes, from 25 to 600, 50 trials each. So getHighs is just a function that returns the temperatures. I'm going to get the standard deviation of the whole population, then the standard error of the means and the sample standard deviations, both. And then I'm just going to go through and run it. So for size and sample size, I'm going to append the standard error of the mean. And remember, that uses the population standard deviation and the size of the sample. So I'll compute all the SEMs. And then I'm going to compute all the actual standard deviations, as well. And then we'll produce a bunch of plots-- or a plot, actually. All right, so let's see what that plot looks like.","70.1431655883789","3","DPRSearchEngine","soZv_KKax3E.en-qlPKC2UN_YU_10_mp4","soZv_KKax3E.en-qlPKC2UN_YU","6.0002","8"
"327","What are the two main methodologies for characterizing the believability of statistical results and how are they implemented?"," 
 
 
Class LogisticRegression  
fit(sequence of feature vectors, sequence of labels) 
Returns object of type LogisticRegression 
coef_ 
Returns weights of features 
predict_proba(feature vector) 
Returns probabilities of labels 
6.0002 LECTURE 13 
22 
","69.90614318847656","4","DPRSearchEngine","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13_22_pdf","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13","6.0002","13"
"327","What are the two main methodologies for characterizing the believability of statistical results and how are they implemented?","!	!	 	
 
Let D be the original data set 
    n be the number of random samples  
 
 
 usually n between 20% and 50% 
    k be number of trials 
 
testResults = [] 
for i in range(k) 
    randomly select n elements for testSet,  
       keep rest for training 
    model = buildModel(training) 
    testResults.append(test(model, testSet)) 
 
Average testResults 

	

;G
","69.4451675415039","5","DPRSearchEngine","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10_38_pdf","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10","6.0002","10"
"327","What are the two main methodologies for characterizing the believability of statistical results and how are they implemented?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Monte Carlo Simulation  
A method of estimating the value of an unknown 
quantity using the principles of inferential statistics 
Inferential statistics 
◦ Population: a set of examples 
◦ Sample: a proper subset of a population 
◦ Key fact: a random sample tends to exhibit the same  
properties as the population from which it is drawn  
Exactly what we did with random walks 
6.0002 LECTURE 6 
4
","69.33769226074219","6","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_4_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"327","What are the two main methodologies for characterizing the believability of statistical results and how are they implemented?","I want to deal with. In each case, get a different training and test set, at random. And then, for each dimension, do the fit. There's polyfit on the training x and training y values in that dimension. Gives you back a model. I could just check to see how well the training set gets, but I really want to look at, given that model, how well does polyval predict the test set, right? The model will say, here's what I expect is the values. I'm going to compare that to the actual values that I saw from the training set, computing that r squared value and adding it in. And then the last of this just says, I'll run this through a set of examples. OK, here's what happens if I do that. I'm not going to run it, although the code will run it. Let me, again, remind you what I'm doing. I got a big set of data I'm going to pick out at random, subsets of it, build the model on one part, test it on the other part. And if I run it, I get a linear fit, quadratic fit, cubic fit, and a quartic fit. And here's the standard deviation of those samples. Remember, I've got multiple trials. I've got 10 trials, in this case. So this gives me the average over those trials. And this tells me how much they vary. What can I conclude from this? Well, I would argue that the linear fit's probably the winner here. Goes back to Einstein. I want the simplest possible model that accounts for it. And you can see it's got the highest r-squared value, which is already a good sign. It's got the smallest deviation across the trials, which says it's probably a pretty good fit. And it's the simplest model. So linear sounds like a pretty good fit. Now, why should we run multiple data sets to test this? I ran 10 trials of each one of these dimensions. Why bother with it? Well, notice that those deviations-- I'll go back to it here-- they're pretty good. They're about an order of magnitude less than the actual mean, which says they're pretty tight, but they're still reasonable size. And that suggests that, while there's good agreement, the deviations are large enough that you could see a range of variation across the trials. So in fact, if I had just run one trial, I could have been screwed. Sorry, oh-- sorry, pick your favorite [INAUDIBLE] here. [? Hose ?] is a Canadian expression, in case you haven't seen it. Here are the r-squared values for each trial of the linear fit. And you can see the mean comes up pretty well. But notice, if I'd only run one trial and I happened to get that one, oh, darn. That's a really low r-squared value. And we might have decided, in this case, a different conclusion, that the linear fit was not a good fit. So this is a way of saying, even in a random sampling, run multiple trials, because it lets you get statistics on those trials, as well as statistics within each trial. So with any trial, I'm doing a whole bunch of different random samples on measuring those values. And then, across those trials, I'm seeing what the deviation is. I'm going to hope my machine comes back, because what I want to do is then pull this together. What have we done? Something you're going to use. We've seen how you can use linear regression to fit a curve to data, 2D, 3D, 6D, however big the data set is. It gives us a mapping from the independent values to the dependent values. And that can then be used to predict values associated with the independent values that we haven't seen yet. That leads, naturally, to both a way to measure, which is r squared, but especially to see that we want to look at how well does that model actually predict new data, because that lets us select the simplest model we can that accounts for the data, but predicts new data in an effective way. And that complexity can either be based on theory, in the case of Hooke, or in more likely cases, by doing cross-validation to try and figure out which one is the simplest model that still does a good job of predicting out of data behavior. And with that, I'll see you next time.","68.9004135131836","7","DPRSearchEngine","fQvg-hh9dUw.en-qlPKC2UN_YU_21_mp4","fQvg-hh9dUw.en-qlPKC2UN_YU","6.0002","10"
"327","What are the two main methodologies for characterizing the believability of statistical results and how are they implemented?","The idea is to walk through a number of trials, number trials equal to the size of the data set. And for each one, take the data set or a copy of it, and drop out one of the samples. So leave one out. Start off by leaving out the first one, then leaving out the second one, and then leaving out the third one. For each one of those training sets, build the model. For example, by using linear regression. And then test that model on that data point that you left out. So leave out the first one, build a model on all of the other ones, and then see how well that model predicts the first one. Leave out the second one, build a model using all of them but the second one, see how well it predicts the second one. And just average the result. Works when you don't have a really large data set, because it won't take too long. But it's a nice way of actually testing validation. If the data set's a lot bigger, you can still use the same idea. You can use what's called, k-fold. Divide the data set up into k equal sized chunks. Leave one of them out. Use the rest to build the model. And then use that model to predict that first chunk you left out. Leave out the second chunk, and keep doing it. Same idea, but now with groups of things rather than just leaving those single data points. All right, the other way you can deal with it, which has a nice effect to it, is to use what's called, repeated random sampling. OK, start out with some data set. And what I'm going to do here is I'm","68.82757568359375","8","DPRSearchEngine","fQvg-hh9dUw.en-qlPKC2UN_YU_18_mp4","fQvg-hh9dUw.en-qlPKC2UN_YU","6.0002","10"
"327","What are the two main methodologies for characterizing the believability of statistical results and how are they implemented?"," 
 
 
 
 
Lecture: Sampling and 
Standard Error 
6.0002  LECTURE 8 
 
1
","68.75328063964844","9","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_1_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"327","What are the two main methodologies for characterizing the believability of statistical results and how are they implemented?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Logistic Regression 
Analogous to linear regression 
Designed explicitly for predicting probability of an event 
◦ Dependent variable can only take on a finite set of values  
◦ Usually 0 or 1 
Finds weights for each feature 
◦ Positive implies variable positively correlated with  
outcome  
◦ Negative implies variable negatively correlated with  
outcome  
◦ Absolute magnitude related to strength of the correlation  
Optimization problem a bit complex, key is use of a log
function—won’t make you look at it 
6.0002 LECTURE 13 
21 
","68.66358947753906","10","DPRSearchEngine","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13_21_pdf","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13","6.0002","13"
"329","How is the model built and optimized in the context of logistic regression, and what are the necessary inputs?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Monte Carlo Simulation  
A method of estimating the value of an unknown 
quantity using the principles of inferential statistics 
Inferential statistics 
◦ Population: a set of examples 
◦ Sample: a proper subset of a population 
◦ Key fact: a random sample tends to exhibit the same  
properties as the population from which it is drawn  
Exactly what we did with random walks 
6.0002 LECTURE 6 
4
","77.98333740234375","1","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_4_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"329","How is the model built and optimized in the context of logistic regression, and what are the necessary inputs?"," 
 
Looking at  Distributions 
def plotDistributions():  
uniform, normal, exp = [], [], []  
for i in range(100000):  
uniform.append(random.random())  
normal.append(random.gauss(0, 1))  
exp.append(random.expovariate(0.5))  
makeHist(uniform, 'Uniform', 'Value', 'Frequency')  
pylab.figure()  
makeHist(normal, 'Gaussian', 'Value', 'Frequency')  
pylab.figure()  
makeHist(exp, 'Exponential', 'Value', 'Frequency')  
6.0002  LECTURE 8 
 
27
","76.40608978271484","2","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_27_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"329","How is the model built and optimized in the context of logistic regression, and what are the necessary inputs?","!	!	 	
 
Let D be the original data set 
    n be the number of random samples  
 
 
 usually n between 20% and 50% 
    k be number of trials 
 
testResults = [] 
for i in range(k) 
    randomly select n elements for testSet,  
       keep rest for training 
    model = buildModel(training) 
    testResults.append(test(model, testSet)) 
 
Average testResults 

	

;G
","76.40260314941406","3","DPRSearchEngine","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10_38_pdf","aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10","6.0002","10"
"329","How is the model built and optimized in the context of logistic regression, and what are the necessary inputs?"," 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
Modeling the  World  
§Models  always  inaccurate
◦Provide abstractions of reality
§Deterministic models, e.g., graph theoretic
§Statistical models
◦Simulation models: Monte Carlo simulation
◦Models  based on sampling
◦Characterizing accuracy is critical
◦Central limit theorem
◦Empirical rule
◦Machine learning
◦Unsupervised and supervised
§Presentation of data
◦Plotting
◦Good and bad practices
6.0002  LECTURE 15 
21 
","75.44982147216797","4","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_18_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"329","How is the model built and optimized in the context of logistic regression, and what are the necessary inputs?","I'm going to look at a bunch of different sample sizes, from 25 to 600, 50 trials each. So getHighs is just a function that returns the temperatures. I'm going to get the standard deviation of the whole population, then the standard error of the means and the sample standard deviations, both. And then I'm just going to go through and run it. So for size and sample size, I'm going to append the standard error of the mean. And remember, that uses the population standard deviation and the size of the sample. So I'll compute all the SEMs. And then I'm going to compute all the actual standard deviations, as well. And then we'll produce a bunch of plots-- or a plot, actually. All right, so let's see what that plot looks like.","75.2792739868164","5","DPRSearchEngine","soZv_KKax3E.en-qlPKC2UN_YU_10_mp4","soZv_KKax3E.en-qlPKC2UN_YU","6.0002","8"
"329","How is the model built and optimized in the context of logistic regression, and what are the necessary inputs?"," 
 
 
Class LogisticRegression  
fit(sequence of feature vectors, sequence of labels) 
Returns object of type LogisticRegression 
coef_ 
Returns weights of features 
predict_proba(feature vector) 
Returns probabilities of labels 
6.0002 LECTURE 13 
22 
","75.21699523925781","6","DPRSearchEngine","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13_22_pdf","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13","6.0002","13"
"329","How is the model built and optimized in the context of logistic regression, and what are the necessary inputs?"," 
 
 
 
 
 
 
 
 
  
 
  
 
   
 
 
 
 
  
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Model Dependence 
Number of steps to decide ! = a#b# $ ≥0 depends on the model. 
• 1-tape TM: '() log )) 
• Multi-tape TM: '()) 
Computability theory: model independence (Church-Turing Thesis) 
Therefore model choice doesn’t matter. Mathematically nice. 
Complexity Theory: model dependence 
But dependence is low (polynomial) for reasonable deterministic models. 
We will focus on questions that do not depend on the model choice. 
So… we will continue to use the 1-tape TM as the basic model for complexity. 
6 
","74.93054962158203","7","DPRSearchEngine","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_6_pdf","7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12","18.404J","12"
"329","How is the model built and optimized in the context of logistic regression, and what are the necessary inputs?",";
/
def testGreedys(maxUnits):
print('Use greedy by value to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits, Food.getValue)
print('\\nUse greedy by cost to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits,
lambda x: 1/Food.getCost(x))
print('\\nUse greedy by density to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits, Food.density)
testGreedys(800)
	


4
","74.9015884399414","8","DPRSearchEngine","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_26_pdf","0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1","6.0002","1"
"329","How is the model built and optimized in the context of logistic regression, and what are the necessary inputs?"," 
 
 
 
 
 
 
 
 
Supervised Learning  
Regression 
◦ Predict a real number associated with a feature vector  
◦ E.g., use linear regression to fit a curve to data 
Classification 
◦ Predict a discrete value (label) associated with a feature 
vector 
6.0002 LECTURE 13 
3 
","74.02281188964844","9","DPRSearchEngine","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13_3_pdf","19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13","6.0002","13"
"329","How is the model built and optimized in the context of logistic regression, and what are the necessary inputs?"," 
 
 
  
 
 
 
    
 
 
    
 
        
 
        
 
 
    
 
        
 
 
 
 
        
 
 
 
              
 
    
 
 
 
  
 
 
 
 
    
 
 
        
 
 
 
Monte Carlo Simulation  
def playRoulette(game, numSpins, pocket, bet): 
totPocket = 0 
for i in range(numSpins): 
game.spin()  
totPocket += game.betPocket(pocket, bet)  
if toPrint: 
print(numSpins, 'spins of', game) 
print('Expected return betting', pocket, '=',\\ 
str(100*totPocket/numSpins) + '%\\n') 
return (totPocket/numSpins) 
game = FairRoulette() 
for numSpins in (100, 1000000): 
for i in range(3): 
playRoulette(game, numSpins, 2, 1, True) 
6.0002 LECTURE 6 
12
","73.98565673828125","10","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_12_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"333","What happens when you cherry pick hypotheses?","   
 
 
 
 
How  Likely Is it Just Bad Luck?  
A variant of cherry picking called  
multiple hypothesis testing 
6.0002  LECTURE 15 
14 
","71.42247772216797","1","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_13_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"333","What happens when you cherry pick hypotheses?"," 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
Gambler’s Fallacy  
ϮŎ August 18, 1913, at the casino in Monte Carlo, 
black came up a record twenty-six times in succession 
̐ϭ̆ ̜̍ͅϿή̪̪ή̑Ϩ ϩ ̐ϴϪή̜ή̑ ͑Β̠ Β ̆ήΒ̜-panicky rush to bet 
on red, beginning about the time black had come up a 
phenomenal fifteen ̪ϭ̅ή̠Ϩϯ -- Huff and Geis, How to 
Take a Chance 
Probability of 26 consecutive reds 
• 
1/67,108,865 
Probability of 26 consecutive reds when previous 25 
rolls were red 
• 
1/2 
6.0002 LECTURE 6 
15
","66.78761291503906","2","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_15_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"333","What happens when you cherry pick hypotheses?"," 
 
 
 
 
 
 
 
 
 
 
  
Other applications 
1. Computer viruses. 
2. A true but unprovable mathematical statement due to Kurt Gödel: 
“This statement is unprovable.” 
10 
","66.35073852539062","3","DPRSearchEngine","779043ea724131d008eae652d703938f_MIT18_404f20_lec11_10_pdf","779043ea724131d008eae652d703938f_MIT18_404f20_lec11","18.404J","11"
"333","What happens when you cherry pick hypotheses?"," 
 
 
   
 
 
 
   
   
      
 
 
 
 
 
 
  
 
Stochastic Processes  
An ongoing process where the next state might depend on 
both the previous states and some random element 
def rollDie(): 
"""""" returns an int between 1 and 6"""""" 
def rollDie(): 
"""""" returns a randomly chosen int 
between 1 and 6"""""" 
6.0002 LECTURE 4 
8
","66.10291290283203","4","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_8_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"333","What happens when you cherry pick hypotheses?","that grades into a quiz. And it's simply a question of solving this optimization problem.","65.14857482910156","5","DPRSearchEngine","uK5yvoXnkSk.en-qlPKC2UN_YU_16_mp4","uK5yvoXnkSk.en-qlPKC2UN_YU","6.0002","2"
"333","What happens when you cherry pick hypotheses?","A pretty small number. But the probability of 26 consecutive reds when the previous 25 rolls were red is what? No, that. AUDIENCE: Oh, I thought you meant it had been 26 times again. JOHN GUTTAG: No, if you had 25 reds and then you spun the wheel once more, the probability of it having 26 reds is now 0.5, because these are independent events. Unless of course the wheel is rigged, and we're assuming it's not. People have a hard time accepting this, and I know it seems funny. But I guarantee there will be some point in the next month or so when you will find yourself thinking this way, that something has to even out. I did so badly on the midterm, I will have to do better on the final. That was mean, I'm sorry. All right, speaking of means-- see? Professor Grimson not the only one who can make bad jokes. There is something-- it's not the gambler's fallacy-- that's often confused with it, and that's called regression to the mean. This term was coined in 1885 by Francis Galton in a paper, of which I've shown you a page from it here.","64.46173858642578","6","DPRSearchEngine","OgO1gpXSUzU.en-j3PyPqV-e1s_8_mp4","OgO1gpXSUzU.en-j3PyPqV-e1s","6.0002","6"
"333","What happens when you cherry pick hypotheses?"," 
 
 
  
 
 
 
    
 
 
    
 
        
 
        
 
 
    
 
        
 
 
 
 
        
 
 
 
              
 
    
 
 
 
  
 
 
 
 
    
 
 
        
 
 
 
Monte Carlo Simulation  
def playRoulette(game, numSpins, pocket, bet): 
totPocket = 0 
for i in range(numSpins): 
game.spin()  
totPocket += game.betPocket(pocket, bet)  
if toPrint: 
print(numSpins, 'spins of', game) 
print('Expected return betting', pocket, '=',\\ 
str(100*totPocket/numSpins) + '%\\n') 
return (totPocket/numSpins) 
game = FairRoulette() 
for numSpins in (100, 1000000): 
for i in range(3): 
playRoulette(game, numSpins, 2, 1, True) 
6.0002 LECTURE 6 
12
","64.43919372558594","7","DPRSearchEngine","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_12_pdf","5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6","6.0002","6"
"333","What happens when you cherry pick hypotheses?"," 
 
 
 
 
Stochastic  Thinking  
§The world is (predictably) non-deterministic
§Thinking in terms of probabilities is often useful
§Randomness is a powerful tool for building
computations that model the world 
§Random computations useful even when for problems
that do not involve randomness 
◦E.g.,  integration
6.0002  LECTURE 15 
20 
","64.31876373291016","8","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_17_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"333","What happens when you cherry pick hypotheses?","Arithmetization Method
Method:  Simulate ∧and ∨with + and ×.
%&
0 1
'
' (1 −%&)
' %&
' ,
' -
' .
' , + ' - + ' .
%,
%-
%-
0 1
0
1
%.
%.
0
1
0
1
0
1
0
1
Replace Boolean labeling with arithmetical labeling
Inductive rules:
Start node labeled 1
' ∧/ →' ×/ = '/
'
→
1 −'
' ∨/ →' + / −'/
Simulate ∨with + because the BP is acyclic.
The execution path can enter a node 
at most one time. 
' ∧%&
' ∧%&
' , ∨' - ∨' .
5
","64.23054504394531","9","DPRSearchEngine","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_5_pdf","cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24","18.404J","24"
"333","What happens when you cherry pick hypotheses?"," 
 
 
 
 
 
 
 
 
 
  
 
Simulation Models
A description of computations that provide useful
information about the possible behaviors of the system
being modeled
Descriptive, not prescriptive
Only an approximation to reality
“All models are wrong, but some are useful.” – George Box
6.0002 LECTURE 4 
24
","64.14108276367188","10","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_24_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"335","What are some of the reasons random walks are considered significant in various fields?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Why Random Walks?
Random walks are important in many
domains
◦Understanding the stock market (maybe)
◦Modeling diffusion processes
◦Etc.
Good illustration of how to use
simulations to understand things
Excuse to cover some important
programming topics
◦Practice with classes
◦More about plotting
6.0002 LECTURE 4 
26
","74.25130462646484","1","DPRSearchEngine","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_26_pdf","5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4","6.0002","4"
"335","What are some of the reasons random walks are considered significant in various fields?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
Why Random Walks?  
§Random walks are important in many
domains
◦Understanding the stock market (maybe)
◦Modeling diffusion processes
◦Etc.
§Good illustration of how to use
simulations  to understand things
§Excuse to cover some important
programming topics
◦Practice with classes
◦Practice with plotting
6.0002  LECTURE 5 
3 
","74.02428436279297","2","DPRSearchEngine","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_3_pdf","508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5","6.0002","5"
"335","What are some of the reasons random walks are considered significant in various fields?","And it does give me an excuse to cover some important topics related to programming. You'll remember that one of the subtexts of the course is while I'm covering a lot of what you might think of as abstract material, we're using it as an excuse to teach more about programming and software engineering. A little practice with classes and subclassing, and we're going to also look at producing plots. So the first random walk I want to look at is actually not a diffusion process or the stock market, but an actual walk. So imagine that you've got a field which has somehow","72.45503234863281","3","DPRSearchEngine","6wUD_gp5WeE.en-qlPKC2UN_YU_2_mp4","6wUD_gp5WeE.en-qlPKC2UN_YU","6.0002","5"
"335","What are some of the reasons random walks are considered significant in various fields?","The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. JOHN GUTTAG: Today we're starting a new topic, which is, of course, related to previous topics. As usual, if you go to either the 60002 or the 600 web site, you'll find both today's PowerPoint and today's Python. You'll discover if you look at the Python file that there is quite a lot of code in there. And I'll be talking only about some of it. But it's probably all worth looking at. And a fair amount of reading associated with this week. Why are we looking at random walks? See a picture here of, think of them as molecules just bouncing around. This is actually a picture of what's called Brownian motion, though Robert Brown probably did not discover it. We're looking at random walks because, well, first of all, they're important in many domains. There are people who will argue, for example, that the movement of prices in the stock market is best modeled as a random walk. There was a very popular book called A Random Walk Down Wall Street that made this argument. And a lot of modern portfolio analysis is based upon that. Those of you who are not interested in making money, and I presume that's most of you, it's also very important in many physical processes. We use random walks, say, to model diffusion, heat diffusion, or the diffusion of molecules in suspension, et cetera. So they're very important in a lot of scientific, and indeed, social disciplines. They're not the only important thing, so why are we looking at those? Because I think it provides a really good illustration","71.2163314819336","4","DPRSearchEngine","6wUD_gp5WeE.en-qlPKC2UN_YU_1_mp4","6wUD_gp5WeE.en-qlPKC2UN_YU","6.0002","5"
"335","What are some of the reasons random walks are considered significant in various fields?","   
 
 
 
 
How  Likely Is it Just Bad Luck?  
A variant of cherry picking called  
multiple hypothesis testing 
6.0002  LECTURE 15 
14 
","70.32780456542969","5","DPRSearchEngine","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_13_pdf","77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15","6.0002","15"
"335","What are some of the reasons random walks are considered significant in various fields?","almost the same, except the choices are slightly different. If he chooses to head north, he doesn't go one step. He goes 1.1 steps north. And if he chooses to go south, he only goes 9/10 of a step. So what we're seeing here is what's called a biased random walk. And the bias here is the direction of the walk that he's moving either up or down. Pretty simple. How about just for to test things out, we'll ask the question is this an immutable or a mutable type? Are drunks mutable or immutable? This is a deep philosophical question. But if we ignore the philosophical underpinnings of that question, what about the two types here? Who thinks it's immutable? Who thinks it's mutable? Why do you think it's mutable? What's getting changed? The answer is nothing. It gets created, and then it's returning the step, but it's not actually changing the drunk. So so far we have two things that are immutable, drunks and locations. Let's look at fields. Fields are a little bit more complicated. So field will be a dictionary, and the dictionary is going to map a drunk to his or her location in the field. So we can add a drunk at some location, and we're going to check.","70.10792541503906","6","DPRSearchEngine","6wUD_gp5WeE.en-qlPKC2UN_YU_8_mp4","6wUD_gp5WeE.en-qlPKC2UN_YU","6.0002","5"
"335","What are some of the reasons random walks are considered significant in various fields?","random.choice. It takes as an argument a sequence, in this case a list, and randomly chooses one member of the list. And it chooses it uniformly. It's a uniform distribution. And what that means is that it's equally probable that it will choose any number in that list each time you call it. We'll later look at distributions that are not uniform, not equally probable, where things are weighted. But here, it's quite simple, it's just uniform. And then we can test it using testRoll-- take some number of n and rolls the die that many times and creates a string telling us what we got. So let's consider running this on, say, testRoll of five. And we'll ask the question, if we run it, how probable is it that it's going to return a string of five 1's? How do we do that? Now, how many people here are either in 6.041 or would have taken 6.041? Raise your hand. Oh, good. So very few of you know probability. That helps. So how do we think about that question? Well, probability, to me at least, is all about counting, especially discrete probability, which is what we're looking at here. What you do is you start by counting the number of events that have the property of interest and the number of possible events and divide one by the other. So if we think about rolling a die five times, we can enumerate all of the possible outcomes of five rolls. So if we look at that, what are the outcomes? Well, I could get five 1's. I could get four 1's and a 2 or four 1's and 3, skip a few. The next one would be three 1's, a 2 and a 1, then a 2 and 2, and finally, at the end, all 6's. So remember, we looked before at when we're looking at optimization problems about binary numbers. And we said we can look at all the possible choices of items in the knapsack by a vector of 0's and 1's. We said, how many possible choices are there? Well, it depended on how many binary numbers you could get in that number of digits. Well, here we're doing the same thing, but instead of base 2, it's base 6. And so the number of possible outcomes of five rolls is quite high. How many of those are five 1's? Only one of them, right? So in order to get the probability of a five 1's, I divide 1 by 6 to the fifth. Does that makes sense to everybody? So in fact, we see it's highly unlikely. The probability of a five 1's is quite small. Now, suppose we were to ask about the probability of something else-- instead of five 1's, say 53421. It kind of looks more likely than that than five 1's in a row, but of course, it isn't, right? Any specific combination is equally probable. And there are a lot of them. So this is all the probability we're going to think about we could think about this way, as simply a matter of counting-- the number of possible events, the number of events that have the property of interest-- in this case being all 1's-- and then simple division. Given that framework, there were three basic facts about probability we're going to be using a lot of. So one, probabilities always range from 0 to 1. How do we know that? Well, we've got a fraction, right? And the denominator is all possible events. The numerator is the subset of that that's of interest. So it has to range from 0 to the denominator. And that tells us that the fraction has to range from 0 to 1. So 1 says it's always going to happen, 0 never. So if the probability of an event occurring is p, what's the probability of it not occurring? This follows from the first bullet. It's simply going to be 1 minus p. This is a trick that we'll find we'll use a lot. Because it's often the case when you want to compute the probability of something happening, it's easier to compute the probability of it not happening and subtract it from 1. And we'll see an example of that later today. Now, here's the biggie. When events are independent of each other, the probability of all of the events occurring is equal to the product of the probabilities of each of the events occurring. So if the probability of A is 0.5 and the probability of B","69.7170639038086","7","DPRSearchEngine","-1BnXEwHUok.en-qlPKC2UN_YU_4_mp4","-1BnXEwHUok.en-qlPKC2UN_YU","6.0002","4"
"335","What are some of the reasons random walks are considered significant in various fields?","And second, that the distribution of errors will be normally distributed. I didn't probably mention at the time, but we often call this distribution Gaussian after the astronomer Carl Gauss. And it looks like that. Normal distributions are very easy to generate in Python. I have a little example here of generating, not a real normal distribution, but a discrete approximation of one. And the thing to really notice about it here is this line random.gauss. So that's a built in function of the random library. The first argument is the mean. And the second argument is the standard deviation or a mu and sigma as they're usually called. Every time I call that, I will get a different-- or usually a different random value drawn from a Gaussian with the mean, in this case of 0 and a standard deviation of 100. I'm then going to produce a plot of those so you can see what it looks like. And I'm going to do that using some things we haven't seen before. So first of all, we've seen histograms.","69.6649169921875","8","DPRSearchEngine","rUxP7TM8-wo.en-qlPKC2UN_YU_2_mp4","rUxP7TM8-wo.en-qlPKC2UN_YU","6.0002","7"
"335","What are some of the reasons random walks are considered significant in various fields?"," 
 
Looking at  Distributions 
def plotDistributions():  
uniform, normal, exp = [], [], []  
for i in range(100000):  
uniform.append(random.random())  
normal.append(random.gauss(0, 1))  
exp.append(random.expovariate(0.5))  
makeHist(uniform, 'Uniform', 'Value', 'Frequency')  
pylab.figure()  
makeHist(normal, 'Gaussian', 'Value', 'Frequency')  
pylab.figure()  
makeHist(exp, 'Exponential', 'Value', 'Frequency')  
6.0002  LECTURE 8 
 
27
","69.60151672363281","9","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_27_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"
"335","What are some of the reasons random walks are considered significant in various fields?"," 
 
Three Different Distributions  
random.random() 
random.gauss(0, 1) 
6.0002  LECTURE 8 
 
random.expovariate(0.5) 
28
","69.26705932617188","10","DPRSearchEngine","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_28_pdf","02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8","6.0002","8"

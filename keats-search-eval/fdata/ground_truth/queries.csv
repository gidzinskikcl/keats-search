index,question,content,answer,label,difficulty,course_name,lecture_title,doc_id
23,What are the three elements that need to be present to compose an injection vector?," 
 
 
 
 
 
 
 
 
 
 
  
 
 
MIT OpenCourseWare 
https://ocw.mit.edu 
18.404J / 18.4041J / 6.840J Theory of Computation 
Fall 2020 
For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms. 
","An injection vector is composed of a NOP sled, shellcode, and shellcode address.",empty,Basic,18.404J,Lecture 7 - Decision Problems for Automata and Grammars,78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_12_pdf
50,What is the goal of a code injection attack?,So here is the proof sketch for--,To hijack the execution of the target application/program toward some code injected by the attacker.,empty,Basic,18.404J,5 CF Pumping Lemma Turing Machines,IycOPFmEQk8.en-j3PyPqV-e1s_6_mp4
51,What is the purpose of the goal of code injection?,"MIT OpenCourseWare
https://ocw.mit.edu
18.404J / 18.4041J / 6.840J Theory of Computation
Fall 2020
For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
",To hijack the execution of the target application/program toward some code injected by the attacker.,empty,Basic,18.404J,Lecture 24 - Probabilistic Computation (cont.),cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_12_pdf
66,What is the goal of a code injection attack?," 
 
 
 
 
 
 
 
 
 
 
  
 
 
MIT OpenCourseWare 
https://ocw.mit.edu 
18.404J / 18.4041J / 6.840J Theory of Computation 
Fall 2020 
For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms. 
",To hijack the execution of the target application/program toward some code injected by the attacker.,empty,Basic,18.404J,"Lecture 19 - Games, Generalized Geography",fd9c1b8656c7def498dcf662f6750d87_MIT18_404f20_lec19_10_pdf
230,What is the role of a NOP sled in a code injection attack?," -""'""#%#/5&',%
 1*)LM>M
Q>KKKMN
M
","A NOP sled is a sequence of do-nothing instructions (NOP). It is used to ease the exploitation, such that the attacker can jump anywhere inside and will eventually reach the shellcode to execute it.",empty,Intermediate,6.2002,Lecture 3: Graph-theoretic Models,69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_2_pdf
231,What does the goal of a code injection attack involve in terms of target application execution?," 
Output  
6.0002  LECTURE 14 
9 
",To hijack the execution of the target application/program toward some code injected by the attacker.,empty,Advanced,6.2002,Lecture 14: Classification and Statistical Sins,b9d60f4ecb325e4648f9cf0379419338_MIT6_0002F16_lec14_9_pdf
232,What is the goal of a code injection attack?," 
Lecture  12:  Clustering  
6.0002  LECTURE 12 
1 
",To hijack the execution of the target application/program toward some code injected by the attacker.,empty,Basic,6.2002,Lecture 12: Clustering,367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_1_pdf
233,How does altering a code pointer contribute to the success of a code injection attack?," 6574
 4576=
 45>$=
(

 $
	

6

","Altering a code pointer inside the virtual address of the process, such as the return address, hijacks the execution flow. The return address is changed to point to the address of the writable memory region that contains the shellcode, thus enabling the execution of the injected malicious code.",empty,Advanced,6.2002,Lecture 9: Understanding Experimental Data,20a7e184a1a2b3c34a5055dc1f1dc066_MIT6_0002F16_lec9_6_pdf
235,What is the purpose of code injection?,"!
 
	

0
",To hijack the execution of the target application/program toward some code injected by the attacker.,empty,Intermediate,6.2002,Lecture 9: Understanding Experimental Data,20a7e184a1a2b3c34a5055dc1f1dc066_MIT6_0002F16_lec9_20_pdf
237,What are the three components that compose an injection vector in a code injection attack?,"*)
&!	 '
	


","An injection vector is composed of a NOP sled, shellcode, and shellcode address.",empty,Intermediate,6.2002,Lecture 10: Understanding Experimental Data (cont.),aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10_6_pdf
240,What is the goal of a code injection attack?,"%/$ 
	

QJ
",To hijack the execution of the target application/program toward some code injected by the attacker.,empty,Basic,6.2002,Lecture 11: Introduction to Machine Learning,4c4fc506075a8502ccc5191583d22882_MIT6_0002F16_lec11_19_pdf
242,What is the goal of code injection?,"(
	$
 
	

G
",To hijack the execution of the target application/program toward some code injected by the attacker.,empty,Basic,6.2002,Lecture 10: Understanding Experimental Data (cont.),aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10_8_pdf
246,What is the goal of a code injection attack?," &&	%$$(!0(#""%# !
 #*.0/0,0#.*()L0*)M
W #*.0/0/-3)*""//3#0#0
W *3.)**./0""$/)L
W /1)1*)*'/0""$/)M
W *.""/<L)M<$)0#/-3)<$M*''*5/L$)0#
/-3)<0#/*3.*M$/0#/1)1*)*L
 #*.0/05$""#0,0#
W $)$($80#/3(*0#5$""#0/*0#""/$)0#,0#
Q>KKKMN
ML
",To hijack the execution of the target application/program toward some code injected by the attacker.,empty,Basic,6.2002,Lecture 3: Graph-theoretic Models,69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_21_pdf
250,What is the primary goal of a code injection attack?,")%%%$
""
!1%%)$""$
""
%%""
+%%$""""%)
""%%""
&(""""!
""+%)""%
87	&

	

'
",To hijack the execution of the target application/program toward some code injected by the attacker.,empty,Intermediate,6.2002,Lecture 1: Introduction and Optimization Problems,0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_15_pdf
252,What is the main goal of a code injection attack?,"	%$6'#%(# &
%	%!&#""

$%'!""' '% """"%""""
#!$,'%""
Q>KKKMN
L
",To hijack the execution of the target application/program toward some code injected by the attacker.,empty,Intermediate,6.2002,Lecture 3: Graph-theoretic Models,69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_1_pdf
258,What is the basic goal of code injection?," 
 
Iteration 4  
6.0002  LECTURE 12 
16 
",The goal of code injection is to hijack the execution of the target application/program toward some code injected by the attacker.,empty,Intermediate,6.2002,Lecture 12: Clustering,367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_16_pdf
259,What is the process of code injection using an injection vector?,"$+	
	
	
)$*!
)+,+-..
,
$%,.,(/(
.(,,
&%,..'0'+
('-.-
# $%&'
	

1
","1. Inject the code to be executed (shellcode) into a writable memory region (stack, data, heap, etc.). 2. Alter a code pointer inside the VA (virtual address) of the process (eg, return address) to hijack the execution flow. The return address will be the address of the writable memory region that contains the shellcode. An injection vector is composed of three elements: NOP sled (optional), shellcode, and shellcode address.",empty,Advanced,6.2002,Lecture 7: Confidence Intervals,3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7_5_pdf
261,"What is the main goal of code injection, and how does it differ from overwriting a return address?"," L0&'-'(&
&)*&&
 @*(&'2
(')&
-'""5
! 
)*-'''
7):""
! 
..&&-'
('*M7):(&
-'&'(
	&$% 
	










6.0002 LECTURE 11 
Slide 3 
	 -'
& 
","The goal of code injection is to hijack the execution of the target application/program toward some code injected by the attacker. Unlike overwriting the return address of a function, which may result in the termination of the process by returning a segmentation fault, code injection involves injecting malicious code (shellcode) into a writable memory region to be executed by the process.",empty,Advanced,6.2002,Lecture 11: Introduction to Machine Learning,4c4fc506075a8502ccc5191583d22882_MIT6_0002F16_lec11_34_pdf
262,What is the goal of code injection?,"   
 
 
 
How  Likely Is it Just Bad Luck?  
6.0002  LECTURE 15 
13 
",To hijack the execution of the target application/program toward some code injected by the attacker.,empty,Basic,6.2002,Lecture 15: Statistical Sins and Wrap Up,77d2977095e184f22da9bb75faf39535_MIT6_0002F16_lec15_12_pdf
271,What are the components required for a successful code injection attack?," 
  !
""#$% %&'(
 ) ""*%+#!&
## + #* 
%&$
 ,$&$#""(+ # +
!% *
- ./#!*%+#+
$
!""	 
	


","To inject code, three elements (NOP sled, shellcode, and shellcode address) need to be present, which compose an injection vector.",empty,Intermediate,6.2002,Lecture 10: Understanding Experimental Data (cont.),aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10_2_pdf
273,What is the purpose of altering a code pointer during a code injection attack?,"
-0
7 )%>%--00%+
%%%'+.
7 )%>'.
7 *%'.
7 A'++*
K+-
-(:
	

""1
","Altering a code pointer inside the VA (virtual address) of the process (eg, return address) hijacks the execution flow.",empty,Intermediate,6.2002,Lecture 7: Confidence Intervals,3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7_34_pdf
277,Explain the purpose of a NOP sled in a code injection attack.,"!+ 
	

S
","A NOP sled is a sequence of do-nothing instructions (NOP). It is used to ease the exploitation, such that the attacker can jump anywhere inside and will eventually reach the shellcode to execute it.",empty,Basic,6.2002,Lecture 11: Introduction to Machine Learning,4c4fc506075a8502ccc5191583d22882_MIT6_0002F16_lec11_15_pdf
278,What is the purpose of injecting code in a code injection attack?,""".!$ 
Q>KKKMN
MT
*/0*)
*/0*)
.*4$)
.*4$)
5*.&
5*.&
#$""*
#$""*
)4.
)4.
#*)$6
#*)$6
*/)""'/
*/)""'/
%)7$/0
*/0*)=.*4$)<5*.&
.*4$)=*/0*)<5*.&
5*.&=#$""*
#$""*=)4.<#*)$6
)4.=#*)$6<5*.&
*/)""'/=*/0*)
#*)$6=
",To hijack the execution of the target application/program toward some code injected by the attacker.,empty,Intermediate,6.2002,Lecture 3: Graph-theoretic Models,69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_29_pdf
301,"What is an injection vector, and what are its components?","
!$ !""("""",&""%$&
 3$'$)"""".,#/
W */
W ""/
W 10#$)""0*""0#.0*(&"".,#/
 /$)"""".,#/
W .#$)""*.,0#/05))*/
W .#$)""*.*,1(',0#/05))*/
Q>KKKMN
LO
","An injection vector is composed of three elements: 1. NOP sled (optional): a sequence of do-nothing instructions (NOP). It is used to ease the exploitation, such that the attacker can jump anywhere inside and will eventually reach the shellcode to execute it. 2. Shellcode: a sequence of machine instructions executed as a result of a code injection attack. Typically, a shellcode executes a shell (eg, execve(""/bin/sh"")). The shellcode is injected by the attacker into a writable and executable memory region. The address of the writable memory region is called the shellcode address. 3. Shellcode address: The address of the memory region that contains the shellcode.",empty,Advanced,6.2002,Lecture 3: Graph-theoretic Models,69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_14_pdf
304,What is a key component of a code injection attack used to ease exploitation?,"""!1

"",,""%
""$""
/+11$%""
1""$
+%%""%$""+

/+11$%""
1)""""
,*$1 ,
*$1 ,
#5*3	-67

	

&
","A NOP sled is a key component, which is a sequence of do-nothing instructions (NOP). It is used to ease the exploitation, such that the attacker can jump anywhere inside and will eventually reach the shellcode to execute it.",empty,Intermediate,6.2002,Lecture 1: Introduction and Optimization Problems,0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_13_pdf
309,What is the anatomy of a code injection attack?,"3..)0,0#=*/0*)
3..)0,0#=*/0*)CV.*4$)
3..)0,0#=*/0*)CV5*.&
3..)0,0#=*/0*)CV.*4$)CV5*.&
3..)0,0#=*/0*)CV5*.&CV#$""*
3..)0,0#=*/0*)CV.*4$)CV5*.&CV#$""*
3..)0,0#=*/0*)CV5*.&CV#$""*CV)4.
3..)0,0#=*/0*)CV5*.&CV#$""*CV#*)$6
#*.0/0,0#.*(*/0*)0*#*)$6$/*/0*)CV5*.&CV#$""*CV#*)$6
*/0*)
*/0*)
.*4$)
.*4$)
5*.&
5*.&
#$""*
#$""*
)4.
)4.
#*)$6
#*)$6
*/)""'/
*/)""'/
,'$,'7#&'#""'##"".8
Q>KKKMN
NP
*00#05
/&$,,0#
0#0.4$/$0/
)*
",To hijack the execution of the target application/program toward some code injected by the attacker. An attacker injects a malicious code (shellcode) into a writable memory region.,empty,Basic,6.2002,Lecture 3: Graph-theoretic Models,69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_35_pdf
314,Goal of code injection,"	=	
!(
 9
	

32
",To hijack the execution of the target application/program toward some code injected by the attacker.,empty,Basic,6.2002,Lecture 9: Understanding Experimental Data,20a7e184a1a2b3c34a5055dc1f1dc066_MIT6_0002F16_lec9_32_pdf
320,What are the essential steps for a successful code injection attack?," #1&$ ( ##+
#*
 .+! &11 #&$
 .+( (! ""1+#&$
11(&$
 3+-	#	 
) ,
	

;
","Inject the code to be executed (shellcode) into a writable memory region (stack, data, heap, etc.), and alter a code pointer inside the VA (virtual address) of the process (eg, return address) to hijack the execution flow. The return address will be the address of the writable memory region that contains the shellcode.",empty,Intermediate,6.2002,Lecture 10: Understanding Experimental Data (cont.),aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10_36_pdf
323,What is the role of a code pointer in a code injection attack?,"-4
%%
# /+11$%""
1)""""
,*$1 ,*$1
,
-!%$$+%) ""+4
# /!$$!)

 
(%1$""""$1""
$64
# 191'11:1;1212;19&1'1&9
9	
	
	

	


","To alter a code pointer inside the VA (virtual address) of the process (eg, return address) to hijack the execution flow.",empty,Intermediate,6.2002,Lecture 1: Introduction and Optimization Problems,0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_16_pdf
324,What is a code injection attack?,"$'%&'%
 0.00)$)$1')*
 *)/$.''0#""/0#0'40#0)*<$)/*(
*..
 *''*50#./0""<)#&0*/$0""*')*
 
)*0<.,00#,.*//.*()5)*
 *)1)33)1'$0#.)""*')*<*..3)*30*
*,1*)/
W #).3)*30**,1*)/<&0.&0*0#,.4$*3/)*
)0.70#)60""<.,1)""0#$/,.*//
Q>KKKMN
MQ
",A code injection attack involves hijacking the execution of the target application/program toward some code injected by the attacker.,empty,Basic,6.2002,Lecture 3: Graph-theoretic Models,69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_26_pdf
325,What is the purpose of injecting a NOP sled along with shellcode during a code injection attack?,"		&$% 
	









6.0002 LECTURE 11 
Slide 3 
Images of rattlesnake, dart frog, boa constrictor © sources unknown. All rights reserved. This content is excluded
from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.
","A NOP sled is a sequence of do-nothing instructions (NOP) used to ease the exploitation of a code injection attack, such that the attacker can jump anywhere inside it and will eventually reach the shellcode to execute it.",empty,Advanced,6.2002,Lecture 11: Introduction to Machine Learning,4c4fc506075a8502ccc5191583d22882_MIT6_0002F16_lec11_36_pdf
326,What is the goal of a code injection attack?,"	5 6
6.0002 LECTURE 11 
Slide 5 
",To hijack the execution of the target application/program toward some code injected by the attacker.,empty,Intermediate,6.2002,Lecture 11: Introduction to Machine Learning,4c4fc506075a8502ccc5191583d22882_MIT6_0002F16_lec11_50_pdf
328,What are the steps for code injection?,"



 !

	


","1. Inject the code to be executed (shellcode) into a writable memory region (stack, data, heap, etc.). 2. Alter a code pointer inside the VA (virtual address) of the process (eg, return address) to hijack the execution flow. The return address will be the address of the writable memory region that contains the shellcode.",empty,Advanced,6.2002,Lecture 7: Confidence Intervals,3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7_2_pdf
332,"What are the components needed for a code injection to be successful, and what role does each component play in the process?","$
 .,#/.**'
W /0570*.0(*'*()70#$)""/
W ,03..'1*)/#$,/(*)""*%0/
W )7$(,*.0)0,.*'(/),*//"".,#
*,1($81*),.*'(/5'.7&)*5#*50*/*'4
 ,0#C./0).0#C./0/.#.$(,*.0)0
'""*.$0#(/
W )3/0*/*'4()7,.*'(/
Q>KKKMN
NR
","To inject code, three elements (NOP sled, shellcode, and shellcode address) need to be present, which compose an injection vector. 1. NOP sled (optional): a sequence of do-nothing instructions (NOP). It is used to ease the exploitation, such that the attacker can jump anywhere inside and will eventually reach the shellcode to execute it. 2. Shellcode: a sequence of machine instructions executed as a result of a code injection attack. Typically, a shellcode executes a shell (eg, execve(“/bin/sh”)). The shellcode is injected by the attacker into a writable and executable memory region. The address of the writable memory region is called the shellcode address. 3. Shellcode address: The address of the memory region that contains the shellcode.",empty,Advanced,6.2002,Lecture 3: Graph-theoretic Models,69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_37_pdf
1,What is a log space transducer?,"OK. So we think of a log space transducer as computing a function, which is just a mapping from the input to the output that the transducer provides for you. A transducer is a deterministic machine, by the way. So you take the transducer. You give it w. And you turn it on. And then it halts with f of w on its output tape. That's what it means to be computing the function f, OK? And we'll say that A is log space reducible to B, using the l subscript symbol on the less than or equal to sign, if it's mapping reducible to B, but by a reduction function that's computable in log space, just the same way we define polynomial time reducibility. But there, we insisted that the reduction function was computable in polynomial time. OK. Just quickly, I got a question again. Why log space here? Because polynomial time would be too powerful for doing reductions internal to P. Every language in P is reducible to every other language in P. And so everything in NL would be reducible to everything else in L with a polynomial time reducibility. And so that would not be an interesting notion. We have to use a weaker notion than that, a weaker kind of reduction, using a weaker model, so that you don't get-- otherwise, the reduction function would be able to answer whether-- would be able to solve the problem A itself if we had a polynomial time reduction, and we're mapping things from NL to other problems in NL. The reduction would solve the problem. And that's not what you want. The reduction should be constrained only to be able to do simple transformations on the problem, not to solve the problem. Anyway, you have to look at that. This is an issue that's come up before when we talked about, what's the right notion of reduction to use for PSPACE completeness? Same exact discussion.","A log space transducer is a deterministic machine that computes a function by mapping an input to an output, with the computation being performed using logarithmic space.",valid,Basic,18.404J,20 L and NL NL  coNL,q3xvno_KgRY.en-j3PyPqV-e1s_6_mp4
2,What does it imply about two low-degree polynomials if they agree on more than d places?,"And other very important thing-- if I have two polynomials that are both low-degree, they cannot agree on very many places. That follows from what I just proved above. Because what I'll do is I take those two polynomials, and they look at the difference, which is also a low-degree polynomial. Every time there's an agreement between those two original polynomials, there's a zero of the difference polynomial. And because that difference polynomial cannot have too many zeroes, the two original polynomials cannot have too many agreements. So the corollary is that if x and y are both polynomials of degree at most d, and they're not the same polynomial, because then the difference would be the 0 polynomial, then the number of places where they're equal is at most d. So the proof is just letting p be","If two low-degree polynomials agree on more than d places, it implies that they are actually the same polynomial. This follows because the difference between the two polynomials would have more zeroes than its degree, which is not possible unless the difference is the zero polynomial, indicating the polynomials are identical.",valid,Advanced,18.404J,24 Probabilistic Computation cont,7J1HD9rqEB4.en-j3PyPqV-e1s_5_mp4
3,Why is prior experience with mathematical theorems and proofs important for this course?,"Talk about the expectations of the course. First of all, prerequisites. There are a bunch of prerequisites listed, 6.042, 18.062 , or maybe some other subject as well. The real thing is that this is a math class. This is a class where-- and it's not a beginning math class, this is a moderate-to-advanced math class. And I'm expecting people to have had some prior experience, of a substantial nature, with mathematical theorems and proofs. We'll start off slow, but we're going to ramp up pretty fast. So if you haven't really got the idea or gotten comfortable with doing proofs, coming up with proofs to mathematical statements, that's going to be a concern. I would just be monitoring yourself and seeing how you're doing. Because the homeworks and the exams are going to count on your being able to produce proofs, and so you're going to be struggling if that's going to be a real-- something that you haven't had experience with. And let me talk a little bit about the role of theory in computer science. This is a theory class, as you know. So before we jump into the material, I just thought it would be worth it for you to give you at least my perspective on the role of theoretical computer science within the field. So I've been in computer science for a long time. I go back-- I'm sure I'm getting to be a dinosaur here-- but I go back to the days when you had punch cards. That's what we did when I was an undergraduate. And, obviously, things are very different now. And you can argue that computer science as a discipline has matured, and sort of the basic stuff has all been solved. Well, I would say there's a certain truth to that, but there's a certain way in which I would say that's not true. I think we're still at the very beginning, at least in certain respects, of computer science as a discipline. For one thing, there are a lot of things that we do, a lot of things relating to computation, that we just don't know the answer to-- very fundamental things. Let's take as an example, how does the brain work? Obviously, the brain computes in a certain fashion. And we've made good progress, you can argue, with machine learning and all of those things that have very-- very powerful and doing very cool things. But I would also say that at some deeper level, the methods that we have so far don't allow us to understand creativity. We're not close to being able to create a computer program that can do mathematics or that can do many of the creative kinds of things that human beings can do. I think machine learning, powerful as it is, is really successful only for a very narrow set of tasks. And so I think there's probably something deeper and more fundamental going on that we're missing. That would be my hunch. Now, whether something like theoretical computer science is going to give you an answer there-- or this kind of theory, or some kind of theory-- I think some kind of theory has at least a decent shot at playing a role in helping us to understand computation in a deeper way. And the fact that we can't understand something as basic as, can you factor a big number quickly or not? You can't really say you understand computation until you can answer questions like that. So I would argue that we have a really very primitive understanding of computation at this stage and that there is a lot that has yet to be discovered, not just on the technological side, but just on the very fundamental theoretical side that has a real shot at playing a role in affecting the practice of how we use computers. And so I think for that reason-- again, I'm not sure what kind of theory is going to be the most useful, but the theory we're going to cover in this course is a particularly elegant theory, and it has already paid off in many applications and in terms of our understanding of computation. And I think, at least as a starting point, it's a good subject to learn. Certainly, I enjoy it, and I've spent a good chunk of my career doing that.","The homeworks and the exams are going to count on your being able to produce proofs, and you're going to be struggling if you haven't had experience with doing proofs, coming up with proofs to mathematical statements.",administrative,Intermediate,18.404J,1 Introduction Finite Automata Regular Expressions,9syvZr-9xwk.en-j3PyPqV-e1s_3_mp4
4,How can the students in the interactive proof system protocol convince the professor that two graphs are not isomorphic without revealing an isomorphism?,okay so in in interactive proofs there are two parties um and i'm going to think about them as one of them is going to be the professor okay so the professor is going to play the role of the verifier in a sense but it's like that the one who checks um and uh the professor being kind of old and tired he's been teaching too long maybe can only operate in probabilistic polynomial time so the professor if wants to tell whether two graphs are isomorphic or not probabilistic polynomial time doesn't seem to be enough to tell whether two graphs are isomorphic or not because it seems to be a more than polynomial problem however the professor has um help it has an army of graduate students and the graduate students they're not limited uh in the same way the professor is the graduate students are young they are energetic they can stay up all night they know how to code so the graduate students have unlimited computational ability so that we're going to think of the graduate students playing the role of the approver because they're not they're not limited in their capabilities we'll assume the professor on the other hand is limited so the professor wants to know if the two graphs are isomorphic let's say whatever they are um can't do it by himself so he's going to ask his students to figure out the answer and report back now there's only one problem the professor knows that students uh well in the old days they'd like to party i guess these days they like to play on uh play computer games a lot and so they're not really that eager to spend all their time figuring out whether graphs are isomorphic so he's worried that the the students will just come up with some answer and figure that he won't be able to tell the difference so the professor does not trust the students it's not enough to he for the professor to give the problem to the students and just take any answer that they're going to give the professor wants wants to be convinced okay so um now how could the students convince the professor of the answer that they've really done the work and figured out whether the graphs are isomorphic or not well if the graphs are isomorphic if it turns out that the graphs were isomorphic and the students figure that out then life is good because what are they going to do to convince the professor they're going to hand over the isomorphism and show yeah i mean they are you know those graphs really are isomorphic and here's how the correspondence works professor can check oh yeah i i now not now i'm convinced but suppose the graphs were not isomorphic what are we going to do then um the students have figured out where after night else the professor wants wants to be convinced oh no what are we going to do well in fact we're going to engage the the professor and the students are going to engage in the following protocol dialogue what's going to happen is now you have to make sure you're you're this is critical to follow to understand this little part of the story here because it's really going to set the pattern for everything in today's and tomorrow and to today's lecture and the and the next lecture okay so we're going to engage in a following interaction between the students and the professor which is going to enable the students to convince the professor that the two graphs really are not isomorphic so how is that going to work this is a beautiful little uh thing by the way so the professor is going to take the two graphs and pick one of them at random because the two graphs g and h um let's say they're not they really are not isomorphic the professor doesn't know that for sure that's what the students claim the professor really wants to not be convinced that the students are right um so the professor's gonna pick one of the two at random randomly permute that uh that choice the one that he picked and hand it over to the students say okay here is one of those two graphs randomly scrambled then i'm going to ask the students which one did i pick okay now if the graphs were really not isomorphic the students can check whether that randomly scrambled graph is isomorphic to either g or to h it's going to be isomorphic to one or the other and then they students can figure it out and they say oh you picked g or no you picked h as the case may be the students can figure that out but if the graphs were isomorphic then that scrambled version of g or h could equally well have come from either of them and the students would have no way of knowing which one the professor picked so that there's nothing they could do which would be better than guessing so if we do that a bunch of times the professor picks at random sometimes secretly of course the picks the grip picks either g or picks h and the students get it right every time either the students are really doing the work and the graphs are really not isomorphic or the students are just incredibly lucky they're managing to guess right let's say a hundred times so how the the the professor randomly and secretly picks grh uses this uses its probabilism flips a coin just a two-sided coin and says okay sometimes if we're going to do g sometimes they're going to do h just completely at random picks one or the other and then with some more randomness gets finds a random permutation of the one that he picked and then sends that over to the students and say which one did it come from um i'm not sure okay so let's pause here let's let's make sure we all understand this because this is really important um so i'm getting a question here how do we i'm not sure what your question is um okay so let me just say yeah the professor's going to play the role the verifier the graduate students play they're all approver that's coming but i really want to understand this protocol here okay so how is the professor picking the graph skin if you're okay i don't you know picking the graphs at random you have just two graphs they're in part of the input uh the both the students and the professor can see the graphs and the professors are just picking one of them at random using a coin so i'm not sure i understand the question there could p and v engage in a protocol where the secretary is on the prover side instead the question of revealing the isomorphism i there is no why so i'm not sure i understand this question either um maybe we'll make this clear you know if for for this little illustration the professor doesn't know the graphs could be isomorphic or they could be not isomorphic and so uh the professor wants to be convinced either way whatever the students whatever answer the students come up with we're going to shift this into a problem about a um deciding a language next but right now i'm just trying to give a sense of the how the model works i want to move from this informal model and now i'm going to formalize that in terms of model which will be deciding a language okay so so the interactive proof system model we have two interacting parties a verifier which is probabilistic polynomial time playing played by the professor in the previous slide and the prover which is unlimited computational power played by the students in the previous slide both of them get to see the input which in the previous case well it could be for example the pair of graphs they exchange a polynomial number of polynomial size messages so the whole exchange including the verifier's own computation is going to be polynomial the only thing that's not not not included within the computational cost is the prover's work which is unlimited um after that the verifier after the interaction the verifier will accept or reject and we're going to define the probability that the verifier together with a particular approver ends up accepting as you look over the different possible coin tosses of the verifier which could lead to different behavior on the part of the verifier and therefore different behavior on the part of the approver so over all the different possibility possibilities for the verifiers computation we're going to look at the probability that the verifier with this particular approver ends up accepting and i've written it this way this is the probability of the verifier interacting with the prover accepts the input is just simply that um and so we're going to work through an example we're going to work through the previous example more precisely in a second the class ip for interactive proofs stands for it's the class of languages such that for some verifier and approver um for strings in the language the prover makes the verifier accept with high probability and here's the interesting part for strings not in the language the prover makes it except with low probability but every there's no prover which can make it except with high probability so there's no way to cheat if you think about it in the case of the graphic non-isomorphism there's nothing you know if if the graphs were really isomorphic and the students were trying to in a devious way prove through that protocol that they're not isomorphic they would fail because there's nothing they can do if the graphs were isomorphic then um when the verifier the the professor picks one or the other at random um and scrambles it the students would have no way of telling which one the professor did so no matter what kind of scheme they try to come up with they're going to be out of luck so it's no mat for any strategy for strings that are not in the language for any s any prover calling that p with a tilde to stand for a devious or crooked prover for any uh possibly crooked prover even that with working with the verifier is still going to end up accepting with low probability so strings in the language there's going to be an honest prover who just follows the protocol in the correct way which makes the verifier accept with high probability for strings not in the language every prover is going to fail to make it accept with high probability um okay so that i mean the way i like to think about it is that p tilde is a possibly crooked proverb which is trying to make the verifier accept when it shouldn't because the string is not in the language it's like you know it's like even you can think of this in the case of um satisfiability um you know you a crooked prover might try to convince of the verifier that the formula is satisfiable when it isn't by by somehow trying to produce a satisfying assignment but that's going to be impossible there's nothing any strategy can possibly work when the formula is not satisfiable if that's what the verifier is going to check it's going to be looking for that satisfying assignment okay and by the way this is we're not going to prove this but it's really going to be proved in the same way you can make that one third error that could that occurs here something very tiny by the same kind of repetition argument okay so let's see um so why can't the prover in the first case be crooked um the prover in the first case would could be crooked but that's not going to serve the purposes um you know what what we want to show um you think about it like we think about np for strings in the language there exists a certificate there is a proof that you're in the language so if somebody is going to not produce the proof that's irrelevant the question is if you look at the best possible case the best possible prover um you know who's going to be able we're asking does there exist a way to convince the verifier that the um string is in the language so it doesn't matter that there might be some other uh silly way that doesn't work we're just looking at the best possible way so the best possible way when you're in the language is going to end up with a verifier having high probability when you're not in the language the best possible way is still going to end up with low probability when when i talk about best possible i'm trying to maximize the probability that the verifier is going to end up accepting let's continue um not sure as clear as i would like but um maybe again we're going to we're going to stick with that example because this is a very uh helpful example and to try to understand the setup and uh so we're gonna i'm gonna revisit that previous example about non-isomorphism but now in the context of this thinking about as a language so we're going to take this non-isomorphism um uh yeah we're going to take the non-isomorphism problem and show that it's an ip so there's going to be a verifier together with approver which are going to make the verifier accept with high probability for strings in the language namely graphs not ice being isomorphic and nothing there's going to be no way to make the verifier except with high probability for strings out of the language therefore that's when the graphs are isomorphic okay um so the protocol is just gonna we're gonna repeat the following thing twice you know i said in the previous case do it a hundred times just to help us think about it but actually,"The professor picks one of the two graphs (G or H) at random after applying a random permutation and presents it to the students. If the graphs are truly not isomorphic, the students can determine which of the original two graphs the scrambled version is isomorphic to, thereby proving they are not isomorphic without revealing an isomorphism. If the graphs were isomorphic, the scrambled version could correspond to either, and the students would have no better strategy than guessing.",invalid,Advanced,18.404J,25 Interactive Proof Systems IP,TSI3LR5WZmo.en_2_mp4
5,What is the significance of TQBF in proving that PSPACE properly includes NL?,"OK. So the time and space hierarchy theorems-- because we're going to be using those today-- they say that if you give a little bit more space here-- so for space constructible functions, functions that you can actually compute within the amount of space that they specify, you can show that the things that you can do in that much space is probably larger than what you can do in less space. And you can prove a similar slightly weaker fact about the time complexity classes. So what that means is that these classes form a hierarchy. So as you add more time, or let's say, in this case, space, from n squared, to n cubed, to n to the 4th, you get larger and larger classes, which I'm kind illustrating here by putting a dot there, which shows that there's something that we know that's new in those classes as you go up these different bounds. And this is going to be true for space complexity and it's also going to be true for time complexity. And one of the corollaries that we pointed out last time is that, PSPACE is a-- properly includes non-deterministic log space, NL. So NL is a proper subset of PSPACE. So there's stuff in PSPACE that is not in NL. And remember this notation here, this means proper subset. One of the things that-- a follow-on corollary that we didn't mention last time, but that's something that you should know, is that the TQBF problem, our PSPACE based complete problem, is an example of a problem that's in PSPACE, obviously, but we know it's also not in NL. And in order to get that conclusion, you have to look, again, at the proof that TQBF is PSPACE complete, and observe that the reductions that we gave in that proof can be carried out not only in polynomial time, but they can be carried out in log space. And therefore, if TQBF turned out to go down to NL, then because everything in PSPACE is log space reducible to TQBF, that would bring all of PSPACE down to NL. But that we just proved is not the case. So therefore, TQBF could not be in NL. OK, and we're going to be using that kind of reasoning again in this lecture. So just a quick check-in. These are a few, more or less easy, maybe more or less tricky, follow-ons that you can conclude from the time and space hierarchy theorems plus some of the other things we've proven along the way. And so just as a check of your understanding, maybe these a little bit on the tricky side, so you have to read them carefully. Which of these are known to be true based on the material that we've presented? And this is also just material that's the facts that we know to be true in complexity theory. So let me launch that poll. And just check off the ones that we can prove. Hmm. OK. I'm going to close it down. So please answer quickly if you're going to. OK, 1, 2, 3, end. OK. Well, the two leading candidates are correct. And the two that are the laggards here are, in fact, the ones that are not true. So A and D are not true, based on what we know. And B and C are true. So let's understand, first of all, A, we know it's false because 2 to the n plus 1 is just 2 times 2 to the n. And so these two bounds differ only by a constant factor. And so in fact, they're the same complexity class. And so you don't get proper containment for A. So that one we absolutely know is false. D, well, if we could prove that, then we would have solved the famous problem, because we don't know whether even P equals PSPACE. So if P equals PSPACE, then certainly PSPACE would equal NP, which is in between the two. And so we don't know how to prove PSPACE is different from NP, that's based on the current state of knowledge of the field. So this would not be something that we know to be true based on what things that we've said. Now, B follows directly from the time hierarchy theorem, because 2 to the 2n is the square of 2 to the n. And that is, asymptotically, a significantly larger bound. And so you can prove that time 2 the n is properly contains time 2 the n. C is a little trickier because you need to remember Savitch's theorem. Savitch's theorem applies to space. But you also need to remember that what you can do in time, in non-deterministic time n squared, you can also do in non-deterministic space n squared, which, then, in turn, you can do in deterministic space n to the 4th, which is properly contained within space n to the 5th. So you can prove that PSPACE properly contains non-deterministic time n squared. OK, just a bunch of containments there. A and C are perhaps, in a sense, it may be the most tricky of this group.","The TQBF problem is an example of a problem in PSPACE that is not in NL. If TQBF were in NL, then everything in PSPACE, being log space reducible to TQBF, would also be in NL, which contradicts the proven fact that PSPACE properly includes NL.",valid,Intermediate,18.404J,22 Provably Intractable Problems Oracles,N32bnUliSzo.en-j3PyPqV-e1s_2_mp4
6,How does a pushdown automaton check if an input string is in the language of a given grammar?,yeah so now what we're going to do we're going to prove our one so far we really haven't proved anything we've just given some definitions and some examples today was going to now we're going to come to our big theorem which actually is um important and has some meat to it um and that is how do we convert you know i claim that to put context-free grammars and push down automata are equivalent well we're going to prove that equivalence in one direction converting the grammars to push down automata okay so um let me show you how that goes in some ways um it's a nice proof not super complicated but it has some meat to it uh so if i give you a grammar here what i'm going to tell you how to do is convert that grammar into push down automaton which does the same language okay so if you're checked out for a minute please come back because we're sort of starting this topic now that you can think a bit about this good good uh re-entry point if you're sort of uh been doing something else which i can't tell good thing uh so all right so converting a given grammar to a push down automaton how is that going to work so the idea is okay actually before i tell you the idea let's just think about it together again i like to think about the push down automaton building a push on automaton the way you would do it so a grammar is a generation device it generates strings a push down automaton or thinking about it as you you're a recognizer you're given an input and you want to know is it in the language so you want to know is it possible for that grammar to generate that input you're given so how are you going how are you going to how are you going to do that um and uh are you going how are you going to um test if the input is in the language of the grammar well the thing that you would naturally do is you say well can i derive that string using the rules of the grammar let me start with the start string and try to do substitutions and see if i get the string i'm given and if i can get it then i know it's in the language right that's a natural thing to do you're just going to try try to do so you know try to do the substitutions even get to the string now the thing is there are many there might be many different substitutions that you could make and you know that seems like a really challenging uh hard thing to figure out which substitutions to use among the many possibilities that's where non-determinism is going to come in because you can think of yourself as guessing which substitutions to make and you're always going to make the right guess so the choices of which substitutions to make that's not going to be a problem for you that's going to be managed by the non-determinist so imagine you're always going to make the right substitution but now the challenge is how do you keep track of the intermediate results as you're doing those substitutions um and that's where the stack is going to come in the machine is going to write down those intermediate results on the stack but even there there's a subtlety that's an important subtlety that you have to look at so let's try pulling that together so far before i get to that subtlety uh okay so as i mentioned um uh the push down automaton is is going to start out with the starting variable and is going to guess to be guessing the substitutions to make it's going to keep the intermediate results on the stack when it's done doing all the substitutions and it has only terminal strings on the stack it can compare with the input and see if it got the right thing so if it made it all the right guesses so you think of it as guessing doing the right guesses but in the end you have to check to make sure that you've got the right the you that you did all the right thing and you accept when when things um have matched up you know you and you made all the right guesses so you have to in the end you have to check that you actually got,"The pushdown automaton guesses substitutions to make from the starting variable, keeps track of intermediate results on the stack, and eventually compares the resulting terminal strings on the stack with the input to check if they match. If they do and all the right guesses were made, the input is accepted.",valid,Basic,18.404J,4 Pushdown Automata Conversion of CFG to PDA and Reverse Conversion,m9eHViDPAJQ.en_12_mp4
7,Why is it conjectured that P ≠ NP even though polynomial-time algorithms are known to be powerful?,"Intuition for P and NP
NP = All languages where can verify membership quickly
P  = All languages where can  test membership quickly
Examples of quickly verifying membership:
- !""#$""%!:  Give the Hamiltonian path. 
- &'#$'()%*(:  Give the factor. 
The Hamiltonian path and the factor are called short certificates of membership.
P ⊆NP
Question:  P = NP?  Famous unsolved problem (Cook 1971).
Conjecture:  P ≠ NP.   Some problems are NP and not in P. 
Hard to prove the conjecture because polynomial-time algorithms are powerful.
Example:  Show ""CFG ∈P.
NP
P
Check-in 14.1
Check-in 14.1
Let !""#$""%! be the complement of !""#$""%!.
So 0, 2, 3 ∈!""#$""%! if 0 does not have a Hamiltonian path from 2 to 3.  
Is !""#$""%! ∈NP?
(a) Yes, we can invert the accept/reject output of the NTM for !""#$""%!. 
(b) No, we cannot give a short certificate for a graph not to have a Hamiltonian path. 
(c) I don’t know.
6
","It is conjectured that P ≠ NP because some problems are believed to be in NP and not in P, despite the fact that polynomial-time algorithms are recognized as powerful. However, proving this conjecture is challenging due to the effectiveness and the unproven potential of polynomial-time algorithms, which has left the question, P = NP, an open problem.",valid,Advanced,18.404J,"Lecture 14 - P and NP, SAT, Poly‑Time Reducibility",45e2fd621349cfd7c9faf93a6ba134a3_MIT18_404f20_lec14_6_pdf
8,What does \( \Sigma_8 \) represent in the context provided?," 
 
 
 
 
  
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
>?:8:@ ⋯ :B 
⋯ >reject ⋯
# 
# 
#
⋯
˽ … ˽ 
ababa ⋯ 
abababa
2 BM 
2 BM 
2 BM 
! ≤# $%&'(↑ (*+,-./012 & *+,-.425267) 
Construct *8 to generate all strings except a rejecting computation history for 9 on :. 
*8 = *+,-.<7,47 ∪ *+,-./012 ∪ *+,-.425267 
Rejecting computation history for 9 on :: 
I8 = Istart 
I@ 
Ireject 
267 generates all strings that do not contain >re
*+,-.425 
ject 
∗
*+,-.425267 = Δ.Oreject 
*+,-./012 generates all strings that contain an illegal 2×3 neighborhood 
2 BM —2 
U Δ∗ abc Δ@ VM 
.@ def Δ∗ 
⋯ 
abc 
def 
⋯
*+,-./012 = 
illegal 
a
b
c 
IS 
IST8 
d
e 
f 
7 
",\( \Sigma_8 \) is defined as \( \Sigma_{\text{illegal}} \cup \Sigma_{\text{all}} \cup \Sigma_{\text{reject}} \) which represents a construction to generate all strings except a rejecting computation history for \( M \) on \( x \).,invalid,Basic,18.404J,"Lecture 22 - Provably Intractable Problems, Oracles",50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_7_pdf
9,What defines the class P in terms of time complexity and associated languages?,"solve in a certain time bound, within a certain amount of time. So the time n-squared, for example, is all of the languages or all of the problems that you can solve in n-squared time. We're identifying problems with languages here. And the class P is the collection of all problems that you can solve or all languages that you can solve in polynomial time. So it's the union over all time n to the k-- so n-squared, n-cubed, n to the fifth power, and so on. Union out of all of those bounds. The associated languages, that's the class P. And we gave an example, this path problem. We gave an algorithm for path.","The class P is the collection of all problems or languages that you can solve in polynomial time. It is the union over all time n to the k, such as n-squared, n-cubed, n to the fifth power, and so on. The associated languages with these time bounds form the class P.",valid,Advanced,18.404J,14 P and NP SAT Poly-Time Reducibility,1VhnDdQsELo.en-j3PyPqV-e1s_2_mp4
10,"How can reducing a problem help in determining its complexity or decidability, and what are the two typical ways this can be used?","the problem of determining whether a pushdown automaton ever pushes on its stack for any input. I know a bunch of you were struggling with that problem working on it, hopefully solving it in one way or another. So there's one way to solve it is in effect by reducing the pusher problem to the E CFG the emptiness for CFG which is the equivalent to the emptiness for PDAs. I mean, this is the solution I had in mind, which is a particularly simple and short solution. Of course, not the only solution. You can take your pushdown automaton where you're trying to determine if it ever pushes. And you can take the states that are about to make a push. And instead of making them make a push, you make them accept states. And you get rid of the original accept states. So now you've converted this automaton to one that accepts every time the original push on automaton pushes. And it accepts, and then has to move to the end of the input, of course. So it goes into an accept state and moves to the end of the input. So every time the original machine was about to push, the new machine that you're just creating here is going to go into an accept state at the end of the input. Now to test whether the original machine ever uses stack, it's enough to test whether the new machine ever accepts an S string. OK, so that's a way. I don't want to overcomplicate this right here and get you thinking about the homework again. But this is a way of reducing one problem to another problem. And if you don't quite get this one, just focus on the other two examples. I don't want to spend time on the homework set 2 right now. So we can address that all separately if you want. It's also the solution that's written up in the solution set that's posted on the home page by the way. OK, so getting back to let's see, thinking about reducibility. What I have in mind, again, this is sort of rephrasing it, but I'm trying to hammer it in that if A is reducible to B, then solving B gives a solution to A. Because that's what happens in each of these examples. Now, how are we going to use that? We're going to use that in the following two ways. One is to observe that, if A is reducible to B and B is an easy problem, then A must also be easy because we have a way of converting A problems into B problems. We have a way of solving A using B. So B is easy. Then now you can solve A too easily. Because you can solve A using B, which is easy. Maybe that's clearest up here in example 1, where measuring the area might seem at first glance hard. You could have to walk out over the whole area. But it's not hard because you only have to measure the length and the width. So the fact that B is easy tells you that A is easy. But actually, this is not the way we're going to be using it most typically. We're going to be most typically using it in the second version, which is a little bit more convoluted. But this is the way you're going to have to get used to this. So if A is reducible to B, and you know A is hard, undecidable, unrecognizable, whatever the form of hard you care about, if you know A is hard, and A is reducible to B, then that tells you B also has to be hard. Why? Because if B were easy, then A would be easy. But we're assuming that A is hard. So B also has to be hard. OK, so I'm inverting the logic here. But this is logically equivalent. So you have to mull that over a bit. So why don't you think about that. And let me just take a few questions on the chat and don't forget the TAs are there too. So they're happy to answer your questions. Don't make them sit there lonely, all right. So somebody is asking, is it possible that A is reducible to B and that B is also reducible to A? So that's a good question. That can certainly happen. In that case in a certain sense, A and B are going to be equivalent. So solving 1 is going to be just as easy or hard as solving the other one, OK? So they're going to be equivalent from the perspective of the difficulty of solving them. So somebody is asking-- and this is a perennial confusion-- so in the previous slide here, I think I'll just flip back to it here. So which direction are we doing? Are we reducing A TM to HALT TM or HALT TM to A TM? The way it's written on the slide is what I have in mind. Here we're reducing A TM to HALT TM because we're using HALT TM to solve A TM. And that's reducing A TM to HALT TM. Just like here, measuring the area is reducible to measuring the lengths of the sides, we're using measuring the length of the sides to solve the area. So we're reducing the area to the lengths, the area to the length of the sides. But I know you're going to have to play with it, digest it, get used to it. All right, OK, so let's continue. OK, so as I said, this latter one because the focus on this course is mainly on the limitations of computation. So we're going to be looking at ways of showing problems or difficulty. It could be difficult in principle, like undecidable. Or it could be difficult in terms of complexity, which is what we're going to focus on in the second half.","Reducing a problem A to another problem B can help in determining its complexity or decidability because if A is reducible to B, solving B gives a solution to A. This can be used in two typical ways: 1) If A is reducible to B and B is known to be an easy problem, then A must also be easy because we can convert A problems into B problems and solve A using B, which is easy. 2) More commonly, if A is reducible to B and A is known to be difficult (e.g., hard, undecidable), then B also has to be hard. This is because if B were easy, then A would be easy, contradicting the assumption that A is hard.",valid,Advanced,18.404J,9 Reducibility,N28g_YBXY8Y.en-j3PyPqV-e1s_4_mp4
11,What is the class BPP?,don't i move on so let's define now the class bpp using this notion of a probabilistic turing machine which is now going to be running in polynomial time so bpp is going to be another one of these complexity classes a collection of languages like p and np and p space and so on and um but it's going to be now associated with the capabilities of these probabilistic machines the kinds of languages that they can do so we'll say the class bpp is the set of languages a such that there's some probabilistic polynomial time during machines so all branches have to halt within you know to the k for some k so some polynomial time polynomial time probabilistic turing machine decides a with error possibility at most one-third so in other words when it's accepting for some for strings in the language the machine has to reject with at most one-third so saying it equivalently for strings in the language it has to accept with two-thirds probability and for strings not in the language it has to reject what two-thirds probability at least in both cases um okay somehow ended up with didn't check my animation here but okay that's fine so there is a um uh now if you look at the one-third here in the definition uh you know it seems strange to define a complexity class in terms of some arbitrary constant like one-third why didn't we use one-quarter you know or uh you know one-tenth in the definition of bpp and say the machine has to get have an error with at most one tenth or one hundredth uh well it doesn't matter and that's the point of this uh next statement called the amplification lemma which says that um you can always if you have a machine that's running in a certain uh a polynomial time that's running within this with a certain error which it is most one-half if you have an error one-half it's not interesting because the machine could just flip a coin for every uh input and it could get uh the right answer with it with probability one-half so probability one-half is not interesting you have to have probability strictly less than one-half for the machine to actually be doing something that's meaningful about that language so um if you have a probabilistic turing machine that has error let's say epsilon one which is at most one half which is less than one half then you can convert that to any error probability you want for some other polynomial time probabilistic turing machine so you can make that error which maybe starts out as one-third and you can drive that error down to one out of one over or google um and seriously you can really make the error extremely extremely small using a very simple procedure and and that's simply this so if you're starting out with a machine that has an error possibility of one-third say so that means two-thirds of the time it's going to get the right answer and at most one-third of the time at least two-thirds of the time the right answer most one-third of the time the the incorrect answer whether that's accepting or rejecting um and now you want to get that answer down to be something much that error down to something much smaller um the the idea is you just you're going to take that machine and you're going to run it multiple times it's kind of with independent runs if that me if you want to think about it you sort of more formally speaking but it's sort of intuitive you're just going to run the machine uh tossing your coins um uh instead of just running it once you're going to run the machine 100 times or or a million times but you can do that so it's a constant factor and even a thousand times is going to be enough to increase your confidence in the result tremendously because if you run the machine a thousand times and 600 of those times the mach the machine accepts and 400 of the time the machine rejects um uh it's very powerful evidence that this machine is biased toward accepting that it's accepting most of the time um so it's um was uh if it had an error probability of most one-third um uh the the probability that you're seeing it except 600 times when really two-thirds of the time it's rejecting overall is extremely unlikely um and you can calculate that uh which we're not going to bother to do but it's a routine probability calculation uh to show that the the probability that if you run it a whole bunch of times and you see the majority coming up um which is not the not the right answer that's extremely the the probability of that is extremely small um so i'm not saying that very clearly but um the the the the method here is you're going to take your original machine which has error probability one-third or whatever it whatever it is some you know you know maybe has error probability 49 and you run it uh for a large number of times and then you take the majority vote and it you're kind of sampling the the outcomes of this machine and if you take enough samples it's overwhelmingly likely since you're just doing them uniformly you're taking those samples uniformly it's overwhelmingly likely that you're going to be seeing the predominant one come up more often um and exactly what that right value is we're not going to bother to calculate but that's something that you know if you i will i'll refer you to the textbook or you know that's the kind of thing that comes up in any elementary probability book and it's sort of very intuitive so i don't want to spend the time and do that calculation which is not all that interesting um uh okay so just one quick question here that i'm getting what happens if you bound if the error is greater than a half i don't think that because we're bounding the error so we're not saying the error actually is one you know like sixty percent on everything because then if you knew the error was sixty percent guaranteed you can always just flip the flip your answer around and get your um error to be 40 but you know i'm saying the error is that most whatever epsilon is and so um if it's you're saying the error is at most 60 percent it doesn't tell you anything um okay um [Music] uh another question is does the amplification lemma also justify that the choice of model with binary branching choices is equivalent to any other perhaps you could say that um because you can change those you know if you had through a three-way branching um you can simulate that with two-way branching to any accuracy that you want um you know not going to get it down to zero but you're going to get it very close um so it's maybe it's the amplification level maybe it's,The class BPP is the set of languages A such that there's some probabilistic polynomial time Turing machine that decides A with an error possibility of at most one-third.,valid,Basic,18.404J,23 Probabilistic Computation BPP,Vp_AzDGQyrA.en_3_mp4
12,Why is proving a problem to be NP-complete considered strong evidence that it lacks a polynomial time solution?,"[SQUEAKING] [RUSTLING] [CLICKING] MICHAEL SIPSER: OK, everybody. Let's begin. Welcome back. Good to see you all here on Zoom. So we're going to pick up with what we had been discussing last week, which was an introduction to NP-completeness. So we're following on our description of time complexity. We started talking about the time complexity classes, the class P, the nondeterministic classes, the class NP, P versus NP problem, and then leading to this discussion of NP-completeness. And today we're going to prove the big theorem in the field, which really kind of got things going back in the early 1970s by Cook and Levin that there was actually an NP-complete problem, that SAT in particular is an NP-complete problem. And then we'll also talk about 3SAT, which is a useful tool. Just to remember, we had this notion of NP-completeness. A language is NP-complete if it's in NP. And everything else in NP is polynomial time reducible to it. And if an NP-complete problem turns out to have a polynomial time solution, then every NP-problem has a polynomial time solution. And that's part of the importance of NP-completeness, because since we consider it unlikely that P equals NP, and that there probably are some problems that are an NP, but are not solvable in polynomial time. That would imply that an NP-complete problem would have that property. And so proving a problem being NP-complete is evidence, very strong evidence, that it doesn't have a polynomial time solution. And so therefore it's called intractable. It's a very difficult problem. So the way we are going to typically show problems NP-complete is by reducing a known-- a previously known NP-complete problem to that problem. Often it's 3SAT, as we've seen in several examples already, or it could be some other example. So let's just survey briefly the things that we've already-- languages that we've already seen, which are NP-complete.","Proving a problem being NP-complete is considered strong evidence that it doesn't have a polynomial time solution because if an NP-complete problem turns out to have a polynomial time solution, then every NP-problem would also have a polynomial time solution. Since it is considered unlikely that P equals NP, and there probably are some problems that are in NP but are not solvable in polynomial time, showing a problem is NP-complete indicates that it likely possesses this intractable property.",valid,Advanced,18.404J,16 Cook-Levin Theorem,6Az1gtDRaAU.en-j3PyPqV-e1s_1_mp4
13,What is the comparison mentioned between biology and physics regarding reducibility?,"biology reducible to physics? Maybe yes, or maybe there are some things like consciousness which cannot be reduced to physics. Or maybe we don't know. So I'm curious to know your thoughts. But it does kind of use in a sense the notion of reducible in the spirit of what I have in mind here. In the sense that if you could fully understand physics, would that allow you to fully understand biology? OK, here we are. We're almost-- kind of interesting, though not too unexpected I suppose. So we are, I think, just about done. 5 seconds, pick anything if you want to get credit for this and you haven't selected yet. Ready to go, ending polling. Here are the results. And as I say, there's no right answer here. But if I had been in the class, I would have picked B. But I'm not surprised, especially in an MIT crowd that A is the winner, all right. Let's continue. OK, so now we're going to use reducibility again. This is going to be yet another example like the HALT TM example, but a little bit harder. And we're going to be doing this. You know, next lecture, we're going to be doing more reducibilities but much harder. So we really got to get really comfortable, all right.","The comparison is about whether biology is reducible to physics. If fully understanding physics would allow one to fully understand biology, though for things like consciousness, it might not be reducible. There's no right answer given, but the lecturer mentions choosing option B as a personal preference.",valid,Basic,18.404J,9 Reducibility,N28g_YBXY8Y.en-j3PyPqV-e1s_6_mp4
14,What does the claim (1) state about functions F(x) and G(x) and their probability of agreeing on a random assignment?,"Algorithm for !""ROBP = “On input (), (+
[on variables ,), … , ,.]
1.  Find a prime / ≥32.
2.  Pick a random non-Boolean input assignment 3 = 3), … , 3. where each 34 ∈67. 
3.  Evaluate () and (+ on 3 by using arithmetization.
4.  If () and (+ agree on 3 then accept.
If they disagree then reject.”
Claim:  (1)  () ≡(+ →Pr :) 3 = :+ 3
= 1
(2)  () ≢(+ →Pr :) 3 = :+ 3
≤⁄
) ?
Proof (1):  If () ≡(+ then they agree on all Boolean inputs.
Thus their functions have the same truth table.
Thus their associated polynomials :) and :+ are identical. 
Thus :) and :+ always agree (even on non-Boolean inputs).
Proof (2):  If () ≢(+ then :) ≠:+ so : = :) −:+ ≠0.
From Schwartz-Zippel, Pr :) 3 = :+ 3
≤
⁄
C. 7 ≤
⁄
. ?. = ⁄
) ?.
(Note that D = 1.)   
!""ROBP ∈BPP
:) and :+ each have the form:
1 −,)
,+
1 −,?
,E
⋯(1 −,.)
+
,)
,+
,?
1 −,E
⋯
,.
+
,)
1 −,+
1 −,?
,E
⋯
(,.)
⋮
+
,)
,+
1 −,?
,E
⋯
(,.)
,)
0
1
0
1
()
,E
0
1
0
1
(+
arithmetize
:)
:+
Check-in 24.2
Check-in 24.2
If the BPs were not read-once, the polynomials might 
have exponents ≥1.  Where would the proof fail? 
(a) () ≡(+ implies they agree on all Boolean inputs
(b) Agreeing on all Boolean inputs implies :) = :+
(c) Having :) = :+ implies :) and :+ always agree
9
","The claim (1) states that if F(x) ≡ G(x), then Pr[φ(x) = ψ(x)] = 1, meaning they agree on all inputs when the functions are equivalent.",invalid,Intermediate,18.404J,Lecture 24 - Probabilistic Computation (cont.),cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_9_pdf
15,What condition must an NFA satisfy to accept the empty string when using closure under star?,"Now let's do closure under star. And closure under star works very similarly, but now we're just going to have a single language. If A is regular, so is A star. So they're not a pair of languages, because a star is a unary operation applying to just a single language. So if we have a DFA recognizing A, in order to show that A star is regular, we have to construct a machine that recognizes A star. And the machine we're going to construct is as before and then an NFA. OK? So here is M, the DFA for A. And we're going to build an NFA M prime that recognizes A star. And let's think now, what does it mean to recognize A star? So if I'm going to give you an input, when is it in the star language? What does M prime have to do? So remember what star is. Star means you can take as many copies of you lot as you like of strings in the original language, and that's in the star language. So to determine if something is in the star language, you have to see, can I break it up into pieces which are all in the original language? So you want to see, can I take my input w and cut it up into a bunch of pieces-- four, in this case-- where each of those pieces are members of A, the members of the original language? So that's what M prime's job is. It has its input and wants to know, can I cut that input up into pieces, each of which are accepted by the original machine M? That's what M prime does. And if you think about it a little bit, really what's happening is that as soon as M-- so M prime is going to be simulating M. That's the way I like to think about this, as having M inside. So if you were going to be doing this yourself, you're going to take w. You're going to run it for a while. You'll see, oh, M is accepted. Now I have to start him over again to see if it accepts the next segment. So every time M accepts, you're going to restart M to see if it accepts another segment. And so by doing that, you're going to be cutting w up into different segments, each of which is accepted by M. Of course, it's never totally clear whether you should, for any given segment, you should cut it there or you should wait a little longer and find another, a later place to cut. But that's exactly the same problem that we had before with concatenation. And we solved it using nondeterminism, and we're going to solve it again using nondeterminism. So the way we're going to get that effect of starting the machine over again, once it's accepted, is by adding in epsilon transitions that go from the start states back to-- from the accept state back to the start state. So now every time M has accepted, it has an option-- not a requirement, but has an option. It can either stay continuing to process, or it could restart, making a cut at that point and trying to see if there's yet a second, another segment of the input that it's going to accept. And this is basically the whole thing, with one little problem that we need to deal with. And that is we need to make sure that M prime accepts the empty string. Because remember, the empty string is always a member of the star language. And as it's written right now, we're going to be requiring there to be at least one copy of at least one segment. We're not taking into account the possibility of no segments, which is the empty string. And the way we're going to get that is-- well, I mean, one thing, one way to get to add-- so we're missing the empty string right now. So how do we fix it? Basically, we're just going to take the construction we have on the screen, and we're going to adjust it to add in the empty string. Because it's possibly missing. One way to do that, which is tempting, but wrong, is to make the start state of M an accepting state for M prime. So we could have made this an accepting state, too. And now M prime is also going to accept the empty string. That's the good news. The problem is that the start date might be playing some other role in M besides just being the start. There might be times when M comes back to the start state later on. And if we make the start state the an accept state, it's going to suddenly start accepting a bunch of other things too, which might not be intended. So it's a bad idea to make the start state an accept state. Instead, we'll take the simple solution alternative of adding a new start state, which will never be returned to under any circumstances, and make that a new start-- an accept state as well. So here, we'll have to make this additional modification. So as I'm saying, this is what we need to do. And the way we'll do that is by adding a new start state, which is also an accept state, to make sure it accepts the empty string. And then that also can branch to start off M as before, if the string that's input is not the empty string. And so then M prime is actually going to have to do some work to see if it can be cut off, as it was doing before. So that's the proof of closure under star. I'm not going to do it anything beyond what I've just described. These proofs by picture are convincing enough, I hope. And if not, they are explained in somewhat more detail, somewhat more formally, in the textbook. But for the lecture, this is where I'm going to stop, with these two arguments. And so now-- oh, we have one quick check-in on this. So if M has n states, how many states does M prime have by this construction? So I'm not intending these to be very hard, more just to keep you awake. So how many states does M prime have? OK, maybe a little too easy even for a check-in. Yeah, everybody is getting this one. Because all you did was-- we added one new state. So the answer is as you have-- I think pretty much everybody is observing that it's number b. So I'm going to end the polling, and I'm going to share the results. And everybody got that one. And so let's continue on. And so the very last thing we're going to do today is show you how to convert regular expressions to NFAs, thereby showing that every language that you can describe with a regular expression is a regular language. On Tuesday, we'll show how to do the conversion in the other direction and so thereby showing that these two methods of describing languages are equivalent to one another. So here's our theorem. If R is a regular expression, and A is the language-- a set of strings that that regular expression describes, then A is regular. OK? So we're going to show how to convert. The strategy is to convert R to an equivalent NFA M. And so we have to think about, remember, these regular expressions that we introduced last time. These are these expressions that look like ab union b star, something like that-- so built up out of the regular operations from the primitive regular expressions that don't have any operations, that we're calling atomic. So if R is an atomic regular expression, it just looks like either just a single symbol or an empty string symbol or an empty language symbol. Or R can be a composite regular expression-- whoops. We're having a little-- yeah, so we have two possibilities here. R is either atomic or composite. And so let's look at what the equivalent expression is in each case. So if R is just the single letter regular expression-- that's a totally legitimate regular expression, just a regular expression 1. So that just describes the language of the string 1. So we have to make an NFA which accepts-- which recognizes just that language, accepts only the string 1. So it's a very simple NFA. It just starts in the start state. And on that single symbol, it branches to an accept state. And there were no other transitions allowed. So if you get anything else coming in besides that one, that string, which is just that one symbol, the NFA is going to reject it. If it's too long, if it gets aa coming in, well, there's nowhere to go from this accepting state on an A. So the machine is just going to die. It has to be in an accept state at the end of the input. Now, I want you think for yourself for a minute, how do we make an NFA which accepts only the empty string and no other strings? You can do that with just one state with an NFA, just this one here. The machine is going to start off in the start state, which is also immediately an accept state. So it accepts the empty string. But if anything else comes in, there's nowhere to go when the machine dies. So this machine accepts just the empty string. Or its language is the language with one element, the empty string. How about the empty language? Well, here's an NFA which has no accepting state, so it can't be accepting anything. Now, if we have a composite regular expression, we're already finished. Because we showed how to build up-- we showed constructions which give us closure under union, concatenation, and star. And those constructions are going to enable us to build up the NFAs that do the language of these more complex regular expressions built up out of the NFAs that do the individual parts. So if we already have NFAs that do R1 and R2, then the closure under union construction gives us an NFA that does R1 union R2 as a language. So I hope that's clear, but I'm going to do an example which will hopefully illustrate it. And it's going to show you-- basically, what I'm giving you is an automatic procedure for converting a regular expression into an equivalent NFA. So let's just see that procedure in action, which is really just following this recipe that I described for you. So here is a regular expression a union ab star. So this is a regular expression. It's some language. Whatever it is, I don't care. But I want to make an NFA which recognizes that same language. And the way I'm going to do that is first build",The NFA should have a new start state that is also an accept state to ensure that it accepts the empty string.,valid,Basic,18.404J,2 Nondeterminism Closure Properties Conversion of Regular Expressions to FA,oNsscmUwjMU.en-j3PyPqV-e1s_8_mp4
16,What arguments are made to support using a one-tape Turing machine as a model for defining time complexity classes?,"[CLICKING] [RUSTLING] [SQUEAKING] [CLICKING] MICHAEL SIPSER: OK. Hi, everybody. Let's get started. So, it's been a while since we came together in a lecture. Last week, we had the holiday. We had the midterm. So with that, what have we been doing? We finished the first half of the course about two weeks ago, where we talked about-- we were talking about computability theory. We have shifted into the second half, talking about complexity theory. So get your mind back to that. We discussed the various different models and ways of measuring complexity on different models-- at least in terms of the amount of time that's used. And in the end, we settled on the one-tape Turing machine, which is the same model we had been working with in the first half of the course, and argued that though the measures of complexity are going to differ somewhat from model to model, they're not going to differ by more than a polynomial amount. And so, since the kinds of questions we're going to be asking are going to be, basically, whether problems are polynomial or not, it's not going to really matter which model we pick among reasonable deterministic models. And so, the one-tape Turing machine is a reasonable choice. Given that, we defined time complexity classes, the TIME[T(n)] classes. We defined the class P, which was invariant among all of those different deterministic models in the sense that it didn't matter which model we choose, we were going to end up with the same class P. So that argues for its naturalness. And we gave an example of this path problem being in P. And we kind of ended that lecture before the midterm with the discussion of this Hamiltonian path problem. So we're going to come back to that today. So today, we're going to look at non-non-deterministic complexity; define the classes' non-deterministic time or NTIME; talk about the class NP, the P versus NP problem-- which one of the very famous unsolved problems in our field; and look at dynamic programming, one of the most basic algorithm - polynomial-time algorithms and polynomial-time reproducibility - moving toward our discussion of NP completeness, which we will begin next lecture. So with that, let's move into today's content, which is, well, just a quick review. As I mentioned, we defined the time complexity class. The time complexity class is a collection","Though the measures of complexity differ somewhat from model to model, they do not differ by more than a polynomial amount. Since the questions of interest are whether problems are polynomial or not, it does not really matter which model is chosen among reasonable deterministic models. Thus, the one-tape Turing machine is a reasonable choice.",valid,Advanced,18.404J,14 P and NP SAT Poly-Time Reducibility,1VhnDdQsELo.en-j3PyPqV-e1s_1_mp4
17,What is the definition of EXPTIME in terms of complexity classes?,"  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
Exponential Complexity Classes 
Defn: EXPTIME = ⋃"" TIME 2 $% 
EXPSPACE = ⋃"" SPACE 2 $% 
≠
Time Hierarchy Theorem 
L ⊆ NL 
≠
⊆ P ⊆ NP ⊆ PSPACE 
≠
⊆ EXPTIME ⊆ EXPSPACE 
Space Hierarchy Theorem 
Defn: & is EXPTIME-complete if 
1) 
& ∈ EXPTIME 
2) 
For all ( ∈ EXPTIME, ( ≤* & 
Same for EXPSPACE-complete 
Theorem:  If B is EXPTIME-complete then & ∉ P 
intractable 
Theorem:  If B is EXPSPACE-complete then & ∉ PSPACE (and & ∉ P) 
Next will exhibit an EXPSPACE-complete problem 
3 
",EXPTIME is defined as the union of TIME functions: EXPTIME = ⋃ TIME 2^n.,valid,Basic,18.404J,"Lecture 22 - Provably Intractable Problems, Oracles",50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_3_pdf
18,Why is co-NP a subset of PSPACE?,um well here's a language we haven't i'm not going to define uh as in terms of its complement it's a the tautology problem so these are the problem language these are all formulas or these are the formulas where all assignments satisfy the formula all assignments make the formula true um so a tautology is a statement that's always true so no matter how you plug in the variables so the the tautology tautology language is in co-np um because it's complement which is the non-tautologies those are the formulas for which um there's some assignment which makes it false so that's going to be clearly an np language so tautology is a co and p language okay um now one thing that we get immediately from the theorem as a corollary really should write this as a corollary is that cohen p is also a subset of p space and the reason for that is and this is something that you know it's um again easy but make sure you understand it is that p space itself is closed under complement because it is defined in terms of deterministic machines and deterministic machines you can always flip the answer and get a machine of the same type which um uh uh will decide the complementary language so for deterministic machines deterministic deciders i should say um you can always flip the answer um now so here we have anything that's in p space it has a deterministic polynomial time a polynomial space uh machine and so its complementary line which is also going to be in p space so p space and cos base p co p space are equal and so that's why coen p uh is going to be in p space it's going to be a subset of p space okay i hope that's not getting mixed up by all of the,"co-NP is a subset of PSPACE because PSPACE is closed under complements, meaning that for any language in PSPACE, its complement is also in PSPACE due to the deterministic nature of polynomial space machines, which can decide both the language and its complement. Hence, since NP is a subset of PSPACE, its complement, co-NP, is also a subset of PSPACE.",valid,Intermediate,18.404J,17 Space Complexity PSPACE Savitchs Theorem,cT_qwkTigv4.en_7_mp4
19,What is the computation history method used for?,"[SQUEAKING] [RUSTLING] [CLICKING] MICHAEL SIPSER: Hi, everybody. Can you hear me? Yes. Good. Welcome back to the course. And so we are now at lecture 10, and let's see. What have we been doing? We've been talking about undecidability. So we introduced, last time, reducibilities and mapping reducibilities for proving various problems are undecidable. And this time, we're going to-- and today, we're going to introduce a more sophisticated method for proving undesirability using reducibilities. And that's called the computation history method. And that's pretty much what's used in all of the more serious cases where people have proved problems undecidable. It's pretty much a widespread method. Especially it's not an active area of research these days, but at times when people were proving problems undecidable, this was frequently a method that was used. So we'll go over that today, and we'll prove a few examples of problems undecidable using that method. All right.","The computation history method is used for proving the undecidability of problems, particularly in cases where reducibilities are involved. It's a sophisticated method applied in more serious instances where problems have been shown to be undecidable.",invalid,Advanced,18.404J,10 Computation History Method,MGqoLm2aAgc.en-j3PyPqV-e1s_1_mp4
20,What is the main idea behind showing that coNP is a subset of IP?,"[SQUEAKING] [RUSTLING] [CLICKING] MICHAEL SIPSER: Greetings, everybody. Welcome to our last lecture of the term. We have survived a semester online in 18.404 and we are going to conclude our last topic today, which is interactive proof systems that we started last time. And with the big-- well, the big theorem of interactive proof systems is that IP equals PSPACE. And we're going to give the main idea for that in a slightly weaker theorem, as we'll see. So why don't we jump in? So we have been doing interactive proofs. We gave an example of showing that the graph isomorphism problem, the complement of that is an IP, as I hope you remember. We had that interaction with the approver and a verifier. We're going to go through it quickly. Not that protocol, but just the setup. And then we're going to finish by showing that this number SAT problem is an IP and should conclude that coNP is a subset of IP. All right, so let's go for it. Yes.","The main idea is to demonstrate that the number SAT problem is an IP, thereby concluding that coNP is a subset of IP. This involves showing that there exists an interactive proof system for a problem in coNP, exemplifying that problems in coNP can be verified within this framework.",valid,Advanced,18.404J,26 coNP is a subset of IP,eEXSv0jChO4.en-j3PyPqV-e1s_1_mp4
21,Why doesn't the initial proof attempt for closure under concatenation for regular languages work?," 
 
 
 
   
 
 
 
 
 
 
 
 
 
   
 
 
 
 
  
 
 
  
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Closure Properties for Regular Languages 
Theorem: If !"", !$ are regular languages, so is !""!$ (closure under ∘) 
Recall proof attempt: Let &"" = ()"", Σ, +"", ,"", -"") recognize !"" 
&$ = ()$, Σ, +$, ,$, -$) recognize !$ 
Construct & = (), Σ, +, ,0, -) recognizing !""!$ 
&"" 
&$ 
& should accept input 0 
if 0 = 12 where 
&"" accepts 1 and &$ accepts 2. 
& 
0 
1
2 
Doesn’t work: Where to split 0? 
Hold off. Need new concept. 
3 
","The initial proof attempt for closure under concatenation for regular languages doesn't work because it's unclear where to split the input string. The automata need to recognize if the input is of the form xy, where the first automaton accepts x and the second automaton accepts y, but the point of division between x and y is not obvious.",invalid,Intermediate,18.404J,"Lecture 2 - Nondeterminism, Closure Properties, Regular Expressions → Finite Automata",d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_3_pdf
22,What is fixed by the Fixed-point Theorem in relation to a program transformation function?,"   
 
  
 
 
 
 
   
 
 
 
 
 
 
  
 
 
  
 
 
 
 
  
 
 
  
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Ex 2: Fixed-point Theorem 
Theorem: For any computable function !: Σ∗ → Σ∗ , 
there is a TM & such that ' & = '(*) where ! & 
= 〈*〉. 
In other words, consider ! to be a program transformation function. 
Then for some program &, its behavior is unchanged by !. 
Proof: Let & be the following TM. 
& = “On input . 
1. Get own description 〈&〉. 
2. Compute !
& and call the result 〈*〉. 
3. Simulate * on ..” 
8 
","For some program & (denoted as TM &), its behavior is unchanged by the program transformation function !.",invalid,Intermediate,18.404J,Lecture 11 - Recursion Theorem and Logic,779043ea724131d008eae652d703938f_MIT18_404f20_lec11_8_pdf
24,How is the size of the formula related to the tableau for a given NTM and input in the context of the Cook-Levin Theorem?,"Conclusion:  !""# is NP-complete
$% &' &( &) ⋯&+
a
$, &(
⋯
⋯
$accept ⋯
˽    … ˽
23
23
Summary: 
For "" ∈NP, decided by NTM 5, 
we gave a reduction 6 from "" to !""#:
6: Σ∗→formulas
6 &
= 〈=>,@〉
& ∈"" iff  =>,@ is satisfiable.
=>,@ = =cell ∧=start ∧=move ∧=accept
The size of =>,@ is roughly the size of the tableau 
for 5 on &, so size is I 23×23 = I 2(3 .
Therefore 6 is computable in polynomial time.
8
","The size of the formula is roughly the size of the tableau for the NTM on the input, which is I 23×23 = I 2(3 . Therefore, the reduction is computable in polynomial time.",valid,Advanced,18.404J,Lecture 16 - Cook‑Levin Theorem,8212b19fc5a34f500ca6acf03a3a7d74_MIT18_404f20_lec16_8_pdf
25,What is the toy problem used to demonstrate the proof method similar to Hilbert’s 10th problem?," 
 
 
 
 
 
 
   
 
  
  
 
 
 
 
   
 
 
 
 
 
  
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
  
 
 
Revisit Hilbert’s 10th Problem 
Recall ! = 〈$〉 polynomial $ &', &), … , &+ = 0 has integer solution) 
Hilbert’s 10th problem (1900): Is ! decidable? 
Theorem (1971): No 
Proof: Show -TM is reducible to !. [would take entire semester] 
Do toy problem instead which has a similar proof method. 
Toy problem: The Post Correspondence Problem. 
Method: The Computation History Method. 
3 
",The Post Correspondence Problem.,valid,Intermediate,18.404J,Lecture 10 - Computation History Method,a48f01c5374e72ee4f68a70bc0e38583_MIT18_404f20_lec10_3_pdf
26,What is the operation performed when taking a string from one language and another from a second language and joining them together called?,"So first, we're going to introduce this concept of regular expressions-- which, again, these are things you may have run into in one way or another before. So we're going to introduce something called the regular operations. Now, I'm sure you're familiar with the arithmetical operations, like plus and times. Those apply to numbers. The operations we're going to talk about are operations that apply to languages. So they're going to take, let's say, two languages, you apply an operation, you're going to get back another language. Like the union operation, for example, that's one you probably have seen before. The union of two languages here is a collection of strings that are in either one or the other. But there are other operations, which you may not have seen before, that we're going to look at-- the concatenation operation, for example. So that says you're going to take a string from the first language and another string from the second language and stick them together. And it's called concatenating them. And you do that in all possible ways, and you're going to get the concatenation language from these two languages that you're starting with, A and B. The symbol we use for concatenation is this little circle. But often, we don't. We just suppress that and we write the two languages next to one another with the little circle implied.",This operation is called concatenation.,invalid,Intermediate,18.404J,1 Introduction Finite Automata Regular Expressions,9syvZr-9xwk.en-j3PyPqV-e1s_9_mp4
27,What is the aim of marking all occurrences of terminals in the CFG when deciding the emptiness problem?," 
 
 
  
  
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
    
  
 
 
 
 
 
  
 
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
S 
a
R 
T 
a
Emptiness Problem for CFGs 
Let !CFG = { ' | ' is a CFG and ) ' = ∅} 
Theorem: !CFG is decidable 
Proof: 
,E−CFG = “On input ' 
[IDEA: work backwards from terminals] 
1. Mark all occurrences of terminals in '. 
S → RTa
2. Repeat until no new variables are marked 
R → 
R
Tb
Tb
Mark all occurrences of variable A if 
A → B1B2 ⋯ B4 is a rule and all B5 were already marked. 
T → a 
3. 
Reject if the start variable is marked. 
Accept if not.” 
8 
","The aim of marking all occurrences of terminals in the CFG is to work backwards from terminals to identify which variables can derive terminal strings, helping determine if the CFG generates any strings.",valid,Intermediate,18.404J,Lecture 7 - Decision Problems for Automata and Grammars,78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_8_pdf
28,What is the purpose of the space hierarchy theorem?,shifting gears the space hierarchy theorem so um so as i mentioned i think um,"The purpose of the space hierarchy theorem is to demonstrate that more space allows for the solution of more problems, meaning that for more complex problems, increased computational space can enable an algorithm to solve problems that could not be solved in smaller space configurations.",extrapolated,Advanced,18.404J,21 Hierarchy Theorems,vqFRAWeEcUs.en_6_mp4
29,What does it mean when we say that a set is uncountable?," 
 
 
 
 
   
 
  
  
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
  
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
   
 
 
 
  
 
 
 
Σ∗
{ ',
0,
1,
00,
01,
10,
11,
000,
…
0 ∈ℒ
{ 
0,
00,
01,
…
4 0
.0
1
0
1
1
0
0
0
…
ℝ is Uncountable – Corollaries 
Let ℒ= all languages 
Corollary 1: ℒ is uncountable 
Proof: There’s a 1-1 correspondence from ℒ to ℝ so they are the same size. 
Observation: Σ∗ = {', 0,1,00,01,10,11,000, … } is countable. 
Let ℳ= all Turing machines 
Observation: ℳ is countable. 
Because .
. is a TM} ⊆ Σ∗ . 
Corollary 2: Some language is not decidable. 
Because there are more languages than TMs. 
We will show some specific language 0TM is not decidable. 
Check-in 8.1 
Hilbert’s 1st question asked if there is a set of 
intermediate size between ℕ and ℝ. Gödel and 
Cohen showed that we cannot answer this question 
by using the standard axioms of mathematics. 
How can we interpret their conclusion? 
(a) We need better axioms to describe reality. 
(b) Infinite sets have no mathematical reality so 
Hilbert’s 1st question has no answer. 
Check-in 8.1 
6 
","A set is uncountable if there is no one-to-one correspondence between it and the set of natural numbers, implying it has a larger size than countable sets like Σ∗, which can be put into a one-to-one correspondence with the natural numbers.",valid,Intermediate,18.404J,Lecture 8 - Undecidability,3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_6_pdf
30,What does the concept 'coNP ⊆ IP' imply in complexity theory?," 
 
 
 
 
 
 
 
 
 
 
  
 
 
MIT OpenCourseWare 
https://ocw.mit.edu 
18.404J / 18.4041J / 6.840J Theory of Computation 
Fall 2020 
For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms. 
","The concept 'coNP ⊆ IP' implies that every problem in coNP can be solved by an Interactive Proof system. This was a significant result in complexity theory, showcasing that the complexity class coNP, which consists of the complement of decision problems in NP (nondeterministic polynomial time), is included within the class IP (Interactive Polynomial time).",invalid,Intermediate,18.404J,Lecture 26 - coNP ⊆ IP,7ac944716e076209c3964e073929f42e_MIT18_404f20_lec26_11_pdf
31,"How is a 3CNF formula constructed from a formula \((\varphi)\) using a reduction \(f\) while preserving satisfiability, and how does this relate to logical equivalence?","3""#$ is NP-complete
Theorem:  3""#$ is NP-complete
Proof:  Show ""#$ ≤& 3""#$
Give reduction ' converting formula ( to 3CNF formula (′, preserving satisfiability. 
(Note: ( and (′ are not logically equivalent) 
Example:  Say ( =
a ∧b
∨c
∧
a ∨b
Tree structure for (:   
a
b
b
c
a
∧
∧
∨
∨
-.
-/
-0
-1
(2 =
a ∧b →-.
∧
a ∧b →z.
∧
a ∧b →z.
∧
a ∧b →z.
∧
-. ∧c →-/ ∧
z. ∧c →-/
∧
-. ∧c →-/
∧
z. ∧c →z/
⋮repeat for each -5
∧(-1)
Observe that 
a ∧b →c is logically equivalent to a ∨b ∨c
a ∧b →c
↔
a ∧b
∨c
↔
a ∨b ∨c
↔
a ∨b ∨c
Logical equivalence:  # →9
and  # ∨9
# ∧9
and  # ∨9
a   b    a ∧b = c
1   1       1
0   1       0
1   0       0
0   0       0
a ∧b →c
a ∧b →c
a ∧b →c
a ∧b →c
Check-in 16.3
Check-in 16.3
If ( has : operations (∧and ∨), how many clauses has (’?
(a)
: + 1
(c)    :/
(b)
4: + 1
(d)   2:/
a   b    a ∨b = c
1   1       1
0   1       1
1   0       1
0   0       0
a ∧b →c
a ∧b →c
a ∧b →c
a ∧b →c
9
","To construct a 3CNF formula from a formula \((\varphi)\) using a reduction \(f\), you transform \((\varphi)\) into a 3CNF formula \((\varphi')\) that preserves satisfiability but does not necessarily maintain logical equivalence. The reduction involves generating clauses for each operation in \((\varphi)\), such as converting expressions like \(a \land b \rightarrow c\) into clauses like \(a \lor b \lor c\), which shows logical equivalence between \(a \land b \rightarrow c\) and \(a \lor b \lor c\). This approach maintains whether the original formula is satisfiable while changing the form to a 3CNF.",valid,Advanced,18.404J,Lecture 16 - Cook‑Levin Theorem,8212b19fc5a34f500ca6acf03a3a7d74_MIT18_404f20_lec16_9_pdf
32,What is meant by the collection of all languages being uncountable?,"So there are a number of corollaries that follow from the statement that the real numbers is uncountable. First of all, if you let script L be the collection of all languages, if you want to consider it over some particular alphabet, that's fine. But that's not going to be really important for this point that I'm going to make. So script L is the collection of all languages. So every subset of sigma star-- every subset of sigma star is a language. So look at all those possible subsets. So that includes 0 to the k, 1 to the k, plus every other language you can ever think of and more-- all possible languages. So the collection of all languages is uncountable. There's uncountably many different languages out there. I don't want to belabor this point. You can just take this if you don't quite follow the quick argument I'm going to make here. But you can make a one-to-one correspondence from all languages to the reals so that each language gets its own real number. And the way I'm going to think about that-- let's put the real numbers into binary form. And if you imagine here being sigma star, all of the possible strings of sigma star written out in their standard order. And now if you have a language here, A, it's just some arbitrary language. So that's going to have some of the strings of sigma star appearing. Like 0 is appearing, but 1 is not appearing. 00 is appearing and 01, but not these three. And I'm going to associate to A, my language, some real number in binary by putting in a 0 in the decimal representation-- well, the binary representation, I should say-- for that string if it's not there and a 1 if it is there. And so a real number-- because there's infinitely many yes/no choices in the binary representation can represent a language because of each of the yes/no choices of a string being present or not. I'm going to put a 1 for when the string is present, a 0 when it's not present. So each language has its own real number, and each real number is going to be associated to its own language. Here, I'm restricting myself to real numbers between 0 and 1. That's not going to be an essential point. So let's not get hung up on that. So the fact that the languages can be putting it into a one-to-one correspondence with the real numbers shows that the collection of all languages is also uncountable. Now another observation here-- another point worth noting is that if you look at sigma star itself, the strings, all possible strings, that's a countable set. The collection of all possible languages is uncountable. But the collection of all possible finite strings is countable because I can just list them. Here's my list of all possible strings, which you can put into a table if you like to think of it matching up with the natural numbers in that way. Now I'm trying to make a point here, which is that if you take M, which is all possible Turing machines-- script M is all possible Turing machines-- the collection of all possible Turing machines is countable. There are only countably many different Turing machines. And you can argue that in all sorts of messy different ways. But I think the most simple way to see that is to think about each Turing machine as having a description, which is a string. So the collection of all descriptions of Turing machines is just a subset of sigma star, which we already know is countable. And the subset of any countable set is going to be countable. So anyway, I think it's worth remembering that the collection of old Turing machines is countable. Whereas the collection of all languages is uncountable. And that tells you right there that some language is not decided because there are more languages than Turing machines. We've unaccountably many language, only countably many Turing machines, so that's fewer Turing machines than languages. There's no way to map all the languages onto Turing machines. So there's going to always be some languages that got unmapped. And so, in particular, there are going to be some languages which are undecidable. There are going to be some languages which are not Turing-recognizable. And anything based on some automata kind of a definition process is going to be some languages that they're not going to be defined. OK, now what this corollary shows you that there is some language out there, which is not decidable. What we're going to show next is that there is a specific language-- A,TM-- which is not decidable. And but first, I think we have a check-in coming up. And let me give you a little bit of background here because this is relevant to this question that I got about intermediate size sets. So the question of whether there is a set of size between the natural numbers and the real numbers strictly in between-- so bigger than the natural numbers, not the same size as the natural numbers, but not the same size as the real numbers either, but in between in size. That was Hilbert's question number 1 out of his list of 23 that I talked about a few lectures back. It's interesting that he put it as number 1 in that very privileged special place because I know Hilbert was very-- he felt that the understanding infinity was a really central issue in mathematics. And that if we can't answer a question like this, we don't really understand infinity. You want to understand what kind of sizes of infinities are there. We know there's the real number is bigger than the natural numbers. Is there something in between? So fundamental, really. But it was shown during the course of the 20th century, really, in two separate steps-- one in the 1930s by Godel, one in the early 1970s by Cohen-- that we can't answer this question by using the standard axioms of mathematics. The answer can go either way. And both of them are consistent with the axes mathematics. So you're never going to be able to prove that there is a set whose size is in between or that there is no such set. It's just impossible to prove either way using the standard axiom of mathematics, which, actually, is kind of remarkable. And so my question for you is-- and this is really a philosophical question, not one that is directly you need to know about material in the course. I think it's just a matter of your own interest. I hope you find it interesting. If you don't, you can just answer it randomly. But what's going on here that we can't answer that question about whether there is a set of intermediate size? Is it because our axioms for mathematics are inadequate? Or maybe there is no such thing as a mathematical reality. You can talk about what's real here? What's the reality? Either there is a set in between or not. If you can imagine, all of these things have their own reality to them, well, then, there's going to be an answer. And then you would expect, well, maybe we can find better axioms, which will actually give us that answer. Or you can say, well, there is no reality. And infinite sets are kind of human constructs anyway, so we can make them kind of play out any way we like. Mathematicians argue about that to this day. And it is, as I say, really, it's a philosophical question. But just out of curiosity, let's see how you guys end up deciding on that one. So here is the poll. 5 seconds to go. Please vote. And we're going to end the polling, 1, 2, 3, now. All right, here we go. So there's no right answer. I think if most mathematicians were to, I think, the instinct of most logicians, especially, I'm not sure if general mathematicians really even care about this question, but logicians would probably have an instinct that, probably, there are sets in between. There's no reason that there shouldn't be. It seems kind of strange that there should be this sort of jump from the natural numbers to the real numbers and why nothing in between? But I don't think that question is really settled. All right, let's continue on.","The collection of all languages being uncountable means there are more languages than can be listed or put into one-to-one correspondence with the natural numbers, similar to how there are more real numbers than natural numbers.",valid,Basic,18.404J,8 Undecidability,3PzuSPQPEU4.en-j3PyPqV-e1s_7_mp4
33,What is the relationship between Turing machines and languages in terms of countability?,"So there are a number of corollaries that follow from the statement that the real numbers is uncountable. First of all, if you let script L be the collection of all languages, if you want to consider it over some particular alphabet, that's fine. But that's not going to be really important for this point that I'm going to make. So script L is the collection of all languages. So every subset of sigma star-- every subset of sigma star is a language. So look at all those possible subsets. So that includes 0 to the k, 1 to the k, plus every other language you can ever think of and more-- all possible languages. So the collection of all languages is uncountable. There's uncountably many different languages out there. I don't want to belabor this point. You can just take this if you don't quite follow the quick argument I'm going to make here. But you can make a one-to-one correspondence from all languages to the reals so that each language gets its own real number. And the way I'm going to think about that-- let's put the real numbers into binary form. And if you imagine here being sigma star, all of the possible strings of sigma star written out in their standard order. And now if you have a language here, A, it's just some arbitrary language. So that's going to have some of the strings of sigma star appearing. Like 0 is appearing, but 1 is not appearing. 00 is appearing and 01, but not these three. And I'm going to associate to A, my language, some real number in binary by putting in a 0 in the decimal representation-- well, the binary representation, I should say-- for that string if it's not there and a 1 if it is there. And so a real number-- because there's infinitely many yes/no choices in the binary representation can represent a language because of each of the yes/no choices of a string being present or not. I'm going to put a 1 for when the string is present, a 0 when it's not present. So each language has its own real number, and each real number is going to be associated to its own language. Here, I'm restricting myself to real numbers between 0 and 1. That's not going to be an essential point. So let's not get hung up on that. So the fact that the languages can be putting it into a one-to-one correspondence with the real numbers shows that the collection of all languages is also uncountable. Now another observation here-- another point worth noting is that if you look at sigma star itself, the strings, all possible strings, that's a countable set. The collection of all possible languages is uncountable. But the collection of all possible finite strings is countable because I can just list them. Here's my list of all possible strings, which you can put into a table if you like to think of it matching up with the natural numbers in that way. Now I'm trying to make a point here, which is that if you take M, which is all possible Turing machines-- script M is all possible Turing machines-- the collection of all possible Turing machines is countable. There are only countably many different Turing machines. And you can argue that in all sorts of messy different ways. But I think the most simple way to see that is to think about each Turing machine as having a description, which is a string. So the collection of all descriptions of Turing machines is just a subset of sigma star, which we already know is countable. And the subset of any countable set is going to be countable. So anyway, I think it's worth remembering that the collection of old Turing machines is countable. Whereas the collection of all languages is uncountable. And that tells you right there that some language is not decided because there are more languages than Turing machines. We've unaccountably many language, only countably many Turing machines, so that's fewer Turing machines than languages. There's no way to map all the languages onto Turing machines. So there's going to always be some languages that got unmapped. And so, in particular, there are going to be some languages which are undecidable. There are going to be some languages which are not Turing-recognizable. And anything based on some automata kind of a definition process is going to be some languages that they're not going to be defined. OK, now what this corollary shows you that there is some language out there, which is not decidable. What we're going to show next is that there is a specific language-- A,TM-- which is not decidable. And but first, I think we have a check-in coming up. And let me give you a little bit of background here because this is relevant to this question that I got about intermediate size sets. So the question of whether there is a set of size between the natural numbers and the real numbers strictly in between-- so bigger than the natural numbers, not the same size as the natural numbers, but not the same size as the real numbers either, but in between in size. That was Hilbert's question number 1 out of his list of 23 that I talked about a few lectures back. It's interesting that he put it as number 1 in that very privileged special place because I know Hilbert was very-- he felt that the understanding infinity was a really central issue in mathematics. And that if we can't answer a question like this, we don't really understand infinity. You want to understand what kind of sizes of infinities are there. We know there's the real number is bigger than the natural numbers. Is there something in between? So fundamental, really. But it was shown during the course of the 20th century, really, in two separate steps-- one in the 1930s by Godel, one in the early 1970s by Cohen-- that we can't answer this question by using the standard axioms of mathematics. The answer can go either way. And both of them are consistent with the axes mathematics. So you're never going to be able to prove that there is a set whose size is in between or that there is no such set. It's just impossible to prove either way using the standard axiom of mathematics, which, actually, is kind of remarkable. And so my question for you is-- and this is really a philosophical question, not one that is directly you need to know about material in the course. I think it's just a matter of your own interest. I hope you find it interesting. If you don't, you can just answer it randomly. But what's going on here that we can't answer that question about whether there is a set of intermediate size? Is it because our axioms for mathematics are inadequate? Or maybe there is no such thing as a mathematical reality. You can talk about what's real here? What's the reality? Either there is a set in between or not. If you can imagine, all of these things have their own reality to them, well, then, there's going to be an answer. And then you would expect, well, maybe we can find better axioms, which will actually give us that answer. Or you can say, well, there is no reality. And infinite sets are kind of human constructs anyway, so we can make them kind of play out any way we like. Mathematicians argue about that to this day. And it is, as I say, really, it's a philosophical question. But just out of curiosity, let's see how you guys end up deciding on that one. So here is the poll. 5 seconds to go. Please vote. And we're going to end the polling, 1, 2, 3, now. All right, here we go. So there's no right answer. I think if most mathematicians were to, I think, the instinct of most logicians, especially, I'm not sure if general mathematicians really even care about this question, but logicians would probably have an instinct that, probably, there are sets in between. There's no reason that there shouldn't be. It seems kind of strange that there should be this sort of jump from the natural numbers to the real numbers and why nothing in between? But I don't think that question is really settled. All right, let's continue on.","The collection of all possible Turing machines is countable, while the collection of all languages is uncountable. This means there are more languages than Turing machines, leading to the conclusion that some languages are not decidable by any Turing machine.",valid,Basic,18.404J,8 Undecidability,3PzuSPQPEU4.en-j3PyPqV-e1s_7_mp4
34,What does showing a one-to-one correspondence between languages and real numbers illustrate?,"So there are a number of corollaries that follow from the statement that the real numbers is uncountable. First of all, if you let script L be the collection of all languages, if you want to consider it over some particular alphabet, that's fine. But that's not going to be really important for this point that I'm going to make. So script L is the collection of all languages. So every subset of sigma star-- every subset of sigma star is a language. So look at all those possible subsets. So that includes 0 to the k, 1 to the k, plus every other language you can ever think of and more-- all possible languages. So the collection of all languages is uncountable. There's uncountably many different languages out there. I don't want to belabor this point. You can just take this if you don't quite follow the quick argument I'm going to make here. But you can make a one-to-one correspondence from all languages to the reals so that each language gets its own real number. And the way I'm going to think about that-- let's put the real numbers into binary form. And if you imagine here being sigma star, all of the possible strings of sigma star written out in their standard order. And now if you have a language here, A, it's just some arbitrary language. So that's going to have some of the strings of sigma star appearing. Like 0 is appearing, but 1 is not appearing. 00 is appearing and 01, but not these three. And I'm going to associate to A, my language, some real number in binary by putting in a 0 in the decimal representation-- well, the binary representation, I should say-- for that string if it's not there and a 1 if it is there. And so a real number-- because there's infinitely many yes/no choices in the binary representation can represent a language because of each of the yes/no choices of a string being present or not. I'm going to put a 1 for when the string is present, a 0 when it's not present. So each language has its own real number, and each real number is going to be associated to its own language. Here, I'm restricting myself to real numbers between 0 and 1. That's not going to be an essential point. So let's not get hung up on that. So the fact that the languages can be putting it into a one-to-one correspondence with the real numbers shows that the collection of all languages is also uncountable. Now another observation here-- another point worth noting is that if you look at sigma star itself, the strings, all possible strings, that's a countable set. The collection of all possible languages is uncountable. But the collection of all possible finite strings is countable because I can just list them. Here's my list of all possible strings, which you can put into a table if you like to think of it matching up with the natural numbers in that way. Now I'm trying to make a point here, which is that if you take M, which is all possible Turing machines-- script M is all possible Turing machines-- the collection of all possible Turing machines is countable. There are only countably many different Turing machines. And you can argue that in all sorts of messy different ways. But I think the most simple way to see that is to think about each Turing machine as having a description, which is a string. So the collection of all descriptions of Turing machines is just a subset of sigma star, which we already know is countable. And the subset of any countable set is going to be countable. So anyway, I think it's worth remembering that the collection of old Turing machines is countable. Whereas the collection of all languages is uncountable. And that tells you right there that some language is not decided because there are more languages than Turing machines. We've unaccountably many language, only countably many Turing machines, so that's fewer Turing machines than languages. There's no way to map all the languages onto Turing machines. So there's going to always be some languages that got unmapped. And so, in particular, there are going to be some languages which are undecidable. There are going to be some languages which are not Turing-recognizable. And anything based on some automata kind of a definition process is going to be some languages that they're not going to be defined. OK, now what this corollary shows you that there is some language out there, which is not decidable. What we're going to show next is that there is a specific language-- A,TM-- which is not decidable. And but first, I think we have a check-in coming up. And let me give you a little bit of background here because this is relevant to this question that I got about intermediate size sets. So the question of whether there is a set of size between the natural numbers and the real numbers strictly in between-- so bigger than the natural numbers, not the same size as the natural numbers, but not the same size as the real numbers either, but in between in size. That was Hilbert's question number 1 out of his list of 23 that I talked about a few lectures back. It's interesting that he put it as number 1 in that very privileged special place because I know Hilbert was very-- he felt that the understanding infinity was a really central issue in mathematics. And that if we can't answer a question like this, we don't really understand infinity. You want to understand what kind of sizes of infinities are there. We know there's the real number is bigger than the natural numbers. Is there something in between? So fundamental, really. But it was shown during the course of the 20th century, really, in two separate steps-- one in the 1930s by Godel, one in the early 1970s by Cohen-- that we can't answer this question by using the standard axioms of mathematics. The answer can go either way. And both of them are consistent with the axes mathematics. So you're never going to be able to prove that there is a set whose size is in between or that there is no such set. It's just impossible to prove either way using the standard axiom of mathematics, which, actually, is kind of remarkable. And so my question for you is-- and this is really a philosophical question, not one that is directly you need to know about material in the course. I think it's just a matter of your own interest. I hope you find it interesting. If you don't, you can just answer it randomly. But what's going on here that we can't answer that question about whether there is a set of intermediate size? Is it because our axioms for mathematics are inadequate? Or maybe there is no such thing as a mathematical reality. You can talk about what's real here? What's the reality? Either there is a set in between or not. If you can imagine, all of these things have their own reality to them, well, then, there's going to be an answer. And then you would expect, well, maybe we can find better axioms, which will actually give us that answer. Or you can say, well, there is no reality. And infinite sets are kind of human constructs anyway, so we can make them kind of play out any way we like. Mathematicians argue about that to this day. And it is, as I say, really, it's a philosophical question. But just out of curiosity, let's see how you guys end up deciding on that one. So here is the poll. 5 seconds to go. Please vote. And we're going to end the polling, 1, 2, 3, now. All right, here we go. So there's no right answer. I think if most mathematicians were to, I think, the instinct of most logicians, especially, I'm not sure if general mathematicians really even care about this question, but logicians would probably have an instinct that, probably, there are sets in between. There's no reason that there shouldn't be. It seems kind of strange that there should be this sort of jump from the natural numbers to the real numbers and why nothing in between? But I don't think that question is really settled. All right, let's continue on.",Showing a one-to-one correspondence between languages and real numbers illustrates that the collection of all languages is uncountable.,valid,Basic,18.404J,8 Undecidability,3PzuSPQPEU4.en-j3PyPqV-e1s_7_mp4
35,What defines a Context Free Grammar (CFG)?,"is called a derivati 
for so 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
   
 
 
 
 
 
   
 
 
 
 
 
 
 
 
  
  
   
   
 
 
 
 
   
 
 
 
 
 
  
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
!
ution steps in !
on of - from ,. 
me CFG !. 
CFG – Formal Definition 
Defn: A Context Free Grammar (CFG) ! is a 4-tuple (#, Σ, &, ') 
# finite set of variables 
Σ finite set of terminal symbols 
& finite set of rules (rule form: # → # ∪Σ ∗ )
' start variable 
For ,, - ∈ # ∪Σ ∗ write 
Check-in 4.1 
1) , ⇒ ­ if can go from , to - with one substitution step in Which of these are valid CFGs? 
∗ 
2) , ⇒ - if can go from , to - with some number of substit 
90: 
B → 0B1 | ε 
91: 
S → 0S | S1 
, ⇒,0 ⇒,1 ⇒⋯⇒,3 = -
B1 → 1B 
R → RR 
If , = ' then it is a derivation of -. 
0B → 0B 
∗ 
a) 90 only 
5 ! = 6 6 ∈Σ∗ and ' ⇒ 6} 
b) 91 only 
Defn: 8 is a Context Free Language (CFL) if 8 = 5(!) 
c) Both 90 and 91 
d) Neither 
Check-in 4.1 
3 
","A Context Free Grammar (CFG) is a 4-tuple (#, Σ, &, '), where # is a finite set of variables, Σ is a finite set of terminal symbols, & is a finite set of rules (rule form: # → # ∪Σ ∗ ), and ' is the start variable.",valid,Basic,18.404J,"Lecture 4 - Pushdown Automata, CFG ↔ PDA",a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_3_pdf
36,What is the role of the verifier in an interactive proof system?," 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
  
  
 
 
 
 
 
 
 
 
 
  
 
  
 
 
   
 
  
 
 
 
 
 
 
  
   
   
 
 
  
  
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
Interactive Proofs – formal model 
Two interacting parties 
Verifier (V): Probabilistic polynomial time TM 
Prover (P): Unlimited computational power 
Both P and V see input !. 
They exchange a polynomial number of polynomial-size messages. 
Then V accepts or rejects. 
Defn: Pr[ (V ↔ P) accepts ! ] = probability that V accepts when V interacts with P, given input !. 
Defn: IP = $ for some V and P (This P is an “honest” prover) 
! ∈$ → Pr [ (V ↔ P) accepts ! ] ≥ )⁄* 
! ∉$ → for any prover P, Pr [ (V ↔ P) 
, accepts ! ] ≤ .⁄* 
Think of ,P as a “crooked” prover trying to make V accept when it shouldn’t. 
An amplification lemma can improve the error probability from .⁄* to ./)0123 4 
5 
",The verifier in an interactive proof system is a probabilistic polynomial time Turing machine (TM) that exchanges polynomial-size messages with the prover and ultimately decides to accept or reject the input.,valid,Basic,18.404J,"Lecture 25 - Interactive Proof Systems, IP",fe9281999e2d720710e4b58de72aa7e0_MIT18_404f20_lec25_5_pdf
37,What does it mean for a set to be T-recognizable in the context of showing that ! is T-recognizable iff there is a decidable set related to a collection of string pairs?,"Problem Set 2 
#5)  Show ! is T-recognizable  iff  there is a decidable "" where 
! =
$ ∃&
$, & ∈"" }
$, & ∈Σ∗
〈$, &〉is an encoding of the pair of strings $ and & into a single string.  
Think of "" as a collection of pairs of strings.
$-axis
&-axis
($, &)
""
!
! is a “projection” of ""
$
10
","A set is T-recognizable if there exists a Turing machine that will halt and accept for any string in the set, but may either reject or loop forever for strings not in the set. The statement '! is T-recognizable iff there is a decidable set' implies that there is a relationship between the T-recognizability of '!' and the decidability of a set derived from pairs of strings, where the set are projections of '!'.",valid,Intermediate,18.404J,"Lecture 6 - TM Variants, Church‑Turing Thesis",7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_10_pdf
38,"Which of the following statements about BPP and complexity classes are known to be true: BPP is closed under union, BPP is closed under complement, P ⊆ BPP, and BPP ⊆ PSPACE?","NP and BPP
Computation trees 
for ! on ""
"" ∈$
NP
≥1 accepting
Few accepting
Many rejecting
BPP
Many accepting
Few 
rejecting
all rejecting
"" ∉$
Check-in 23.1
Check-in 23.1
Which of these are known to be true?
Check all that apply.
(a) BPP is closed under union.
(b) BPP is closed under complement.
(c) P ⊆BPP
(d) BPP ⊆PSPACE
4
",(a) BPP is closed under union. (b) BPP is closed under complement. (c) P ⊆ BPP. (d) BPP ⊆ PSPACE.,valid,Advanced,18.404J,"Lecture 23 - Probabilistic Computation, BPP",44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_4_pdf
39,How is a regular expression converted to an equivalent NFA if it is atomic?," 
 
   
 
 
 
 
 
 
   
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Regular Expressions → NFA 
Theorem: If "" is a regular expr and # = % "" then # is regular 
Proof: Convert "" to equivalent NFA &: 
If "" is atomic: 
Equivalent & is: 
) 
Example:  
"" = ) for ) ∈Σ 
Convert a ∪ ab ∗ to equivalent NFA 
"" = ε 
a
a:
"" = ∅ 
b
b: 
a 
ε 
b 
If "" is composite: 
ab: 
a 
"" = "". ∪""/ 
a ∪ ab: 
ε 
a 
ε 
b
"" = "". ∘""/ 
Use closure constructions 
ε
}
∗ 
a ∪ ab ∗ : 
ε
"" = "". 
a
ε
ε 
a 
ε 
b
ε 
10 
ε 
","If a regular expression is atomic, the equivalent NFA is constructed directly based on the atomic elements. For example, for a regular expression consisting of a single element 'a' from the alphabet Σ, the equivalent NFA simple states are constructed with a transition based on 'a'.",valid,Intermediate,18.404J,"Lecture 2 - Nondeterminism, Closure Properties, Regular Expressions → Finite Automata",d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_10_pdf
40,What is an NP-complete problem and why is it significant?,,"An NP-complete problem is a problem that is both in NP (nondeterministic polynomial time) and as hard as any problem in NP; in other words, any NP problem can be reduced to it using a polynomial-time transformation. It is significant because solving or proving an efficient solution to an NP-complete problem would provide solutions to all problems in NP, a major unsolved question in computer science.",empty,Intermediate,18.404J,Lecture 15 - NP‑Completeness,c1aca7046a69c913721e5eb910a5fb21_MIT18_404f20_lec15_4_pdf
41,How do the labeling rules for probabilities correspond to the TRUE rows in the Boolean function truth table?,"! ""
! #
! #
0
1
0 
1
0
1
0
1
Symbolic Execution
Leave the ! $ as variables and obtain an expression in the ! $
for the output of the BP. 
1
1 −! ""
! ""
1 −! ""
1 −! #
+ (! "" ) ! #
(1 −! "" ) 1 −! #
1 −! "" (x#)
(! "" ) ! #
(! "" ) 1 −! #
1 −! ""
x#
+ (! "" ) 1 −! #
! $
0 1
+
+(1 −! $)
+! $
+""
+#
+,
+"" + +# + +,
Recall 
labeling rules:
1 −! ""
! ""
= output
=
1 −! ""
x#
,
1 −! ,
! .
⋯(1 −! 0 )
+
! ""
! #
! ,
1 −! .
⋯
! 0
+
! ""
1 −! #
1 −! ,
! .
⋯
(! 0 )
⋮
+
! ""
! #
1 −! ,
! .
⋯
(! 0 )
form of 
output
Corresponds to the TRUE rows in the 
truth table of the Boolean function
Exponents ≤1
due to “read-once”
Assume read exactly once so that for each 3
(! $) or (1 −! $) appears in every row 
8
","The labeling rules indicate that each row corresponds to the TRUE rows in the truth table of the Boolean function. Each expression in the output form, such as (1 −! $), corresponds to a variable or its negation being read exactly once, so that for each probability, either (! $) or (1 −! $) appears in every row, contributing to the output.",valid,Advanced,18.404J,Lecture 24 - Probabilistic Computation (cont.),cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_8_pdf
42,What is a self-reproduction paradox?,"OK, so today's topic is about self-reference, self-reproducing machines, and the broader topic called the recursion theorem. So let me introduce it with what I would call the self-reproduction paradox. And that is, suppose you have a factory, like a Tesla effect or a car manufacturing factory. See, there's a picture of the factory, and it's producing cars. All right? So we have a factory that makes cars. And what can we say about the relative complexity of the cars compared with the factory, in some informal sense? So I would argue that you would be reasonable to say that the complexity of the factory is going to have to be greater than the complexity of the cars that it makes. Because not only does the factory have to know how to make the cars, so it has to have all the instructions and whatever things that go into a car, it has to be included in at least some kind of-- it has to be, in some sense, represented in the factory. But the factory also has to have other stuff-- the robots, and the other manufacturing items, tools, and so on-- for making the cars. So the factory has to have all the complexity of a car incorporated plus other things as well. And for that reason, one could imagine that the factory's complexity is more than the car's complexity. But now, suppose you want to have a factory that makes factories-- so imagine here's the picture-- or in general, a machine that makes copies of itself. Well, that seems, at first glance, to be impossible. Because not only does the factory obviously have to have all of the instructions for what a factory is like, but it needs to have all of the extra things that it would need to do the manufacturing. And so for that reason, it seems like it's not possible to have a machine make copies of itself. I mean, you would run into the very same problem if I asked you to produce a program in your favorite language that prints out itself-- an exact copy of the same code. You can always write a program which is going to print out some string, like Hello, world. That's easy because you just put Hello, world into some kind of a variable or some sort of a table into the program and say print that table. But if you want the program to print out a copy of itself, you can't take the whole program and stick that into a table because the program is going to have to be bigger than the table. And so, you're going to end up with something impossible happening. Because the program-- an entire copy of the program can't fit inside the program. You just get the program inside itself, inside itself, inside itself, forever. And so, you end up with an infinite program that way. So if you just kind of naively approach the problem for how to make a program which is going to print out a copy of itself, it's not so easy to do. But hopefully, after today's lecture, you will see that it is possible and in fact, how to do it. And not only that is an idle bit of curiosity, but there are actually applications for why you might want to do that, mainly within mathematics and in computer science theory. But there's even a kind of a real-world application, if you will, in a way too. So we'll get to that at the end. So it seems, as I'm saying, impossible to have a self-reproducing machine. But we know that in the world, there are things that make copies of themselves-- living things. So it seems like a paradox. Cells can make copies exactly of themselves. All living things can make copies of themselves. So how do they manage to get around this paradox? Well, in fact, it is no paradox because it is possible to make a machine that self-reproduces, that makes copies of itself. And this has been known for many years. Probably, it goes back to Von Neumann who wrote a famous paper on self-reproducing machines. OK, so self-reproducing machines are, in fact, possible.","The self-reproduction paradox involves the idea of a factory that makes cars and the relative complexity between the factory and the cars. It questions how a factory that makes copies of factories could exist, as it seems impossible for a machine to make copies of itself because the factory would need all the instructions for what a factory is like plus extra manufacturing tools, making its complexity seem greater than what it produces.",valid,Basic,18.404J,11 Recursion Theorem and Logic,N-_XmLanPYg.en-j3PyPqV-e1s_2_mp4
43,What are the two conditions for a problem to be considered PSPACE-complete?,"≤ 
≤ 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
   
 
 
 
  
  
 
 
 
  
 
 
 
 
Why
% and not
%'%()* when defining PSPACE-complete?
- Reductions should be “weaker” than the class. Otherwise all
problems in the class would be reducible to each other, and then 
all problems in the class would be complete.
Theorem: +,!- is PSPACE-complete
PSPACE-completeness 
Defn: ! is PSPACE-complete if 
1) ! ∈ PSPACE 
2) For all # ∈ PSPACE, # ≤% ! 
If ! is PSPACE-complete and ! ∈ P then P = PSPACE. 
Check-in 18.1 
Knowing that +,!- is PSPACE-complete, 
what can we conclude if +,!- ∈ NP? 
Check all that apply. 
(a) P = PSPACE 
(b) NP = PSPACE 
(c) P = NP 
(d) NP = coNP 
5 
PSPACE-complete 
NP-complete 
PSPACE = 
NPSPACE 
NP
P 
Think of complete problems as the “hardest” 
in their associated class. 
Check-in 18.1 
","A problem is PSPACE-complete if: 1) it is in PSPACE, and 2) for all problems in PSPACE, each problem is polynomial-time reducible to it.",valid,Intermediate,18.404J,Lecture 18 - PSPACE‑Completeness,88f789664d3236a64481714fc911d119_MIT18_404f20_lec18_5_pdf
44,What was completed in relation to IP and coNP?," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
Quick review of today 
Finished #""#$ ∈ IP and coNP ⊆ IP 
Additional subjects: 
18.405/6.841 Advanced complexity F2021 
18.425/6.875 Cryptography F2021 
6.842 Randomness and Computation ? 
Good luck on the final! 
Best wishes for the holidays and the New Year! 
10 
","The completion of #""#$ ∈ IP and coNP ⊆ IP was mentioned.",administrative,Intermediate,18.404J,Lecture 26 - coNP ⊆ IP,7ac944716e076209c3964e073929f42e_MIT18_404f20_lec26_10_pdf
45,How is a configuration of a Turing machine represented as a string for proof purposes?,"OK. So now we're going to work our way up to introducing this computation history method. And first, let me define something for a Turing machine that I'm going to call a configuration. Configuration is just a snapshot of the Turing machine in the middle of its computation. So if you're running the Turing machine and you just stop it at some moment, it's going to be in a certain state, the head is going to be on a certain position, and the tape is going to have a certain contents. And with that information, you can then continue the computation of the Turing machine. That's a full set of the information that you need about the Turing machine that tells you everything about its computation at that moment in time. The state, head position, and tape contents. And so that, we're calling that information together, state, head position, tape contents, we're calling that a configuration. Fairly basic notion. I mean, if your program-- if you have something-- if you have the states of all the variables and where the current execution of the program is at a moment in time, same idea. OK. So in terms of a picture here, here is the Turing machine. Imagine it's in state q3. The head position is in the sixth position on the tape, so p would be 6 because it's in the sixth position, and the tape contents is going to be this bunch of as followed by this bunch of bs. So I would write it down like this. State's in q3, head position number 6, this is the contents of the tape. Now, what we're going to often do for convenience in using this notion in proofs is that we're going to want to represent a configuration as a string in a particular way that's going to be-- that's going to-- this concept is going to come up kind of again and again during the course. And so it's going to be handy to have a particular way of writing down configurations for doing proofs about them. And so the way we're going to write them down is-- I think it's just maybe-- I can just put it right up here like this. We're going to write down the symbols of the tape. But what we're going to do is stick in the middle of those symbols the state of the machine immediately to the left of the position that the machine is currently reading. So you can imagine the head here, which is coming. Imagine the state is kind of where the head is. It's pointing at the symbol immediately to its right. So this is just another way of writing down a configuration. Here's the tape contents, which I'm sort of writing formally here. I'm breaking the tape contents into two parts, which I'm calling t1 and t2. This is the t1 part, the t2 part. And I'm putting the state in between t1 and t2 where I have in mind that the machine's head position is right at the beginning of t2. But maybe this picture just says it all and it's clear enough. So just keep in mind that when we're going to be writing down configurations of machines, we're typically going to write it down this way. OK, so I think this is a good moment to take a-- to take a moment for questions. Oh. I see there's a lot of questions already. So one question is, how does the encoding differentiate between the string and the state? If I'm understanding you correctly, I'm going to be assuming that the symbols that represent states and the symbols that appear on the tape are distinct from one another. So you can always tell just like usually the way we write things down when you have a state symbol or whether you have a tape symbol. And so in a configuration, you're going to have a bunch of tape symbols and a single state symbol represent in the position where the head is. Somebody says-- 6 here is just this is 1, 2, 3, 4, 5, 6. We're in head p-- the head is in position six. That's all I had in mind for 6, and that's why that 6 is appearing over there because that's the position of the head. Good. All right. So why don't we continue.","The configuration is represented by writing down the symbols of the tape and placing the state of the machine immediately to the left of the position that the machine is currently reading. This representation separates the tape into two parts, t1 and t2, with the state in between, indicating the head position is at the beginning of t2.",valid,Intermediate,18.404J,10 Computation History Method,MGqoLm2aAgc.en-j3PyPqV-e1s_5_mp4
46,What is the idea behind constructing a DFA from an NFA?," 
 
 
   
 
 
 
 
   
   
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
) ) ∈((4, 2) for some 4 ∈1}
""
)8
)9
NFA
Check-in 2.2 
If "" has : states, how many 
states does ""′ have by this 
construction? 
(a) 2: 
(b) :< 
(c) 2= 
Converting NFAs to DFAs 
Theorem: If an NFA recognizes ! then ! is regular 
Proof: Let NFA "" = (%, Σ, (, )*, +) recognize ! 
Construct DFA ""′ = (%′, Σ, (′, )*
. , +′) recognizing ! 
(Ignore the ε-transitions, can easily modify to handle them) 
IDEA: DFA ""′ keeps track of the subset of possible states in NFA "". 
""′ 
Construction of /′: 
%′ = 0 % 
{)8,)9} 
(. 1, 2 = 
1 ∈%′ 
)*
. = {q*} 
+′ = 1 ∈%. 1 intersects +} 
DFA 
Check-in 2.2 
6 
",DFA 'keeps track of the subset of possible states in NFA.',valid,Intermediate,18.404J,"Lecture 2 - Nondeterminism, Closure Properties, Regular Expressions → Finite Automata",d741901d23b4522588e267177c77d10d_MIT18_404f20_lec2_6_pdf
47,How does a probabilistic Turing machine decide a language with an error probability ε?,a uh so we're gonna start off by defining the notion of a probabilistic turing machine or ptm um a probabilistic turing machine is a lot like the way we have thought about non-deterministic touring machines in that it's a kind of a machine that can have multiple choices multiple ways to go in its computation so there's not just going to be a fixed uh deterministic path um of its computation but there's going to be a tree of possibilities um and for our purposes we're going to limit the branching in that tree to be either um a step of the computation where there's no branching where it's a deterministic step uh as shown over here um so every step of the way leads uniquely to the next step or there might be some steps which have a choice and we're only going to allow for these purposes uh to keep life simple um having only uh a choice among two possibilities um and we'll associate to that uh um the notion of a probability that each choice will have a 50 50 chance of getting taken and this kind of corresponds with the way some of us or some of you think about non-determinism which is not exactly right up and up until this point is that the machine is kind of taking a random branch it really we don't think about it randomly until now now we're going to think about the machine as actually taking sort of picking a random choice among all the different branches that it could make um and picking the choice kind of uniformly by flipping a coin every time it has an option of which way to go uh now you could define i'm getting a question here uh the uh a machine that has several different ways to more than two ways to go and then you would need to have a three-way coin a four-way coin and so on and you could define it all of that that way as well but it doesn't end up giving you anything different or anything uh interesting or new for uh for the kinds of things we're going to be discussing so and it's just going to be simpler to keep the discussion limited to the case where the machine can only have two possibilities um if it's going to be having a choice at all or or just one possibility when there's no choice okay so um so now we're going to have to talk about the probability of a the machine taking a sum branch of its computation so you imagine here here is the same computation tree that we've seen before in the case of ordinary non-deterministic machines where you have m on w there could be several different ways to go and there might be some particular branch but now we want to talk about the probability that the machine actually ends up picking that branch and it's going to be um uh you know when we talk about uh the machine having a choice of ways to go we're going to associate that with a coin flip so we're going to call that a coin flip step when the machine has a possibility of ways to go and so on a particular branch the probability of that branch occurring is going to be one over two to the number of coin flips coin flip states on that branch and the reason for i mean this is kind of the the the definition that makes sense um in that if you imagine looking at the computation tree here and here is the branch that we're focusing on um of interest every time there's a coin flip on that branch there's a 50 50 chance of taking a different branch or staying on that branch so the more coin flips there are on some particular branch the less likely that branch would be the one that the machine actually actually ends up taking taking and so it's going to be one over two to the number of coin flips and that's the way we're defining it now once we have that notion we can also talk about the probability that the machine ends up accepting because each as before each of these branches is going to end up at an accept state or reject state i'm thinking about this only in terms of deciders and the probability of the machine accepting here is just going to be the sum over all probabilities of the branches that end up accepting so just add up all of those probabilities of a branch leading to an accept and we'll call that the probability that the machine accepts its input [Music] and the probability that the machine rejects is going to be one minus the probability that it accepts because it's going to the machine um on every branch is either either going to do one or the other okay um now if you're thinking about a particular language that the machine is trying to decide this probabilistic machine now is trying to decide um you know on on each input some of the branches of the machine may not may give the correct answer they're going to accept when the input is in the language other branches may give the wrong answer they may reject when the input is in the language and vice versa so there's going to be a possibility of error now in the machine in any particular branch it might actually give the wrong answer and what we're going to say is bound that error over all possible inputs um and so and uh we'll say that the machine for any epsilon greater than or equal to zero um we will say that the machine decides the language with error probability epsilon if that's the worst that can possibly happen you know if every um for every input the machine gives the wrong answer with probability at most epsilon um equivalently if you like to spell it out a little bit more you know a little differently for strings that are in the language the probability that the machine rejects that input is going to be at most epsilon and for strings in the language the probability of for strings not in the language the probability that accepts is a most epsilon so again this is the machine doing the the thing that it's not supposed to be doing for things in the language it should be rejecting very rarely for things not in the language it should be accepting very rarely and that's what this bound is doing for you okay um [Music] so let's just see uh so we'll talk about so i'm getting some questions here about um um so let me just look at these one second here the yeah so probability zero so there's a possibility that the machine have might have a probability zero say of accepting that means there are no branches that end up accepting or probability zero of rejecting there were no rejecting branches um but i think we're going to talk in a minute about the connection between this and and the standard notion of np um so just hold off on that for a second uh also about what what about the you know the um the possibility that the machine is you know being a decider or running in a certain amount of time um so we will look at time-bounded machines in a second um on the next slide or two um talking about machines that run in polynomial time so that means all branches have to halt within some polynomial number of steps um so that's where we're going but for the time being we're only looking at the siders where the machine has to hold on every branch but some branches might run for a long time but for now we're not going to be thinking about machines that have branches that run um forever where all of our machines are deciders so they they hold on every,"A probabilistic Turing machine decides a language with an error probability ε by ensuring that for every input, the probability of the machine giving the wrong answer is at most ε. For strings in the language, the probability that the machine rejects that input is at most ε, and for strings not in the language, the probability that it accepts is at most ε. This means the machine is doing what it's not supposed to very rarely.",valid,Advanced,18.404J,23 Probabilistic Computation BPP,Vp_AzDGQyrA.en_2_mp4
48,What is the role of the start variable in generating strings from a context-free grammar (CFG)?," 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
0 S 1
0 S 1
R
ε
0S1
00S11
00R11
0011
Context Free Grammars (CFGs) 
#% 
Shorthand: 
S → 0S1 
S → R
S → 0S1 | R 
R →ε 
R →ε 
Recall that a CFG has terminals, variables, and rules. 
Example of #% generating a string 
Grammars generate strings 
1. 
Write down start variable 
Tree of 
S
S 
Resulting 
string 
“parse tree” 
2. 
Replace any variable according to a rule 
substitutions 
Repeat until only terminals remain 
3. 
Result is the generated string 
4. 
!(#) is the language of all generated strings 
5. 
We call !(#) a Context Free Language. 
∈! #%
! #% = 0*1* , ≥0} 
2 
","The start variable in a context-free grammar (CFG) serves as the initial symbol from which string generation begins. The process involves writing down the start variable, and then repeatedly replacing any variable according to a rule, continuing these substitutions until only terminals remain. The result is the generated string, and the language of all such generated strings is a Context Free Language.",valid,Advanced,18.404J,"Lecture 4 - Pushdown Automata, CFG ↔ PDA",a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_2_pdf
49,How do the action and template parts differ in an English sentence compared to a Turing machine when applying the recursion theorem?,"And basically it says, so really what we're doing here is called the recursion theorem, as you'll see. We'll actually present the recursion theorem formally on the next slide. But here, in both of these cases, we kind of have a template part and an action part. In both cases, there are two parts to the instructions, the template and the action. OK? So I'm going to leave it to you to try to imagine which of those is which, in each of these two examples. And then, I'm going to ask you to pick. In the Turing machine, which is the action and which is the template, and in the sentence, which is the action and which is the template. The action is the part where there's some interesting sort of instructional stuff happening that you have to carry out. The template is really basically just text or just a string. So let me pull up that poll. See what you think. Because I'm asking you now to indicate where is the action part in both of those cases. What is the upper phrase and lower phrase? I mean, of this sentence here. So write the following twice. This is the upper phrase. And the part in quotations is the lower phrase-- sorry. OK, almost done here? 5 seconds-- a few of you have not answered yet. Answer it. One second to go. OK, here we go, ending polling. So the majority here is correct. I would say, in the English sentence here, the action part is the first part. That's where you actually have been directed to do something. The second half of the sentence, the lower part of the sentence, is just a template written. This is just some string here. There's no action really being directed. It happens to be the same as the top, but this could have been just Hello World. This could have been anything. And then the upper part acts on that. So the upper part is the action part. So it's the upper phrase that's the relevant part. Now, in the Turing machine, in a sense, it's the other way around. The first part is really just the template. The second part, B, is where you're doing some actual work on the template. You're taking that, basically text, which could be anything. A could be anything. And you're looking at that template and reconstructing what A was from that string that appears on the tape. So B is actually the one that's doing the work. So it's B and the upper phrase with part c is correct. So let us continue then. Oh, I want to mention here problem 6 on the Pset. So your job really is to implement this in-- if you have a programming language that you like-- it could be Python or whatever your favorite Java, whatever you like-- you can implement this. If you don't know any programming languages, then just make up some sort of pseudo programming language and implement it there. Let me point out that getting the quoting right is a bit of a pain because you have to kind of escape the quotes and so on. I'm not going to be fussy about that. So you can still get full credit even if you don't get the quoting part quite correct. Do your best. I think it's an interesting problem to try to solve. And if you struggle with it for a while, it's slippery. It's the kind of thing you can easily spend a couple of hours on this problem. Because it's a bit tricky to manage to make a program which prints itself out, which is what the task of problem is on the Pset. But don't fuss about too much on the quoting if that's the only thing that's hanging you up. Try to get the main structure of it, which is fairly simple, actually. And if you can't get the quoting part to work, I'll ask the graders not to penalize you for that part.","In the English sentence, the action part is the first part where one is directed to do something, and the second half of the sentence is just a template or string. In a Turing machine, it is the reverse: the first part is just the template, whereas the second part is where actual work is done on the template. This distinction highlights the difference in how the recursion theorem applies.",valid,Advanced,18.404J,11 Recursion Theorem and Logic,N-_XmLanPYg.en-j3PyPqV-e1s_6_mp4
52,How can non-Boolean assignments be used in an IP protocol to demonstrate coNP problems?," 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
    
 
 
Idea for fixing #""#$ ∈ IP protocol 
)
) 
=
= 
#& 
#& 
+ 
#& 0 
#& 1 
#& ,-
+
+ 
Non-Boolean assignments 
to the variables of & 
#& 00 
#& 01 
#& 10 
#& 11 
#& ,-,. 
+ 
+
+
+ 
⋮
⋮ 
⋮ 
#& 0 ⋯0 
⋯ 
#& 1 ⋯1 
#& ,- ⋯,/ 
& 0 ⋯ 0
=
⋯ 
=
& 1 ⋯ 1 
=
& ,- ⋯,/ 
5 
","The protocol involves creating non-Boolean assignments to the variables of & in a systematic manner: start with #& 00, then #& 01, #& 10, #& 11, and continue this pattern. The pattern is represented as #& 0 ... 0 to #& 1 ... 1 in sequence, and each non-Boolean assignment is systematically checked to ensure they satisfy certain conditions within the protocol.",valid,Advanced,18.404J,Lecture 26 - coNP ⊆ IP,7ac944716e076209c3964e073929f42e_MIT18_404f20_lec26_5_pdf
53,What is the significance of the star operation in set operations for languages?,"And the last of the regular operations is the so-called star operation, which is a unary operation. It applies to just a single language. And so what you do is now you're going to take-- to get a member of the star language, you're going to take a bunch of strings in the original language, A, you stick them together. Any number of members of A, you stick them together, and that becomes an element of the star language. And we'll do an example in a second if you didn't get that. But one important element is that when you have the star language, you can also allow it to stick zero elements together, and then you get the empty string. So that's always a member of the star language, the empty string. OK, so let's look at some examples. Let's say A is the language-- these are two strings here-- good, bad. And B is the language boy, girl. Now, if we take the union of those two, we get good, bad, boy, girl. That's kind of what you'd expect. And now let's take a look at the concatenation. Now, if you concatenate the A and the B language, you're going to get all possible ways of having an A string followed by all possible ways of having a B string. So you can get goodboy, goodgirl, badboy, badgirl. Now, looking at the star, well, that applies to just one language. So let's say it's the good, bad language from A. And so the A star that you get from that is all possible ways of sticking together the strings from A. So using no strings, you always get the empty string. That's always guaranteed to be a member of A. And then just taking one element of A, you get good, or another element, bad. But now two elements of A, you get goodgood or goodbad, and so on. Or three elements of A, goodgoodgood, goodgoodbad. And so, in fact, A star is going to be an infinite language if A itself contains any non-empty member. So if A is the empty language or if A contains just the language empty string, then A star will be not an infinite language. It'll just be the language empty string. But otherwise, it'll be an infinite language. I'm not even sure-- OK. I'm not-- [LAUGHS] I'm ignoring the chat here. I'm hoping people are getting-- are you guys are getting your questions answered by our TAs? How are we doing, Thomas? AUDIENCE: One question is, are the slides going to be posted? MICHAEL SIPSER: Are the slides going to be posted? Well, the whole lecture is going to be recorded. Is it helpful to have the slides separately? I can post the slides. Sure. Remind me if I don't, but I'll try to do that. Yes, it is helpful. I will do that. Yeah. Yeah, I will post the slides. Just, Thomas, it's your job to remind me. AUDIENCE: OK. MICHAEL SIPSER: All right, good. So we talked about the regular operations. Let's talk about the regular expressions. So regular expressions are-- just like you have the arithmetical operations, then you can get arithmetical expressions, like 1 plus 3 times 7. So now we're going to make expressions out of these operations. First of all, you have, the more atomic things, the building blocks of the expressions, which are going to be like elements of sigma, elements of the alphabet or the sigma itself as an alphabet symbol, or the empty language or the empty string. These are going to be the building blocks for the regular expressions. We'll do an example in a second. And then you combine those basic elements using the regular operations of union, concatenation, and star. So these are the atomic expressions, these are the composite expressions. So, for example, if you look at the expression 0 union 1 star-- so we can also write that as sigma star. Because if sigma is 0 and 1, then sigma star is the same thing as 0 union 1-- sigma is the same as 0 union 1. And that just gives all possible strings over sigma. So this is something you're going to see frequently. Sigma star means this is the language of all strings over the alphabet we're working with at that moment. Now, if you take sigma star 1, you just concatenate 1 onto all of the elements of sigma star, and that's going to give you all strings that end with a 1. Technically, you might imagine writing this with braces around the 1, but generally, we don't do that. We just-- single element sets, single element strings, we write without the braces, because it's clear enough without them, and it gets messy with them. So sigma star 1 is all strings that end with 1. Or, for example, you take sigma star 11 sigma star, that is all strings that contain 11. And we already saw that language once before. That's the language of that other machine that we presented one or two slides back. OK? Right. Yeah, but in terms of readings-- by the way, sorry, I don't know if it's helpful to you for me to do these interjections-- but the readings are listed also on the homework. So if you look at the posted homework 1, it tells you which chapters you should be reading now. And also, if you look at the course schedule, which is also on the home page, it has the whole course plan and which readings are for which dates. So it's all there for you. And so our goal here-- this is not an accident that sigma star 11 sigma star happens to be the same language as we saw before from the language of that finite automaton M1. In fact, that's a general phenomenon. Anything you can do with a regular expression, you can also do with a finite automaton and vice versa. They are equivalent in power with respect to the class of languages they describe. And we'll prove that. OK? So if you step back for a second and just let yourself appreciate this, it's kind of an amazing thing. Because finite automata, with the states and transitions, and the regular expressions, with these operations of union, concatenation, and star, they look totally different from one another. They look like they have nothing to do with one another. But, in fact, they both describe exactly the regular languages, the same class of languages. And so it's kind of a cool fact that you can prove, that these two very different looking systems actually are equivalent to one another. Can we get empty string from empty set? Yeah. There are a bunch of exotic cases, by the way. So empty language star is the language which has just the empty string. If you don't get that, chew on that one. But that is true.","The star operation, or Kleene star, is significant because it allows for the creation of all possible concatenations of strings from an original language, including the concatenation of zero strings, which results in the inclusion of the empty string in the language. A star applied to a language creates an infinite language if the original language contains any non-empty string.",valid,Intermediate,18.404J,1 Introduction Finite Automata Regular Expressions,9syvZr-9xwk.en-j3PyPqV-e1s_10_mp4
54,What is the essence of the hierarchy theorems in the context of computational resources?,"[SQUEAKING] [RUSTLING] [CLICKING] MICHAEL SIPSER: Welcome, everyone. Welcome back to theory of computation. And just to recap where we are, we have been looking at time complexity and space complexity. And we just finished proving what are called the hierarchy theorems, which, in a nutshell, basically say that, if you allow the computational model to have a little bit more resource, a little bit more time, a little bit more space, then you can do more things with certain conditions. So we proved that last time. It was a proof, basically, by a diagonalization. I don't know if you recognized the diagonalization there, but when you're encoding a machine by an input and then basically running all possible different machines, that's essentially a diagonalization. So today, we're going to build on that work to give an example of what we call a natural intractable problem. We'll say a bit more about what that means. And then, we're going to talk about something which is a different topic, but nevertheless related, having to do with oracles and methods which may or may not work to solve the P versus NP problem, which, of course, is","The hierarchy theorems essentially state that, if you allow the computational model to have a little bit more resource, a little bit more time, or a little bit more space, then you can do more things, given certain conditions.",valid,Advanced,18.404J,22 Provably Intractable Problems Oracles,N32bnUliSzo.en-j3PyPqV-e1s_1_mp4
55,What is computability theory concerned with?,"So let me just tell you what the course is about. Basically, it's going to be in two halves. We're going to be talking about what are the capabilities and limitations of computers-- of computer algorithms, really, computation. And the two parts of the course are more or less divided in half. The first half of the course is going to talk about a subject called computability theory, which it really asks what you can compute with an algorithm in principle. That's-- was an active area of research in the earlier part of the 20th century. It's pretty much closed off as a research subject these days, mainly because they answered all of their big questions. And so a mathematical field really only stays vital when it has problems to solve, and they really solved all of their interesting problems-- for the most part, not 100%. But for the most part, it sort of finished off in the 1950s-- just to say a little bit more about what we're going to talk about there. When you're interested to know what kinds of problems you can solve with an algorithm-- there are problems that you might want to solve that you just can't solve. For example, given a specification for a computer problem you want to solve, whatever that specification might be-- say your algorithm actually is a sorting algorithm, for example-- and you want to write down that specification and have an automatic verifier that's going to check whether a program meets the specification. Well, that's just in principle impossible. You cannot make a verifier which is going to answer, in all cases, whether or not a program meets a certain specification. So with things like that, we will prove this semester. Questions about mathematical truth-- if you're given a mathematical statement, is it true or is it false? It'd be great if you can write a computer program that would answer that problem. Well, it would not be great if you were a mathematician, because that would put us all out of business. But you can imagine that might be a nice thing to have, but you can't. I mean, there is no algorithm which can answer that question. Well, along the way, we're going to introduce models of computation, like finite automata, which we'll see today, Turing machines, and some other models that we'll see along the way. The second half of the course, which is going to be after the midterm, we're going to shift gears and talk about complexity theory, which is instead of looking at what's computable in principle, you're going to look at what's computable in practice, so things that you can solve in a reasonable amount of time. And, for example, I'm sure many of you are aware of the factoring problem, which has connections to the RSA cryptosystem, cryptography, and asks whether you can factor big numbers quickly. That's a problem we don't know the answer to. We just don't know how to factor big numbers quickly. But it's possible that there are algorithms out there that we haven't discovered yet that can do so. It's connected with this very famous problem in the intersection of computer science and mathematics called the P versus NP problem, which many of you may have heard of. We'll talk about that. We'll spend a lot of time on that this term. And along the way, we'll talk about different measures of complexity, of computation, time and space, time and memory, theoretical memory, electrical space. That's going to be a big part of the course in the complexity theory part-- introduce other models of computation,","Computability theory is concerned with what you can compute with an algorithm in principle, which includes asking what kinds of problems you can solve with an algorithm. It deals with the capabilities and limitations of computer algorithms and addresses questions about whether certain problems can be solved computationally.",valid,Intermediate,18.404J,1 Introduction Finite Automata Regular Expressions,9syvZr-9xwk.en-j3PyPqV-e1s_2_mp4
56,Why is it impossible to determine whether a machine is looping or just taking a long time?,"tell if the machine is looping or if it's really just taking a very long time? You can't. That's what we're going to prove not in today's lecture, but going to prove that on Thursday. You just can't tell. So if that's in reference to problem 5, you're going to have to find some other way of doing-- solving that problem without knowing whether the machine is actually ever going to halt.","Because it is a decision problem that will be proved as unsolvable, meaning you can't tell if the machine will halt or not.",valid,Intermediate,18.404J,7 Decision Problems for Automata and Grammars,4MgN6uxd4i4.en-j3PyPqV-e1s_3_mp4
57,What is the definition of TIME \( f(n) \) and how does it relate to deterministic 1-tape Turing Machines?," 
 
   
  
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
. . .
TIME 2;
. . .
TIME Complexity Classes 
Defn: Let !: ℕ→ℕ. Say TM % runs in time !(') if
% always halts within !(') steps on all inputs of length '. 
Defn: TIME ! ' 
= {+| some deterministic 1-tape TM % decides + 
and % runs in time - ! ' } 
Example: 
Check-in 12.2 
/ = a0b0 
< ∈ a, b ∗}. 
What is the smallest function ! 
TIME '9 
such that + ∈ TIME ! ' 
? 
1 ≥0 ∈ TIME ' log ' 
Let + = <<ℛ 
TIME '8 
TIME ' log ' 
(a) -(') 
Regular 
/ 
(b) - ' log ' 
languages 
(c) -('8) 
(d) - '9 
Check-in 12.2 
7 
","TIME \( f(n) \) is defined as the set of languages that are decided by a deterministic 1-tape Turing machine which runs in time \( f(n) \). Specifically, if a Turing machine \( M \) runs in time \( f(n) \), it means \( M \) halts within \( f(n) \) steps on all inputs of length \( n \).",valid,Advanced,18.404J,Lecture 12 - Time Complexity,7278be637b3ba371d16c9dd574705e23_MIT18_404f20_lec12_7_pdf
58,What is the relationship between the strings 23 and 25 in the provided reduction?," 
 
 
  
 
  
 
 
 
 
  
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Pad all configurations with blanks
to have length 2 -.
2
Showing ! ≤# $%&'(↑ 
Theorem:  $%&'(↑ is EXPSPACE-complete 
Proof continued: Let ! ∈ EXPSPACE decided by TM + in space 2 -. . 
Give a polynomial-time reduction / mapping ! to $%&'(↑. 
/ 0 = 23, 25
0 ∈! iff 6 23 = 6 25 
Construct 23 so that 6 23 
all strings except a rejecting computation history for + on 0.
= 
Construct 25 = Δ∗ ( Δ is the alphabet for computation histories, i.e., Δ = Γ ∪% ∪ # ) • 
…
˽ 
˽ 
ababa 
abababa
IJ0305 ⋯0-
# 
⋯ 
# 
⋯ 
# 
⋯Ireject ⋯ 
Q3 = Qstart 
Q5 
Qreject 
Check-in 22.2 
Roughly estimate the size of 
the rejecting computation 
history for + on 0. 
(a) 2-
(c) 25 T. 
(b) 2 -. 
Check-in 22.2 
5 
23 construction: 23 = 2<=>?@A=BA ∪ 2<=>?CDEF ∪ 2<=>?BFGFHA 
Rejecting computation history for + on 0: 
2 -. 
2 -. 
-. 
",The string 0 is in the language if and only if 6 23 equals 6 25.,invalid,Basic,18.404J,"Lecture 22 - Provably Intractable Problems, Oracles",50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_5_pdf
59,What prevents Savitch's theorem from working with less than log n space?,"Why does Savitch's theorem work for log n? You have to look back and see what you needed. And all you needed to be able to do was to write down the configurations. And if you look back at how Savitch's film works, you're just needing to write down the configuration. So the deterministic machine can write down the configurations for the nondeterministic machine. They take exactly the same size. And then you look at the recursion. And the depth of the recursion is going to be exponential in the size of the configurations. And so you're going to end up with a squaring again. You have to go back and just rethink that proof. And you'll see nowhere did it need a linear amount of space. It works down to-- it actually does not work for less than log n. Log n is sort of the lower threshold there. And the reason for that is because you also need to store the input location, and that already takes log space. The tape heads-- the tape heads already kind have kind of a log space aspect to them. And so if you're going to use less than log space, then funky things happen with storing the tape heads. And so less than log space usually turns out not to be interesting, very specific to Turing machines and not general models. Yeah, so somebody's asking, suppose in the reduction to generalized geography from TQBF, if the formula had two Exists in a row, then you would do kind of the natural thing in the graph. Instead of having that spacer edge between the two diamonds, you could just have one diamond connecting directly to the other diamond without a spacer edge. And that would give you the effect of not switching whose turn it is. Somebody is asking me just a general question, are people thinking about these open problems? I don't know. People don't say. There was a lot of work on problems related, that seemed to be related to those many open questions, like P versus NP, L versus NL or L versus P and so on, P versus PSPACE. We'll talk a little bit more about some of that. There's some very interesting things that have been developed. I think there's a sense within the community that people are stuck, and you're going to need some sort of major new idea in order to push the thing forward. So I don't know how many people are still thinking about them. I hope people are because I would like to see the answer at some point, or get the answer. I think about them sometimes myself, but one has to acknowledge chances of success are not high. So we're a little after past the end of the hour here. Unless there's any other questions, if I didn't answer your question, I may have missed it, so you can ask again. But otherwise, I'm going to close this, close the session here. OK, bye-bye all. Have a good weekend. See you next week. Take care.","Savitch's theorem does not work for less than log n space because storing the input location requires log space, and the tape heads inherently have a log space aspect. If you use less than log space, issues arise with storing the tape heads, making less than log space not generally applicable or interesting for Turing machines.",valid,Advanced,18.404J,19 Games Generalized Geography,4dFPVJrNLDs.en-j3PyPqV-e1s_12_mp4
60,What is a Generalized Nondeterministic Finite Automaton (GNFA) and how does it differ from a standard NFA in terms of transition labels?," 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Generalized NFA 
Defn: A Generalized Nondeterministic Finite Automaton (GNFA) is 
similar to an NFA, but allows regular expressions as transition labels 
a
a ∗ b ∗ 
ab
!1 
#1 
#2 
For convenience we will assume: 
b 
ε 
- One accept state, separate from the start state 
∅ 
- One arrow from each state to each state, except 
a ∪ b 
aab 
a) only exiting the start state 
#3 
#4 
b) only entering the accept state 
ε 
We can easily modify a GNFA to have this special form. 
3 
","A Generalized Nondeterministic Finite Automaton (GNFA) is similar to an NFA, but allows regular expressions as transition labels.",valid,Intermediate,18.404J,"Lecture 3 - Regular Pumping Lemma, Finite Automata → Regular Expressions, CFGs",a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3_3_pdf
61,How does a non-deterministic log space machine compute the complement of the path problem?,okay welcome everybody so we are um here today lecture number 21 uh coming into the home stretch of the course uh i'd say probably um this last quarter of the class of the course is a bit more technical uh perhaps so a little bit more abstract some of the theorems are going to be more difficult um so i'll i'll try to work through them slowly and answer your questions but uh um you know it's i think you can expect them to find the material a bit more challenging as we started uh um [Music] uh as we started um um you know with uh this theorem last time uh uh uh non-deterministic log space being closed under complement so nl equals colonel we kind of only got about part maybe a third of the way through that so i'm going to start over with that and spend kind of the first half of the lecture today talking about that and then we're going to talk about the hierarchy theorems which are very important um uh aspect of the complexity landscape basically they tell you that if you allow you know your favorite model let's say turing machines to have more resources then they can do more things um but we'll get to that in due course okay so let us uh go back to oops reminder to myself um go back to the immerman celeb cheney uh which is that nl is equal to co nl um so as i mentioned these are going to be the same slides as last time uh and i'll just try to walk through them slowly um i hope hope i hope you i hope you uh get it but if you don't you know uh ask me at the ta's questions so we're gonna first i mean the the the the i the thing we're gonna show is that the complement of path is solvable in non-deterministic log space we already know that path is solvable in nl that's easy to do you basically just start at the start node and you guess the sequence of nodes storing only the current node in your log space working memory on the on your in your logs based work tape you guess the sequence of nodes on the different branches of the non-determinism and if you ever get to the target node t then you can accept um but how can a non-deterministic log space machine know or accept the complement of path so it would have to accept when there's no path um and that uh is a lot harder but it's a big surprise to the complexity community that it is it is true um so as we uh discussed last time we're going to talk about computing functions with a non-deterministic machine and that turns out to be a convenient way of looking at this so we're going to have non-deterministic machines that have different branches of their non-determinism you know on some input and they're supposed to compute some function value you know remaining on the tape but because of the non-determinism you can't imagine that different branches might have different function outputs well that's not allowed all branches must either report the value of the function um that we're trying to compute or they can punt basically they can reject and say well you know uh i i you know it's a basically i i don't know so all branches can must either report the correct answer or they can say i don't know and some branch must at least one branch must report an answer must report the answer um for and that's what it means to be computing a function with a non-deterministic machine and we're going to show that certain functions can be computed with non-deterministic log space machines um in particular this path function which sort of incorporates both the positive and negative of the pair both when there is a path and when there is an is not a path into into the function because the function has to answer yes when there is a path from s to t and no when there is no path from s to t okay so if you could do this you're done because um you can make a non-deterministic you could make an nl machine so if you could compute the path function you could make an nl machine which would accept whenever the function says no um and the other cases you know and if the um machine that's computing the function uh rejects you can then you'll reject as well but you accept if the function says no and so therefore you're going to be making a an nl machine which does the complement of the path problem so it's uh you know if you can compute the path function that would be great so that's what we would like to be able to do so as i mentioned we're going to have two other values that that are going to be relevant to computing the path function which is what we're ultimately going to do and that's going to be the number of nodes that you can reach from the start uh from the the start node in your graph and the and then for r is is the collection of nodes and c is the number of reachable nodes um so shown on this picture and here i'm if it's helpful to you to see it in a more form is you can think of r as a function of the graph and the start node of course but sometimes we'll just call it r you know when it's clear which graph and start node we're talking about r is the set of reachable nodes so it's the collection u such that the answer is yes and c is the size of r okay so the way we're going to start is kind of an easy theorem though this is still going to be relevant kind of at the end um but for now it's really more a practice with the concept that we have come up you know this function concept that we've just introduced so i want to say that the path function with an nl machine then i can compute the count,"To compute the complement of the path problem, a non-deterministic log space machine needs to accept when there is no path from a start node to a target node in a graph. This requires showing that the complement of the path function is solvable in non-deterministic log space. It involves having non-deterministic machines that, on different branches, should either report the correct answer or reject by saying 'I don't know,' and at least one branch must report an answer. If a machine can compute the path function that incorporates both positive and negative instances, it can be used to construct an NL machine that accepts when the function says 'no,' which corresponds to solving the complement of the problem.",valid,Advanced,18.404J,21 Hierarchy Theorems,vqFRAWeEcUs.en_1_mp4
62,What is the Gödel statement implemented in the given context?," 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
  
 
 
  
 
 
 
  
  
 
 
 
 
  
 
 
 
 
 
  
 
  
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
→TM # accepts 0 →#, 0 ∈'TM is false →!"" cannot have a
oof.
→#, 0 ∉'TM →R accepts 0 →# found a proof that !"" is true
"" is true.
A True but Unprovable Statement 
Implement Gödel statement “This statement is unprovable.” 
Let !"" be the statement #, 0 ∈ 'TM where # is the following TM: 
# = “On any input 
1. Obtain 〈#〉 and use it to obtain !"" . 
2. For each possible proof - = -., -/, … 
Test if - is a proof that !"" is true. 
If yes, then accept. Otherwise, continue.” 
Theorem: (1) !"" has no proof 
(2) !"" is true 
!"" 
Proof: 
(1) If !"" has a proof 
pr
→!
(2) If !"" is false 
12 
","The Gödel statement implemented is 'This statement is unprovable', represented as the statement !"", where !"" stands for #, 0 ∈ 'TM, defining a scenario where a Turing Machine checks the provability of its own unprovability.",invalid,Intermediate,18.404J,Lecture 11 - Recursion Theorem and Logic,779043ea724131d008eae652d703938f_MIT18_404f20_lec11_12_pdf
63,What is the key concept for understanding NP?,"So let's turn here, to trying to get an intuitive feeling for P and NP. And we'll return now to this notion of NP corresponding to easy verifiability. NP are the languages where you can easily verify membership quickly. I'll try to explain what that means. In contrast, P are the languages where you can test membership quickly. By quickly, I'm using polynomial time. That's going to be, for us, that's what quickly means in this course. In the case of the Hamiltonian path problem, the way you verify the membership is you give the path. In the case of the composites, the way you verify the membership is you give the factor. In those two cases, and in general, when we have a problem that's in NP, we think of this verification as having-- we give it a special name, called a certificate, or sometimes a short certificate, to emphasize the polynomiality of the certificate. It's like a way of proving that you're a member of the language. In the case of COMPOSITES, the proof is the factor. In the case of HAMPATH, the proof is the path, the Hamiltonian path. Contrast that, for example, if you had a prime number. Proving a number is composite is easy because you just exhibit the factor. How would you prove that a number is prime? What's the short certificate of proving that some number has no factor? That's not so obvious. In fact, there are ways of doing it, which I'm not going to get into in the case of testing of numbers prime. And now it's even known to be in P, so that's even better. But there's no obvious way of proving that a number is prime with a short certificate. This concept of being able to verify when you are a member of the language, that's key to understanding NP. That's the intuition you need to develop and hopefully take away from today's lecture, or at least","The key concept for understanding NP is the ability to verify membership in a language easily, which involves using a certificate or short certificate to prove membership. This verification is done quickly, meaning in polynomial time.",valid,Basic,18.404J,14 P and NP SAT Poly-Time Reducibility,1VhnDdQsELo.en-j3PyPqV-e1s_7_mp4
64,What are some roles of theory in computer science?," 
 
 
 
 
 
 
 
  
 
 
 
Role of Theory in Computer Science 
1. Applications 
2. Basic Research 
3. Connections to other fields 
4. What is the nature of computation? 
5 
",1. Applications 2. Basic Research 3. Connections to other fields 4. What is the nature of computation?,valid,Advanced,18.404J,"Lecture 1 - Introduction, Finite Automata, Regular Expressions",b4d9bf1573dccea21bee82cfba4224d4_MIT18_404f20_lec1_5_pdf
65,What does it mean for a language to be T-unrecognizable?,"  
  
 
 
  
 
  
  
 
   
   
  
 
   
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
!TM is T-unrecognizable 
Recall !TM = { & | & is a TM and ( & = ∅} 
Theorem: !TM is T-unrecognizable 
Proof: Show +TM ≤- !TM 
Reduction function: . &, 0 
= &1 
Recall TM &1 = “On input 3 
1.  If 3 ≠0, reject.
Explanation: 
&, 0 ∈ +TM iff &1 ∈!TM 
2. else run & on 0
& rejects 0 iff ( &1 
= ∅ 
3. Accept if & accepts.” 
+TM 
. 
!TM 
9 
",A language is T-unrecognizable if there is no Turing machine that can recognize it.,valid,Intermediate,18.404J,Lecture 9 - Reducibility,dae35894f6f5d5d09bb9fc225c664fff_MIT18_404f20_lec9_9_pdf
67,What limitation prevents the machine from writing all strings of sigma star at once?,"So that's an interesting question. So one question is because sigma has an infinite-- sigma star is infinite, if I understand this question correctly, which says it's an infinite number of strings here. How does the machine even get started because it has to go through and enumerate all of it? No, it's not first writing down all of those strings. Because yeah, you can't write down-- you can't do this infinite step of writing down all the strings. What I had in mind is you're going to take each string in turn. First you're going to take the first string on the list of sigma star, run M on that string, and then the next string in sigma star, run it on that string, and so on, string after string. And so you're never going to have infinitely many strings to deal with. It's just going to be more and more strings as you're going along. And the question I was trying to get at is whether you're going to run each one to completion before you get to the next one or you're going to kind of try to do them all in parallel, which is what you need to do to prove this there. Won't there be infinitely many wi? Yes, so there are a-- similar question. Infinitely many wi. There are infinitely many wi. But it's just an infinite loop that we're in. One by one, you're taking care of more and more wi as you're going. Let's see here. Yes. So another question is are we running all the strings in parallel? Yes, we are running all of the strings in parallel. But it's running them in parallel, but these are-- we're not defining a parallel Turing machine. It's running them in parallel using time sharing. It runs a little bit in this block, runs a little bit in that block and another block, and sort of shifts around and sort of does a few steps of each. And that's how it's getting the effect of the parallelism. Question is would the enumerator essentially have a print tape and a work tape? Yeah, you can think of it as having a print tape. However you want to formalize it. It doesn't matter. I mean, I'm being a little whimsical with attaching it to a picture of a real printer. But yeah, you think conceptually you can have a print tape. However you like to think about it is fine. How can we directly say that without knowing the program of the printer? We don't have to get into the structure of the printer. The printer is just something where you say print a string and a string comes out. That's all we know about the printer, and that's all we need to know. So there's no program for the printer. Sorry if I'm not understanding your question. But the question literally says, how can we say that without knowing the name of the printer? So if the machine is decidable, why does it have to print all strings in order? For example, if one string is shorter, can it be decided later? Well, yeah. The reason why we want-- so the question is, if the machine is decidable, why does it have to print all strings in order? Because that's what I'm asking you to do in the problem. If you read the problem, I think it's number five on the P set. That's what I'm asking you to do. That's why you have to print it in order. Otherwise you wouldn't have to worry about printing in order. It's just because I'm asking you to. OK, so I think we're out of time. Let us move back into our material.","The infinite nature of sigma star prevents the machine from writing all strings at once. Therefore, the machine takes each string in turn, running it sequentially instead of attempting to handle all at once.",invalid,Basic,18.404J,6 TM Variants Church-Turing Thesis,TTArY7ojshU.en-j3PyPqV-e1s_6_mp4
68,"How does the satisfiability problem relate to P and NP, and why is it significant in computational complexity theory?","Oh yeah. This is somehow related. And feel free to ask questions too, while you're thinking about this check-in. But the check-in says here, we've solved the A CFG problem in polynomial time. Does that tell us that every context-free language itself is also solvable in polynomial time? Just mull that over, and please give me an answer to it. I hope you do better on this check-in than you did on the last one. But anyway, why don't you go ahead and think about that. I can take some questions in the meantime. Somebody is asking here-- actually, I'm getting several questions on this. Why isn't it order n cubed or something greater than order n squared because of the variables? The variables don't depend on n. When you're given-- well, actually that's not true. No. You are right. Because the grammar is part of the input. So you might have as many as n different variables in the given grammar. So you are right. There is potentially-- the grammar might be half the size of the input, and the input to the grammar w might be half the size of the input. So I didn't think about that, but you're correct. There are potentially different numbers of variables in different grammars, so you have to add an extra factor, which would be at most the size of the input, because that's as many variables as you could possibly have. So it really should be, I think, order n cubed to take that into account as well. Plus all of the work that needs to happen in terms of dividing things up. On a one-tape Turing machine, there's going to be some extra work just to carry out some of these individual steps, because with a single tape things are sometimes a little awkward. I think the total running time is going to end up being something like n to the 4th or into the 5th on a one-tape Turing machine. But that's a good point. Somebody's saying, how can we be storing n squared strings in finite time? I'm not saying finite time. We have polynomial time. Every stage of this algorithm is allowed to run for polynomially many steps. As long as it's clearly polynomial, we can just write that down as a single stage. Part two should say-- oh. There's a typo here. So use D. Thank you. That is a typo. I'm afraid if I change it on my original slide here, things will break in some horrible way. Let's just see. Did I completely wreck my slide? No, that's good. Yeah, thank you. Good point. Oops. OK, how's our check-in doing? I think you're just about all done. Spent a lot of time on this. End polling. As you may remember from the first half of the course-- so the answer is A, indeed. Remember that we showed A CFG is decidable, and therefore each context-free language itself is decidable, just because you can plug in a specific grammar into the A CFG problem. The very same reasoning works here. If you have a context-free language, it has a grammar. You can plug that grammar into the A CFG problem. And then, that's polynomial time, you're going to get a polynomial time algorithm for that language. Good to review that. It's the same thing, same argument we used before. I don't want to spend a lot of time on this. There's another way of looking at dynamic programming. We'll talk about this again maybe in a lecture, probably next lecture, just because I you have a homework problem on it. If you've seen dynamic programming before, this is going to be easy. If you haven't seen it before, it's going to be, I think, probably a little challenging. Another way of looking at dynamic programming is the so-called bottom-up version of dynamic programming. And what that would mean is, you solve all of the subproblems first. You solve all the smaller subproblems before you solve the larger subproblems. It's here on the slide. I'm not sure I want to talk it through. But basically, you solve the subproblems here where, start with strings of length 1, and then from that you build up to subproblems with the substrings are of length 2, and then 3, and so on. And each of those only relies on the smaller previously solved subproblems. So you can, kind of in a systematic way, solve all the larger and larger subproblems for larger and larger substrings. That gives kind of a different perspective on dynamic programming. And for different problems, sometimes it's better to think about either this sort of top-down recursion based process, or the bottom-up process that I'm describing here. They're really completely equivalent. The version that's described for this particular algorithm, which appears in the textbook, is actually the bottom-up algorithm. So you shouldn't be confused if you see something there which looks somewhat different. You basically solve all possible subproblems, basically filling out a table. Let me not say anything more about that here, since we're running a little short on time. There are really two perspectives on dynamic programming. So moving on from there, let's shift gears. Leave context-free languages and dynamic programming behind. And so I'm moving toward understanding P and NP. And for that, we will introduce a new problem called the satisfiability problem. And that's one we're going to spend a lot of time on. If you tuned out a little bit during the dynamic programming discussion, time to get back on board. The satisfiability problem is going to be a computational problem that we're going to be working on. And it has to do with Boolean formula. So these are expressions, like arithmetical formula, like x plus y times z, but instead of using numerical variables, we're going to be using Boolean variables that take on Boolean values, true, false. Or sometimes represented by 1 and 0. The operators that we're going to be using are going to be the and, or, and negation operations. And, or, not. I'm going to say such a formula, such a Boolean formula, we're going to call it satisfiable-- we'll do an example in a second-- if that formula value evaluates to true if you make some assignment of values to its variables. So just like arithmetical formula will have some value if you plug in values for the variables, Boolean formula is going to have some value if you plug in Boolean values for its variables. And I want to know, is there some way to plug in values which makes the whole thing evaluate to true. The formula itself is going to evaluate to either true or false, and I wanted to evaluate to true. Here is our example. Let's take the formula, phi, which is x or y, and x complement-- or, not x or not y. So the notation x with a bar over it, x complement, is just x bar, not x. It's just the way if you're familiar with the other notation, the not operation, which just inverts 1s and 0s. We're going to write it with a bar instead of the negation symbol. I'm assuming that you've all seen Boolean algebra, Boolean arithmetic before, where the and operation is only true if both inputs are true. These are going to be binary and operations and binary or operations. Or is going to be true if either input is true. And not is true if its single input is false. Oops, just looked at the answer. Here I want to know, for this Boolean formula, here is it satisfiable. Is there some way to assign values to the variables to make this formula evaluate to true? So for example, let's just try things. Let's make x and y both true. So x is true and y is true. So x or y, well that's good, that's true. But now we have to do an and, so we need both sides to be true. So now we have x complement-- well we said we said x is true, so x complement is false, y complement is false. False or false is false. So now we have a true and false. That's going to be false. We did not find a satisfying assignment. But maybe there's another one. And in fact, there is. If you make x true and y false, then both of these parts will evaluate to true, and then you'll have true and true. So we found a satisfying assignment to this formula. It is, in fact, satisfiable. So if you say x is 1 and y is 0, yes. This is satisfiable. Now the problem of testing for a Boolean formula, if it is satisfiable, is going to be the SAT language. It's a set. It's a collection of satisfiable Boolean formula. And testing whether you're in SAT or not is going to be an important computational problem. There was an amazing theorem which really got this whole subject going, discovered independently by Steve Cook in North America and Leonid Levin in the former Soviet Union, almost exactly at the same time, which made a connection between this one problem and all of the problems in NP. By solving this one satisfiability problem in polynomial time, it allows you to solve all of the problems in NP in polynomial time. So if you could solve this problem set in P, then Hamiltonian path is also solvable in P. If you step back and think about that, it's kind of amazing. And the method that we're going to introduce is called polynomial time reducibility. Let's do a quick check-in on this. This should be an easy one. Why don't you just think about, is SAT, the SAT problem that we just described here, is that in NP? Three seconds. You all there? OK. Ending polling. Hopefully you're getting the intuition for NP that these are the problems-- to be in NP means that when you're a member of the language, there's a short proof or a short certificate of membership. And in this case, the short certificate that the formula is satisfiable is the assignment, which makes it true, also called the satisfying assignment. So yes, this is an NP language, language that's in NP. There are a lot of things that we don't know in the subject, but this isn't one of them. We do know that SAT is in NP. So let's talk about our method for showing this remarkable fact that, if you can solve SAT in polynomial time, then all of NP is solvable in polynomial time. And it uses this notion of polynomial time reducibility, which is just like mapping reducibility that I hope you've all grown to know and love in the first half of the course. But now, the reduction has to operate in polynomial time. So it's the same picture that we had before, mapping A to B, transforming A questions to B questions. But now the transformation has to operate quickly. And we get that if A is polynomial time reducible to B, and B is polynomial time, then A is also polynomial time. Same pattern as before. If A is reducible to B and B is easy, then A is easy. Here is kind of the essence of the idea, or at least the outline of the idea of this Cook and Levin theorem. That if satisfiable is in P, then everything in NP can be done in P. Which is because, we will show that all problems in NP are polynomial time reducible to SAT. That's the amazing fact. So therefore, if you can bring SAT down into P by using this reduction, it brings everything else along with it, everything is reducible to SAT. So we just have to show how to do that. There is an analogy that we had in the first half of the course, in one of our homework problems, if you may remember. We showed that A TM has the very special property that all Turing recognizable languages are mapping reducible to it. I think that was problem 2, or 2a, either in problem set 3 or problem set 2. I think problem set 3. That every Turing recognizable language is polynomial time reducible to A TM. And so, very similar picture. And there's a lot of analogies here that you can draw between the computability section and the complexity section. With that, I know we're just about out of time. So let's just quick review of what we've done here. I will stick around for questions for a while. Is there a-- OK, that's a good question. Is there a regular reduction analogy version to mapping reducibility? We had the general reduction for the computability section. And we had the mapping reduction for the computability section. Here, we're only going to be focusing now on the mapping reduction. So polynomial time reduction is, by assumption, going to be a mapping reduction. Yes, there is a general polynomial time reduction notion as well. This is not required, but if you are curious about the general reduction and how to precisely formulate that, it actually appears in chapter 6 under Turing reducibility. That's the general notion of reducibility spelled out in a formal way. And there's polynomial time Turing reducibility as well. We're not going to talk about it in this course. Other questions? Does NP correspond exactly to verification in polynomial time? For me to answer that as a precise question, we have to have a precise definition of verification. But with the right definition, the answer is yes. So you can define a verifier as a polynomial time algorithm that gives a certificate, that takes a certificate and an input to the language, and will accept if that certificate is a valid certificate for that input. This is actually discussed in chapter, I think, 9 of the text. Now I'm forgetting already, what's where in the book. But yeah, you can think of NP in terms of verification as the definition. Is proving P equal NP the same as proving that a polynom-- actually, I can even make the-- if you want, you can post public comments too. I should have done that in other cases. Is proving P equal NP the same as proving that a polynomial time non-deterministic Turing machine N has a polynomial time deterministic? Yeah. Suppose we prove that P equals NP, which is the minority view, I would say, the small minority view. There are some people who believe that that is entirely possible, and might even be the case. But that's a very small group. But yeah, if you prove P equal NP, that's the same as saying that every non-deterministic polynomial time Turing machine is going to have a companion deterministic polynomial time Turing machine which does the same language. That's exactly what it means. Bye bye, everybody.","The satisfiability problem (SAT) is significant in computational complexity theory because it is the first problem that was shown to be NP-complete. This means that if SAT can be solved in polynomial time, then every problem in NP can also be solved in polynomial time. This relationship is a result of the Cook-Levin theorem, which established that all problems in NP are polynomial time reducible to SAT, implying that solving SAT in polynomial time would allow all NP problems to be solved in polynomial time, thus showing that NP = P.",valid,Advanced,18.404J,14 P and NP SAT Poly-Time Reducibility,1VhnDdQsELo.en-j3PyPqV-e1s_12_mp4
69,How can branching programs be used to evaluate Boolean functions probabilistically?,"Review:  Branching Programs
","Branching programs can evaluate Boolean functions probabilistically by allowing certain paths of the program to be followed based on random choices. This method can provide efficient evaluation, especially in the context of decision problems where the correct answer can be determined with high probability after exploring only a subset of possible paths.",valid,Advanced,18.404J,Lecture 24 - Probabilistic Computation (cont.),cbfe4302bc8bfa4dca3c3bfcfd4661a8_MIT18_404f20_lec24_3_pdf
70,"What is the condition for a TM to accept an input consisting of strings of 'a', 'b', and 'c'?","TM – example revisited 
TM ! recognizing  "" = a$b$c$
% ≥0
! = “On input (
1.  Check if ( ∈a∗b∗c∗,  reject if not.
2.  Count the number of a’s, b’s, and c’s in (.
3.  Accept if all counts are equal; reject if not.”
High-level description is ok.  
You do not need to manage tapes, states, etc… 
9
","The TM accepts if the counts of 'a's, 'b's, and 'c's are equal; otherwise, it rejects.",valid,Intermediate,18.404J,"Lecture 6 - TM Variants, Church‑Turing Thesis",7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_9_pdf
71,Why is model independence less applicable in complexity theory compared to computability theory?,"we had model independence. The choice of the model didn't matter. And that was nice for us. Because the theory of the decidability didn't depend upon whether you had a one tape Turing machine, or a multi-tape Turing machine, it was all the same set of decidable and recognizable languages. So we didn't have to worry about which model we're actually going to work with. We could work with any model, even just an informal model of algorithm would be good enough. Because we're going to end up with the same notion in the end. Now that goes away in complexity theory. Now, we have a difference, depending upon the model. And from a mathematical standpoint, that's a little less nice. Because which model do you work with? If you want to understand the complexity of some problem that you have at hand, now you have to make a choice. You're going to work with a Turing machine, or how many tapes, or you're going to look at some other model, and you're going to get different results. So it's somewhat less natural from a mathematical standpoint just to talk about the complexity of some problem. But we're going to kind of bring back something close enough to model independence by observing that even though we don't have model independence, as we did in computability theory, we can limit how much dependence there is. So the amount of dependence is going to be low, as we will see, provided you stick with a reasonable class of deterministic models. So the dependence, though it does exist, is not going to be that much. It's going to be polynomial dependence. And we'll say exactly what that means in a second. And from our standpoint, that's going to be a small difference, a negligible difference that we're going to ignore. So we're going to focus on questions that do not depend on the model choice among these reasonable deterministic models. Now, you may say, well, that's not interesting from a practical standpoint, because polynomial differences, say the difference between n squared and n cubed certainly make a difference in practice. But it really depends on what kinds of questions you're focusing on. So if you want to look at something that's a very precise distinction, say between n squared and n cubed, then you might want to focus in on which model you want to be working with. And that's going to be more the domain of an algorithms class. But from our standpoint, we're going to be looking at other, still important, questions. But they are questions that don't depend upon exactly which polynomial you're going to have. We're going to be looking more at distinctions between polynomial and exponential. And still, there are important practical questions that arise in that somewhat different setting. So with that in mind, we're going to continue to use the one tape Turing machine as our basic model of complexity. Since the model among the reasonable deterministic models in the end is not going to matter from the perspective of the kinds of questions we're going to be asking. So with that, so we are going to continue, then, it's important to remember that from going forward, we're going to stick with the one tape Turing machine model. Maybe that's something you would have expected us to do anyway. But I'm trying to justify that through this little discussion","In complexity theory, there is a dependence on the choice of the model, unlike in computability theory where the choice between models like one tape or multi-tape Turing machines didn't affect the set of decidable and recognizable languages. Complexity results can vary based on the model, such as a Turing machine with different tape configurations. However, this dependence is often limited to polynomial differences among reasonable deterministic models, which are considered negligible for certain types of questions, such as the distinction between polynomial and exponential complexities.",valid,Intermediate,18.404J,12 Time Complexity,asjAc90L8rE.en-j3PyPqV-e1s_5_mp4
72,Why does the choice of a Turing machine model become significant when comparing complexities like n squared and n cubed?,"we had model independence. The choice of the model didn't matter. And that was nice for us. Because the theory of the decidability didn't depend upon whether you had a one tape Turing machine, or a multi-tape Turing machine, it was all the same set of decidable and recognizable languages. So we didn't have to worry about which model we're actually going to work with. We could work with any model, even just an informal model of algorithm would be good enough. Because we're going to end up with the same notion in the end. Now that goes away in complexity theory. Now, we have a difference, depending upon the model. And from a mathematical standpoint, that's a little less nice. Because which model do you work with? If you want to understand the complexity of some problem that you have at hand, now you have to make a choice. You're going to work with a Turing machine, or how many tapes, or you're going to look at some other model, and you're going to get different results. So it's somewhat less natural from a mathematical standpoint just to talk about the complexity of some problem. But we're going to kind of bring back something close enough to model independence by observing that even though we don't have model independence, as we did in computability theory, we can limit how much dependence there is. So the amount of dependence is going to be low, as we will see, provided you stick with a reasonable class of deterministic models. So the dependence, though it does exist, is not going to be that much. It's going to be polynomial dependence. And we'll say exactly what that means in a second. And from our standpoint, that's going to be a small difference, a negligible difference that we're going to ignore. So we're going to focus on questions that do not depend on the model choice among these reasonable deterministic models. Now, you may say, well, that's not interesting from a practical standpoint, because polynomial differences, say the difference between n squared and n cubed certainly make a difference in practice. But it really depends on what kinds of questions you're focusing on. So if you want to look at something that's a very precise distinction, say between n squared and n cubed, then you might want to focus in on which model you want to be working with. And that's going to be more the domain of an algorithms class. But from our standpoint, we're going to be looking at other, still important, questions. But they are questions that don't depend upon exactly which polynomial you're going to have. We're going to be looking more at distinctions between polynomial and exponential. And still, there are important practical questions that arise in that somewhat different setting. So with that in mind, we're going to continue to use the one tape Turing machine as our basic model of complexity. Since the model among the reasonable deterministic models in the end is not going to matter from the perspective of the kinds of questions we're going to be asking. So with that, so we are going to continue, then, it's important to remember that from going forward, we're going to stick with the one tape Turing machine model. Maybe that's something you would have expected us to do anyway. But I'm trying to justify that through this little discussion","The choice of a Turing machine model becomes significant when comparing complexities like n squared and n cubed because the differences in complexity can be model-dependent at that level of granularity. From a more practical standpoint, these polynomial differences can be important. However, such precise distinctions are more relevant to algorithms classes, whereas in theoretical discussions of complexity, the focus is more on broader distinctions such as between polynomial and exponential complexities.",valid,Intermediate,18.404J,12 Time Complexity,asjAc90L8rE.en-j3PyPqV-e1s_5_mp4
73,Why is the proof that the language !TM is undecidable a diagonalization proof?," 
  
  
 
 
 
  
 
 
 
 
   
 
 
 
 
 
 
 
 
 
  
 
 
  
 
  
 
 
  
 
 
 
  
 
  
 
 
 
  
 
  
  
  
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
acc
rej
acc
acc
. . .
rej
rej
rej
rej
acc
acc
acc
acc
. . .
rej
rej
acc
acc
⋮
rej
acc
rej
rej
?
!TM is undecidable
Recall !TM = { &, ( | & is a TM and & accepts (} 
Theorem: !TM is not decidable 
Proof by contradiction: Assume some TM + decides !TM. 
Accept if & accepts (
So + on &, ( = , 
Why is this proof a diagonalization? 
Reject 
if not 
Use + to construct TM -
- = “On input 〈&〉
1. Simulate + on input 〈&, & 〉 
2. Accept if + rejects. Reject if + accepts.”
- accepts 〈&〉 iff & doesn’t accept & . 
- accepts 〈-〉 iff - doesn’t accept
- . 
Contradiction. 
7 
〈&0〉〈&1〉〈&2〉〈&3〉
. . .
〈-〉
&0
ac
acc
rej
acc
acc
. . .
&1
rej
re
rej
rej
rej
&2
acc
acc
ac
acc
acc
. . .
&3
rej
rej
acc
ac
acc
⋮
⋮
-
rej
acc
rej
rej
?
All TM descriptions:
All 
TMs
","The proof is a diagonalization because it uses a TM - that simulates another TM + on its own description, and constructs a contradiction by reaching a situation where - accepts its own description if and only if it does not accept, thus applying a diagonal argument.",valid,Intermediate,18.404J,Lecture 8 - Undecidability,3ab8452b4b29eb28a1416e4a1575323c_MIT18_404f20_lec8_7_pdf
74,"What is a tableau in the context of nondeterministic computation, and how does it relate to an accepting branch and computation history?","So first of all, let me describe what my computation history is going to look like. And the situation is a little bit different than what we had before because when we were talking about the Post correspondence problem we had a deterministic machine. And now our machine is nondeterministic. So we're going to call the object-- instead of an accepting computation or a computation history, we're just going to-- we're going to call it a tableau, or sometimes an accepting tableau if you want to emphasize the accepting nature of it. But generally, we're just going to call it a tableau. So a tableau is really an accepting computation history for the machine on an accepting branch of its nondeterministic computation. So if M accepts w, it's got to have some accepting branch, and the tableau is going to be the sequence of configurations that the machine goes through on that accepting branch. If there are several accepting branches, there may be several tableaus. There will be several tableaus. So there's going to be one tableau for each accepting branch of the machine's computation on w. If the machine does not accept w, there won't be any tableaus. And so the whole point is that we're going to make our formula represent the statement that there is a tableau. And satisfying that formula is going to correspond to filling out the symbols in the tableau to make it a tableau. So here is a tableau. So a tableau is just, again, an accepting computation history on some branch, some accepting branch of the machine's computation. The rows are the-- instead of writing the computation history out linearly, we're going to represent it in a table form where each configuration is going to be on a separate row. Now, the dimensions of that table are going to be n to the k by n to the k, because the machine runs for n to the k steps. So there's going to-- if there's an accepting branch, it's going to accept within that number of steps. And we'll have enough rows here to write down all of the configurations that the machine goes through one after the next, row by row, each one having a configuration in it. And then at the bottom, there'll be an accept. Minor detail, if the machine accepts earlier, we'll just say the machine stays in the-- once it enters an accept, the machine does not change from that point on. So the rule of the machine is nothing changes. And it just remains in the same configuration from that point on.","A tableau is really an accepting computation history for the machine on an accepting branch of its nondeterministic computation. If a machine M accepts an input w, it has some accepting branch, and the tableau is the sequence of configurations that the machine goes through on that accepting branch. If there are several accepting branches, there are several tableaus. A tableau is represented in a table form where each configuration is on a separate row, and the dimensions of the table are n to the k by n to the k, representing the steps the machine runs. The tableau ensures that if there's an accepting branch, filling out the symbols in the tableau makes it a tableau.",valid,Advanced,18.404J,16 Cook-Levin Theorem,6Az1gtDRaAU.en-j3PyPqV-e1s_4_mp4
75,What is one of the conditions of the Pumping Lemma for context-free languages (CFLs) concerning the substring x of a string s?," 
 
 
 
 
 
   
   
 
 
  
 
 
  
  
 
 
  
  
 
 
 
 
 
 
 
 
  
  
 
   
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Pumping Lemma – Proof 
Pumping Lemma for CFLs:   For every CFL !, there is a "" 
such that if # ∈! and # ≥ "" then # = '()*+ where 
1) '(,)*,+ ∈ ! for all - ≥0 
2) (* ≠ ε 
E
3) ()* ≤ "" 
Proof by picture: 
R
R
E 
R 
E 
R 
'
( 
*
+ 
R
R 
)
(
) 
* 
Generates '(()**+ 
' 
Generates ')+ 
+ 
= '(1)*1+ 
= '(2)*2+
# = 
' 
(
) 
*
+ 
Long # → 
“cutting and pasting” argument 
tall parse tree 
4 
","One of the conditions is that |xuy| ≤ p, where p is the constant associated with the context-free language.",valid,Intermediate,18.404J,"Lecture 5 - CF Pumping Lemma, Turing Machines",18c8cd00b14d48dc5865f3bdc41abd76_MIT18_404f20_lec5_4_pdf
76,What is an unprovable mathematical statement mentioned in the content?," 
 
 
 
 
 
 
 
 
 
 
  
Other applications 
1. Computer viruses. 
2. A true but unprovable mathematical statement due to Kurt Gödel: 
“This statement is unprovable.” 
10 
",A true but unprovable mathematical statement due to Kurt Gödel: 'This statement is unprovable.',valid,Basic,18.404J,Lecture 11 - Recursion Theorem and Logic,779043ea724131d008eae652d703938f_MIT18_404f20_lec11_10_pdf
77,What does the GNFA conversion process involve with respect to the states?," 
  
 
 
 
  
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
! −1 states
! states
$
$
%&
%'
%&
%'
()
(*
(+
(,
() (*
∗(+ ∪(,
!-state GNFA → (!—1)-state GNFA 
Check-in 3.1 
We just showed how to convert GNFAs to regular expressions 
but our goal was to show that how to convert DFAs to 
regular expressions. How do we finish our goal? 
(a) Show how to convert DFAs to GNFAs 
(b) Show how to convert GNFAs to DFAs 
(c) We are already done. DFAs are a type of GNFAs. 
Thus DFAs and regular expressions are equivalent. 
1. Pick any state $ except 
the start and accept states. 
2. Remove $. 
3. Repair the damage by 
recovering all paths that 
went through $. 
4. Make the indicated change 
for each pair of states %&, %' . 
Check-in 3.1 
5 
","It involves picking any state $ except the start and accept states, removing $, and repairing the damage by recovering all paths that went through $. Then, making the indicated change for each pair of states %& and %'.",valid,Basic,18.404J,"Lecture 3 - Regular Pumping Lemma, Finite Automata → Regular Expressions, CFGs",a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3_5_pdf
78,What is a branching program (BP)?,"Example:  Branching Programs
Defn: A branching program (BP) is a directed, acyclic (no cycles) graph that has
1.  Query nodes labeled !"" and having two outgoing edges labeled 0 and 1.
2.  Two output nodes labeled 0 and 1 and having no outgoing edges.
3.  A designated start node.
BP # with query nodes !$, … , !' describes a Boolean function (: 0,1 ' →{0,1}:
Follow the path designated by the query nodes’ outgoing edges 
from the start note until reach an output node.
Example:  For !$ = 1, !/ = 0, !0 = 1 we have ( 101 = 0 = output.
BPs are equivalent if they describe the same Boolean function.
Defn:  12BP =
#$, #/
#$ and #/ are equivalent BPs (written #$ ≡#/) } 
Theorem:  12BP is coNP-complete  (on pset 6)
12BP ∈BPP ?  Unknown. That would imply NP ⊆BPP and would be surprising!
Instead, consider a restricted problem.
!$
!0
!$
!/
!/
!0
0
1
0
1
0
1
0
1
0
1
0
1
0
1
5
","A branching program (BP) is a directed, acyclic graph with query nodes labeled and having two outgoing edges labeled 0 and 1, two output nodes labeled 0 and 1 with no outgoing edges, and a designated start node.",valid,Basic,18.404J,"Lecture 23 - Probabilistic Computation, BPP",44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_5_pdf
79,How can the equivalence of two regular expressions be determined using automata?,"equivalents of regular expressions. Can we now conclude that this problem is also decidable, either immediately from stuff we've already shown; or yes, but would take some significant extra work; or no, because intersection is not a regular operation? So let's see if I can pull that out here-- launch the polling. Here we go. OK, I think we're just about done here. Five seconds more-- OK, ready, set, end. All right. Yes, the correct answer is A. We have basically already shown this fact, because-- why is that? Because we have shown that we can convert-- if you're given two regular expressions, and we want to test whether they're equivalent, they generate the same language, we can convert them both to find out automata. We can convert them to NFAs, and then the NFAs to DFAs. And then we can apply what we've just showed about testing equivalence of DFAs. So yes, it really follows immediately from stuff we've already shown-- the conversion, number one, and then the testing of equivalence for DFAs. So there's not really any work to do here. And in fact, what I'm trying to illustrate with this check-in-- that, once you've shown how to do some kind of a test for one model, it-- going to apply for all of the equivalent models that we've shown to be equivalent, because the Turing machine can do the constructions which show the equivalence. OK, so let's move on. Somebody didn't get the poll. Did most people not get the poll? Well, I think most of you have gotten it. Did you? I'm not seeing a lot of complaints. So if you didn't get the poll, something is wrong with your setup, and you're going to have to take the recorded check-ins that are going to launch right after this lecture's over. Sorry. But you should figure out what's wrong with the setup there, because I think most people are getting these. OK, and with that, we're going to take a little break, and then we'll continue on afterward. Let me know how this is-- should I be speed a little speedier about the little mini breaks that we're taking, or is this good for you? Feedback is always-- I'm trying to make this as good as I can for all of you. OK, I think there's a mixture of between people saying that these breaks are good. Someone says they're a little overlong, so I'll try to tighten them up a little. Some folks are saying what-- more people should be asking the TAs. I don't know how the TAs are doing, in terms of their-- I'll check with them afterward-- how well this is going for them, in terms of the questions. But I think some amount of break is good so that we don't-- so there's time to be asking questions. Otherwise, what's the point of having a live lecture? So we will start promptly when this timer runs down. So be ready to go in 55 seconds from now. Just to confirm, to show the decidability of the equivalence of two regular expressions, do we need to show that we can use a Turing machine to convert them to two DFAs first? If you want to test whether two regular expressions are equivalent, you can give any procedure for doing that deciding you want. I'm just offering one simple way to do it that takes advantage of stuff we've already shown. But if you want to dig down and do some analysis of those regular expressions to show that they describe the same language, they generate the same language, be my guest. I think that's-- actually would be complicated to do that that way. OK, so we're just about ready to go here, so let's continue. And let me take this timer off here. All right. Now, we are going to talk a little about context-free grammars. So we talked about decision problems for finite automata. Let's talk about some for grammars. OK, now I'm going to give us an analogous problem. I'm going to give you a-- I'm calling it the acceptance problem, but-- just for consistency with everything else, but it's really the generating problem. So I'm giving you a grammar-- context-free grammar G and a string that's in a string. And I want to know, is it in the language of G? So does G generate w? I'm calling that the ACFG problem. So that's going to be a decidable again. These are getting slightly harder as we're moving along, so I'm giving you a grammar and a string, and I want to know, does the grammar generate that string? Well, it's not totally trivial to solve that. One thing you might try doing is looking at all possible things, all possible derivations from that grammar and see if any one of them leads to w-- leads you to generate w. Well, you have to be careful, because as I've-- as we've shown in some of our examples, you actually could have-- because you're allowed to have variables that can get converted to empty string, you might have very long intermediate strings being generated from a, grammar which then ultimately give you a small string of terminals that get generated, a small string in the language that gets produced. You certainly don't want to try every possible derivation, because there's infinitely many different derivations-- most of them generating, of course, things that are irrelevant to the string w. But you have to know how to cut things off, and it's not immediately obvious how you do that-- unless you have done the homework problems that I asked you to do, which I'm sure very many of you have not done-- the zero point X problems, because they're-- that's going to come in handy right now. And so I'll help you through that. Remember-- you should remember, but you may not have looked at it-- something called Chomsky normal form, which is for context-free grammars, but only allows the rules to be of a special kind. And they have to look like this. They can be a variable that goes to two variables, on the right-hand side, or a variable that goes to a terminal. Those are the only kinds of rules that you're allowed. This is a special case for the empty string, but let's ignore that for-- the start variable can also work to the empty string, if you want to have a-- the empty string in a language. But that's a special case. Let's ignore that. These are the only two kinds of rules that you can have in a Chomsky normal form grammar. Once you have a Chomsky normal form grammar-- well, first of all, there's two things. First of all, you can always convert any context-free grammar into Chomsky normal form. So that's given in the textbook. You do the obvious thing. I'm not going to spend time on it. And you don't have to know it. It's just a little bit tedious, but it's straightforward and it's there, if you're curious. But the second lemma's the thing that's important to us, which is that, if you have a grammar which is in Chomsky normal form and a string that's generated, every derivation of that string has exactly 2 times the length of the string minus 1 steps. If you think about it, this is a lemma-- very easy to prove. I think the homework problem asks you to prove that in the 0.2 or whatever it was in problem set 1-- or problem set 2-- I don't remember. Rules of this kind allow you to make the string one longer, and rules of this kind allow you to produce a new terminal symbol. If the length w is n, you're going to have n minus 1 of these and n of. Those that's why you get 2n minus 1 steps. But the point is that I don't really care exactly how many. It's just that we have a bound. And once you have that bound, life is good from the point of view of giving a Turing machine which is going to decide this language-- because here's the Turing machine. What it's going to do-- the first thing is it's going to convert G into Chomsky normal form. That we assume we know how to do. Now, we're going to try all derivations, but only those of length 2-- twice the length of the string minus 1, because if any derivation is going to generate w, it has to be this many steps, now that we know the grammar is in Chomsky normal form. OK, so we have converted this problem of one that might be a very unboundedly lengthy problem and to one where it's going to terminate after some fixed number of steps. And so therefore, we can accept, if any of those generate w, and reject if not. OK? Before moving on, so this answers the problem-- shows that this language is decidable, the ACFG language. So that's something that-- make sure you understand. We're basically trying old derivations of up to-- of a certain length, because that's all that's needed when the grammar is in that form. Now we're going to use that to prove a corollary, which is important for understanding how everything fits together. And that corollary states that every context-free language is a decidable language. Every context-free language is decidable. Now, why does that follow from this? Well, suppose you have a context-free language. We know that language is generated by some context-free grammar G. That's what it means. So then you can take that grammar G and you can build it into a Turing machine. So there's going to be a term machine which is constructed with the knowledge of G. And that Turing machine is going to take its w and run the ACFG algorithm with w combined with a G that's already built into it. So it's just going to stick that grammar G in front of w, and now we run the ACFG decider. It's going to say, does degenerate w? Well, that's going to be yes every time w is in A. And so this machine here now is going to end up accepting every string that's in A, because it's every string that G generates. So that is, I think, what I wanted to say about this. Now, I feel that this corollary here throws a little bit of a curveball. And we can just pause for a moment here just to make sure you're understanding this. The tricky thing about this corollary is-- that I often get-- a question I often get where-- is when we start off with a context-free language, who gives-- how do we get G? Because we need G to build a Turing machine M sub G. So we know A is a context-free language, but how do we know what G is? Well, the point is that we may not know what G is, but we know G exists, because that's a definition of A being a context-free language. It must have a context-free grammar, by definition. And so because G exists, I now know my Turing machine, M sub G, exists. And that's enough to know that A is decidable, because it has a decider that exists. Now, if you're not going to tell me the grammar for G, I'm not going to tell you the Turing machine which decides A. But both of them exist. So if you tell me G, then I can tell you the Turing machine. So it's a subtle, tricky issue there. A certain little element maybe of-- sometimes people call it non-constructive, because we're just, in a sense, showing just that something is existing. It does the job for us, because it shows that A is a decidable language. OK, so not so many questions here-- maybe the TAs are getting them. So let's move on. Here's another check-in. So now, can we conclude that A-- instead of ACFG, APDA is decidable? People are getting this one pretty fast. Another 10 seconds-- three seconds-- OK, going to shut it down-- end polling, share results. Yeah. So this problem here is APDA is decidable. I was almost wondering whether or not to give this poll, because it has-- it's true for the same reason as poll number 1, because we know how to convert PDAs-- or we stated we can convert PDAs to CFGs. And that conversion has given in the book. We didn't do in lecture, but I just stated you have to know that fact, but not necessarily know how to do it. That's OK. But the fact is true. The conversion is in the book, and it could be implemented on a Turing machine. So if you want to know whether a PDA's language is empty, you convert it to a context-free grammar and then use this procedure here to test whether it's a language--","To determine the equivalence of two regular expressions, we can convert each regular expression to a nondeterministic finite automaton (NFA), then convert the NFAs to deterministic finite automata (DFAs). Finally, we can apply the method for testing equivalence of DFAs. This process shows that determining the equivalence of two regular expressions is decidable, as it relies on previously shown conversions and tests.",valid,Advanced,18.404J,7 Decision Problems for Automata and Grammars,4MgN6uxd4i4.en-j3PyPqV-e1s_11_mp4
80,What is a Context Free Grammar?," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Quick review of today 
1. Defined Context Free Grammars (CFGs) 
and Context Free Languages (CFLs) 
2. Defined Pushdown Automata(PDAs) 
3. Gave conversion of CFGs to PDAs. 
12 
",Context Free Grammars (CFGs) are defined within the lecture content.,invalid,Basic,18.404J,"Lecture 4 - Pushdown Automata, CFG ↔ PDA",a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_12_pdf
81,What is a Pushdown Automaton?," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Quick review of today 
1. Defined Context Free Grammars (CFGs) 
and Context Free Languages (CFLs) 
2. Defined Pushdown Automata(PDAs) 
3. Gave conversion of CFGs to PDAs. 
12 
",Pushdown Automata (PDAs) are defined within the lecture content.,invalid,Basic,18.404J,"Lecture 4 - Pushdown Automata, CFG ↔ PDA",a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_12_pdf
82,Was a method given for converting between CFGs and PDAs?," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Quick review of today 
1. Defined Context Free Grammars (CFGs) 
and Context Free Languages (CFLs) 
2. Defined Pushdown Automata(PDAs) 
3. Gave conversion of CFGs to PDAs. 
12 
","Yes, the conversion of CFGs to PDAs was given in the lecture content.",invalid,Basic,18.404J,"Lecture 4 - Pushdown Automata, CFG ↔ PDA",a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_12_pdf
83,What does BPP stand for?,"[SQUEAKING] [RUSTLING] [CLICKING] MICHAEL SIPSER: Welcome back. I hope you had a good Thanksgiving and all refreshed and ready to think about some theory of computation. We're in the homestretch now. We have this lecture and two more to go. And so today, I have for you, a completion of the theorem we started before the break, where we introduced probabilistic computation and we talked about the class BPP, as I hope you remember, and we looked, in particular, at these problems involving branching programs, where we started the proof that the problem of equivalence of two read-once branching programs can be solved in this class BPP. So what I'm going to do is spend the first 15 minutes or so just reviewing where we were, because we started this, it feels like a long time ago now. And I just want to make sure that you're all on the same page and we're all remembering what we were doing. And then, I will finish off the proof. And along with doing that, we're going to introduce an important method. Well, we started that. We looked at the method of arithmetization last time. So we'll review that. We're going to use that again in the work that we're going to start on Thursday on interactive proof systems. So this is a kind of, in some ways, both an interesting theorem in its own right, and a warm up for what we're going to be doing in the last topic of the semester. OK. So let's just remember what we were doing. So we introduced probabilistic Turing machines. So those are these machines that have-- a kind of non-deterministic machine, but there's a different rule for acceptance. And these are also non-deterministic machines which can either make one choice, just to have a deterministic move at a step, or they can make two choices. And when the machine makes two choices, we actually think of there being a probability there, where the machine is tossing a coin to decide which branch to go on. So with that, there is a tree of possible branches. And the probability of some particular branch is going to be 1 over 2 to the number of coin tosses on that branch. And so we then use that to define the probability that the machine accepts, which is the sum over all of the probabilities of the accepting branches. And the probability that it rejects is 1 minus the probability that it accepts. So thinking about it-- this captures the idea that if you just run the machine on a random set of inputs from the coin tosses, what the probability that you're going to end up with the machine accepting. That's the probability of acceptance, defined in that way. Now, if we're thinking about the machine deciding some particular language, it's supposed to accept the strings in the language and reject the strings which are not in the language. But because of the probabilistic nature of the machine, it might get the wrong answer on some branches. And so we say that a machine decides a language with a certain error probability, means that the probability of getting the wrong answer is going to be, at most, that error probability epsilon over all of the possible inputs to the machine. So if we say that the machine is error probability 1/3 that means that it gets the right answer for every string with probability at least 2/3. OK, so that led us to the definition of this complexity class BPP, which I don't even remember if I told you what it stands for. It's bounded probabilistic polynomial time. That's what BPP stands for. The ""bounded"" means is bounded away from 1/2 because we don't want to allow the machine to have probability 1/2, because then bad things happen. The machine can just toss a coin when it decides to make an answer, and not really give us any information. Then, we also went over the amplification lemma. We did not give the proof, but we went over the statement of the theorem. The proof is really just a calculation that you can drive down that error probability to something extremely tiny just by basically repeating the machine and taking the majority vote of what it does on several different runs. If you run the machine 100 times and you see if it's mostly accepting, then you want to accept. And the chances that the machine was really biased toward rejecting, even though you're in your sample see mostly acceptance, is extremely small. And you can calculate that, but you can make that very tiny. So small that, for all practical purposes, it's really giving you the right answer. But it's not deterministic. So it's not quite 100% guaranteed. And the way I like to think about BPP in terms of the computation tree of the machine, so that when it's accepting, most of the branches are accepting, weighted by their probability, of course. So the there are many accepting branches when you're accepting, and many rejecting branches when you're rejecting. So just another way of saying the same thing. Now, we're going to jump right in with a check-in. And this is a little bit more, not exactly the material of the course, but a little bit more on the philosophical side. But let's just see how you do with it. When you're actually running a probabilistic machine, you imagine the machine, as we're kind of informally describing it, is tossing coins. Every time it has a non-deterministic-- every time it has a choice. So it choice tosses a coin to decide which way to go. Of course, a real computer does not have a coin to toss, presumably. Well, maybe you might actually build some hardware into the machine that lets it access randomness in some sense. Maybe it uses some quantum mechanical effect to get some random value or maybe it uses the timer. I'm not exactly sure. You can imagine having a bunch of ways of implementing that. A typical way that people implement randomness in an algorithm is to use a pseudo random number generator, which is a procedure that might give you some kind of a value that looks random, but may not actually be random. It's, for example, giving you the digits of pi. If you want binary, expressing pi as a binary number, then you might calculate the different successive digits of pi and use that as for your random number generator. Of course, that's a deterministic procedure, so it's not really random. But often, people do use those kinds of things when they're simulating random machines. So what do you think about doing that? Could we use a pseudo random generator as the source of randomness for our randomized algorithm? Yes, or no, or what do you think? So let's launch a poll on that, so I can see what your opinion about using pseudo random number generators instead of true randomness for our algorithms. I'll give you a few seconds, a minute to weigh in on that. OK. We're going to close this down. Everybody's participated who wants to? 1, 2, 3. OK. Yeah, I think probably the best answer is A. Let's take a look. There were a couple of answers here that, really, that don't make-- that aren't as good. I would say, B, well, usually people think of pseudo random generators as pretty fast procedures. They're not that interesting, otherwise. So I wouldn't say that B is a good choice because they're usually pretty quick to implement. C is a worse choice, even, because Turing machines can do anything that any other algorithm can do. So, certainly, if there is such a thing as a pseudo random number generator, and there is, then you could implement it on the Turing machine. D is kind of an interesting answer because you're saying, well, that would imply that P equals BPP if you could actually simulate randomness with a deterministic procedure. But in fact, the reason I would not choose D is because it's perfectly conceivable that P does equal BPP. We don't know that P is different from BPP, so it's conceivable that they're equal. And in fact, I think if you polled most complexity theorists, most people in my field would believe that P does equal BPP just for this very reason, that if you had sufficiently good pseudo random number generators, you could actually eliminate the probabalism in these probabilistic computations. You could just run them on the pseudo random number generator. And in fact, there is some theory around that that has been developed. But at the present time, we do not know how to prove that there were pseudo random number generators. And it has some, actually, there's actually, in some line of this research, has some connection with the P versus NP problem, but we don't know how to prove that there are sufficiently good pseudo random number generators that would allow you to run them on a probabilistic algorithm and have a guaranteed behavior which is as good as running truly random numbers into the probabilistic algorithm. And so the answer that I would pick would be A, that you could use it, sure. You might get the right answer, but it's not guaranteed. We just don't know how to do the analysis for the pseudo random number generators. And if you had ones that were good enough, they would show P is equal to BPP. But that might be, in fact, the correct-- that might actually be true. OK, so let's continue on.",BPP stands for bounded probabilistic polynomial time.,valid,Basic,18.404J,24 Probabilistic Computation cont,7J1HD9rqEB4.en-j3PyPqV-e1s_1_mp4
84,What is the Church-Turing Thesis and why is it significant?,"MIT OpenCourseWare
https://ocw.mit.edu
18.404J / 18.4041J / 6.840J Theory of Computation
Fall 2020
For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
",The Church-Turing Thesis posits that anything that can be computed algorithmically can be computed by a Turing Machine. It is significant because it provides a foundational framework for understanding the limits of what can be computed and forms the basis for the development of computer science theory.,invalid,Intermediate,18.404J,"Lecture 6 - TM Variants, Church‑Turing Thesis",7405f6112c8ca7242e1edd9a021c1e63_MIT18_404f20_lec6_12_pdf
85,What is the opinion about the possibility of proving P = NP or P ≠ NP within 20 years?," 
 
    
 
 
 
 
 
 
 
 
 
     
 
 
 
 
 
     
 
 
  
 
 
 
     
 
 
  
 
     
 
 
  
 
     
 
 
  
 
 
 
  
  
 
 
   
 
 
 
   
 
 
Check-in 26.3 
P = NP ? 
a) YES. Deep learning will do !""# ∈ P, but we won’t understand how. 
b) NO. 
But we will never prove it.
c) NO. 
We will prove it but only after 100 years
d) NO. 
We will prove it in ' years, 20 ≤ ' ≤ 100
e) NO. 
We will prove it in ' years, 1 ≤ ' < 20
f) NO. 
One of us is writing up the proof now…
9 
Check-in 26.3 
",The opinion is that it will not be proven within 20 years (1 ≤ ' < 20).,valid,Intermediate,18.404J,Lecture 26 - coNP ⊆ IP,7ac944716e076209c3964e073929f42e_MIT18_404f20_lec26_9_pdf
86,"What principle explains why if an FA with p states runs for more than p steps, it must enter some state twice?","So the pumping lemma depends on the fact that if M has p states and it runs for more than p steps, then it's going to enter some state twice. So you may have seen that before. It actually has a name which some of you may have seen. So let's see how to just get a poll here. And I hope not too many of you are going to pick C, as it's-- some of you are. [LAUGHS] Oh well. Yes, I think this one most of you are-- you've seen this before. This is-- I think you pretty much all got it. This is what's known as the Pigeonhole Principle. So here, sharing the results, obviously I was having a little fun with this. I'm sure some of you were having fun back at me. That's OK.",This is what's known as the Pigeonhole Principle.,valid,Basic,18.404J,3 Regular Pumping Lemma Conversion of FA to Regular Expressions,KAySmSEGc9U.en-j3PyPqV-e1s_12_mp4
87,What does the computable function 'q' do?,"So let me give you an example of how you would make a self-reproducing Turing machine. What do we mean by that? I mean a machine-- I'm going to call it SELF-- which ignores its input. So on any input, you turn it on, the machine grinds around for a while, and halts with a description of itself on the tape-- with the description of SELF, its own code, sitting on the tape. So very much like producing a program which would print out its own code, that's really what we're doing. So for that, we're going to first need a little lemma, which is a very simple lemma, but it looks worse than it is. So let me just read it out to you, and then I'll explain what its saying. Because what it's saying is extremely simple. So there's a computable function, I'm going to call it q, that maps strings to strings, which will take any string, w, and produce from w a Turing machine which will print w. OK? That's all it does. So as you know, if I give you a string, w, you could produce a Turing machine which would have w represented in the states and transitions of the machine. So that if you turn the machine on, the machine will output w. If I want you to give me a Turing machine that prints the string 1, 1, 0, 1 on the tape, you could do that-- I hope. And no matter what that string was, instead of 1, 1, 0, 0, or whatever, it's 20 0's and then five 1's, you could do that too. And in fact, there's a simple procedure that takes a string and maps that onto a Turing machine which prints out that string. So that's a computable function, which basically takes a string and converts it to something that evaluates to that string. And I'm calling it q. I don't know if this is helpful to you or not. It's kind of like it converts the string w to w in quotes. So q stands for quotes, in a way. So if that's helpful, then good. But anyway, Pw is a Turing machine. When you turn it on, it just prints out w and halts. And I can find Pw from w-- straightforward proof. So now, I'm going to tell you, assuming that we have that computable function, q, I'm going to tell you how to make this machine SELF. And it's not complicated. The Turing machine SELF is going to have","The computable function 'q' maps strings to strings and produces a Turing machine from any string, w, which will print w.",invalid,Basic,18.404J,11 Recursion Theorem and Logic,N-_XmLanPYg.en-j3PyPqV-e1s_3_mp4
88,Why do we need a 2 by 3 neighborhood to ensure a legitimate tableau in a computation history?,"And here is another kind of a weird legal neighborhood. If you have a, b, c, and then the a changes to a d, that could also be a legal neighborhood if the machine transition function allows an a to get converted to a d when there is some machine-- when there is some state reading that a, and that state also moves its head left. So it doesn't move into this picture. So those are examples of legal neighborhoods. Let me show you some illegal neighborhoods. Just I'm doing this-- this is kind of a proof by example now. This is perhaps the most intuitive part. But I claim that this is easy to turn this into something airtight and formal. So this would be clearly illegal. If you have a piece of the tape in the previous step where it's a, b, c, and then suddenly the b changes to a d. The symbol on the tape changes out of nowhere without having a head nearby to a different-- to something else. That could never happen. So that would be illegal. Another thing that would be illegal is if a state appears from nowhere. That could never happen. Or if it just disappears. That could never happen. And here's another-- here's an interesting one. If a state becomes two states. Don't forget the machine is nondeterministic. So the machine in principle could move its head left on one branch and move its head right on a different branch, but those would have to be in different tableaus. They can't be in the same tableau, because that doesn't correspond to any of the threads of the computation, those with multiple threads. And I say this because if you think about my claim, which is going to put down over here, that if every 2 by 3 neighborhood is legal, then the tableau overall corresponds to a computation history. This illustrates why it's not enough to have a 2 by 2 neighborhood, where you really need the 2 by 3. Because if this was a 2 by 2 neighborhood, if you just look at these four-- this leftmost 2 by 2, that could be a legal neighborhood if it was a 2 by 2, if the rules of the machine allowed for that. And the right four box-- right four cells could also be a legal neighborhood. So you could have something that looks OK from the perspective of 2 by 2 neighborhoods, but globally, in terms of the overall tableau, it's completely nonsensical because it has multiple hits. But if you have a 2 by 3 neighborhood, it's big enough to prevent this situation from occurring. And then you can check the details. And I think it's very plausible that it guarantees that the overall tableau is legitimate if all of the 2 by 3 neighborhoods are legal. And so that's what we're going to turn into a Boolean expression. We're going to say for each cell that the set-- for each neighborhood-- so here's a neighborhood at the i, j location. I'm calling this position here sort of the home location for that neighborhood. For each neighborhood, it has to be set to one of the legal possibilities. And there's, again, only a fixed number of those because there's a fixed number of possible symbols that can appear in those cells. So this is that fixed number to the sixth power at most. And I'm going to say that the cell in the upper left, which would be this one, is in r. And this one here is an s. And this one is a t. And this one is a v, if you just trace down what the indices are telling you. It says that that piece of the tape, that piece of the tableau here is set according to one of the possible legal settings. And we're just going to OR over all of those possible fixed number of legal settings. And then I take an AND over all possible tape cells, over all possible neighborhoods. And so that's going to be my phi move. And that's it. OK. Let's see. Can I explain again the third example of illegal? So this one over here, I presume, I'm being asked about. Well, if the machine is in a state q7 reading a c, the head has to move either left or right. So at the next configuration, there's got to be a state symbol appearing either in this cell or in this cell. And here the tape-- the head has basically just vanished with nowhere to-- it's gone. That could not happen according to the rules of the machine the way we talk about Turing machines. So that's not possible. So this would be an illegal neighborhood. You want to prevent any of the bad stuff from happening anywhere in here. So only good stuff can be happening locally. And that guarantees the overall picture is OK. Do we have to check that the head doesn't leave the tableau from the left most to right right? Yeah, there are some little details here like that. So the question is, do I have to make sure that the-- yeah, you probably need to mark. I think the book probably does this correctly. You may have to mark the left and right ends to make sure that-- I mean, the right end is not a problem, because the machine can never go off the right end. And if you design the machine so that it never moves its head off the left end either, which you can do, then you wouldn't have to worry about that possibility. But otherwise, you would have to put some sort of delimiter here to enforce the head not moving off the left end. So there are some details like that, too. There will be two heads in the same row. No, this can-- I don't know what you-- somebody says, there will be two heads in the same row. Please elaborate, because this is designed not to allow two heads in the same row. Could I go over the OR for legal again? OK. The OR, the big OR here, what I have in mind is I take-- there's going to be-- first of all, I look at the machine and I look at the transition function. And based on that, I write down the list of all the legal 2 by 3 neighborhoods. So all the settings which correspond to legal 2 by 3 neighborhoods. There's going to be some fixed number of those. 100. There's 100 possible legal neighborhoods of which I've written down here four. But maybe there's some number, say 100. So now there's going to be an OR over those 100 different possibilities. It's either going to be this legal neighborhood, or some other legal neighborhood, or some other legal neighborhood. And for each one of those legal neighborhoods, I'm going to say, well, the variables are set according to that legal neighborhood, or the variables are set according to the next legal neighborhood, or the variables are set according to the next legal neighborhood, and do that 100 times. One of those has got to end up-- I mean it's an OR, so one of them has to work. Otherwise, the formula fails. And it will be false, because you're going to AND that over all of the neighborhoods in the picture. Is it possible to have a head on the far left of the configuration and one on the far right? You mean a head over here and a head over there? I mean, how'd the head get there? It can't happen. You know, the head has to come from a head above it. If you're going to be worrying about the details of the boundaries here, all that's fixable. So let's not lose sight of the main idea. I mean, if you understand the main idea, you can fix the little details. So I want to make sure you understand the main idea of what's happening. So let's finish up this proof. So in summary, we gave a reduction from 8 to SAT. This is what we needed. It was in those four pieces. And you really just need to argue that that formula we're building is not too big. And it's going to be basically the size of the tableau if you look at what we constructed. The number of variables is roughly the size of the tableau. And the amount of logic that we're putting into the formula is also going to be a fixed amount of logic independent of n for each of the variables in that tableau. And somebody asked me about the size-- how big the indices are. The indices for the x i value, the i and j values, technically, they're going to be numbers between 1 and n to the k. So you're going to have to write those down. And so that's going to be a slight additional logarithmic cost to write those things down. It's not really that interesting a point. And so the overall f is going to be computable in polynomial time because the output is not very big. And it's also not complicated to write the output down. So that's the end of the proof. I can take a couple of questions. Why can't we just check that the whole-- this is a good question. Why can't we just check that the whole row is legal? You can check that a row actually is a configuration. But to check that the row follows from the previous row, ultimately, the operation of a Turing machine is a local thing. I mean, the way it moves from one configuration to the next depends locally on how where the head is. And so really, that's just another way of-- the way I'm saying it is just really checking the whole configuration, but just doing it locally. I don't know if that's satisfying to you. Why don't I move on because I just want to make sure we have enough time to get to the very last part, which is a little bit-- I'm afraid, a little technical. So we're going to kind of shift gears now and talk about reducing SAT to 3SAT. And let's see how it goes. I don't always have the most success with presenting this little piece, because it's slightly a technical argument. But if you don't get it, don't worry. Just you have to accept that it's true. But I'd like to show it to you just to make the whole presentation complete in that sense. So I'm going to give a reduction that maps general formulas to 3CNF formulas. So that's how we map SAT to 3SAT. If you remember 3SAT is satisfiability but for three CNFs. So a conjunctive normal form in the form of those clauses, which are ANDed together. And each clause is an OR of a bunch of literals, which are variables or negated variables. So I want to convert phi to phi prime, which is 3CNF formula, but preserve the satisfiability. And phi prime is not going to be logically equivalent to phi, because I could do that, too. I can convert any formula to a logically equivalent CNF formula. Maybe not even a 3CNF, but yeah, you won't be able to get a 3CNF, but you can get a CNF. But it might be exponentially larger. And that's not good enough. I have to do the reduction in polynomial time. So I can't generate a much larger formula that's exponentially larger. And so I'm going to do that by adding additional variables. So it won't be logically equivalent because the new formula is going to have additional variables in it. I'm going to kind of do it by example. And we'll see how that goes. So here's phi, which is not in 3CNF. It's not even in CNF, because it's got ORs of ANDs appearing, which is not allowed to happen in a CNF. So how are we going to convert that into a 3CNF formula preserving the satisfiability? And just working it through with this example, I hope to at least give you some idea of how you do the conversion in general. So first of all, I'm going to represent this formula as a tree using its natural tree structure. So you understand. So a AND B becomes a AND b written as a tree. And then I OR that with c. So I get the tree structure here in sort of the natural way. And I'm going to label all of these intermediate nodes, which are associated now with operations. And I'm assuming also that the formula is fully parenthesized so that each operation I'm only thinking about is applying just the two-- it's a binary operation. And let's ignore negations for the minute, because negations, you can always push those through down to the leaves. But it's just going to make it too complicated. So negations turn out not to be a problem. So there's only going to be negations at the level of the inputs, not at the negation operations in the middle. So we have this tree structure here. And now I'm going to use these two logical facts. And I don't know if-- you've probably all seen ANDs and ORs, I hope. Otherwise, it's going to be really tough. But there's also other logical operators, such as the implication operator, where you have A implies B sort of as a logical operation. And so this requires that if A is true, then B is true. However, if A is false, B can be anything. And similarly if B is true, A can be anything. The only thing that's prohibited is that if A is true and B is false. That's the only thing that would be invalid. And so if you think about it, that's going to be equivalent to saying that either A is false or B is true. One of those has to be. And that's going to be logically equivalent to saying that A implies B. Another logical equivalence may be more familiar to you. It's just simply De Morgan's law, which says that if you have the not of A AND B, that's equivalent to saying the not of A or the not of B. I'm going to make use of both of these. Now, here, I want to-- I ran out of room on this slide. So I'm going to take myself out of the picture here for a minute. I had no place else to put this. So here we have-- if you're going to think of the AND in terms of its truth table, so here's a and b in terms of a and b. So 1 and 1 is 1, but all other settings of a and b yield 0 for the AND. And I'm going to represent those-- if you imagine a and b is going to be called c. I'm going to represent this information with four small formulas, which taken together, you AND them together, are going to force c to have the correct behavior associated with a AND b. So if a AND b are both 1, then c is 1. If a is 0 and b is 1, then it forces c to be 0. And similarly, every other setting besides a AND b being true, for C to be false, which is what you want when you have AND. So I'm going to write this expression here down with z1 being in the place of c by just taking those four expressions and ANDing them together. So this is exactly those same four expressions written out linearly. Now I want to do the same thing for z2, but now that's written in terms of an OR. So there's a slightly different truth table here up in this corner. So now if either one is 1, we get a 1 result. And so now if a AND b are true, you get c is true. However, if a is true and b is false, that still implies c is true. So I'm going to write down those rules for specifying how z2 must be set. And each one of these things is going to get converted into clauses, three clauses with three literals, using these rules over here. So I'm going to do that for each zi. And lastly, to make sure the whole thing is satisfied, which means there's an output of one here, I'm going to have one clause associated, which says that z4, the output, is 1. Now, I can convert all of those when I have a AND b implies c. That's logically equivalent to not a OR not b OR c. And the way you can see that is really by repeated application of these rules here. We're running a little low on time. So maybe you'll just have to check this offline. But quickly, a AND b implies c using the first equivalence is the not of this part, OR C. And then I can use De Morgan to convert that not of an AND to an OR of the nots. And then I can remove the parentheses because OR is associative. And so I get a clause, which is what I need. So each one of these guys is really equivalent to a clause. And so I just get a bunch of clauses. And actually, technically, this needs to be three, a copy of three things here. It should be z4 OR z4 OR z4, which is a lot. So check-in-- [INAUDIBLE] I realize my check-in is broken, because I only realized that last point just now as I was talking. So the actual value that you get in terms of-- oh, no, the number of clauses is correct. No, I take it back. This is fine. So if you understood what I was saying, hopefully, you can see how big the formula phi prime is in terms of the number of operations in phi. So let's see how many people get that. I acknowledge this may be a little on the technical side. OK. I'm going to close it, close it down. Please enter your value. OK. Yeah, the correct answer is 4k plus 1, because each one of these operations is going to end up being a row in this picture. Each operation is going to have a variable associated to it. It's going to become a row in this picture. And so then each row is going to have four clauses, which define what you need-- set what you need in order to force that variable to have the right value corresponding to that operation. And so then you need-- and you need one extra clause here for saying that this whole thing evaluates to true. So that's all I wanted to do today. We proved those two main theorems. And now we know that there are NP-complete problems. And all of the other problems that we can get from-- by reductions from these problems are also going to be NP-complete as long as they're in NP. So that's it. Feel free to put some questions into the chat, or move on to whatever else you're going to be doing next. So a good question here is, why is phi prime not logically equivalent with this construction? It can't be logically equivalent. Logically equivalent means that it gives you exactly the same function. If you set the variables in the same way, you get the same result coming out. Well, phi prime has more variables than phi does. So it wouldn't even make sense to talk about logical equivalence because they're two functions on different numbers of variables. So in that sense, it doesn't really make sense. What you could say is that for every setting of the overlapping variables, so the variables that appear in both phi and phi prime-- so those are the original variables of phi-- there's going to exist some setting of new variables, which is going to make the-- there's going to be-- there will exist some setting of the new variables which will make the two formulas agree, but that's not the definition of logical equivalence. So why-- going back to the proof, the satisfiability proof and the legal neighborhoods, could I go over why the number of legal neighborhoods is polynomial. The number of legal neighborhoods is not only polynomial. It's constant. It depends only on the machine. It does not depend on M. Because each cell can have at most some fixed number of-- can have the number of tape symbols plus the number of state symbols. That depends on the machine only. So now we have six tape cells for the six cells in a 2 by 3 neighborhood. So you're going to have that number to the sixth power. But still, it's a constant to the sixth power. It's still a constant. It doesn't depend on M. So it's not a question of even being polynomial. It's a constant value. It's a constant multiplier if you want to think about it in terms of the size of the formula that's going to result. Don't forget we're trying to make a formula which is-- the reduction has to be polynomial. It's a polynomial time reduction. So that means that as n increases, the time to calculate the reduction increases as a polynomial. But we're fixing M. So M does not change. So therefore anything that depends on M only is just going to be a constant impact on the formula. It's not going to be-- it doesn't depend on M. OK, everybody. Bye bye. See you.","A 2 by 3 neighborhood is sufficient to ensure that the tableau corresponds to a legitimate computation history because it is large enough to prevent situations where multiple heads could appear in the same tableau. By checking all 2 by 3 neighborhoods for legality, it guarantees that locally, only 'good' transitions can occur, thus maintaining the legitimacy of the entire tableau.",valid,Intermediate,18.404J,16 Cook-Levin Theorem,6Az1gtDRaAU.en-j3PyPqV-e1s_11_mp4
89,"What are the five components of a finite automaton as defined by a 5-tuple, and what does each component represent?","OK, so now we gave it this informal idea of a finite automaton. We're going to have to try to get a formal definition now, which is going to be a more mathematical way of saying the same thing that I just said. And the reason for having a formal definition is, for one thing, it allows us to be very precise. Then we'll know exactly what we mean by a finite automaton, and it should answer any questions about what counts and what doesn't count. It also is a way of providing notation. So it'll help us describe finite automata. And sometimes there might be an automaton where the picture is just too big, so you might want to be able to describe it in some mathematical terminology rather than by giving a picture. Or maybe you're going to be asked to give a family of automata, where there is going to be a parameter, N, associated with the class of languages you're trying to describe with the automaton. And then it'll be more helpful to describe it in this formal notation rather than as a kind of a picture, because it might be infinitely many pictures that are being needed. So maybe examples of that will come up now. So a finite automaton, we call it a 5-tuple. Don't be put off by that. A 5-tuple is just a list of five things. So a finite automaton, in our definition, is going to have five components. It's going to have Q, which is going to be a finite set of states, so it's going to be a finite set, which we'll designate as the states of the automaton. Sigma is the alphabet symbols of the automaton, another finite set. Delta is the transition function. That tells us how the automaton moves from state to state. Those describes how those transition arrows-- those arrows which connected the states with each other-- it describes them in a mathematical way instead in terms of a picture. And the way I'm doing that is with a function. So delta is a function which takes two things. So I'm hoping you've seen this notation before. I'll help you through it once, but this is the kind of thing I would expect you to have seen already. So we have Q cross sigma. So I'm going to give delta a state and an alphabet symbol. So Q is states, sigma is alphabet symbols. So you're going to get a state and an alphabet symbol, and it's going to give you back a state. So describing it kind of a little bit more detail, delta, if you give it state q and symbol a equals r, that means q, when you read an a, you go to r. So that's the way this picture gets translated into a mathematical function, which describes those transitions. And then now q0 is going to be the starting state. That's the one with the arrow coming in from nowhere. And F is the set of accepting states. So there's only going to be one starting state, but there might be several different-- or possibly even 0-- accepting states. That's all legal when we have a finite automaton. And so in terms of using the notation-- going back to the machine that we just had from the previous slide, which I've given you here again-- let me show you how I would describe this using this notation that comes out of the definition. So here is M1 again. It's this 5-tuple where Q now is the set-- q1, q2, q3-- that's the set of states. The input alphabet is 0, 1. It might vary in other automata. And f is the set q3, which has only the element q3, because this has just one accept state, q3. So I hope that's helpful. Oh, of course, I forgot the transition function, which here I'm describing as a table. So the transition function says if you have a state and an input alphabet, you can look up in the table where you're supposed to go under the transition function according to the state and the alphabet symbol that you're given. So, for example, if we were in state q2 here getting a 0, then q2 goes back to q1 so that q2 on 0 is q1. But q2 on 1 here is q3. OK? So that's how that table captures this picture. OK? And it's just a function. It's a way of representing a function, a finite function, in terms of this table here. So I realize, for some of you, this may be slow. We will ramp up in speed, but I'm trying to get us all together in terms","A finite automaton is defined as a 5-tuple consisting of the following components: Q, Σ, δ, q0, F. 
- Q: a finite set of states.
- Σ: the input alphabet, a finite set of symbols.
- δ: the transition function, which is a function that takes a state and an input symbol and returns a state (δ: Q x Σ -> Q).
- q0: the starting state, one of the states in Q.
- F: the set of accepting states, which may contain zero or more states from Q.",valid,Advanced,18.404J,1 Introduction Finite Automata Regular Expressions,9syvZr-9xwk.en-j3PyPqV-e1s_6_mp4
90,What are the main components and operations involved in converting a Context-Free Grammar (CFG) to a Pushdown Automaton (PDA)?," 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
18.404/6.840 Lecture 4 
Last time: 
- Finite automata → regular expressions 
- Proving languages aren’t regular 
- Context free grammars 
Today: (Sipser §2.2) 
- Context free grammars (CFGs) – definition 
- Context free languages (CFLs) 
- Pushdown automata (PDA) 
- Converting CFGs to PDAs 
1 
","The process of converting a CFG to a PDA involves understanding the definitions and characteristics of both Context-Free Grammars and Pushdown Automata. A CFG is defined by its rules which generate strings in a context-free language, and a PDA is basically an automaton that uses a stack. The conversion involves mapping the CFG's rules to transitions in the PDA, where the stack is used to manage the derivation process of the grammar, using pushing and popping operations to simulate the production rules of the CFG.",invalid,Advanced,18.404J,"Lecture 4 - Pushdown Automata, CFG ↔ PDA",a22fce6f6824c53dbb79a0da786966a6_MIT18_404f20_lec4_1_pdf
91,"What is required for Pr[ algorithm rejects f+, f- ]?","!""ROBP ∈BPP 
Theorem:   !""ROBP ∈BPP 
Proof attempt:  Let ( = “On input *+, *-
1.  Pick . random input assignments and evaluate *+ and *- on each one.
2.  If *+ and *- ever disagree on those assignments then reject.
If they always agree on those assignments then accept.”
What . to chose?  
If *+ ≡*- then they always agree so  Pr[ ( accepts *+, *- ] = 1
If *+ ≢*- then want  Pr[ ( accepts *+, *- ]  ≤⁄
+ 3
so want  Pr[ ( rejects *+, *- ]  ≥
⁄
- 3 .
But *+ and *- may disagree rarely, say in 1 of the 26 possible assignments.
That would require exponentially many samples to have a good chance of 
finding a disagreeing assignment and thus would require  . >
⁄
- 3 26.
But then this algorithm would use exponential time.
Try a different idea:  Run *+ and *- on non-Boolean inputs.
8+
0
1
0
1
*+
89
0
1
0
1
*-
7
","Pr[ algorithm rejects f+, f- ] must be greater than or equal to epsilon minus 1 over 3.",invalid,Basic,18.404J,"Lecture 23 - Probabilistic Computation, BPP",44f3286933ae429ff3cd163e8181ee46_MIT18_404f20_lec23_7_pdf
92,What does the Cook-Levin Theorem state about SAT?," 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
18.404/6.840 Lecture 16 
Last time: 
- NP-completeness 
- 3""#$ ≤P &'()*+ 
- 3""#$ ≤P ,#-.#$, 
Today: (Sipser §7.4) 
- Cook-Levin Theorem: ""#$ is NP-complete 
- 3""#$ is NP-complete 
1 
",Cook-Levin Theorem states that SAT is NP-complete.,invalid,Intermediate,18.404J,Lecture 16 - Cook‑Levin Theorem,8212b19fc5a34f500ca6acf03a3a7d74_MIT18_404f20_lec16_1_pdf
93,What does the space hierarchy theorem state about space-bound functions?,space hierarchy theorem so here is the statement of the theorem and it says for any bound think of s is going to be some you know space bound and again f has to satisfy some technical condition in yellow remember that it's yellow because that's going to be relevant later um uh so there's going to be some technical condition um for no matter what function you you have whatever space bound you have as long as it satisfies this condition which is a mild condition but you need it uh whatever space bound you have um you can find a language a which requires exactly that much space so if f is like n cubed we're going to find a language a that requires n cubed space if it's n to the hundredth we can find the language that requires into the 100th space and cannot be done within 1999 space whatever it is you can find a language that requires exactly that much space and if you like it a little bit more formally so that means that it can be decided in that much space but it cannot be decided in less space okay framing it in a slightly different way in terms of our space classes um i'm going to define a notion which is you know kind of it's not it's not said this way in the book but maybe it's a helpful way to write it down it's space little o of f of n so those are all the things that you can do by a function that's little o of f of n in space so space little o of f n is properly contained within space f of n in other words there's something here which is not in there okay picture pictorially i'm going to exhibit some language some explicit language a which i can do in this much space but not in any less now you know you can sort of think of this as a little bit like the situation for context-free languages and regular languages where we exhibited a particular language that differentiated that was it context-free but not regular and we're going to kind of do the same thing now but the one key difference is that in the case of separating the context free and the regular we could give a nice language like 0 to the k1 to the k here the language is not going to be so nice to describe it's going to be the language that some turing machine we're going to give decides but you're not going to be able to get a nice simple understanding of a it's going to be whatever that turing machine does and so in that sense it's not a very natural language um that's easy to sort of get your mind around um so the i outline and really you don't have to worry about this but maybe it helps it's really going to be a kind of a diagonalization proof um the way this machine d um is going to operate so d is going to give you my language a um so d is going to be designed and i'm going to show you d on the next slide uh d is going to run within my target space bound f of n and here's the key here's the kicker d is going to be designed to make sure that its language cannot be done in less space and the way it does that is it makes sure that its language is different from any language that that is um decidable by a turing machine in in less space and it's going to be different in at least one place so any d is going to guarantee that its language cannot be done in little o of f of n space because it's going to be different from every language that's doable in little o of f of n space somewhere okay that's the point and then the language a is going to be the language of this uh turing machine d okay so it looks like a tall order the d has to make sure that each you know that that for every machine its language differs uh from that machine's language if that machine is running in little of f event space but it's basically going to be a diagonalization so for all of the different possible inputs to d that input is going to actually code up a machine uh on which we're going to make sure that we're different from that machine if it's a small space machine okay let's see so i can take a couple of questions here does f have to be computable so that's going to be one of the conditions um that we're going to have to guarantee where f satisfies the technical condition yeah it's going to end up being half it's going to be computable but that's not enough um good question though uh okay so let's let's let's move on from there okay now so here is now what's what my job is to give you this turing machine d so d these language is going to be my my language a which i can which requires f of n space cannot be done unless okay oops i need to i need the full slide here so i have to take myself out um [Music] all right uh now this is my goal i want to exhibit this language a which i can do in this much space but not in any less and so i'm going to give this machine d as i mentioned where a is d's language d runs in order f event space and that sort of that achieves this part and d it makes sure that its language cannot be done in any less space so that achieves this part so it's different from the language of any machine that runs in little o event f of n space okay um [Music] so uh this is how d is gonna work okay i'm gonna try to give you a little picture uh to help help see the to accompany the description uh so d gets its input w which is of length n the very first thing d does is it marks off f of n's space because it's only allowed to use we're only going to allow d to use f of n space because otherwise we're in danger of d not of a not being in in space f of n so d is going to guarantee that by making sure it's going to mark off f of n space and if it ever tries to use more than that it just rejects and but by virtue of that we're sure that these language is in space f of n because d is an f of n space turing machine and it's going to be the side okay so this part so far is not too hard okay now we're going to start getting into the meat here so if w um now what we want to think of w as a description of a machine that we're going to feed that's that's going to run on w so this is going to a little bit you know back to an earlier when we talked about diagonalization so don't get thrown off by this um we if we're going to think of w not only as the input to d but it's also going to be the description of a machine and if it turns out that w is doesn't describe anything it's just a jump w then we're not not interested we're gonna we're just gonna reject on that w we're only interested in the w's that do describe some machine m okay so if m if w uh describes some machine m then we're gonna run m on w and we're going to do the do the opposite of what uh what m does that's the whole idea we're just going to uh make sure that what we're doing is not the same as what emma's doing so at a high level the the basic idea for this is is not hard um so we're going to simulate m on w if m x rejects then we'll accept and if m accepts then we'll reject we're just going to do the opposite um and i think that is so we have to be careful when we do the simulation this is a little bit of a detail but you know this is a proof where you need to pay attention to some details um the cost of simulating m on d is only a constant factor um because if m uses a certain amount of space when d is simulating m you know m may have a larger tape alphabet than d does but these can then encode um m's tape by using several cells for each of m's cells but it's only going to be a constant factor and that's important here because um we have to make sure that you know if this was a big blow up um d would not be able to run m um i i think i'm sort of arguing the details without making sure we understand the fundamental concept um so let me back up the point is that d is doing something the opposite of m now uh d can't be different from every m because d itself is a turing machine of course but but the thing is is that d is only running within f of n tape cells so it has to be able to do that simulation of m within that amount of tape if m is using a lot of tape then d is going to use a lot of tape and it's just going to reject so this is only going to really come into play getting being able to simulate m if m is using a small amount of using a small amount of space so that d can do the simulation okay so let's just see maybe uh so they're going to be some issues here but before i get to that let's just see what uh what your questions are how can a turing machine know if w is encoding some other turing machine no that's simple you know what what is a coding of a turing machine it's just you know the standard we have a standard coding um it's just you know coding the rules of the machine so it has to have states transition function blah blah blah so it just has to be some you know whatever our encoding for the turing machine is we can always test whether a string is a legitimate encoding of a turing machine so that that shouldn't be bad um somebody says why do we reject if we use more than f n cells isn't it okay to use order f of n yes it could be but we have to cut it off somewhere you know it might be it's okay we could use two f of n we could use 10 f of n but we have to have some constant for d and let's just kind of simply constant one so d has to run within f of n cells um and that's going to guaran that's going to be good enough for us okay do we have to make sure that m runs a little of f of n so we can't really tell whether m is running in little o of f of n or we can tell us whether we can finish the simulation so that's actually going to be maybe you can just hold off on that question because there is a point that we have to follow up on in that which is um uh just because you know we may or may not be able to finish simulating m on this w doesn't necessarily tell us what the asymptotic behavior of m is but we'll have to look at that in a bit okay so somebody's saying what happens if m loops on w that's going to be one of our issues we have to deal with that's a good question there step two alone can use them more than f of n cells yeah step two alone can use more than f of n cells if it does we're just going to end up projecting okay so we're getting good questions here some of them we're going to which i'm going to address anyway so why don't we just move on um okay so here is sort of a question i think this is one of the questions that that related to one of the ones that got asked what happens if it runs in little of f of n space so we we remember what we're trying to do is be different from every small space you know little o of f of n space machine so what if m runs a little o of f of n space but has a big constant so what i mean by that concretely is suppose d is an n cubed space so suppose we're trying to get a in in cubed space but show what's not in n squared space d is going to run an n cubed and what and we have to make sure that any machine that's running in n squared space cannot do the same language um so we're going to be different from that but the problem is that uh in uh the machine m might be running in n squared space but with a huge constant so it might be running in a million n squared so that's still a machine that's running in a little o of n cubed and we have to be different from it but for the particular w we're working on we might not have enough space to run m because of the huge constant it that con the asymptotic behavior is only going to be relevant well for large w for smaller b we may not see that we may not have enough space to run m so um what are we going to do to fix that we're going to run that m on infinitely many different w so it's going to be infinitely many different w's that are all going to encode the same m and the way i'm going to do that is by uh thinking of w as representing m but having an unbounded number of trailing zeros after that so i'm going to strip off the very first thing i'm going to do with w is i'm going to strip off the trailing zeros up into the final one i'm going to remove those and then take the rest and as the description of the machine so now i'm going to have potentially w's that have an enormous number of zeros at the end big enough so that i can see the asymptotic behavior of m and that if m is really running in little o of f of n space i'll have enough space to run m to completion on w and so then i'll be able to be different from it okay um so i'm kind of showing that over here so here's a very large w i'm going to strip off the trailing zeros the rest of it is just going to be m and i'm going to run this m on the whole w the entire w without the zero stripped off so now m is going to be running on a very large input um big enough so that d uh d which has asymptotically more space than m does will have enough space to run empty completion um now another question that got asked what happens if m loops that's going to be a problem because d always has to hold and if it just blindly simulates m then d might be looping on m none of m is going to use a lot of space by the way because then d is going to catch it in step one but if m uses his loops on a small amount of space then uh d might end up looping as presently constructed so what i'm going to do is i'm going to put a counter which makes it stop if it runs for 2 to the f of n space so basically because that's how long d could possibly run without looping anyway m could be running without looping anyway and so we're going to run it for this amount of this number of steps and uh i'm going to reject if it hasn't yet halted as well as uh that because it has to be looping at that point anyway um and so it's not interesting for us it doesn't matter what we're going to do,"The space hierarchy theorem states that for any space-bound function f that satisfies a specific technical condition, there exists a language that requires exactly that much space and cannot be decided in less space.",valid,Basic,18.404J,21 Hierarchy Theorems,vqFRAWeEcUs.en_8_mp4
94,What are the terminals in the given context-free grammar?,") 
/ 
} 
 
 
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
  
  
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
3 rules
R,S
0,1
S
Example of ') generating a string
S
0 S 1
0 S 1
R
ε
S
0S1
00S11
00R11
0011
% '
= 0-1-
≥0
In '):
Tree of
substitutions
Resulting
string
∈% ')
Context Free Grammars 
') S → 0S1 
S → R }
(Substitution) Rules 
R →ε 
Rule: Variable → string of variables and terminals 
Variables: Symbols appearing on left-hand side of rule 
Terminals: Symbols appearing only on right-hand side 
Start Variable: Top left symbol 
Grammars generate strings 
1. 
Write down start variable 
2. 
Replace any variable according to a rule 
Repeat until only terminals remain 
3. 
Result is the generated string 
4. 
%(') is the language of all generated strings. 
11 
Check-in 3.3 
(a) 001101 
(b) 000111 
(c) 1010 
(d) ε 
'3 
S → RR 
R → 0R1 
R →ε 
Check all of the strings that are in %('3): 
Check-in 3.3 
","Terminals are symbols appearing only on right-hand side, which in this case are 0 and 1.",valid,Basic,18.404J,"Lecture 3 - Regular Pumping Lemma, Finite Automata → Regular Expressions, CFGs",a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3_11_pdf
95,What is the role of m' in the proof process?,"  
 
 
 
 
 
 
 
 
  
 
  
 
  
  
 
 
     
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
  
 
  
 
 
 
 
 
 
 
 
 
  
  
 
 
   
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
NL = coNL (part 3/4) 
YES, if ( has a path * to % of length ≤1 
Let #$%ℎ"" (, *, % = 8 NO, if not 
Let 6"" = 6"" (, * = / #$%ℎ"" (, *, / = YES} 
Let !"" = !"" (, * = |6""| 
Theorem:  If some NL-machine computes !"", then some NL-machine computes #$%ℎ"" . 
Proof: “On input 〈(, *, %〉 
1. Compute !"" 
(
2. , ←0 
3. For each node / 
4. 
Nondeterministically go to (p) or (n) 
!"" = |6""|
(p) Nondeterministically pick a path from * to / of length ≤1. 
If fail, then reject. 
If / = %, then output YES, else set , ←, + 1. 
(n) Skip / and continue. 
5.  If , ≠ !"" then reject. 
6. Output NO” [found all !"" reachable nodes and none were %} 
11 
6"" 
* 
",The variable m' keeps track of the number of nodes found with a path from * and checks it against |S'|.,invalid,Basic,18.404J,"Lecture 20 - L and NL, NL = coNL",c9b742bd624556b45ac75ea2fb133b32_MIT18_404f20_lec20_11_pdf
96,What are the terminal symbols in the given context-free grammar for arithmetical expressions?,let's do another somewhat interesting example of a context-free grammar um this is a grammar that is um can generate arithmetical expressions involving pluses and times so here it is it has how many rules well there are six rules here each line represents two rules so e goes to e plus t or t t goes to t times f or f and f goes to uh parenthesis e parenthesis or a um now so the variables are going to be the symbols that appear on the left hand side et and f the terminal symbols which are going to be the symbols of the language that you're going to be generating um is going to be the plus the time symbols the parentheses are just terminal symbols here so they're nothing not playing any special role besides that and then you have the a which is representing kind of the um operand on which those operators uh would be working if there was actually an expression you would use but they're just symbols from the perspective of the of the grammar and lastly the start variable is going to be as normally appears on the upper left hand side of the grammar in terms of the way you write it down so sometimes you might specify a different start variable but,"The terminal symbols are the plus, the times symbols, the parentheses, and the symbol 'a', which acts as an operand.",valid,Intermediate,18.404J,4 Pushdown Automata Conversion of CFG to PDA and Reverse Conversion,m9eHViDPAJQ.en_4_mp4
97,What are EXPTIME and EXPSPACE?," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
Quick review of today 
1. Defined EXPTIME and EXPSPACE 
2. Defined EXPTIME- and EXPSPACE-completeness 
3. Showed !""#$%↑ is EXPSPACE-complete and thus !""#$%↑ ∉ PSPACE 
4. Defined oracle TMs 
5. Showed P( = NP( for some oracle * 
6. Discussed relevance to the P vs NP question 
10 
",EXPTIME and EXPSPACE are complexity classes defined during the lecture.,invalid,Basic,18.404J,"Lecture 22 - Provably Intractable Problems, Oracles",50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_10_pdf
98,What does EXPSPACE-complete mean?," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
Quick review of today 
1. Defined EXPTIME and EXPSPACE 
2. Defined EXPTIME- and EXPSPACE-completeness 
3. Showed !""#$%↑ is EXPSPACE-complete and thus !""#$%↑ ∉ PSPACE 
4. Defined oracle TMs 
5. Showed P( = NP( for some oracle * 
6. Discussed relevance to the P vs NP question 
10 
",EXPSPACE-complete is a designation for problems that are both in EXPSPACE and as hard as the hardest problems in EXPSPACE.,invalid,Basic,18.404J,"Lecture 22 - Provably Intractable Problems, Oracles",50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_10_pdf
99,What is the significance of the problem being EXPSPACE-complete?," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
Quick review of today 
1. Defined EXPTIME and EXPSPACE 
2. Defined EXPTIME- and EXPSPACE-completeness 
3. Showed !""#$%↑ is EXPSPACE-complete and thus !""#$%↑ ∉ PSPACE 
4. Defined oracle TMs 
5. Showed P( = NP( for some oracle * 
6. Discussed relevance to the P vs NP question 
10 
","A problem being EXPSPACE-complete indicates that it is in EXPSPACE and represents a class of problems that are among the hardest in EXPSPACE, which also shows that the problem is not in PSPACE.",invalid,Basic,18.404J,"Lecture 22 - Provably Intractable Problems, Oracles",50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_10_pdf
100,What is an oracle Turing Machine (oracle TM)?," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
Quick review of today 
1. Defined EXPTIME and EXPSPACE 
2. Defined EXPTIME- and EXPSPACE-completeness 
3. Showed !""#$%↑ is EXPSPACE-complete and thus !""#$%↑ ∉ PSPACE 
4. Defined oracle TMs 
5. Showed P( = NP( for some oracle * 
6. Discussed relevance to the P vs NP question 
10 
","Oracle TMs are a type of Turing Machine that can query an oracle, which is an entity that can provide solutions to specific decision problems instantly.",invalid,Basic,18.404J,"Lecture 22 - Provably Intractable Problems, Oracles",50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_10_pdf
101,What does P( = NP( imply about oracle TMs?," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
Quick review of today 
1. Defined EXPTIME and EXPSPACE 
2. Defined EXPTIME- and EXPSPACE-completeness 
3. Showed !""#$%↑ is EXPSPACE-complete and thus !""#$%↑ ∉ PSPACE 
4. Defined oracle TMs 
5. Showed P( = NP( for some oracle * 
6. Discussed relevance to the P vs NP question 
10 
",P( = NP( for some oracle * implies that oracle Turing Machines demonstrate instances where the P and NP complexity classes can exhibit different relationships based on the oracle used.,invalid,Basic,18.404J,"Lecture 22 - Provably Intractable Problems, Oracles",50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_10_pdf
102,Why is the concept of oracles relevant to the P vs NP question?," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
Quick review of today 
1. Defined EXPTIME and EXPSPACE 
2. Defined EXPTIME- and EXPSPACE-completeness 
3. Showed !""#$%↑ is EXPSPACE-complete and thus !""#$%↑ ∉ PSPACE 
4. Defined oracle TMs 
5. Showed P( = NP( for some oracle * 
6. Discussed relevance to the P vs NP question 
10 
","The concept of oracles is relevant to the P vs NP question because it shows how the relationship between P and NP can change when oracles are involved, highlighting the complexity and potential limitations of solving the P vs NP problem.",invalid,Basic,18.404J,"Lecture 22 - Provably Intractable Problems, Oracles",50cb369d1be3c7fbe0886e318aea13c2_MIT18_404f20_lec22_10_pdf
103,What is the problem with initially attempting to connect the accepting states of M1 to the start state of M2 when constructing a finite automaton for the concatenation of two regular languages?,"return to the material of the course. As you remember, we were looking at the closure properties for the class of regular languages. We started doing that. And if you recall, hopefully, we did closure under union. And then we tried to do closure under concatenation, which I have shown here on this slide, the proof attempt that we tried to do last time. And let's just review that quickly, because I think that's going to be helpful to see how to fix the problem that came up. So if you remember, we're given two regular languages, A1 and A2. And we're trying to show that the concatenation language A1A2 is also regular. And so the way we go about all of these things is we assume that A1 and A2 are regular. So that means we have machines, finite automata, for A1 and A2. We'll call them M1 and M2, that recognize A1 and A2, respectively. And then what we need to do in order to show the concatenation is regular is to make a finite automaton which recognizes the concatenation. And we tried to do that last time. So if you remember, that concatenation machine-- M, we're calling it-- what is it supposed to do? It's supposed to accept its input if it's in the concatenation language. And that means that the input can be split into two parts, x and y, where x is in the A language, and y is in the B lang-- y is accepted by M1-- and x is accepted by M1, and y is accepted by M2. Sorry I garbled that up. So x should be in A1, and y should be in A2. if you can split w that way, then M should accept it. So M has to figure out if there's some way to split the input so that the first machine accepts the first part, the second machine accepts the second part. And the idea that we came up with for doing that was to take these two machines, build them in to a new machine M, and then connect the accepting states for M to the start state-- connect the accepting states for M1 to the start state for M2. Because the idea would be that if M1 has accepted an initial part, well, then you want to pass control to M2 to accept the rest. But as we observed, that doesn't quite work. Because the first place to split w after you found an initial part that's accepted by M1 may not be the right place. Because the remainder may not be accepted by M2. You might have been better off waiting until you found another place that M1 accepted, later on in the string, say, over here. And then by splitting it over there, then maybe you do get successfully find that the remainder is accepted by M2. Whereas if you tried to split it in the first place, the remainder wouldn't have been accepted by M2. So all you need to do-- M has to know, is there some place to split the input so that you can get both parts accepted by the respective machines? The problem is that M might need to know the future in order to know where to make the split. And it doesn't have access to the future. So what do we do? So what we're going to do is introduce a new concept that will allow us to basically get the effect of M1-- and the-- sort of being able to see the future. And that new concept is going to be very important for us throughout the term.",The initial attempt to connect the accepting states of M1 to the start state of M2 doesn't work because the first place to split the input w after M1 accepts an initial part may not be the correct position. The remainder of the input might not be accepted by M2. Another place further in the string might allow both M1 and M2 to accept their respective parts. M cannot see the future to determine the correct place to split the input for both parts to be accepted by M1 and M2.,valid,Advanced,18.404J,2 Nondeterminism Closure Properties Conversion of Regular Expressions to FA,oNsscmUwjMU.en-j3PyPqV-e1s_3_mp4
104,What is a rejecting computation history?,"It's going to help me in the coming slides because they're a little bit dense. When I'm going to draw this sort of reddish, pinkish box around something, that means that I'm going to try to describe all strings except for that one. I want to avoid describing that one, because that's the rejecting computation history, but I want to describe everything else. That's my wish. So here's a check in before we move forward. But we can also-- maybe we should just take some questions, even before we launch the check in. How are we doing here? So, is our one describing-- well, R1 is a regular expression. Over here, we're talking about a-- this is just an ordinary computation history, but it ends with a reject. That's all. A rejecting computation history is just one that's a little different at the end. The machine just ended up rejecting instead of accepting. Otherwise everything has to be spelled out in accordance with the rules of the machine and the start configuration. Yeah, we were assuming one rejecting state. Yeah, that's the way we actually define Turing machines in the first place. But, who's arguing. Yeah, there's one reject state. We're all deterministic, correct. Why do we need the padding? Because I want to make these all the same size, all of these configurations. That's going to help me later in terms of describing the invalid configurations, the ones that are not legal configurations, legal rejecting configurations. So just simply a matter of convenience, but just accept it for now. I just want all of those configurations to be the same length in my rejecting computation history. Otherwise I'm not going to-- I'm just coding that rejecting computation history in this particular way. So people are asking about the details of bad start. That's yet to come. I have two more slides on this. So I'll tell you about how we're going to do those. So R bad-start-- that's a good question-- is R bad-start all-- these are all the strings that don't start this way. We'll see it in a second. But R bad-start are all the things that don't start with the-- they start bad. They're not starting with the start configuration. They're starting with some other junk. Do we need only one rejecting computation history? What about the other ones? This is a deterministic machine, so there's only going to be-- if I prescribe the lengths as I've done, there's going to be only one rejecting computation history. Because it's deterministic, everything is going to be forced from the beginning. Should R1 be the not of those three? No. R1 is describing all of the strings except, except this one string. So I'm capturing all the different possible ways a string could fail to be the string. It could start wrong. Could be wrong along the middle somewhere. So I have to union them together. Because I'm describing-- as I always believe, negations are the most confusing thing to everybody, including me. So we're describing all the things that are not this string. We're trying to stay away from that one. We want to describe everything else. All right, I think I'd better move on here. We've got a lot of questions. Talk to the TAs. All right, check in. How big is this rejecting computation history anyway? Interesting. There's a lesson here. I got a big burst of answers right at the very beginning. All wrong. But then the bright-- the people who took a little bit more time to think started getting the right answer, which is-- let's look. We've got a close election here folks, so now I have to report. Hope we don't have to do a recount. OK, come on guys. Answer up. 10 seconds. This is not super hard. Stop the count. Yeah, I think we'd better stop at this, we're on the edge. OK, 3 seconds. End polling. Share results. The correct answer is, in fact, c. Why is that? Because each configuration is 2 to the n to the k. So that's how much space the machine has, exponential space. But the amount of time, which is each one-- the number of configurations is going to be the amount of time that's used. It's going to be exponentially more even than that. So it's going to be 2 to the 2 to the n of the k, is how many steps the machine can run. And that's going to be how long the computation history could be. So it's a very long thing. And when you think about it, the regular expression we are generating, how big is that? The regular expression-- again, a lot of people playing off my comments here. Were the votes legal or not? OK. Let's focus here. So this is doubly exponentially large. How big is the regular expression that we're generating? Well that has to be produced in polynomial time, so it's only polynomially big. So we have this little teensy weensy, relatively speaking, regular expression, which is only n to the k. It's having to describe all strings except for this particular string, which is 2 to the 2 to the n to the k. So in a sense, this string that is related to that regular expression is doubly exponentially larger than that. And that kind of presents some of the challenge in doing the reduction, in constructing that regular expression.",A rejecting computation history is an ordinary computation history that ends with a reject. It's just one that's a little different at the end.,valid,Basic,18.404J,22 Provably Intractable Problems Oracles,N32bnUliSzo.en-j3PyPqV-e1s_6_mp4
105,Why is padding needed in rejecting computation histories?,"It's going to help me in the coming slides because they're a little bit dense. When I'm going to draw this sort of reddish, pinkish box around something, that means that I'm going to try to describe all strings except for that one. I want to avoid describing that one, because that's the rejecting computation history, but I want to describe everything else. That's my wish. So here's a check in before we move forward. But we can also-- maybe we should just take some questions, even before we launch the check in. How are we doing here? So, is our one describing-- well, R1 is a regular expression. Over here, we're talking about a-- this is just an ordinary computation history, but it ends with a reject. That's all. A rejecting computation history is just one that's a little different at the end. The machine just ended up rejecting instead of accepting. Otherwise everything has to be spelled out in accordance with the rules of the machine and the start configuration. Yeah, we were assuming one rejecting state. Yeah, that's the way we actually define Turing machines in the first place. But, who's arguing. Yeah, there's one reject state. We're all deterministic, correct. Why do we need the padding? Because I want to make these all the same size, all of these configurations. That's going to help me later in terms of describing the invalid configurations, the ones that are not legal configurations, legal rejecting configurations. So just simply a matter of convenience, but just accept it for now. I just want all of those configurations to be the same length in my rejecting computation history. Otherwise I'm not going to-- I'm just coding that rejecting computation history in this particular way. So people are asking about the details of bad start. That's yet to come. I have two more slides on this. So I'll tell you about how we're going to do those. So R bad-start-- that's a good question-- is R bad-start all-- these are all the strings that don't start this way. We'll see it in a second. But R bad-start are all the things that don't start with the-- they start bad. They're not starting with the start configuration. They're starting with some other junk. Do we need only one rejecting computation history? What about the other ones? This is a deterministic machine, so there's only going to be-- if I prescribe the lengths as I've done, there's going to be only one rejecting computation history. Because it's deterministic, everything is going to be forced from the beginning. Should R1 be the not of those three? No. R1 is describing all of the strings except, except this one string. So I'm capturing all the different possible ways a string could fail to be the string. It could start wrong. Could be wrong along the middle somewhere. So I have to union them together. Because I'm describing-- as I always believe, negations are the most confusing thing to everybody, including me. So we're describing all the things that are not this string. We're trying to stay away from that one. We want to describe everything else. All right, I think I'd better move on here. We've got a lot of questions. Talk to the TAs. All right, check in. How big is this rejecting computation history anyway? Interesting. There's a lesson here. I got a big burst of answers right at the very beginning. All wrong. But then the bright-- the people who took a little bit more time to think started getting the right answer, which is-- let's look. We've got a close election here folks, so now I have to report. Hope we don't have to do a recount. OK, come on guys. Answer up. 10 seconds. This is not super hard. Stop the count. Yeah, I think we'd better stop at this, we're on the edge. OK, 3 seconds. End polling. Share results. The correct answer is, in fact, c. Why is that? Because each configuration is 2 to the n to the k. So that's how much space the machine has, exponential space. But the amount of time, which is each one-- the number of configurations is going to be the amount of time that's used. It's going to be exponentially more even than that. So it's going to be 2 to the 2 to the n of the k, is how many steps the machine can run. And that's going to be how long the computation history could be. So it's a very long thing. And when you think about it, the regular expression we are generating, how big is that? The regular expression-- again, a lot of people playing off my comments here. Were the votes legal or not? OK. Let's focus here. So this is doubly exponentially large. How big is the regular expression that we're generating? Well that has to be produced in polynomial time, so it's only polynomially big. So we have this little teensy weensy, relatively speaking, regular expression, which is only n to the k. It's having to describe all strings except for this particular string, which is 2 to the 2 to the n to the k. So in a sense, this string that is related to that regular expression is doubly exponentially larger than that. And that kind of presents some of the challenge in doing the reduction, in constructing that regular expression.","Padding is needed in rejecting computation histories to make all configurations the same size, which is a matter of convenience for describing invalid configurations and particularly to make rejecting computation histories more uniform.",valid,Basic,18.404J,22 Provably Intractable Problems Oracles,N32bnUliSzo.en-j3PyPqV-e1s_6_mp4
106,What is R bad-start?,"It's going to help me in the coming slides because they're a little bit dense. When I'm going to draw this sort of reddish, pinkish box around something, that means that I'm going to try to describe all strings except for that one. I want to avoid describing that one, because that's the rejecting computation history, but I want to describe everything else. That's my wish. So here's a check in before we move forward. But we can also-- maybe we should just take some questions, even before we launch the check in. How are we doing here? So, is our one describing-- well, R1 is a regular expression. Over here, we're talking about a-- this is just an ordinary computation history, but it ends with a reject. That's all. A rejecting computation history is just one that's a little different at the end. The machine just ended up rejecting instead of accepting. Otherwise everything has to be spelled out in accordance with the rules of the machine and the start configuration. Yeah, we were assuming one rejecting state. Yeah, that's the way we actually define Turing machines in the first place. But, who's arguing. Yeah, there's one reject state. We're all deterministic, correct. Why do we need the padding? Because I want to make these all the same size, all of these configurations. That's going to help me later in terms of describing the invalid configurations, the ones that are not legal configurations, legal rejecting configurations. So just simply a matter of convenience, but just accept it for now. I just want all of those configurations to be the same length in my rejecting computation history. Otherwise I'm not going to-- I'm just coding that rejecting computation history in this particular way. So people are asking about the details of bad start. That's yet to come. I have two more slides on this. So I'll tell you about how we're going to do those. So R bad-start-- that's a good question-- is R bad-start all-- these are all the strings that don't start this way. We'll see it in a second. But R bad-start are all the things that don't start with the-- they start bad. They're not starting with the start configuration. They're starting with some other junk. Do we need only one rejecting computation history? What about the other ones? This is a deterministic machine, so there's only going to be-- if I prescribe the lengths as I've done, there's going to be only one rejecting computation history. Because it's deterministic, everything is going to be forced from the beginning. Should R1 be the not of those three? No. R1 is describing all of the strings except, except this one string. So I'm capturing all the different possible ways a string could fail to be the string. It could start wrong. Could be wrong along the middle somewhere. So I have to union them together. Because I'm describing-- as I always believe, negations are the most confusing thing to everybody, including me. So we're describing all the things that are not this string. We're trying to stay away from that one. We want to describe everything else. All right, I think I'd better move on here. We've got a lot of questions. Talk to the TAs. All right, check in. How big is this rejecting computation history anyway? Interesting. There's a lesson here. I got a big burst of answers right at the very beginning. All wrong. But then the bright-- the people who took a little bit more time to think started getting the right answer, which is-- let's look. We've got a close election here folks, so now I have to report. Hope we don't have to do a recount. OK, come on guys. Answer up. 10 seconds. This is not super hard. Stop the count. Yeah, I think we'd better stop at this, we're on the edge. OK, 3 seconds. End polling. Share results. The correct answer is, in fact, c. Why is that? Because each configuration is 2 to the n to the k. So that's how much space the machine has, exponential space. But the amount of time, which is each one-- the number of configurations is going to be the amount of time that's used. It's going to be exponentially more even than that. So it's going to be 2 to the 2 to the n of the k, is how many steps the machine can run. And that's going to be how long the computation history could be. So it's a very long thing. And when you think about it, the regular expression we are generating, how big is that? The regular expression-- again, a lot of people playing off my comments here. Were the votes legal or not? OK. Let's focus here. So this is doubly exponentially large. How big is the regular expression that we're generating? Well that has to be produced in polynomial time, so it's only polynomially big. So we have this little teensy weensy, relatively speaking, regular expression, which is only n to the k. It's having to describe all strings except for this particular string, which is 2 to the 2 to the n to the k. So in a sense, this string that is related to that regular expression is doubly exponentially larger than that. And that kind of presents some of the challenge in doing the reduction, in constructing that regular expression.","R bad-start refers to strings that don't start with the correct start configuration; they start with something else, essentially junk.",valid,Basic,18.404J,22 Provably Intractable Problems Oracles,N32bnUliSzo.en-j3PyPqV-e1s_6_mp4
107,Why can a deterministic Turing machine only have one rejecting computation history?,"It's going to help me in the coming slides because they're a little bit dense. When I'm going to draw this sort of reddish, pinkish box around something, that means that I'm going to try to describe all strings except for that one. I want to avoid describing that one, because that's the rejecting computation history, but I want to describe everything else. That's my wish. So here's a check in before we move forward. But we can also-- maybe we should just take some questions, even before we launch the check in. How are we doing here? So, is our one describing-- well, R1 is a regular expression. Over here, we're talking about a-- this is just an ordinary computation history, but it ends with a reject. That's all. A rejecting computation history is just one that's a little different at the end. The machine just ended up rejecting instead of accepting. Otherwise everything has to be spelled out in accordance with the rules of the machine and the start configuration. Yeah, we were assuming one rejecting state. Yeah, that's the way we actually define Turing machines in the first place. But, who's arguing. Yeah, there's one reject state. We're all deterministic, correct. Why do we need the padding? Because I want to make these all the same size, all of these configurations. That's going to help me later in terms of describing the invalid configurations, the ones that are not legal configurations, legal rejecting configurations. So just simply a matter of convenience, but just accept it for now. I just want all of those configurations to be the same length in my rejecting computation history. Otherwise I'm not going to-- I'm just coding that rejecting computation history in this particular way. So people are asking about the details of bad start. That's yet to come. I have two more slides on this. So I'll tell you about how we're going to do those. So R bad-start-- that's a good question-- is R bad-start all-- these are all the strings that don't start this way. We'll see it in a second. But R bad-start are all the things that don't start with the-- they start bad. They're not starting with the start configuration. They're starting with some other junk. Do we need only one rejecting computation history? What about the other ones? This is a deterministic machine, so there's only going to be-- if I prescribe the lengths as I've done, there's going to be only one rejecting computation history. Because it's deterministic, everything is going to be forced from the beginning. Should R1 be the not of those three? No. R1 is describing all of the strings except, except this one string. So I'm capturing all the different possible ways a string could fail to be the string. It could start wrong. Could be wrong along the middle somewhere. So I have to union them together. Because I'm describing-- as I always believe, negations are the most confusing thing to everybody, including me. So we're describing all the things that are not this string. We're trying to stay away from that one. We want to describe everything else. All right, I think I'd better move on here. We've got a lot of questions. Talk to the TAs. All right, check in. How big is this rejecting computation history anyway? Interesting. There's a lesson here. I got a big burst of answers right at the very beginning. All wrong. But then the bright-- the people who took a little bit more time to think started getting the right answer, which is-- let's look. We've got a close election here folks, so now I have to report. Hope we don't have to do a recount. OK, come on guys. Answer up. 10 seconds. This is not super hard. Stop the count. Yeah, I think we'd better stop at this, we're on the edge. OK, 3 seconds. End polling. Share results. The correct answer is, in fact, c. Why is that? Because each configuration is 2 to the n to the k. So that's how much space the machine has, exponential space. But the amount of time, which is each one-- the number of configurations is going to be the amount of time that's used. It's going to be exponentially more even than that. So it's going to be 2 to the 2 to the n of the k, is how many steps the machine can run. And that's going to be how long the computation history could be. So it's a very long thing. And when you think about it, the regular expression we are generating, how big is that? The regular expression-- again, a lot of people playing off my comments here. Were the votes legal or not? OK. Let's focus here. So this is doubly exponentially large. How big is the regular expression that we're generating? Well that has to be produced in polynomial time, so it's only polynomially big. So we have this little teensy weensy, relatively speaking, regular expression, which is only n to the k. It's having to describe all strings except for this particular string, which is 2 to the 2 to the n to the k. So in a sense, this string that is related to that regular expression is doubly exponentially larger than that. And that kind of presents some of the challenge in doing the reduction, in constructing that regular expression.","In a deterministic Turing machine, if the lengths of configurations are prescribed, only one rejecting computation history is possible because everything is forced from the beginning.",valid,Basic,18.404J,22 Provably Intractable Problems Oracles,N32bnUliSzo.en-j3PyPqV-e1s_6_mp4
108,How large can the computation history be for a Turing machine using exponential space?,"It's going to help me in the coming slides because they're a little bit dense. When I'm going to draw this sort of reddish, pinkish box around something, that means that I'm going to try to describe all strings except for that one. I want to avoid describing that one, because that's the rejecting computation history, but I want to describe everything else. That's my wish. So here's a check in before we move forward. But we can also-- maybe we should just take some questions, even before we launch the check in. How are we doing here? So, is our one describing-- well, R1 is a regular expression. Over here, we're talking about a-- this is just an ordinary computation history, but it ends with a reject. That's all. A rejecting computation history is just one that's a little different at the end. The machine just ended up rejecting instead of accepting. Otherwise everything has to be spelled out in accordance with the rules of the machine and the start configuration. Yeah, we were assuming one rejecting state. Yeah, that's the way we actually define Turing machines in the first place. But, who's arguing. Yeah, there's one reject state. We're all deterministic, correct. Why do we need the padding? Because I want to make these all the same size, all of these configurations. That's going to help me later in terms of describing the invalid configurations, the ones that are not legal configurations, legal rejecting configurations. So just simply a matter of convenience, but just accept it for now. I just want all of those configurations to be the same length in my rejecting computation history. Otherwise I'm not going to-- I'm just coding that rejecting computation history in this particular way. So people are asking about the details of bad start. That's yet to come. I have two more slides on this. So I'll tell you about how we're going to do those. So R bad-start-- that's a good question-- is R bad-start all-- these are all the strings that don't start this way. We'll see it in a second. But R bad-start are all the things that don't start with the-- they start bad. They're not starting with the start configuration. They're starting with some other junk. Do we need only one rejecting computation history? What about the other ones? This is a deterministic machine, so there's only going to be-- if I prescribe the lengths as I've done, there's going to be only one rejecting computation history. Because it's deterministic, everything is going to be forced from the beginning. Should R1 be the not of those three? No. R1 is describing all of the strings except, except this one string. So I'm capturing all the different possible ways a string could fail to be the string. It could start wrong. Could be wrong along the middle somewhere. So I have to union them together. Because I'm describing-- as I always believe, negations are the most confusing thing to everybody, including me. So we're describing all the things that are not this string. We're trying to stay away from that one. We want to describe everything else. All right, I think I'd better move on here. We've got a lot of questions. Talk to the TAs. All right, check in. How big is this rejecting computation history anyway? Interesting. There's a lesson here. I got a big burst of answers right at the very beginning. All wrong. But then the bright-- the people who took a little bit more time to think started getting the right answer, which is-- let's look. We've got a close election here folks, so now I have to report. Hope we don't have to do a recount. OK, come on guys. Answer up. 10 seconds. This is not super hard. Stop the count. Yeah, I think we'd better stop at this, we're on the edge. OK, 3 seconds. End polling. Share results. The correct answer is, in fact, c. Why is that? Because each configuration is 2 to the n to the k. So that's how much space the machine has, exponential space. But the amount of time, which is each one-- the number of configurations is going to be the amount of time that's used. It's going to be exponentially more even than that. So it's going to be 2 to the 2 to the n of the k, is how many steps the machine can run. And that's going to be how long the computation history could be. So it's a very long thing. And when you think about it, the regular expression we are generating, how big is that? The regular expression-- again, a lot of people playing off my comments here. Were the votes legal or not? OK. Let's focus here. So this is doubly exponentially large. How big is the regular expression that we're generating? Well that has to be produced in polynomial time, so it's only polynomially big. So we have this little teensy weensy, relatively speaking, regular expression, which is only n to the k. It's having to describe all strings except for this particular string, which is 2 to the 2 to the n to the k. So in a sense, this string that is related to that regular expression is doubly exponentially larger than that. And that kind of presents some of the challenge in doing the reduction, in constructing that regular expression.","The computation history can be 2 to the 2 to the n of the k in length, representing an extremely large number of steps the machine can run, which is doubly exponentially large in size.",valid,Basic,18.404J,22 Provably Intractable Problems Oracles,N32bnUliSzo.en-j3PyPqV-e1s_6_mp4
109,What is the process to convert a DFA into a regular expression?," 
 
 
   
 
 
 
 
 
   
  
 
   
 
 
 
 
 
   
   
  
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
DFAs → Regular Expressions 
Recall Theorem: If "" is a regular expressipn and # = % "" then # is regular 
Proof: Conversion "" → NFA & → DFA &′ 
& 
Regular 
Finite 
expression "" 
automaton 
Recall: we did a ∪ ab ∗ as an example 
Today’s Theorem: If # is regular then # = % "" for some regular expr "" 
Proof: Give conversion DFA & → "" 
WAIT! Need new concept first. 
2 
","To convert a DFA into a regular expression, the concept mentioned as needed but not elaborated on in the content indicates some intermediary steps or concepts need to be introduced first. The excerpt points out the theorem for converting a DFA '𝓐' into a regular expression "" but stops short of providing the detailed conversion process, suggesting that a new concept or preparatory step is necessary before proceeding with the conversion.",valid,Advanced,18.404J,"Lecture 3 - Regular Pumping Lemma, Finite Automata → Regular Expressions, CFGs",a77711ed3d212bf472f3485883a121e0_MIT18_404f20_lec3_2_pdf
110,"What is the significance of using the big O notation in analyzing the time complexity of algorithms, particularly for a one tape Turing machine deciding a language like a^k b^k?","So let's begin, then, by looking at this in more detail and taking as our starting point the theorem that says that on a one tape Turing machine, which is deciding this language A, a to the k, b to the k, you can do this on a one tape Turing machine, M, we're calling it. In at most some constant times n squared steps, for any input of length n, where the constant is going to be fixed independent of it. So this is going to be-- having a constant in-- factor in the complexity is going to come up often. And so instead of saying this over and over again, we're going to use a notation that m uses order n squared steps. I'm sure many of you seen that terminology as well. But just for the purposes of making sure we're all together on that, there is this big O and little o notation. I'm expecting you to be familiar with that. Big O is when you apply to functions, as it's done. You say f is big O of g, as for two functions f and g. It's basically if f is less than or equal to g, if you're ignoring constant factors. And you say f is little o of g if f is strictly less than g if you're ignoring constant factors. That's kind of one sort of informal way of looking at it. The precise definition is given up there on the slide. And if you haven't seen it before, make sure you look at it in the book, where it's all carefully described and defined. So that you're comfortable with these notions. Because it's really-- we're going to be using this without any further discussion from here on.","The big O notation is significant in analyzing the time complexity of algorithms because it succinctly conveys an algorithm's performance in terms of its input size, abstracting away constant factors which are not crucial for high-level understanding. In the context of a one tape Turing machine deciding a language like a^k b^k, it is used to express that the machine operates in order of n squared steps. This means that, ignoring constants, the operation count scales quadratically with the input size, providing a clear benchmark of the algorithm’s efficiency as input size increases.",valid,Advanced,18.404J,12 Time Complexity,asjAc90L8rE.en-j3PyPqV-e1s_3_mp4
111,What is the acceptance problem for deterministic finite automata and how can it be described as a language?,"if an English description is possible for a Turing machine? Well, you can always write down an English description for any machine. It's-- might be very technical looking, but if you can write it down in a formal way as states and transitions, then you can simply write down an English description, which would just be, follow those states. OK, let's move on. OK, this is going to be our first example of a algorithm that's going to answer a question about automata. And it's a very simple problem. It's a very simple problem to solve, because we want to start out easy. The name of the problem is the acceptance problem for deterministic finite automata, acceptance problem for DFAs. And I'm going to express it, as I always do, as a language.",The acceptance problem for deterministic finite automata (DFAs) is the problem of determining whether a given DFA accepts a specific string. This problem can be described as a language by defining the set of all pairs consisting of a DFA and a string such that the DFA accepts the string.,invalid,Advanced,18.404J,7 Decision Problems for Automata and Grammars,4MgN6uxd4i4.en-j3PyPqV-e1s_4_mp4
112,What happens to the size of the QBF at each recursive level?," 
 
 
 
 
 
 
 
 
   
 
 
  
 
 
 
 
 
 
 
  
 
  
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
  
Constructing !"",$: 3rd try 
!34, 35, 6 = ∃89:; !34, 3<=>, 6/2 ∧ !3<=>, 35, 6/2 
, , J
Check-in 18.3 
Would this construction still work if N were 
nondeterministic? 
(a) Yes. 
(b) No. 
∀(K ∈L) M
∀ 8B, 8C ∈ 
8E, 89:; , 89:;, 8F 
!3G, 3H, 6/2 
is equivalent to 
⋮ 
∀K K ∈L 
M
!"",$ = !3OPQRP, 3QSSTUP, V 
! 
defined as in Cook-Levin 
/
W = - . 
Size analysis: 
Each recursive level adds %('() to the QBF. 
Number of levels is log - ./ = % '( . 
→ Size is % 
'2( 
•
'(×'( = % 
9 
Check-in 18.3 
",Each recursive level adds %('() to the QBF.,valid,Basic,18.404J,Lecture 18 - PSPACE‑Completeness,88f789664d3236a64481714fc911d119_MIT18_404f20_lec18_9_pdf
113,What is the Church-Turing Thesis?," 
 
 
 
 
 
 
 
 
 
  
 
  
 
  
 
 
 
  
 
 
 
 
18.404/6.840 Lecture 7 
Last time: 
- Equivalence of variants of the Turing machine model 
a. Multi-tape TMs 
b. Nondeterministic TMs 
c. Enumerators 
- Church-Turing Thesis 
- Notation for encodings and TMs 
Today: (Sipser §4.1) 
- Decision procedures for automata and grammars 
1 
",A hypothesis about the nature of computable functions or what it means for a function to be computable.,invalid,Basic,18.404J,Lecture 7 - Decision Problems for Automata and Grammars,78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_1_pdf
114,Why is the language A_CFG decidable?," 
 
 
  
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
  
 
 
 
 
 
  
  
 
 
 
 
 
 
 
 
 
   
 
 
 
 
 
 
    
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
  
 
 
 
 
 
 
  
 
 
   
Corollary: Every CFL is decidable.
Proof: Let ! be a CFL, generated by CFG '.
Construct TM 34 = “on input )
1. Run /A−CFG on ', ) .
2. Accept if /A−CFG accepts
Reject if it rejects.”
Acceptance Problem for CFGs 
Let !CFG = { ', ) | ' is a CFG and ) ∈, ' } 
Theorem: ACFG is decidable 
Proof:   Give TM /A−CFG that decides !CFG . 
/A−CFG = “On input ', ) 
1. 
Convert ' into CNF. 
Recall Chomsky Normal Form (CNF) only allows 
2. 
Try all derivations of length 2|)| − 1. 
rules: 
3. 
Accept if any generate ).
A → BC 
Reject if not. 
B → b 
Check-in 7.2 
Lemma 1: Can convert every CFG into CNF. 
Proof and construction in book. 
Can we conclude that !PDA is decidable? 
a) Yes. 
Lemma 2: If 6 is in CNF and ) ∈ ,(6) then 
b) No, PDAs may be nondeterministic. 
every derivation of ) has 2|)| − 1 steps. 
c) 
No, PDAs may not halt. 
Proof: exercise. 
Check-in 7.2 
7 
","A_CFG is decidable because there exists a Turing machine A-CFG that can decide if a given string can be generated by a given context-free grammar (CFG). The Turing machine works by converting the CFG into Chomsky Normal Form (CNF) and then trying all derivations of the given string with length up to 2|w| - 1. It accepts if any derivation successfully generates the string, and rejects otherwise.",valid,Advanced,18.404J,Lecture 7 - Decision Problems for Automata and Grammars,78c0346bd81b6abcb2b1dde899adfc88_MIT18_404f20_lec7_7_pdf
115,Explain why a negative weight cycle in a graph could result in no finite shortest path between two vertices connected to the cycle.,"to our graph? Well, this comes up a lot in many applications. For example, distances in a road network. if I have a road from here-- so from Mass Ave, front of MIT, to Central Square, we might think of that as one road. Maybe you've got each road is a connection between two intersections in my road network. But an edge, it takes longer to go from, say, Vassar Street to Amherst. That takes a shorter amount of time than it does to go from Memorial Drive across the river to Beacon Street. So we might want to associate a larger distance or a weight associated with that edge. Latency in a network, for example. Maybe strength of relationships in a social network. And you could imagine that it's possible maybe you're ""frenemies"" with someone, you don't like them, and so maybe you have a negative weight associated with an edge in a social network. I'm not sure. Maybe not. But there are lots of applications where you might want weights on your edges. So that comes to the next question of, how do I represent-- how do I give the user, or the algorithm, these weights in my graph? We had a representation for a graph. Our common way to represent a graph was store a set data structure on the vertices mapping to the adjacencies of each vertex, which we stored in what we called an adjacency list, which really could be any data structure. Commonly, it's just an array of the adjacencies. But you could also have that be a set data structure, where you can query in constant time what-- if a particular adjacency exists in that graph. So there are two common ways to store these weights. One is just, with every adjacency, I'm going to store its weight. Maybe just in a tuple. With each adjacency, also store weight of the edge that it corresponds to, just in any way. A second way, instead of trying to modify our graph structure that we gave you before, let's just have a dictionary of all the edges mapping to their weights. And we already know how to do that. Just any set data structure-- any separate set data structure mapping edges to their, I guess, weights. Bad notation, but you get the idea. And it doesn't really matter how we're doing this. The assumption that we're going to rely on here is that, given an edge, given this vertex pair, I can query what the weight of that edge is in constant time. And so if I'm going to do that, I can either store it with maybe a hash table of hash tables-- a hash table mapping the set of vertices to their adjacencies, and then each adjacency list stores its adjacencies in a hash table. And that way, in constant time, I can check what the weight is there. Or here, I'm just-- I could even have just a single hash table mapping the pair, the edge, the tuple, constant size, to its weight. So either way is fine. We're just going to assume that we can query an edge in constant time-- the weight of an edge in constant time. OK, so this is that graph example. It's a little busy here. I'm probably going to erase that in just a second. But we're going to move on to what giving these edges weights implies for these problems that we've defined in terms of unweighted graphs. In particular, we are going to be concentrating on single-source shortest paths, again, at least for the next three lectures. We'll generalize that even still in the next lecture-- I mean, in the fourth-- in three lectures from now. But what we had here was that the distance before in an unweighted graph was the number of edges in the path. Here, we're going to generalize that notion kind of obviously to weighted paths. And the weight of a path, I'm going call it pi. So some weight of path pi is just going to be the sum of the weights in the edges in the path. So edge in the path, I'm going to sum their weights. So that's all the weight of a path means. It's just I'm going to sum all the weights in a path. So if I took a look at the-- maybe there's a particular path here. The path from a to b to f to g is going to be minus 5, minus 4, 2. It's going to be minus 9 plus 2 is minus 7. So just as an example. So then what is the shortest path then? Well, kind of obviously among all paths between two vertices, it's going to be one with the minimum weight. Yeah, question. AUDIENCE: Can I use the same edge more than once? JASON KU: Can I use the same edge more than once? Right now, you're asking about the distinction in our class which we have between paths and simple paths. So here, a weighted path doesn't really care if we visit an edge more than once. So if an edge appears more than once in pi, we have to count that more than once in the edge weight-- in the weight of the path. OK, great question. But what we're going to see later on is shortest paths cannot repeat an edge more than once in certain contexts. So we're going to get to the problem there a little later in this lecture. And we're going to solve that in tomorrow's lecture. But if you have-- we're getting a little ahead of ourselves. But when we have negative weights in a graph, it's possible that things go wrong. We're going to get there in about five lines. OK, great. So a shortest path-- and in this case, I'm going to clarify that this is the weighted shortest path-- is a minimum-- min-i-mum-- sure-- is a minimum weight path from s to t. Nothing too interesting here, but there's actually some subtleties we have to deal with here. We're going to call-- just like we did with breadth-first search when we talked about shortest paths, we're going to define an expression for what the distance or the shortest path weight is between two vertices. And I'm going to represent that by a delta. A delta from a vertex s to t is going to be-- let's-- I'm going to do the wrong thing first-- the minimum over the weight of all paths for all paths pi from s to t. OK, so there's a couple things that go wrong here. First thing that goes wrong is the same thing that went wrong with breadth-first search. Anyone remember what could go wrong with breadth-first search for this delta definition? AUDIENCE: Maybe there's no path. JASON KU: Maybe there's no path, right. So except if no path. Just by convention, we're setting delta s, t, to equal infinity. But there's one additional problem with weighted shortest paths, and it's a little subtle. It's possible that a finite shortest-- finite length shortest path doesn't exist. And what do I mean by that? It means I could keep going through edges in my graph and continually getting a shorter path. So if the shortest-- the minimum weight of a path from s to t actually goes through an infinite number of edges, then this isn't really well-defined. So I'm going to change this minimum here to-- in mathematics we would, just to be specific, we call it an infimum. So if in the case where the weight of a shortest path can approach arbitrarily small, then we'll call this thing minus infinity. So when does that occur? When does that occur? When could we have our shortest path go through lots and lots of vertices? Well, let's actually take a look at this example here. Can someone tell me what the shortest path is from a to actually any vertex in this graph? AUDIENCE: b, f, g, c. JASON KU: Ah, OK. So well, we could look at this path I have to b. Let's just take a look at b. I have a path going from a to b that is minus 5. OK, that's pretty good. That's pretty small. And it seems that if I go around this graph through another way, it might be bigger. So I go 7 plus 3 plus 8-- that's 15-- minus 1-- that's 14. That's much bigger than minus 5, so it seems like minus 5 should be good, right? Anyone have a problem with this path or a problem with this being the shortest path? And what your colleague just informed me was that there is something interesting happening here in this graph in particular. We have a cycle from b to f to g to c that has negative total weight back to b. This has minus 4 plus 2 plus 1 minus 1. So that total cycle has a cycle weight of minus 2, this negative weight cycle. So if I want to get to b, I could go there via this minus 5 weight edge. But every time I circled around this cycle, I incur minus 2 to my path weight. So I just keep going around this cycle over and over and over and over and over and over again, and I don't have any finite length minimum weight path. And in such cases, we just say that delta is minus infinity. So the problem here is that we could have negative weight cycles-- deserves a capital letter-- Negative weight cycles. It's a problem. In particular, if there exists a path from s to some vertex v that goes through a vertex on a negative weight cycle, then I can take that path to that vertex, circle around the negative weight cycle, and then proceed to v, and I can take that cycle as many times as I want. Then this delta s,v we're going to set to minus infinity. And in such cases, in our shortest paths algorithm, we don't really care about what the shortest path is. We're not even going to deal with parent pointers here, because there is no finite length shortest path. So I'm just going to kind of throw up my hands in the air and say, you know what, I can't return you a shortest path, but I might want to return to you a negative weight cycle. If you told me that this thing has bad weight, maybe I want you to tell me what a path is that goes through a negative weight cycle to get back to s. So that's what we're going to talk about next lecture. This lecture, we are not going to talk about that. We are going to talk about weighted shortest paths, though. That's what the remainder of this unit on graphs is really about is weighted shortest paths. OK, so in weighted shortest paths, we actually know an algorithm already to solve a subset of weighted shortest parts, namely BFS, right? Now, you're like wait, Jason, BFS doesn't solve weighted shortest paths. We didn't even know about weighted graphs then. How does that solve weighted shortest paths? Well, there's a couple cases where","A negative weight cycle in a graph allows a path to repeatedly traverse the cycle, reducing the overall path weight by the sum of the cycle's weight with each traversal. If there exists a path from a vertex s to another vertex v that goes through a negative weight cycle, the path weight can be decreased indefinitely by looping through the cycle. Consequently, there is no finite weighted shortest path as the weight can approach arbitrarily negative values, effectively making the shortest path weight minus infinity.",valid,Advanced,6.006,11 Weighted Shortest Paths,5cF5Bgv59Sc.en-j3PyPqV-e1s_4_mp4
116,"What is the purpose of right and left rotations in binary trees, and why is it important to maintain traversal order during these operations?","What does this something else need to do? This is just a tool for rebalancing the tree. So it should not change the data that's represented by the tree. What is the data represented by the tree? Traversal order. Traversal order is sacrosanct. We're not allowed to touch it. It's already defined two different ways, depending on whether you're using a set or sequence. So we want to modify the tree in a way that doesn't modify the traversal order. So we're exploiting redundancy. If you wrote down the traversal order in an array, there's exactly one representation of a given order. But in a tree, there's many representations. It could be a long line. It could be a balance thing. They could represent the exact same order on the nodes if you label them right. In fact, there are exponentially many different representations of the same thing. And we're going to exploit that, the same order, and define-- this is just a thing you need to know. Let me label, A, X, B, Y, C. You can tell I've drawn this diagram before many, many times. This is a very powerful tool in all tree data structures, which are most of data structures. And they are called right rotate of y and left rotate of x. So if I have this tree-- which I'm just black boxing some of the subtrees into little triangles. If I have a node, and it has a left child, then I'm allowed to right rotate this edge, which means take this edge and go like this-- 90 degrees, kind of. Or you could just think of it as rewriting it this way. Now, you might also have keeping track of the parent pointer. Parent pointer moves around. Before, this was the parent of y. Now it's the parent of x. So x and y are switching places. But we couldn't just swap these items around, because that would change traversal order. In this picture, x comes before y,","Rotations in binary trees, such as right and left rotations, are tools used for rebalancing the tree. They should not change the data represented by the tree, specifically the traversal order, which is crucial to maintain. This is because rotations are designed to exploit the redundancy in tree representations. Although a given traversal order can be represented in many different structures, rotations allow modifications without altering this fixed traversal order. This ensures the consistent representation of data in the tree while allowing structural changes needed for balancing.",valid,Advanced,6.006,7 Binary Trees Part 2 AVL,U1JYwHcFfso.en-j3PyPqV-e1s_16_mp4
117,What happens when deleting a leaf node in a binary tree?,,"If you want to delete a leaf node, you simply remove it. Leaf nodes are easy to delete because there is nothing to work with. This means deleting the pointer from its parent node.",valid,Intermediate,6.006,6 Binary Trees Part 1,76dhtgZt38A.uk-XlqDmAj_UsM_11_mp4
118,What is a dynamic array sequence in the context of data structures?,"3 
Lecture 2: Data Structures 
Linked List Sequence 
• Pointer data structure (this is not related to a Python “list”) 
• Each item stored in a node which contains a pointer to the next node in sequence 
• Each node has two ﬁelds: node.item and node.next 
• Can manipulate nodes simply by relinking pointers! 
• Maintain pointers to the ﬁrst node in sequence (called the head) 
• Can now insert and delete from the front in Θ(1) time! Yay! 
• (Inserting/deleting efﬁciently from back is also possible; you will do this in PS1) 
• But now get at(i) and set at(i, x) each take O(n) time... :( 
• Can we get the best of both worlds? Yes! (Kind of...) 
Data 
Operation, Worst Case O(·) 
Container 
Static 
Dynamic 
Structure 
build(X) 
get at(i) 
set at(i,x) 
insert first(x) 
delete first() 
insert last(x) 
delete last() 
insert at(i, x) 
delete at(i) 
Linked List 
n 
n 
1 
n 
n 
Dynamic Array Sequence 
• Make an array efﬁcient for last dynamic operations 
• Python “list” is a dynamic array 
• Idea! Allocate extra space so reallocation does not occur with every dynamic operation 
• Fill ratio: 0 ≤ r ≤ 1 the ratio of items to space 
• Whenever array is full (r = 1), allocate Θ(n) extra space at end to ﬁll ratio ri (e.g., 1/2) 
• Will have to insert Θ(n) items before the next reallocation 
• A single operation can take Θ(n) time for reallocation 
• However, any sequence of Θ(n) operations takes Θ(n) time 
• So each operation takes Θ(1) time “on average” 
","A dynamic array sequence is an array that is made efficient for last dynamic operations by allocating extra space so reallocation does not occur with every dynamic operation. It maintains a fill ratio (0 ≤ r ≤ 1), and when full, it allocates Θ(n) extra space at the end to maintain a fill ratio (e.g., 1/2). While a single operation can take Θ(n) time for reallocation, any sequence of Θ(n) operations takes Θ(n) time, making each operation take Θ(1) time 'on average.'",valid,Intermediate,6.006,Lecture 2 - Data Structures,79a07dc1cb47d76dae2ffedc701e3d2b_MIT6_006S20_lec2_3_pdf
119,How can we prove that the height of a height-balanced tree is logarithmic with respect to the number of nodes?,"So, the first claim is that if I could maintain height balance, then I will guarantee that h equals log n. So in other words, height balance implies balance. So let's prove that first quickly. And then, the interesting part is how do we actually prove-- or how do we actually maintain the balance property? We're going to do that using rotations. But how is a big question. So why does height balance imply balance? So what this is saying is that all height balanced trees have logarithmic height. So what I'd like to think about is sort of the least balanced height balanced tree. The least balanced one is going to have every node a mismatch. Let's say the left subtree is shallower than the right subtree by 1, and recursively all the way down. So every node has a gap here, a-- what do we call it-- a skew of 1, which I'm going to write-- I'm going to introduce some notation. I'll write a dissenting rightward arrow of this one is higher than the left subtree. So the easy way to think about this is this is sort of our worst case. This is going to be the fewest nodes for the maximum depth. Let's just count how many nodes are in this tree. I'm going to write that as a recurrence, which is the number of nodes in a tree of height h. So if this whole tree has height h, as we said in this picture, if I just subtract 2 from all these numbers, then this one has height h minus 2, and this one has height h minus 1. So how many nodes are in here? Well, this is a recurrence I'm going to write. So this will be N sub h minus 2. This will be N sub h minus 1. And then I just count how many nodes are in this picture. It is Nh minus 1 plus Nh minus 2 plus 1, or this node. Now you might ask, what is Nh a recurrence for? But it is the number of nodes in this sort of worst case if the worst case has total height h. So you can also think of it as what is the minimum number of nodes I could have in an AVL tree, which is a height balanced tree, that has a height h in a height balanced tree? OK, so now I just need to solve this recurrence. This recurrence look familiar-ish? It's like Fibonacci numbers. If I remove the plus 1, it's Fibonacci. And if you happen to know the Fibonacci numbers grow as, like, a golden ratio to the n, then we know that this is exponential, which is what we want. Because if Nh is exponential in h, that means h is logarithmic in N, because log is inverse of exponential. But maybe you don't know about Fibonacci numbers. And so we can still easily show that this is exponential as follows. I want to prove that it's at least an exponential, because that gives me that h is at most logarithmic. So we need a lower bound. And so we have these two terms which are hard to compare-- Nh minus 1 and Nh minus 2. It's kind of ugly. But if we're allowed to be sloppy-- and we'll see if we're not too sloppy-- and still get an exponential answer, let's just make them equal like so. So this is a true statement, in fact, strictly greater than. Why? Because I removed the plus 1. That should only make something smaller. And I replaced Nh minus 1 with Nh minus 2. Here, I'm implicitly using a fact, which is obvious by induction, that this tree on height-- if I take this tree versus this tree, this one has more nodes than this one. If I have larger height, this construction is going to build a bigger tree, at least as big. It doesn't even need to be strictly bigger. So certainly, Nh minus 1 is greater than or equal to Nh minus 2. Now, this is 2 times Nh minus 2. And this is an easy recurrence. This is just powers of 2. I keep multiplying by 2, and subtracting 2 from h. So this solves to 2 to the h over 2, maybe with a floor or something. But I'm using a base case here, which is N sub 0 equals 1. Maybe it's a ceiling then. But the point is this is exponential. So this implies that the height is always, at most, 2 times log n. This 2 corresponds to this 2. If you just invert this formula, this was a number of nodes is going to be at least 2 to the h over 2. And so h is, at most, 2 log n. So it's not log n. That would be perfect. But it's within a factor of 2 of log n. So AVL trees are always quite balanced. Number of levels is at most double what you need to store n nodes. Great. We're left with the main magic-- not domain magic. That's different. And let's see, we're going to use subtree augmentation. Keep that. Big remaining challenge is how do we maintain this high balance property using rotations? We have all the ingredients lined up for us. We have subtree augmentation. What does that let me do? It's relevant to AVL trees. Well, it lets me store height. I need to be able to compute the height of a node. That, in general, takes linear time, because I have to look at all the downward paths-- all the leaves within that subtree. But height is a subtree property-- so, yes-- height. Why? Because-- let me just write it here-- node.height equals 1 plus max of node.left.height and node.right.height and of max. Let me put this in a box. This equation, or I guess it's an assignment operation--","To prove that the height of a height-balanced tree is logarithmic with respect to the number of nodes, consider the least balanced height-balanced tree where every node has a skew of 1, meaning each left subtree is shallower than the right by 1. This is a worst-case scenario, which forms a recurrence: the number of nodes in a tree of height h is N(h) = N(h-1) + N(h-2) + 1. This recurrence resembles the Fibonacci sequence. If the Fibonacci numbers grow exponentially as the golden ratio to the n, then N(h) is exponential in h, implying h is logarithmic in N. Therefore, h is at most 2 times log N, as N(h) is at least 2 to the power of h/2. This demonstrates that AVL trees are always quite balanced.",valid,Advanced,6.006,7 Binary Trees Part 2 AVL,U1JYwHcFfso.en-j3PyPqV-e1s_20_mp4
120,"What is the relation used in the divide-and-conquer Bowling Algorithm to calculate B(i, j)?","6 
Lecture 15: Recursive Algorithms 
Bowling Algorithms 
• Let’s start with a more familiar divide-and-conquer algorithm: 
– Subproblems: B(i, j) = maximum score starting with just pins i, i + 1, . . . , j − 1, 
for 0 ≤ i ≤ j ≤ n 
– Relation: 
∗ m = b(i + j)/2c 
∗ Either hit m and m + 1 together, or don’t 
∗ B(i, j) = max{vm · vm+1 + B(i, m) + B(m + 2, j), B(i, m + 1) + B(m + 1, j)} 
– Topo. order: 
Increasing j − i 
– Base cases: 
B(i, i) = 0, B(i, i + 1) = max{vi, 0} 
– Original: 
B(0, n) 
– Time: 
T (n) = 4 T (n/2) + O(1) = O(n2) 
• This algorithm works but isn’t very fast, and doesn’t generalize well 
(e.g., to allow for a bigger ball that hits three balls at once) 
• Dynamic programming algorithm: use sufﬁxes 
– Subproblems: B(i) = maximum score starting with just pins i, i + 1, . . . , n − 1, 
for 0 ≤ i ≤ n 
– Relation: 
∗ Locally brute-force what could happen with ﬁrst pin (original pin i): 
skip pin, hit one pin, hit two pins 
∗ Reduce to smaller sufﬁx and recurse, either B(i + 1) or B(i + 2) 
∗ B(i) = max{B(i + 1), vi + B(i + 1), vi · vi+1 + B(i + 2)} 
– Topo. order: 
Decreasing i (for i = n, n − 1, . . . , 0) 
– Base cases: 
B(n) = B(n + 1) = 0 
– Original: 
B(0) 
– Time: 
(assuming memoization) 
∗ Θ(n) subproblems · Θ(1) work in each 
∗ Θ(n) total time 
• Fast and easy to generalize! 
• Equivalent to maximum-weight path in Subproblem DAG: 
B0 
B1 
B2 
B3 
· · · 
Bn 
max{v0, 0} 
max{v1, 0} 
max{v2, 0} 
v0 · v1 
v1 · v2 
v2 · v3 
","The relation is B(i, j) = max{v_m \cdot v_{m+1} + B(i, m) + B(m + 2, j), B(i, m + 1) + B(m + 1, j)}, where m = \lfloor(i + j)/2\rfloor.",valid,Intermediate,6.006,"Lecture 15 - Dynamic Programming, Part 1 - SRTBOT, Fib, DAGs, Bowling",9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_6_pdf
121,How does the dynamic programming approach for the Bowling Algorithm generalize the problem better compared to the divide-and-conquer method?,"6 
Lecture 15: Recursive Algorithms 
Bowling Algorithms 
• Let’s start with a more familiar divide-and-conquer algorithm: 
– Subproblems: B(i, j) = maximum score starting with just pins i, i + 1, . . . , j − 1, 
for 0 ≤ i ≤ j ≤ n 
– Relation: 
∗ m = b(i + j)/2c 
∗ Either hit m and m + 1 together, or don’t 
∗ B(i, j) = max{vm · vm+1 + B(i, m) + B(m + 2, j), B(i, m + 1) + B(m + 1, j)} 
– Topo. order: 
Increasing j − i 
– Base cases: 
B(i, i) = 0, B(i, i + 1) = max{vi, 0} 
– Original: 
B(0, n) 
– Time: 
T (n) = 4 T (n/2) + O(1) = O(n2) 
• This algorithm works but isn’t very fast, and doesn’t generalize well 
(e.g., to allow for a bigger ball that hits three balls at once) 
• Dynamic programming algorithm: use sufﬁxes 
– Subproblems: B(i) = maximum score starting with just pins i, i + 1, . . . , n − 1, 
for 0 ≤ i ≤ n 
– Relation: 
∗ Locally brute-force what could happen with ﬁrst pin (original pin i): 
skip pin, hit one pin, hit two pins 
∗ Reduce to smaller sufﬁx and recurse, either B(i + 1) or B(i + 2) 
∗ B(i) = max{B(i + 1), vi + B(i + 1), vi · vi+1 + B(i + 2)} 
– Topo. order: 
Decreasing i (for i = n, n − 1, . . . , 0) 
– Base cases: 
B(n) = B(n + 1) = 0 
– Original: 
B(0) 
– Time: 
(assuming memoization) 
∗ Θ(n) subproblems · Θ(1) work in each 
∗ Θ(n) total time 
• Fast and easy to generalize! 
• Equivalent to maximum-weight path in Subproblem DAG: 
B0 
B1 
B2 
B3 
· · · 
Bn 
max{v0, 0} 
max{v1, 0} 
max{v2, 0} 
v0 · v1 
v1 · v2 
v2 · v3 
","The dynamic programming approach uses subproblems defined as B(i) = maximum score starting with just pins i, i + 1, ..., n - 1, allowing for more flexibility like skipping a pin, hitting one pin, or hitting two pins. It has a time complexity of Θ(n), making it faster and easier to generalize (e.g., for a bigger ball that hits multiple pins at once).",valid,Intermediate,6.006,"Lecture 15 - Dynamic Programming, Part 1 - SRTBOT, Fib, DAGs, Bowling",9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_6_pdf
122,How is the maximum score obtained in the dynamic programming Bowling Algorithm according to its relation?,"6 
Lecture 15: Recursive Algorithms 
Bowling Algorithms 
• Let’s start with a more familiar divide-and-conquer algorithm: 
– Subproblems: B(i, j) = maximum score starting with just pins i, i + 1, . . . , j − 1, 
for 0 ≤ i ≤ j ≤ n 
– Relation: 
∗ m = b(i + j)/2c 
∗ Either hit m and m + 1 together, or don’t 
∗ B(i, j) = max{vm · vm+1 + B(i, m) + B(m + 2, j), B(i, m + 1) + B(m + 1, j)} 
– Topo. order: 
Increasing j − i 
– Base cases: 
B(i, i) = 0, B(i, i + 1) = max{vi, 0} 
– Original: 
B(0, n) 
– Time: 
T (n) = 4 T (n/2) + O(1) = O(n2) 
• This algorithm works but isn’t very fast, and doesn’t generalize well 
(e.g., to allow for a bigger ball that hits three balls at once) 
• Dynamic programming algorithm: use sufﬁxes 
– Subproblems: B(i) = maximum score starting with just pins i, i + 1, . . . , n − 1, 
for 0 ≤ i ≤ n 
– Relation: 
∗ Locally brute-force what could happen with ﬁrst pin (original pin i): 
skip pin, hit one pin, hit two pins 
∗ Reduce to smaller sufﬁx and recurse, either B(i + 1) or B(i + 2) 
∗ B(i) = max{B(i + 1), vi + B(i + 1), vi · vi+1 + B(i + 2)} 
– Topo. order: 
Decreasing i (for i = n, n − 1, . . . , 0) 
– Base cases: 
B(n) = B(n + 1) = 0 
– Original: 
B(0) 
– Time: 
(assuming memoization) 
∗ Θ(n) subproblems · Θ(1) work in each 
∗ Θ(n) total time 
• Fast and easy to generalize! 
• Equivalent to maximum-weight path in Subproblem DAG: 
B0 
B1 
B2 
B3 
· · · 
Bn 
max{v0, 0} 
max{v1, 0} 
max{v2, 0} 
v0 · v1 
v1 · v2 
v2 · v3 
","B(i) = max{B(i + 1), v_i + B(i + 1), v_i \cdot v_{i+1} + B(i + 2)}; it considers skipping the current pin, hitting one pin, or hitting two pins recursively.",valid,Intermediate,6.006,"Lecture 15 - Dynamic Programming, Part 1 - SRTBOT, Fib, DAGs, Bowling",9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_6_pdf
123,"What are the three cases for adjustment in an AVL tree when the lowest bad node has been identified, and how are rotations applied in each case to restore balance?","OK, so that's bad and we want to fix it. The obvious thing to do is to rotate this edge. Because that'll make this-- this is too high and this is too low. So if we rotate, this should go down by 1 and this should go up by 1. And that works most of the time. So case one is the skew of y. What is y? I want y to be the right child of x. Because we have a positive skew, we know there is a right child. Now, because this was the lowest bad node, we know that y is actually good. It's either right heavy-- or even the two subtrees have the same height-- or left heavy. The easy cases are when skew of y is either 1 or 0, which I will draw. So a double right arrow, let's say single right arrow-- so I'm just going to add some labels here to make this picture consistent-- k plus 1, k plus 2. I'm riding the heights. So this is an example where C is taller than B. A and B are the same height. And then if you compute the heights up here, indeed this one is right leaning. This one is doubly right leaning. Because this one has height k plus 1. This one has height k minus 1. That's bad. But if we do this right rotation on x, we get exactly what we want. So I'm just going to copy the labels on A, B, C-- we have k minus 1, k minus 1, and k-- and then recompute. That means this guy has height k, this one has height k plus 1. And now, all the nodes in this picture that I've highlighted-- A, B, and C haven't changed. They were height balanced before. They still are. But now, x and y-- x wasn't height balanced before, y was. Now, both x and y are height balanced. That's case one. In case two, the skew of y is flat, which means that this is a k, and this is a k, and this is a k plus 1, and this is a k plus 2. But still, all the nodes are balanced-- height balanced. They're still plus or minus 1. So those are the easy cases. Unfortunately, there is a hard case-- case three. But there's only one, and it's not that much harder. So it's when skew of y is minus 1. In this case, we need to look at the left child of y. And to be alphabetical, I'm going to rename this to z. So this one, again, is double right arrow. This one is now left arrow. And this is letter y. And so we have A, B, C, and D potential subtrees hanging off of them. And I'm going to label the heights of these things. These are each k minus 1 or k minus 2. This one's k minus 1. And now, compute the inside. So this is going to height k for this to be left leaning. So this is k plus 1, and this is k plus 2. But the problem is this is 2 higher than this. The height of z is 2 higher than the height of A. This case, if I do this rotation, things get worse, actually. I'll just tell you the right thing to do is-- this is the one thing you need to memorize. And let me draw the results. You can also just think of it as redrawing the tree like this. But it's easier from an analysis perspective to think about it as two rotations. Then we can just reduce. As long as we know how rotations work, then we know that this thing works-- ""works"" meaning it preserves traversal order and we can maintain all the augmentations. So now, if I copy over these labels-- the height labels-- I have k minus 1. I have, for these two guys, k minus 1 or k minus 2. The biggest one is k minus 1. This is k minus 1. And so this will be k. This will be k. This will be k plus 1. And lo and behold, we have a nice, height balanced tree in all three cases for this one node. Now, this was the lowest node. Once we update this one, it could be that we changed the height of the root. Before it was k plus 2, now it's k plus 1. Or sometimes, we keep it the same, like over in this case. And so now, we have to check the parent. Maybe the parent is out of balance. And we just keep walking up the node, and also maintain all the augmentations as we go. Then, we'll keep track of height and subtree size if we want them, or any other augmentations. And after order h operations, we will have restored height balanced property, which means all the way through, h equals order log n. And so all of our operations now are magically order log n.","Case one is when the skew of y is either 1 or 0, which allows for a right rotation on x to restore balance. Case two is when the skew of y is flat, and a single rotation corrects the imbalance. Case three, which is harder, occurs when the skew of y is -1, requiring a consideration of the left child of y, called z, and may involve a double rotation to achieve balance. After adjustments, the height balanced property is restored through these rotations, leading to order log n operations.",valid,Advanced,6.006,7 Binary Trees Part 2 AVL,U1JYwHcFfso.en-j3PyPqV-e1s_23_mp4
124,How can a set interface be used to manage a collection of students and their associated information?,"In any event, today, in our lecture, we're concerned with one particular interface, which is called a set. A set is exactly what it sounds like. It's a big pile of things. And so a set interface is like an object that just you can keep adding things to it. And then querying inside of my set, is this object here? Can I find it? And then maybe I associate with my objects in my set different information. So for example, maybe I have a set which represents all the students in our classroom today. Yeah, and all of you guys are associated with your student ID, which I believe at MIT is a number, which has less than sign, which is convenient. So we can sort all of you guys. And that might be the key that's associated to every object in the room. And so when I'm searching for students, maybe I enter in the student number. And then I want to ask my set, does this number exist in the set of students that are in 6.006? And if it does, then I can pull that student back. And then associated with that object is a bunch of other information that I'm not using to search-- so for instance, your name, your-- I don't know-- your social security number, your credit card number, all the other stuff that I need to have a more interesting profession.","A set interface allows adding objects, such as students, to it. Each student can be associated with a student ID, which is a number that can be sorted conveniently since it has a less than sign. To find out if a student with a specific ID is present in the set, you enter the student number and query the set. If the number exists in the set, the student can be pulled back, with associated information such as their name, social security number, or credit card number.",valid,Advanced,6.006,3 Sets and Sorting,oS9aPzUNG-s.en-j3PyPqV-e1s_4_mp4
125,"How can the structure of a complete binary tree be maintained implicitly without storing explicit pointers, and how are the relationships between nodes computed?","3 
Lecture 8: Binary Heaps 
Array as a Complete Binary Tree 
• Idea: interpret an array as a complete binary tree, with maximum 2i nodes at depth i except 
at the largest depth, where all nodes are left-aligned 
1 
d0 
______O____ 
2 
d1 
____O____ 
__O__ 
3 
d2 
__O__ 
__O 
O 
O 
4
d3 
O 
O 
O 
• Equivalently, complete tree is ﬁlled densely in reading order: root to leaves, left to right 
• Perspective: bijection between arrays and complete binary trees 
1 
Q = [0,1,2,3,4,5,6,7,8,9] 
2 
d0 
0 
-> 
______0____ 
3 
d1 
1 2 
-> 
____1____ 
__2__ 
4 
d2 
3 4 5 6 
-> 
__3__ 
__4 
5 
6 
5
d3 
7 8 9
->
7
8
9 
• Height of complete tree perspective of array of n item is dlg ne, so balanced binary tree 
Implicit Complete Tree 
• Complete binary tree structure can be implicit instead of storing pointers 
• Root is at index 0 
• Compute neighbors by index arithmetic: 
left(i) = 2i + 1 
right(i) = 2i + 2 

 
i − 1 
parent(i) = 
2 
","In a complete binary tree interpreted as an array, the structure is maintained implicitly by using index arithmetic instead of explicit pointers. The root is at index 0. The left child of a node at index i is located at index 2i + 1, the right child is at index 2i + 2, and the parent of a node at index i is located at index (i − 1) / 2.",valid,Advanced,6.006,Lecture 8 - Binary Heaps,40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_3_pdf
126,What does the relaxation process in Dijkstra's algorithm achieve?,"3 
Lecture 13: Dijkstra’s Algorithm 
Example 
Delete 
v from Q 
s 
c 
d 
a 
b 
δ(s, v) 
s 
0 
0 
Correctness 
a 
∞ 
10 
7 
7 
7 
d(s, v) 
b 
∞ 
∞ 
11 
10 
9 
9 
c 
∞ 
3 
3 
d 
2 
G 
∞ 
10 
∞ 
1
5
s 
a 
b 
c 
d 
4 
7
5 
8 
3 
2 
5 
• Claim: At end of Dijkstra’s algorithm, d(s, v) = δ(s, v) for all v ∈ V 
• Proof: 
– If relaxation sets d(s, v) to δ(s, v), then d(s, v) = δ(s, v) at the end of the algorithm 
∗ Relaxation can only decrease estimates d(s, v) 
∗ Relaxation is safe, i.e., maintains that each d(s, v) is weight of a path to v (or ∞) 
– Sufﬁces to show d(s, v) = δ(s, v) when vertex v is removed from Q 
∗ Proof by induction on ﬁrst k vertices removed from Q 
∗ Base Case (k = 1): s is ﬁrst vertex removed from Q, and d(s, s) = 0 = δ(s, s) 
∗ Inductive Step: Assume true for k < k0, consider k0th vertex v0 removed from Q 
∗ Consider some shortest path π from s to v0, with w(π) = δ(s, v0) 
∗ Let (x, y) be the ﬁrst edge in π where y is not among ﬁrst k0 − 1 (perhaps y = v0) 
∗ When x was removed from Q, d(s, x) = δ(s, x) by induction, so: 
d(s, y) ≤ δ(s, x) + w(x, y) 
relaxed edge (x, y) when removed x 
= δ(s, y) 
subpaths of shortest paths are shortest paths 
≤ δ(s, v 0) 
non-negative edge weights 
0)
≤ d(s, v 
relaxation is safe 
≤ d(s, y) 
v 0 is vertex with minimum d(s, v 0) in Q 
∗ So d(s, v0) = δ(s, v0), as desired 
","The relaxation process in Dijkstra's algorithm can only decrease estimates d(s, v) and it maintains that each d(s, v) is the weight of a path to v (or ∞). It ensures that when relaxation sets d(s, v) to δ(s, v), then d(s, v) = δ(s, v) at the end of the algorithm.",valid,Basic,6.006,Lecture 13 - Dijkstra’s Algorithm,d819e7f4568aced8d5b59e03db6c7b67_MIT6_006S20_lec13_3_pdf
127,What is the main argument for why most decision problems are uncomputable?,"This is just another word for being not in R. OK, and next thing I'd like to do is prove to you that most decision problems are uncomputable, or sketcher proof. So remember, decision problems are problems where the answer is just yes or no. This is a very special kind of problem. And even those, almost all of them, cannot be solved. So halting is an example of a problem we want-- we can't solve. This whole class, this 006, is about problems we can solve. But today I'm going to show you that, actually, those are in the minority. Most problems cannot be computed. This is very strange and also a little depressing. So we'll talk more about that in a moment. First let me argue why this is the case. So I'm going to be a little informal about what exactly is a computer program and what exactly is a decision problem. But roughly, all I need to do, the only level of precision I need is just to count how many are there. What is a computer program? Well, it's usually a file. What's a file? It's like a string of characters. What's a character? It's a string of bits. So a program is just, in the end, a string of bits, finite string of bits. We all understand that. Whatever language you define, in the end, every program is just a string of bits. And a string of bits we can translate into a number. So we can convert between strings of bits and numbers. When I say number, I mean what's usually called a natural number or a non-negative integer. This is usually represented by bold board bold-- blackboard bold capital N. So this is just 0, 1, 2, and so on. Now, what about decision problems? Decision problem is a specification of what we want to solve. So we can think of it as saying, for every input, is the answer yes or no? That's literally what a decision problem is. The only question is, what is an input? And we've talked about inputs and the size of inputs. And there's lots of different ways to measure them. But in the end, we can think of an input as a string of bits also. It's just a file. So a decision problem is a function from inputs to yes or no. And inputs we're going to say, well, that's a string of bits, which we can associate with a number in N. So here we can start to tie things together. So in other words, a program is a finite string of bits, and a problem is, in some sense, an infinite string of bits because there are infinitely many possible inputs. And for each of them, we specify yes or no. So this is basically an infinite string of bits. So we can imagine 011010001110, infinitely. Just some-- for every string of bits, we can say, OK, if your input is the number 0, here's the answer-- no. If your input is the number 1, then the answer is yes. If your input is the number 2, your answer is yes, and so on down this line. Every infinite string of bits corresponds to exactly one decision problem, which specifies for every possible input integer, which corresponds to a string of bits, what is the answer, yes or no? So this may seem subtle, or it may seem like not a big deal. This is a finite string of bits. This is an infinite string of bits. But mathematics has well studied this problem. And infinite strings of bits, there are very many of them, infinitely many. It's not surprising. There are also infinitely many integers. So maybe it doesn't seem that deep. But there's a difference in infinitude. Programs and integers are countably infinite. And infinite strings of bits are what's called uncountable. I think the most intuitive way to see this is, an infinite string of bits, if I put a decimal or a binary point in front, this encodes a real number between 0 and 1. So this is roughly a real number in 01. And when I'm writing approximately equal here, this really goes in both directions. Given a decision problem, I can define a string of bits, of course giving me the answer for all inputs. And I can convert that into a real number between 0 and 1. But also the other direction, if I take any real number, that is a corresponding decision problem. These are 1 to 1 bijection between them. And the bad news is, real numbers are uncountable, and natural numbers are countable, which means there's a lot more of these than there are these. So one way you might phrase this is, informally, the number of natural numbers is way smaller than the number of real numbers. And so from that, we derive that most problems are unsolvable, because every program solves exactly one decision problem. We can also run a program, conceptually, on all possible inputs, and we will figure out what function at solving. And if we don't allow random numbers in our program, which I'm not here, then every program solves exactly one decision problem. Possibly, it's even worse for us because multiple programs probably solve the same decision problem. They're just-- they add irrelevant lines of code or they don't do anything different. Or you run Bellman-Ford versus running Bellman-Ford five times, you'll get the same result. And that's actually the bad direction for us. We'd like to know whether there is a program that solves every decision problem. And because there are only this many programs and this many decision problems, it just-- there aren't enough to go around.","The main argument is that decision problems can be represented as infinite strings of bits corresponding to real numbers, which are uncountably infinite. In contrast, programs, which are finite strings of bits, are countably infinite. Since there are more decision problems (uncountable) than programs (countable), most decision problems cannot be computed because there aren't enough programs to solve them all.",valid,Advanced,6.006,19 Complexity,JbafQJx1CIA.en-j3PyPqV-e1s_4_mp4
128,What is the key distinction between directed and undirected graphs in terms of edge representation?,"some people call this network, but sometimes that term is overloaded with a few different kind of variations on the theme-- is a collection of two things. That's what this parentheses notation means. There's a set of vertices and a set of edges. And the edges, like you can see in the sort of third point on our screen here, are a subset of v cross v. Now this is fancy notation for something really, really simple. Because what is this telling me? This is telling me that an edge, like in the picture that we see on the screen here. it just just something that connects to vertices together. So if I think of there being a pair of vertices, like the from and the to, then that is a subset of the cross product of v and itself. So hopefully the notation in that third line on the screen makes some sense. This is just fancy notation for edges are pairs of vertices. But of course, inside of that notation there are two special cases that we care about in this class. One is when you have a directed graph, and one is when you have an undirected graph-- because I said them in opposite order from what's on the screen. So in an undirected graph, I guess we still think of an edge like a pair of vertices, but really I should have notated this slightly differently-- in fact, maybe I'll revise it in the slides before they go into OCW-- where instead of writing e equals w comma v, I should write in fact equals v comma w. And notice that there's a slight difference between the notation on the slide and what I've written on the board, which is the set notation here. What's the difference between parentheses and squiggly lines is that this guy is unordered. This is a set of things. And what's on the board is ordered-- or what's on the screen rather. And of course, in an undirected edge there's no such thing as an edge from w to v being distinct from an edge from v to w. Those are the same thing. They're undirected. It just is a notion of connectivity. Whereas in a directed graph, now we're going to use that parenthetical notation to say that the edge from w to v is different than the edge from v to w. That's going to make a big difference. So for example in the graph on the right-- let's maybe redraw it on the board here. So we have four vertices. I drew this last night, and I'm hoping that this example actually works. Like that-- can I get from the upper right vertex to the lower left vertex following edges in this graph? I heard one person. Everybody on three-- 1, 2, 3. AUDIENCE: No. JUSTIN SOLOMON: No, right. Because if I wanted to-- I mean maybe I think of drawing this path here-- but of course, if I would go from the upper right to the lower left-- this is like the ugliest thing I've ever done, I'm so sorry-- you can notice that the edges are pointing in the up direction here. So I'd have to go against the stream of the water, but that's not allowable in the directed graph case. Of course, I'm already anticipating the notion of a path which we haven't really defined yet. But I think intuitively, that's sort of the big difference between a directed and undirected graph. Does that distinction makes sense to all of you all or have I managed to lose you in four minutes or less? Excellent.","In a directed graph, an edge from vertex w to vertex v is considered distinct from an edge from vertex v to vertex w, and is represented using parenthetical notation that implies an order (e.g., (v, w)). In contrast, in an undirected graph, an edge between vertex v and vertex w is the same as an edge from vertex w to vertex v, and should ideally use set notation which implies no order (e.g., {v, w}). The core difference is that directed edges denote a specific direction of connectivity, while undirected edges simply represent a bi-directional connectivity without distinguishing the order of vertices.",valid,Advanced,6.006,9 Breadth-First Search,oFVYVzlvk9c.en-j3PyPqV-e1s_3_mp4
129,What is the purpose of the 'build(X)' operation in a Set interface?,"2 
Lecture 2: Data Structures 
Set Interface (L03-L08) 
• Sequence about extrinsic order, set is about intrinsic order 
• Maintain a set of items having unique keys (e.g., item x has key x.key) 
• (Set or multi-set? We restrict to unique keys for now.) 
• Often we let key of an item be the item itself, but may want to store more info than just key 
• Supports set operations: 
Container 
build(X) 
len() 
given an iterable X, build sequence from items in X 
return the number of stored items 
Static 
find(k) 
return the stored item with key k 
Dynamic 
insert(x) 
delete(k) 
add x to set (replace item with key x.key if one already exists) 
remove and return the stored item with key k 
Order 
iter ord() 
find min() 
find max() 
find next(k) 
find prev(k) 
return the stored items one-by-one in key order 
return the stored item with smallest key 
return the stored item with largest key 
return the stored item with smallest key larger than k 
return the stored item with largest key smaller than k 
• Special case interfaces: 
dictionary set without the Order operations 
• In recitation, you will be asked to implement a Set, given a Sequence data structure. 
Array Sequence 
• Array is great for static operations! get at(i) and set at(i, x) in Θ(1) time! 
• But not so great at dynamic operations... 
• (For consistency, we maintain the invariant that array is full) 
• Then inserting and removing items requires: 
– reallocating the array 
– shifting all items after the modiﬁed item 
Data 
Operation, Worst Case O(·) 
Container 
Static 
Dynamic 
Structure 
build(X) 
get at(i) 
set at(i,x) 
insert first(x) 
delete first() 
insert last(x) 
delete last() 
insert at(i, x) 
delete at(i) 
Array 
n 
1 
n 
n 
n 
",The 'build(X)' operation is used to construct or build a sequence from items in the provided iterable X.,invalid,Intermediate,6.006,Lecture 2 - Data Structures,79a07dc1cb47d76dae2ffedc701e3d2b_MIT6_006S20_lec2_2_pdf
130,What does BFS do when every edge in a graph is assigned a weight of 1?,"BFS. Can anyone think of such a scenario? So let's say, I mean, kind of what we did before was we counted the number of edges. So if we gave a weight of 1 to every edge in my graph, then just that graph, that weighted graph, corresponds to an unweighted graph using the other distance metric. So in that case, BFS just solves our problem. And in fact, we can generalize further. What if all of our weights were positive, but the same value? If it was all positive and the same value, then we could just divide by that value. Now we have an unweighted graph which we can run BFS, and then multiply shortest path distances by that value later on. And in fact, there's one further generalization we can make, which is a little bit of a tricky graph transformation problem.","If every edge in a graph is assigned a weight of 1, BFS solves the problem by counting the number of edges, effectively acting as if the graph is unweighted.",valid,Basic,6.006,11 Weighted Shortest Paths,5cF5Bgv59Sc.en-j3PyPqV-e1s_5_mp4
131,Why is it important to choose a hash function randomly and carefully instead of using a fixed hash function?,"3 
Lecture 4: Hashing 
• Always exists keys a, b such that h(a) = h(b) → Collision! :( 
• Can’t store both items at same index, so where to store? Either: 
– store somewhere else in the array (open addressing) 
∗ complicated analysis, but common and practical 
– store in another data structure supporting dynamic set interface (chaining) 
Chaining 
• Idea! Store collisions in another data structure (a chain) 
• If keys roughly evenly distributed over indices, chain size is n/m = n/Ω(n) = O(1)! 
• If chain has O(1) size, all operations take O(1) time! Yay! 
• If not, many items may map to same location, e.g. h(k) = constant, chain size is Θ(n) :( 
• Need good hash function! So what’s a good hash function? 
Hash Functions 
Division (bad): 
h(k) = (k mod m) 
• Heuristic, good when keys are uniformly distributed! 
• m should avoid symmetries of the stored keys 
• Large primes far from powers of 2 and 10 can be reasonable 
• Python uses a version of this with some additional mixing 
• If u ≫ n, every hash function will have some input set that will a create O(n) size chain 
• Idea! Don’t use a ﬁxed hash function! Choose one randomly (but carefully)! 
","Choosing a hash function randomly and carefully is important because if u (the universe of keys) is much larger than n (the number of keys), every hash function will have some input set that will create an O(n) size chain. Therefore, selecting a hash function this way helps avoid this issue and promote better distribution of keys, leading to better average-case performance.",invalid,Advanced,6.006,Lecture 4 - Hashing,ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_3_pdf
132,"How does tuple sort make use of auxiliary sorting algorithms to sort tuples, and why is sorting from least significant to most significant key crucial?","3 
Lecture 5: Linear Sorting 
Tuple Sort 
• Item keys are tuples of equal length, i.e. item x.key = (x.k1, x.k2, x.k2, . . .). 
• Want to sort on all entries lexicographically, so ﬁrst key k1 is most signiﬁcant 
• How to sort? Idea! Use other auxiliary sorting algorithms to separately sort each key 
• (Like sorting rows in a spreadsheet by multiple columns) 
• What order to sort them in? Least signiﬁcant to most signiﬁcant! 
• Exercise: [32, 03, 44, 42, 22] =⇒ [42, 22, 32, 03, 44] =⇒ [03, 22, 32, 42, 44](n=5) 
• Idea! Use tuple sort with auxiliary direct access array sort to sort tuples (a, b). 
• Problem! Many integers could have the same a or b value, even if input keys distinct 
• Need sort allowing repeated keys which preserves input order 
• Want sort to be stable: repeated keys appear in output in same order as input 
• Direct access array sort cannot even sort arrays having repeated keys! 
• Can we modify direct access array sort to admit multiple keys in a way that is stable? 
Counting Sort 
• Instead of storing a single item at each array index, store a chain, just like hashing! 
• For stability, chain data structure should remember the order in which items were added 
• Use a sequence data structure which maintains insertion order 
• To insert item x, insert last to end of the chain at index x.key 
• Then to sort, read through all chains in sequence order, returning items one by one 
1 
def counting_sort(A): 
2 
""Sort A assuming items have non-negative keys"" 
3 
u = 1 + max([x.key for x in A]) 
# O(n) find maximum key 
4 
D = [[] for i in range(u)] 
# O(u) direct access array of chains 
5 
for x in A: 
# O(n) insert into chain at x.key 
6 
D[x.key].append(x) 
7 
i = 0 
8 
for chain in D: 
# O(u) read out items in order 
9 
for x in chain: 
10 
A[i] = x 
11 
i += 1 
",Tuple sort uses auxiliary sorting algorithms to separately sort each key of the tuple. The order to sort them is from the least significant key to the most significant key. This order is crucial because sorting from least significant to most significant key helps in maintaining the stability of the sort. It ensures that sorting each subsequent key does not disrupt the order established by previous sorting steps.,valid,Advanced,6.006,Lecture 5 - Linear Sorting,78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5_3_pdf
133,How can one solve the Single-Source Shortest Paths problem quickly if given the order of vertices in increasing distance from the source?," 
 
 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) Lecture 
General Unweighted 
BFS 
|V | + |E| L09 
L11 
L12 
L13 (Today!) 
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Any 
Bellman-Ford 
Dijkstra 
|V | · |E|
General Non-negative 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 13: Dijkstra’s Algorithm 
Lecture 13: Dijkstra’s Algorithm 
Review 
• Single-Source Shortest Paths on weighted graphs 
• Previously: O(|V | + |E|)-time algorithms for small positive weights or DAGs 
• Last time: Bellman-Ford, O(|V ||E|)-time algorithm for general graphs with negative weights 
• Today: faster for general graphs with non-negative edge weights, i.e., for e ∈ E, w(e) ≥ 0 
|V | log |V | + |E| 
Non-negative Edge Weights 
• Idea! Generalize BFS approach to weighted graphs: 
– Grow a sphere centered at source s 
– Repeatedly explore closer vertices before further ones 
– But how to explore closer vertices if you don’t know distances beforehand? 
:( 
• Observation 1: If weights non-negative, monotonic distance increase along shortest paths 
– i.e., if vertex u appears on a shortest path from s to v, then δ(s, u) ≤ δ(s, v) 
– Let Vx ⊂ V be the subset of vertices reachable within distance ≤ x from s 
– If v ∈ Vx, then any shortest path from s to v only contains vertices from Vx 
– Perhaps grow Vx one vertex at a time! (but growing for every x is slow if weights large) 
• Observation 2: Can solve SSSP fast if given order of vertices in increasing distance from s 
– Remove edges that go against this order (since cannot participate in shortest paths) 
– May still have cycles if zero-weight edges: repeatedly collapse into single vertices 
– Compute δ(s, v) for each v ∈ V using DAG relaxation in O(|V | + |E|) time 
","By removing edges that go against this order, as they cannot participate in shortest paths, and then computing distances using DAG relaxation in O(|V| + |E|) time.",valid,Intermediate,6.006,Lecture 13 - Dijkstra’s Algorithm,d819e7f4568aced8d5b59e03db6c7b67_MIT6_006S20_lec13_1_pdf
134,What is the time complexity of Dijkstra's algorithm compared to Bellman-Ford when solving single source shortest paths and how does this relate to sorting algorithms?,"[SQUEAKING][RUSTLING][CLICKING] JASON KU: Welcome, everybody, to our lecture 14 of 6.006. This is our last lecture on graph algorithms, in particular, the last lecture we'll have on weighted shortest paths. But we're going to talk about a slightly different problem today, different than single source shortest paths. We're going to be talking about all-pairs shortest paths. But first, let's review our single source shortest paths algorithms. We had BFS, DAG relaxation, Dijkstra, which we saw last time, which gets pretty close to linear. V log V plus E is pretty close to linear. It's much closer to linear than the general algorithm we have for solving single source shortest paths, namely, Bellman-Ford, which is a little bit more like quadratic. This is like the difference between-- for sparse graphs, this is like the difference between sorting, using insertion sort and n squared, and merge sort in N log N, for example. We're going to get actually quite a big bonus for large input sizes by using Dijkstra when we can. Today, we're going to be focusing","Dijkstra's algorithm has a time complexity of V log V plus E, which is much closer to linear compared to Bellman-Ford, which is more quadratic. This is analogous to the difference between sorting algorithms such as insertion sort at n squared and merge sort at N log N, where Dijkstra provides a significant advantage for large input sizes, particularly in sparse graphs.",valid,Advanced,6.006,14 APSP and Johnson,EmSmaW-ud6A.en-j3PyPqV-e1s_1_mp4
135,What is the runtime complexity of the merge function in merge sort?,"So if we do our runtime in two minutes or less-- bare with me guys-- well, what is this merge function going to do? Well, in some sense, there's two branches. There's an if statement with two pieces. But both of those pieces call merge with one fewer piece in it. So in some sense, we have s of n equals s of n minus 1 plus theta of 1, which we already know from our previous proof means that s of n is equal to theta of n. So in other words, it takes linear time to merge. It makes sense intuitively because essentially you're touching every one of these things once with your two fingers. And now, probably the hardest part of the lecture, which I left zero time for, is deriving the runtime for the actual merge sort algorithm. And what does that look like? Well, that one's a little bit trickier because, of course, I call the merge sort algorithm twice, each time on a list that's half the size. In this class, we're going to assume that our list is always a power of 2 in its length. Otherwise, this analysis is a itty bitty bit more of a headache. So first of all, how long does it take to sort an array of length 1? I am not going to ask hard questions. Everybody? Yeah, it's just 1, right? Because there's nothing to do. An array of length 1 has one element and it's sorted. It's also the biggest element and the smallest element. And now, what does our algorithm do? Well, it makes two recursive calls on lists that are half the length. And then it calls that merge function. And we know that the merge function takes theta of n time. Does that make sense? So one thing we might do, because we have some intuition from your 6042 course, is that we think that this thing is order n log n because it makes the two recursive calls. And then it puts them together. And let's double check that that's true really quick using the substitution method. So in particular, on the left-hand side here, maybe I have cn log n. Now, I have 2 c. Well, I have to put an n over 2 log n over 2 plus theta of n. And I want to double check that this expression is consistent. I've got about a foot to do it in. So remember-- let's see. If we use our favorite identities from high school class that you probably forgot, remember that log of 2 things divided by each other is the difference of the logs. So this is really 2. OK. 2 divided by 2 is 1. So this is c times n times log n minus log of 2 plus theta n. I'm already out of time. But notice that there's a c n log n on the right-hand side. There's a c n log n on the left-hand side. So those two things go away. And what am I going to be left with? I'm going to be left with theta of n equals cn log of 2. Notice that c and log 2 are both constants. We have a theta event on the left-hand side. So there's order in the universe. And we've derived our runtime. So I know I rest a little bit through merge sort. I'm sure that Erik and Jason can review this a little bit next time. But with that, we'll see you, what? Thursday and Friday. And it's been a pleasure to talk to you all.","The runtime complexity of the merge function in merge sort is theta of n (θ(n)), which means it takes linear time to merge.",valid,Basic,6.006,3 Sets and Sorting,oS9aPzUNG-s.en-j3PyPqV-e1s_22_mp4
136,How can subtree properties in binary trees be efficiently maintained when nodes are added or removed?,"then how is it happening in constant time? Wouldn't it be happening [INAUDIBLE]?? ERIK DEMAINE: Why is this-- OK, good question. So one natural way, you can think of this as a recursion, which gives you a recursive algorithm. So I wrote-- but didn't write it. But I could have written size of node equals this-- size of node.left plus-- and that would give you a linear time algorithm to count the size. And if you don't have any information, that is what you would do. And that would be very painful. So that would make this algorithm really slow. If I'm calling size as a recursive function, it's bad. What I'm instead doing is storing the sizes on every single node and pre-computing this. So in fact, I'm going to define the size of node in-- so this is the definition mathematically. But the algorithm for this function is just going to be return node.size. So that's constant time. So the challenge now is I have to keep these sizes up to date, no matter what I do to the tree. And you could look back at last lecture and see, OK, what were all the changes that I did in a tree? We only did changes during insert and delete. And I will just claim to you, when we did insert and delete, what they ended up doing in the end, they add or remove a leaf of the tree. Remember, a leaf was a node with no children. So let's just think about if I add a new leaf in a tree-- here's a tree, suppose I add a leaf here-- which subtrees change? Well, which subtrees contain that node? It is its own new subtree. Then it's in its parent subtree, and its grandparent subtree, and the overall subtree. In general, these nodes are called the ancestors of this node that we added. And those are the ones that update. This subtree over here didn't change. It didn't change size. And because it's a subtree property, no subtree property will change over here, because the subtree was untouched. So when I touch this guy, I just have to update the subtree property here, update the subtree property here, update subtree property here. How many of these are there? Yeah? h-- I'll say order h to be safe. But I think it's exactly h. So also, when I remove a leaf, the same thing-- if I remove this leaf, then the subtrees that change are exactly its former ancestors. Cool, so we're going to update those order h ancestors in order up the tree. So what do I mean by update? I mean apply this rule. For size, it's this rule. But in general, the subtree property gives me an update rule that takes constant time. And so I'm going to apply that update rule to this node, which will fix whatever property is stored in there. Maybe there's more than one property. And then I'll apply it to this node. And because this is already correct by induction, and this is already correct because I didn't touch this subtree-- it's unchanged-- then I can update the value at this node-- the property at this node in constant time. Then I update this one. And because this one is already correct by induction, and this one is already correct because this subtree is unchanged, I can update the property correctly here in constant time. So when I make a change in order h time, because I'm making h calls to this constant time algorithm, I can update a constant number of subtree properties. This is very powerful. Data structure augmentation is super useful. You will use it on your problem set. We will use it again today. Let me give you some examples of subtree properties. They could be-- common ones are, like, the sum, or the product, or the min, or the max, or sum of squares, or all sorts of things, of some feature of every node in the subtree. In fact, subtree size is an example of such a thing. It is the sum over all nodes in the subtree of the value 1. It's another way to say count the number of nodes. But you could also say, what's the sum of the keys in these nodes? Or you could say, what's the maximum key in these nodes? Or you could say, what is the maximum value in these nodes? You can take any property. It doesn't have to be key. It doesn't have to be anything in particular. It's very powerful. You can take all sums, products and maintain them as long as they're downward looking-- as long as you're only thinking about the subtree. Some examples of things you cannot maintain are-- not a nodes index. So if you get a little bit too excited about augmentation, you might think, oh, I could do everything. I needed to support subtree_at, or let's just say, get_at globally, I wanted to know what is the ith node in my tree? Well, I'll just use data structure augmentation and store in every node what is its index, 0 through n minus 1. I can't maintain that efficiently. Because if I insert at the beginning of my traversal order, then all the indices change. So that's an example of a edit. So if I insert a new node over here, so this guy's index was 0, now it's 1. This guy's index was 1, now it's 2. This was 2, now it's 3, and so on. Every node changes its index. Index is not a subtree property, and that's why we can't maintain it. Because it depends on all of the nodes in the tree. Or it depends on all the nodes to its left-- all the predecessors.","Subtree properties in binary trees are efficiently maintained when nodes are added or removed by storing these properties at each node and updating them only for the node's ancestors. When a new leaf is added or a leaf is removed, only the subtree properties of its ancestors need to be updated. Since these updates are made in constant time for each ancestor, and there are h ancestors where h is the height of the tree, the total update time is order h, allowing efficient maintenance of subtree properties.",valid,Advanced,6.006,7 Binary Trees Part 2 AVL,U1JYwHcFfso.en-j3PyPqV-e1s_11_mp4
137,How do you determine the optimal way to hit pins in this carnival bowling game to maximize the score given the possibility of negative values and pair combinations?,"you will just hit that one pin. And if you bowl in the middle between two pins, you will knock down-- that's a ball, sorry-- you will knock down two pins. And this is your model of bowling, model of computation. Now, what makes this interesting is that the pins have values. Pin i has value-- this is obviously a toy problem, though this problem-- this type of bowling does go back to 1908, it was also a toy problem in that setting. So each of these bowling pins has some number on it, let's say 1, 9, 9-- I'll do a slightly more interesting example, maybe another one here and a 2 and a 5 and a 5, something like this. OK. Or maybe make it a little more interesting. Let's put some negative numbers on here. OK. And the model-- so you're at the carnival bowling. Each pin has different-- potentially different values. And the model is if you hit one pin, i, then you get vi points. So that's straight forward. To make it interesting, when you hit two pins, you get the product. So if I hit two pins, it's always i and i plus 1 for some I. You get vi times vi plus 1 points. This is the game you're playing. And it doesn't really matter that this is a product. Product is just some weird function that's hard to imagine. If you stare at this long enough, you should convince yourself that the optimal solution is probably to-- so, for each of these numbers, I could leave it singleton or pair it with its left neighbor or pair it with its right neighbor. But the pairings can't overlap because once I hit a pin, it's gone. It's knocked over. It disappears. So because of these nine, which are a very high value, what I'd probably like to do is hit both of them together, so pair them up, because 9 times 9 is 81. That's really big, much better than hitting them individually or hitting 9 times 1 or 9 times 2. 1 and 1 is kind of funny, because it's actually better to hit them individually. That will give you two points, whereas if I'd pair them up, I only get one point. 2 and minus 5, that seems bad. Negative 10 points. My goal is to maximize score. Do you have to hit all the pins? Let's say no, you don't have to hit all the pins. So I could skip the minus fives. But in fact, here, because they're adjacent, minus 5 times minus 5 is good. That's 25 points. So the optimal solution for this particular instance are to hit all the pins, these positive, these together, these together. If I added, for example, another pin of minus 3 here, I would choose not to hit that pin. Good question. So you just play until you are tired.","To determine the optimal way to hit pins and maximize the score, consider each pin individually or pair it with its left or right neighbor. The pairings cannot overlap. Calculate the score for individual pins as their value and for pairs as the product of their values. Opt for the pairing that yields the highest score. Negative values can contribute positively to scoring if paired such that their product is positive, for example, two negative values. Also, you can choose to skip hitting certain pins if it benefits the overall score.",valid,Advanced,6.006,15 Dynamic Programming Part 1 SRTBOT Fib DAGs Bowling,r4-cftqTcdI.en-j3PyPqV-e1s_10_mp4
138,What is a binary heap and how does it simplify the priority queue operations compared to AVL trees?,"2 
Lecture 8: Binary Heaps 
Priority Queue: Set AVL Tree 
• Set AVL trees support insert(x), find min(), find max(), delete min(), and 
delete max() in O(log n) time per operation 
• So priority queue sort runs in O(n log n) time 
– This is (essentially) AVL sort from Lecture 7 
• Can speed up find min() and find max() to O(1) time via subtree augmentation 
• But this data structure is complicated and resulting sort is not in-place 
• Is there a simpler data structure for just priority queue, and in-place O(n lg n) sort? 
YES, binary heap and heap sort 
• Essentially implement a Set data structure on top of a Sequence data structure (array), using 
what we learned about binary trees 
Priority Queue: Array 
• Store elements in an unordered dynamic array 
• insert(x): append x to end in amortized O(1) time 
• delete max(): ﬁnd max in O(n), swap max to the end and remove 
• insert is quick, but delete max is slow 
• Priority queue sort is selection sort! (plus some copying) 
Priority Queue: Sorted Array 
• Store elements in a sorted dynamic array 
• insert(x): append x to end, swap down to sorted position in O(n) time 
• delete max(): delete from end in O(1) amortized 
• delete max is quick, but insert is slow 
• Priority queue sort is insertion sort! (plus some copying) 
• Can we ﬁnd a compromise between these two array priority queue extremes? 
","A binary heap is a simpler data structure for implementing a priority queue, which allows for an in-place O(n log n) sorting algorithm known as heap sort. Unlike AVL trees that support operations such as insert, find min, find max, delete min, and delete max in O(log n) time but are complex and non-in-place, binary heaps use an array-based approach. Priority queue operations can be efficiently executed by leveraging array structures while maintaining heap order properties without the complexities involved in AVL tree balancing.",valid,Advanced,6.006,Lecture 8 - Binary Heaps,40d4851e550507ca14dc778b9b2266cc_MIT6_006S20_lec8_2_pdf
139,What is merge sort?,"And instead, we should jump to an algorithm that actually matters, which is something called merge sort. How many of us have encountered merge sort before? Fabulous. Good. So then I'm done. So let's say that I have a list. Now, I'm sending a message back to Jason. I made this one up last night. So I have 7, 1, 5, 6, 2, 4, 9, 3. This is not in sorted order. But I can make a very deep observation, which is that every number by itself is in sorted order if I think of it as an array of length 1. It's really deep, like deep learning deep. So now, what can I do? Well, I could take every pair of numbers, draw a little red box. Well, now, they're not in sorted order any more inside of the red boxes. So I'm going to sort inside of every box. In this case, it's not too exciting because it's just pairs. And now, they're in sorted order because they said they were. Now, I'm going to keep doubling the size of my boxes. So now, let's say I have box of length 4. What do I know about the left and right-hand sides of the dotted lines here? On the two sides of the dotted lines, the array is in sorted order. There's a 1 and then a 7. Those are in sorted order, 5 and a 6. That's because, in the previous step, I sorted every pair. So when I merge these two sides together, I have an additional useful piece of information, namely that the two sides of the dotted line are already in sorted order. That's going to be our basic inductive step here. So in this case, I merge the two sides. I get 1, 5, 6, 7, and 2, 3, 4, 9. Then finally, I put these two things together. And I have to sort these two. I have to merge these two sorted lists. But they're in sorted order. And that's going to give me a big advantage because-- oops, I lost my chalk. I suppose I've got space on this board here. Oh no. So if I want to merge 1, 5, 6, 7 and 2, 3, 4, 9, there's a nice, clever technique that we can do that's going to take just linear time. Jason tells me it's the two finger algorithm. I think that's a cute analogy here. So here are my two fingers. They're going to point at the end of the list. And I'm going to construct the merged array backwards. So how many elements are in my merged array, if I'm merging two things of length 4? I don't ask you guys hard questions. It's 8, yeah? 4 plus 4. 8, yeah? So what do I know? I know that my merge array-- 5, 6, 7-- has eight elements. And now, I'm going to have two fingers at the end of my array. Which one should I put at the end of the merged guy? The 7 of the 9? AUDIENCE: The 9 JUSTIN: The 9. Right, thank you. So now, I can move my lower finger to the left because I've already added that. Notice that I never need to look to the left of where my finger is because they're already in sorted order. Now what should I add, the 4 or the 7? AUDIENCE: 7. JUSTIN: The 7. And so on, dot, dot, dot, yeah? So that's going to be the basic idea of the merge sort. I'm going to take two sorted lists. And I'm going to make a new sorted list, which is twice as long, by using two fingers and moving from the and backward. So that's the basic intuition here. Indeed, there's our sorted list. It's stressing me out that there's no eight. I need the power of 2. So I think merge sort, we're going to present it in a backward way from the previous one, where I'm going to give you the high level algorithm. And then actually, the headache is that merging step, which I have four minutes for. And I apologize for it. So what does the merger sort do? Well, it computes an index c, which is the middle of my array. And it's going to make a recursive call which is sort the left, which is everything between index A and index C. And then sort everything on the right, which is everything from index C to index B. I know this is confusing because usually letters appear in order. But C, if you think of as standing for center, then it makes sense like. Here's my array. I'm going to choose an index right in the middle. I've done myself a disservice by not using a power of 2. But that's OK. I'm going to say sort everything to the left of the dotted line first. Sort everything to the right of the dotted line second. Now, I have two sorted lists on the two sides of the dotted line. And then I'm going to use my two fingers to put them together. So that's what this is implementing here. See, there's two recursive calls-- sort from A to C, and then sort from C to B. Oops, I didn't actually label this. So this is A, C, B. And then I've got to call merge.","Merge sort is an algorithm that sorts a list by dividing it into two halves, recursively sorting each half, and then merging the two sorted halves into a single sorted list.",valid,Basic,6.006,3 Sets and Sorting,oS9aPzUNG-s.en-j3PyPqV-e1s_20_mp4
140,What is a Directed Acyclic Graph (DAG) and why is it significant?,"the runtime of this full DFS algorithm is v plus e time because every edge is touched no more than one time. Kind of amortized over all the different calls to DGS here. And there's this for loop over vertices. So there's clearly an order v that you need here. Does that argument make sense? So again, we call that linear in the size of the input. I'm going to say it as many times to get it in my own head correctly. OK. Right. So this is the basic problem. This comes up all the time, by the way. Like, it seems like somehow a totally brain dead weird algorithm. Like, somehow, why would you want an algorithm that finds connected components. Like, why would you even have a graph that's disconnected or something? But of course, that can happen a lot. So for instance, maybe you work at a social media company, and people have friends. But like, Eric and I are friends. And we're not friends with anybody else. We have a-- there's like, a blood oath kind of thing. Then that might be not so easy to find in the graph because, of course, we're just two among a sea of students in this classroom, all of which have different interconnections that are just enumerated based on the list of edges. And so even though like, pictorially, it's kind of hard to draw a connecting component algorithm in a way that doesn't make it sound kind of like a useless technique from the start, because it's very clear there are two connected components there. Of course, we still have to be able to write code to solve this sort of thing. OK. So for once, I think I'm almost on time in lecture today. So we have one additional application of depth-first search in our class today, which is sort of on the opposite end of the spectrum. So we just talked about graphs that are undirected and thinking about cycles. Now, on the opposite end we might think of a DAG. So a DAG is a Directed Acyclic Graph. Can anyone think of a special case of a DAG? I suppose I should define it first. And then we'll come back to that question, which means exactly what it sounds like. So it's a graph that has directed edges now and doesn't have any cycles in it. So actually, the graph I gave you all the way at the beginning of lecture I think secretly was an example of one of these. So let's say that I have directed edges. Maybe if I make the head a triangle, it's a little easier to see. I'm not so sure. In any event, so I'm going to have an edge up and an edge to the right, and similarly, an edge down and an edge to the right. This graph looks like a cycle. But it's not because the only direction that I can move is from the left-hand side to the right-hand side. So this is a directed graph. And it doesn't contain any cycles, meaning there's no path that it can take from a vertex that gets back to itself along the directed edges. OK. And DAGs show up all the time. Now that I've defined what a DAG is,","A Directed Acyclic Graph (DAG) is a graph that has directed edges and does not contain any cycles. It is significant because it shows up frequently in various applications where relationships have a direction and cyclical dependencies are not possible, such as scheduling tasks that must occur in a specific order without repetition.",valid,Intermediate,6.006,10 Depth-First Search,IBfWDYSffUU.en-j3PyPqV-e1s_15_mp4
141,How can transforming a graph into a Directed Acyclic Graph (DAG) using vertex duplication facilitate finding the shortest paths in linear time?,"many versions of a vertex. And I want this version of the vertex to correspond to whether I came here using 0 edges, 1 edge, 2 edges, 3 edges-- I have a different vertex version of the vertex for each one of these-- for a path going through, at most, a certain number of edges. OK. So this is an idea called graph duplication. Idea, graph duplication. And this is a very common technique for solving graph-related problems. Because essentially what I get to do is I get to store information. If I'm having different versions of a vertex, I can have that vertex correspond to reaching that vertex in a different state. So that's what we're going to do here. The idea here is make V plus 1 levels-- basically duplicate vertices in our graph-- where vertex Vk in level k represents reaching vertex V using at most k edges. OK, so this definition seems similar to what we're doing up here. If we have vertices that have this property, then their shortest paths in this new graph might correspond to these k edge distances. And really, the name of the game here is to compute these two for every vertex, because then we can-- then if d is finite, delta is finite, then this guy will be the length of our shortest path. And if they are different, that will be a witness and we can explore from it. So-- and if we connect edges from one level to only higher levels, basically levels with a higher k, then this graph is going to be a DAG. Whoa. That's cool. Why is that cool? Because we saw how to solve single-source shortest paths in a DAG and linear time. Now this graph that we're going to construct is going to have V plus 1 levels. So could have-- our graph kind of explodes V times. We're going to do that in a second. I'm going to be more precise with what I mean there. But if we're multiplying our graph V plus 1 times, then the size of our graph is now V times larger. Now that doesn't-- that's not so hard to believe. But if we made our graph V times larger and we ran a shortest path algorithm in linear time with respect to that graph, then that graph has something like size V times V plus E size. That looks familiar, maybe? That's this running time. So if we can find an algorithm that runs in that running time, we can get down to V times E. So let's try to do that.","By creating V+1 levels and duplicating vertices in our graph so that a vertex Vk in level k represents reaching vertex V using at most k edges, the transformed graph becomes a DAG. This is beneficial because we know how to solve the single-source shortest paths in a DAG in linear time. With the graph having V times more vertices, running a shortest path algorithm in linear time on this expanded graph effectively allows us to achieve a running time of V times E.",valid,Advanced,6.006,12 Bellman-Ford,f9cVS_URPc0.en-j3PyPqV-e1s_7_mp4
142,How does the inductive hypothesis assure the correctness of the shortest-path distances computed by the Bellman-Ford algorithm?,"So the base case-- so induct on k base case, k equals 0? Check. That's all good. Now we-- in our inductive step, let's take a look at the shortest-path distance from 0-- from S0 to V of k prime for some k prime. And the assumption is, the inductive hypothesis is that this distance is the k edge distance for all k prime less than-- I mean all k less than k prime. Well, kind of by definition of a shortest path, this is the minimum overall incoming vertices of the shortest path from S0 to U of k prime minus 1 plus the weight of the edge from U of k prime minus to Vk prime for all Uk prime minus 1 in the adjacencies, the incoming adjacencies of Vk prime. OK, what does this mean? I'm just saying in my graph G prime, a shortest path to this vertex needs to go first through some vertex in the layer before it, which is one of these. And in particular, I'm only connected to things adjacent to me. That's all this is saying. I have to go through that vertex and take some shortest path to one of those previous vertices. Now s actuality, these adjacencies, I constructed them to be similar to the adjacencies in my original graph in addition to one edge coming from my original vertex, from vertex V. So this is the same as the minimum of this set delta S0. Same thing. Plus W U, V for all U in the adjacent-- incoming adjacencies of my original vertex. In addition to one more term. What is that other term? These are all of the things corresponding to my incoming edges in my original thing, but I also have that one edge coming from the V before it. So this is-- I'm going to union-- union-- union this with delta S0 V of k prime minus 1. Awful. I think there's another one here. This is S0 of k prime minus 1. I""m not going to rewrite it. OK. Then by induction, this thing and this thing must be the edge shortest paths using k minus 1 vertices. And then that's just the statement of what the shortest path should be using at most k prime edges going from S to V. So, these things are the same as we claimed. Yay, check. All right. And then it's not such-- it's kind of a trivial leap, then, to say that at the end of Bellman-Ford, these guys-- sorry, the things that we return, these guys, are the shortest-path distances, because here, if they're finite, we set them to their true shortest-path distance; and if they're minus infinity, that invariant means that these things correspond to exactly this claim over here. It's a witness.","The inductive hypothesis assures the correctness by stating that the shortest-path distance from S0 to Vk is the k-edge distance for all k less than k'. By definition of a shortest path, it should go through some vertex in the previous layer. The hypothesis ensures that these distances rely on the shortest path from S0 to a vertex in the preceding layer plus the edge weight to the current vertex. At the end of Bellman-Ford, if values are finite, they represent true shortest-path distances, and if they are minus infinity, they conform to the negative cycle detection invariant.",valid,Advanced,6.006,12 Bellman-Ford,f9cVS_URPc0.en-j3PyPqV-e1s_10_mp4
143,"What does ""recurse but re-use"" mean in dynamic programming?"," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 16: Dyn. Prog. Subproblems 
Lecture 16: Dyn. Prog. Subproblems 
Dynamic Programming Review 
• Recursion where subproblem dependencies overlap, forming DAG 
• “Recurse but re-use” (Top down: record and lookup subproblem solutions) 
• “Careful brute force” (Bottom up: do each subproblem in order) 
Dynamic Programming Steps (SRT BOT) 
1. Subproblem deﬁnition 
subproblem x 2 X 
• Describe the meaning of a subproblem in words, in terms of parameters 
• Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence 
• Often multiply possible subsets across multiple inputs 
• Often record partial state: add subproblems by incrementing some auxiliary variables 
2. Relate subproblem solutions recursively 
x(i) =  f(x(j), . . .) for one or more j < i  
• Identify a question about a subproblem solution that, if you knew the answer to, reduces 
the subproblem to smaller subproblem(s) 
• Locally brute-force all possible answers to the question 
3. Topological order to argue relation is acyclic and subproblems form a DAG 
4. Base cases 
• State solutions for all (reachable) independent subproblems where relation breaks down 
5. Original problem 
• Show how to compute solution to original problem from solutions to subproblem(s) 
• Possibly use parent pointers to recover actual solution, not just objective function 
6. Time analysis 
P 
• 
x2X work(x), or if work(x) =  O(W) for all x 2 X, then |X| · O(W) 
• work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time 
","""Recurse but re-use"" refers to the top-down approach in dynamic programming where you record and lookup subproblem solutions.",valid,Basic,6.006,"Lecture 16 - Dynamic Programming, Part 2 - LCS, LIS, Coins",28461a74f81101874a13d9679a40584d_MIT6_006S20_lec16_1_pdf
144,Who is Justin Solomon?,"[SQUEAKING] [RUSTLING] [CLICKING] JUSTIN SOLOMON: OK, team. Let's get started for the day. It's a pleasure to see all of you guys. In case you don't remember, I'm Justin. I'm the third instructor of 006 that you probably forgot about, but you're going to see a lot more of me in the graph theory part of our course because that's the part of algorithms that I like. If I were reincarnated as a theoretical computer scientist, I would probably go into this area. Hey, guys. OK. We have our PhD admit visit days coming up for the next couple of days I'm working on my camp counselor cheerleader voice. So don't make me wake all of you guys up for the day. You're not going to like it. But in any event, so in 6.006 if you look back at the course outline, we're officially","Justin Solomon is the third instructor of 006, specializing in the graph theory part of the course, and has a noted interest in algorithms related to this area.",administrative,Basic,6.006,9 Breadth-First Search,oFVYVzlvk9c.en-j3PyPqV-e1s_1_mp4
145,What is one conservative test to eliminate unnecessary computation when rendering a 3D scene?,"that our way out of these problems, in graphics, is data structures and algorithms. It's completely unavoidable. For instance, obviously, we spent quite a bit of time in this course talking about AVL trees. In 837, we'll spend a big chunk of our tours talking about space partitioning trees. Here-- I actually forgot what kind of tree this is. I think it's a KD tree. Doesn't matter. In any event, one thing I could do is take all of the triangles of my bunny, and I could put the entire bunny in a giant cube with the property that the cube is outside the bunny. Let's say I cast a ray and the ray doesn't touch the cube. Can the ray touch the bunny? No, right? It zings right past it. So suddenly, I just saved myself a lot of computation time, right? I don't have to iterate over all the triangles inside of the body to see whether they hit the ray or not, because I already convinced myself, by this conservative test, that I didn't hit even the bounding box of the whole bunny. Well, that's sort of a nice order 1 speed-up. But depending on how big the bunny is relative to the size of my rendered image, that might not be a super useful efficiency test. But of course, what could I do? I could take the box containing the bunny, I could slice it in half, and now it's saying, does my ray hit the front or the back of the bunny? Or maybe both. That's where you've got to-- that's where things get gnarly. And so on. So now you have this nice recursive tree structure, where I keep taking the box containing my bunny and chopping it in half and placing-- in some sense, usually, the triangles-- maybe not the leaves of my tree, but [INAUDIBLE] that's probably good enough. You get a structure like what you see on the screen here. And why should you do that? Well, remember, it takes pn time to render my image of my bunny normally. Well, now, the picture is actually misleadingly suggestive. But you might think that, maybe, it takes roughly-- remember, n is the number of objects in my scene-- p log n time to render my bunny now, because I can kind of traverse the tree of objects in my scene. Of course, notice, I put a question mark here. And the devil's in the details here. In fact, I think computer graphics people often believe that their rendering algorithm takes p log n time. That's often not possible, although kind of an interesting question, which is, the heuristics they use for building these sorts of trees often do, on average, give them log n time. And so there's something about the data that's making this problem easier than it might seem. So we'll dig into that a little bit in the graphics class. Of course, you're not going to proof as many bounds as you might in a theory course. But we're certainly building on the intuition that we've seen in this class to build on practical data structures. And these data structures appear everywhere in computer graphics. For instance, directed acyclic graphs appear all over the place in computer graphics literature to describe 3D scenes. For example, this classroom is a stark reminder of why we need DAGs and computer graphics, because we have all of these empty seats here, and they're all copies of one another. So would it make sense for me to store however many, like, 100 3D molds of the same chair? Probably not. So instead, what do I do? I store one instance of a chair, and then some instructions on how to tile it into my entire scene. One way that I can do that is to think of there being a node in a graph which knows how to draw one chair. And now, I can have a bunch of different nodes in my scene for all of the instances of the chair and then store a different transformation for each one. So if you think about the graph structure here, each of those ones is going to point into the same 3D model of the chair for rendering. And that makes a directed acyclic graph structure called a scene graph, which we'll spend quite a bit of time talking about in 837, how to traverse and construct all that good stuff. And there are lots of different models of computation in that universe, as well. Your graphics card is a very specific kind of parallel processor that's kind of like Lucille Ball on the conveyor belt, hammering at the same object over and over again. But if you ask it to do anything other than the one thing it knows how to do to a bunch of data at a time, then all of your computation grinds to a halt. This is called Single Instruction Multiple Data parallelism, SIMD. Numerical algorithms matter a lot for things like fluid simulation. And approximation algorithms are quite critical, too. In computer graphics, the complexity is kind of interesting, because of course, your eyeball is sensitive to about 29.97 frames per second worth of material. You can choose that time to do really well-rendering one object, but then you take out of the time rendering something else. There's kind of an interesting conservation law that you have to balance when you solve these kinds of problems, which is an interesting balance, now, between complexity and runtime of your algorithm and perception. What things can you get away with when you draw a scene? And maybe I can do tons of extra computation to get that extra shadow, but it's just not worth it. I'll quickly sketch out another completely different application of the material that we've covered in 6.006 from my own research. Again, just like Erik-- I guess, in a funny way, both of our groups, I think, are kind of broad in terms of subject material, rather than-- some of our colleagues have really laser focus on one topic or another. Another Research area that I have sort of backed into is the area of political redistricting. This is relevant in the United States. Recently, I've been reading this great proposal about other countries, which is really interesting, how they do this stuff. In the US, when we vote for people in Congress-- by the way, not necessarily for presidents. This is a common misconception. But certainly for Congress, your state is divided into little regions, each of which elects one member of the House. And there's sort of a subtle problem if you're not used to thinking about it, or one that's staring you in the face and screaming, depending on how often you read the news and politics. There is an issue called gerrymandering, where your legislature draws the lines for what area on the map elects a member of Congress. And depending on how you draw the lines, you can engineer different results for who's likely to get elected. So for instance, maybe there's some minority. I can cluster them all together into one voting district. Then they will only get the opportunity to elect one person. But maybe, if I divide the space where they live into two, I managed to engineer two districts with a high probability of electing somebody with their political interests in mind. It turns out that political redistricting, in a broad sense, is a great problem, computationally. Even if you're a totally heartless theorist, there are some really fun problems here. So for example, the state of Iowa-- we all pick on Iowa because it has a unique law, which is that districts have to be built out of counties, which are much larger than the typical census unit, so it computationally is easier. But even in Iowa, which is a giant grid-- with the exception of one shift in the middle, which is fascinating to me-- I know [INAUDIBLE], fun fact. Literally, people were making the map of Iowa, and they worked from the bottom up and the top down, and it meets in the middle and their grids were shifted, and now we're stuck with that. And it has an interesting effect on the topology of the graph, because it looks like squares, but then there's triangles in the middle. But in any event, even though there's only 99 counties in four districts, there's approximately quintillions of possible ways you can divide that state into four contiguous districts that satisfy the rules as they were-- at least, if you read the code literally in the law. It seems like computers are useful, but unfortunately, it's a little subtle how. For instance, there's no single ""best"" districting plan out there. I can't think of a single state with a law that gives you an objective function, similar to whatever cute characters that we've had in 6.006. They often have very clear objectives in life, but unfortunately, redistricting, that's very rarely the case. You have to balance contiguity, population balance, compactness, all of these different things. Reality check number two is that, even if somebody did give you an objective function, for just about any interesting objective function, it's very obvious that generating the best possible districting plan is NP-hard. And by the way, it doesn't even matter, because the law doesn't say that computers have to draw the best districts. Even if P equals NP really could extract the best possible districting plan using an algorithm, it doesn't mean you have to use it, at least the way the law's written now. Interestingly, this is not true in certain parts of Mexico, where they actually make you compare your districting plan against a computer-generated one, which is philosophically really interesting, although in practice, it doesn't work terribly well. Our researchers studied analysis of districting plans instead. So instead of running a piece of software that takes in your state, draws your districts, and then you're done-- instead, we ask statistical questions about, I propose a districting plan, what does it look like relative to the space of the possibilities? So that, of course, begs the question, what are the possibilities? So these are the connected graph partitions. Meaning, you have a graph, and you take the vertices and you cluster them together in a way where they're connected to one another. The one thing that we all agree on-- actually, philosophically, it's questionable why-- is that you should be able to start at any point in your district and walk to any other one without leaving. These days, with the internet, it's not clear that that's actually the best criterion. But that's a law that, I think, is never going to get passed in the near future. Anyway, I think I'm out of time, so I don't think I'll walk you guys through the theory here. Maybe I'll leave it in the slides. There's a sort of very simple proof that can show that, at least the very simplest thing you might think of for analyzing your districting plan, which is to say, you propose a plan, and now, I want your plan to be at least as good, under some axis, as it's a randomly drawn one from the space of all possible connected partitions-- all of the possible ways I could draw the lines. Well, then, it might be useful to have a piece of software that could just randomly draw such a thing. So in other words, to draw something where the probability of any one partition is 1 over the number of partitions. This seems innocent. In fact, there's a number of papers that claim to do things like this. But it turns out that it's computationally difficult, assuming that you believe that P doesn't equal NP. So I'll maybe leave some suggestive pictures in the slide that we can-- if you guys text me, or if we have a professor-student chat, I'm happy to sketch it out to you then. There's a very nice, easy proof that reduces this to Hamiltonian cycle, and shows you that maybe you shouldn't trust these tools, as much as they're argued about, literally, in the Supreme Court a couple of months ago. By the way, it was pretty fun. Our expert report was referenced in the defense of the case last summer. And when you read the discussion, you can see the judges trying to talk their way around complexity. And it's an interesting, if somewhat dry, read. In any event, that's just the starting point for our research, which says that, of course, these sampling problems are really hard. The questions is, what can you do?","One conservative test involves enclosing the entire object, such as a bunny made up of triangles, in a giant cube. If a ray does not touch this cube, it cannot touch the object inside, thereby saving computation time by eliminating the need to check all the triangles within the object.",valid,Intermediate,6.006,21 AlgorithmsNext Steps,4nXw-f6NJ9s.en-j3PyPqV-e1s_12_mp4
146,What is the formula for calculating the minimum total difficulty from note t_i with starting finger f?,"6 
Lecture 17: Dyn. Prog. III 
• Solution: 
1. Subproblems 
• x(i, f) = minimum total difﬁculty for playing notes ti, ti+1, . . . , tn−1 starting with ﬁn­
ger f on note ti 
• For 0 ≤ i < n and 1 ≤ f ≤ F 
2. Relate 
• Guess next ﬁnger: assignment f 0 for ti+1 
• x(i, f) = min{x(i + 1, f 0) + d(ti, f, ti+1, f 0) | 1 ≤ f 0 ≤ F } 
3. Topological order 
• Decreasing i (any f order) 
4. Base 
• x(n − 1, f) = 0 (no transitions) 
5. Original problem 
• min{x(0, f) | 1 ≤ f ≤ F } 
6. Time 
• Θ(n · F ) subproblems 
• Θ(F ) work per subproblem 
• Θ(n · F 2) 
• No dependence on the number of different notes! 
","x(i, f) = min{x(i + 1, f') + d(t_i, f, t_i+1, f') | 1 ≤ f' ≤ F}",valid,Intermediate,6.006,"Lecture 17 - Dynamic Programming, Part 3",665523227a175e9e9ce26ea8d3e5b51c_MIT6_006S20_lec17_6_pdf
147,What is a changeable priority queue?,"But the basic idea behind Dijkstra is the following idea. Relaxed edges from vertices in increasing distance from source. OK. This is the same kind of difficulty we had before when we were trying to generalize BFS. So how do we know what the next vertex is with increasing distance to s? Well, the second idea is find the next vertex efficiently using a data structure. And the data structure we're going to use is something I like to call a changeable priority queue. So this is a little different than a normal priority queue that we had at the end of our data structures unit. This changeable priority queue has three operations. We're going to say it's a queue. We can build it on an iterable set of items. Just stick x-- like n items in there. We can delete min from the queue. OK, this is the same now as the priority queue. It's this third operation that's going to be different. Decrease the key of an item that has id, id. OK, so this is a little strange. What the heck is this id? All right, with a change of priority queue, each of our items has two values instead of one value. It has a key, but it also-- on which the priority queue is leading the min item with the minimum key. But also, each item has an ID associated with it, a unique integer. So that when we perform this operation, decrease_key, it can find some item in our data structure with the given ID. And if it's contained there, it's going to change its key to some smaller value k. And don't worry about the edge cases here. We're always going to make sure this k is going to be smaller then whatever that key was to begin with. So this is really a kind of a funky operation. If I had a priority queue, not a changeable priority queue,","A changeable priority queue is a data structure that supports three operations: building the queue on an iterable set of items, deleting the min item, and decreasing the key of an item with a specific ID. Each item has a key and a unique ID, allowing the decrease_key operation to find and update the item's key to a smaller value.",valid,Basic,6.006,13 Dijkstra,NSHizBK9JD8.en-j3PyPqV-e1s_2_mp4
148,What is the max-heap property?,"So there are multiple types of heaps. This type of heap is called a binary heap. We will talk about others in future lectures. I'm going to call it Q. Explicit thing-- this is an array representing a complete binary tree, called the array Q. And we want every node to satisfy the so-called max-heap property, which says Q[i] is greater than or equal to Q[j] for both children left of i and right of i. So we have a node i. And it has two children-- 2i plus 1 and 2i plus 2. These are two values of j. What we want is a greater than or equal to relation here and here. So this node should be bigger than both this one and this one. Which of these is larger? We don't know, and we don't care-- very different from binary search trees or set binary trees, where we said these guys were less than or equal to this one, this one was less than or equal to all the nodes in the subtree here. We're just locally saying, this node is greater than or equal to this node and this node. So the biggest is at the top. So one nice lemma about these heaps-- this is weird. Let me give you some more intuition. If you are a binary heap, if you satisfy this max-heap property everywhere, then in fact, you learn that every node i is greater than or equal to all nodes in its subtree. These are what we call descendants in subtree of i. Let me look at this example. So I haven't written any numbers here. You can imagine. So A here is greater than or equal to both B and C, and B is greater than or equal to D and E, and C is greater than or equal to F and G, D is greater than or equal to H and I, and E is greater than or equal to J. That would make this structure a heap, not just a complete binary tree. So what does that imply? It implies that A must be the maximum. So you look at any node here, like J, A is greater than or equal to B is greater than or equal to E is greater than or equal to J. And in general, what we're saying is that A is greater than or equal to all nodes in the tree. B is greater than or equal to all nodes in its subtree down here. C is greater than or equal to all nodes in its subtree. That's what this lemma is saying. You can prove this lemma by induction. But it's really simple. If you have two nodes, i and j, and j is somewhere in the subtree, that means there's some downward path from i to j. And you know that, for every edge we traverse on a downward path, our key is going down non-strictly. So every child is less than or equal to its parent. i is greater than or equal to this, is greater than or equal to this, is greater than or equal to this, is greater than or equal to j, OK? So by transitivity of less than or equal to, you know that i is, in fact, greater than or equal to j. Or sorry, the key in i is greater than or equal to the key in j. This is what we're calling i, the index. This is what we would call Q of i. This is Index j Q of j. Very different way to organize keys in a tree, but as you might imagine, this is going to be good for priority queues. Because priority queues just need to find the maximum elements. Then they need to delete it. That's going to be harder, because leading the root is, like-- that's the hardest node to delete, intuitively. I'd really prefer to delete leaves. But leading leaves and keeping a complete binary tree is actually kind of hard. If I want to delete H, that doesn't look like a binary tree, or it doesn't look like a complete binary tree anymore. It's not left justified. Similarly, if I want to delete F, that's bad. Because now, I don't have four nodes here. The one node that's easy to delete is J, right? If I remove that node, I still have a complete tree. The last leaf, the last position in my array, is the one that's easy to delete. That's good, because arrays are good at leading the last item. But what I've set up here is it's easy to find the max. It's going to be up here at the root. Deleting it is annoying. I'd like to somehow take that key and put it at position-- at the last position at the last leaf, because that's the one that's easy to delete. And that's indeed what we're going to do in a delete algorithm. Let me first do insert. I guess that's a little simpler, kind of symmetric to what we just said. So if I want to insert a key or an item x which has some key, again, the only thing I really can do in an array-- if I want to add a new item, it has to go at the end. The only thing we know how to do is insert at the end of an array. This is what we called insert_last. this? Corresponds to adding a node containing x-- the item x-- in the very last level of the complete binary tree. Either it goes to the right of all the existing nodes, or starts a new level. But it's always going to be the last leaf. After we do the insertion, it will be at position size of Q minus 1. This is probably not enough, though. We just inserted an arbitrary item in a leaf. And now, it may not satisfy the max-heap property anymore. So let's just check if it does, and if it doesn't, fix it. That's what we know how to do. But this time, we're not even going to need rotations, which is cool. So I'm going to define an operation called max_heapify_up. This will make things more like a max-heap. We're going to start at size of Q minus 1 for our value i. But it's going to be recursive, so what we're going to do is look at a node i, in particular the one that just got inserted. And where could it violate things? Well, with its parent, because we have no idea what key we just put here. Maybe it's less than our parent. Then we're happy. But if it's greater than our parent, we're in trouble and we should fix it. So if the item in the parent's key is less than i's key-- ah, I see I forgot to write key and all these spots. This should be dot key and dot key, because Q[i] is an item that gets its key. So this is the bad case. This is if the parent is smaller than the child. We wanted the parent to always be greater than or equal to its children. So in that case, what could we do? Swap them. Let's swap Q parent of i-- excellent, more chalk-- with Q[i]. Now they're in the right order. Now, we need to think about what about the other child of that node? And what about its parent? So I have some numbers here. Let's say this was 5 and this was 10. What do I know about this picture before? Well, I know that 10 is this newly inserted item. It's the only one that could have caused violations when I first inserted it. So I know that before this-- before I moved 10 around, I knew all the things in this left subtree are less than or equal to 5, and everything up here are created equal to 5. I also know that the nodes in here, in fact, were less than or equal to 5. Other than this node 10 that we just inserted, this was a correct heap. So 5 was a separator between-- things above it on the ancestor chain are greater than or equal to 5, and things in its subtree are less than or equal to it. So after I do this swap, which I'm just going to do-- after I swap the items 5 and 10, 10 is up here, 5 is here. And now, I realize, OK, great, this edge is happy, because now 10 is greater than or equal to 5. But also this edge is happy, because it used to be happy, and we only made its parent larger. Now this edge maybe is bad. And so we need to recurse-- recurse on the parent. But that's it. So we fixed this one edge. Initially, this happens way down at the leaf. But in general, we're taking our item that we inserted, which is x, and it starts at the last leaf, and it may be bubbles up for a while. And maybe it gets all the way to the root if we inserted a new maximum item. But in each step, it goes up one. And so the running time of all this stuff is the height of the tree, which is log n. And because there's only this one item that could potentially be wrong, if it ever stops moving, we've just checked that it satisfies the max-heap property. If it gets to the root, you can also check it satisfies the max-heap property. So there's a base case I didn't write here, which is if i equals 0, we're at the root, we're done. And then you can prove this correct by induction. There's just one item that's in the wrong spot, initially. And we put it into a right spot. There are many places it could go, but we will move it to the, I guess, unique ancestor position that is correct-- that satisfies max-heap property, OK? So that's insert.","For a binary heap, the max-heap property states that for every node i in the heap, Q[i] is greater than or equal to both of its children (left and right).",valid,Basic,6.006,8 Binary Heaps,Xnpo1atN-Iw.en-j3PyPqV-e1s_10_mp4
149,Why is it sufficient to check only the ancestor nodes after an insertion or deletion in an AVL tree?,"so the only things that change the tree are when we insert or delete a new node. And the way that we implemented those so far is to add or remove a leaf. So we should still be thinking about adding or removing a leaf. The problem is, when I add a new leaf, now maybe this tree is higher than it used to be. So some node here may no longer be height balanced. But because height is a subtree property, the only nodes we need to check are the ones up this ancestor path. And there's only log n of them, because now height is log n. That's what we just proved as long as we have this property. Now, we right now don't have it for, like, maybe these few nodes. But it was long n before. It's at most log n-- 2 log n plus 1 right now, because we just added a node. So what I want to do is check all of these ancestor nodes in sequence from bottom up, and find one that's out of balance. So let's take the lowest out of balance node. I'm going to call that x. Now, because we just insert or deleted a single leaf, it's only out of balance by 1, because we only changed height-- one height went up by 1, or one height went down by 1. And before, all of our skews were plus or minus 1, or 0. So now, it's-- the bad case is when it's plus or minus 2. If it happens to still be in this range for all the nodes, we're happy. But if it's outside this range, it's only going to be out by 1. So this means the skew is n plus 2 or minus 2. And let's say that it's 2 by symmetry. So my picture is-- I'm going to draw double right arrow","After inserting or deleting a node in an AVL tree, it is sufficient to check only the ancestor nodes because these are the nodes whose heights may be affected by the insertion or deletion. The height property is a local property of subtrees, and hence any imbalance caused by a change in tree height can only propagate upward along this path. There are only log n such ancestor nodes to check since the height of the tree is maintained at log n by the AVL properties.",valid,Advanced,6.006,7 Binary Trees Part 2 AVL,U1JYwHcFfso.en-j3PyPqV-e1s_22_mp4
150,Does Depth-First Search (DFS) ever visit a vertex that is not reachable from the source?,"Right. Now, does DFS ever visit a vertex that is not reachable from the source? Well, the answer is no because all I ever do is recursively call on my neighbors. And so kind of by definition, if I'm not reachable, DFS will never see it. So if I think about my runtime carefully, it's not quite the same as breadth-first search. Remember that breadth-first search took v plus e time. In depth-first search, it just takes order e time because I'm expanding outward from the source vertex, hitting every edge adjacent to every vertex that I've seen so far. But I never reach a vertex that I haven't-- that isn't reachable. Right? And so because this only ever touches every edge one time, we're in good shape. And I see a question here. Yeah. AUDIENCE: Does BFS reach vertices that are not reachable? JUSTIN SOLOMON: Does BFS reach vertices that are not reachable? I guess not, now that you mention it. But at least in my boring proof of order v time last time, our very first step of BFS, reserve space proportional to v, which is enough to already make that runtime correct. Good question. Yeah. So I guess the way that we've talked about it where you can stretch one little set after a time, if you think of that as reachability, then no. It doesn't reach it in the for loop. But just by construction, when we started we already took the time that we're talking about here. So notice these run times aren't exactly the same. So for example, if my graph has no edges, BFS still is going to take time because it still has to take order v time, at least in the sort of brain-dead way that we've implemented it last time. Obviously, in that case, we could probably do something better. Whereas the way that we've defined the DFS algorithm, it only takes edge time. I see confusion on my instructor's face. No? OK. Good. The one thing to notice is that these are algorithms for slightly different tasks in some sense. The way that we wrote down breadth-first search last time, conveniently, it gives us the shortest path. There are breadth-first search algorithms that doesn't. I think in this class we kind of think of breadth-first search-- we motivate it in terms of the shortest path problem. But it's just kind of a strategy of working outwards from a vertex. Whereas here, the way we've written down depth-first search, there's no reason why the path that we get should be the shortest. Right? So to think of a really extreme example, let's say that I have a cycle graph. So I get a big loop like this. Let's say that I do depth-first search starting from this vertex. Well, what will happen? Well, this guy will call its neighbor recursively, who will then call its neighbor recursively, who will then call his neighbor recursively, and so on. So of course, when I do depth-first search, when I get to this vertex, there's a chain of 1, 2, 3, 4 vertices behind it. Is that the shortest path from the source to the target here? Well, clearly not. Right? I could have traversed that edge. I just chose not to. OK. So that's the depth-first search algorithm. It's just essentially a recursive strategy where I traverse all my neighbors, and each of my neighbors traverses their neighbors, and so on. OK. So why might we want to use this algorithm? Well, we've already solved the reachability problem. So let's solve a few more things using the same basic strategy here. So there's some notions that we've sort of-- actually, in some sense, already used in the lecture here. But we might as well call them out","No, because DFS only recursively calls on its neighbors and never reaches a vertex that isn't reachable from the source.",valid,Intermediate,6.006,10 Depth-First Search,IBfWDYSffUU.en-j3PyPqV-e1s_11_mp4
151,How does memoization change the time complexity of computing Fibonacci numbers?,"talking about the word ram model of computation. A question here that usually doesn't matter in this class. Usually we assume additions take constant time. And we usually do that because it's usually true. And in general, our model is the w bit additions-- where w is our machine word size-- takes constant time. But for this problem and this problem only, pretty much, for Fibonacci numbers, I happen to know that the Fibonacci numbers grow exponentially. So to write them down actually requires theta n bits because they are some constant to the n power. And so they're actually really big . n is probably bigger than w. Usually you think of problems that are much bigger than 64 or whatever your word size happens to be. We do assume that w is at least log n. But n is probably bigger than w. It might be bigger or smaller. We don't know. And in general, to do an n bit addition-- these are n bit additions-- is going to take ceiling of n over w time. So in the end, we will spend this times n, because we have to do that, many of them, which is n plus n squared over w time. So a bit of a weird running time. But it's polynomial, whereas this original recursive algorithm was exponential here. Using this one simple idea of just remembering the work we've done, suddenly this exponential time algorithm becomes polynomial. Why? Because we have few sub problems. We had n sub problems. And for each sub problem, we could write a recurrence relation that if we already knew the solutions to smaller sub problems, we could compute this bigger problem very efficiently. This happened to be constant time or constant additions. n over w time. But as long as this is polynomial and this is polynomial, we're happy, because we have this nice formula that the time it takes is, at most, the sum over all sub problems of the relation time. So I'm referring to sub problems, like a number of them and the time it takes to evaluate this, ignoring the recursive calls. That's important. This is the non recursive part. In the notes, I call this non-recursive work. So this formula gives us a way to bound the running time of one of these algorithms if we use memoization. Without memoization, this is not true, Fibonacci to exponential time. But if we add memoization, we know that we only solve each sub-problem once. And so we just need to see, for each one, how much did it cost me to compute it, assuming all the recursion work is free, because that's already taken into account by the summation. So in particular, this summation is at most the number of sub-problems times the time per sub-problem,","Without memoization, computing Fibonacci numbers takes exponential time. However, with memoization, we ensure that each sub-problem is solved only once, transforming the algorithm to run in polynomial time.",valid,Intermediate,6.006,15 Dynamic Programming Part 1 SRTBOT Fib DAGs Bowling,r4-cftqTcdI.en-j3PyPqV-e1s_8_mp4
152,What is a weighted graph?," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 11: Weighted Shortest Paths 
Lecture 11: Weighted Shortest Paths 
Review 
• Single-Source Shortest Paths with BFS in O(|V | + |E|) time (return distance per vertex) 
• Single-Source Reachability with BFS or DFS in O(|E|) time (return only reachable vertices) 
• Connected components with Full-BFS or Full-DFS in O(|V | + |E|) time 
• Topological Sort of a DAG with Full-DFS in O(|V | + |E|) time 
• Previously: distance = number of edges in path Today: generalize meaning of distance 
Weighted Graphs 
• A weighted graph is a graph G = (V, E) together with a weight function w : E → Z 
• i.e., assigns each edge e = (u, v) ∈ E an integer weight: w(e) = w(u, v) 
• Many applications for edge weights in a graph: 
– distances in road network 
– latency in network connections 
– strength of a relationship in a social network 
• Two common ways to represent weights computationally: 
– Inside graph representation: store edge weight with each vertex in adjacency lists 
– Store separate Set data structure mapping each edge to its weight 
• We assume a representation that allows querying the weight of an edge in O(1) time 
Examples 
G1 
G2 
a 
e 
b 
f 
c 
g 
d 
h 
6 
8 
−2 
5 
9 
−5 
7 
3 
2 
−1 
−4 
1 
4 
a 
e 
b 
f 
c 
g 
d 
h 
6 
8 
−2 
5 
9 
−5 
7 
3 
2 
−1 
−4 
1 
4 
","A weighted graph is a graph G = (V, E) together with a weight function w : E → Z that assigns each edge e = (u, v) ∈ E an integer weight: w(e) = w(u, v).",valid,Basic,6.006,Lecture 11 - Weighted Shortest Paths,aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11_1_pdf
153,What is the role of the word RAM model in accessing static arrays and how does it influence the operations on the arrays?,"to this interface problem-- the natural solution-- is what I'll call a static array. Jason mentioned these in lecture one. It's a little tricky because there are no static arrays in Python. There are only dynamic arrays, which is something we will get to. But I want to talk about, what is a static array, really? And this relates to our notion of-- our model of computation, Jason also talked about, which we call the word RAM, remember? The idea, in word RAM, is that your memory is an array of w-bit words. This is a bit circular. I'm going to define an array in terms of the word RAM, which is defined in terms of arrays. But I think you know the idea. So we have a big memory which goes off to infinity, maybe. It's divided into words. Each word here is w bits long. This is word 0, word 1, word 2. And you can access this array randomly-- random access memory. So I can give you the number 5 and get 0 1, 2, 3, 4, 5, the fifth word in this RAM. That's how actual memories work. You can access any of them equally quickly. OK, so that's memory. And so what we want to do is, when we say an array, we want this to be a consecutive chunk of memory. Let me get color. Let's say I have an array of size 4 and it lives here. Jason can't spell, but I can't count. So I think that's four. We've got-- so the array starts here and it ends over here. It's of size 4. And it's consecutive, which means, if I want to access the array at position-- at index i, then this is the same thing as accessing my memory array at position-- wherever the array starts, which I'll call the address of the array-- in Python, this is ID of array-- plus i. OK. This is just simple offset arithmetic. If I want to know the 0th item of the array, it's right here, where it starts. The first item is one after that. The second item is one after that. So as long as I store my array consecutively in memory, I can access the array in constant time. I can do get_at and set_at as quickly as I can randomly access the memory and get value-- or set a value-- which we're assuming is constant time. My array access is constant time. This is what allows a static array to actually solve this problem in constant time per get_at and set_at operation. This may seem simple, but we're really going to need this model and really rely on this model increasingly as we get to more interesting data structures. This is the first time we're actually needing it. Let's see. Length is also constant time. We're just going to store that number n, along with its address. And build is going to take linear time. Iteration will take linear time. Pretty straightforward. I guess one thing here, when defining build, I need to introduce a little bit more of our model of computation, which is, how do you create an array in the beginning? I claim I could do it in linear time, but that's just part of the model. This is called the memory allocation model. There are a few possible choices here, but the cleanest one is just to assume that you can allocate an array of size n in theta n time. So it takes linear time to make an array of size n. You could imagine this being constant. It doesn't really matter much. But it does take work. And in particular, if you just allocate some chunk of memory, you have no idea whether it's initialized. So initializing that array to 0s will cost linear time. It won't really matter, constant versus linear, but a nice side effect of this model is that space-- if you're just allocating arrays, the amount of space you use is, at most, the amount of time you use. Or, I guess, big O of that. So that's a nice feature. It's pretty weird if you imagine-- it's unrealistic to imagine you can allocate an array that's infinite size and then just use a few items out of it. That won't give you a good data structure. So we'll assume it costs to allocate memory. OK, great. We solved the sequence problem. Very simple, kind of boring. These are optimal running times. Now, let's make it interesting-- make sure I didn't miss anything--","The word RAM model is used to describe memory as an array of w-bit words, allowing random access to each word in constant time. When dealing with static arrays, this model allows for access operations, get_at and set_at, to also occur in constant time, as long as the array is stored consecutively in memory. Accessing an array element at index i involves calculating the memory position as the starting address of the array plus i, which is simple offset arithmetic. This reliance on the word RAM model underscores how critical access speed is when dealing with static arrays, as it influences the efficiency of array operations.",valid,Advanced,6.006,2 Data Structures and Dynamic Arrays,CHhwJjR0mZA.en-j3PyPqV-e1s_3_mp4
154,What implications does altering a computer's paradigm have on its problem-solving power?,"We could basically change something about our computer to be put in some other weird paradigm of solving problems with more power essentially, or you're","Changing the paradigm of a computer essentially involves restructuring how it processes and solves problems, potentially increasing its computational power and capability to tackle more complex or 'weird' problems.",invalid,Advanced,6.006,20 Course Review,2NMtS1ecb3o.en-j3PyPqV-e1s_12_mp4
155,What is the difference between the depth and the height of a node in a binary tree?,,"The depth of a node is the number of edges on the path from the node to the root, while the height of a node is the number of edges on the longest path down from that node to a leaf.",valid,Intermediate,6.006,6 Binary Trees Part 1,76dhtgZt38A.uk-XlqDmAj_UsM_6_mp4
156,Is there an algorithm that can solve the halting problem for all possible computer programs?,"Given a computer program, does it ever halt? Does it ever terminate? This would be a great thing if we knew how to solve. It's basically an infinite loop detector. If your problem doesn't halt, then it has an infinite loop of some sort. And you'd like to tell your user, hey, you have a bug in your program. So this is one part of bug detection. And it's impossible. There is no algorithm that always-- that solves all inputs to this problem. Maybe given one program that, say, has 0 lines of code, it could solve that. It says, yeah, that one terminates. And maybe you can detect simple kinds of infinite loops. So there's some inputs, some computer programs that you could detect. But there's no one algorithm that solves all inputs. This is kind of sad news.",There is no algorithm that solves all inputs to the halting problem.,valid,Basic,6.006,19 Complexity,JbafQJx1CIA.en-j3PyPqV-e1s_3_mp4
157,What is a binary tree?,,"A binary tree, also known as a root binary tree in mathematics, is a structure where each node has at most two children.",valid,Basic,6.006,6 Binary Trees Part 1,76dhtgZt38A.uk-XlqDmAj_UsM_3_mp4
158,What is the difference between solving a problem with a small input instance and an arbitrarily large input instance?," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 1: Introduction 
Lecture 1: Introduction 
The goal of this class is to teach you to solve computation problems, and to communicate that 
your solutions are correct and efﬁcient. 
Problem 
• Binary relation from problem inputs to correct outputs 
• Usually don’t specify every correct output for all inputs (too many!) 
• Provide a veriﬁable predicate (a property) that correct outputs must satisfy 
• 6.006 studies problems on large general input spaces 
• Not general: small input instance 
– Example: In this room, is there a pair of students with same birthday? 
• General: arbitrarily large inputs 
– Example: Given any set of n students, is there a pair of students with same birthday? 
– If birthday is just one of 365, for n > 365, answer always true by pigeon-hole 
– Assume resolution of possible birthdays exceeds n (include year, time, etc.) 
Algorithm 
• Procedure mapping each input to a single output (deterministic) 
• Algorithm solves a problem if it returns a correct output for every problem input 
• Example: An algorithm to solve birthday matching 
– Maintain a record of names and birthdays (initially empty) 
– Interview each student in some order 
∗ If birthday exists in record, return found pair! 
∗ Else add name and birthday to record 
– Return None if last student interviewed without success 
","For a small input instance, the inputs are limited in size, such as checking if there is a pair of students with the same birthday in a single room. For an arbitrarily large input instance, the inputs can be of any size, such as determining if a pair of students with the same birthday exists in any set of n students.",valid,Intermediate,6.006,Lecture 1 - Introduction,477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_1_pdf
159,How does Dijkstra's algorithm determine the shortest path in a graph with non-negative weights and what role does a priority queue play in this process?,"MIT OpenCourseWare 
https://ocw.mit.edu 
6.006 Introduction to Algorithms 
Spring 2020 
For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms 
","Dijkstra's algorithm determines the shortest path from a source vertex to all other vertices in a graph with non-negative weights by progressively building the shortest-path tree using a priority queue. The priority queue is utilized to efficiently select the vertex with the minimum tentative distance that has not yet been added to the shortest-path tree. Initially, all vertices have infinite distance, except for the source vertex, which has a distance of zero. Iteratively, the vertex with the smallest distance is extracted from the priority queue, and its neighbors are relaxed, updating their distances if a shorter path is found through this vertex. This process continues until all vertices are added to the shortest-path tree.",invalid,Advanced,6.006,Lecture 13 - Dijkstra’s Algorithm,d819e7f4568aced8d5b59e03db6c7b67_MIT6_006S20_lec13_5_pdf
160,What must be updated after inserting a new item in the middle of a tree to correctly search for items by index?,"before that one. And conveniently, we already have-- I didn't mention, but we have a subtree insert. We had two versions-- before and after. I think we covered after, which I use successor before I use predecessor. But we can just call subtree insert before at that node, and boom, we will have added a new item just before it. And great, so magically, somehow, we have inserted in the middle of this sequence. And all of the indices update, because I'm not storing indices. Instead, to search for an item at index i, I'm using the search algorithm. But there's a problem. What's the problem? This seems a little too good to be true. I insert in the middle of this tree, and then somehow, I can magically search and still find the ith item, even though all the indices to the right of that item incremented by 1. It's almost true. Answer? Yeah? AUDIENCE: [INAUDIBLE] ERIK DEMAINE: Because we have to update the sizes, right. I didn't say, how do I compute the size of the left subtree? So that is the next topic.",The sizes of the left and right subtrees must be updated to correctly compute the indices after insertion.,invalid,Intermediate,6.006,7 Binary Trees Part 2 AVL,U1JYwHcFfso.en-j3PyPqV-e1s_8_mp4
161,What is the distinction between a set interface and a set data structure?,"Now, this description here-- notice that I've labeled this as a set interface. This is not a set data structure. And the way to remember that is that I haven't told you how I've actually implemented this. I haven't told you that I'm going to behind the scenes have an array of information, and look inside of it, and that's how I'm going to implement find min or find max with a for loop or whatever. All I'm telling you is that a set is a thing that implements these operations. And behind the scenes, my computer does what it does. Now, it might sound abstract. But it's more or less what you guys do when you write code in Python. I think in Python what we're calling a set is maybe a dictionary. I'm a Matlab Coder. I'm sorry. I'm a numerical analysis kind of guy. But essentially, one of the beautiful things about coding in these high level programming languages is that they take care of these ugly details. And what you're left with is just the high level interfacing with this object","A set interface describes the operations that a set can perform, without specifying how these operations are implemented, while a set data structure includes the actual implementation, which could involve data structures like arrays or lists.",valid,Basic,6.006,3 Sets and Sorting,oS9aPzUNG-s.en-j3PyPqV-e1s_6_mp4
162,What is a strategy to handle new types of subproblems when solving dynamic programming problems?,"and this is an idea that we will expand on next lecture. And the idea is that sometimes you start with the obvious subproblems of prefixes, suffixes, or substrings. Here, the obvious version was substrings, because we were moving from both ends. If you don't know, probably suffixes or prefixes are enough. So we start there, but sometimes that's still not enough subproblems. Here, as soon as we made a move, our problem almost turned upside-down, because now it's your turn, instead of my turn. And that was just annoying to deal with, and so we could-- whenever you run into a new type of problem, just build more subproblems. As long as it stays polynomial number, we'll get polynomial time. And so here we doubled the number of subproblems to just the me case and the you case, and that made this recurrence really easy to write. In the notes, you'll see a messier way to write it, if you don't do that. In the examples we'll see next lecture, we're going to do a lot more expansion, maybe multiplying the number of problems by n or n squared. And this will give us-- it will let us add more constraints to our subproblems, like we did in longest increasing subsequence. We added this constraint that we start with a particular item. The more subproblems we have, we can consider more constraints, because we'll just brute force all the possible constraints that could apply. Well, we'll see more of that next time. That's it for today.","Whenever you run into a new type of problem, just build more subproblems. As long as it stays polynomial number, we'll get polynomial time. This allows adding more constraints to the subproblems, similar to what is done in longest increasing subsequence.",valid,Intermediate,6.006,16 Dynamic Programming Part 2 LCS LIS Coins,KLBCUx1is2c.en-j3PyPqV-e1s_11_mp4
163,What are the main steps involved in the selection sort algorithm?,"So now, I see you. But we're a little low on time. So we'll save it for the lecture. OK. So if we want to implement the selection sort algorithm, well, what do we do? Well, we're going to think of i as the index of that red line that I was showing you before. Everything beyond i is already sorted. So in selection sort, the first thing I'm going to do is find the max element between 0 and i. And then I'm going to swap it into place. So this is just a code version of the technique we've already talked about. Hopefully, this makes sense. So you find the biggest element between 0 and index i. That's what we're going to call j here. I swap that with the one in index i. That's step 2. And then step 3 is I still have to sort everything to the left of index i and that's that recursive call. So if I want to justify the runtime of this particular technique, well, now let's call that t for time. Well, what do I do? Well, for one, I call selection sort with index i minus 1. So that incurs time that looks like this. But I also call that prefix max function. And how much time does that take? That takes order n time. So at the end of the day, I have some relationship that looks like this. Does that makes sense? So by the way, notice that this order n swallowed up the order 1 computations that I had to do to swap and so on. So remember, there's this nice relationship, which you probably learned in your combinatorics class, which is that 1 plus 2 plus dot, dot, dot plus n. OK. I can never remember exactly the formula. But I'm pretty sure that it looks like n squared. So based on that and taking a look at this recursive thing, which is essentially doing exactly that-- n plus n minus 1 plus n minus 2, and so on-- I might hypothesize that this thing is really order n squared. So if I'm going to do that, then again if I want to use the same technique for proof, I have to plug this relationship in, and then double check that is consistent. So maybe I hypothesize that t of n equals cn squared. In which case, I plug it in here. I have cn squared equals with a question mark over it cn minus 1 squared plus big O or even theta n here. So if I expand the square, notice I'm going to get c times n squared plus a bunch of linear stuff. This is really cn squared-- I should be careful with that-- minus 2 cn plus c plus theta of n. Notice that there's a cn squared on both sides of this equation. They go away. And what I'm left with is a nice, consistent formula that theta of n equals 2 cn minus c. And indeed, this is an order n expression. So there's order in the universe. Life is good. Yeah, this is the substitution method. And again, I think you'll cover it more in your recitation. So what have we done? We have derived the selection sort. We've checked that it runs in n squared time. And by this nice, inductive strategy, we know that it's correct. So life is pretty good. Unfortunately, I promised for you guys on the slides that sorting really takes n log n time. And this is an order n squared algorithm. So we're not quite done yet. I'm way over time. So we're going to skip a different algorithm, which is called insertion sort, also runs on n time. Essentially, insertion sort runs in the reverse order. I'm going to sort everything to the left, and then insert a new object, whereas, in selection, I'm going to choose the biggest object and then sort everything to the left. But I'll let you guys piece through that at home.",The main steps in the selection sort algorithm are: 1) Find the max element between 0 and index i and call it j. 2) Swap the element found at j with the one at index i. 3) Sort everything to the left of index i using a recursive call.,valid,Basic,6.006,3 Sets and Sorting,oS9aPzUNG-s.en-j3PyPqV-e1s_19_mp4
164,What is a non-deterministic algorithm and how does it guarantee a solution for decision problems in polynomial time?,"you might find one way or the other more intuitive. They're equivalent. So as long as you understand at least one of them, it's good. NP is just a class of decision problems. So I define P and EXP and R arbitrary. They can be problems with any kind of output. But NP only makes sense for decision problems. And it's going to look almost like the definition of P-- problem solvable in polynomial time. We've just restricted to decision problems. But we're going to allow a strange kind of computer or algorithm, which I like to call a lucky algorithm. And this is going to relate to the notion of guessing that we talked about for the last four lectures in dynamic programming. With dynamic programming, we said, oh, there are all these different choices I could make. What's the right choice? I don't know, so I'd like to make a guess. And what that meant in terms of a real algorithm is, we tried all of the possibilities, and then took the max or the OR or whatever over all those possibilities. And so we were-- but what we were simulating is something that I call a lucky algorithm, which can make guesses and always makes the right guess. This is a computer that is impossible to buy. It would be great if you could buy a computer that's lucky. But we don't know how to build such a computer. So what does this mean? So informally, it means your algorithm can make lucky guesses, and it always makes the right guess. And whereas in DP, we had to try all the options and spend time for all of them, the lucky algorithm only has to spend time on the lucky guess, on the correct guess. More formally, this is called a non-deterministic model of computation. And this N is the-- the N in non-determinism is the N for NP. So this is non-deterministic polynomial time. So algorithm can make guesses. And then in the end, it should output yes or no. Like say if you're exploring a maze, this algorithm could say, should I go left or go right? I'm going to guess whether to go left or go right. And let's say it guesses left. And so then it just goes left. And then it reaches another junction. It says, should I go left or right? And it'll say, I'll guess, and it'll say, guess right this time. And in the end, if I get to some dead end maybe and I say no, or if I get to the destination I'm trying to get to, I say yes. So that's a non-deterministic algorithm. And what does it mean to run that algorithm? What does it mean for the guesses to be lucky? Here's what it means. These guesses are guaranteed-- which way you end up going is guaranteed to lead you to a yes if there is one-- if possible. So in my maze analogy, if my destination is reachable from my source, then I'm guaranteed, whenever I guessed left or right, I will choose a path that leads me to my destination. Whereas, if the destination is in some disconnected part of the maze and I can't get there, then I don't know what the guesses do. It doesn't really matter. Because no matter what I do, I'll end up in a dead end and say no. That's the model. As long as you have an algorithm that always outputs yes or no in polynomial time-- because we're only talking about polynomial time, lucky algorithms-- if there's any way to get to a yes, then your machine will magically find it without having to spend any time to make these decisions. So it's a pretty magical computer, and it's not a computer that exists in real life. But it's a computer that's great to program on. It's very powerful. You could solve lots of things with it. Yeah. AUDIENCE: If you had this magical computer, it can guess whether it's yes or no, why doesn't it just answer the question? ERIK DEMAINE: Right. So what if we-- so a nice check is, does this make all problems trivial, all decision problems? Maybe I should say, well, I don't know whether the answer to the problem is yes or no, so I'll just guess yes or no. This is problematic because-- so I might say, it will guess A or B, and if I choose the A option, I will output yes, and if I choose the B option, I will output no. In this model, that algorithm will always output yes. Because what it's saying is, if there's any way to get to a yes answer, I will do that way. And so such an algorithm that tries to cheat and just guess the whole answer to the problem will actually end up always saying yes, which means it doesn't solve a very interesting problem. It only solves the problem, which is represented by the bit vector 1111111, where all the answers are yes. But good check. Yeah. AUDIENCE: Does there have to be a bound of a number of things it has to choose between when it [AUDIO OUT] ERIK DEMAINE: Yes. AUDIENCE: Does it have an exponential number of them? ERIK DEMAINE: Exponential number of choices is OK. I usually like to think of it, as you can only guess one bit at a time. But we're allowed polynomial time, so you're actually allowed to guess polynomial number of bits. At that point, you can guess over an exponential size space, but not more than exponential. So it's-- yeah, polynomial time let's say in the one-bit guessing model. What did I say? Makes guesses-- let's add binary here. Otherwise we get some other class, which I don't want. OK, let's do an example, a real example of such an algorithm","A non-deterministic algorithm is one that can make ""lucky"" guesses, meaning it always makes the right choice among multiple possibilities, and it is part of the non-deterministic model of computation. In this model, if there is any way to arrive at a 'yes' solution in a decision problem, the algorithm will magically find it without trying all possibilities, ensuring a solution in polynomial time. This model, called non-deterministic polynomial (NP) time, involves guessing and requires the algorithm to output 'yes' or 'no' in polynomial time.",valid,Advanced,6.006,19 Complexity,JbafQJx1CIA.en-j3PyPqV-e1s_6_mp4
165,What is the limitation on memory when using a 64-bit architecture with byte addressable memory?,"That was very limiting, actually. That's a restriction. With 64 bits, what's my limitation on memory that I can address-- byte addressable? Turns out to be something like 20 exabytes-- to put this in context, all data that Google stores on their servers, on all drives throughout the world-- it's about 10.","With 64 bits in a byte addressable memory architecture, the limitation is about 20 exabytes.",valid,Intermediate,6.006,1 Algorithms and Computation,ZA-tUyM_y7s.en-j3PyPqV-e1s_9_mp4
166,What data structure is suggested for fast lookup of outgoing edges in a graph?,"2 
Lecture 9: Breadth-First Search 
Neighbor Sets/Adjacencies 
• The outgoing neighbor set of u ∈ V is Adj+(u) = {v ∈ V | (u, v) ∈ E} 
• The incoming neighbor set of u ∈ V is Adj−(u) = {v ∈ V | (v, u) ∈ E} 
• The out-degree of a vertex u ∈ V is deg+(u) = |Adj+(u)| 
• The in-degree of a vertex u ∈ V is deg−(u) = |Adj−(u)| 
• For undirected graphs, Adj−(u) = Adj+(u) and deg−(u) = deg+(u) 
• Dropping superscript defaults to outgoing, i.e., Adj(u) = Adj+(u) and deg(u) = deg+(u) 
Graph Representations 
• To store a graph G = (V, E), we need to store the outgoing edges Adj(u) for all u ∈ V 
• First, need a Set data structure Adj to map u to Adj(u) 
• Then for each u, need to store Adj(u) in another data structure called an adjacency list 
• Common to use direct access array or hash table for Adj, since want lookup fast by vertex 
• Common to use array or linked list for each Adj(u) since usually only iteration is needed1 
• For the common representations, Adj has size Θ(|V |), while each Adj(u) has size Θ(deg(u)) 
P 
• Since 
u∈V deg(u) ≤ 2|E| by handshaking lemma, graph storable in Θ(|V | + |E|) space 
• Thus, for algorithms on graphs, linear time will mean Θ(|V | + |E|) (linear in size of graph) 
Examples 
• Examples 1 and 2 assume vertices are labeled {0, 1, . . . , |V | − 1}, so can use a direct access 
array for Adj, and store Adj(u) in an array. Example 3 uses a hash table for Adj. 
Ex 1 (Undirected) 
| Ex 2 (Directed) 
| Ex 3 (Undirected) 
G1 = [ 
| G2 = [ 
| G3 = { 
[2, 1], 
# 0 | 
[2], 
# 0 | 
a: [s, b], 
b: [a], 
[2, 0, 3], # 1 | 
[2, 0], 
# 1 | 
s: [a, c], 
c: [s, d, e], 
[1, 3, 0], # 2 | 
[1], 
# 2 | 
d: [c, e, f], e: [c, d, f], 
[1, 2], 
# 3 | ] 
| 
f: [d, e], 
g: [], 
] 
| 
| } 
• Note that in an undirected graph, connections are symmetric as every edge is outgoing twice 
1A hash table for each Adj(u) can allow checking for an edge (u, v) ∈ E in O(1)(e) time 
",It is common to use a direct access array or hash table for Adj since fast lookup by vertex is desired.,valid,Intermediate,6.006,Lecture 9 - Breadth-First Search,196a95604877d326c6586e60477b59d4_MIT6_006S20_lec9_2_pdf
167,What is the base case for the insert_last function in the insertion sort algorithm?,"4 
Lecture 3: Sorting 
Insertion Sort 
• Recursively sort preﬁx A[:i] 
• Sort preﬁx A[:i + 1] assuming that preﬁx A[:i] is sorted by repeated swaps 
• Example: [8, 2, 4, 9, 3], [2, 8, 4, 9, 3], [2, 4, 8, 9, 3], [2, 4, 8, 9, 3], [2, 3, 4, 8, 9] 
1 
def insertion_sort(A, i = None): 
# T(i) 
2 
’’’Sort A[:i + 1]’’’ 
3 
if i is None: i = len(A) - 1 
# O(1) 
4 
if i > 0: 
# O(1) 
5 
insertion_sort(A, i - 1) 
# T(i - 1) 
6 
insert_last(A, i) 
# S(i) 
7 
8 
def insert_last(A, i): 
# S(i) 
9 
’’’Sort A[:i + 1] assuming sorted A[:i]’’’ 
10 
if i > 0 and A[i] < A[i - 1]: 
# O(1) 
11 
A[i], A[i - 1] = A[i - 1], A[i] 
# O(1) 
12 
insert_last(A, i - 1) 
# S(i - 1) 
• insert last analysis: 
– Base case: for i = 0, array has one element so is sorted 
– Induction: assume correct for i, if A[i] >= A[i - 1], array is sorted; otherwise, 
swapping last two elements allows us to sort A[:i] by induction 
– S(1) = Θ(1), S(n) = S(n − 1) + Θ(1) =⇒ S(n) = Θ(n) 
• insertion sort analysis: 
– Base case: for i = 0, array has one element so is sorted 
– Induction: assume correct for i, algorithm sorts A[:i] by induction, and then 
insert last correctly sorts the rest as proved above 
– T (1) = Θ(1), T (n) = T (n − 1) + Θ(n) =⇒ T (n) = Θ(n2) 
","The base case for insert_last is when i = 0, where the array has one element so is sorted.",valid,Intermediate,6.006,Lecture 3 - Sorting,6d1ae5278d02bbecb5c4428928b24194_MIT6_006S20_lec3_4_pdf
168,How can the problem of finding the existence of a path between two vertices be solved using the shortest path approach?,"But of course, there's sort of many variations on that theme when we talk about shortest path or even just existence of a path. So these are three sort of model problems that we might solve on a graph. So the first one, which in this of course we're calling the single pair reachability, would be the idea that I take two vertices s and t on my graph g, and I ask you does there exists a path between s and t. So what would be the sort of extreme example where this problem may not always give back the answer yes? Somehow in our head, I think we think of all graphs as being connected. But a perfectly valid graph the way we've defined it would be like 10 vertices and no edges. This function would be very easy to code if that were the only graph you ever cared about. But any event, the existence of a path is already a query that takes a little bit of algorithmic thinking. We haven't figured out how to do that yet. Now another problem we can solve would be the shortest path. Given a graph and two vertices, we might say, well, how far apart are these vertices of my graph if I want to use the shortest possible distance from one to the other. Notice that I can use the second problem to solve the first one. Because what's the length of the shortest path between two vertices that don't have a path between them? Infinity or a shrug-- that's actually a totally valid answer. Yeah, that's right. So how could I implement the reachability code? Well, I could call my shortest path code, and it gives me infinity. Then I return no, it's not reachable. And if it gives me not infinity, I return yes. So remember that a key idea in an algorithms class is this idea of reduction. That I can use one function to solve another. So in case, if we can solve shortest path, then we can certainly solve the reachability problem by calling that piece of code. And then finally we could talk about single source shortest path. So notice now that there's only one input node here s-- so what this problem is saying is give me the length of the shortest path from s to every single other vertex in my graph. Does that makes sense? Like maybe I return a big array with all the information, every single shortest distance. So can we solve single pair shortest path using single source shortest path? Absolutely. I could take s in my single pair shortest path problem, compute the shortest path from s to literally everything else, and then throw away all of that information except the shortest path to t, and now I'm good. Now I haven't justified that this is the fastest possible way to solve that second problem, but at least it shows that if I can solve problem three I can also solve problem two. If I can solve from two I can also solve problem one. So in today's lecture, we're just going to worry about problem three. In other words, these things are sort of listed in increasing order of their difficulty. OK, so in order to think about the single source shortest path problem, we're going to make one additional construction. And this is an idea called the shortest path tree. I got lazy drawing PowerPoint slides at 2:00 AM yesterday,","To determine if a path exists between two vertices, one can use the shortest path approach by calling the shortest path code. If it returns infinity, there is no path, and if it returns a finite number, a path exists.",valid,Basic,6.006,9 Breadth-First Search,oFVYVzlvk9c.en-j3PyPqV-e1s_10_mp4
169,What is the goal when finding a Minimum Spanning Tree in a weighted graph?,"Minimum Spanning Tree-- so I'm trying to find a tree connecting all of the vertices in a connected component of my graph. And I'm trying to find-- in a weighted graph, I'm trying to find the spanning tree that has minimum total weight. So that's a problem-- a fundamental problem in weighted-graph algorithms. They've solved this via a greedy algorithm. And network flows and I guess cuts. So this is-- what is this? This is, I'm given a weighted graph. Basically, each of the weights correspond to a capacity. I could push water through along this edge. And I may be given a source vertex and a sink vertex. And I want to say, I want to shove water through the source vertex along the edges with their various capacities. And I'll get some amount of water on the other end in the source. So the question is, what's the most amount of water that I can push through this? Well, I could build that pipe network with the different things and just do this experimentally. I just stick a bunch of-- maybe-- I'm a mechanical engineer, so that maybe makes sense to me. But you want to be able to just look at those numbers and be able to tell me how much water can I push through. That's what the max flow in a network is talking about.",To find a spanning tree connecting all the vertices in a connected component of the graph that has the minimum total weight.,valid,Intermediate,6.006,20 Course Review,2NMtS1ecb3o.en-j3PyPqV-e1s_7_mp4
170,What does the Max Flow problem involve in the context of network flows?,"Minimum Spanning Tree-- so I'm trying to find a tree connecting all of the vertices in a connected component of my graph. And I'm trying to find-- in a weighted graph, I'm trying to find the spanning tree that has minimum total weight. So that's a problem-- a fundamental problem in weighted-graph algorithms. They've solved this via a greedy algorithm. And network flows and I guess cuts. So this is-- what is this? This is, I'm given a weighted graph. Basically, each of the weights correspond to a capacity. I could push water through along this edge. And I may be given a source vertex and a sink vertex. And I want to say, I want to shove water through the source vertex along the edges with their various capacities. And I'll get some amount of water on the other end in the source. So the question is, what's the most amount of water that I can push through this? Well, I could build that pipe network with the different things and just do this experimentally. I just stick a bunch of-- maybe-- I'm a mechanical engineer, so that maybe makes sense to me. But you want to be able to just look at those numbers and be able to tell me how much water can I push through. That's what the max flow in a network is talking about.","The Max Flow problem involves determining the most amount of flow (e.g., water) that can be pushed from a source vertex to a sink vertex in a weighted graph, where each weight corresponds to a capacity.",valid,Intermediate,6.006,20 Course Review,2NMtS1ecb3o.en-j3PyPqV-e1s_7_mp4
171,What is the running time of the provided algorithm for finding LIS?,"5 
Lecture 16: Dyn. Prog. Subproblems 
6. Time 
• # subproblems: |A| 
• work per subproblem: O(|A|) 
• O(|A|2) running time 
• Exercise: speed up to O(|A| log |A|) by doing only O(log |A|) work per subproblem, 
via AVL tree augmentation 
1 
def lis(A): 
2 
a =  len(A) 
3 
x = [1] * a 
4 
for i in reversed(range(a)): 
5 
for j in range(i, a): 
6 
if A[j] > A[i]: 
7 
x[i] = max(x[i], 1 + x[j]) 
8 
return max(x) 
",The running time is O(|A|^2).,invalid,Basic,6.006,"Lecture 16 - Dynamic Programming, Part 2 - LCS, LIS, Coins",28461a74f81101874a13d9679a40584d_MIT6_006S20_lec16_5_pdf
172,How does ray casting determine the color for each pixel on the screen?,"If you continue with me next fall, we'll teach 6.837, which is the Intro to Computer Graphics course. One thing that's always amazing to students is, these, algorithms that produce these really beautiful images, can fit in about 10, 20 lines of code. So really, this is totally facetious, because if you want those beautiful images and you use those 20 lines of code, you'll be waiting until the death of the universe to actually compute these things. But in any event, one nice one for rendering-- so drawing a bunch of shapes [INAUDIBLE],, something called ray casting, or its better known cousin, ray tracing. Typically, the difference is whether your rays can bounce off of the surface and have a secondary thing. Right. Here's the ray casting algorithm. Let's say I have a scene built out of spheres and cubes. I'm going to have a for loop over every pixel on the computer screen. For every pixel, I've got to discover what color that should be. So I shoot a ray from my eyeball through that pixel and find the first object that it runs into. It's not so hard to intersect a line of a sphere or a line of a cube. So what is that algorithm? I've given it to you on the screen here. Not too bad to think about. And I think you guys are all extremely well equipped to analyze the runtime of this, which is roughly the number of pixels times the number of objects. Because for every pixel, I've got to decide what object the ray out of my eyeball hits first. So I need a for loop over [INAUDIBLE].. Make sense? Cool. So let's look at a basic rendering problem.","To determine the color for each pixel on the screen, ray casting involves shooting a ray from the viewer's eye through each pixel and identifying the first object the ray intersects in the scene.",valid,Intermediate,6.006,21 AlgorithmsNext Steps,4nXw-f6NJ9s.en-j3PyPqV-e1s_10_mp4
173,"What is the role of ""w"" in the running time of data structures like van Emde Boas and fusion trees?","That was a brief tour of computational geometry. I work mostly in four different areas of algorithms-- geometry, data structures, graph algorithms, and what I call recreational algorithms. I think I made up that term. And let's go into data structures, which is represented by this class, 6.851. All of the classes I mentioned have online video lectures, especially for those watching at home on OpenCourseWare. Most of these classes are on OpenCourseWare, and if not, they're on my webpage. 6.851, Advanced Data Structures, is an extension of the sorts of data structures you've seen here, in 006 and the ones you will see in 6.046. I thought I would give you a flavor of one such result, which is a problem we've seen in this class done better. Suppose you want to store a dynamic ordered set. This is the set interface. Dynamic in the sense that I have insert and delete, and ordered in the sense that I want to support find-next and find-previous. Exactly which subset of the set interface you choose influences what data structure you've seen. We've seen, for dynamic sets, you want to use hashing. If you don't care about find-next, if you just care about find, then hashing is great-- constant expected. You can prove stronger things about hashing. And we do in that class. But if you want dynamic and ordered, you cannot do constant time per operation. You can prove that, which is cool. What data structure have we seen that solves this problem pretty well? Set AVL trees, which solve everything in log n. So log n is one competitor. Yeah. I'm interested in the word RAM model, which is the only model we've seen in this class. This happens to work in a stronger model. And we can do better than log n in the following-- it will take me a while before I get better, but here's, at least, a different bound we can get-- log w. This is via a structure called van Emde Boas, who is a person. AVL is two people. van Emde Boas, I've actually met. Log w-- remember, w is our word size. So this is a bit of a weird running time. It's great if w is log n, then this is log log n. And we know w is at least log n, but it could be bigger. We don't really have a sense of how big w could get. Maybe it's even n. Maybe it's big-- and then these are the same. Maybe it's bigger than n, and then this is maybe worse. But for most ws, this is actually pretty good-- and indeed, optimal. But it's not strictly better, in any sense, yet. On the other hand, there's another data structure which runs in log n divided by log w. This is called fusion trees. This was invented around the time that cold fusion was in the news, and so they wanted data structures to represent. We can achieve this bound or we can achieve this bound. And this bound is good is if w is large. This band as good if w is small. You can always take the min of the two, whatever is better. And in particular, the min of those two things is at most-- I think it's square root log n over log log n. If you want to bound just in terms of n, then the crossover point between these two is this place. And so you're always, at most, this, which is quite a bit better than the log n of AVL. We've got a square root and we've got a slight thing in the denominator. Pretty tiny. But the big thing is the square root. And that's kind of cool. And it turns out, that's pretty much optimal. In terms of an n bound, this is optimal. The min of these two, in general, is roughly optimal up to log log terms. For fun, I threw up the actual formula for the right-bound, which is tight up to constant factors of matching upper and lower bounds, which we talk about. It's min of three things-- four things, including log of w over a divided by log of log w over a log of log n over a. That's the last term that I just read. This was messy. Surprisingly, that is the right answer for this very particular problem-- a very natural problem. AUDIENCE: What is a? ERIK DEMAINE: A is the log of the space you're using. So it's the address size. Good question. If you throw it-- so it depends. If you have a polynomial space data structure, then basically, these are optimal. And this is generalizing to beyond that. Maybe you have a little bit more than polynomial space. Cool. So that's data structures. I'm going to jump ahead to graph algorithms, which, if you want to take this class, I recommend a time travel device.","""w"" represents the word size in the word RAM model. The running time of certain data structures such as van Emde Boas is expressed in terms of log w. If w is large, the running times for operations can be very efficient. The performance of fusion trees benefits when w is large, achieving a running time of log n divided by log w.",valid,Intermediate,6.006,21 AlgorithmsNext Steps,4nXw-f6NJ9s.en-j3PyPqV-e1s_4_mp4
174,"What does the subproblem x(i,f) represent in this context?","And this is going to use subproblem expansion. So the subproblems are going to be x of i, comma f-- this is the minimum total difficulty to play suffix-- because I like suffixes-- t i up to t n minus 1, starting with finger f on note t i. The obvious subproblems would be without this constraint.","The subproblem x(i,f) represents the minimum total difficulty to play the suffix from t_i up to t_{n-1}, starting with finger f on note t_i.",invalid,Basic,6.006,17 Dynamic Programming Part 3 APSP Parens Piano,TDo3r5M1LNo.en-j3PyPqV-e1s_14_mp4
175,What is the goal of the picture hanging problem as described?,"need to make each polyhedron. And some of these problems are NP-hard, and it's a lot of fun. Cool. I think that's the end of the slides. The last thing I wanted to show you is a problem, a puzzle/magic trick-- it comes from the puzzle world-- called the picture hanging problem. So imagine you have a picture. You want to hang it on a wall. So you invested in some nice rope, and you hang it on a nail. If the nail falls out, the picture falls, and you're sad. So you invest in two nails, like I have here, and maybe you hang your picture on both those nails. Now, if one of the nails falls out, you still have a crookedly hung picture. If the other nail falls out, OK, it's gone. I want to hang a picture on two nails such that, if I remove either nail, the picture falls. So, Jason, pick a nail, left or right. Left, we remove. Make sure this doesn't fall off-- and, boom, the picture falls. Same wrapping. You can check-- you can rewind the video, make sure I did the same wrapping. JASON KU: And take out the right. ERIK DEMAINE: Then take out the right one. Good choice. Then, also, the picture falls. This is a classic puzzle, but you can generalize it. So let me do it for three nails, which is all I have here. This nail is sagging a little bit. y, x-- y inverse, x inverse. I think that's right. So this is one way to hang a picture on three nails such that, if I remove any of the nails, the picture falls. Justin, 1, 2, or 3? 2. OK. Yeah, I want to get out of the way and make sure I don't go over the edge here. Yeah. It's a lot easier to make this one work. But you can see, boom, picture falls there. And of course, imagine infinite gravity. And the picture falls. Ta-da! You can generalize this to do essentially any-- what's called a monotone Boolean function-- on any set of nails. I mean, you can make any subset of the nails cause the picture to fall and any collection of subsets of nails to make it fall. Of course, if you remove more nails, it's still going to fall. That's the monotone sense. But otherwise, you can do an arbitrary pattern, which is fun. That's actually a result with Ron Rivest and a bunch of other people. I think I'm approximately on time. So that was a quick tour. And there are obviously various classes here you can take. 6.892, the hardness class, was just offered last semester, so it probably won't be for a while. But all of these classes are online. Watch the videos, feel free to ask me questions. And now we have Justin. I left you space here for your outline. You don't have to, but I'll put your name. JUSTIN SOLOMON: Thank you. JASON KU: So Justin is also a geometer. ERIK DEMAINE: Yeah, we've got a lot of geometry people in 006 this semester. JUSTIN SOLOMON: Thank you. OK. I can't help but share that, on our instructor chat, Erik was texting that he was going to be-- he was somehow nervous that the applied guy would have all of the cool stuff to show off, and now I feel totally boring. [LAUGHING] Right. Yeah. We have three different geometry instructors in this class. In this class, I think we have many different flavors of geometry that are kind of represented in this room here, from mechanical engineering, to theory plus lots of other cool stuff, to whatever it is that I do. I'm a professor, also, in CSAIL, and lead a group that studies slightly more applied geometry problems, in some sense, and in CSAIL, we kind of cross a lot of boundaries-- actually, closer to the math department than to the theory group and computer science, which I would argue is largely a historical artifact rather than anything interesting about computer science or math. Continuing in our whirlwind tour of interesting geometry classes here at MIT, I have some more fun things to add to the list. And we'll introduce some of the ideas in the next couple of slides here.","To hang a picture on nails such that if any of the nails is removed, the picture falls.",valid,Basic,6.006,21 AlgorithmsNext Steps,4nXw-f6NJ9s.en-j3PyPqV-e1s_7_mp4
176,"What challenges might an instructor face when teaching sorting algorithms to a large group of students, and how can these be addressed?","[SQUEAKING] [RUSTLING] [CLICKING] JUSTIN: OK. So it's a pleasure to see all of you guys. I'm Justin. I'm your third instructor for 6.006. This is my first time with this course. Although, of course, this is material that we all know and love in the computer science department. I'll admit, I find the prospect of teaching sorting to 400 people all at once is mildly, low key terrifying. But we're going to give it a shot. And hopefully, that will subside as the lecture goes on today, all right? So we're going to pick up where we left off in our last lecture and continue on with a similar theme that we're going to see throughout our algorithms class here in 6.006. I think Jason and colleagues have done a really great job of organizing this class around some interesting themes. And so I thought I'd start with just a tiny bit of review","Teaching sorting algorithms to a large group of students can be daunting, as the instructor may feel pressure due to the sheer number of students. To address this, the instructor can rely on a well-organized course structure and continuity in themes throughout the course, which helps in managing the flow of information and maintaining student engagement during the lecture.",administrative,Advanced,6.006,3 Sets and Sorting,oS9aPzUNG-s.en-j3PyPqV-e1s_1_mp4
177,What is the Shellcode address?,"MIT OpenCourseWare 
https://ocw.mit.edu 
6.006 Introduction to Algorithms 
Spring 2020 
For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms 
",The address of the memory region that contains the shellcode.,invalid,Basic,6.006,Lecture 4 - Hashing,ce9e94705b914598ce78a00a70a1f734_MIT6_006S20_lec4_5_pdf
178,What is the primary goal of the lecture covered?,"There are a few corollaries to that fact. So unless there are any questions about that, we'll get started with our new unit in 6.006 which is a graph theory. If you're wondering, there's a graph on the screen here. But of course, we'll fill in a little bit more information today throughout our lecture. When I was learning how to teach, which I'm still doing, actually my PhD advisor told me if you want somebody to learn something, you have to write it as big as possible. And so I'm really leaning into that approach today in our slides. So in any event, so today we're going to have our first lecture on graphs which I think will somewhat be a review for many of you guys. And if it's not, that's cool too. Because we'll start from the beginning and kind of build up all the notions that we need to understand and process graphs and hopefully by the end of lecture, have some style of algorithm for computing the shortest path from one vertex to all the other ones.",To have some style of algorithm for computing the shortest path from one vertex to all the other ones.,administrative,Basic,6.006,9 Breadth-First Search,oFVYVzlvk9c.en-j3PyPqV-e1s_2_mp4
179,What does it mean for relaxation to be safe?,"just talking about the correctness of Dijkstra's algorithm. OK. Correctness follows from two main observations. So the claim here that we're trying to prove is that d of s equals the delta s-- so the estimates equal the shortest-path distance is at the end of Dijkstra for all v and V at end. And this is going to follow from two observations. So the proof here, first, if ever relaxation sets d of s of v-- it sets the estimate equal to the shortest-path distance, if it ever does that, I argue to you that still true at end. OK, that's not a very strong statement. This is saying if I ever set the distance estimate to the true distance, I'm never going to set it to a different value later on. And why is that? Well, relaxation only ever decreases the distance. Relaxation only decreases d s, v. But we proved in lecture 11-- so two lectures ago that relaxation is safe. And what does safe mean? Safe means that relaxation-- that relaxation will only ever change these distant estimates to be either infinite-- it was never-- there was never a path to my vertex. Or it was the length of some path to v. Length of some path. OK. So what does that mean? It only decreases, but it's always the length of some path to v. So if this is the length of the shortest path to v, I could never set it to a smaller length, because there are no paths with shorter distance. That's the whole point. OK. So with this observation, I'm going to argue this final claim. It suffices to show that my estimate equals the shortest distance when v is removed from the Q. And since I removed every vertex from the Q in this while loop, I will eventually said to all of the distance estimates to the real distance and we'll be golden. Happy days. All right. So we'll be done if we can prove that statement. All right. So we're going to prove this by induction obviously. Induction on first k vertices removed from the Q. So the Q, we're popping vertices from this Q in some order. So I'm going to just argue that this claim is true for the first k. Clearly that's true for k equals 1. Base case, k equals 1. What is k equals 1? That means the first word vertex that I pop has this property, which is definitely true, because we set the shortest distance to s to be 0. That's all good. Now we have our inductive step. Assume it's true for k prime-- sorry, k less than k prime. And let's let v prime be k prime vertex popped. v prime. OK. And now let's look at some shortest path from s to v prime. So we got the shortest path from s to v prime. It exists. v prime is accessible. Let's say we pruned our graph to be only the things accessible from s so that, yeah, there exists the shortest path to v prime. And now let's think about these vertices. Some of them were removed from the Q and some of them were not. s was definitely removed from the Q. But some of these other vertices might not be. I want to be able to induct on this path, in particular, the vertex before me so that I can say that when I removed it and I relax the edge to v prime, then we're all golden. But that might not be the case. There could be a vertex, the vertex preceding me in the graph in this shortest path that was not popped from Q. I need to argue that it was or some other thing. So let's consider the first vertex in this path from s to v. I'm going to call it y, I think. Yeah. A vertex y that is not in Q. After I pop v prime, this is the first-- or before I pop v prime, y is not in the Q. Now these might be the same vertex if all of the preceding ones on this path were in the Q. But in particular, we're going to look at this guy. And say its predecessor's x in the path. Well what do I know? I know that x is in the queue. Everything here was popped from the Q-- not in. Which means that by induction, the shortest-path distance was set here correctly. So that the distance estimate at y can't be bigger than the shortest path to x plus w x, y. But this is on the shortest path to y, because the subpaths of shortest paths or shortest paths. So this has to equal d s, y, the distance to y. So actually, y is all good here. And so if v prime were y, we'd be done. That's the same argument is DAG relaxation. But we need to prove something about v prime. Well, because we have non-negative weights, the distance to v prime has to be at least as big as this distance, because it's a subpath. So this has to be less than or equal to the true distance to v prime. Because of negative-- non-negative weights, because the weights are non-negative. But because relaxation is safe, we know that our distance estimate for v prime has to be at least the shortest-path distance. This is because it's safe. This is-- weights are greater than or equal to 0. The last step here is that because we're popping the minimum from our priority queue, the thing with the smallest shortest-path distance, this has to be less than or equal to the shortest-path distance estimate to y. Because this is the smallest among all such vertices in my Q. But these are the same value. So everything between here is the same value. In particular, the estimate here is equal to my true shortest-path distance, which is exactly what we're trying to prove. OK, so that's why Dijkstra's correct. I'm going to spend the last five minutes on the running time of Dijkstra. We set this up so that we did everything in terms of these Q operations. Right so we have these Q operations, we have three of them. I'm going to say if I have a build operation, let's say it takes B time; to lead min, I'm going to say it takes M time; and this decreased key,","Relaxation is safe means that relaxation will only ever change distance estimates to be either infinite (indicating there was no path to the vertex) or the length of some path to the vertex. It decreases the estimate, but it is always the length of some path to the vertex.",valid,Basic,6.006,13 Dijkstra,NSHizBK9JD8.en-j3PyPqV-e1s_5_mp4
180,What is the significance of having a negative weight edge in an undirected graph?,"JASON KU: Ah. Your colleague has determined an interesting fact about undirected graphs. If you have a negative weight edge in an undirected graph, I can just move back and forth along that edge. That's a cycle of length 2-- or I guess three vertices back to where we came from. There is of negative weight, because I'm just traversing that weight over and over and over again. So the question of single-source shortest paths of finding negative weights is not particularly interesting in the undirected case. What I can do is just for every negative weight edge, undirected edge in my graph, I can just find the readability from the vertices-- the endpoints of that edge and label them as minus-- basically if the connected component containing S has a negative weight edge, then everything in the graph is accessible from a negative weight cycle. So this is not such an interesting problem. And so we're going to restrict our discussion today to directed graphs. So this is if and only if exists negative weight edge. OK, exercise 2, kind of a little preview for what's to come, we're actually not going to show you an algorithm directly that meets this Bellman-Ford running time, V times E. What instead we're going to show you is an algorithm that solves single-source shortest paths in-- So given an algorithm, Alg A, solves single-source shortest paths in order V times V plus E time. OK, what is that? That's V squared plus V times E. That's close to what this V times E is. That's what we're going to show you. But if I had such an algorithm, can anyone tell me a single-source shortest paths algorithm-- how we can use this algorithm to solve single-source shortest paths in just V times E time? Show how to solve SSSP in order the V times E. I guess we can put a dot there as well. So this is a little tricky. It's kind of related to the difference we had between the reachability problem and the single-source shortest paths problem that we saw last lecture. When are these asymptotically different in their upper bound is when V is asymptotically larger than E. But the connected component containing S can have at most E vertices, or order E. It can actually have at most E plus 1 vertices, because otherwise it wouldn't be connected. So, what we can do if we had such an algorithm, we could first, when we're giving our graph, explore everything in the graph using BFS or DFS, find all the things reachable from S, and then just throw away everything else. Now I have a graph for which V is asymptotically no bigger than E, and then we can use this algorithm to solve single-source shortest paths in V times E time. I'm not going to write all that down here. You can see it in the notes. Yeah? AUDIENCE: Does this work if your graph isn't simple? JASON KU: Does this work as your graph isn't simple? I haven't thought about it. We are not going to talk about non-simple graphs in this class, but probably not because you've got a lot of edges. Though in our class if we're talking about single-source shortest paths, if we have multiple edges between two vertices, we can just take the minimum weight one because it's never better to take the larger ones. Does that answer your question? Great. All right. So those are our warm-ups, that's our goal. We need to find an algorithm for single-source shortest paths. And general graphs, graphs with-- potentially graphs with cycles, and negative weights, and solve it in this V times linear kind of time. That makes sense? All right. So first, before we get to the algorithm, we're going to discuss a little bit about simple short-- about shortest paths in general. If we didn't-- the problem here is negative weights. How do we find-- if we had negative weight cycles, there seems to be these problems, because we could have minus infinities is in our deltas. But if we didn't have negative weights, I'd like to assert to you that our shortest paths, even if there are negative weights, are going to be simple. They won't repeat vertices. So that's the first thing we're going to show you. Let's see. Simple shortest paths. OK. So, claim. I'm going to give my claims numbers today just because I'm going to have a lot of them. If my shortest path distance from S to some vertex is finite, meaning it's not infinite or minus infinite-- some finite value, there exists a shortest path-- a shortest S to V path that is simple. And remember, simple means not going through a vertex more than once. All right. How are we going to prove this? Well, consider if this claim was not true. If every shortest path contained a cycle, essentially. It repeated a vertex. Then my path looks something like this. I mean, there's some vertices along here, and then I go to V. So here's S, and then there's some cycle I repeat, some vertex. I'm going to call this cycle C. Now what do I know about this path? I know that it has-- it's a shortest path and it has finite weight. So in particular, this path-- this delta distance is not minus infinity. But if this is not minus infinity, what do I know about the weight of this cycle? AUDIENCE: It's not negative. JASON KU: Yeah. It can't be negative. Because if it was negative, I could keep going around this cycle, and this would have a non-finite weight. Shortest path distance from S. So I know this is-- can't be negative, so it must be 0 or positive. But if it's 0 or positive and this is a shortest path-- went through this cycle, then I could remove it, and now I have a new path with one fewer cycle. I could just keep doing this to create a simple path. So that checks out. OK. So, that's interesting. If it's simple, what do we know about the number of edges in a simple shortest paths? How many could there possibly be? How long in number of edges could a simple shortest path be? If I can't repeat vertices, I can have at most vertices on my simple path, which means I can use at most V minus 1 edges-- fence posting. So, simple paths have at most V minus 1 edges. That's a nice little thing I'd like to box off. That's a really nice property. So while a shortest path here could have an infinite number","If there is a negative weight edge in an undirected graph, it allows for the creation of a cycle of negative weight by moving back and forth along that edge, making the problem of finding single-source shortest paths with negative weights uninteresting in undirected graphs.",valid,Basic,6.006,12 Bellman-Ford,f9cVS_URPc0.en-j3PyPqV-e1s_4_mp4
181,What is a simple shortest path in the context of graphs?,"JASON KU: Ah. Your colleague has determined an interesting fact about undirected graphs. If you have a negative weight edge in an undirected graph, I can just move back and forth along that edge. That's a cycle of length 2-- or I guess three vertices back to where we came from. There is of negative weight, because I'm just traversing that weight over and over and over again. So the question of single-source shortest paths of finding negative weights is not particularly interesting in the undirected case. What I can do is just for every negative weight edge, undirected edge in my graph, I can just find the readability from the vertices-- the endpoints of that edge and label them as minus-- basically if the connected component containing S has a negative weight edge, then everything in the graph is accessible from a negative weight cycle. So this is not such an interesting problem. And so we're going to restrict our discussion today to directed graphs. So this is if and only if exists negative weight edge. OK, exercise 2, kind of a little preview for what's to come, we're actually not going to show you an algorithm directly that meets this Bellman-Ford running time, V times E. What instead we're going to show you is an algorithm that solves single-source shortest paths in-- So given an algorithm, Alg A, solves single-source shortest paths in order V times V plus E time. OK, what is that? That's V squared plus V times E. That's close to what this V times E is. That's what we're going to show you. But if I had such an algorithm, can anyone tell me a single-source shortest paths algorithm-- how we can use this algorithm to solve single-source shortest paths in just V times E time? Show how to solve SSSP in order the V times E. I guess we can put a dot there as well. So this is a little tricky. It's kind of related to the difference we had between the reachability problem and the single-source shortest paths problem that we saw last lecture. When are these asymptotically different in their upper bound is when V is asymptotically larger than E. But the connected component containing S can have at most E vertices, or order E. It can actually have at most E plus 1 vertices, because otherwise it wouldn't be connected. So, what we can do if we had such an algorithm, we could first, when we're giving our graph, explore everything in the graph using BFS or DFS, find all the things reachable from S, and then just throw away everything else. Now I have a graph for which V is asymptotically no bigger than E, and then we can use this algorithm to solve single-source shortest paths in V times E time. I'm not going to write all that down here. You can see it in the notes. Yeah? AUDIENCE: Does this work if your graph isn't simple? JASON KU: Does this work as your graph isn't simple? I haven't thought about it. We are not going to talk about non-simple graphs in this class, but probably not because you've got a lot of edges. Though in our class if we're talking about single-source shortest paths, if we have multiple edges between two vertices, we can just take the minimum weight one because it's never better to take the larger ones. Does that answer your question? Great. All right. So those are our warm-ups, that's our goal. We need to find an algorithm for single-source shortest paths. And general graphs, graphs with-- potentially graphs with cycles, and negative weights, and solve it in this V times linear kind of time. That makes sense? All right. So first, before we get to the algorithm, we're going to discuss a little bit about simple short-- about shortest paths in general. If we didn't-- the problem here is negative weights. How do we find-- if we had negative weight cycles, there seems to be these problems, because we could have minus infinities is in our deltas. But if we didn't have negative weights, I'd like to assert to you that our shortest paths, even if there are negative weights, are going to be simple. They won't repeat vertices. So that's the first thing we're going to show you. Let's see. Simple shortest paths. OK. So, claim. I'm going to give my claims numbers today just because I'm going to have a lot of them. If my shortest path distance from S to some vertex is finite, meaning it's not infinite or minus infinite-- some finite value, there exists a shortest path-- a shortest S to V path that is simple. And remember, simple means not going through a vertex more than once. All right. How are we going to prove this? Well, consider if this claim was not true. If every shortest path contained a cycle, essentially. It repeated a vertex. Then my path looks something like this. I mean, there's some vertices along here, and then I go to V. So here's S, and then there's some cycle I repeat, some vertex. I'm going to call this cycle C. Now what do I know about this path? I know that it has-- it's a shortest path and it has finite weight. So in particular, this path-- this delta distance is not minus infinity. But if this is not minus infinity, what do I know about the weight of this cycle? AUDIENCE: It's not negative. JASON KU: Yeah. It can't be negative. Because if it was negative, I could keep going around this cycle, and this would have a non-finite weight. Shortest path distance from S. So I know this is-- can't be negative, so it must be 0 or positive. But if it's 0 or positive and this is a shortest path-- went through this cycle, then I could remove it, and now I have a new path with one fewer cycle. I could just keep doing this to create a simple path. So that checks out. OK. So, that's interesting. If it's simple, what do we know about the number of edges in a simple shortest paths? How many could there possibly be? How long in number of edges could a simple shortest path be? If I can't repeat vertices, I can have at most vertices on my simple path, which means I can use at most V minus 1 edges-- fence posting. So, simple paths have at most V minus 1 edges. That's a nice little thing I'd like to box off. That's a really nice property. So while a shortest path here could have an infinite number",A simple shortest path is one that does not repeat any vertices.,valid,Basic,6.006,12 Bellman-Ford,f9cVS_URPc0.en-j3PyPqV-e1s_4_mp4
182,Why can't a simple shortest path in a graph contain a cycle with negative weight?,"JASON KU: Ah. Your colleague has determined an interesting fact about undirected graphs. If you have a negative weight edge in an undirected graph, I can just move back and forth along that edge. That's a cycle of length 2-- or I guess three vertices back to where we came from. There is of negative weight, because I'm just traversing that weight over and over and over again. So the question of single-source shortest paths of finding negative weights is not particularly interesting in the undirected case. What I can do is just for every negative weight edge, undirected edge in my graph, I can just find the readability from the vertices-- the endpoints of that edge and label them as minus-- basically if the connected component containing S has a negative weight edge, then everything in the graph is accessible from a negative weight cycle. So this is not such an interesting problem. And so we're going to restrict our discussion today to directed graphs. So this is if and only if exists negative weight edge. OK, exercise 2, kind of a little preview for what's to come, we're actually not going to show you an algorithm directly that meets this Bellman-Ford running time, V times E. What instead we're going to show you is an algorithm that solves single-source shortest paths in-- So given an algorithm, Alg A, solves single-source shortest paths in order V times V plus E time. OK, what is that? That's V squared plus V times E. That's close to what this V times E is. That's what we're going to show you. But if I had such an algorithm, can anyone tell me a single-source shortest paths algorithm-- how we can use this algorithm to solve single-source shortest paths in just V times E time? Show how to solve SSSP in order the V times E. I guess we can put a dot there as well. So this is a little tricky. It's kind of related to the difference we had between the reachability problem and the single-source shortest paths problem that we saw last lecture. When are these asymptotically different in their upper bound is when V is asymptotically larger than E. But the connected component containing S can have at most E vertices, or order E. It can actually have at most E plus 1 vertices, because otherwise it wouldn't be connected. So, what we can do if we had such an algorithm, we could first, when we're giving our graph, explore everything in the graph using BFS or DFS, find all the things reachable from S, and then just throw away everything else. Now I have a graph for which V is asymptotically no bigger than E, and then we can use this algorithm to solve single-source shortest paths in V times E time. I'm not going to write all that down here. You can see it in the notes. Yeah? AUDIENCE: Does this work if your graph isn't simple? JASON KU: Does this work as your graph isn't simple? I haven't thought about it. We are not going to talk about non-simple graphs in this class, but probably not because you've got a lot of edges. Though in our class if we're talking about single-source shortest paths, if we have multiple edges between two vertices, we can just take the minimum weight one because it's never better to take the larger ones. Does that answer your question? Great. All right. So those are our warm-ups, that's our goal. We need to find an algorithm for single-source shortest paths. And general graphs, graphs with-- potentially graphs with cycles, and negative weights, and solve it in this V times linear kind of time. That makes sense? All right. So first, before we get to the algorithm, we're going to discuss a little bit about simple short-- about shortest paths in general. If we didn't-- the problem here is negative weights. How do we find-- if we had negative weight cycles, there seems to be these problems, because we could have minus infinities is in our deltas. But if we didn't have negative weights, I'd like to assert to you that our shortest paths, even if there are negative weights, are going to be simple. They won't repeat vertices. So that's the first thing we're going to show you. Let's see. Simple shortest paths. OK. So, claim. I'm going to give my claims numbers today just because I'm going to have a lot of them. If my shortest path distance from S to some vertex is finite, meaning it's not infinite or minus infinite-- some finite value, there exists a shortest path-- a shortest S to V path that is simple. And remember, simple means not going through a vertex more than once. All right. How are we going to prove this? Well, consider if this claim was not true. If every shortest path contained a cycle, essentially. It repeated a vertex. Then my path looks something like this. I mean, there's some vertices along here, and then I go to V. So here's S, and then there's some cycle I repeat, some vertex. I'm going to call this cycle C. Now what do I know about this path? I know that it has-- it's a shortest path and it has finite weight. So in particular, this path-- this delta distance is not minus infinity. But if this is not minus infinity, what do I know about the weight of this cycle? AUDIENCE: It's not negative. JASON KU: Yeah. It can't be negative. Because if it was negative, I could keep going around this cycle, and this would have a non-finite weight. Shortest path distance from S. So I know this is-- can't be negative, so it must be 0 or positive. But if it's 0 or positive and this is a shortest path-- went through this cycle, then I could remove it, and now I have a new path with one fewer cycle. I could just keep doing this to create a simple path. So that checks out. OK. So, that's interesting. If it's simple, what do we know about the number of edges in a simple shortest paths? How many could there possibly be? How long in number of edges could a simple shortest path be? If I can't repeat vertices, I can have at most vertices on my simple path, which means I can use at most V minus 1 edges-- fence posting. So, simple paths have at most V minus 1 edges. That's a nice little thing I'd like to box off. That's a really nice property. So while a shortest path here could have an infinite number","If a simple shortest path contained a cycle with negative weight, the total path weight could be made indefinitely smaller by repeating that cycle, thus it cannot qualify as a shortest path with finite weight.",valid,Basic,6.006,12 Bellman-Ford,f9cVS_URPc0.en-j3PyPqV-e1s_4_mp4
183,How many edges can a simple path in a graph have at most?,"JASON KU: Ah. Your colleague has determined an interesting fact about undirected graphs. If you have a negative weight edge in an undirected graph, I can just move back and forth along that edge. That's a cycle of length 2-- or I guess three vertices back to where we came from. There is of negative weight, because I'm just traversing that weight over and over and over again. So the question of single-source shortest paths of finding negative weights is not particularly interesting in the undirected case. What I can do is just for every negative weight edge, undirected edge in my graph, I can just find the readability from the vertices-- the endpoints of that edge and label them as minus-- basically if the connected component containing S has a negative weight edge, then everything in the graph is accessible from a negative weight cycle. So this is not such an interesting problem. And so we're going to restrict our discussion today to directed graphs. So this is if and only if exists negative weight edge. OK, exercise 2, kind of a little preview for what's to come, we're actually not going to show you an algorithm directly that meets this Bellman-Ford running time, V times E. What instead we're going to show you is an algorithm that solves single-source shortest paths in-- So given an algorithm, Alg A, solves single-source shortest paths in order V times V plus E time. OK, what is that? That's V squared plus V times E. That's close to what this V times E is. That's what we're going to show you. But if I had such an algorithm, can anyone tell me a single-source shortest paths algorithm-- how we can use this algorithm to solve single-source shortest paths in just V times E time? Show how to solve SSSP in order the V times E. I guess we can put a dot there as well. So this is a little tricky. It's kind of related to the difference we had between the reachability problem and the single-source shortest paths problem that we saw last lecture. When are these asymptotically different in their upper bound is when V is asymptotically larger than E. But the connected component containing S can have at most E vertices, or order E. It can actually have at most E plus 1 vertices, because otherwise it wouldn't be connected. So, what we can do if we had such an algorithm, we could first, when we're giving our graph, explore everything in the graph using BFS or DFS, find all the things reachable from S, and then just throw away everything else. Now I have a graph for which V is asymptotically no bigger than E, and then we can use this algorithm to solve single-source shortest paths in V times E time. I'm not going to write all that down here. You can see it in the notes. Yeah? AUDIENCE: Does this work if your graph isn't simple? JASON KU: Does this work as your graph isn't simple? I haven't thought about it. We are not going to talk about non-simple graphs in this class, but probably not because you've got a lot of edges. Though in our class if we're talking about single-source shortest paths, if we have multiple edges between two vertices, we can just take the minimum weight one because it's never better to take the larger ones. Does that answer your question? Great. All right. So those are our warm-ups, that's our goal. We need to find an algorithm for single-source shortest paths. And general graphs, graphs with-- potentially graphs with cycles, and negative weights, and solve it in this V times linear kind of time. That makes sense? All right. So first, before we get to the algorithm, we're going to discuss a little bit about simple short-- about shortest paths in general. If we didn't-- the problem here is negative weights. How do we find-- if we had negative weight cycles, there seems to be these problems, because we could have minus infinities is in our deltas. But if we didn't have negative weights, I'd like to assert to you that our shortest paths, even if there are negative weights, are going to be simple. They won't repeat vertices. So that's the first thing we're going to show you. Let's see. Simple shortest paths. OK. So, claim. I'm going to give my claims numbers today just because I'm going to have a lot of them. If my shortest path distance from S to some vertex is finite, meaning it's not infinite or minus infinite-- some finite value, there exists a shortest path-- a shortest S to V path that is simple. And remember, simple means not going through a vertex more than once. All right. How are we going to prove this? Well, consider if this claim was not true. If every shortest path contained a cycle, essentially. It repeated a vertex. Then my path looks something like this. I mean, there's some vertices along here, and then I go to V. So here's S, and then there's some cycle I repeat, some vertex. I'm going to call this cycle C. Now what do I know about this path? I know that it has-- it's a shortest path and it has finite weight. So in particular, this path-- this delta distance is not minus infinity. But if this is not minus infinity, what do I know about the weight of this cycle? AUDIENCE: It's not negative. JASON KU: Yeah. It can't be negative. Because if it was negative, I could keep going around this cycle, and this would have a non-finite weight. Shortest path distance from S. So I know this is-- can't be negative, so it must be 0 or positive. But if it's 0 or positive and this is a shortest path-- went through this cycle, then I could remove it, and now I have a new path with one fewer cycle. I could just keep doing this to create a simple path. So that checks out. OK. So, that's interesting. If it's simple, what do we know about the number of edges in a simple shortest paths? How many could there possibly be? How long in number of edges could a simple shortest path be? If I can't repeat vertices, I can have at most vertices on my simple path, which means I can use at most V minus 1 edges-- fence posting. So, simple paths have at most V minus 1 edges. That's a nice little thing I'd like to box off. That's a really nice property. So while a shortest path here could have an infinite number","A simple path can have at most V - 1 edges, where V is the number of vertices.",valid,Basic,6.006,12 Bellman-Ford,f9cVS_URPc0.en-j3PyPqV-e1s_4_mp4
184,How can the parent node index be computed from a given left or right child node index in a binary heap stored as an array?,"basically means no pointers, just an array of the n items. How are we going to get away without storing pointers? I'd still like to treat it like a tree. I'd still like to know the left child of B is D and the right child B is E. We'll see why in a moment. Well, we can do this with index arithmetic. So maybe I should add some labels before I get there. So this array naturally has indices. This is index 0. This is index 1, index 2, index 3, index 4, index 5, index 6, 7, 8, 9, because there are 10 items, 0 through 9. And I can apply those labels up here, too. These are the same nodes, so 0, 1, 2. This is just a depth order. But once I have this labeling, it's going to be a lot easier to figure things out. So if I wanted to know the left child of B is D, somehow, given the number 1, I want to compute the number 3. Add 2, there are all sorts-- multiply by 3, there are all sorts of operations that take 1 and turn it into 3. But there's only one that's going to work in all cases. And the intuition here is, well, I have to 2 the i nodes at level i. If I want to go to the child level, there's 2 to the i plus 1 nodes down there-- exactly double. So it's the very last one, but that won't really matter. If there is a left child, it will behave the same. And so, intuitively, I have this space of size 2 to the i. I have to expand it to a space of size 2 to the i plus 1, So I should multiply by 2. And that's almost right, but then there's some constants. So I'd like to say 2 times i. But if we look at the examples here, 1 times 2 is 2, which is 1 less than 3. 2 times 2 is 4, which is 1 less than 5. Hey, we almost got it right. It's just off by 1. Off by 1 is-- index errors are the most common things in computer science. What about the right child? If the left child is a 2i plus 1, where is the right child? I hear lots of mumbles. 2i plus 2-- one more. Because we're writing things left to right in depth order, the right child is the right sibling of the left child. So it's just one larger, OK? Given those rules, we can also compute parent. It's just whatever is the inverse of both of these functions, which I want to divide by 2 at some point. I want to get back to i given 2i plus 1 or given 2i plus 2. And so if I subtract 1 from i, then I either get 2i or 2i plus 1. And then, if I take an integer division by 2, I get i-- the original i. Sorry, maybe I'll call this j to be clearer. So j is the left or right child. Then I can reconstruct i, which was the parent. So this is constant number arithmetic operations. So I don't have to store left and right pointers. I can just compute them whenever I need them. Whenever I'm at some node like E, and I want to know what's its left child-- sorry, given the node index 4, which happens to contain the item E, and I want to know what's its left child, I just multiply by 2 and add 1. I get 9. And then, I can index into this array at position 9. Because I don't-- this is just in my head, remember. We're just thinking that there's a tree here. But in reality, on the computer, there's just the array. So if we want to go from E to J, we can, from 4 to 9. If we go try to go to the right child, we multiply by 2. 8 add 2-- 10. And we see, oh, 10 is beyond the end of the array. But our array stores its size, so we realize, oh, E does not have a right child. This is something you can only do in a complete binary tree. In a general binary tree you don't have these nice properties. Cool, so this is basically a heap. I just need to add one more property, naturally called the heap property.","Given a child node index j (which could be from 2i+1 for a left child or 2i+2 for a right child), the parent node index i can be computed by first subtracting 1 from j, then performing integer division by 2. This operation effectively reverses the relationship and retrieves the parent index.",valid,Advanced,6.006,8 Binary Heaps,Xnpo1atN-Iw.en-j3PyPqV-e1s_9_mp4
185,What is a key message about the relevance of the course content?,"But the real message here is, of course, that this course is unavoidable. Even in these extremely applied problems showing up in court cases or on your graphics card, you still-- complexity and algorithms and data structures are going to come back to play. So with that, our other two instructors up here for our final farewell-- suitably distance ourselves. ERIK DEMAINE: So algorithms are everywhere. I hope you enjoyed this class. It's been a lot of fun teaching you and having you as students. Even though you're not here physically in the room, we still feel your presence. And I look forward to seeing you all soon. Thanks for being a part of this fun thing. I want to thank our two-- my two co-instructors for an awesome time this semester. It's been a lot of fun teaching to you guys. JASON KU: Thanks for spending 006 with us this term. JUSTIN SOLOMON: Yeah. Thank you. And hopefully we'll see you again soon. ERIK DEMAINE: Bye. JASON KU: Bye.","Complexity, algorithms, and data structures are unavoidable and will play a role even in extremely applied problems.",administrative,Basic,6.006,21 AlgorithmsNext Steps,4nXw-f6NJ9s.en-j3PyPqV-e1s_13_mp4
186,Why is time complexity critical in the learning algorithms used in autonomous driving systems?,"I really lead kind of a weird, extremely [INAUDIBLE] group, where some of our students are essentially theory students-- touch your keyboard. I'm sorry. It was a reflex. But it was fast. All right. So we have some students whose background is in math, other ones that we're in autonomous driving industry and decided to come back and work in research. Because of that, we have this extremely broad set of research problems, everything from the sort of classic machine learning problems you might encounter in geometry world-- like if I have a self-driving car and I want to identify pedestrians and other cars on the road in an efficient and accurate fashion. By the way, part of that is machine learning and deep whatever, but there's another part, which is algorithms. Because actually, what comes into your LiDAR scanner is on the order of [INAUDIBLE] with points and some minuscule fraction of time. And time complexity of your learning algorithm actually is really critical to get it right, and something that there are a lot of open problems right now, because it's really not compatible with the hardware architecture that these cars often use. We also look at [INAUDIBLE] geometry problems, like if I give you data, can I find a geometric structure? So it's a classic example of natural language processing. When we use words like near and far, in terms of semantics and meaning, all the time. The question is, can we actually find an embedded of our word data into a geometric space to facilitate the statistical algorithms that we care about? And of course, we apply geometry to lots of practical problems, everything from meshing and scientific computing, which I think is sort of a classic one-- in fact, I think we're the first group that sort of enumerated all of the cool things that may happen to decahedral meshes, which is this bottom figure here. I should show this to people. There's some fun things to look at there. To other practical problems, like taking-- Erik took a zebra and folded it. We can take a zebra and move its texture onto a cat or a pig-- or, actually, off the side of the screen. But if we don't move the paper, [INAUDIBLE] for the 3D scan of what it might [INAUDIBLE]. In any event, in my five minutes remaining here, I thought I would dig into a little bit of detail of two-- or maybe one application, depending on when Jason and Erik get bored. And essentially, my message for you guys is, of course, [INAUDIBLE]. I'm not really a central CS theory group member here at MIT. But unfortunately for you guys, 6.006 is unavoidable. Even if you want to go into deep learning, statistics, whatever-- data science-- you're going to encounter the material that you've seen in this course. And in fact, it's really the bread and butter of just about everything everybody does here in this Data Center. So then, I'll give you two quick examples, one of which","Time complexity is critical in the learning algorithms for autonomous driving systems because the data coming into the LiDAR scanner is massive, and processing it efficiently and accurately is essential. The learning algorithms need to operate within a minuscule fraction of time due to the volume of data, and the current open problems involve making them compatible with the hardware architecture used in these systems.",valid,Advanced,6.006,21 AlgorithmsNext Steps,4nXw-f6NJ9s.en-j3PyPqV-e1s_9_mp4
187,What is the reachability problem in graph theory?,"is called depth-first search, which doesn't do that, but rather, starts with its first vertex and just starts walking all the way out until it can't do that anymore. And then it kind of backtracks. That's one way to think about it. And so somehow, in breadth-first search, we're like, drawing concentric circles. In depth-first search, we're doing the opposite. We're like, shooting outward until we reach the outer boundary, and then exploring the graph that way. OK. And these are sort of the two extremes in terms of graph search kind of techniques that are typically used under the basic building blocks for algorithms in graph theory. So in order to motivate and think about depth-first search, we're going to define a second problem, which is closely related to shortest path, but not exactly the same. And that's the reachability problem. So here I have the world's simplest directed graph. So the black things are the edges. And the circles are the nodes or the vertices. And I've marked one special node in blue. And his name is the source node. And now the question I want to ask is, what are all of the other nodes in my graph that I can reach by following edges-- directed edges-- starting with the source? So obviously, I can get to the node in the lower right, no problem. And of course once I get there, I can traverse and edge upward to get to that second green vertex. Notice that I was really sneaky and evil, and I drew edges in this graph that might make you think that the red node is reachable. The red one being on the upper left. I'm realizing now that for colorblind people, this isn't a great slide. But of course, because all the edges from the red vertex on the left here point out, I can't actually reach it from the blue source node. So the reachability problem is just asking, which nodes can I reach from a given source? Pretty straightforward, I think. Of course, there are many ways to solve this. Right? In fact, one way we could do it would be to use our previous lecture. We could compute the shortest path distance from the source to all the other nodes. And then what would the length of the shortest path from the source to an unreachable node be? Any thoughts from our audience here? Infinity. Thank you, Professor Demaine. Right. So in addition to this, of course, a totally reasonable question, thinking back to our shortest path lecture, there are sort of two queries we might make. Right? One is just what is the length of the shortest path? The other is like, what is the actual shortest path from the source to a given vertex? We can ask a very similar thing here, which is like, OK. You tell me that the green guy is reachable, but how? Give me a path as evidence or a certificate, if you want to be fancy about it. So in order to do that, just like last time, remember, we defined a particular data structure that was the shortest path tree. We can do something very similar here. In particular, this is like the extent of my PowerPoint skills here. If I have a reachability problem, I can additionally store-- I can decorate every node in my graph with one other piece of information, which is the previous node along some path from my source to that thing. Right? And just like last time, if I want to get an actual path from the source to w, what could I do? I can start with w and then just keep following those parent relationships until I get back to the source. Then if I flip the order of that list of vertices, I get a path from the source to the target that's valid. So this object is called a path tree, just like we talked-- or a parent tree, rather. Just like we talked about in our last lecture, there's no reason why this thing should ever have a cycle in it. It's certainly a tree. Right. So that's the basic reachability problem. And in addition to that, we can compute this object P, which is going to give me sort of information about how any given node was reachable. There's a slight difference between the parent tree that I've defined here and the shortest path tree, which I defined last time, which is, I'm not going to require that the shortest path I get-- oh, man-- the path I get when I backtrack along my tree P is the shortest path, it's just a path because for the reachability problem, I actually don't care. Like, I could have a weird, circuitous, crazy long path. And it still tells me that a node is reachable. Right. So that's our basic set up and our data structure. And now we can introduce a problem to solve reachability. Again, we already have an algorithm for doing that, which is to compute shortest paths. And remember that our shortest path algorithm from previous lecture took linear time and the size of the input. It took v plus e time. Now the question is, can we do a little better? The answer, obviously, is yes, because I just asked it, and I gave you this problem. OK. And here's a technique for doing that, which unsurprisingly, is a recursive algorithm. I'm going to swap my notes for my handwritten notes.",The reachability problem asks which nodes can be reached from a given source node by following directed edges in a graph.,valid,Intermediate,6.006,10 Depth-First Search,IBfWDYSffUU.en-j3PyPqV-e1s_8_mp4
188,How can we use a path tree to solve the reachability problem in a graph?,"is called depth-first search, which doesn't do that, but rather, starts with its first vertex and just starts walking all the way out until it can't do that anymore. And then it kind of backtracks. That's one way to think about it. And so somehow, in breadth-first search, we're like, drawing concentric circles. In depth-first search, we're doing the opposite. We're like, shooting outward until we reach the outer boundary, and then exploring the graph that way. OK. And these are sort of the two extremes in terms of graph search kind of techniques that are typically used under the basic building blocks for algorithms in graph theory. So in order to motivate and think about depth-first search, we're going to define a second problem, which is closely related to shortest path, but not exactly the same. And that's the reachability problem. So here I have the world's simplest directed graph. So the black things are the edges. And the circles are the nodes or the vertices. And I've marked one special node in blue. And his name is the source node. And now the question I want to ask is, what are all of the other nodes in my graph that I can reach by following edges-- directed edges-- starting with the source? So obviously, I can get to the node in the lower right, no problem. And of course once I get there, I can traverse and edge upward to get to that second green vertex. Notice that I was really sneaky and evil, and I drew edges in this graph that might make you think that the red node is reachable. The red one being on the upper left. I'm realizing now that for colorblind people, this isn't a great slide. But of course, because all the edges from the red vertex on the left here point out, I can't actually reach it from the blue source node. So the reachability problem is just asking, which nodes can I reach from a given source? Pretty straightforward, I think. Of course, there are many ways to solve this. Right? In fact, one way we could do it would be to use our previous lecture. We could compute the shortest path distance from the source to all the other nodes. And then what would the length of the shortest path from the source to an unreachable node be? Any thoughts from our audience here? Infinity. Thank you, Professor Demaine. Right. So in addition to this, of course, a totally reasonable question, thinking back to our shortest path lecture, there are sort of two queries we might make. Right? One is just what is the length of the shortest path? The other is like, what is the actual shortest path from the source to a given vertex? We can ask a very similar thing here, which is like, OK. You tell me that the green guy is reachable, but how? Give me a path as evidence or a certificate, if you want to be fancy about it. So in order to do that, just like last time, remember, we defined a particular data structure that was the shortest path tree. We can do something very similar here. In particular, this is like the extent of my PowerPoint skills here. If I have a reachability problem, I can additionally store-- I can decorate every node in my graph with one other piece of information, which is the previous node along some path from my source to that thing. Right? And just like last time, if I want to get an actual path from the source to w, what could I do? I can start with w and then just keep following those parent relationships until I get back to the source. Then if I flip the order of that list of vertices, I get a path from the source to the target that's valid. So this object is called a path tree, just like we talked-- or a parent tree, rather. Just like we talked about in our last lecture, there's no reason why this thing should ever have a cycle in it. It's certainly a tree. Right. So that's the basic reachability problem. And in addition to that, we can compute this object P, which is going to give me sort of information about how any given node was reachable. There's a slight difference between the parent tree that I've defined here and the shortest path tree, which I defined last time, which is, I'm not going to require that the shortest path I get-- oh, man-- the path I get when I backtrack along my tree P is the shortest path, it's just a path because for the reachability problem, I actually don't care. Like, I could have a weird, circuitous, crazy long path. And it still tells me that a node is reachable. Right. So that's our basic set up and our data structure. And now we can introduce a problem to solve reachability. Again, we already have an algorithm for doing that, which is to compute shortest paths. And remember that our shortest path algorithm from previous lecture took linear time and the size of the input. It took v plus e time. Now the question is, can we do a little better? The answer, obviously, is yes, because I just asked it, and I gave you this problem. OK. And here's a technique for doing that, which unsurprisingly, is a recursive algorithm. I'm going to swap my notes for my handwritten notes.","In a path tree, each node stores information about the previous node along some path from the source node. To find a path to a reachable node, you start at the node and follow the parent relationships back to the source, which gives a valid path. The order of the list of vertices is then reversed to show the path from source to the target node.",valid,Intermediate,6.006,10 Depth-First Search,IBfWDYSffUU.en-j3PyPqV-e1s_8_mp4
189,Why might a path from a path tree not be the shortest path?,"is called depth-first search, which doesn't do that, but rather, starts with its first vertex and just starts walking all the way out until it can't do that anymore. And then it kind of backtracks. That's one way to think about it. And so somehow, in breadth-first search, we're like, drawing concentric circles. In depth-first search, we're doing the opposite. We're like, shooting outward until we reach the outer boundary, and then exploring the graph that way. OK. And these are sort of the two extremes in terms of graph search kind of techniques that are typically used under the basic building blocks for algorithms in graph theory. So in order to motivate and think about depth-first search, we're going to define a second problem, which is closely related to shortest path, but not exactly the same. And that's the reachability problem. So here I have the world's simplest directed graph. So the black things are the edges. And the circles are the nodes or the vertices. And I've marked one special node in blue. And his name is the source node. And now the question I want to ask is, what are all of the other nodes in my graph that I can reach by following edges-- directed edges-- starting with the source? So obviously, I can get to the node in the lower right, no problem. And of course once I get there, I can traverse and edge upward to get to that second green vertex. Notice that I was really sneaky and evil, and I drew edges in this graph that might make you think that the red node is reachable. The red one being on the upper left. I'm realizing now that for colorblind people, this isn't a great slide. But of course, because all the edges from the red vertex on the left here point out, I can't actually reach it from the blue source node. So the reachability problem is just asking, which nodes can I reach from a given source? Pretty straightforward, I think. Of course, there are many ways to solve this. Right? In fact, one way we could do it would be to use our previous lecture. We could compute the shortest path distance from the source to all the other nodes. And then what would the length of the shortest path from the source to an unreachable node be? Any thoughts from our audience here? Infinity. Thank you, Professor Demaine. Right. So in addition to this, of course, a totally reasonable question, thinking back to our shortest path lecture, there are sort of two queries we might make. Right? One is just what is the length of the shortest path? The other is like, what is the actual shortest path from the source to a given vertex? We can ask a very similar thing here, which is like, OK. You tell me that the green guy is reachable, but how? Give me a path as evidence or a certificate, if you want to be fancy about it. So in order to do that, just like last time, remember, we defined a particular data structure that was the shortest path tree. We can do something very similar here. In particular, this is like the extent of my PowerPoint skills here. If I have a reachability problem, I can additionally store-- I can decorate every node in my graph with one other piece of information, which is the previous node along some path from my source to that thing. Right? And just like last time, if I want to get an actual path from the source to w, what could I do? I can start with w and then just keep following those parent relationships until I get back to the source. Then if I flip the order of that list of vertices, I get a path from the source to the target that's valid. So this object is called a path tree, just like we talked-- or a parent tree, rather. Just like we talked about in our last lecture, there's no reason why this thing should ever have a cycle in it. It's certainly a tree. Right. So that's the basic reachability problem. And in addition to that, we can compute this object P, which is going to give me sort of information about how any given node was reachable. There's a slight difference between the parent tree that I've defined here and the shortest path tree, which I defined last time, which is, I'm not going to require that the shortest path I get-- oh, man-- the path I get when I backtrack along my tree P is the shortest path, it's just a path because for the reachability problem, I actually don't care. Like, I could have a weird, circuitous, crazy long path. And it still tells me that a node is reachable. Right. So that's our basic set up and our data structure. And now we can introduce a problem to solve reachability. Again, we already have an algorithm for doing that, which is to compute shortest paths. And remember that our shortest path algorithm from previous lecture took linear time and the size of the input. It took v plus e time. Now the question is, can we do a little better? The answer, obviously, is yes, because I just asked it, and I gave you this problem. OK. And here's a technique for doing that, which unsurprisingly, is a recursive algorithm. I'm going to swap my notes for my handwritten notes.","A path from a path tree might not be the shortest path because the reachability problem doesn't require the path to be the shortest. It only needs to show that a node is reachable, so the path can be long and circuitous.",valid,Intermediate,6.006,10 Depth-First Search,IBfWDYSffUU.en-j3PyPqV-e1s_8_mp4
190,What does the function 'prefix_max' return when the input 'i' is 0?,"3 
Lecture 3: Sorting 
Selection Sort 
• Find a largest number in preﬁx A[:i + 1] and swap it to A[i] 
• Recursively sort preﬁx A[:i] 
• Example: [8, 2, 4, 9, 3], [8, 2, 4, 3, 9], [3, 2, 4, 8, 9], [3, 2, 4, 8, 9], [2, 3, 4, 8, 9] 
1 
def selection_sort(A, i = None): 
# T(i) 
2 
’’’Sort A[:i + 1]’’’ 
3 
if i is None: i = len(A) - 1 
# O(1) 
4 
if i > 0: 
# O(1) 
5 
j = prefix_max(A, i) 
# S(i) 
6 
A[i], A[j] = A[j], A[i] 
# O(1) 
7 
selection_sort(A, i - 1) 
# T(i - 1) 
8 
9 
def prefix_max(A, i): 
# S(i) 
10 
’’’Return index of maximum in A[:i + 1]’’’ 
11 
if i > 0: 
# O(1) 
12 
j = prefix_max(A, i - 1) 
# S(i - 1) 
13 
if A[i] < A[j]: 
# O(1) 
14 
return j 
# O(1) 
15 
return i 
# O(1) 
• prefix max analysis: 
– Base case: for i = 0, array has one element, so index of max is i 
– Induction: assume correct for i, maximum is either the maximum of A[:i] or A[i], 
returns correct index in either case. 
– S(1) = Θ(1), S(n) = S(n − 1) + Θ(1) 
∗ Substitution: S(n) = Θ(n), 
cn = Θ(1) + c(n − 1) =⇒ 1 = Θ(1)
P n−1
∗ Recurrence tree: chain of n nodes with Θ(1) work per node, 
i=0 1 = Θ(n) 
• selection sort analysis: 
– Base case: for i = 0, array has one element so is sorted 
– Induction: assume correct for i, last number of a sorted output is a largest number of 
the array, and the algorithm puts one there; then A[:i] is sorted by induction 
– T (1) = Θ(1), T (n) = T (n − 1) + Θ(n) 
∗ Substitution: T (n) = Θ(n2), 
cn2 = Θ(n) + c(n − 1)2 =⇒ c(2n − 1) = Θ(n)
P n−1
∗ Recurrence tree: chain of n nodes with Θ(i) work per node, 
i=0 i = Θ(n2) 
","For i = 0, the array has one element, so the index of max is i.",valid,Intermediate,6.006,Lecture 3 - Sorting,6d1ae5278d02bbecb5c4428928b24194_MIT6_006S20_lec3_3_pdf
191,What is the running time of the direct access array sort if the range of keys \( u \) is \( \Theta(n) \)?,"2 
Lecture 5: Linear Sorting 
Comparison Sort Lower Bound 
• Comparison model implies that algorithm decision tree is binary (constant branching factor) 
• Requires # leaves L ≥ # possible outputs 
• Tree height lower bounded by Ω(log L), so worst-case running time is Ω(log L) 
• To sort array of n elements, # outputs is n! permutations 
• Thus height lower bounded by log(n!) ≥ log((n/2)n/2) = Ω(n log n) 
• So merge sort is optimal in comparison model 
• Can we exploit a direct access array to sort faster? 
Direct Access Array Sort 
• Example: [5, 2, 7, 0, 4] 
• Suppose all keys are unique non-negative integers in range {0, . . . , u − 1}, so n ≤ u 
• Insert each item into a direct access array with size u in Θ(n) 
• Return items in order they appear in direct access array in Θ(u) 
• Running time is Θ(u), which is Θ(n) if u = Θ(n). Yay! 
1 
def direct_access_sort(A): 
2 
""Sort A assuming items have distinct non-negative keys"" 
3 
u = 1 + max([x.key for x in A]) 
# O(n) find maximum key 
4 
D = [None] * u 
# O(u) direct access array 
5 
for x in A: 
# O(n) insert items 
6 
D[x.key] = x 
7 
i = 0 
8 
for key in range(u): 
# O(u) read out items in order 
9 
if D[key] is not None: 
10 
A[i] = D[key] 
11 
i += 1 
• What if keys are in larger range, like u = Ω(n2) < n2? 
• Idea! Represent each key k by tuple (a, b) where k = an + b and 0 ≤ b < n 
• Speciﬁcally a = bk/nc < n and b = (k mod n) (just a 2-digit base-n number!) 
• This is a built-in Python operation (a, b) = divmod(k, n) 
• Example: [17, 3, 24, 22, 12] ⇒ [(3,2), (0,3), (4,4), (4,2), (2,2)] ⇒ [32, 03, 44, 42, 22](n=5) 
• How can we sort tuples? 
",The running time is \( \Theta(n) \).,valid,Basic,6.006,Lecture 5 - Linear Sorting,78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5_2_pdf
192,What is the lower bound for the height of a decision tree required to sort an array of \( n \) elements using comparison sorts?,"2 
Lecture 5: Linear Sorting 
Comparison Sort Lower Bound 
• Comparison model implies that algorithm decision tree is binary (constant branching factor) 
• Requires # leaves L ≥ # possible outputs 
• Tree height lower bounded by Ω(log L), so worst-case running time is Ω(log L) 
• To sort array of n elements, # outputs is n! permutations 
• Thus height lower bounded by log(n!) ≥ log((n/2)n/2) = Ω(n log n) 
• So merge sort is optimal in comparison model 
• Can we exploit a direct access array to sort faster? 
Direct Access Array Sort 
• Example: [5, 2, 7, 0, 4] 
• Suppose all keys are unique non-negative integers in range {0, . . . , u − 1}, so n ≤ u 
• Insert each item into a direct access array with size u in Θ(n) 
• Return items in order they appear in direct access array in Θ(u) 
• Running time is Θ(u), which is Θ(n) if u = Θ(n). Yay! 
1 
def direct_access_sort(A): 
2 
""Sort A assuming items have distinct non-negative keys"" 
3 
u = 1 + max([x.key for x in A]) 
# O(n) find maximum key 
4 
D = [None] * u 
# O(u) direct access array 
5 
for x in A: 
# O(n) insert items 
6 
D[x.key] = x 
7 
i = 0 
8 
for key in range(u): 
# O(u) read out items in order 
9 
if D[key] is not None: 
10 
A[i] = D[key] 
11 
i += 1 
• What if keys are in larger range, like u = Ω(n2) < n2? 
• Idea! Represent each key k by tuple (a, b) where k = an + b and 0 ≤ b < n 
• Speciﬁcally a = bk/nc < n and b = (k mod n) (just a 2-digit base-n number!) 
• This is a built-in Python operation (a, b) = divmod(k, n) 
• Example: [17, 3, 24, 22, 12] ⇒ [(3,2), (0,3), (4,4), (4,2), (2,2)] ⇒ [32, 03, 44, 42, 22](n=5) 
• How can we sort tuples? 
",The height is lower bounded by \( \Omega(n \log n) \).,valid,Basic,6.006,Lecture 5 - Linear Sorting,78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5_2_pdf
193,"In the direct access sort algorithm, why is the direct access array initialized with size \( u \)?","2 
Lecture 5: Linear Sorting 
Comparison Sort Lower Bound 
• Comparison model implies that algorithm decision tree is binary (constant branching factor) 
• Requires # leaves L ≥ # possible outputs 
• Tree height lower bounded by Ω(log L), so worst-case running time is Ω(log L) 
• To sort array of n elements, # outputs is n! permutations 
• Thus height lower bounded by log(n!) ≥ log((n/2)n/2) = Ω(n log n) 
• So merge sort is optimal in comparison model 
• Can we exploit a direct access array to sort faster? 
Direct Access Array Sort 
• Example: [5, 2, 7, 0, 4] 
• Suppose all keys are unique non-negative integers in range {0, . . . , u − 1}, so n ≤ u 
• Insert each item into a direct access array with size u in Θ(n) 
• Return items in order they appear in direct access array in Θ(u) 
• Running time is Θ(u), which is Θ(n) if u = Θ(n). Yay! 
1 
def direct_access_sort(A): 
2 
""Sort A assuming items have distinct non-negative keys"" 
3 
u = 1 + max([x.key for x in A]) 
# O(n) find maximum key 
4 
D = [None] * u 
# O(u) direct access array 
5 
for x in A: 
# O(n) insert items 
6 
D[x.key] = x 
7 
i = 0 
8 
for key in range(u): 
# O(u) read out items in order 
9 
if D[key] is not None: 
10 
A[i] = D[key] 
11 
i += 1 
• What if keys are in larger range, like u = Ω(n2) < n2? 
• Idea! Represent each key k by tuple (a, b) where k = an + b and 0 ≤ b < n 
• Speciﬁcally a = bk/nc < n and b = (k mod n) (just a 2-digit base-n number!) 
• This is a built-in Python operation (a, b) = divmod(k, n) 
• Example: [17, 3, 24, 22, 12] ⇒ [(3,2), (0,3), (4,4), (4,2), (2,2)] ⇒ [32, 03, 44, 42, 22](n=5) 
• How can we sort tuples? 
",Because \( u \) is the range of unique non-negative keys such that \( n \leq u \).,valid,Basic,6.006,Lecture 5 - Linear Sorting,78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5_2_pdf
194,How can keys in a larger range \( u = \Omega(n^2) \) be represented for the direct access sort?,"2 
Lecture 5: Linear Sorting 
Comparison Sort Lower Bound 
• Comparison model implies that algorithm decision tree is binary (constant branching factor) 
• Requires # leaves L ≥ # possible outputs 
• Tree height lower bounded by Ω(log L), so worst-case running time is Ω(log L) 
• To sort array of n elements, # outputs is n! permutations 
• Thus height lower bounded by log(n!) ≥ log((n/2)n/2) = Ω(n log n) 
• So merge sort is optimal in comparison model 
• Can we exploit a direct access array to sort faster? 
Direct Access Array Sort 
• Example: [5, 2, 7, 0, 4] 
• Suppose all keys are unique non-negative integers in range {0, . . . , u − 1}, so n ≤ u 
• Insert each item into a direct access array with size u in Θ(n) 
• Return items in order they appear in direct access array in Θ(u) 
• Running time is Θ(u), which is Θ(n) if u = Θ(n). Yay! 
1 
def direct_access_sort(A): 
2 
""Sort A assuming items have distinct non-negative keys"" 
3 
u = 1 + max([x.key for x in A]) 
# O(n) find maximum key 
4 
D = [None] * u 
# O(u) direct access array 
5 
for x in A: 
# O(n) insert items 
6 
D[x.key] = x 
7 
i = 0 
8 
for key in range(u): 
# O(u) read out items in order 
9 
if D[key] is not None: 
10 
A[i] = D[key] 
11 
i += 1 
• What if keys are in larger range, like u = Ω(n2) < n2? 
• Idea! Represent each key k by tuple (a, b) where k = an + b and 0 ≤ b < n 
• Speciﬁcally a = bk/nc < n and b = (k mod n) (just a 2-digit base-n number!) 
• This is a built-in Python operation (a, b) = divmod(k, n) 
• Example: [17, 3, 24, 22, 12] ⇒ [(3,2), (0,3), (4,4), (4,2), (2,2)] ⇒ [32, 03, 44, 42, 22](n=5) 
• How can we sort tuples? 
","Keys can be represented by tuples \((a, b)\) where \( a = \lfloor k/n \rfloor < n \) and \( b = (k \mod n) \).",valid,Basic,6.006,Lecture 5 - Linear Sorting,78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5_2_pdf
195,What does the comparison model imply about the decision tree of an algorithm?,"2 
Lecture 5: Linear Sorting 
Comparison Sort Lower Bound 
• Comparison model implies that algorithm decision tree is binary (constant branching factor) 
• Requires # leaves L ≥ # possible outputs 
• Tree height lower bounded by Ω(log L), so worst-case running time is Ω(log L) 
• To sort array of n elements, # outputs is n! permutations 
• Thus height lower bounded by log(n!) ≥ log((n/2)n/2) = Ω(n log n) 
• So merge sort is optimal in comparison model 
• Can we exploit a direct access array to sort faster? 
Direct Access Array Sort 
• Example: [5, 2, 7, 0, 4] 
• Suppose all keys are unique non-negative integers in range {0, . . . , u − 1}, so n ≤ u 
• Insert each item into a direct access array with size u in Θ(n) 
• Return items in order they appear in direct access array in Θ(u) 
• Running time is Θ(u), which is Θ(n) if u = Θ(n). Yay! 
1 
def direct_access_sort(A): 
2 
""Sort A assuming items have distinct non-negative keys"" 
3 
u = 1 + max([x.key for x in A]) 
# O(n) find maximum key 
4 
D = [None] * u 
# O(u) direct access array 
5 
for x in A: 
# O(n) insert items 
6 
D[x.key] = x 
7 
i = 0 
8 
for key in range(u): 
# O(u) read out items in order 
9 
if D[key] is not None: 
10 
A[i] = D[key] 
11 
i += 1 
• What if keys are in larger range, like u = Ω(n2) < n2? 
• Idea! Represent each key k by tuple (a, b) where k = an + b and 0 ≤ b < n 
• Speciﬁcally a = bk/nc < n and b = (k mod n) (just a 2-digit base-n number!) 
• This is a built-in Python operation (a, b) = divmod(k, n) 
• Example: [17, 3, 24, 22, 12] ⇒ [(3,2), (0,3), (4,4), (4,2), (2,2)] ⇒ [32, 03, 44, 42, 22](n=5) 
• How can we sort tuples? 
",The comparison model implies that the algorithm decision tree is binary (constant branching factor).,valid,Basic,6.006,Lecture 5 - Linear Sorting,78a3c3444de1ff837f81e52991c24a86_MIT6_006S20_lec5_2_pdf
196,What is the base case when dealing with an empty suffix in dynamic programming problems?,that we only have to sum over sub problems because we only compute each sub problem once so without memoization this would take exponential time just like fibonacci with memorization magic i just think this is beautiful so even though it's one of our simpler dps i think it's an impressive one okay uh topological order well let's look at these function calls so here we have to be a little bit careful when we call x recursively we always increment i but sometimes we don't decrement t sometimes t doesn't go down so if i wrote decreasing t here that would be bad because sometimes i call with the same value of t and i don't want to get into i want to ensure that this has already been computed when i try to compute this so i is the right thing and we should say decreasing i it doesn't actually matter how we order with respect to t just any order that is decreasing i will be good because these function calls always increase i okay we need a base case base cases let's see the natural given this aspect i think the natural thing is to have a base case when my suffix is empty which is when i equals n so this is x of uh n comma t for any little t because we don't have a lot of control of how t is changing but this is easy so this is saying if i give you no numbers what sums can you represent the only sum i can represent is 0. okay so if t equals 0 then the answer is yes and otherwise the answer is no so that's my base case and that's enough and we needed this base case because if we wrote x of n comma t this would try to call x of n plus 1 which doesn't make sense but x of n call in as a natural suffix which we only allowed i to go up to n and that's the empty suffix so this is enough we need the original problem uh which is the entire string from zero onwards and capital t for little t that's our target sum and then the running time as i said there are n times t sub problems theta and the amount of work we spend for each one that isn't recursion is constant we just do a couple subtractions additions do an or and recursive calls so constant time,"The base case is when the suffix is empty, which occurs when i equals n. At this point, for any small t, if t is 0, the answer is yes (indicating you can represent the sum). Otherwise, the answer is no.",valid,Basic,6.006,18 Dynamic Programming Part 4 Rods Subset Sum Pseudopolynomial,i9OAOk0CUQE.en_6_mp4
197,What is the significance of a problem being classified as NP-complete?," 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 20: Course Review 
Lecture 20: Course Review 
6.006: Introduction to Algorithms 
• Goals: 
1. Solve hard computational problems (with non-constant-sized inputs) 
2. Argue an algorithm is correct (Induction, Recursion) 
3. Argue an algorithm is “good” (Asymptotics, Model of Computation) 
– (effectively communicate all three above, to human or computer) 
• Do there always exist “good” algorithms? 
– Most problems are not solvable efﬁciently, but many we think of are! 
– Polynomial means polynomial in size of input 
– Pseudopolynomial means polynomial in size of input AND size of numbers in input 
– NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates 
– NP-hard: set of problems that can be used to solve any problem in NP in poly-time 
– NP-complete: intersection of NP-hard and NP 
How to solve an algorithms problem? 
• Reduce to a problem you know how to solve 
– Search/Sort (Q1) 
∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures 
∗ Sort: Comparison Model, Stability, In-place 
– Graphs (Q2) 
∗ Reachability, Connected Components, Cycle Detection, Topological Sort 
∗ Single-Source / All-Pairs Shortest Paths 
• Design a new recursive algorithm 
– Brute Force 
– Divide & Conquer 
– Dynamic Programming (Q3) 
– Greedy/Incremental 
","A problem is NP-complete if it is both in NP (nondeterministic polynomial time, meaning it has polynomially checkable certificates) and NP-hard (meaning it can be used to solve any problem in NP in polynomial time).",valid,Intermediate,6.006,Lecture 20 - Course Review,aa4f264093faf990054cc4820553bb46_MIT6_006S20_lec20_1_pdf
198,"What distinguishes a local property from a global property in the context of binary trees, and why is maintaining local properties preferable for subtree computations?","ERIK DEMAINE: OK, what does it mean for a property to be local to a subtree versus global? The best answer is this definition. But that's maybe not the most intuitive definition. This is what I mean. Something that can be computed just knowing information about your left and right children, that is the meaning of such a property. And those are the only things you're allowed to maintain. Because those are the only things that are easy to update by walking up this path. And the contrast is that global property like index, it's global, in particular, because I can do one change, add one node, and all of the node's properties change. So that's an extreme example of global. We want this very particular notion of local, because that's what we can actually afford to recompute. Hopefully that clarifies. Yeah? AUDIENCE: Doesn't size not work with that [INAUDIBLE]?? ERIK DEMAINE: You're right that if we added-- oh, no. OK, let's think about that. If we added a new parent to the tree-- this is not something that we've ever done. But even if we did that, which subtrees change? Only this one. This node, it's a totally new subtree. But the subtree of this node is completely unchanged. Because subtrees are always downward looking, if I added a new root, I didn't change any subtrees except for one.","Local properties are those that can be computed using only the information from a node's left and right children, making them easier to update as they do not rely on the entire structure of the tree. A global property, on the other hand, would require recalculations that consider the entire tree, which is less efficient, especially when a single addition can affect many nodes. Maintaining local properties is preferable because they are computationally affordable to update when traversing the tree.",valid,Advanced,6.006,7 Binary Trees Part 2 AVL,U1JYwHcFfso.en-j3PyPqV-e1s_13_mp4
199,How do different finger counts on a hand affect the five-finger algorithm for playing piano notes?,"Here, we're given a sequence of notes t 0, t 1-- t for note-- up to t n minus 1. These are single notes. And all of the single notes-- all of the single notes, right? And we have fingers on our hands. This is not like two-finger algorithm. This is the five-finger algorithm. So in general, I'm going to assume an arbitrary anthropomorphic object. So this is 5 for humans-- most humans. Some humans-- I think the maximum on each hand is 7. Could be smaller. Maybe you've had an accident.","The five-finger algorithm assumes that an anthropomorphic object, typically a human, has five fingers on each hand. This algorithm is adapted to such a configuration. However, some humans may have more or fewer fingers due to genetic variations or accidents. A maximum of seven fingers per hand is mentioned, and this could modify the algorithm to accommodate the additional dexterity or limitations, affecting how notes are played.",invalid,Advanced,6.006,17 Dynamic Programming Part 3 APSP Parens Piano,TDo3r5M1LNo.en-j3PyPqV-e1s_12_mp4
200,What is the difference between an interface and a data structure?,"Fairly simple data structures today. This is the beginning of several data structures we'll be talking about in the next few lectures. But before we actually start with one, let me tell you/remind remind you of the difference between an interface-- which you might call an API if you're a programmer, or an ADT if you're an ancient algorithms person like me-- versus a data structure. These are useful distinctions. The idea is that an interface says what you want to do. A data structure says how you do it. So you might call this a specification. And in the context of data structures, we're trying to store some data. So the interface will specify what data you can store, whereas the data structure will give you an actual representation and tell you how to store it. This is pretty boring. Just storing data is really easy. You just throw it in a file or something. What makes it interesting is having operations on that data. In the interface, you specify what the operations do, what operations are supported, and in some sense, what they mean. And the data structure actually gives you algorithms-- this is where the algorithms come in-- for how to support those operations. All right. In this class, we're going to focus on two main interfaces and various special of them. The idea is to separate what you want to do versus how to do it. Because-- you can think of this as the problem statement. Yesterday-- or, last class, Jason talked about problems and defined what a problem was versus algorithmic solutions to the problem. And this is the analogous notion for data structures, where we want to maintain some data according to various operations. The same problem can be solved by many different data structures. And we're going to see that. And different data structures are going to have different advantages. They might support some operations faster than others. And depending on what you actually use those data structures for, you choose the right data structure. But you can maintain the same interface. We're going to think about two data structures. One is called a set and one is called a sequence. These are highly loaded terms. Set means something to a mathematician. It means something else to a Python programmer. Sequence, similarly. I guess there's not a Python sequence data type built in. The idea is, we want to store n things. The things will be fairly arbitrary. Think of them as integers or strings. And on the one hand, we care about their values. And maybe we want to maintain them in sorted order and be able to search for a given value, which we'll call a key. And on the other hand, we care about representing a particular sequence that we care about. Maybe we want to represent the numbers 5, 2, 9, 7 in that order and store that. In Python, you could store that in a list, for example. And it will keep track of that order. And this is the first item, the second item, the last item. Today, we're going to be focusing on this sequence data structure, although at the end, I'll mention the interface for sets. But we're going to be actually solving sequences today. And in the next several lectures, we'll be bouncing back and forth between these. They're closely related. Pretty abstract at the moment. On the other hand, we're going to have two main-- let's call them data structure tools or approaches. One is arrays and the other is pointers-- pointer-based or linked data structures. You may have seen these. They're used a lot in programming, of course. But we're going to see both of these today. I'll come back to this sort of highlight in a moment. Let's jump into the sequence interface, which I conveniently have part of here. There's a few different levels of sequences that we might care about. I'm going to start with the static sequence interface. This is where the number of items doesn't change, though the actual items might. Here, we have n items. I'm going to label them x 0 to x n minus 1, as in Python. So the number of items is n. And the operations I want to support are build, length, iteration, get, and set. So what do these do? Build is how you get started. To build a data structure in this interface, you call build of x. Exactly how you specify x isn't too important, but the idea is, I give you some items in some order. In Python, this would be an iterable. I'm going to want to also know its length. And I want to make a new data structure of size and a new static sequence of size n that has those items in that order. So that's how you build one of these. Because somehow, we have to specify n to this data structure, because n is not going to be allowed to change. I'm going to give you a length method. Methods are the object-oriented way of thinking of operations that your interface supports. Length will just return this fixed value n. Iter sequence. This is the sense in which we want to maintain the order. I want to be able to output x 0 through x n minus 1 in the sequence order, in that specified order that they were built in or that it was changed to. This is going to iterate through all of the items. So it's going to take at least linear time to output that. But more interesting is, we can dynamically access anywhere in the middle of the sequence. We can get the ith item, x i, given the value i, and we can change x i to a given new item. OK. So that's called get_at and set_at. Pretty straightforward. This should remind you very closely of something-- a data structure. So this is an interface. This is something I might want to solve. But what is the obvious data structure that solves this problem? Yeah? AUDIENCE: A list. ERIK DEMAINE: A list. In Python, it's called a list. I prefer to call it an array, but to each their own. We're going to use ""list.""","An interface specifies what you want to do, outlining operations and data types, while a data structure provides an actual representation and algorithms for how to perform those operations.",valid,Intermediate,6.006,2 Data Structures and Dynamic Arrays,CHhwJjR0mZA.en-j3PyPqV-e1s_2_mp4
201,Why are subsequences not preferred for dynamic programming problems when finding subproblems?,"There are many variations of this game. All of them-- basically any variation-- not literally every variation, but many, many variations of this problem can all be solved quickly with dynamic programming. But let's solve this particular one. OK. So now we're really in algorithmic design mode. We need to think about SRTBOT. And in particular, we need to think about what would the sub problems be here? And at this point, we don't have a lot of help. So I should probably give you some tools. If I want to solve a problem like this, the input is a sequence of numbers. It's a sequenced data structure. Maybe it's an array of numbers, which is this v array. And let's see. A general tool for sub-problem design which will cover most of the problems-- maybe all of the problems that we see in this class for dynamic programming. Here's a trick. If your input is a sequence, here are some good sub-problems to consider. We could do all prefixes. So let's call the sequence x. So we could do x prefix means up to a given i for all i. We could do all the suffixes, x from i onward for all i. Or we could do substrings, which are the consecutive items from i to j. I don't write subsequence here. Subsequence means you can omit items in the middle. So substring you have to start in some position and do all the things up to j. So these are nice, easy to express in Python notation. And these are great, because they're polynomial. If I have n things-- if the length of my sequence, x, is n, then there are n prefixes-- technically n plus 1. So let's do theta n prefixes. There are theta n suffixes. And there are theta n squared substrings because there's n-- roughly n choices for i and j separately. Sorry? Sub-sequences. Good. Right. I didn't write sub-sequences, because in fact, there are exponentially many sub sequences. It's 2 to the n. For every item, I could choose it or not. So I don't want to parameterize-- I don't want my sub problems to be sub sequences because that's guaranteed-- well, then you're guaranteed to get an exponential number of sub-problems, which is bad. We'd like to balance the numbers of sub-problems by polynomial. So these are three natural ways to get polynomial bounds. Now, prefixes and suffixes are obviously better because there's fewer of them, linear instead of quadratic. And usually almost every problem you encounter, prefixes and suffixes are equally good. It doesn't really matter which one you choose. So maybe you'd like to think of-- well, we'll get to--","Subsequences are not preferred because there are exponentially many subsequences, specifically 2 to the n, as for every item you can choose it or not. This results in an exponential number of sub-problems, which is undesirable. We prefer polynomial bounds on the number of sub-problems, making prefixes and suffixes better options.",valid,Intermediate,6.006,15 Dynamic Programming Part 1 SRTBOT Fib DAGs Bowling,r4-cftqTcdI.en-j3PyPqV-e1s_11_mp4
202,What is a trade-off that must be considered when using subproblem constraint/expansion in dynamic programming?,"8 
Lecture 16: Dyn. Prog. Subproblems 
Subproblem Constraints and Expansion 
• We’ve now seen two examples of constraining or expanding subproblems 
• If you ﬁnd yourself lacking information to check the desired conditions of the problem, or 
lack the natural subproblem to recurse on, try subproblem constraint/expansion! 
• More subproblems and constraints give the relation more to work with, so can make DP 
more feasible 
• Usually a trade-off between number of subproblems and branching/complexity of relation 
• More examples next lecture 
","There is usually a trade-off between the number of subproblems and the branching/complexity of the relation. Using more subproblems and constraints gives the relation more to work with, which can make dynamic programming more feasible.",valid,Advanced,6.006,"Lecture 16 - Dynamic Programming, Part 2 - LCS, LIS, Coins",28461a74f81101874a13d9679a40584d_MIT6_006S20_lec16_8_pdf
203,How can the single-source shortest path be calculated in a graph with cycles and negative weights?,"[SQUEAKING] [RUSTLING] [CLICKING] JASON KU: OK, let's get started. Welcome to the 12th lecture of 6.006. This is our second lecture talking about weighted graphs, and in particular, weighted shortest paths, algorithms. Last time we talked about weighted graphs. This is a kind of a generalization of what we mean by distance in an unweighted graph instead of each edge having a weight of 1, essentially. We generalize that to be any integer. And last time, we showed how to solve shortest single-source shortest paths in a graph that doesn't have cycles even if it has 0 or negative weights in linear time using an algorithm called DAG relaxation. We also showed in that lecture how in linear time, if we are given the shortest path weights to all the things reachable in finite-- or with shortest path distance that's finite, we can construct a shortest paths tree from those weights in linear time. So this is motivating why we're not really going to talk about parent pointers for the next couple of lectures. We're just going to concentrate on the shortest path weights. And so today, we're going to be talking about our most general algorithm we'll be showing for solving single source shortest paths, in particular in graphs that could contain cycles and could have negative weights.","To solve the single-source shortest paths problem in a graph with cycles and negative weights, the Bellman-Ford algorithm is applied. This algorithm is a general approach that handles graphs with cycles and negative weights by efficiently calculating the shortest path weights from a source to all reachable vertices.",valid,Advanced,6.006,12 Bellman-Ford,f9cVS_URPc0.en-j3PyPqV-e1s_1_mp4
204,What is the time complexity of the procedure that involves finding all vertices reachable from witnesses and setting certain vertices to minus infinity?,"And then finding all the vertices reachable from those witnesses, we set all of the infinite ones to be minus infinity as desired. OK, so what's the running time of this thing? Well, we had to construct this graph, so we had to take that time. We ran DAG relaxation, that takes the same amount of time. For every vertex, we did order V at work. And then for each witness, how many could there be? And most, V. Checking the reachability of each vertex, that can be done in how long? Order E time. Because we don't need to consider the things that aren't connected to S-- or aren't connected to the witness. So this thing takes order V times E work. So we're upper-bounded by this time it took to construct the original graph and by the claim we had before, that takes V times E time. OK. So that's Bellman-Ford. I'm just going to leave you with two nuggets. First, the shortest path, if for any witness-- let's say we have a witness here. Do I have any witnesses here? I didn't fill in all these. But is there a vertex on this cycle that goes through who has the shortest path? That goes through four vertices that's smaller than any other. OK. I can go from a to c to b to d to b to c. And you can work out this algorithm-- I have it in the notes that you can take a look at. This will actually have a shorter path for vertex-- sorry. It'll have a shorter path for vertex b. a to b to c to d to b. Thank you. That's a path of length 4, of four edges. That has shorter path than any path that has fewer edges. In particular, there's only one other path to b using fewer than four-- there's two other paths. One path of length-- that has one edge, that has weight minus 5, and one path-- this path that has weight 9 minus 1 is 8. Whereas this path, minus 5, minus 4, 3, minus 1 has minus 10 plus 3 is minus 7, which is shorter than minus 5. So b and d is a witness. And if we actually take a look at that path through this graph, going from a to b to c to d back to b we see that there's a negative weight cycle in this graph. b to c to d to b. And indeed, that's always the case for our witnesses. You can see a proof of that in the notes, and you can see in recitation a little space optimization to make us not have to construct this entire graph on the fly, but actually only use order V space while they're going. OK. So that's Bellman-Ford. Sorry for running a little late.","The procedure takes order V times E work, which is upper-bounded by the time it took to construct the original graph, V times E.",valid,Basic,6.006,12 Bellman-Ford,f9cVS_URPc0.en-j3PyPqV-e1s_11_mp4
205,What is the structure of a binary tree node in terms of pointers?," 
 
 
 
 
Introduction to Algorithms: 6.006 
Massachusetts Institute of Technology 
Instructors: Erik Demaine, Jason Ku, and Justin Solomon 
Lecture 6: Binary Trees I 
Lecture 6: Binary Trees I 
Previously and New Goal 
Sequence 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
build(X) 
get at(i) 
set at(i,x) 
insert first(x) 
delete first() 
insert last(x) 
delete last() 
insert at(i, x) 
delete at(i) 
Array 
n 
1 
n 
n 
n 
Linked List 
n 
n 
1 
n 
n 
Dynamic Array 
n 
1 
n 
1(a) 
n 
Goal 
n 
log n 
log n 
log n 
log n 
Set 
Data Structure 
Operations O(·) 
Container 
Static 
Dynamic 
Order 
build(X) 
find(k) 
insert(x) 
delete(k) 
find min() 
find max() 
find prev(k) 
find next(k) 
Array 
n 
n 
n 
n 
n 
Sorted Array 
n log n 
log n 
n 
1 
log n 
Direct Access Array 
u 
1 
1 
u 
u 
Hash Table 
n(e) 
1(e) 
1(a)(e) 
n 
n 
Goal 
n log n 
log n 
log n 
log n 
log n 
How? Binary Trees! 
• Pointer-based data structures (like Linked List) can achieve worst-case performance 
• Binary tree is pointer-based data structure with three pointers per node 
• Node representation: node.{item, parent, left, right} 
• Example: 
1 
2 
3 
4 
5 
________<A>_____ 
__<B>_____ 
<C> 
__<D> 
<E> 
<F> 
node 
| 
item 
| 
parent | 
left 
| 
right 
| 
<A> | 
A 
| 
-
| 
<B> | 
<C> | 
<B> 
B 
<A> 
<C> 
<D> 
| 
| 
| 
| 
| 
<C> | 
C 
| 
<A> | 
-
| 
-
| 
<D> | 
D 
| 
<B> | 
<F> | 
-
| 
<E> | 
E 
| 
<B> | 
-
| 
-
| 
<F> 
F 
<D> 
-
-
| 
| 
| 
| 
| 
","A binary tree node has three pointers per node: parent, left, and right.",valid,Intermediate,6.006,"Lecture 6 - Binary Trees, Part 1",376714cc85c6c784d90eec9c575ec027_MIT6_006S20_lec6_1_pdf
206,How is a binary search tree's property utilized when deleting a node with a left child?,,"If there is a left child, the predecessor of the node is located within the left subtree, which guarantees that it is lower in the tree. The node's content is swapped with its predecessor's, and then the predecessor is recursively deleted while maintaining the tree order.",valid,Advanced,6.006,6 Binary Trees Part 1,76dhtgZt38A.uk-XlqDmAj_UsM_12_mp4
207,What does the acronym ASP stand for in the context of algorithms?,"MIT OpenCourseWare 
https://ocw.mit.edu 
6.006 Introduction to Algorithms 
Spring 2020 
For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms 
",ASP stands for All-Pairs Shortest Path.,invalid,Basic,6.006,Lecture 14 - ASP & Johnson’s Algorithm,7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14_5_pdf
208,What is the main benefit of using binary heaps for sorting as discussed?,"They take linear time for some of the operations. So the sorting algorithms are not efficient. But they're ones we've seen before, so it's neat to see how they fit in here. They had the-- selection sort and insertion sort had the advantage that they were in place. You just needed a constant number of pointers or indices beyond the array itself. So they're very space efficient. So that was a plus for them. But they take n squared time, so you should never use them, except for n, at most, 100 or something. AVL tree sort is great and then it gets n log n time, probably more complicated than merge sort and you could stick to merge sort. But neither merge sort nor set AVL tree sort are in place. And so the goal of today is to get the best of all those worlds in sorting to get n log n comparisons, which is optimal in the comparison model, but get it to be in place. And that's what we're going to get with binary heaps. We're going to design a data structure that happens to build a little bit faster-- as I mentioned, linear time building. So it's not representing a sorted order in the same way that AVL trees are. But it will be kind of tree-based. It will also be array-based. We're going to get logarithmic time for insert and delete_max. It happens to be amortized, because we use arrays. But the key thing is that it's an in-place data structure. It only consists of an array of the items. And so, when we plug it into our sorting algorithm-- priority queue sort or generic sorting algorithm-- not only do we get n log n performance, but we also get an in-place sorting algorithm. This will be our first and only-- to this class-- n log n in-place sorting algorithm. Cool. That's the goal.",The main benefit of using binary heaps for sorting is achieving an n log n in-place sorting algorithm. It provides optimal performance in the comparison model while being space-efficient as it only consists of an array of items.,valid,Intermediate,6.006,8 Binary Heaps,Xnpo1atN-Iw.en-j3PyPqV-e1s_5_mp4
209,What was the reason Bellman named the approach 'dynamic programming'?,"Why did Bellman call dynamic programming dynamic programming? Mostly because it sounded cool, and he was trying to impress government agencies giving him grants. I mean, how can you argue with something as cool-sounding as dynamic programming? But there is some logic to it. Programming is a reference to an old form of this word, which means optimization. And generally, we're trying to optimize things. And instead of optimizing according to some static kind of approach or program, we're doing it dynamically. This is a reference to the local brute force we're doing to optimize at each stage. You can't tell, at the top, what you're going to do in the middle. And so it's kind of-- each subproblem is behaving differently. And so, in that sense, dynamic. And it sounds cool. All right. Then we'll go to all-pairs shortest paths. We'll see a new algorithm for that that's not asymptotically any better, but it's nice and simple, and another way to-- a cool way to see subproblem expansion. And then we'll look at a couple of sort of practical problems-- parenthesizing arithmetic expressions and a real-world problem, piano and guitar fingering, so assigning a fingering how to play a piece. And we're going to do that with our SRTBOT framework. Quick recollection of what that is. We define subproblems. And we saw how to do that for sequences. We try either prefixes, suffixes, or substrings. We prefer prefixes and suffixes because there's fewer of them. If there's more than one sequence, we take the product of those spaces. And then the idea we're going to stress today is, we can always add subproblems","Bellman called it dynamic programming mostly because it sounded cool, and he was trying to impress government agencies giving him grants. 'Programming' is a reference to an old form of the word, meaning optimization, where the goal is to optimize things dynamically instead of using a static approach. The term 'dynamic' refers to the local brute force optimization done at each stage, with each subproblem behaving differently.",valid,Basic,6.006,17 Dynamic Programming Part 3 APSP Parens Piano,TDo3r5M1LNo.en-j3PyPqV-e1s_2_mp4
210,What is the definition of a negative-weight cycle in a graph?,"2 
Restrictions 
SSSP Algorithm 
Graph 
Weights 
Name 
Running Time O(·) Lecture 
General Unweighted 
BFS 
|V | + |E| L09 
L11 (Today!) 
L12 
L13 
DAG 
Any 
DAG Relaxation 
|V | + |E|
General Any 
Bellman-Ford 
Dijkstra 
|V | · |E|
General Non-negative 
Lecture 11: Weighted Shortest Paths 
Weighted Paths 
• The weight w(π) of a path π in a weighted graph is the sum of weights of edges in the path 
• The (weighted) shortest path from s ∈ V to t ∈ V is path of minimum weight from s to t 
• δ(s, t) = inf{w(π) | path π from s to t} is the shortest-path weight from s to t 
• (Often use “distance” for shortest-path weight in weighted graphs, not number of edges) 
• As with unweighted graphs: 
– δ(s, t) = ∞ if no path from s to t 
– Subpaths of shortest paths are shortest paths (or else could splice in a shorter path) 
• Why inﬁmum not minimum? Possible that no ﬁnite-length minimum-weight path exists 
• When? Can occur if there is a negative-weight cycle in the graph, Ex: (b, f, g, c, b) in G1 
• A negative-weight cycle is a path π starting and ending at same vertex with w(π) < 0 
• δ(s, t) = −∞ if there is a path from s to t through a vertex on a negative-weight cycle 
• If this occurs, don’t want a shortest path, but may want the negative-weight cycle 
Weighted Shortest Paths Algorithms 
• Next four lectures: algorithms to ﬁnd shortest-path weights in weighted graphs 
• (No parent pointers: can reconstruct shortest paths tree in linear time after. Next page!) 
• Already know one algorithm: Breadth-First Search! Runs in O(|V | + |E|) time when, e.g.: 
– graph has positive weights, and all weights are the same 
– graph has positive weights, and sum of all weights at most O(|V | + |E|) 
• For general weighted graphs, we don’t know how to solve SSSP in O(|V | + |E|) time 
• But if your graph is a Directed Acyclic Graph you can! 
|V | log |V | + |E| 
",A negative-weight cycle is a path starting and ending at the same vertex with the sum of the weights of its edges being less than zero.,valid,Basic,6.006,Lecture 11 - Weighted Shortest Paths,aa57a9785adf925bc85c1920f53755a0_MIT6_006S20_lec11_2_pdf
211,"What is the significance of amortized analysis in the context of dynamic arrays, particularly for the insert_last operation?","which we call amortization. I want to say an operation takes t of n amortized time if, let's say, any k of those operations take, at most, k times t of n time. This is a little bit sloppy, but be good enough. The idea is here, if this works for n or k, to do n operations from an empty array here takes linear time, which means I would call this constant amortized. Amortized means a particular kind of averaging-- averaging over the sequence of operations. So while individual operations will be expensive, one near the end, when I have to resize the array, is going to take linear time just for that one operation. But most of the operations are cheap. Most of them are constant. So I can think of charging that high cost to all of the other operations that made it happen. This is averaging over the operation sequence. Every insert_last over there only takes constant time, on average, over the sequence of operations that we do. And so it's almost constant. It's not quite as good as constant, worst case, but it's almost as good. And it's as good as you could hope to do in this dynamic array allocation model. Let me put this into a table. And you'll find these in the lecture notes, also. We have, on the top, the main operations of sequence interface, which we will revisit in lecture seven. We'll see some other data structures for this. Get_at and set_at in the first column. Insert_ and delete_first, insert_ and delete_last, insert_ and delete_at an arbitrary position. We've seen three data structures now. Arrays were really good at get_at/set_at. They took constant time. That's the blue one. We're omitting the thetas here. All of the other operations took linear time, no matter where they were. Linked lists were really good at insert- and delete_first. They took constant time, but everything else took linear time, in the worst case. These new dynamic arrays achieve get_at and set_at in constant time because they maintain this invariant here that a of i equals x i. So we can still do get- and set_at quickly. And we also just showed that insert_last is constant amortized. delete_last, you don't have to resize the array. You could just decrease length and, boom, you've deleted the last item. It's not so satisfying, because if you insert n items and then delete n items, you'll still have an array of size theta n, even though your current value of n is 0. You can get around that with a little bit more trickery, which are described in the lecture notes. But it's beyond the-- we're only going to do very simple amortized analysis in this class-- to prove that that algorithm is also constant amortized, which it is. You'll see in 046, or you can find it in the CLRS book. That's it for today.","Amortized analysis is significant for dynamic arrays as it allows us to average the cost of operations over a sequence, making operations appear to be constant time on average. For example, while the insert_last operation in a dynamic array may be costly when it triggers a resize (taking linear time), most operations are cheap, only taking constant time. Thus, by distributing the expensive operation's cost over multiple cheaper ones, we conclude that insert_last has constant amortized time. This method of analysis provides a realistic understanding of performance where operations on dynamic arrays can appear almost constant in terms of time complexity over a series of operations.",valid,Advanced,6.006,2 Data Structures and Dynamic Arrays,CHhwJjR0mZA.en-j3PyPqV-e1s_9_mp4
212,What process involves exploring the entire graph using BFS or DFS for connected components?,"about connected components. And we didn't just reduce to using a search algorithm like a single-source reachability algorithm like BFS or DFS. We put a for loop around that to explore the entire graph by basically saying, if I've explored one connected component, then I can look at any other vertex I haven't seen and explore the next one. And so that actually with some-- a little analysis, also got linear time, because I'm at most traversing any component of my graph once. That's kind of the idea. And we can use that using BFS or DFS really, because we're just trying to get a thing that searches an entire connected component. And then this topological sort we did at the end of the last lecture. We used full DFS to give an ordering of the vertices in a DAG-- maybe I'll specify clearly that this is only for a DAG-- where we have an ordering of the vertices so all the edges go forward in that order, for example. And that we also did in linear time. All right, in this lecture, and in actually the next four lectures, what we're going to do is instead of measuring distance in terms of the number of edges in a path-- so previously, distance equaled number of edges-- we're going to generalize that notion. So instead counting an edge, we're going to count an integer associated with that edge.","The process involves putting a for loop around a single-source reachability algorithm like BFS or DFS to explore the entire graph by exploring one connected component and then looking at any other vertex not seen to explore the next one. This is done to ensure that the entire graph is covered, and it can be achieved in linear time.",valid,Intermediate,6.006,11 Weighted Shortest Paths,5cF5Bgv59Sc.en-j3PyPqV-e1s_2_mp4
213,What is the optimal strategy dynamic programming seeks to solve in the alternating coin game?,"Alternating coin game-- this is a two player game. We're going to find the optimal strategy in this game. In general, you have a sequence of coins, and we have two players. They take turns. So given coins of value v0 to v n minus 1-- so it's a sequence. They're given in order-- in some order-- for example, 5, 10, 100, 25-- not necessarily sorted order. And the rules of the game are we're going to take turns. I'm going to take turns with you. I'm going to use I and you to refer to the two players. And so in each turn, either one-- whoever's turn it is, I get to-- we get to choose either the first coin or the last coin among the coins that remain. So at the beginning, I can choose 5 or 25. And I might think, oh, 25's really good. That's better than 5. I should choose that. But then, of course, you're going next, and you're going to choose 100, and you'll win the game. You'll get more of the total value of the coins. So in this is example, a better strategy is to take the 5, because then the 100 is still in the middle. And so once I take 5, you get to choose 10 or 25. At this point, you'd probably prefer 25, because that's better than 10. But whichever you choose, I can take the 100. And so I get 105 points, and you're going to get 35 points. OK-- good example for me. So that's easy for a simple example, but in general, there are exponentially many strategies here. At each step, either of us could go left or right-- choose is the leftmost or the rightmost. And we're going to give a dynamic programming algorithm that just solves this fast. I didn't mention-- so this algorithm is quadratic time, but it can be made n log n time. It's a fun exercise. Using a lot of the data structure augmentation stuff we've done, you can make this n log n. This algorithm, I think, is going to be n squared time. So I won't right the problem exactly, but I think you know the rules. Choose leftmost or rightmost coin, alternating moves. So I'd like to define some subproblems. And this is a problem that's very naturally a substring problem. If I just looked at suffixes, that would deal great with-- if I'm deleting coins from the left, but as soon as I delete-- and if I delete coins only from the right, that would give me prefixes. But I'll tell you now, there's no dynamic programming where the answer is suffixes and prefixes. You can do suffixes or prefixes, but if you need both, you almost certainly need substring, because as soon as I delete the first coin, and then maybe you take the second coin-- that's exactly the optimal strategy here-- now you have an arbitrary substring in the middle. But substrings are enough, because we're only leading from the ends. We'll look at substrings. So more precisely-- this is just the intuition-- we're going to define some generic x of i, j is going to be what is the maximum total value I can get from this game, if we play it on coins of value Vi to Vj. So that's a substring. So this is one way to write down the subproblems, and it's also a good way. You could write down a relation on this definition of subproblems. But I'm low on time. There's two ways to solve this problem. This is a reasonable way, exploiting that the game is zero-sum. But I'd like to change just a little bit to give you, I think, what's a cleaner way to solve the problem, which is to add a third coordinate to my subproblems. So now it's parameterized by three things. P here is-- only has two choices. It's me or you. And this gets at a point that's maybe not totally clear from this definition-- max total value that I can get from these-- this substring of coins. But this is not obviously what I need. So obviously, at the beginning, I want the whole string and I want to know what my maximum value is-- fine. And I go first in this game. I didn't specify, but I do. [INAUDIBLE] But as soon as I do a move-- as soon as I take the first coin, for example-- it's now your turn. And so I don't really want to know the maximum total value that I would get if I go first. I'd like to say, if player P goes first. I'd really like to know what happens in the case where you go first. So for some of the substrings, I want to know what happens when you go first, and for some of them, I want to know what happens when I go first, because as soon as I make a move, it's your turn. And so we're going to flip back and forth between P being me and P being you-- P-U. So you don't have to parameterize. There's a way to write the recurrence otherwise, but this is, I think, a lot more intuitive, because now we can do a very simple relation, which is as follows. So I'm going to split into two cases. One is x of i, j, me and the other is x of i, j, you. So x of i, j, me-- so I have some substring from i to j. What could I do? I could take the first coin or I could take the second coin. Which should I do? That's my question. What is my first move? Should I take the first coin or the second coin? So this is my question. What is the first move? There are exactly two possible answers to that question, so we can afford to just brute force them and take the max. If we're moving, we want the maximum number of points we can get-- maximum total value of the two choices. So if I take from the i side, the left side, that would be x sub i plus 1, j. Sorry. And now, crucially, we flip players, because then it's your turn. And if I take from the j side, that will make it j minus 1. This is what I accidentally wrote at the beginning of lecture. Also flip players. So either I shrink on the i side or I shrink on the j side. Oh, I should add on here the value of the coin that I get, and add on the value the coin that I took. This is an expression inside the max. That sum. And if I take the max those two options, that will give-- that is my local brute force the best choice of how many-- what are the total value of coins I will get out of the remainder, given that you start, plus this coin that I took right now in the first step, and for the two possible choices of what that coin is? OK, what remains is, how do we define this x of i, j, you. This is a little bit funnier, but it's conceptually similar. I'm going to write basically the same thing here, but with me, instead of you-- because again, it flips. This is, if you go first, then the very next move will be me. So this is just the symmetric formula here. I can even put the braces in-- so far, the same. Now, I don't put in the plus Vi and I don't put in the plus Vj here, because if you're moving, I don't get those points. So there's an asymmetry in this definition. You could define it in different ways, but this is the maximum total value that I would get if you start. So in your first move, you get some points, but I don't get any points out of that. So there's no plus Vi. There's no plus Vj. It's just you either choose the i-th coin or you choose the j-th coin, and then the coins that remain for me shrink accordingly. Now, you're kind of a pain in the ass. You're an adversary you're trying to minimize my score potentially because you're trying to maximize your score. This is a 0 sum game. So anything that you get I don't get. If you want to maximize your score, you're trying to minimize my score. These are symmetric things. And so if you think for a while, the right thing to put here is min. From our perspective, we're imagining what is the worst case that could happen, no matter what you do. And we don't have control over what you do, and so we'd really like to see, what score would I get if you chose the i-th coin? What score do you get if you chose the j-th coin? And then what we get is going to be the worst of those two possibilities. So when we get to choose, we're maximizing. And this is a general two player phenomenon that, when you choose, we end up minimizing, because that's the saddest thing that could happen to us. OK, this is one way to write a recurrence relation. We have, of course, all of SRTBOT to do, so the topological order here is in increasing length of substance. So the T is increasing j minus i. Start with empty strings. So base case is that x of i, i, me is Vi. So here I'm inclusive in both ends in this definition. So there is a coin I can take at the end. But if you move last and there's one coin left, then I don't get it, so it's 0. Then we have the original problem that is x i, j, me-- sorry-- x 0, n. That's the entire coin set, starting with me. That was the problem I wanted to do. And then the running time we get is the number of subproblems-- that's theta n squared, because we're doing substrings-- times the amount of non-recursive work I do here. That's just a max of two numbers. Very simple. Constant time. So this is quadratic. Let me show you an example. This is hard to draw, but what I've described here is called solution 2 in the notes. So here's our sequence-- 5, 10, 100, 25-- in both directions. And what we're interested in is all substrings. So over here I've written the choice for i. So we start at one of these, and if you start here, you can't end earlier than there. So that's why we're in the upper diagonal of this matrix. And then there's two versions of each problem-- the white version and the blue version just down and to the right of it. If you can't see what blue is, this is the version where you start. This is the version where I start. And I've labeled here all of the different numbers. Please admire, because this took a long time to draw. But in particular, we have 105 here, meaning that the maximum points I can get 105. And that's the case because, if we look over there, it is the max of these two incoming values plus the Vi that I get. So either I go to the left and I take that item or I go down and I take that item. So the option here is I went to the left and took-- well, that's going to be tricky to do in time. The claim is that the best answer here is to go here with the 100 and take the 5, because going down corresponds to removing the last item. If I went to the left, that corresponds to-- sorry-- the first item. If I went to the left, that corresponds to removing the last item, so my options are 10 plus 25, which is 35, versus 100 plus 5. 105 wins, so that's why there's a red edge here showing that was my better choice. And in general, if you follow these parent pointers back, it gives you the optimal strategy in what you should do. First, you should take the 5 is what this is saying, because we just clipped off the 5. We used to start here, and now we start here in this subinterval. Then our opponents, to be annoying, will take the 25-- doesn't actually matter, I think. Then we will take the 100, and then they take the 10, and it's game over. OK, all the numbers here are how many points we get-- doesn't say how many points the opponent gets. Of course, you could add that as well. It's just the total sum minus what we get. Now, let me come back to high level here.","Dynamic programming aims to solve the optimal strategy in the alternating coin game by finding the maximum total value a player can get from a sequence of coins, using subproblems defined by the substrings of coins between indices i and j, and considering whose turn it is (player one or player two). The recursion involves maximizing or minimizing based on whose turn it is, resulting in a solution that considers all possible decisions at each step.",valid,Intermediate,6.006,16 Dynamic Programming Part 2 LCS LIS Coins,KLBCUx1is2c.en-j3PyPqV-e1s_10_mp4
214,What is the disadvantage of using static arrays for dynamic operations like insertions?,"Our goal is the next data structure, which is dynamic arrays. But linked lists and static arrays each have their advantages. Let's first analyze dynamic sequence operations, first on a static array and then on a linked list. On a static array, I think you all see, if I try to insert at the beginning of the static array-- that's kind of the worst case. If I insert first, then everybody has to shift over. If I'm going to maintain this invariant, that the ith item in the array represents-- I guess I didn't write it anywhere here. Maybe here. Static array. We're going to maintain this invariant that a of i represents x i. If I want to maintain that at all times, when I insert a new thing in the front, because the indices of all the previous items change, I have to spend time to copy those over. You can do it in linear time, but no better. Static array. Insert and delete anywhere costs theta n time-- actually, for two reasons. Reason number one is that, if we're near the front, then we have to do shifting. What about insert or delete the last element of an array? Is that any easier? Because then, if I insert the very last element, none of the indices change. I'm just adding a new element. So I don't have to do shifting. So can I do insert and delete last in constant time in a static array? Yeah? AUDIENCE: No, because the size is constant. ERIK DEMAINE: No, because the size is constant. So our model is that remember allocation model is that we can allocate a static array of size em but it's just a size n I can't just say please make it bigger by 1 I need I need space to store this extra element. And if you think about where things are in memory, when you call to this memory allocator, which is part of your operating system, you say, please give me a chunk of memory. It's going to place them in various places in memory, and some of them might be next to each other. So if I try to grow this array by 1, there might already be something there. And that's not possible without first shifting. So even though, in the array, I don't have to do any shifting, in memory, I might have to do shifting. And that's outside the model. So we're going to stick to this model of just-- you can allocate memory. You can also de-allocate memory, just to keep space usage small. But the only way to get more space is to ask for a new array. And that new array won't be contiguous to your old one. Question? AUDIENCE: [INAUDIBLE] ERIK DEMAINE: What is the dynamic array will be the next topic, so maybe we'll come back to that. Yeah? In a static array, you're just not allowed to make it bigger. And so you have to allocate a new array, which we say takes linear time. Even if allocating the new array didn't take linear time, you have to copy all the elements over from the old array to the new one. Then you can throw away the old one. Just the copying from an array of size n to an array of size n plus 1, that will take linear time. So static arrays are really bad for dynamic operations-- no surprise. But you could do them. That's static array. Now, linked lists are going to be almost the opposite-- well, almost. If we store the length, OK, we can compute the length of the array very quickly. We can insert and delete at the front really efficiently. If I want to add a new item as a new first item, then what do? I do I allocate a new node, which I'll call x. This is insert-first of x. I'll allocate a new array of size 2. I'm going to change-- let me do it in red. I'm going to change this head pointer. Maybe I should do that later. I'm going to set the next pointer here to this one, and then I'm going to change this head pointer to point to here. And, boom, now I've got a linked list. Again, we don't know anything about the order and memory of these lists. We just care about the order that's represented implicitly by following the next pointers repeatedly. Now, I've got a new list that has x in front, and then x 0, and then x 1, and so on. So insert- and delete_first, at least are really efficient. We won't get much more than that, but the linked list, insert- and delete_first are constant time. So that's cool. However, everything else is going to be slow. If I want to get the 10th item in a linked list, I have to follow these pointers 10 times. I go 0, 1, 2, 3, and so on. Follow 10 next pointers and I'll get the 10th item. Accessing the ith item is going to take order i time. Get- and set_at need i time, which, in the worst case, is theta n. We have sort of complementary data structures here. On the one hand, a static array can do constant time get_at/set_at. So it's very fast at the random access aspect because it's an array. Linked lists are very bad at random access, but they're better at being dynamic. We can insert and delete-- at the beginning, at least-- in constant time. Now, if we want to actually insert and delete at a particular position, that's still hard, because we have to walk to that position. Even inserting and leading at the end of the list is hard, although that's fixable. And maybe I'll leave that for problem session or problem set. But an easy-- here's a small puzzle. Suppose you wanted to solve get-last efficiently in a linked list. How would you solve that in constant time? Yeah? AUDIENCE: Doubly linked list. ERIK DEMAINE: Doubly linked list. It's a good idea, but actually not the right answer. That's an answer to the next question I might ask. Yeah? AUDIENCE: [INAUDIBLE] ERIK DEMAINE: [INAUDIBLE] pointer to the last element. That's all we need here. And often, a doubly linked list has this. They usually call this the tail-- head and tail. And if we always just store a pointer to the last list-- this is what we call data structure augmentation, where we add some extra information to the data structure and-- we have to keep it up to date all the time. So if we do an insert_last or something, insert_last also becomes easy because I can just add a new node here and update the pointer here. delete_last is trickier. That's where you get a doubly linked list. But whenever I add something to the end of this list, I have to update the tail pointer also. As long as I maintain this, now, suddenly get-last is fast in constant time. So linked lists are great if you're working on the ends, even dynamically. Arrays are great if you're doing random access and nothing dynamic-- nothing adding or deleting at the ends or in the middle. Our final goal for today is to get sort of the best of both worlds with dynamic arrays. We're going to try to get all of the good running times of linked lists and all of the good running times of static arrays. We won't get quite all of them, but most of them. And in some sense, another way to describe what these introductory lectures are about is telling you about how Python is implemented. What we're going to talk about next, dynamic arrays, I've alluded to many times. But these are what Python calls lists. You don't have to implement a dynamic array by hand because it's already built into many fancy new languages for free, because they're so darn useful. This lecture is about how these are actually implemented and why they're efficient. And in recitation nodes, you'll see how to actually implement them if all you had were static arrays. But luckily, we have dynamic arrays, so we don't have to actually implement them. But inside the Python interpreter, this is exactly what's happening. The idea is to relax the constraint-- or the invariant, whatever-- that the size of the array we use equals n, which is the number of items in the sequence. Remember, in the sequence problem, we're supposed to represent n items. With a static array, we allocated an array of size exactly n. So let's relax that. Let's not make it exactly n. Let's make it roughly n. How roughly, you can think about for a while. But from an algorithms perspective, usually, when we say roughly, we mean throw away constant factors. And that turns out to be the right answer here. It's not always the right answer. But we're going to enforce that the size of the array is theta n-- probably also greater than or equal to n. 0.5 n would not be very helpful. So it's going to be at least n, and it's going to be at most some constant times n. 2n, 10n, 1.1 times n. Any of these constants will work. I'm going to use 2n here, but there are lots of options. And now, things almost work for free. There's going to be one subtlety here. And I'm going to focus on-- we're still going to maintain that the ith item of the array represents x i. This data structure-- let me draw a picture. We've got an array of some size. The first few items are used to store the sequence. But then, there's going to be some blank ones at the end. Maybe we'll keep track of this-- so the data structure itself is going to have an array and it's going to have a length. Something like this. We're also going to keep track of the length. So we know that the first length items are where the data is, and the remainder are meaningless. So now, if I want to go and do an insert_last, what do I do? I just go to a of length and set it to x. And then I increment length. Boom. Easy. Constant time. Yeah? AUDIENCE: [INAUDIBLE] ERIK DEMAINE: How do you have enough room. Indeed, I don't. This was an incorrect algorithm. But it's usually correct. As long as I have extra space, this is all I need to do for insert_last. But I am also going to store the size of the array. This is the actual-- this whole thing is size, and this part is length. Length is always going to be less than or equal to size. And so there's a problem. If length equals size, then I don't have any space. Just add to end unless n equals size. I'm using n length for the same thing. So length here is the same as n. That's our actual number of things we're trying to represent. And size-- this is great. This is the interface size. This is what we're trying to represent. And this is the representation size. This is the size of my array. These are the number of items I'm trying to store in that array. This is the interface versus data structure. Here's the interface. Here's the data structure. OK, cool.","Static arrays are inefficient for dynamic operations because inserting or deleting elements requires shifting existing elements, especially if operations are done at the beginning. Also, static arrays have a fixed size, so expanding the array requires allocating a new one and copying existing elements, all of which take linear time.",valid,Intermediate,6.006,2 Data Structures and Dynamic Arrays,CHhwJjR0mZA.en-j3PyPqV-e1s_6_mp4
215,Why are linked lists inefficient for random access operations?,"Our goal is the next data structure, which is dynamic arrays. But linked lists and static arrays each have their advantages. Let's first analyze dynamic sequence operations, first on a static array and then on a linked list. On a static array, I think you all see, if I try to insert at the beginning of the static array-- that's kind of the worst case. If I insert first, then everybody has to shift over. If I'm going to maintain this invariant, that the ith item in the array represents-- I guess I didn't write it anywhere here. Maybe here. Static array. We're going to maintain this invariant that a of i represents x i. If I want to maintain that at all times, when I insert a new thing in the front, because the indices of all the previous items change, I have to spend time to copy those over. You can do it in linear time, but no better. Static array. Insert and delete anywhere costs theta n time-- actually, for two reasons. Reason number one is that, if we're near the front, then we have to do shifting. What about insert or delete the last element of an array? Is that any easier? Because then, if I insert the very last element, none of the indices change. I'm just adding a new element. So I don't have to do shifting. So can I do insert and delete last in constant time in a static array? Yeah? AUDIENCE: No, because the size is constant. ERIK DEMAINE: No, because the size is constant. So our model is that remember allocation model is that we can allocate a static array of size em but it's just a size n I can't just say please make it bigger by 1 I need I need space to store this extra element. And if you think about where things are in memory, when you call to this memory allocator, which is part of your operating system, you say, please give me a chunk of memory. It's going to place them in various places in memory, and some of them might be next to each other. So if I try to grow this array by 1, there might already be something there. And that's not possible without first shifting. So even though, in the array, I don't have to do any shifting, in memory, I might have to do shifting. And that's outside the model. So we're going to stick to this model of just-- you can allocate memory. You can also de-allocate memory, just to keep space usage small. But the only way to get more space is to ask for a new array. And that new array won't be contiguous to your old one. Question? AUDIENCE: [INAUDIBLE] ERIK DEMAINE: What is the dynamic array will be the next topic, so maybe we'll come back to that. Yeah? In a static array, you're just not allowed to make it bigger. And so you have to allocate a new array, which we say takes linear time. Even if allocating the new array didn't take linear time, you have to copy all the elements over from the old array to the new one. Then you can throw away the old one. Just the copying from an array of size n to an array of size n plus 1, that will take linear time. So static arrays are really bad for dynamic operations-- no surprise. But you could do them. That's static array. Now, linked lists are going to be almost the opposite-- well, almost. If we store the length, OK, we can compute the length of the array very quickly. We can insert and delete at the front really efficiently. If I want to add a new item as a new first item, then what do? I do I allocate a new node, which I'll call x. This is insert-first of x. I'll allocate a new array of size 2. I'm going to change-- let me do it in red. I'm going to change this head pointer. Maybe I should do that later. I'm going to set the next pointer here to this one, and then I'm going to change this head pointer to point to here. And, boom, now I've got a linked list. Again, we don't know anything about the order and memory of these lists. We just care about the order that's represented implicitly by following the next pointers repeatedly. Now, I've got a new list that has x in front, and then x 0, and then x 1, and so on. So insert- and delete_first, at least are really efficient. We won't get much more than that, but the linked list, insert- and delete_first are constant time. So that's cool. However, everything else is going to be slow. If I want to get the 10th item in a linked list, I have to follow these pointers 10 times. I go 0, 1, 2, 3, and so on. Follow 10 next pointers and I'll get the 10th item. Accessing the ith item is going to take order i time. Get- and set_at need i time, which, in the worst case, is theta n. We have sort of complementary data structures here. On the one hand, a static array can do constant time get_at/set_at. So it's very fast at the random access aspect because it's an array. Linked lists are very bad at random access, but they're better at being dynamic. We can insert and delete-- at the beginning, at least-- in constant time. Now, if we want to actually insert and delete at a particular position, that's still hard, because we have to walk to that position. Even inserting and leading at the end of the list is hard, although that's fixable. And maybe I'll leave that for problem session or problem set. But an easy-- here's a small puzzle. Suppose you wanted to solve get-last efficiently in a linked list. How would you solve that in constant time? Yeah? AUDIENCE: Doubly linked list. ERIK DEMAINE: Doubly linked list. It's a good idea, but actually not the right answer. That's an answer to the next question I might ask. Yeah? AUDIENCE: [INAUDIBLE] ERIK DEMAINE: [INAUDIBLE] pointer to the last element. That's all we need here. And often, a doubly linked list has this. They usually call this the tail-- head and tail. And if we always just store a pointer to the last list-- this is what we call data structure augmentation, where we add some extra information to the data structure and-- we have to keep it up to date all the time. So if we do an insert_last or something, insert_last also becomes easy because I can just add a new node here and update the pointer here. delete_last is trickier. That's where you get a doubly linked list. But whenever I add something to the end of this list, I have to update the tail pointer also. As long as I maintain this, now, suddenly get-last is fast in constant time. So linked lists are great if you're working on the ends, even dynamically. Arrays are great if you're doing random access and nothing dynamic-- nothing adding or deleting at the ends or in the middle. Our final goal for today is to get sort of the best of both worlds with dynamic arrays. We're going to try to get all of the good running times of linked lists and all of the good running times of static arrays. We won't get quite all of them, but most of them. And in some sense, another way to describe what these introductory lectures are about is telling you about how Python is implemented. What we're going to talk about next, dynamic arrays, I've alluded to many times. But these are what Python calls lists. You don't have to implement a dynamic array by hand because it's already built into many fancy new languages for free, because they're so darn useful. This lecture is about how these are actually implemented and why they're efficient. And in recitation nodes, you'll see how to actually implement them if all you had were static arrays. But luckily, we have dynamic arrays, so we don't have to actually implement them. But inside the Python interpreter, this is exactly what's happening. The idea is to relax the constraint-- or the invariant, whatever-- that the size of the array we use equals n, which is the number of items in the sequence. Remember, in the sequence problem, we're supposed to represent n items. With a static array, we allocated an array of size exactly n. So let's relax that. Let's not make it exactly n. Let's make it roughly n. How roughly, you can think about for a while. But from an algorithms perspective, usually, when we say roughly, we mean throw away constant factors. And that turns out to be the right answer here. It's not always the right answer. But we're going to enforce that the size of the array is theta n-- probably also greater than or equal to n. 0.5 n would not be very helpful. So it's going to be at least n, and it's going to be at most some constant times n. 2n, 10n, 1.1 times n. Any of these constants will work. I'm going to use 2n here, but there are lots of options. And now, things almost work for free. There's going to be one subtlety here. And I'm going to focus on-- we're still going to maintain that the ith item of the array represents x i. This data structure-- let me draw a picture. We've got an array of some size. The first few items are used to store the sequence. But then, there's going to be some blank ones at the end. Maybe we'll keep track of this-- so the data structure itself is going to have an array and it's going to have a length. Something like this. We're also going to keep track of the length. So we know that the first length items are where the data is, and the remainder are meaningless. So now, if I want to go and do an insert_last, what do I do? I just go to a of length and set it to x. And then I increment length. Boom. Easy. Constant time. Yeah? AUDIENCE: [INAUDIBLE] ERIK DEMAINE: How do you have enough room. Indeed, I don't. This was an incorrect algorithm. But it's usually correct. As long as I have extra space, this is all I need to do for insert_last. But I am also going to store the size of the array. This is the actual-- this whole thing is size, and this part is length. Length is always going to be less than or equal to size. And so there's a problem. If length equals size, then I don't have any space. Just add to end unless n equals size. I'm using n length for the same thing. So length here is the same as n. That's our actual number of things we're trying to represent. And size-- this is great. This is the interface size. This is what we're trying to represent. And this is the representation size. This is the size of my array. These are the number of items I'm trying to store in that array. This is the interface versus data structure. Here's the interface. Here's the data structure. OK, cool.","Linked lists are inefficient for random access because accessing the ith item requires traversing i pointers, which takes order i time. This is unlike arrays where you can access any item in constant time.",valid,Intermediate,6.006,2 Data Structures and Dynamic Arrays,CHhwJjR0mZA.en-j3PyPqV-e1s_6_mp4
216,What modification can improve linked list operations at both ends?,"Our goal is the next data structure, which is dynamic arrays. But linked lists and static arrays each have their advantages. Let's first analyze dynamic sequence operations, first on a static array and then on a linked list. On a static array, I think you all see, if I try to insert at the beginning of the static array-- that's kind of the worst case. If I insert first, then everybody has to shift over. If I'm going to maintain this invariant, that the ith item in the array represents-- I guess I didn't write it anywhere here. Maybe here. Static array. We're going to maintain this invariant that a of i represents x i. If I want to maintain that at all times, when I insert a new thing in the front, because the indices of all the previous items change, I have to spend time to copy those over. You can do it in linear time, but no better. Static array. Insert and delete anywhere costs theta n time-- actually, for two reasons. Reason number one is that, if we're near the front, then we have to do shifting. What about insert or delete the last element of an array? Is that any easier? Because then, if I insert the very last element, none of the indices change. I'm just adding a new element. So I don't have to do shifting. So can I do insert and delete last in constant time in a static array? Yeah? AUDIENCE: No, because the size is constant. ERIK DEMAINE: No, because the size is constant. So our model is that remember allocation model is that we can allocate a static array of size em but it's just a size n I can't just say please make it bigger by 1 I need I need space to store this extra element. And if you think about where things are in memory, when you call to this memory allocator, which is part of your operating system, you say, please give me a chunk of memory. It's going to place them in various places in memory, and some of them might be next to each other. So if I try to grow this array by 1, there might already be something there. And that's not possible without first shifting. So even though, in the array, I don't have to do any shifting, in memory, I might have to do shifting. And that's outside the model. So we're going to stick to this model of just-- you can allocate memory. You can also de-allocate memory, just to keep space usage small. But the only way to get more space is to ask for a new array. And that new array won't be contiguous to your old one. Question? AUDIENCE: [INAUDIBLE] ERIK DEMAINE: What is the dynamic array will be the next topic, so maybe we'll come back to that. Yeah? In a static array, you're just not allowed to make it bigger. And so you have to allocate a new array, which we say takes linear time. Even if allocating the new array didn't take linear time, you have to copy all the elements over from the old array to the new one. Then you can throw away the old one. Just the copying from an array of size n to an array of size n plus 1, that will take linear time. So static arrays are really bad for dynamic operations-- no surprise. But you could do them. That's static array. Now, linked lists are going to be almost the opposite-- well, almost. If we store the length, OK, we can compute the length of the array very quickly. We can insert and delete at the front really efficiently. If I want to add a new item as a new first item, then what do? I do I allocate a new node, which I'll call x. This is insert-first of x. I'll allocate a new array of size 2. I'm going to change-- let me do it in red. I'm going to change this head pointer. Maybe I should do that later. I'm going to set the next pointer here to this one, and then I'm going to change this head pointer to point to here. And, boom, now I've got a linked list. Again, we don't know anything about the order and memory of these lists. We just care about the order that's represented implicitly by following the next pointers repeatedly. Now, I've got a new list that has x in front, and then x 0, and then x 1, and so on. So insert- and delete_first, at least are really efficient. We won't get much more than that, but the linked list, insert- and delete_first are constant time. So that's cool. However, everything else is going to be slow. If I want to get the 10th item in a linked list, I have to follow these pointers 10 times. I go 0, 1, 2, 3, and so on. Follow 10 next pointers and I'll get the 10th item. Accessing the ith item is going to take order i time. Get- and set_at need i time, which, in the worst case, is theta n. We have sort of complementary data structures here. On the one hand, a static array can do constant time get_at/set_at. So it's very fast at the random access aspect because it's an array. Linked lists are very bad at random access, but they're better at being dynamic. We can insert and delete-- at the beginning, at least-- in constant time. Now, if we want to actually insert and delete at a particular position, that's still hard, because we have to walk to that position. Even inserting and leading at the end of the list is hard, although that's fixable. And maybe I'll leave that for problem session or problem set. But an easy-- here's a small puzzle. Suppose you wanted to solve get-last efficiently in a linked list. How would you solve that in constant time? Yeah? AUDIENCE: Doubly linked list. ERIK DEMAINE: Doubly linked list. It's a good idea, but actually not the right answer. That's an answer to the next question I might ask. Yeah? AUDIENCE: [INAUDIBLE] ERIK DEMAINE: [INAUDIBLE] pointer to the last element. That's all we need here. And often, a doubly linked list has this. They usually call this the tail-- head and tail. And if we always just store a pointer to the last list-- this is what we call data structure augmentation, where we add some extra information to the data structure and-- we have to keep it up to date all the time. So if we do an insert_last or something, insert_last also becomes easy because I can just add a new node here and update the pointer here. delete_last is trickier. That's where you get a doubly linked list. But whenever I add something to the end of this list, I have to update the tail pointer also. As long as I maintain this, now, suddenly get-last is fast in constant time. So linked lists are great if you're working on the ends, even dynamically. Arrays are great if you're doing random access and nothing dynamic-- nothing adding or deleting at the ends or in the middle. Our final goal for today is to get sort of the best of both worlds with dynamic arrays. We're going to try to get all of the good running times of linked lists and all of the good running times of static arrays. We won't get quite all of them, but most of them. And in some sense, another way to describe what these introductory lectures are about is telling you about how Python is implemented. What we're going to talk about next, dynamic arrays, I've alluded to many times. But these are what Python calls lists. You don't have to implement a dynamic array by hand because it's already built into many fancy new languages for free, because they're so darn useful. This lecture is about how these are actually implemented and why they're efficient. And in recitation nodes, you'll see how to actually implement them if all you had were static arrays. But luckily, we have dynamic arrays, so we don't have to actually implement them. But inside the Python interpreter, this is exactly what's happening. The idea is to relax the constraint-- or the invariant, whatever-- that the size of the array we use equals n, which is the number of items in the sequence. Remember, in the sequence problem, we're supposed to represent n items. With a static array, we allocated an array of size exactly n. So let's relax that. Let's not make it exactly n. Let's make it roughly n. How roughly, you can think about for a while. But from an algorithms perspective, usually, when we say roughly, we mean throw away constant factors. And that turns out to be the right answer here. It's not always the right answer. But we're going to enforce that the size of the array is theta n-- probably also greater than or equal to n. 0.5 n would not be very helpful. So it's going to be at least n, and it's going to be at most some constant times n. 2n, 10n, 1.1 times n. Any of these constants will work. I'm going to use 2n here, but there are lots of options. And now, things almost work for free. There's going to be one subtlety here. And I'm going to focus on-- we're still going to maintain that the ith item of the array represents x i. This data structure-- let me draw a picture. We've got an array of some size. The first few items are used to store the sequence. But then, there's going to be some blank ones at the end. Maybe we'll keep track of this-- so the data structure itself is going to have an array and it's going to have a length. Something like this. We're also going to keep track of the length. So we know that the first length items are where the data is, and the remainder are meaningless. So now, if I want to go and do an insert_last, what do I do? I just go to a of length and set it to x. And then I increment length. Boom. Easy. Constant time. Yeah? AUDIENCE: [INAUDIBLE] ERIK DEMAINE: How do you have enough room. Indeed, I don't. This was an incorrect algorithm. But it's usually correct. As long as I have extra space, this is all I need to do for insert_last. But I am also going to store the size of the array. This is the actual-- this whole thing is size, and this part is length. Length is always going to be less than or equal to size. And so there's a problem. If length equals size, then I don't have any space. Just add to end unless n equals size. I'm using n length for the same thing. So length here is the same as n. That's our actual number of things we're trying to represent. And size-- this is great. This is the interface size. This is what we're trying to represent. And this is the representation size. This is the size of my array. These are the number of items I'm trying to store in that array. This is the interface versus data structure. Here's the interface. Here's the data structure. OK, cool.","By maintaining a pointer to the last element, or tail, in a linked list, operations like get-last can be performed in constant time. This is an example of data structure augmentation, where additional information is stored to optimize certain operations.",valid,Intermediate,6.006,2 Data Structures and Dynamic Arrays,CHhwJjR0mZA.en-j3PyPqV-e1s_6_mp4
217,"What defines a path in a graph, and how is the length of a path measured?","is to start introducing sort of the canonical problem that we all worry about on graphs which is computing paths, in particular shortest paths. So the first thing we should do is, of course, define what a path is on a graph. So we're going to talk about our graph like a road network. Let's think of maybe every node here as an intersection. So this is a roughly Kendall Square. See it's a square. But in any event, let's say that I want to find-- maybe a question one would be does there exist a way to get from vertex 1 to vertex 3. And then a better question to ask would be does there exists a short way to get from vertex 1 to vertex 3. Then of course, the first thing I have to do is to define my enemy. I have define what I'm looking for, which is a path. So a path is nothing more than a sequence of vertices in a graph where every pair of adjacent vertices in that sequence is an edge. I think this all aligns with our intuition of what a path is in a graph. So for instance, here's a path p equals v1, v2, v3. So notice that there's an edge from v1 to v2 and also an edge from v2 to v3. So it satisfies the assumptions set forth in our definition. What would not be a path in our graph-- would be like v1 comma v3, because there's no edge there. OK, so if we talk about paths, then there's a very natural notion which is the length. Length, I guess you could think of like the number of vertices in your path minus 1, or the number of edges that your path traverses. Those are the same thing. So for instance, the length of the path p here is 2. Does everybody see that? A very common coding bug that I encounter a lot is adding 1 to that number by accident. Because of course, there's one more vertex in your path than there are edges. OK, and there are many different-- there could be potentially more than one path between any pair of vertices. So let's say that I have an undirected graph that looks like the following. So it's just a square plus a diagonal. So here are nodes. So then a perfectly valid path from the lower left to the upper right would be to go one over and one up, but of course, there's a more efficient way to get from the lower left to the upper right, which is to go across the diagonal. And so when we talk about the shortest path, it's nothing more than the length of the path that has the fewest number of edges or vertices between any pair of vertices in my graph. OK, so this is our enemy. This is what we're after. It's computing the shortest path between vertices in a graph. And this is the thing that we'll be talking about quite a bit in this course. Because of course, it's a very practical matter. Like when I want to solve routing problems, I want to move packets out of my network, I'd prefer not to-- well, unless I'm doing Tor-- I would prefer them not to hit too many computers in between. Then maybe I want a computer shortest path. Or on a surface maybe I want to move information","A path is defined as a sequence of vertices in a graph where every pair of adjacent vertices in that sequence is an edge. The length of a path is measured by the number of vertices in the path minus one, or equivalently, the number of edges that the path traverses.",valid,Advanced,6.006,9 Breadth-First Search,oFVYVzlvk9c.en-j3PyPqV-e1s_9_mp4
218,What is the significance of ensuring that the parameter ai is only considered an option when ai is less than or equal to t in the subset sum dynamic programming approach?,show you an example as a subproblem tag really helpful to see how these are hard to draw but they're easy to read i think they're helpful to show what's really going on in this dp this remember every node here corresponds to a possible subproblem we could have so we have the choices for little t on the top the choices for little i on the left so the original problem we care about is i equals 0 t equals 6. this is the same example that i showed you before where we have three or no it's a different example sorry my new set a is three four three one four numbers here my target value is six this is definitely possible i can add three and three this shows that a doesn't have to be sorted we're not assuming anything about the order of a and we're allowed duplicate values and we see indeed there's a y here for yes it is possible and how did i compute that well i just drew a bunch of arrows so there's vertical arrows here always going from each problem to the next one above it because we have this dependency x i of t calls x of i plus 1 comma t so that's the calls are going in this direction so the dependency order is you have to compute things lower down before you compute things up here um and indeed down here is the base case where we write yes for the first problem and no for all the others because we don't have any numbers we can't represent anything above zero okay and then we have these blue lines i just drew them a different color so they stand out hopefully and they correspond to the numbers here so our first choice is do we include a zero which is three so that's only possible if we're trying to represent a number uh that's greater than or equal to three which reminds me i forgot to write down in this dp i need to say this option is only an option if a i is less than or equal to t just move my comments here those are the same so this notation means i put this item in this set that we take an or of only if this condition holds okay otherwise i admit it because it's not a choice why is that important because i don't want to call x on a negative value of t we only are allowed to call x here when t is between zero and capital t so that's subtlety but important for a correct dp so then that's why there's no edge from here for example that goes three to the left because there's no vertex there there's no sub problem so only for uh little t from three onwards we have this edge that goes three back and that's just the same pattern over and over then our next number is four and so we have these edges that are go four to the right then our next number is three so we again have edges that go three to the right and then our next number is one so we have these nice diagonal edges that go one to the right and then what's happening in here at each stage let's take an interesting one maybe this vertex is we look at each of the incoming neighbors and we take the or so the incoming neighbor here has a no incoming neighbor here has a yes and so we write a yes here which means that given just these numbers three and one we can represent the number three namely by taking this edge of weight three sorry of length three and then just going straight down to a base case that's yes that's representing 0. so in this case we this example i didn't draw the parent pointers here but they're in the notes this yes is possible not from going this way but from going this way so we take the number three then we go down which means we skip the number four and then we go left which means we take the number three and then we go down which means we skip the number one okay so we can represent six as three plus three cool so subset sum not only can we solve the decision problem but by following parent pointers in the yes instances we can actually find a valid subset question you added that condition to the relation good question um so ins uh it's it's a generally useful technique to add if conditions to the cases to only when they apply you can write a lot of dps that way and that's why i wanted to stress it you could instead of adding this condition allow the case that little t is negative but you have to think about how negative would it be you might say well maybe t between minus big t and plus big t is enough i don't think so it should be um we're at some value t and we subtract some ai we don't know how the ai's compared to big t probably they're less than or equal to big t because they're not useful if they're bigger than big t so you could first prune the ais to guarantee all the ais are less than big t then minus big t to big t would work otherwise it's like minus the maximum ai up to big t would be enough i think yeah does this restrict to only the positive integers in the input ah do i i am implicitly assuming here that all the ai's are positive uh i think you can solve it with negative numbers but it's not uh and maybe we'll do it in recitation it is not as it's not a trivial change to this dp i've definitely thought about it before yeah so i should have said positive integers thank you,"This condition is significant because it ensures we do not attempt to call x with a negative value of t. The parameter ai is only an option if it is less than or equal to t, as it guarantees that we only make valid recursive calls. This requirement prevents the algorithm from considering impossible subproblems and reduces unnecessary computations, ensuring that the dynamic programming approach operates correctly. Without this condition, we might incorrectly attempt to evaluate subproblems with invalid states, which could lead to incorrect results or inefficiencies.",valid,Advanced,6.006,18 Dynamic Programming Part 4 Rods Subset Sum Pseudopolynomial,i9OAOk0CUQE.en_7_mp4
219,What is the role of the changeable priority queue in Dijkstra's algorithm?,"OK, so this is Dijkstra's algorithm. OK. Set-- so same initialization step. We're going to set-- this is a distance estimate d, not delta. We're going to want the d's be our delta is at the end of the algorithm. That's what we're going to have to prove. So we first set all of them to infinity, and then set d of s, s equal to 0. And here, we're never going to update it again, because our shortest distance is in a graph with non-negative edge weights certainly can't go below 0. All right. Now we build our-- build our changeable priority queue-- queue-- with an item-- I'm going to say an item is-- x is represented by a tuple of its ID, and then its key just for brevity here. With an item v, d of s, v. So I'm going to be storing in my changeable priority queue the vertex label and its shortest-path distance estimate d. And that's going to be the key, the minimum that I'm trying going to be querying on for each the v and V. So I'm going to build that thing. It's going to then have all of my vertices in my graph. Then while my changeable priority queue still has items, not empty, I'm going to delete some u, d s, u. So some item such that its distance is minimized from Q that has minimum distance. OK. So I'm going to I'm going to look at all the things in my priority queue. At the start it's just going to be s, because everything as shortest-path distance estimate infinite except for s. And so that's clearly the smallest. OK, so I'm going to remove that from my queue, and then I'm going to process it. How am I going to process it? It's the exact same kind of thing as DAG relaxation. I'm going to relax all its outgoing edges. So just for completeness for v in the outgoing adjacencies of u, I'm going to relax-- sorry. We have to check whether we can relax it. Basically if the shortest-path distance estimate to v is greater than going to u first and then crossing that edge, if going through that is better, this is violating our triangle inequality. And so we relax edge u, v, and by that we mean set this thing to be equal to that thing. That's what we meant by relax. And then we have one other thing to do. We have changed these distance estimates but our Q doesn't know that we change these things. We added these items in here. But it doesn't know that my distances have changed. So we to tell the Q to remember to change its key value associated with the item v. So decrease-- what is it? Decrease key vertex v in Q to the new d s, v, the one that I just decreased here. And I know that I decreased it because I said it to a smaller value. That makes sense. All right, so that's Dijkstra. Let's run it on an example. So here's an example. I have a directed graph. It does contain cycles. In particular, here are some cycles. I think those are the main ones. There are definitely cycles in this graph. But as you see, all of the weights are non-negative, in particular-- they're positive, actually. It's going to be just helpful in writing out this example. So let's run Dijkstra on this graph. First we initialize and we set the shortest-path distance. I'm going to label it in white here to all of the things. Then I'm going to, as I update it, I'm just going to cross them out and write a new number. So that's what it is at the start. That's initialization, that's after step 1. And then I stick things into my Q. What's in my Q? Here's my Q. It's everything. It's vertices s, a, b, c, d. I got five items in my Q. Really, it's the item pair with its shortest distance estimate, I'm just not going to rewrite that here. So the idea here is-- the while loop, OK. Q is not empty, great. We're going to delete the one with the smallest distance estimate, which is s, right, yeah. So I remove that, and then I relax edges out of s. So I relax edge here to a. That's better than the distance estimate-- 10 is better than the distance estimate infinite, so I'm going to change this to 10. And then here's another outgoing edge. 3 is better than infinite, so I'm going to change its delta to 3. OK. So now I go back in here and I change the distance estimates associated with my Q. Now, next step of the algorithm, s is done. I've processed everything distance 0 away. But I'm now going to use my priority queue to say which of my vertices has the shortest distance estimate now. So which one is it? a, b, or c, or d? Yeah, it's 3 and c. 3 is smaller than 10. So Q is going to magically delete c for me, tell me what that is, and now I'm going to process that. Now I've changed my boundary to this. And now I relax edges out of c. So here's an edge at a c, that's a 4. A 4 plus the 3 is smaller than 10, so I update it. 3 plus 8 is 11, that's smaller than infinite, so I update it, I relax. 3 plus 2 is smaller than infinite, so I relax that as well. Now of the things still left in my Q, I'm actually going to remove it from my Q instead of crossing it out, maybe that's better. Of the vertices still left in my Q, which has smallest distance? Yeah. d. d has 5, 7, or 11. 5 is the smallest. So I remove d from my cue and I relax edges from it. And now my boundary looks something like this. I relax edges out of it. 5 plus 5, that's 10. 10 is smaller than 11, so that's a 10. And that's the only outgoing edge from d. so I'm done. And then the last, 7 is smaller than 10, I relax edges out of a. a to b, 7 plus 2 is smaller than 10. And now I'm done. So what I did every time I removed s-- or I removed a vertex, I said its shortest-path distance to the small-- the last value I assigned to it. So this was then 3, and then a was 7, b was 9, and then d was 5. So that's Dijkstra in action. It seems like these are the shortest-path distances, but how do we prove that? Did it do the right thing? Well, let's find out.",The changeable priority queue is used to manage vertices based on their shortest-path distance estimates. It stores the vertex label and its shortest-path distance estimate as a key. The algorithm queries this queue to find and process the vertex with the smallest distance estimate at each step.,valid,Intermediate,6.006,13 Dijkstra,NSHizBK9JD8.en-j3PyPqV-e1s_4_mp4
220,How does Johnson's Algorithm ensure that shortest paths are maintained when reweighting edges in a graph?,"3 
Lecture 14: Johnson’s Algorithm 
• Even works with multiple vertices! 
• Deﬁne a potential function h : V → Z mapping each vertex v ∈ V to a potential h(v) 
• Make graph G0: same as G but edge (u, v) ∈ E has weight w0(u, v) = w(u, v)+h(u)−h(v) 
• Claim: Shortest paths in G are also shortest paths in G0 
• Proof: 
Pk
– Weight of path π = (v0, . . . , vk) in G is w(π) = 
i=1 w(vi−1, vi)
Pk
– Weight of π in G0 is: 
i=1 w(vi−1, vi) + h(vi−1) − h(vi) = w(π) + h(v0) − h(vk) 
– (Sum of h’s telescope, since there is a positive and negative h(vi) for each interior i) 
– Every path from v0 to vk changes by the same amount 
– So any shortest path will still be shortest 
Making Weights Non-negative 
• Can we ﬁnd a potential function such that G0 has no negative edge weights? 
• i.e., is there an h such that w(u, v) + h(u) − h(v) ≥ 0 for every (u, v) ∈ E? 
• Re-arrange this condition to h(v) ≤ h(u) + w(u, v), looks like triangle inequality! 
• Idea! Condition would be satisﬁed if h(v) = δ(s, v) and δ(s, v) is ﬁnite for some s 
• But graph may be disconnected, so may not exist any such vertex s... 
:( 
• Idea! Add a new vertex s with a directed 0-weight edge to every v ∈ V ! 
:) 
• δ(s, v) ≤ 0 for all v ∈ V , since path exists a path of weight 0 
• Claim: If δ(s, v) = −∞ for any v ∈ V , then the original graph has a negative-weight cycle 
• Proof: 
– Adding s does not introduce new cycles (s has no incoming edges) 
– So if reweighted graph has a negative-weight cycle, so does the original graph 
• Alternatively, if δ(s, v) is ﬁnite for all v ∈ V : 
– w0(u, v) = w(u, v) + h(u) − h(v) ≥ 0 for every (u, v) ∈ E by triangle inequality! 
– New weights in G0 are non-negative while preserving shortest paths! 
","The algorithm ensures shortest paths are maintained by defining a potential function h : V → Z mapping each vertex v ∈ V to a potential h(v). The graph G' is constructed with edge weights w'(u, v) = w(u, v) + h(u) - h(v). The weight of any path π in G' is adjusted uniformly by the difference h(v0) - h(vk), where v0 and vk are the endpoints of the path, ensuring that the relative weights of paths remain the same. Therefore, any shortest path in the original graph G will also be a shortest path in the reweighted graph G'.",valid,Advanced,6.006,Lecture 14 - ASP & Johnson’s Algorithm,7d7d5c35490f41b7b037cafbda7019ad_MIT6_006S20_lec14_3_pdf
221,What does the process of 'relaxing an edge' achieve in a weighted shortest path algorithm?,"that the shortest path distance from u to v can't be bigger than the shortest path distance from u to x plus the shortest path distance from x to v for any x in my graph that's not u and v. So that's the triangle inequality. Pretty intuitive notion, right? Why is this useful? OK, well, if I find-- if I find an edge in my graph, if there's an edge u, v, in my graph such that this condition is violated for the estimates that I have-- it obviously can't be violated on my shortest path distances, but if it violates it on the estimates-- u, v, is bigger than u, x-- sorry, u-- how am I going to do this? I want this to be s. I'm calculating shortest path distances from s and shortest path distances from s to some incoming vertex u plus the edge weight from u to v. All right, so what is this doing? I have some edge u, v in my graph. Basically, what I've said is that I have some distance estimate to u, but going through-- making a path to v by going through u, and then the edge from u to v is better than my current estimate, my shortest path estimate to v. That's bad, right? That's violating the triangle inequality. These cannot be the right weights. These cannot be the right distances. So how we're going to do that is lower-- this is what we said, repeatedly lower these distance estimates. I'm going to lower this guy down to equal this thing. In a sense, this constraint was violated. But now we're relaxing that constraint so that this is no longer violated. So relax is a little weird word here. We're using it for historical reasons. But that's what we mean by when we say relax. This thing is a violated constraint. It's got some pressure to be resolved. And so what we're doing is, to resolve it, we're just setting this guy equal to this, so it at least resolves, locally, that constraint. Now, it may violate the triangle inequality other places now that we've done this change. But at least this constraint is now relaxed and satisfied. OK, so relax edge by lowering d of s, v, to this thing. That's what we're going to mean by relaxing an edge. And relaxing an edge is what I'll call safe. It's safe to do. What do I mean by relaxation is safe? It means that as I am computing these shortest path distances, I'm going to maintain this property that each one of these estimates-- sorry, these estimates here-- has the property that it's either infinite or it is the weight of some path to v. So that's the thing the-- relaxation is safe. OK, so each distance estimate, s, v, is weight of some path from s to v or infinite. And this is a pretty easy thing to prove. If I had the invariant that these were all weights of shortest paths, let's try to relax an edge. And we need to show that this property is maintained. Relax edge u, v, OK? Now, if I relax edge u, v, what do I do? I set this thing-- or, sorry, I set this thing, my shortest path distance to v, to be this thing plus this thing. There's a weight of an edge from u to v. Now, by my assumption that we're maintaining that this is the weight of some path in my graph, if this thing is bigger, I'm setting it to the weight of some path on my graph to u, plus an edge from u to v, and so this checks out. So assign d of s, v, to weight of some path. I'm not going to write down all the argument that I just had here. But basically, since this distance estimate was by supposition before the weight of some path to v-- to u, then this is, again, the weight of some path to v. OK, great. So now we're ready to actually go through this algorithm. So DAG relaxation, from over there, initializes all of our distance estimates to equal infinity, just like we did in BFS. Then, set my distance estimate to myself to be 0. Now, it's possible that this might be minus infinity or negative at some point. But right now, I'm just setting it to 0. And either way, 0 is going to upper-bound the distance to s. So in particular, at initialization, anything not reachable from s is set correctly. And s itself is set as an upper bound to the shortest path distance. Now we're going to process each vertex u in a topological sort order. So remember, our input to DAG relaxation is a DAG. So this thing has a topological sort order. We're going to process these vertices in that order. You can imagine we're starting at the top, and all my vertices are-- all my edges are pointed away from me. And I'm just processing each vertex down this topological sort line. And then for each of these vertices, what am I going to do? I'm going to look at all the outgoing neighbors. And if the triangle inequality is violated, I'm going to relax that edge. The algorithm is as simple as that. For each outgoing neighbor of v-- sorry, of u-- I always get u and v mixed up here. If my shortest path estimate to v violates the triangle inequality for an edge, for an incoming edge, then I'm going to set-- relax u, v, i.e. set d, s,v, equal to d, s,u, plus w, u,v. So that's the algorithm. So if I were to take a look at this example graph over here, maybe a is my start vertex. I initialize it to-- AUDIENCE: DAG. JASON KU: This is not a DAG. Thank you. Let's make it a DAG. I claim to you now this is a DAG. In particular, a topological sort order is when there's a path through all the vertices, then there's a unique topological sort order-- a, b, e, f, g, h, d, c. This is a topological order. You can check all the edges. So I'm going to start by setting the-- actually, let's use e. Let's use shortest paths from e. Why not? Shortest paths from e. Vertex a actually comes before e in the topological order. So it has no-- I mean, its shortest path distance, when I initialize, I'm going to initialize this to 0. I'm going to initialize this to infinite, infinite, infinite, infinite, all these things to infinite. These are my estimates. These are not quite the shortest paths yet-- distances. But when I get here, clearly I can't be-- distance to me being infinite can never violate the triangle inequality with something infinite or finite. It doesn't matter, right? So I don't do anything to a. Anything before my source vertex in the topological order can't be visited, because it's before in the topological order. That's kind of the point. There's no path from my source vertex to anything before it in the topological order. So same with b. b is before a in the topological order. Now, I'm at e, and it's possible we are violating triangle inequality, in particular here. I think the shortest path distance to f is infinite. But actually, if I go to e through this edge with a weight 3, I know that this is violating triangle inequality. So actually, this thing is wrong, and I can set it equal to 3. Now, that might not be the shortest path distance. But right now it's a better estimate, so we've set it. Now, I'm moving on. I'm done with this guy. I move to the next vertex in my topological order. And again, I relax edges out of f. OK, so here, looking at 8, 3 plus 8 is better than infinite, so we'll say that that's 11. And 3 plus 2 is better than infinite, so that's 5. Now, I keep going in the topological order. g is the next. 5 plus 1 is 6. OK, so we found a better estimate here. So this 11 is not as good. 6 is better, so we replace it. Here, we haven't visited before. It's still infinite. So 5 plus minus 2 is 3. This is the next in the topological order. 3 plus 9 is bigger than 6, so that's not a shorter path. 3 plus 4 is certainly smaller than infinite, so set that equal to 7. Then, 7 plus 5 is also bigger than 6. And actually, you can confirm that these are all the shortest path distances from e. So this algorithm seems to work. Does it actually work? Let's take a look. The claim to you is that at the end of relaxation, this algorithm, we've set-- claim at end, all the estimates equal shortest path distances. The basic idea here is that if I take the k-th vertex in the topological order, assuming that these distances are all equal for the ones before me in the topological order, I can prove by induction. We can consider a shortest path from s to v, the k-th vertex, and look at the vertex preceding me along the shortest path. That vertex better be before me in the topological order or we're not a DAG. And we've already set its shortest path distance to be equal to the correct thing by induction. So then when we processed u-- s to u to v-- when we processed u in DAG relaxation here, processed the vertex and looked at all its outgoing adjacencies, we would have relaxed this edge to be no greater than that shortest path distance. So this is correct. You can also think of it as the DAG relaxation algorithm for each vertex looks all at its incoming neighbors, assuming that their shortest path distances are computed correctly already. Any shortest path distance to me needs to be composed of a shortest path distance to one of my incoming neighbors through an edge to me, so I can just check all of them. That's what DAG relaxation does. And again, we're looping over every vertex and looking at its adjacencies doing constant work. This, again, takes linear time. OK, so that's shortest paths and a DAG. Next time, we'll look at, for general graphs, how we can use kind of the same technique in an algorithm we call Bellman-Ford. OK, that's it for today.","Relaxing an edge u, v in the context of finding weighted shortest paths means updating the shortest path estimate to v. If the current estimate of the shortest path to v (d_s,v) violates the triangle inequality with respect to u, then relaxing entails setting the estimate d_s,v to the value of d_s,u plus the weight of the edge from u to v (w_u,v). This action corrects the violation, making the constraint locally satisfied.",valid,Intermediate,6.006,11 Weighted Shortest Paths,5cF5Bgv59Sc.en-j3PyPqV-e1s_10_mp4
222,"Who are the instructors involved in teaching the Introduction to Algorithms class, and how are the lectures distributed among them?","[SQUEAKING] [RUSTLING] [CLICKING] JASON KU: Good morning, everybody. STUDENT: Morning-- JASON KU: My name's Jason Ku. I'm going to be teaching this class in Introduction to Algorithms with two other instructors here-- faculty in the department-- Eric Demaine and Justin Solomon. They're excellent people, and so they will be working on teaching this class with me. I will be teaching the first lecture, and we'll have each of them teach one of the next two lectures, and then we'll go from there. This is Intro to Algorithms.","The instructors involved in teaching the Introduction to Algorithms class are Jason Ku, Eric Demaine, and Justin Solomon. Jason Ku will teach the first lecture, while each of the other two instructors will teach one of the next two lectures.",administrative,Advanced,6.006,1 Algorithms and Computation,ZA-tUyM_y7s.en-j3PyPqV-e1s_1_mp4
223,What is the process for dynamically maintaining connected components in a changing graph using sets?,"It's basically-- it's a set type thing, where I can make a set of just a single element, I can take two sets, merge them together, make them their union, and then given an object, I say, which set am I part of, essentially by electing a leader within a set and saying, return me a pointer to that one. And so this can be useful in dynamically maintaining, say, the connected components in a dynamically changing graph supporting the query of, am I in the same component as this other guy? That could be a very useful thing to know about a graph as it's changing. So that's an application of this problem. And they get near-constant performance for a lot of these queries. It's not quite, but pretty close. OK, on the graph side, they solve","The process involves representing components of the graph as sets. For each element, we can make a set of just that single element. When two sets need to be merged, they are combined to form their union. To determine which set an object is a part of, a leader is elected within each set, and a pointer to that leader is returned. This structure allows queries such as determining whether two elements are in the same component, which is useful when maintaining the connected components of a dynamically changing graph, achieving near-constant performance for many queries.",valid,Advanced,6.006,20 Course Review,2NMtS1ecb3o.en-j3PyPqV-e1s_6_mp4
224,What is the main goal when discussing data structures for implementing sets?,"So of course, in today's lecture, now that we set out our goal, which is to fill in-- if I wanted to write code for a set, how could I do it? Now, of course, our goal is to give different data structures that implement these, and then understand them in terms of their efficiency, data storage, correctness, all that good stuff. So before we get into all these ugly details, let me pause for a second. Are there any questions about this basic interface? You all should feel free to stop me any time because this is going to be hella boring if you're not","The main goal is to give different data structures that implement sets and understand them in terms of their efficiency, data storage, and correctness.",administrative,Basic,6.006,3 Sets and Sorting,oS9aPzUNG-s.en-j3PyPqV-e1s_7_mp4
225,What are the two strategies for solving subproblems in dynamic programming?,"3 
Lecture 15: Recursive Algorithms 
Re-using Subproblem Solutions 
• Draw subproblem dependencies as a DAG 
• To solve, either: 
– Top down: record subproblem solutions in a memo and re-use 
(recursion + memoization) 
– Bottom up: solve subproblems in topological sort order (usually via loops) 
• For Fibonacci, n + 1 subproblems (vertices) and < 2n dependencies (edges) 
• Time to compute is then O(n) additions 
1 
# recursive solution (top down) 
2 
def fib(n): 
3 
memo = {} 
4 
def F(i): 
5 
if i < 2: return i 
# base cases 
6 
if i not in memo: 
# check memo 
7 
memo[i] = F(i - 1) + F(i - 2) 
# relation 
8 
return memo[i] 
9 
return F(n) 
# original 
1 
# iterative solution (bottom up) 
2 
def fib(n): 
3 
F = {} 
4 
F[0], F[1] = 0, 1 
# base cases 
5 
for i in range(2, n + 1): 
# topological order 
6 
F[i] = F[i - 1] + F[i - 2] 
# relation 
7 
return F[n] 
# original 
• A subtlety is that Fibonacci numbers grow to Θ(n) bits long, potentially ≫ word size w 
• Each addition costs O(dn/we) time 
• So total cost is O(ndn/we) = O(n + n2/w) time 
",The two strategies are: 1) Top down: record subproblem solutions in a memo and re-use (recursion + memoization). 2) Bottom up: solve subproblems in topological sort order (usually via loops).,valid,Basic,6.006,"Lecture 15 - Dynamic Programming, Part 1 - SRTBOT, Fib, DAGs, Bowling",9eb3e9a51a7b5b60b0f67c2277f8b0ee_MIT6_006S20_lec15_3_pdf
226,What is the purpose of the reweighting scheme in Johnson's algorithm?,"It's really a reduction problem or a reduction algorithm. We reducing from solving kind of signed all-pairs shortest paths, graphs where their weights could be positive or negative, and we're reducing to creating a graph that has the same shortest paths properties, but only has non-negative edge weights. So we're reducing from a signed context to a non-negative weight context. So Johnson's algorithm, what are the steps? Construct Gs from G, just as up here. I make a new vertex s. I put a 0 weight directed edge from s to every vertex. So that's the first step. Second step-- compute E, s,v for all V in V, i.e-- or e.g-- I guess really it should be i.e. because I don't really have another option here-- but by Bellman-Ford. This is just a single run of Bellman-Ford here. Compute. And then there are two possibilities. If there exists a delta s, v that's minus infinity, then abort. Else, make-- or reweight the graph according to this reweighting scheme, by reweighting each edge in my original graph to have weight-- our new weight, which is our old weight, plus our transformation. Now, our transformation is now going to set h, v to this delta s, v. So I'm going to add delta s, u, and subtract delta s, v. That's our reweighting scheme. I'm just identifying h, v with this shortest path distance here. And after I reweighted that, I can just solve all-pairs shortest paths on G prime with Dijkstra. And then compute G shortest path distances from G prime shortest path distances. Compute these distances from the other using this algorithm up here-- can compute distances in G from distances in G prime in linear time-- or sorry, v times linear time, linear time for each s-- for each vertex in my graph. OK, so that's the algorithm. It's basically, correctness is trivial. We already proved-- the whole part of this lecture, the interesting part of this lecture was proving that, if we had a transformation based on a potential function that changed outgoing edges in a symmetrically opposite way as incoming edges, then that preserves shortest paths. And then realizing that the triangle inequality enforces this condition that edge weights will be non-negative under this reweighting, so we find shortest path distances from some other arbitrary vertex, and set our potential functions to be those shortest path distance weights. We do the reweighting, because that reweighting preserves shortest paths, which we already argued. Then we can do-- then this has positive edge weights, so Dijkstra applies. And then computing this takes a small amount of time. OK, what is the running time of this algorithm? So this part, reconstructing this thing, this takes linear time. I'm just adding. I'm just making a new graph of the same size, except I added v edges and one vertex. Computing-- doing Bellman-Ford on this new modified graph, that's just-- I'm doing that once. That takes V times E time. Doing this check, that just takes-- I'm looping over my vertices. That just takes V time. Otherwise, doing this reweighting, I change the weight of every edge. That takes order E time. And then solving G prime-- solving all-pairs shortest paths on the modified edge weight graph with Dijkstra takes V times Dijkstra. That's-- I could use a little bit more board space here. That's V times V log, V plus E time, which is actually the running time that we're looking for. I wanted to reduce to not using more than this time. We used this amount of time. Let's make sure we still didn't use even more. After that, we compute these paths, as proofed before, in V times V plus E, which is smaller than that. And so summing up all of these running times, this one dominates. And so Johnson's can solve signed weighted all-pairs shortest paths, signed all-pairs shortest paths, not in V times Bellman-Ford, like we had before up here, but faster, in nearly linear for sparse graphs, just without this log factor. So we got quite a big improvement. So that's the nice thing about all-pairs shortest paths is that, really, we don't have to incur this big cost in the context of negative weights. Essentially, we just run Bellman-Ford once to see if there is a negative weight cycle in my graph. If it is, I save a lot of work by stopping early. So that's Johnson's. That's the end of our graphs lectures. We'll be having a review and problem session about how to solve problems, graph problems using this material. But we've talked about a lot of different things so far. We've talked about graph reachability, connected components, detecting cycles, detecting topological sort orders of a DAG. We've talked about finding negative weight cycles, single source shortest path algorithms, and now finally, today, all-pairs shortest path algorithms, with a new algorithm that's really not an entirely new algorithm. We didn't have to do any proof by induction here. Really, the heavy work that's happening is we're reducing to using either Dijkstra or Bellman-Ford to do the heavy lifting of finding single source shortest paths efficiently. So Johnson's is really just glue to transform a graph in a clever way, and then reducing to using some of the shortest paths algorithms faster. So that's our unit on graphs. Our next lecture, we'll start talking about a general form of, not presenting you with an algorithm, but how to design your own algorithm in the context of dynamic programming. So see you next lecture.","The reweighting scheme in Johnson's algorithm is used to transform a graph with signed edge weights (which could be positive or negative) into one with only non-negative edge weights, without altering the shortest path properties. This transformation allows Dijkstra's algorithm, which requires non-negative edge weights, to be used efficiently to find all-pairs shortest paths after the initial Bellman-Ford run to detect negative weight cycles.",valid,Advanced,6.006,14 APSP and Johnson,EmSmaW-ud6A.en-j3PyPqV-e1s_6_mp4
227,What is a simplicial complex?,"which is the introduction to computer graphics course. In fact, my background was working in an animation studio for a little bit of time, and got one movie credit out of it until they changed the standards for movie credits, and then that stopped happening. But in any event, if you watch-- what's that movie-- Up, with the old man. If you hit pause at just the right moment, you can find me right above the list of babies that were born during production. But in any event-- although computer graphics might not sound like an algorithmic discipline, I'll try to convince you guys that, in some sense, you could take just about anybody in our department, have them teach 6.006, and give a similar talk that, like, the material that you've encountered in this course is going to be relevant to your life. The other course that I teach that might be of interest-- and actually, is a little more theoretically flavored-- that I teach is 6.838. So since Erik so kindly put my name on the board here, I guess I can draw The So the main object of interest in 6.838 is a particular thing called the simplicial complex. Usually, in 6.006, we spend a lot of time thinking about graphs. Let me draw you a graph. So I'm going to take a square and subdivide it. And now, let's say I put edges diagonally like that. Now, in 6.006, this thing is just a bunch of nodes connected by edges. In fact, if I took this edge and I moved it down or something, it would be the same graph. But of course, in a lot of computer graphics applications, this thing also looks an awful lot like a square. And the reason is that, of course, the graph here contains triangles inside of it. And so for instance, maybe I think of my graph as a collection of vertices, a collection of edges. This is the sort of notation we've seen before. And then I add a third thing to my description, which is a set of triplets. That's a set of triangles here. And we can take a lot of the algorithms that we've talked about in this class and extend it to this case. For example, here's a deceptively annoying one. Let's say that I want the shortest path between two vertices of my graph. We certainly have learned Dijkstra's algorithm. That's one technique to do that. And indeed, common practice in computer graphics, which is shameful, is on your triangle mesh, if you want the shortest path between two vertices, run Dijkstra's algorithm on the edges. And let's see if that works really quick. Let's say that I want the shortest path between-- and, by the way, I'm going to assume the length of my edges are the lengths as I've drawn them on the board here. So it's like 1, 1, square root of 2. OK. So let's say I want the shortest path between the bottom left and the upper right. If I run Dijkstra's algorithm, we're in good shape, right? We get-- I'll let you do the computations at home. You'll get the path that is these two edges. But here's a really annoying thing. Let's say, instead, I wanted the shortest path from the upper left to the lower right. If I run Dijkstra's algorithm on this triangulated square, what's going to be the shortest path? Yeah. In fact, there's a bunch of them. One of them might go all the way down, and then all the way to the right. What's the length of this path? 1, 2, 3, 4. Is that the length of the shortest path? Well, probably not. Well, we would like our shortest path to do something like that. But graphs don't know how to talk to triangles. And this is going to be a problem. In fact, it wasn't until fairly recently [INAUDIBLE] history terms that we were able to kind of work out the correct algorithm for the shortest path in a triangulated domain like this. And that's the runtime that we would expect. This is called MMP. I'm guessing Erik and Jason could do a better job describing it than I can. But the basic idea of the MMP algorithm actually is a really-- happens to be a nice extension of the way that we taught Dijkstra's algorithm in 6.006, because they really do keep track of these level sets of the distance function. But now, the level sets have to-- oops-- have to window and edge like that when I compute shortest path, which is a giant headache. This is one of these algorithms that was known in theory about 10 years before anybody bothered to implement it in a way that they could convince themselves it ran in n log n time. And nowadays, there's a cottage industry in computer graphics research papers to implement this and then speed it up in different ways. And sadly, the reality is that a different algorithm that we cover in 6.838 called fast marching-- which doesn't actually give you the shortest path, but some approximation thereof-- is faster, easier to use, and basically indistinguishable. In any event, in 6.838, we kind of have an interesting dual-mindset. We'll talk about a lot of algorithms that look like what we've done in whatever this class is-- 6.006. But at the same time, start to have a more geometric flavor, and we don't worry quite as much about [INAUDIBLE].. So in our computation model, oftentimes, we're kind of OK with real numbers, because that's not where the headache is. And of course, when you write code in this class, you use double-precision floating-point. If you're more responsible, like in Jason's previous lecture, you should probably keep track of the number of operations to make sure that your error is counted. But I'm not sure that we really bother with that. In any event, this allows us to have two different mindsets. There's one mindset, which is discrete. There's another mindset, which is smooth. We think about understanding geometry, like these triangular domains, as an approximation of a smooth surface. And then we might want to do stuff like compute curvature and so on, which is really associated with computing derivatives, which of course, we'll have on these kinds of simplicial objects. And that leads to this really fun area of math and computer science, whatever, called discrete differential geometry, which sounds like a contradiction in terms. And it's something that we covered in quite some detail in this course. So we build up, all of calculus, that the only calculations you're left to do are on the vertices and edges and triangles of a triangle mesh. And get pretty far, including some constructions of topology, like the Duran complex, and so on. I would argue, actually, if you take our course and then the differential geometry courses in that department, somehow, some of the indices and headaches that you often encounter in that world are much more concrete when you try to make them work on a mesh. In any event, I think I've already spent all of my time.","A simplicial complex is an object of interest in computer graphics that consists of a set of vertices, edges, and triangles.",valid,Basic,6.006,21 AlgorithmsNext Steps,4nXw-f6NJ9s.en-j3PyPqV-e1s_8_mp4
228,What is the base case in the induction proof for the correctness of the birthday matching algorithm?,"2 
Lecture 1: Introduction 
Correctness 
• Programs/algorithms have ﬁxed size, so how to prove correct? 
• For small inputs, can use case analysis 
• For arbitrarily large inputs, algorithm must be recursive or loop in some way 
• Must use induction (why recursion is such a key concept in computer science) 
• Example: Proof of correctness of birthday matching algorithm 
– Induct on k: the number of students in record 
– Hypothesis: if ﬁrst k contain match, returns match before interviewing student k + 1 
– Base case: k = 0, ﬁrst k contains no match 
– Assume for induction hypothesis holds for k = k0, and consider k = k0 + 1 
– If ﬁrst k0 contains a match, already returned a match by induction 
– Else ﬁrst k0 do not have match, so if ﬁrst k0 + 1 has match, match contains k0 + 1 
– Then algorithm checks directly whether birthday of student k0 + 1 exists in ﬁrst k0 
Efﬁciency 
• How fast does an algorithm produce a correct output? 
– Could measure time, but want performance to be machine independent 
– Idea! Count number of ﬁxed-time operations algorithm takes to return 
– Expect to depend on size of input: larger input suggests longer time 
– Size of input is often called ‘n’, but not always! 
– Efﬁcient if returns in polynomial time with respect to input 
– Sometimes no efﬁcient algorithm exists for a problem! (See L20) 
• Asymptotic Notation: ignore constant factors and low order terms 
– Upper bounds (O), lower bounds (Ω), tight bounds (Θ) 
∈, =, is, order 
– Time estimate below based on one operation per cycle on a 1 GHz single-core machine 
– Particles in universe estimated < 10100 
input constant logarithmic linear 
log-linear 
quadratic 
polynomial 
exponential 
n 
Θ(1) 
Θ(log n) 
Θ(n) 
Θ(n log n) 
Θ(n2) 
Θ(nc) 
2Θ(nc) 
1000 
1 
≈ 10 
1000 
≈ 10,000 
1,000,000 
1000c 
21000 ≈ 10301 
Time 
1 ns 
10 ns 
1 µs 
10 µs 
1 ms 
103c−9 s 
10281 millenia 
","The base case is when k = 0, meaning the first k contains no match.",valid,Basic,6.006,Lecture 1 - Introduction,477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_2_pdf
229,What is the purpose of using asymptotic notation in algorithm analysis?,"2 
Lecture 1: Introduction 
Correctness 
• Programs/algorithms have ﬁxed size, so how to prove correct? 
• For small inputs, can use case analysis 
• For arbitrarily large inputs, algorithm must be recursive or loop in some way 
• Must use induction (why recursion is such a key concept in computer science) 
• Example: Proof of correctness of birthday matching algorithm 
– Induct on k: the number of students in record 
– Hypothesis: if ﬁrst k contain match, returns match before interviewing student k + 1 
– Base case: k = 0, ﬁrst k contains no match 
– Assume for induction hypothesis holds for k = k0, and consider k = k0 + 1 
– If ﬁrst k0 contains a match, already returned a match by induction 
– Else ﬁrst k0 do not have match, so if ﬁrst k0 + 1 has match, match contains k0 + 1 
– Then algorithm checks directly whether birthday of student k0 + 1 exists in ﬁrst k0 
Efﬁciency 
• How fast does an algorithm produce a correct output? 
– Could measure time, but want performance to be machine independent 
– Idea! Count number of ﬁxed-time operations algorithm takes to return 
– Expect to depend on size of input: larger input suggests longer time 
– Size of input is often called ‘n’, but not always! 
– Efﬁcient if returns in polynomial time with respect to input 
– Sometimes no efﬁcient algorithm exists for a problem! (See L20) 
• Asymptotic Notation: ignore constant factors and low order terms 
– Upper bounds (O), lower bounds (Ω), tight bounds (Θ) 
∈, =, is, order 
– Time estimate below based on one operation per cycle on a 1 GHz single-core machine 
– Particles in universe estimated < 10100 
input constant logarithmic linear 
log-linear 
quadratic 
polynomial 
exponential 
n 
Θ(1) 
Θ(log n) 
Θ(n) 
Θ(n log n) 
Θ(n2) 
Θ(nc) 
2Θ(nc) 
1000 
1 
≈ 10 
1000 
≈ 10,000 
1,000,000 
1000c 
21000 ≈ 10301 
Time 
1 ns 
10 ns 
1 µs 
10 µs 
1 ms 
103c−9 s 
10281 millenia 
",Asymptotic notation is used to ignore constant factors and low order terms when analyzing algorithm efficiency.,valid,Basic,6.006,Lecture 1 - Introduction,477c78e0af2df61fa205bcc6cb613ceb_MIT6_006S20_lec1_2_pdf
234,What does NumPy add?," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
Pylab  
§NumPy adds vectors,  matrices,  and many high-level 
mathematical functions 
§SciPy adds mathematical  classes and functions useful  
to scientists 
§MatPlotLib adds an object-oriented API for plotting 
§PyLab combines the other libraries to provide a
MATLAB- like interface
®
 
6.0002  LECTURE 5 
29 ââ
","NumPy adds vectors, matrices, and many high-level mathematical functions.",invalid,Basic,6.2002,Lecture 5: Random Walks,508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_29_pdf
236,What does the variable 'n' represent in the process of evaluating a model with randomized sampling?,"!	!	 	
 
Let D be the original data set 
    n be the number of random samples  
 
 
 usually n between 20% and 50% 
    k be number of trials 
 
testResults = [] 
for i in range(k) 
    randomly select n elements for testSet,  
       keep rest for training 
    model = buildModel(training) 
    testResults.append(test(model, testSet)) 
 
Average testResults 

	

;G
","n' represents the number of random samples selected from the original data set, usually between 20% and 50% of the total data set.",valid,Basic,6.2002,Lecture 10: Understanding Experimental Data (cont.),aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10_38_pdf
238,Why are all dates not equally likely for birthdates in a demographic context?," 
 
 
 
 
 
 
  
 
 
But All Dates Are Not Equally Likely
Are you exceptional?
6.0002 LECTURE 4 
Chart
22
Chart © Matt Stiles / The Daily Viz. All rights reserved. This content is excluded from our
Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.
","Because certain birthdates are influenced by seasonal, cultural, or social factors, making some dates more common than others.",valid,Intermediate,6.2002,Lecture 4: Stochastic Thinking,5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_22_pdf
239,What is the purpose of calling pylab.figure() before testFits in the given code?," 
pylab.figure() 
testFits(models1, degrees, xVals2, yVals2, 
         'DataSet 2/Model 1') 
pylab.figure() 
testFits(models2, degrees, xVals1, yVals1, 
         'DataSet 1/Model 2') 
	


s1,
S
s2,
s2,
s2,
s1,
s1,
","Calling pylab.figure() is used to create a new figure or plotting window for the subsequent plot commands, ensuring that each call to testFits() creates its own separate plot.",invalid,Intermediate,6.2002,Lecture 10: Understanding Experimental Data (cont.),aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10_21_pdf
241,What are experimental devices used for?,")""%)""%
""""%+
Experimental devices that help us to understand 
something that has happened or to predict the future
56%
3%%
3)%%


	


Images © sources unknown. All rights reserved. This content is excluded from our Creative
Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use.
",Experimental devices help us to understand something that has happened or to predict the future.,valid,Basic,6.2002,Lecture 1: Introduction and Optimization Problems,0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_6_pdf
243,What is the purpose of using 'pylab.polyval' in the code?,"6
*)6

 	 
	

G
xVals = xVals + (20,) 
yVals = xVals 
pylab.plot(xVals, yVals, label = 'Actual values') 
estYVals = pylab.polyval((a,b,c), xVals) 
pylab.plot(xVals, estYVals, 'r--', label = 'Predictive values') 
print('R-squared = ', rSquared(yVals, estYVals)) 
(20,) 
12 D
","It is used to evaluate the polynomial fit with coefficients (a,b,c) for the given xVals, to get the estimated y-values (estYVals) for plotting predictive values.",invalid,Intermediate,6.2002,Lecture 10: Understanding Experimental Data (cont.),aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10_28_pdf
244,What are the core concepts in graph-theoretic models?,"/	%$&%#&, 
 5$''/0#0)*0*)'7*"".,#/,03.
.'1*)/#$,/$)*))0)05*.&/*'()0/<0#7
'/*/3,,*.0$).)*)0#*//0.303./
W $)$)""/-3)/*'$)&/05)'()0/D$/0#.
,0#.*(0*
W $)$)""0#'/06,)/$4,0#05)'()0/E&
/#*.0/0,0#,.*'(F
W .11*)$)""0#"".,#$)0*/0/**))0'()0/
E&"".,#,.11*),.*'(F
W $)$)""0#(*/0$)0570*/,.0/0/*
*))0'()0/E&0#($)C30B(6C *5,.*'(F
Q>KKKMN
T
","Graph-theoretic models involve the study and analysis of graphs, which are mathematical structures used to model pairwise relations between objects. Key concepts include nodes (or vertices), which represent objects, and edges, which represent the relationships between objects. These models are widely used in computer science for a variety of applications including network analysis, pathfinding, and optimizing connections.",valid,Advanced,6.2002,Lecture 3: Graph-theoretic Models,69b5b28067ecf1769a6143453d77eba1_MIT6_0002F16_lec3_9_pdf
245,What is polynomial regression in the context of fitting lines to data?,"In a little bit, I'll show you where that mystery data came from. But here's another set of data that I've plotted out. I could run the same thing. I could run exactly the same code and fit a line to it. And if I do it, I get that. What do you think? Good fit? Show of hands, how many people like this fit to the data? Show of hands, how many people don't like this fit to the data? Show of hands, how many hope that I'll stop asking you questions? Don't put your hands up. Yeah, thank you. I know. Too bad. It's a lousy fit. And you kind of know it, right. It's clear that this doesn't look like it's coming from a line, or if it is, it's a really noisy line. So let's think about this. What if I were to try a higher order degree. Let's change the one to a two. So I'm going to come back to it in a second. I've changed the one to a two. That says I'm still using the polynomial fit, but now I'm going to ask what's the best fitting parabola, ax squared plus bx plus c. Simple change. Because I was using polyval, exactly the same code will work. It's going to do the fit to it. This is, by the way, still an example of linear regression. So think of what I'm doing now. I have a three-dimensional space. One axis is a values. Second axis is b values. Third axis is c values. Any point in that space describes a parabola, and every point in that space describes every possible parabola. And now you've got to twist your head a little bit. Put a four-dimensional surface on that three-dimensional basis, where the point in that surface is the value of that objective function. Play the same game. And you can. It's just a higher-dimensional thing. So you're, again, going to walk down the gradient to find the solution, and be glad you don't have to write this code because PyLab will do it for you freely. But it's still an example of regression, which is great. And if we do that, we get that fit. Actually just to show you that, I'm going to run it, but it will do exactly the same thing. If I go over to Python-- wherever I have it here-- I'm going to change that order of the model. Oops, it went a little too far for me. Sorry about that. Let me go back and do this again. There's the first one, and there's the second one. So I could fit different models to it. Quadratic clearly looks like it's a better fit.","Polynomial regression involves fitting a polynomial model of higher order than a linear model to a set of data points. It is still considered a form of linear regression. For example, using a parabola (ax^2 + bx + c) instead of a line to fit the data.",valid,Basic,6.2002,9 Understanding Experimental Data,vIFKGFl1Cn8.en-qlPKC2UN_YU_12_mp4
247,How does the implementation of k-means in this context avoid ending up with empty clusters?,"And we'll look at what happens when we scale and when we don't scale. And that's why my getData function has this parameter to scale. It either creates a set of examples with the attributes as initially or scaled. And then there's k-means. It's exactly the algorithm I showed you with one little wrinkle, which is this part. You don't want to end up with empty clusters. If I tell you I want four clusters, I don't mean I want three with examples and one that's empty, right? Because then I really don't have four clusters. And so this is one of multiple ways to avoid having empty clusters. Basically what I did here is say, well, I'm going to try a lot of different initial conditions. If one of them is so unlucky to give me an empty cluster, I'm just going to skip it and go on to the next one by raising a value error, empty cluster. And if you look at the code, you'll see how this value error is used. And then try k-means. We'll call k-means numTrial times, each one getting a different set of initial centroids, and return the result with the lowest dissimilarity.","The k-means implementation avoids empty clusters by trying multiple initial conditions. If an initial condition results in an empty cluster, it raises a 'value error, empty cluster' and skips that particular run. The k-means function is then retried 'numTrial' times with different sets of initial centroids, and it returns the result with the lowest dissimilarity.",invalid,Advanced,6.2002,12 Clustering,esmzYhuFnds.en-qlPKC2UN_YU_13_mp4
248,What is one benefit of using simulations involving random walks?," 
 
 
 
 
 
 
 
 
 
 
 
  
 
  
 
Simulations Are Used a Lot
To model systems that are mathematically intractable
To extract useful intermediate results
Lend themselves to development by successive
refinement and “what if” questions
Start by simulating random walks
6.0002 LECTURE 4 
25
",To model systems that are mathematically intractable.,valid,Intermediate,6.2002,Lecture 4: Stochastic Thinking,5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_25_pdf
249,Why is fair roulette considered a better bet than European or Las Vegas roulette?,"100,000, and a million. And what do we see as we look at this? Well, right away we can see that fair roulette is usually a much better bet than either of the other two. That even with only 1,000 spins the return is negative. And as we get more and more as I got to a million, it starts to look much more like closer to 0. And these, we have reason to believe at least, are much closer to true expectation saying that, while you break even in fair roulette, you'll lose 2.7% in Europe and over 5% in Las Vegas, or soon in Massachusetts. All right, we're sampling, right? That's why the results will change, and if I ran a different simulation with a different seed I'd get different numbers. Whenever you're sampling, you can't be guaranteed to get perfect accuracy. It's always possible you get a weird sample. That's not to say that you won't get exactly the right answer. I might have spun the wheel twice and happened to get the exact right answer of the return. Actually not twice, because the math doesn't work out, but 35 times and gotten exactly the right answer. But that's not the point. We need to be able to differentiate between what happens to be true and what we actually know, in a rigorous sense, is true. Or maybe don't know it, but have real good reason to believe it's true. So it's not just a question of faith. And that gets us to what's in some sense the fundamental question of all computational statistics, is how many samples do we need to look at before we can have real, justifiable confidence in our answer? As we've just seen-- not just, a few minutes ago-- with the coins, our intuition tells us that it depends upon the variability in the underlying possibilities. So let's look at that more carefully. We have to look at the variation in the data. So let's look at first something called variance.","Fair roulette is considered a better bet because, even with only 1,000 spins, the return is negative, but as the number of spins increases to a million, the return approaches closer to 0. This indicates that, while you break even in fair roulette, you'll lose 2.7% in European roulette and over 5% in Las Vegas roulette.",valid,Basic,6.2002,6 Monte Carlo Simulation,OgO1gpXSUzU.en-j3PyPqV-e1s_11_mp4
251,What is the purpose of a random walk?," 
 
 
Lecture 5:  Random 
Walks 
6.0002  LECTURE 5 
1 
","The lecture content does not directly provide an answer to this question, so it is important to refer to other resources about random walks to get a comprehensive answer.",empty,Intermediate,6.2002,Lecture 5: Random Walks,508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_1_pdf
253,What is the purpose of a confidence interval?,"/4112
	


'@CC...+%C.%2,:GAA3HI83G
",Confidence intervals provide a range of values used to estimate the true parameter of a population with a given level of confidence.,empty,Intermediate,6.2002,Lecture 7: Confidence Intervals,3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7_25_pdf
254,What does the term 'shellcode address' refer to?,"The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation, or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu.",The address of the memory region that contains the shellcode.,empty,Basic,6.2002,14 Classification and Statistical Sins,K2SC-WPdT6k.en-qlPKC2UN_YU_1_mp4
255,"What are the different strategies used in the testGreedys function to allocate calories, and how do they differ?",";
/
def testGreedys(foods, maxUnits):
print('Use greedy by value to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits, Food.getValue)
print('\nUse greedy by cost to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits,
lambda x: 1/Food.getCost(x))
print('\nUse greedy by density to allocate', maxUnits,
'calories')
testGreedy(foods, maxUnits, Food.density)
names = ['wine', 'beer', 'pizza', 'burger', 'fries',
'cola', 'apple', 'donut', 'cake']
values = [89,90,95,100,90,79,50,10]
calories = [123,154,258,354,365,150,95,195]
foods = buildMenu(names, values, calories)
testGreedys(foods, 750)
)
	

:
","The testGreedys function uses three different strategies to allocate calories: 1) Greedy by value: This strategy chooses foods based on their value, using the Food.getValue function. 2) Greedy by cost: This strategy chooses foods based on their cost-effectiveness, using a lambda function that prioritizes lower cost by calculating 1/Food.getCost(x). 3) Greedy by density: This strategy chooses foods based on their value-to-calories ratio, using the Food.density function. Each strategy prioritizes a different attribute of the foods to optimize the total value within a given calorie budget.",invalid,Advanced,6.2002,Lecture 1: Introduction and Optimization Problems,0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_28_pdf
256,What differentiates supervised from unsupervised machine learning in terms of the input data and the goal of the model?," 
 
 
 
 
 
 
 
 
Machine  Learning Paradigm  
§Observe set of examples: training data 
§Infer something about process that generated that 
data 
§Use inference to make predictions about previously 
unseen data: test data 
§Supervised: given a set of feature/label pairs, find a 
rule that predicts the label associated with a previously 
unseen input 
§Unsupervised: given a set of feature vectors (without 
labels) group them into “natural clusters” 
6.0002  LECTURE 12 
3 
","In supervised machine learning, the model is given a set of feature/label pairs and aims to find a rule that predicts the label associated with a previously unseen input. In contrast, unsupervised machine learning is provided with a set of feature vectors without labels and seeks to group the data into 'natural clusters.'",valid,Advanced,6.2002,Lecture 12: Clustering,367ebcbfde99ec18e14e87b69f564035_MIT6_0002F16_lec12_3_pdf
257,Why is it important to fix the values of mu and sigma when integrating over values of x using the Gaussian function?,"That gives us all the different integration methods. I'm not going to show you the code for Gaussian since I showed it to you a couple of minutes ago. But I wanted you to remember that it takes three arguments, x, mu, and sigma. Because when we get down here to the integration, we'll pass at the function Gaussian and then the values that we want to integrate over. So those will be the values that x can take upon. And that will change as we go from mu minus the number of standard deviations times sigma to mu plus the number of standard deviations times sigma. And then, this is the optional fourth argument, the tuple, mu, and sigma. Why do I need to pass that in? Because Gaussian is a ternary argument, or a function that takes three values. And I'm going to integrate over values of x so I have to fix mu and sigma to constants, which is what I'm doing down here. And then I'll take the zeroth value, which is its estimate of the integral. All right, so that's the new thing. The rest of the code is all stuff you've seen. For t and range number of trials, I'm going to choose a random mu between minus 10 and 10 and a random sigma between 1 and 10. It doesn't matter what those constants are. And then for the number of standard deviations in 1, 1.96, and 3, I'm going to integrate Gaussian over that range. And then we're just going to see how many of them fall within that range. In some sense, what we're doing is we're checking the empirical rule. We're saying, take the Gaussian. I don't care what mu and sigma are. It doesn't matter. The empirical rule will still hold, I think. But we're just checking it here, OK? Well, here are the results. So from mu equals 9 and sigma equals 6, I happened to choose those, we'll see the fracture within 1, fraction within 1.96 and 3. And so for these random mus and sigmas, you can see that all of them-- and you can set them to whatever you want when you get your hand them the code. Essentially, what we have is, whoops, the empirical rule actually works. One of those beautiful cases where you can test the theory and see that the theory really is sound. So there we go. So why am I making such a big deal of normal distributions? They have lots of nice mathematical properties, some of which we've already talked about. But all of that would be irrelevant if we didn't see them. The good news is they're all over the place. I've just taken a few here.","The values of mu and sigma need to be fixed because the Gaussian function is a ternary function that takes three values: x, mu, and sigma. When integrating over values of x, mu and sigma must be fixed as constants to accurately compute the integral over the specified range of x.",valid,Advanced,6.2002,7 Confidence Intervals,rUxP7TM8-wo.en-qlPKC2UN_YU_5_mp4
260,What is the purpose of the wormholes dictionary in the OddField class?," 
 
 
 
 
A  Subclass of Field, part 1  
class OddField(Field):  
def __init__(self, numHoles = 1000,  
xRange = 100, yRange = 100):  
Field.__init__(self)  
self.wormholes = {}  
for w in range(numHoles):  
x = random.randint(-xRange, xRange)  
y = random.randint(-yRange, yRange)  
newX = random.randint(-xRange, xRange)  
newY = random.randint(-yRange, yRange)  
newLoc = Location(newX, newY)  
self.wormholes[(x, y)] = newLoc  
6.0002  LECTURE 5 
36 
","The wormholes dictionary in the OddField class maps a coordinate pair (x, y) to a new location (newLoc) created using random integers within a specified range.",valid,Intermediate,6.2002,Lecture 5: Random Walks,508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_36_pdf
263,How do sample size and variance affect the confidence in an estimate?," 
 
 
  
 
 
 
 
 
 
 
 
 
  
 
  
 
Why the Difference in Confidence?  
Confidence in our estimate depends upon two things  
Size of sample (e.g., 100 versus 2) 
Variance of sample (e.g., all heads versus 52 heads) 
As the variance grows, we need larger samples to have 
the same degree of confidence 
6.0002 LECTURE 6 
9
","Confidence in an estimate depends on two factors: the size of the sample and the variance of the sample. A larger sample size generally increases confidence, while higher variance requires larger samples to achieve the same degree of confidence.",valid,Advanced,6.2002,Lecture 6: Monte Carlo Simulation,5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_9_pdf
264,"How does the function rollDie simulate a random process, and what is the expected outcome when testRoll is executed with n=10?","  
 
 
  
 
 
  
 
 
    
 
 
 
 
    
 
  
 
    
 
    
 
        
 
 
 
    
 
Implementing a Random Process  
import random 
def rollDie(): 
""""""returns a random int between 1 and 6"""""" 
return random.choice([1,2,3,4,5,6]) 
def testRoll(n = 10): 
result = '' 
for i in range(n): 
result = result + str(rollDie()) 
print(result) 
6.0002 LECTURE 4 
9
","The function rollDie simulates a random process by using the random.choice method to return a random integer between 1 and 6, simulating the roll of a die. When testRoll is executed with n=10, it calls rollDie 10 times, concatenating the results into a string, and then prints it. The expected outcome is a string of 10 numbers, each ranging from 1 to 6, representing the results of 10 simulated die rolls.",valid,Advanced,6.2002,Lecture 4: Stochastic Thinking,5b4ec0ef29910b74e6a4bbd5ccf4dda5_MIT6_0002F16_lec4_9_pdf
265,What is the main question related to the 0/1 Knapsack Problem discussed?,"§ Do these condi<ons hold? 
What About 0/1 Knapsack Problem? 
6.0002 LECTURE 2 
21 
Ques<ons 2 and 3 
",Questions 2 and 3 address whether the conditions hold for the 0/1 Knapsack Problem.,empty,Basic,6.2002,Lecture 2: Optimization Problems,3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_21_pdf
266,"Why might a 16th order polynomial model not be suitable for explaining a physical process, despite its high accuracy in fitting data points?","4, 8, and 16. Now you can see that model 2, that's the green line here. That's the one that we saw before. It's basically a parabolic kind of arc. It kind of follows the data pretty well. But if I look at those r-squared values. Wow, look at that. Order 16 fit accounts for all but 3% of the variation in the data. It's a great fit. And you can see. You can see how it follows. It actually goes through most, but not quite all, of the data points. So it's following them pretty well. OK, so if that's the case, the order 16 fit is really the best fit. Should we just use it? And I left you last time with that quote that says, from your parents, right, your mother telling you, just because you can do something doesn't mean you should do something. I'll leave it at that. Same thing applies here. Why are we building the model? Remember, I said two reasons. One is to be able to explain the phenomena. And the second one is to be able to make predictions. So I want to be able to explain the phenomena in the case of a spring, with things like it's linear and then that gives me a sense of a linear relationship between compression and force. In this case, a 16th order model, what kind of physical process has an order 16 variation? Sounds a little painful. So maybe not a great insight into the process. But the second reason is I want to be able to predict future behavior of this system. In the case of this spring, I put a different weight on than I've done before. I want to predict what the displacement is going to be. I've done a set of trials for an FDA approval of a drug. Now I want to predict the effect of a treatment on a new patient. How do I use the model to help me with that? One that maybe not so good, currently, I want to predict the outcome of an election. Maybe those models need to be fixed from, at least, what happened the last time around. But I need to be able to make the prediction. So another way of saying it is, a good model both explains the phenomena and let's me make the predictions. OK, so let's go back, then, to our example. And before I do it, let me tell you where that data came from. I actually built that data by looking at another kind of physical phenomenon. And it was a lot of them. Things that follow a parabolic arc. So for example, comets. Any particle under the influence of a uniform gravitational field follows a parabolic arc, which","Although a 16th order polynomial model provides a high accuracy fit, accounting for all but 3% of the variation in the data, it may not be suitable for explaining a physical process because such complexity does not offer insight into the physical phenomena. Most physical processes do not exhibit an order 16 variation, making it unlikely that the model provides meaningful understanding. Additionally, effective models should both explain the phenomena and allow for reliable predictions, which might not be the case with such a high-order polynomial.",valid,Advanced,6.2002,10 Understanding Experimental Data cont,fQvg-hh9dUw.en-qlPKC2UN_YU_5_mp4
267,Why is having a small training error not sufficient for a great model?,"All right, the green line still is doing not a bad job. The purple line, boy, is fitting it really well. And again, notice here's the best fit. That's amazing. That is accounting for all but 0.4% of the variation in the data. Great fit. Order 16. Came from an order 2 thing. All right, what about the second data set? Oh, grumph. It also says order 16 fit is the best fit. Not quite as good. It accounts for all but about 2% of the variation. Again, the green line, the red line, do OK. But in this case, again, that purple line is still the best fit. So I've still got this puzzle. But I didn't quite test what I wanted, right? I said I want to see how well it predicts new behavior. Here what I did was I took two datasets, fit the model, and I got two different fits, one for each dataset. They both fit well for order 16. But they're not quite right. OK, so best fitting model is still order 16 but we know it came from an order 2 polynomial. So how could I will get a handle on seeing how good this model is? Well, what we're seeing here is coming from training error. Or another way of saying it is, what we're measuring is how well does the model perform on the data from which it was learned? How well do I fit the model to the training data? I want a small training error. And if you think about it, go back to the first example, when I fit a line to this data, it did not do well. It was not a good model. When I fit a quadratic, it was pretty decent. And then I got better and better as I went on. So I certainly need at least a small training error. But it's, to use the mathematical terms, a necessary, but not sufficient condition to get a great model. I need a small training error, but I really want to make sure that the model is capturing what I'd like. And so for that, I want to see how well does it do on other gen data, generated from the same process, whether it's weights on springs, different comets besides Haley's comet, different voters than those surveyed when we tried to figure out what's going to happen in an election. And I'm set up to do that, by using a really important tool called, validation or cross-validation. We set the stage, and then we're going to do the example. I'm going to get a set of data. I want to fit a model to it, actually, different models, different degrees, different kinds of models. To see how well they work, I want to see how well they predict behavior under other data than that from which I did the training. So I could do that right here.","Having a small training error is necessary because it indicates how well the model performs on the data from which it was learned. However, it is not sufficient because it does not guarantee that the model will perform well on new, unseen data. To ensure a model is capturing the underlying process, it's important to validate it using other generated data from the same process, which can be done through methods like validation or cross-validation.",valid,Advanced,6.2002,10 Understanding Experimental Data cont,fQvg-hh9dUw.en-qlPKC2UN_YU_9_mp4
268,What does the simulation reveal about the relationship between the number of steps taken in a random walk and the distance traveled by the drunk?,"which is the drunk class. Then the origin, distances, and for t in range number of trials, we'll just do it, and then we'll return the distances. So it's initialized to the empty list. So we're going to return a list for however many trials we do, how far the drunk ended up from the origin. Then we can average that, and we look at the mean. Maybe we'll look at the min or the max. Lots of different questions we could ask about the behavior. And now we can put it all together here. So drunkTest will take a set of different walk lengths, a list of different walk lengths, the number of trials, and the class. And for a number of steps and walk lengths, distances will be simWalks of number of steps, numTrials, dClass. And then I'm going to just print some statistics. You may or may not have seen this. This is something that's built in to Python. I can ask for the name of a class. So dClass, remember, is a class, and _name_ will give me the name of the class. Might be usual, it might be drunk, in this case. So let's try it. So the code we've looked at. So let's go down here, and we'll run it, and we'll try it for walks of 10, 100, 1,000, and 10,000 steps. And we'll do 100 trials. Here's what we got. So my question to you is does this look plausible? What is it telling us here? Well, it's telling us here that the length of the walk actually doesn't really affect-- the number of steps doesn't affect how far the drunk gets. There's some randomness. 8.6, 8.57, 9.2, 8.7. Not much variance. So we've done this simulation and we've learned something, maybe. So does this look plausible? We can look at it here. I've just transcribed it. What do you think? Well, go ahead. AUDIENCE: I was going to say, it seems plausible because after the first two steps, there's a 50% chance he's going closer to the origin. And a 50% chance he's going away from it. JOHN GUTTAG: So we have at least one vote for plausible, and it's certainly a plausible argument. Well, one of the things we need to learn to do is whenever we build a simulation, we need to do what I call a sanity check to see whether or not the simulation actually makes sense. So if we're going to do a sanity check, what might we do in this case? We should try it on cases where we think we know the answer. So we say, let's take a really simple case where we're pretty sure we know what the answer is. Let's run our simulation and make sure it gives us the right answer for this simple case. So if we think of a sanity check here, maybe we should look at these numbers. We just did it. We know how far the drunk should get in zero steps. How far should the drunk move in zero steps? Zero. How far should the drunk move in one steps? We know that should be one. Two steps, well, we knew what that should be. Well, if I run this sanity check, these are the numbers I get. I should be pretty suspicious. I should also be suspicious they're kind of the same numbers I got for 10,000 steps. What should I think about? I should think that maybe there's a bug in my code. So if we now go back and look at the code, yes, this fails the pants on fire test that there's clearly something wrong with these numbers.","The simulation reveals that the length of the walk or the number of steps does not significantly affect how far the drunk gets from the origin. Even with varying step lengths such as 10, 100, 1,000, or 10,000, the distances observed (8.6, 8.57, 9.2, 8.7) show little variance, indicating that the random nature of the walk keeps the average distance traveled relatively stable.",valid,Advanced,6.2002,5 Random Walks,6wUD_gp5WeE.en-qlPKC2UN_YU_12_mp4
269,What are the three main steps of a brute force algorithm for solving a problem by enumerating item combinations and selecting the optimal one?,"§ 1. Enumerate all possible combina<ons of items. 
§ 2. Remove all of the combina<ons whose total units 
exceeds the allowed weight. 
§ 3. From the remaining combina<ons choose any one 
whose value is the largest. 
Brute Force Algorithm 
6.0002 LECTURE 2 
4 
",1. Enumerate all possible combinations of items. 2. Remove all of the combinations whose total units exceed the allowed weight. 3. From the remaining combinations choose any one whose value is the largest.,valid,Intermediate,6.2002,Lecture 2: Optimization Problems,3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_4_pdf
270,Why is normalizing the variability of clusters by their size not always ideal in clustering?,"The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high-quality educational resources for free. To make a donation, or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. JOHN GUTTAG: I'm a little reluctant to say good afternoon, given the weather, but I'll say it anyway. I guess now we all do know that we live in Boston. And I should say, I hope none of you were affected too much by the fire yesterday in Cambridge, but that seems to have been a pretty disastrous event for some. Anyway, here's the reading. This is a chapter in the book on clustering, a topic that Professor Grimson introduced last week. And I'm going to try and finish up with respect to this course today, though not with respect to everything there is to know about clustering. Quickly just reviewing where we were. We're in the unit of a course on machine learning, and we always follow the same paradigm. We observe some set of examples, which we call the training data. We try and infer something about the process that created those examples. And then we use inference techniques, different kinds of techniques, to make predictions about previously unseen data. We call that the test data. As Professor Grimson said, you can think of two broad classes. Supervised, where we have a set of examples and some label associated with the example-- Democrat, Republican, smart, dumb, whatever you want to associate with them-- and then we try and infer the labels. Or unsupervised, where we're given a set of feature vectors without labels, and then we attempt to group them into natural clusters. That's going to be today's topic, clustering. So clustering is an optimization problem. As we'll see later, supervised machine learning is also an optimization problem. Clustering's a rather simple one. We're going to start first with the notion of variability. So this little c is a single cluster, and we're going to talk about the variability in that cluster of the sum of the distance between the mean of the cluster and each example in the cluster. And then we square it. OK? Pretty straightforward. For the moment, we can just assume that we're using Euclidean distance as our distance metric. Minkowski with p equals two. So variability should look pretty similar to something we've seen before, right? It's not quite variance, right, but it's very close. In a minute, we'll look at why it's different. And then we can look at the dissimilarity of a set of clusters, a group of clusters, which I'm writing as capital C, and that's just the sum of all the variabilities. Now, if I had divided variability by the size of the cluster, what would I have? Something we've seen before. What would that be? Somebody? Isn't that just the variance? So the question is, why am I not doing that? If up til now, we always wanted to talk about variance, why suddenly am I not doing it? Why do I define this notion of variability instead of good old variance? Any thoughts? What am I accomplishing by not dividing by the size of the cluster? Or what would happen if I did divide by the size of the cluster? Yes. AUDIENCE: You normalize it? JOHN GUTTAG: Absolutely. I'd normalize it. That's exactly what it would be doing. And what might be good or bad about normalizing it? What does it essentially mean to normalize? It means that the penalty for a big cluster with a lot of variance in it is no higher than the penalty of a tiny little cluster with a lot of variance in it. By not normalizing, what I'm saying is I want to penalize big, highly-diverse clusters more than small, highly-diverse clusters. OK? And if you think about it, that probably makes sense. Big and bad is worse than small and bad. All right, so now we define the objective function. And can we say that the optimization problem we want to solve by clustering is simply finding a capital C that minimizes dissimilarity? Is that a reasonable definition? Well, hint-- no. What foolish thing could we do that would optimize that objective function? Yeah. AUDIENCE: You could have the same number of clusters as points? JOHN GUTTAG: Yeah. I can have the same number of clusters as points, assign each point to its own cluster, whoops. Ooh, almost a relay. The dissimilarity of each cluster would be 0. The variability would be 0, so the dissimilarity would be 0, and I just solved the problem. Well, that's clearly not a very useful thing to do. So, well, what do you think we do to get around that? Yeah. AUDIENCE: We apply a constraint? JOHN GUTTAG: We apply a constraint. Exactly. And so we have to pick some constraint. What would be a suitable constraint, for example? Well, maybe we'd say, OK, the clusters have to have some minimum distance between them. Or-- and this is the constraint we'll be using today-- we could constrain the number of clusters. Say, all right, I only want to have at most five clusters. Do the best you can to minimize dissimilarity, but you're not allowed to use more than five clusters. That's the most common constraint that gets placed in the problem. All right, we're going to look at two algorithms. Maybe I should say two methods, because there are multiple implementations of these methods. The first is called hierarchical clustering, and the second is called k-means. There should be an S on the word mean there. Sorry about that. All right, let's look at hierarchical clustering first.","By not normalizing, it means that the penalty for a big cluster with a lot of variance is higher than the penalty for a small cluster with the same amount of variance. This is because normalizing would make the penalty for a big cluster with a lot of variance no higher than a small cluster with similar variance, whereas not normalizing emphasizes penalizing big, highly-diverse clusters more than small, highly-diverse clusters. The reasoning is that 'big and bad' is worse than 'small and bad.'",valid,Advanced,6.2002,12 Clustering,esmzYhuFnds.en-qlPKC2UN_YU_1_mp4
272,How does the search tree method ensure the selection of the optimal set of items for the knapsack problem?,"§ The tree is built top down star<ng with the root  
§ The ﬁrst element is selected from the s<ll to be 
considered items 
◦ If there is room for that item in the knapsack, a node is 
constructed that reﬂects the consequence of choosing to 
take that item.  By conven<on, we draw that as the leS 
child 
◦ We also explore the consequences of not taking that 
item. This is the right child 
§ The process is then applied recursively to non-leaf 
children 
§ Finally, chose a node with the highest value that meets 
constraints 
Search Tree Implementa#on 
6.0002 LECTURE 2 
5 
","The optimal set of items is selected by building the search tree top-down, starting with the root. For each item, a node is constructed that reflects the consequence of choosing to take it (left child) and not to take it (right child). The process is applied recursively to non-leaf children, and finally, a node with the highest value that meets the constraints is chosen.",valid,Advanced,6.2002,Lecture 2: Optimization Problems,3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_5_pdf
274,"What are the main components of an optimization model, and how do they interact with each other in the context of the knapsack problem?","So let's talk first about optimization models. An optimization model is a very simple thing. We start with an objective function that's either to be maximized or minimized. So for, example, if I'm going from New York to Boston, I might want to find a route by car or plane or train that minimizes the total travel time. So my objective function would be the number of minutes spent in transit getting from a to b. We then often have to layer on top of that objective function a set of constraints, sometimes empty, that we have to obey. So maybe the fastest way to get from New York to Boston is to take a plane, but I only have $100 to spend. So that option is off the table. So I have the constraints there on the amount of money I can spend. Or maybe I have to be in Boston before 5:00 PM and while the bus would get me there for $15, it won't get me there before 5:00. And so maybe what I'm left with is driving, something like that. So objective function, something you're either minimizing or maximizing, and a set of constraints that eliminate some solutions. And as we'll see, there's an asymmetry here. We handle these two things differently. We use these things all the time. I commute to work using Waze, which essentially is solving-- not very well, I believe-- an optimization problem to minimize my time from home to here. When you travel, maybe you log into various advisory programs that try and optimize things for you. They're all over the place. Today you really can't avoid using optimization algorithm as you get through life. Pretty abstract. Let's talk about a specific optimization problem called the knapsack problem. The first time I talked about the knapsack problem I neglected to show a picture of a knapsack, and I was 10 minutes into it before I realized most of the class had no idea what a knapsack was. It's what we old people used to call a backpack, and they used to look more like that than they look today. So the knapsack problem involves-- usually it's told in terms of a burglar who breaks into a house and wants to steal a bunch of stuff but has a knapsack that will only hold a finite amount of stuff that he or she wishes to steal. And so the burglar has to solve the optimization problem of stealing the stuff with the most value while obeying the constraint that it all has to fit in the knapsack. So we have an objective function. I'll get the most for this when I fence it. And a constraint, it has to fit in my backpack. And you can guess which of these might be the most valuable items here. So here is in words, written words what I just said orally. There's more stuff than you can carry, and you have to choose which stuff to take and which to leave behind. I should point out that there are two variants of it. There's the 0/1 knapsack problem and the continuous. The 0/1 would be illustrated by something like this. So the 0/1 knapsack problem means you either take the object or you don't. I take that whole gold bar or I take none of it. The continuous or so-called fractional knapsack problem says I can take pieces of it. So maybe if I take in my gold bar and shaved it into gold dust, I then can say, well, the whole thing won't fit in, but I can fit in a path, part of it. The continuous knapsack problem is really boring. It's easy to solve. How do you think you would solve the continuous problem? Suppose you had over here a pile of gold and a pile of silver and a pile of raisins, and you wanted to maximize your value. Well, you'd fill up your knapsack with gold until you either ran out of gold or ran out of space. If you haven't run out of space, you'll now put silver in until you run out of space. If you still haven't run out of space, well, then you'll take as many raisins as you can fit in. But you can solve it with what's called a greedy algorithm, and we'll talk much more about this as we go forward. Where you take the best thing first as long as you can and then you move on to the next thing. As we'll see, the 0/1 knapsack problem is much more complicated because once you make a decision, it will affect the future decisions. Let's look at an example, and I should probably warn you, if you're hungry, this is not going to be a fun lecture. So here is my least favorite because I always want to eat more than I'm supposed to eat. So the point is typically knapsack problems are not physical knapsacks but some conceptual idea. So let's say that I'm allowed 1,500 calories of food, and these are my options. I have to go about deciding, looking at this food-- and it's interesting, again, there's things showing up on your screen that are not showing up on my screen, but they're harmless, things like how my mouse works. Anyway, so I'm trying to take some fraction of this food, and it can't add up to more than 1,500 calories. The problem might be that once I take something that's 1,485 calories, I can't take anything else, or maybe 1,200 calories and everything else is more than 300. So once I take one thing, it constrains possible solutions. A greedy algorithm, as we'll see, is not guaranteed to give me the best answer. Let's look at a formalization of it. So each item is represented by a pair, the value of the item and the weight of the item. And let's assume the knapsack can accommodate items with the total weight of no more than w. I apologize for the short variable names, but they're easier to fit on a slide. Finally, we're going to have a vector l of length n representing the set of available items. This is assuming we have n items to choose from. So each element of the vector represents an item. So those are the items we have. And then another vector v is going to indicate whether or not an item was taken. So essentially I'm going to use a binary number to represent the set of items I choose to take. For item three say, if bit three is zero I'm not taking the item. If bit three is one, then I am taking the item. So it just shows I can now very nicely represent what I've done by a single vector of zeros and ones. Let me pause for a second. Does anyone have any questions about this setup? It's important to get this setup because what we're going to see now depends upon that setting in your head. So I've kind of used mathematics to describe the backpack problem. And that's typically the way we deal with these optimization problems. We start with some informal description, and then we translate them into a mathematical representation. So here it is. We're going to try and find a vector v that maximizes the sum of V sub i times I sub i. Now, remember I sub i is the value of the item. V sub i is either zero or one So if I didn't take the item, I'm multiplying its value by zero. So it contributes nothing to the sum. If I did take the item, I'm multiplying its value by one. So the value of the item gets added to the sum. So that tells me the value of V. And I want to get the most valuable V I can get subject to the constraint that if I look at the item's dot weight and multiply it by V, the sum of the weights is no greater than w. So I'm playing the same trick with the values of multiplying each one by zero or one, and that's my constraint. Make sense? All right, so now we have the problem formalized. How do we solve it? Well, the most obvious solution is brute force. I enumerate all possible combinations of items; that is to say, I generate all subsets of the items that are available-- I don't know why it says subjects here, but we should have said items. Let me fix that. This is called the power set. So the power set of a set includes the empty subset. It includes the set that includes everything and everything in between. So subsets of size one, subsets of size two, et cetera. So now I've generated all possible sets of items. I can now go through and sum up the weights and remove all those sets that weigh more than I'm allowed. And then from the remaining combinations, choose any one whose value is the largest. I say choose any one because there could be ties, in which case I don't care which I choose. So it's pretty obvious that this is going to give you a correct answer. You're considering all possibilities and choosing a winner. Unfortunately, it's usually not very practical. What we see here is that's what the power set is if you have 100 vec. Not very practical, right, even for a fast computer generating that many possibilities is going to take a rather long time. So kind of disappointing. We look at it and say, well, we got a brute force algorithm. It will solve the problem, but it'll take too long. We can't actually do it. 100 is a pretty small number, right. We often end up solving optimization problems where n is something closer to 1,000, sometimes even a million. Clearly, brute force isn't going to work. So that raises the next question, are we just being stupid? Is there a better algorithm that I should have showed you? I shouldn't say we. Am I just being stupid? Is there a better algorithm that would have given us the answer? The sad answer to that is no for the knapsack problem. And indeed many optimization problems are inherently exponential. What that means is there is no algorithm that provides an exact solution to this problem whose worst case running time is not exponential in the number of items. It is an exponentially hard problem. There is no really good solution. But that should not make you sad because while there's no perfect solution, we're going to look at a couple of really very good solutions that will make this poor woman a happier person. So let's start with the greedy algorithm. I already talked to you about greedy algorithms. So it could hardly be simpler. We say while the knapsack is not full, put the best available item into the knapsack. When it's full, we're done. You do need to ask a question. What does best mean? Is the best item the most valuable? Is it the least expensive in terms of, say, the fewest calories, in my case? Or is it the highest ratio of value to units? Now, maybe I think a calorie in a glass of beer is worth more than a calorie in a bar of chocolate, maybe vice versa.","An optimization model consists of an objective function that is either maximized or minimized, and a set of constraints that limit possible solutions. In the context of the knapsack problem, the objective function is acquiring items of the highest total value without exceeding the weight capacity of the knapsack. The constraints are represented by the fixed capacity of the knapsack, which limits the combined weight of the items that can be taken. The interaction involves choosing the combination of items that maximizes the total value while ensuring the total weight does not violate the knapsack's capacity constraint.",valid,Advanced,6.2002,1 Introduction Optimization Problems MIT 60002 Intro to Computational Thinking and Data Science,C1lhuz6pZC0.en-qlPKC2UN_YU_2_mp4
275,What can be concluded if the confidence intervals of different subpopulations do not overlap?,"This is plotting pulse rate against how much exercise you do or how frequently you exercise. And what you can see here is there's definitely a downward trend suggesting that the more you exercise, the lower your average resting pulse. That's probably worth knowing. And these error bars give us the 95% confidence intervals for different subpopulations. And what we can see here is that some of them overlap. So, yes, once a fortnight-- two weeks for those of you who don't speak British-- it does get a little bit smaller than rarely or never. But the confidence interval is very big. And so maybe we really shouldn't feel very comfortable that it would actually help. The thing we can say is that if the confidence intervals don't overlap, we can conclude that the means are actually statistically significantly different, in this case at the 95% level. So here we see that the more than weekly does not overlap with the rarely or never. And from that, we can conclude that this is actually, statistically true-- that if you exercise more than weekly, your pulse is likely to be lower than if you don't. If confidence intervals do overlap, you cannot conclude that there is no statistically significant difference. There might be, and you can use other tests to find out whether there are. When they don't overlap, it's a good thing. We can conclude something strong. When they do overlap, we need to investigate further. All right, let's look at the error bars for our temperatures. And again, we can plot those using something called","If the confidence intervals don't overlap, we can conclude that the means are actually statistically significantly different, in this case at the 95% level.",valid,Intermediate,6.2002,8 Sampling and Standard Error,soZv_KKax3E.en-qlPKC2UN_YU_6_mp4
276,What does the function aveMeanSquareError compute?,"	
	+	 
def aveMeanSquareError(data, predicted): 
    error = 0.0 
    for i in range(len(data)): 
error += (data[i] - predicted[i])**2 
    return error/len(data) 
estYVals = pylab.polyval(model1, xVals)   
print('Ave. mean square error for linear model =', 
aveMeanSquareError(yVals, estYVals)) 
estYVals = pylab.polyval(model2, xVals) 
print('Ave. mean square error for quadratic model =', 
aveMeanSquareError(yVals, estYVals)) 
	

6
L.$!,2$53::3:;
L.$!,2,-$5;GGG:
",It computes the average mean square error between the actual data and the predicted data.,invalid,Basic,6.2002,Lecture 9: Understanding Experimental Data,20a7e184a1a2b3c34a5055dc1f1dc066_MIT6_0002F16_lec9_26_pdf
279,What factors can affect the accuracy of the sample standard deviation as an approximation of the population standard deviation?," 
 
  
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
The Point  
§Once sample reaches a reasonable size, sample
standard deviation is a pretty good approximation to
population  standard  deviation
§True only for this example?
◦Distribution  of population?
◦Size of population?
6.0002  LECTURE 8 
 
26
",The accuracy of the sample standard deviation as an approximation of the population standard deviation can be affected by the distribution of the population and the size of the population.,valid,Intermediate,6.2002,Lecture 8: Sampling and Standard Error,02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_26_pdf
280,Flow hijacking,"*+ 
	

K
",To hijack the execution of the target application/program toward some code injected by the attacker.,empty,Basic,6.2002,Lecture 11: Introduction to Machine Learning,4c4fc506075a8502ccc5191583d22882_MIT6_0002F16_lec11_10_pdf
281,What is the 95% confidence interval calculated as?,"  
 
 
 
 
 
  
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
±
Try It 1000 Times  
What’s  the 95% 
confidence interval? 
16.28  +- 1.96*0.94 
14.5  - 18.1 
Includes population 
mean, but pretty 
wide 
Mean of sample Means = 16.3 
Suppose we want a 
Standard deviation of sample means = 0.94 
tighter bound? 
6.0002  LECTURE 8 
 
14
","16.28 ± 1.96*0.94, which results in the interval 14.5 - 18.1.",invalid,Basic,6.2002,Lecture 8: Sampling and Standard Error,02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_14_pdf
282,What is a probability distribution and what does it capture?,"And we'll come back to this in just a second. But this is a normal distribution, called the Gaussian. Under those two assumptions the empirical rule will always hold. All right, let's talk about distributions, since I just introduced one. We've been using a probability distribution. And this captures the notion of the relative frequency with which some random variable takes on different values.",A probability distribution captures the notion of the relative frequency with which some random variable takes on different values.,valid,Intermediate,6.2002,6 Monte Carlo Simulation,OgO1gpXSUzU.en-j3PyPqV-e1s_16_mp4
283,What is the purpose of the density method in the Food class?,"7
class Food(object):
def __init__(self, n, v, w):
self.name = n
self.value = v
self.calories = w
def getValue(self):
return self.value
def getCost(self):
return self.calories
def density(self):
return self.getValue()/self.getCost()
def __str__(self):
return self.name + ': <' + str(self.value)\
+ ', ' + str(self.calories) + '>'
	


",The purpose of the density method in the Food class is to calculate and return the value-to-calories ratio of a food item by dividing its value by its calories.,valid,Intermediate,6.2002,Lecture 1: Introduction and Optimization Problems,0a353b26f1c6bd161b28b3f249aa05d1_MIT6_0002F16_lec1_21_pdf
284,What is an optimization problem?,"§ Many problems of prac<cal importance can be 
formulated as op<miza<on problems 
§ Greedy algorithms oSen provide adequate (though not 
necessarily op<mal) solu<ons 
§ Finding an op<mal solu<on is usually exponen<ally 
hard 
§ But dynamic programming oSen yields good 
performance for a subclass of op<miza<on problems—
those with op<mal substructure and overlapping 
subproblems 
◦Solu<on always correct 
◦Fast under the right circumstances 
Summary of Lectures 1-2 
6.0002 LECTURE 2 
31 
",A problem of practical importance that can be formulated for optimization.,valid,Basic,6.2002,Lecture 2: Optimization Problems,3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_31_pdf
285,How do greedy algorithms perform in solving optimization problems?,"§ Many problems of prac<cal importance can be 
formulated as op<miza<on problems 
§ Greedy algorithms oSen provide adequate (though not 
necessarily op<mal) solu<ons 
§ Finding an op<mal solu<on is usually exponen<ally 
hard 
§ But dynamic programming oSen yields good 
performance for a subclass of op<miza<on problems—
those with op<mal substructure and overlapping 
subproblems 
◦Solu<on always correct 
◦Fast under the right circumstances 
Summary of Lectures 1-2 
6.0002 LECTURE 2 
31 
",Greedy algorithms often provide adequate (though not necessarily optimal) solutions.,valid,Basic,6.2002,Lecture 2: Optimization Problems,3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_31_pdf
286,Why is dynamic programming beneficial in optimization problems?,"§ Many problems of prac<cal importance can be 
formulated as op<miza<on problems 
§ Greedy algorithms oSen provide adequate (though not 
necessarily op<mal) solu<ons 
§ Finding an op<mal solu<on is usually exponen<ally 
hard 
§ But dynamic programming oSen yields good 
performance for a subclass of op<miza<on problems—
those with op<mal substructure and overlapping 
subproblems 
◦Solu<on always correct 
◦Fast under the right circumstances 
Summary of Lectures 1-2 
6.0002 LECTURE 2 
31 
",Dynamic programming often yields good performance for optimization problems with optimal substructure and overlapping subproblems.,valid,Basic,6.2002,Lecture 2: Optimization Problems,3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_31_pdf
287,What is the purpose of creating a table for storing computed values in optimization problems?,"§ Trade a <me for space 
§ Create a table to record what we’ve done 
◦Before compu<ng ﬁb(x), check if value of ﬁb(x) 
already stored in the table 
◦If so, look it up 
◦If not, compute it and then add it to table 
◦Called memoiza<on 
Clearly a Bad Idea to Repeat Work 
6.0002 LECTURE 2 
18 
","The purpose is to implement memoization: before computing a value like fib(x), it checks if this value is already stored in the table. If it is, it looks it up; if not, it computes the value and then adds it to the table. This approach avoids the redundancy of repeating work.",valid,Advanced,6.2002,Lecture 2: Optimization Problems,3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_18_pdf
288,What advantage does using an array have over a list when performing mathematical operations on data?,"I pass in that tuple, and what it does is it converts it into an array, which is a data structure that has a fixed number of slots in it but has a really nice property I want to take advantage of. I could do all of this with lists. But by converting that into array and then giving it the same name xVals and similarly for the yVals, I can now do math on the array without having to write loops. And in particular right here, notice what I'm doing. I'm taking xVals, which is an array, multiplying it by a number. And what that does is it takes every entry in the array, multiplies that entry, and puts it into basically a new version of the array, which I then store into xVals. If you've programmed in Matlab, this is the same kind of feeling, right. I can take an array, do something to it, and that's really nice. So I'm going to scale all of my values, and then I'm going to plot them out some appropriate things. And if I do it, I get that. I thought we said Hooke's law was a linear relationship. So in an ideal world, all of these points ought to lay along a line somewhere, where the slope of the line would tell me the spring constant. Not so good, right. And in fact, if you look at it, you can kind of see-- in here you can kind of imagine there's a line there, something funky is going on up here. And we're going to come back to that at the end of the lecture. But how do we think about actually finding the line? Well, we know there's noise in the measurement, so our best thing to do is to say, well, could we just fit a line to this data? And how would we do that? And that's the first big thing we want to do today. We want to try and figure out, given that we've got measurement noise, how do we fit a line to it. So how do we fit a curve to data? Well, what we're basically going to try and do is find a way to relate an independent variable, which were the masses, the y values, to the dependent-- sorry, wrong way. The independent values, which are the x-axis, to the dependent value, what is the actual displacement we're going to see? So another way of saying it is if I go back to here, I want to know for every point along here, how do I fit something that predicts what the y value is? So I need to figure out how to do that fit. To decide-- even if I had a curve, a line that I thought was a good fit to that, I need to decide how good it is. So imagine I was lucky and somebody said, here's a line that I think describes Hooke's law in this case. Great. I could draw the line on that data. I could draw it on this chunk of data here. I still need to decide how do I know if it's a good fit. And for that, we need something we call an objective function, and it's going to measure how close is the line to the data to which I'm trying to fit it. Once we've defined the objective function, then what we say is, OK, now let's find the line that minimizes it, the best possible line, the line that makes that objective function as small as possible, because that's going to be the best fit to the data. And so that's what I'd like to do. We're going to see-- we're going to do it for general curves, but we're going to start just with lines, with linear function. So in this case, we want to say what's the line such that some function of the sum of the distances from the line to the measured points is minimized. And I'm going to come back in a second to how do we find the line. But first we've got to think about what does it mean to measure it. So I've got a point.","By converting data into an array, you can perform math on the array without having to write loops. For example, taking an array and multiplying it by a number automatically applies the multiplication to every entry in the array, producing a new array with the results.",valid,Intermediate,6.2002,9 Understanding Experimental Data,vIFKGFl1Cn8.en-qlPKC2UN_YU_5_mp4
289,Why is random sampling generally easier to achieve in simulations compared to in the field?," 
 
 
 
 
 
 
Sampling  
§All statistical techniques are based upon the
assumption that by sampling a subset of a population 
we can infer things about the population as a whole 
§As we have seen,  if random sampling is used, one can
make meaningful mathematical statements about the 
expected relation of the sample to the entire 
population 
§Easy to get random samples in simulations
§Not so easy in the field, where some examples are
more convenient to acquire than others 
6.0002  LECTURE 14 
21 
","In simulations, it is easier to get random samples because the environment is controlled, and all elements of the population can be equally accessed programmatically. In the field, however, some examples are more convenient to acquire than others, making true random sampling more difficult.",valid,Advanced,6.2002,Lecture 14: Classification and Statistical Sins,b9d60f4ecb325e4648f9cf0379419338_MIT6_0002F16_lec14_21_pdf
290,What does an adjacency matrix represent in a directed graph?,"I want to print out what an edge looks like, I'm going to ask that it print out the name of the source, and then an arrow, and then the name of the destination. So notice what I do there. Given an instance of an edge, I can print it. And it will get the source or the node associated with source inside this instance, get for that the getName method, and then call it. Notice the open-close paren there to actually call it. What does that do? It says, inside the edge I've got something that points to a node. I get that node. I take the method associated with it. And I call it. That returns the string. And then I glue that together with the arrow. I do the same thing on the destination. And I just print it out. Pretty straightforward, hopefully. OK, now I have to make a decision about the graph. I'm going to start with digraphs, directed graphs. And I need to think about how I might represent the graph. I can create nodes. I can create edges, but I've got to bring them all together. So I'll remind you, a digraph is a directed graph. The edges pass in only one direction. And here's one way I could do it. Given all the sources and all the destinations, I could just create a big matrix called an adjacency matrix. The rows would be all the sources. The columns would be all the destinations. And then in a particular spot in the matrix, if there is an edge between a source and a destination, I'd just put a one. Otherwise I'd put a zero. Note, by the way, because it's a directed graph, it's not symmetric. There might be a one between S and D, but not between D and S, unless there are edges both ways. This would be a perfectly reasonable way to represent a graph, but not the most convenient one. I'd have to go into the matrix to look things up. It may also not be a very efficient way of representing things. For example, if there are very few edges in the graph, I could have a huge matrix with mostly zeros. And that's not the most effective way to do it. So I'm going to use an alternative called an adjacency list. And the idea here is, for every node in the graph. I'm going to associate with it a list of destinations. That is, for a node, what are the places I can reach with a single edge? OK, so let's see what that does if we want to build it. And yes, there's a lot of code here, but it's pretty easy to look through I hope. Here's the choice I'm going to make. Again, what's a graph? It's a set of nodes. It's a set of edges. I'm going to have a way of putting nodes into the graph. And I'm going to choose to, when I put a node into the graph, to store it as a key in a dictionary. OK? When I initialize the graph, I'm just going to set this internal variable, edges, to be an empty dictionary. And the second part of it is, when I add an edge to the graph between two nodes from a source to a destination, I'm going to take that point in the dictionary associated with the source. It's a key. And associated with it, I'm going to just have a list of the nodes I can reach from edges from that source. So notice what happens here. If I want to add a node, remember, it's a node not an edge-- I'll first check to make sure that it's not already in the dictionary. That little loop is basic, or that if is saying, if it's in this set of keys, it will return true. And I'm going to complain. I'm trying to copy a node or duplicate a node. Otherwise, notice what I do. When I put a node into the dictionary, I go into that dictionary, edges. I create an entry with the key that is the node. And the value I put in there is initially an empty list. I'm going to say one more piece carefully. It's a node not a name. And that's OK in Python. It is literally the key is the node itself. It's an object, which is what I'd like. All right, what if I want to add an edge? Well, an edge is going to go from a source to a destination node. So, I'm going to get out from the edge the source piece. I'm going to get out from the edge the destination piece by calling those methods. Again, notice the open-close paren, which takes the method and actually calls it. Because remember, an edge was an object itself. Given those, I'll check to make sure that they are both in the dictionary. That is, I've already added them to the graph. I can't make a connection between things that aren't in the graph. And then notice the nice little thing I do.","An adjacency matrix represents a directed graph where the rows are all the sources, the columns are all the destinations, and a particular spot in the matrix contains a one if there is an edge between a source and a destination, otherwise it contains a zero.",valid,Basic,6.2002,3 Graph-theoretic Models,V_TulH374hw.en-qlPKC2UN_YU_2_mp4
291,How does an adjacency list represent the edges of a node?,"I want to print out what an edge looks like, I'm going to ask that it print out the name of the source, and then an arrow, and then the name of the destination. So notice what I do there. Given an instance of an edge, I can print it. And it will get the source or the node associated with source inside this instance, get for that the getName method, and then call it. Notice the open-close paren there to actually call it. What does that do? It says, inside the edge I've got something that points to a node. I get that node. I take the method associated with it. And I call it. That returns the string. And then I glue that together with the arrow. I do the same thing on the destination. And I just print it out. Pretty straightforward, hopefully. OK, now I have to make a decision about the graph. I'm going to start with digraphs, directed graphs. And I need to think about how I might represent the graph. I can create nodes. I can create edges, but I've got to bring them all together. So I'll remind you, a digraph is a directed graph. The edges pass in only one direction. And here's one way I could do it. Given all the sources and all the destinations, I could just create a big matrix called an adjacency matrix. The rows would be all the sources. The columns would be all the destinations. And then in a particular spot in the matrix, if there is an edge between a source and a destination, I'd just put a one. Otherwise I'd put a zero. Note, by the way, because it's a directed graph, it's not symmetric. There might be a one between S and D, but not between D and S, unless there are edges both ways. This would be a perfectly reasonable way to represent a graph, but not the most convenient one. I'd have to go into the matrix to look things up. It may also not be a very efficient way of representing things. For example, if there are very few edges in the graph, I could have a huge matrix with mostly zeros. And that's not the most effective way to do it. So I'm going to use an alternative called an adjacency list. And the idea here is, for every node in the graph. I'm going to associate with it a list of destinations. That is, for a node, what are the places I can reach with a single edge? OK, so let's see what that does if we want to build it. And yes, there's a lot of code here, but it's pretty easy to look through I hope. Here's the choice I'm going to make. Again, what's a graph? It's a set of nodes. It's a set of edges. I'm going to have a way of putting nodes into the graph. And I'm going to choose to, when I put a node into the graph, to store it as a key in a dictionary. OK? When I initialize the graph, I'm just going to set this internal variable, edges, to be an empty dictionary. And the second part of it is, when I add an edge to the graph between two nodes from a source to a destination, I'm going to take that point in the dictionary associated with the source. It's a key. And associated with it, I'm going to just have a list of the nodes I can reach from edges from that source. So notice what happens here. If I want to add a node, remember, it's a node not an edge-- I'll first check to make sure that it's not already in the dictionary. That little loop is basic, or that if is saying, if it's in this set of keys, it will return true. And I'm going to complain. I'm trying to copy a node or duplicate a node. Otherwise, notice what I do. When I put a node into the dictionary, I go into that dictionary, edges. I create an entry with the key that is the node. And the value I put in there is initially an empty list. I'm going to say one more piece carefully. It's a node not a name. And that's OK in Python. It is literally the key is the node itself. It's an object, which is what I'd like. All right, what if I want to add an edge? Well, an edge is going to go from a source to a destination node. So, I'm going to get out from the edge the source piece. I'm going to get out from the edge the destination piece by calling those methods. Again, notice the open-close paren, which takes the method and actually calls it. Because remember, an edge was an object itself. Given those, I'll check to make sure that they are both in the dictionary. That is, I've already added them to the graph. I can't make a connection between things that aren't in the graph. And then notice the nice little thing I do.",An adjacency list associates each node in the graph with a list of destinations that can be reached from that node with a single edge.,valid,Basic,6.2002,3 Graph-theoretic Models,V_TulH374hw.en-qlPKC2UN_YU_2_mp4
292,What is the purpose of calling the getName method on a node within an edge?,"I want to print out what an edge looks like, I'm going to ask that it print out the name of the source, and then an arrow, and then the name of the destination. So notice what I do there. Given an instance of an edge, I can print it. And it will get the source or the node associated with source inside this instance, get for that the getName method, and then call it. Notice the open-close paren there to actually call it. What does that do? It says, inside the edge I've got something that points to a node. I get that node. I take the method associated with it. And I call it. That returns the string. And then I glue that together with the arrow. I do the same thing on the destination. And I just print it out. Pretty straightforward, hopefully. OK, now I have to make a decision about the graph. I'm going to start with digraphs, directed graphs. And I need to think about how I might represent the graph. I can create nodes. I can create edges, but I've got to bring them all together. So I'll remind you, a digraph is a directed graph. The edges pass in only one direction. And here's one way I could do it. Given all the sources and all the destinations, I could just create a big matrix called an adjacency matrix. The rows would be all the sources. The columns would be all the destinations. And then in a particular spot in the matrix, if there is an edge between a source and a destination, I'd just put a one. Otherwise I'd put a zero. Note, by the way, because it's a directed graph, it's not symmetric. There might be a one between S and D, but not between D and S, unless there are edges both ways. This would be a perfectly reasonable way to represent a graph, but not the most convenient one. I'd have to go into the matrix to look things up. It may also not be a very efficient way of representing things. For example, if there are very few edges in the graph, I could have a huge matrix with mostly zeros. And that's not the most effective way to do it. So I'm going to use an alternative called an adjacency list. And the idea here is, for every node in the graph. I'm going to associate with it a list of destinations. That is, for a node, what are the places I can reach with a single edge? OK, so let's see what that does if we want to build it. And yes, there's a lot of code here, but it's pretty easy to look through I hope. Here's the choice I'm going to make. Again, what's a graph? It's a set of nodes. It's a set of edges. I'm going to have a way of putting nodes into the graph. And I'm going to choose to, when I put a node into the graph, to store it as a key in a dictionary. OK? When I initialize the graph, I'm just going to set this internal variable, edges, to be an empty dictionary. And the second part of it is, when I add an edge to the graph between two nodes from a source to a destination, I'm going to take that point in the dictionary associated with the source. It's a key. And associated with it, I'm going to just have a list of the nodes I can reach from edges from that source. So notice what happens here. If I want to add a node, remember, it's a node not an edge-- I'll first check to make sure that it's not already in the dictionary. That little loop is basic, or that if is saying, if it's in this set of keys, it will return true. And I'm going to complain. I'm trying to copy a node or duplicate a node. Otherwise, notice what I do. When I put a node into the dictionary, I go into that dictionary, edges. I create an entry with the key that is the node. And the value I put in there is initially an empty list. I'm going to say one more piece carefully. It's a node not a name. And that's OK in Python. It is literally the key is the node itself. It's an object, which is what I'd like. All right, what if I want to add an edge? Well, an edge is going to go from a source to a destination node. So, I'm going to get out from the edge the source piece. I'm going to get out from the edge the destination piece by calling those methods. Again, notice the open-close paren, which takes the method and actually calls it. Because remember, an edge was an object itself. Given those, I'll check to make sure that they are both in the dictionary. That is, I've already added them to the graph. I can't make a connection between things that aren't in the graph. And then notice the nice little thing I do.","The purpose of calling the getName method on a node within an edge is to retrieve the name of the node and return it as a string, which can then be used to display the edge representation including the source and destination.",invalid,Basic,6.2002,3 Graph-theoretic Models,V_TulH374hw.en-qlPKC2UN_YU_2_mp4
293,What is a 'digraph'?,"I want to print out what an edge looks like, I'm going to ask that it print out the name of the source, and then an arrow, and then the name of the destination. So notice what I do there. Given an instance of an edge, I can print it. And it will get the source or the node associated with source inside this instance, get for that the getName method, and then call it. Notice the open-close paren there to actually call it. What does that do? It says, inside the edge I've got something that points to a node. I get that node. I take the method associated with it. And I call it. That returns the string. And then I glue that together with the arrow. I do the same thing on the destination. And I just print it out. Pretty straightforward, hopefully. OK, now I have to make a decision about the graph. I'm going to start with digraphs, directed graphs. And I need to think about how I might represent the graph. I can create nodes. I can create edges, but I've got to bring them all together. So I'll remind you, a digraph is a directed graph. The edges pass in only one direction. And here's one way I could do it. Given all the sources and all the destinations, I could just create a big matrix called an adjacency matrix. The rows would be all the sources. The columns would be all the destinations. And then in a particular spot in the matrix, if there is an edge between a source and a destination, I'd just put a one. Otherwise I'd put a zero. Note, by the way, because it's a directed graph, it's not symmetric. There might be a one between S and D, but not between D and S, unless there are edges both ways. This would be a perfectly reasonable way to represent a graph, but not the most convenient one. I'd have to go into the matrix to look things up. It may also not be a very efficient way of representing things. For example, if there are very few edges in the graph, I could have a huge matrix with mostly zeros. And that's not the most effective way to do it. So I'm going to use an alternative called an adjacency list. And the idea here is, for every node in the graph. I'm going to associate with it a list of destinations. That is, for a node, what are the places I can reach with a single edge? OK, so let's see what that does if we want to build it. And yes, there's a lot of code here, but it's pretty easy to look through I hope. Here's the choice I'm going to make. Again, what's a graph? It's a set of nodes. It's a set of edges. I'm going to have a way of putting nodes into the graph. And I'm going to choose to, when I put a node into the graph, to store it as a key in a dictionary. OK? When I initialize the graph, I'm just going to set this internal variable, edges, to be an empty dictionary. And the second part of it is, when I add an edge to the graph between two nodes from a source to a destination, I'm going to take that point in the dictionary associated with the source. It's a key. And associated with it, I'm going to just have a list of the nodes I can reach from edges from that source. So notice what happens here. If I want to add a node, remember, it's a node not an edge-- I'll first check to make sure that it's not already in the dictionary. That little loop is basic, or that if is saying, if it's in this set of keys, it will return true. And I'm going to complain. I'm trying to copy a node or duplicate a node. Otherwise, notice what I do. When I put a node into the dictionary, I go into that dictionary, edges. I create an entry with the key that is the node. And the value I put in there is initially an empty list. I'm going to say one more piece carefully. It's a node not a name. And that's OK in Python. It is literally the key is the node itself. It's an object, which is what I'd like. All right, what if I want to add an edge? Well, an edge is going to go from a source to a destination node. So, I'm going to get out from the edge the source piece. I'm going to get out from the edge the destination piece by calling those methods. Again, notice the open-close paren, which takes the method and actually calls it. Because remember, an edge was an object itself. Given those, I'll check to make sure that they are both in the dictionary. That is, I've already added them to the graph. I can't make a connection between things that aren't in the graph. And then notice the nice little thing I do.",A digraph is a directed graph where the edges pass in only one direction.,valid,Basic,6.2002,3 Graph-theoretic Models,V_TulH374hw.en-qlPKC2UN_YU_2_mp4
294,How are nodes initially stored in the graph according to the description?,"I want to print out what an edge looks like, I'm going to ask that it print out the name of the source, and then an arrow, and then the name of the destination. So notice what I do there. Given an instance of an edge, I can print it. And it will get the source or the node associated with source inside this instance, get for that the getName method, and then call it. Notice the open-close paren there to actually call it. What does that do? It says, inside the edge I've got something that points to a node. I get that node. I take the method associated with it. And I call it. That returns the string. And then I glue that together with the arrow. I do the same thing on the destination. And I just print it out. Pretty straightforward, hopefully. OK, now I have to make a decision about the graph. I'm going to start with digraphs, directed graphs. And I need to think about how I might represent the graph. I can create nodes. I can create edges, but I've got to bring them all together. So I'll remind you, a digraph is a directed graph. The edges pass in only one direction. And here's one way I could do it. Given all the sources and all the destinations, I could just create a big matrix called an adjacency matrix. The rows would be all the sources. The columns would be all the destinations. And then in a particular spot in the matrix, if there is an edge between a source and a destination, I'd just put a one. Otherwise I'd put a zero. Note, by the way, because it's a directed graph, it's not symmetric. There might be a one between S and D, but not between D and S, unless there are edges both ways. This would be a perfectly reasonable way to represent a graph, but not the most convenient one. I'd have to go into the matrix to look things up. It may also not be a very efficient way of representing things. For example, if there are very few edges in the graph, I could have a huge matrix with mostly zeros. And that's not the most effective way to do it. So I'm going to use an alternative called an adjacency list. And the idea here is, for every node in the graph. I'm going to associate with it a list of destinations. That is, for a node, what are the places I can reach with a single edge? OK, so let's see what that does if we want to build it. And yes, there's a lot of code here, but it's pretty easy to look through I hope. Here's the choice I'm going to make. Again, what's a graph? It's a set of nodes. It's a set of edges. I'm going to have a way of putting nodes into the graph. And I'm going to choose to, when I put a node into the graph, to store it as a key in a dictionary. OK? When I initialize the graph, I'm just going to set this internal variable, edges, to be an empty dictionary. And the second part of it is, when I add an edge to the graph between two nodes from a source to a destination, I'm going to take that point in the dictionary associated with the source. It's a key. And associated with it, I'm going to just have a list of the nodes I can reach from edges from that source. So notice what happens here. If I want to add a node, remember, it's a node not an edge-- I'll first check to make sure that it's not already in the dictionary. That little loop is basic, or that if is saying, if it's in this set of keys, it will return true. And I'm going to complain. I'm trying to copy a node or duplicate a node. Otherwise, notice what I do. When I put a node into the dictionary, I go into that dictionary, edges. I create an entry with the key that is the node. And the value I put in there is initially an empty list. I'm going to say one more piece carefully. It's a node not a name. And that's OK in Python. It is literally the key is the node itself. It's an object, which is what I'd like. All right, what if I want to add an edge? Well, an edge is going to go from a source to a destination node. So, I'm going to get out from the edge the source piece. I'm going to get out from the edge the destination piece by calling those methods. Again, notice the open-close paren, which takes the method and actually calls it. Because remember, an edge was an object itself. Given those, I'll check to make sure that they are both in the dictionary. That is, I've already added them to the graph. I can't make a connection between things that aren't in the graph. And then notice the nice little thing I do.","Nodes are initially stored as keys in a dictionary called 'edges', and the value for each key is initially set to an empty list.",valid,Basic,6.2002,3 Graph-theoretic Models,V_TulH374hw.en-qlPKC2UN_YU_2_mp4
295,What is a random walk and what significance does it hold in computations or simulations?," 
 
 
 
Another Possible First Step  
6.0002  LECTURE 5 
6 
","A random walk is a mathematical object, often used to describe a path that consists of a succession of random steps. It holds significance in computations or simulations as it models scenarios where sequential events are determined probabilistically, providing insights into various stochastic processes.",empty,Advanced,6.2002,Lecture 5: Random Walks,508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_6_pdf
296,What is the purpose of using weights in the histogram plot of the Gaussian distribution?," ! 
dist, numSamples = [], 1000000
for i in range(numSamples):
dist.append(random.gauss(0, 100))
weights = [1/numSamples]*len(dist)
v = pylab.hist(dist, bins = 100,
weights = [1/numSamples]*len(dist))
pylab.xlabel('x')
pylab.ylabel('Relative Frequency')
print('Fraction within ~200 of mean =',
sum(v[0][30:70]))
	

""
","Weights are used to ensure that the area under the histogram sums to 1, representing a relative frequency distribution. Specifically, they are set to [1/numSamples]*len(dist) to normalize the histogram.",valid,Intermediate,6.2002,Lecture 7: Confidence Intervals,3d8b8210a6f919be25369d985b650abf_MIT6_0002F16_lec7_3_pdf
297,How does 6.0002 differ from a typical introductory computer science course when dealing with uncertainty?,"The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. JOHN GUTTAG: So today, we're going to move on to a fairly different world than the world we've been living in. And this will be a world we'll be living in for quite a few lectures. But before I do that, I want to get back to just finish up something that Professor Grimson started. You may recall he talked about family trees and raised the question, was it actually possible to represent all ancestral relationships as a tree? Well, as a counterexample, I'm sure some of you are familiar with Oedipus Rex. For those of you who are not, I'm happy give you a plot summary at the end of the lecture. It's a rather bizarre plot. But it was captured in a wonderful song by Tom Lehrer. The short story is Oedipus ended up marrying his mother and having four children. And Tom Lehrer, if you've never heard of Tom Lehrer, you're missing one of the world's funniest songwriters. And he had a wonderful song called ""Oedipus Rex,"" and I recommend this YouTube as a way to go and listen to it. And you can gather from the quote what the story is about. I also recommend the play, by the way. It's really kind of appalling what goes on, but it's beautiful. Back to the main topic, here's the relevant reading-- a small bit from later in the book and then chapter 14. You may notice that we're not actually going through the book in order. And the reason we're not doing that is because we're trying to get you information you need in time to do problem sets. So the topic of today is really uncertainty and the fact that the world is really annoyingly hard to understand. This is a signpost related to 6.0002, but we won't go into too much detail about it. We'd rather things were certain. But in fact, they usually are not. And this is a place where 6.0002 diverges from the typical introductory computer science course, which focuses on things that are functional-- given an input, you always get the same output. It's predictable. And we like to do that, because that's easier to teach. But in fact, for reasons we'll be talking about, it's not nearly as useful if you're trying to actually write computations that help you understand the world. You have to face uncertainty head on. An analogy is for many years people, believed","6.0002 diverges from the typical introductory computer science course, which focuses on things that are functional, predictable, and produce the same output given the same input. While these courses often do this because it's easier to teach, 6.0002 emphasizes the need to confront uncertainty directly to write computations that help understand the world.",administrative,Advanced,6.2002,4 Stochastic Thinking,-1BnXEwHUok.en-qlPKC2UN_YU_1_mp4
298,How does the depth-first search algorithm avoid loops when searching for a path?,"Don't panic. It's not as bad as it looks. It actually just captures that idea. Ignore for the moment this down here. It's just going to set it up. Depth first search, I'm going to give it a graph, a start node, an end node, and a path that got me to that start node, which initially is just going to be an empty list, something that tells me what's the shortest path I've found so far, which would be my best solution? And then just a little flag here if I want to print out things along the way. What do I do? I set up path to add in the start node. So if path initially is an empty list, the first time around is just, here's the node I'm at. I print out some stuff and then I say, see if I'm done. I'm just going to stay at home. I'm not going to go anywhere. Unlikely to happen, but you'll see recursively why this is going to be nice. If I'm not done, then notice the loop. I'm going to loop over all the children of the start node. Those are the edges I can reach. Then those I can reach with a single edge. I pick the first one. And in answer to the question, in this case, it would be the order in which I started in the list. I just pick that one up. I then say, let's make sure it's not already in the path because I want to avoid loops. And assuming it isn't, and assuming I don't yet have a solution, or the best solution I have is smaller than what I've done so far, oh, cool, just do the same search. So notice, there's that nice recursion. Right? I'm going to explore. I just picked the first option out of that first node. And the first thing I do is try and see if there's a path from that node using the same thing. So it's literally like I picked this one. I don't care about those other edges. I'm going to try and take this search down. When it comes back with a solution, as long as there is a solution, I'll say that's my best solution so far. And then I go back around. Now this last little piece here is just, if in fact the node's already in the path, I'm just going to print something that says don't keep doing it because you don't need to keep going on. And I'm going to do that loop, taking all the paths down until it comes back. And only at that stage do I go to the next portion around this loop. The piece down here just sets this up, calling it with an initial empty list for path and no solution for shortest. So it's just a nice way of putting a wrap around it that gets things started up. This may look a little funky. It may look a little bit twisted. So let's see if it actually does what we'd expect it to. And to do that I'm just going to be a little test function. I'm going to build that city graph I'm just going to call ""Shortest Path."" I'm going to print it out. And I'd like to see, is there a way to get from Boston to Chicago? So let's go back over to my Python and try that out. And I've got a call for that. Oh, and it prints out. I start off-- oh, so I did it the wrong way. It's from Chicago to Boston. Yes, Chicago to Denver to Phoenix, from Denver to New York, it comes back and says, I've already visited. Basically concludes I can't get from Chicago to Boston. It's just printing out each stage. Let's actually look at that a little more carefully to see how it got there. So there's my example. There is the adjacency list.","The depth-first search algorithm avoids loops by checking if the node is already in the current path. Before continuing the search from a node, it verifies that the node is not already included in the path list. If it is, a message is printed to indicate that further exploration in that direction is unnecessary, preventing loops.",valid,Advanced,6.2002,3 Graph-theoretic Models,V_TulH374hw.en-qlPKC2UN_YU_7_mp4
299,How does the function getTempData process a CSV file to extract temperature data?,"!		 	
def getTempData(): 
    inFile = open('temperatures.csv') 
    data = [] 
    for l in inFile: 
        data.append(tempDatum(l)) 
    return data 
	

?
","The function getTempData opens a CSV file called 'temperatures.csv' and reads its content line by line. For each line, it processes the data into a list by appending the result of the function tempDatum applied on the line. Finally, it returns the compiled list of temperature data.",valid,Advanced,6.2002,Lecture 10: Understanding Experimental Data (cont.),aa05d858752700adcf734b7cdb7a699f_MIT6_0002F16_lec10_41_pdf
300,What does the term 'ending locations' refer to in the context of 6.0002 Lecture 5?," 
 
Ending Locations  
6.0002  LECTURE 5 
34 
","Ending locations refer to the final positions after a series of steps in a random walk scenario, as discussed in 6.0002 Lecture 5.",administrative,Intermediate,6.2002,Lecture 5: Random Walks,508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_34_pdf
302,How many total calls to the fibonacci function occur in the recursive computation of fib(6)?,"Call Tree for Recursive Fibonnaci(6) = 13 
6.0002 LECTURE 2 
17 
ﬁb(6) 
ﬁb(5) 
ﬁb(4) 
ﬁb(3) 
ﬁb(2) 
ﬁb(1) 
ﬁb(0) 
ﬁb(1) 
ﬁb(2) 
ﬁb(1) 
ﬁb(0) 
ﬁb(3) 
ﬁb(2) 
ﬁb(1) 
ﬁb(0) 
ﬁb(1) 
ﬁb(4) 
ﬁb(3) 
ﬁb(2) 
ﬁb(1) 
ﬁb(0) 
ﬁb(1) 
ﬁb(2) 
ﬁb(1) 
ﬁb(0) 
",There are 13 total calls to the fibonacci function in the recursive computation of fib(6).,valid,Intermediate,6.2002,Lecture 2: Optimization Problems,3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_17_pdf
303,"What can lead to a misleading interpretation of data when examining graphical representations, and why is it important to investigate the definitions behind the labels used in such representations?","Let's look at another chart, just in case you think I'm the only one who likes to play with graphics. This is a chart from Fox News. And they're arguing here. It's the shocking statistics that there are 108.6 million people on welfare, and 101.7 with a full-time job. And you can imagine the rhetoric that accompanies this chart. This is actually correct. It is true from the Census Bureau data. Sort of. But notice that I said you should read the labels on the axes. There is no label here. But you can bet that the y-intercept is not 0 on this. Because you can see how small 101.7 looks like. So it makes the difference look bigger than it is. Now, that's not the only funny thing about it. I said you should look at the labels on the x-axis. Well, they've labeled them. But what do these things mean? Well, I looked it up, and I'll tell you what they actually mean. People on welfare counts the number of people in a household in which at least one person is on welfare. So if there is say, two parents, one is working and one is collecting welfare and there are four kids, that counts as six people on welfare. People with a full-time job, is actually does not count households. So in the same family, you would have six on the bar on the left, and one on the bar on the right. Clearly giving a very different impression. And so again, pictures can be good. But if you don't dive deep into them, they really can fool you. Now, before I should leave this slide, I should say that it's not the case that you can't believe anything you read on Fox News. Because in fact, the Red Sox did beat the St. Louis Cardinals 4 to 2 that day. So the moral here is to ask whether the things being compared are actually comparable. Or you're really comparing apples and oranges,","A misleading interpretation of data in graphical representations can occur due to factors like unlabeled axes, non-zero y-intercepts, and differing measures for comparison categories. In the Fox News example, the chart showed a misleading comparison by counting 'people on welfare' as individuals in a household with at least one welfare recipient, while 'people with a full-time job' was based on individual employment status. Therefore, it is important to investigate the definitions behind labels because they might compare non-equivalent groups, leading to an inaccurate impression of the data—effectively comparing 'apples and oranges.'",valid,Advanced,6.2002,14 Classification and Statistical Sins,K2SC-WPdT6k.en-qlPKC2UN_YU_7_mp4
305,What is mutated when adding a drunk to a field?,"If the drunk is there, I'm going to get the distance on x and the distance in y by calling drunk.takeStep. So we saw takeStep for a drunk didn't move the drunk anywhere, because the drunks were immutable, but returned new locations. A new x and new values. And then I'm going to use that to move the drunk in the field. So I'll set self.drunk, so drunk to move x distance and y distance. So it's very simple, but having built this set of classes, we can now actually write the simulation. Oh. What about our classes? Are they mutable or immutable? Not classes. What about fields? Any votes for mutable? Yeah, exactly. Because you can see I'm mutating it right here. I'm changing the value of the dictionary. And in fact, every time I add a drunk to the field, I'm changing the value of the dictionary, which is to say mutating the field. So I'll have a bunch of locations, which are immutable objects. Makes sense that a location is immutable. A bunch of drunks, and the thing I'm going to change is where the drunks are in the field. I said we'd start by simulating a single walk.","The value of the dictionary is mutated, which represents the field.",invalid,Basic,6.2002,5 Random Walks,6wUD_gp5WeE.en-qlPKC2UN_YU_10_mp4
306,What is labeled in the distance matrix?,"Distance Matrix  
Label  
R  
R  
R  
~R  
~R  
~R  
6.0002 LECTURE 13 
7 
","R
R
R
~R
~R
~R",invalid,Basic,6.2002,Lecture 13: Classification,19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13_7_pdf
307,What is the function of the 'findPocketReturn' in the provided code example?," 
 
 
  
 
 
 
 
 
 
 
    
 
 
 
 
    
 
 
 
          
 
    
 
        
 
 
 
                                         
 
 
        
 
 
        
 
                                          
 
                                          
 
        
 
 
              
 
               
 
 
 
               
 
Applying Empirical Rule  
resultDict = {}  
games = (FairRoulette, EuRoulette, AmRoulette)  
for G in games:  
resultDict[G().__str__()] = [] 
for numSpins in (100, 1000, 10000): 
print('\nSimulate betting a pocket for', numTrials, 
'trials of', numSpins, 'spins each') 
for G in games: 
pocketReturns = findPocketReturn(G(), 20, 
numSpins, False) 
mean, std = getMeanAndStd(pocketReturns) 
resultDict[G().__str__()].append((numSpins, 
100*mean, 
100*std)) 
print('Exp. return for', G(), '=', 
str(round(100*mean, 3)) 
+ '%,', '+/- ' + str(round(100*1.96*std, 3)) 
+ '% with 95% confidence') 
6.0002 LECTURE 6 
25
","The 'findPocketReturn' function calculates the return on betting a pocket for a specified number of spins in a roulette game, without showing additional information (as indicated by the 'False' argument).",invalid,Basic,6.2002,Lecture 6: Monte Carlo Simulation,5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_25_pdf
308,What is the danger of choosing an overly complex model when fitting data?,"is much better than the second order model. And that's why, in this case, I would want to use that first order model. So take home message. And then we're going to amplify this. If I pick an overly complex model, I have the danger of overfitting to the training data, overfitting meaning that I'm not only fitting the underlying process, I'm fitting the noise. I get an order 16 model is the best fit when it's in fact, in order 2 model that was generating it. That increases the risk that it's not going to do well with the data, not what I'd like. I want to be able to predict what's going to go on well here. On the other hand. So that would say, boy, just stick with the simplest possible model. But there's a trade off here. And we already saw that when I tried to fit a line to a data that was basically quadratic. I didn't get a good fit. So I'd want to find the balance. An insufficiently complex model won't explain the data well. An overly complex model will overfit the training data. So I'd like to find the place where the model is as simple as possible, but still explains the data. And I can't resist the quote from Einstein that captures it pretty well, ""everything should be made as simple as possible, but not simpler."" In the case of where I started, it should be fit to a quadratic, because it's the right fit. But don't fit more than that, because it's getting overly complex Now how might we go about finding the right model? We're not going to dwell on this but here is a standard way in which you might do it. Start with a low order model. Again, take that data. Fit a linear model to it. Look at not only the r-squared value, but see how well it accounts for new data. Increase the order of the model. Repeat the process. And keep doing that until you find a point at which a model does a good job both on the training data and on predicting new data. An after it starts to fall off, that gives you a point where you might say there's a good sized model. In the case of this data, whether I would have stopped at a quadratic or I might have used a cubic or a quartic depends on the values. But I certainly wouldn't have gone much beyond that. And this is one way, if you don't have a theory to drive you, to think about, how do I actually fit the model the way I would like. Let's go back to where we started. We still have one more big topic to do, and we still have a few minutes left. But let's go back to where we started Hooke's law. There was the data from measuring displacements of a spring, as I added different weights to the bottom of the spring. And there's the linear fit. It's not bad. There's the quadratic fit. And it's certainly got a better r-squared value, though. That could be just fitting to the noise. But you actually can see, I think, that that green curve probably does a better job of fitting the data. Well, wait a minute. Even though the quadratic fit is tighter here, Hooke says, this is linear. So what's going on? Well, this is another place where you want to think about your model. And I'll remind you, in case you don't remember your physics, unless we believe that Hooke was wrong, this should tell us something. And in particular, Hooke's law says, the model holds until you reach the elastic limit of the spring. You stretch a slinky too far, it never springs back. You go beyond that elastic limit. And that's probably what's happening right up there. Through here, it's following that linear relationship. Up at this point, I've essentially broken the spring. The elastic limit doesn't hold anymore. And so really, in this case, I should probably fit different models to different segments. And there's a much better fit. Linear through the first part and another later line once I hit that elastic limit. How might I find this? Well, you could imagine a little search process in which you try and find where's the best place along here to break the data into two sets, fit linear segments to both, and get really good fits for both examples. And I raise it because that's the kind of thing you've also seen before. You could imagine writing code to do that search to find that good fit. OK, that gives you a sense, then, of why you want to be careful about overfitting, why you want to not just look at the coefficient of determination, but see how well does this predict behavior on new data sets. Now suppose I don't have a theory, like Hooke, to guide me. Can I still figure out what's a good model to fit to the data? And the answer is, you bet. We're going to use cross-validation to guide the choice of the model complexity. And I want to show you two examples. If the data set's small, we can use what's called leave one out cross-validation. I'll give you a definition of that in a second. If the data sets bigger than that, we can use k-fold cross-validation. I'll give you a definition that a second. Or just what's called, repeated random sampling. But we can use this same idea of validating new data to try and figure out whether the model is a good model or not. Leave one out cross-validation. This is as written in pseudocode, but the idea is pretty simple. I'm given a dataset.","Choosing an overly complex model risks overfitting to the training data, meaning that it not only fits the underlying process, but also the noise. This can lead to a model that does not perform well on predicting new data sets.",valid,Intermediate,6.2002,10 Understanding Experimental Data cont,fQvg-hh9dUw.en-qlPKC2UN_YU_17_mp4
310,What is the code used to create an animal named 'alligator' with specific attributes?," alligator = Animal('alligator', [1,1,0,1,4])
 animals.append(alligator)
 compareAnimals(animals, 3)
%% 
6.0002 LECTURE 11 
Slide 3 
Image of alligator © source unknown. All rights reserved. This content is excluded from our Creative
Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.
","alligator = Animal('alligator', [1,1,0,1,4])",invalid,Basic,6.2002,Lecture 11: Introduction to Machine Learning,4c4fc506075a8502ccc5191583d22882_MIT6_0002F16_lec11_38_pdf
311,What is the basic process for predicting the label of a new example using the distance matrix method in classification?," 
 
 
 
 
 
 
Using Distance Matrix for Classification  
Simplest approach is probably nearest neighbor  
Remember training data 
When predicting the label of a new example 
◦ Find the nearest example in the training data 
◦ Predict the label associated with that example 
X 
6.0002 LECTURE 13 
6 
","The basic process involves remembering the training data and finding the nearest example in the training data for the new example, then predicting the label associated with that nearest example.",valid,Advanced,6.2002,Lecture 13: Classification,19a63b4aaa3fd9c75cd1b8e940654f53_MIT6_0002F16_lec13_6_pdf
312,How might we approximate the standard deviation of a population if it is unknown?," 
 
 
 
 
 
 
 
 
 
 
Standard Error  of the Mean  
σ
SE = 
n
But, we don’t 
know  standard 
deviation  of 
population 
How might we  
approximate it?  
6.0002  LECTURE 8 
 
24
","We can approximate the standard deviation of a population using the sample standard deviation, which can be calculated from the data available.",valid,Advanced,6.2002,Lecture 8: Sampling and Standard Error,02f2ed5e44be5415b2cba8175c924092_MIT6_0002F16_lec8_24_pdf
313,Why might having overlap between clusters not necessarily be an issue in clustering algorithms?,"I like the that. All right? That has a really nice cluster up here. The fact that the algorithm didn't know the labeling is irrelevant. There's a nice grouping of five. There's a nice grouping of four. And there's a nice grouping of three in between. And in fact, if I looked at the average distance between examples in each of these clusters, it is much tighter than in that example. And so that leads to, then, the question of should I look for four clusters? Question, please. AUDIENCE: Is that overlap between the two clusters not an issue? ERIC GRIMSON: Yes. The question is, is the overlap between the two clusters a problem? No. I just drew it here so I could let you see where those pieces are. But in fact, if you like, the center is there. Those three points are all closer to that center than they are to that center. So the fact that they overlap is a good question. It's just the way I happened to draw them. I should really draw these, not as circles, but as some little bit more convoluted surface. OK? Having done three, I could say should I look for four? Well, those points down there, as I've already said, are an example where it's going to be hard to separate them out. And I don't want to overfit. Because the only way to separate those out is going to be to come up with a really convoluted cluster, which I don't like. All right? Let me finish with showing you one other example from the other direction. Which is, suppose I give you labeled examples. So again, the goal is I've got features associated with each example. They're going to have multiple dimensions on it. But I also know the label associated with them. And I want to learn what is the best way to come up with a rule that will let me take new examples and assign them to the right group. A number of ways to do this.","Overlap between clusters is not necessarily an issue because it depends on how the clusters are drawn or conceptualized. For instance, even if clusters overlap visually, the important aspect is how each point relates to the respective centers of the clusters. If the points in question are closer to one cluster's center compared to the other, they can still be correctly assigned to the appropriate cluster. Clusters should not simply be defined as circles, but can instead have more complex shapes that better represent the data, minimizing overlap in terms of distance to centers rather than purely visual overlap.",valid,Advanced,6.2002,11 Introduction to Machine Learning,h0e2HAPTGF4.en_15_mp4
315,What are some examples of how machine learning is used in real-world applications?,"Another great MIT company called Mobileye that does computer vision systems with a heavy machine learning component that is used in assistive driving and will be used in completely autonomous driving. It will do things like kick in your brakes if you're closing too fast on the car in front of you, which is going to be really bad for me because I drive like a Bostonian. And it would be kicking in constantly. Face recognition. Facebook uses this, many other systems do to both detect and recognize faces. IBM Watson-- cancer diagnosis. These are all just examples of machine learning being used everywhere. And it really is. I've only picked nine. So what is it? I'm going to make an obnoxious statement. You're now used to that. I'm going to claim that you could argue that almost every computer program learns something. But the level of learning really varies a lot. So if you think back to the first lecture in 60001, we showed you Newton's method for computing square roots. And you could argue, you'd have to stretch it, but you could argue that that method learns something about how to compute square roots. In fact, you could generalize it to roots of any order power. But it really didn't learn. I really had to program it. All right. Think about last week when we talked about linear regression. Now it starts to feel a little bit more like a learning algorithm. Because what did we do? We gave you a set of data points, mass displacement data points. And then we showed you how the computer could essentially fit a curve to that data point. And it was, in some sense, learning a model for that data that it could then use to predict behavior. In other situations. And that's getting closer to what we would like when we think about a machine learning algorithm. We'd like to have program that can learn from experience, something that it can then use to deduce new facts. Now it's been a problem in AI for a very long time. And I love this quote.","Examples of machine learning in real-world applications include Mobileye's computer vision systems for assistive and autonomous driving, face recognition systems used by companies like Facebook, and IBM Watson for cancer diagnosis.",valid,Intermediate,6.2002,11 Introduction to Machine Learning,h0e2HAPTGF4.en_2_mp4
316,What happens in the code when a drunk encounters a wormhole?," 
 
 
 
 
 
 
A  Subclass of Field, part 2  
def moveDrunk(self, drunk):  
Field.moveDrunk(self, drunk)  
x = self.drunks[drunk].getX()  
y = self.drunks[drunk].getY()  
if (x, y) in self.wormholes:  
self.drunks[drunk] = self.wormholes[(x, y)]  
6.0002  LECTURE 5 
37 
","When a drunk encounters a wormhole, the drunk's position is updated to the position stored in the self.wormholes dictionary for that specific wormhole location.",invalid,Intermediate,6.2002,Lecture 5: Random Walks,508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_37_pdf
317,"What does the coefficient of determination, r-squared, indicate about a model's fit to the data?","I gave you a set of data. In about 3 slides, I'm going to tell you where the data came from. But I give you a set of data. We could fit the best line to this using that linear regression idea. And again, last piece of reminder, I'm going to use polyfit from PiLab. It just solves that linear regression problem. And I give it a set of x values. I give a corresponding set of y values, need to be the same number in each case. And I give it a dimension. And in this case, one says, find the best fitting line. It will produce that and return it as a tuple, which I'll store under the name model 1. And I could plot it out. So just remind you, polyfit will find the best fitting n dimensional surface, n being that last parameter there, and return it. In a second, we're going to use polyval, which will say, given that model and a set of x values, predict what the y value should be. Apply them. OK, so I fit the line. What do you think? Good fit? Not so much, right? Pretty ugly. I mean, you can see it's probably the best-- or not probably. It is the best fitting line. It sort of accounts for the variation on either side of it. But it's not a very good fit. So then the question is, well why not try fitting a higher order model? So I could fit a quadratic. That is a second order model. y equals ax squared plus bx plus c. Run the same code. Block that out. And I get that. That's the linear model. There's the quadratic model. At least my [? i ?] our looks a lot better, right? It looks like it's following that data reasonably well. OK, I can fit a linear model. I can fit a quadratic model. What about higher order models? What about a fourth order model, an eighth order model, a 644th order model? How do I know which one is going to be best? So for that, I'm going to remind you of the last thing we used. And then we're going to start talking about how to use it further, which is if we try fitting higher order polynomials, do we get a better fit? And to do that, we need to measure what it means for the data to fit. If I don't have any other information. For example, if I don't have a theory that tells me this should be linear in the case afoot, then the best way to do it is to use what's called, the coefficient of determination, r-squared. It's a scale independent thing, which is good. By scale independent, I mean if I take all the data and stretch it out, this will still give me back the same value in terms of the fit. So it doesn't depend on the size of the data. And what it does is it basically tells me the a value between 0 and 1, how well does this model fit the data. So just to remind you, in this case, the y's are the measured values, the p's are the predicted values. That's what my model is saying, for each one of these cases. And mu down here is the mean or the average of the measured values. The way to think about this is this top expression here. Well, that's exactly what I'm trying to minimize, right? So it's giving me an estimate or a measure of the error in the estimates between what the model says and what I actually measure. And the denominator down here basically tells me how much does the data vary away from the mean value. Now here's the idea. If in fact, I can get this to 0, I can get a model that completely accounts for all the variation in the estimates, that's great. It says, the model has fit perfectly. And that means this is 0 so this r value or r squared value is 1. On the other hand, if this is equal to that, meaning that all of the variation in the estimates accounts for none of the variation in the data, then this is 1 and this goes to 0. So the idea is that an r-squared value is close to 1 is great. It says, the model is a good fit to the data. r-squared value is getting closer to 0, not so good.","The coefficient of determination, r-squared, provides a value between 0 and 1 indicating how well a model fits the data. An r-squared value close to 1 suggests the model is a good fit to the data, whereas a value closer to 0 indicates a poor fit.",valid,Intermediate,6.2002,10 Understanding Experimental Data cont,fQvg-hh9dUw.en-qlPKC2UN_YU_4_mp4
318,How can you check if a node is present in a graph represented by a dictionary?,"I just go into the dictionary, edges, and look up the value associated with that node. It gives me back the list. I've got all the things I can reach from that particular node. If I want to know if a node is in the graph, I just search over the keys of the dictionary. They'll either return true or false. If I want to get a node by its name, which is going to be probably more convenient than trying to keep track of all the nodes, well I could pass in a name as a string. And what will I do? I'll just search over all the keys in the dictionary, using the getName method associated with it-- there's the call-- then checking to see if it's the thing I'm looking for. And if it is, I'll return M. I'll return the node itself. What about this thing here? It might bother you a little bit. Wait a minute. That raise, isn't it always going to throw an error? No, because I'm going to go through this loop first. And if I actually find a node, that return is going to pop me out of the call and return the node. So I'll only ever get to this if in fact I couldn't find anything here. And so it's an appropriate way to simply raise the error to say, if I get to this point, couldn't find it, raise an error to say the node's not there. The last piece looks a little funky, Although you may have seen this. I like to print out information about a graph. And I made a choice, which is, I'm going to print out all of the links in the graph. So I'm going to set up a string initially here that's empty. And then I'm going to loop over every key in the dictionary, every node in the graph. And for each one, I'm going to look at all the destinations. So notice, I take the dictionary, I look up the things at that point. That's a list. I loop over that. And I'm just going to add in to result, the name of the source, an arrow, and the name of the destination followed by a carriage return. I'll show you an example in a second. But I'm simply walking down the graph, saying for each source, what can it reach? I'll print them all out. And then I'll return everything but the last element. I'm going to throw away the last carriage return because I don't really need it. So let me show you an example here, trusting that my Python has come up the way I wanted it to. So I'm going to load that in, ignore that for the moment. And I'm going to set g to-- I've got something we're going to come back to in a second that actually creates a graph. And if I print out g, it prints out, in this case, all of the links from source to destination, each one on a new line. OK. So I can create the graphs. That was digraphs. Suppose I actually want to get a graph. Well, I'm going to make it as a subclass of digraph. And in particular, the only thing I'm going to do is I'm going to shadow the addEdge method of digraphs. So if you think about it, it's so I make a graph. If I ask it to add edges, it's going to use this version of addEdge. And what am I going to do? I know in a graph, I could have both directions work. So, given an edge that I want to add into this graph,","To check if a node is in the graph, search over the keys of the dictionary. They'll either return true or false.",invalid,Intermediate,6.2002,3 Graph-theoretic Models,V_TulH374hw.en-qlPKC2UN_YU_4_mp4
319,What are features in the context of machine learning?,"	

	
	










	)









Z
?0









Z
X

A


A



Z
	0




A
A

E
3




A


R
Z
=&


A


A
R
E
6'




A



E
,*




A



Z
%( 
	

U
Features 
Label 
+('5
•  *
•  D
•  +
•  	)
•  E
",Features are individual measurable properties or characteristics used by a machine learning model.,valid,Basic,6.2002,Lecture 11: Introduction to Machine Learning,4c4fc506075a8502ccc5191583d22882_MIT6_0002F16_lec11_26_pdf
321,"What do the varying expected returns from 100 spins and 1,000,000 spins of Fair Roulette indicate about the nature of Monte Carlo simulations?"," 
 
 
  
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
100 and 1M Spins of the Wheel  
100 spins of Fair Roulette 
Expected return betting 2 = -100.0% 
100 spins of Fair Roulette 
Expected return betting 2 = 44.0% 
100 spins of Fair Roulette 
Expected return betting 2 = -28.0% 
1000000 spins of Fair Roulette 
Expected return betting 2 = -0.046% 
1000000 spins of Fair Roulette 
Expected return betting 2 = 0.602% 
1000000 spins of Fair Roulette 
Expected return betting 2 = 0.7964% 
6.0002 LECTURE 6 
13
","The varying expected returns from the smaller sample size of 100 spins (ranging significantly around -100.0%, 44.0%, and -28.0%) compared to the larger sample size of 1,000,000 spins (showing much smaller variation around -0.046%, 0.602%, and 0.7964%) indicate that as the number of trials increases, the results of Monte Carlo simulations tend to converge towards theoretical expected values. This demonstrates the principle that larger sample sizes in simulations provide more reliable estimates, effectively reducing variability.",valid,Advanced,6.2002,Lecture 6: Monte Carlo Simulation,5af20311b02eaab959fcdb7ffb5694d3_MIT6_0002F16_lec6_13_pdf
322,What is the purpose of the 'avail' parameter in the maxVal function?,"Header for Decision Tree Implementa#on 
6.0002 LECTURE 2 
9 
def maxVal(toConsider, avail): 
    """"""Assumes toConsider a list of items,  
               avail a weight 
       Returns a tuple of the total value of a  
           solution to 0/1 knapsack problem and  
           the items of that solution""""” 
toConsider. Those items that nodes higher up in the tree 
(corresponding to earlier calls in the recursive call stack) 
have not yet considered 
 
avail. The amount of space still available  
",The 'avail' parameter represents the amount of space still available in the knapsack for additional items.,invalid,Intermediate,6.2002,Lecture 2: Optimization Problems,3edc8db04a770f3da51086320c8fe4da_MIT6_0002F16_lec2_9_pdf
327,What are the two main methodologies for characterizing the believability of statistical results and how are they implemented?,"that we need to be able to characterize how believable the results are. It's not good enough to just run a program and say, oh, it has an answer. You need to know whether to believe the answer. And the point we made is it's not a binary question. It's not yes, it's right, no, it's wrong. Typically, what we do is we have some statement about confidence intervals and confidence levels. We used two variables to describe how believable the answer is. And that's an important thing. And then we looked at tools we use for doing that. We looked at the central limit theorem. We looked at the empirical rule. We talked about different distributions. And especially, we spent a fair amount of time on the normal or Gaussian distribution. And then finally, we looked at statistical models based upon machine learning. We looked at unsupervised learning, basically just clustering, looked at two algorithms-- hierarchical and k-means. And we looked at supervised learning. And there, we essentially focused mostly on classification. And we looked at two ways of doing that-- k-nearest neighbors and logistic regression. Finally, we talked about presentation of data-- how to build plots, utility of plots, and recently, over the last two lectures, good and bad practices in presenting results about data. So my summary is, I hope that you think you've come a long way, particularly those of you-- how many of you were here in September when we started 6.0001? All right, most of you. Yeah, this, by the way, was a very popular ad for a long time, saying that, finally women are allowed to smoke, isn't this great. And Virginia Slims sponsored tennis-- the women's tennis tour to show how good it was that women were now able to smoke. But anyway, I know not everyone in this class is a woman. So just for the men in the room, you too could have come a long way. I hope you think that, if you look back at how you struggled in those early problems sets, I hope you really feel that you've learned a lot about how to build programs. And if you spend enough time in front of a terminal, this is what you get to look like. What might be next? I should start by saying, this is a hard course. We know that many of you worked hard. And the staff and I really do appreciate it. You know your return on investment. I'd like you to remember that you can now write programs to do useful things. So if you're doing a UROP, you're sitting in a lab, and you get a bunch of data from some experiments, don't just stare at it. Sit down and write some code to plot it to do something useful with it. Don't be afraid to write programs to help you out. There are some courses that I think you're now well-prepared to take. I've listed the ones I know best-- the courses in course 6. 6.009 is a sort of introduction to computer science. I think many of you will find that too easy after taking this course. But maybe, that's not a downside. 6.005 is a software engineering course, where they'll switch programming languages on you. You get to program in Java. 6.006 is a algorithms course in Python and I think actually quite interesting. And students seem to like it a lot, and they learn about algorithms and implementing them. And 6.034 is an introduction to artificial intelligence also in Python. And I should have listed 6.036, another introduction to machine learning in Python. You should go look for an interesting UROP. A lot of students come out of this course and go do UROPs, where they use what they've learned in this course. And many of them really have a very positive experience. So if you were worried that you're not ready for a UROP, you probably are-- a UROP using what's been done here. You can minor in computer science. This is now available for the first time this year. But really, if you have time, you should major in computer science, because it is really the best major on campus-- not even close, as somebody I know would say. Finally, sometimes people ask me where I think computing is headed. And I'll quote one of my favorite baseball players. ""It's tough to make predictions, especially about the future."" And instead of my predictions, let me show you the predictions of some famous people. So Thomas Watson, who was the chairman of IBM-- a company you've probably heard of-- and he said, ""I think there is a world market for maybe five computers."" This was in response to, should they become a computer company, which they were not at the time. He was off by a little bit. A few years later, there was an article in Popular Mechanics, which was saying, computers are amazing. They're going to change enormously. Someday, they may be no more than 1 and 1/2 tons. You might get a computer that's no more than 3,000 pounds-- someday. So we're still waiting for that, I guess. I like this one. This is, having written a book recently, the editor in charge of books for Prentice Hall. ""I traveled the length and breadth of this country and talked with the best people. And I can assure you that data processing is a fad that won't last out the year."" MIT had that attitude for a while. For about 35 years, computer science was in a building off campus, because they weren't sure we were here to stay. Maybe that's not why, but that's why I interpret it. Ken Olsen, an MIT graduate-- I should say, a course 6 graduate-- was the founder and president and chair of Digital Equipment Corporation, which in 1977 was the second largest computer manufacturer in the world based in Maynard, Massachusetts. None of you have ever heard of it. They disappeared. And this is in part why, because Ken said, ""there's no reason anyone would want a computer in their home,"" and totally missed that part of computation. Finally, since this is the end of some famous last words, Douglas Fairbanks, Sr., a famous actor-- this is true-- the last thing he said before he died was, ""never felt better."" Amazing. This was from the movie The Mark of Zorro. Scientists are better. Luther Burbank, his last words were, I don't feel so good. And well, I guess not. [LAUGHTER] And this is the last one.","The two main methodologies for characterizing the believability of statistical results are confidence intervals and confidence levels. Confidence intervals provide a range within which we expect the true value to lie, while confidence levels give the probability that the interval contains the true value. These are implemented using the central limit theorem, different distributions (particularly the normal or Gaussian distribution), and various statistical models, including machine learning approaches like clustering (hierarchical and k-means) and classification (k-nearest neighbors and logistic regression).",valid,Advanced,6.2002,15 Statistical Sins and Wrap Up,iOZVbILaIZc.en-qlPKC2UN_YU_10_mp4
329,"How is the model built and optimized in the context of logistic regression, and what are the necessary inputs?","It's the name of a class, and here are three methods of that class. Fit, which takes a sequence of feature vectors and a sequence of labels and returns an object of type logistic regression. So this is the place where the optimization is done. Now all the examples I'm going to show you, these two sequences will be-- well all right. So think of this as the sequence of feature vectors, one per passenger, and the labels associated with those. So this and this have to be the same length. That produces an object of this type, and then I can ask for the coefficients, which will return the weight of each variable, each feature. And then I can make a prediction, given a feature vector returned the probabilities of different labels. Let's look at it as an example. So first let's build the model.","Building and optimizing a logistic regression model involves using the 'fit' method, which takes a sequence of feature vectors and a sequence of labels as inputs. These sequences must be of the same length. The 'fit' method then returns an object of type logistic regression, where the optimization process is done. Once the model is built, we can obtain the coefficients representing the weights of each feature and make predictions on the probabilities of different labels given a feature vector.",valid,Advanced,6.2002,13 Classification,eg8DJYwdMyg.en-qlPKC2UN_YU_6_mp4
330,What is an important precaution to take when doing calculations or simulations where the outcome is expected?," 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
Let’s Try a Sanity Check  
§Try on cases where we think we know the answer  
◦ A  very important precaution! 
6.0002  LECTURE 5 
24 
",Try on cases where we think we know the answer as a sanity check.,invalid,Intermediate,6.2002,Lecture 5: Random Walks,508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_24_pdf
331,What are the possible movements available to the 'masochistic drunk' during a random walk?,"I tried to simulate when I was wandering around, wanders around at random. And a drunk I like to think of it as a New Englander, or a masochistic drunk, who tries forever to move ever northward, because he or she wants to be frozen. I do like this picture of entering the state of Maine in the winter. So here is the usual drunk. Subclass of drunk, and it can take steps at random, one step, either increasing y, a step north, decreasing y, a step south, increasing x, a step east, or decreasing x a step west. So those are the choices. And it's going to return one of those at random. I think we saw random.choice in the last lecture.","The masochistic drunk can take steps at random, either increasing y (a step north), decreasing y (a step south), increasing x (a step east), or decreasing x (a step west). These are the choices, and one of these is returned at random.",invalid,Intermediate,6.2002,5 Random Walks,6wUD_gp5WeE.en-qlPKC2UN_YU_7_mp4
333,What happens when you cherry pick hypotheses?,"and you see a barn with a bunch of bullet holes in the wall right in the middle of a target. But what actually happened was you had a barn. The farmer just shot some things at random at the barn, then got out his paint brush and painted a target right around where they happened to land. And that's what happens when you cherry pick hypotheses. What's the bottom line of all these statistical fallacies? When drawing inferences from data, skepticism is merited. There are, unfortunately, more ways to go wrong than to go right. And you'll read the literature that tells you that in the scientific literature more than half of the papers were later shown to be wrong. You do need to remember that skepticism and denial are different. It's good to be skeptical. And I love Ambrose Bierce's description of the difference here. If you had never read Ambrose Bierce, he's well worth reading. He wrote something called The Devil's Dictionary,","You might create a misleading result, akin to a farmer shooting randomly at a barn and then painting a target around where the bullets hit.",valid,Basic,6.2002,15 Statistical Sins and Wrap Up,iOZVbILaIZc.en-qlPKC2UN_YU_8_mp4
334,What is involved in the process of a random walk taking a possible first step?," 
 
 
 
 
Yet Another Possible First Step  
6.0002  LECTURE 5 
7 
","In a random walk, one considers the possible directions or choices that can be made at each step. The 'possible first steps' are the various options or possible directions available as the walk begins. Specifics about these directions or how they influence the walk aren't provided here, but the mention of 'Yet Another Possible First Step' implies there is a decision point with various outcomes.",empty,Advanced,6.2002,Lecture 5: Random Walks,508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_7_pdf
335,What are some of the reasons random walks are considered significant in various fields?," 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
Why Random Walks?  
§Random walks are important in many
domains
◦Understanding the stock market (maybe)
◦Modeling diffusion processes
◦Etc.
§Good illustration of how to use
simulations  to understand things
§Excuse to cover some important
programming topics
◦Practice with classes
◦Practice with plotting
6.0002  LECTURE 5 
3 
","Random walks are significant because they are important in many domains, such as understanding the stock market and modeling diffusion processes. They also serve as a good illustration of how simulations can be used to understand concepts and provide practice with important programming topics like classes and plotting.",valid,Advanced,6.2002,Lecture 5: Random Walks,508a9076aebfc7d597dde836255182c7_MIT6_0002F16_lec5_3_pdf

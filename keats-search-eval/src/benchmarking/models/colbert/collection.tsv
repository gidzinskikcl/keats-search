0	"18.404/6.840 Lecture 24 Last time: - Probabilistic computation - The class BPP - Branching programs - Arithmetization - Started showing !"" ROBP ∈ BPP Today: (Sipser §10.2) - Finish !"" ROBP ∈ BPP 1"
1	- Review: Probabilistic TMs and BPP coin flip step each choice has Defn: A probabilistic Turing machine (PTM) is a variant of a NTM where each computation step has 1 or 2 possible choices. deterministic step 50% probability Defn: For ! ≥0 say PTM $ decides language % with error probability ! if for every &, Pr[ $ gives the wrong answer about & ∈% ] ≤! . Defn: BPP = % some poly-time PTM decides % with error ! = +⁄, } Check-in 24.1 Actually using a probabilistic algorithm Amplification lemma: 2−. /01 2 presupposes a source of randomness. Can we use a standard pseudo-random number generator (PRG) as the source? & ∈% & ∉% (a) Yes, but the result isn’t guaranteed. (b) Yes, but it will run in exponential time. Many Few Few Many (c) No, a TM cannot implement a PRG. accepting rejecting accepting rejecting (d) No, because that would show P = BPP. 2 Check-in 24.1
2	Review: Branching Programs
3	"Boolean Labeling Alternative way to view BP computation Show by example: Input is !"" = 0, !# = 1, !$ = 1 The BP follows its execution path. !"" 1 Label all nodes and edges on the execution path with 1 0 1 1 0 and off the execution path with 0. Output the label of the output node 1. 1 !# 1 !# 0 0 Obtain the labeling inductively by using these rules: 0 1 0 1 0 0 0 1 ' 0 1 ' ∧!) ' ∧!) '"" ∨'# ∨'$ !$ !$ !) 1 '"" '# '$ 1 0 0 0 0 1 0 0 1 = output 0 1 Label outgoing edges from nodes Label nodes from incoming edges 4"
4	Arithmetization Method Method: Simulate ∧and ∨with + and ×. %& 0 1 ' ' (1 −%&) ' %& ' , ' - ' . ' , + ' - + ' . %, %- %- 0 1 0 1 %. %. 0 1 0 1 0 1 0 1 Replace Boolean labeling with arithmetical labeling Inductive rules: Start node labeled 1 ' ∧/ →' ×/ = '/ ' → 1 −' ' ∨/ →' + / −'/ Simulate ∨with + because the BP is acyclic. The execution path can enter a node at most one time. ' ∧%& ' ∧%& ' , ∨' - ∨' . 5
5	"! "" ! # ! # 0 1 0 1 0 1 0 1 Non-Boolean Labeling Use the arithmetized interpretation of the BP’s computation to define its operation on non-Boolean inputs. Example: ! "" = 2, ! # = 3 Output = −7 ! ( 0 1 ) ) (1 −! () ) ! ( ) "" ) # ) - ) "" + ) # + ) - 1 −1 = 1 1 −2 1 2 = 2 2 8 = 2 + 6 2 = −1 1 −3 −3 = −1 3 2 3 = 6 2 1 −3 = −4 −1 −3 + −4 = −7 Recall labeling rules: Algorithm sketch for 45 ROBP: “On input : "" , : # 1. Pick a random non-Boolean input assignment. 2. Evaluate : "" and : # on that assignment. 3. If : "" and : # disagree then reject. If they agree then accept.” More details and correctness proof to come. First some algebra… 6"
6	"Roots of Polynomials Let ! "" = $%"" & + $( "" &) ( + $*"" &) * + ⋯+ $& be a polynomial. If , is some constant and ! , = 0 call , a root of ! . Polynomial Lemma: If ! "" ≠0 is polynomial of degree ≤0 then ! has ≤0 roots. Proof by induction (see text). Corollary 1: If ! ( ("" ) and ! *("" ) are both degree ≤0 and ! ( ≠! * then ! ( , = ! *(, ) for ≤0 values , . Proof: Let ! = ! ( −! *. Above holds for any field 4 (a field is a set with + and × operations that have typical properties). We will use a finite field 46 with 7 elements where 7 is prime and +, × operate mod 7. Corollary 2: If ! "" ≠0 has degree ≤0 and we pick a random 8 ∈46, then Pr ! 8 = 0 ≤⁄ & 6. Proof: There are at most 0 roots out of 7 possibilities. Theorem"
7	"(Schwartz-Zippel): If ! ""( , … , "" = ≠0 has degree ≤0 in each "" >and we pick random 8( , … , 8= ∈46 then Pr ! 8( , … , 8= = 0 ≤ ⁄ = & 6 Proof by induction (see text). roots 7"
8	"! "" ! # ! # 0 1 0 1 0 1 0 1 Symbolic Execution Leave the ! $ as variables and obtain an expression in the ! $ for the output of the BP. 1 1 −! "" ! "" 1 −! "" 1 −! # + (! "" ) ! # (1 −! "" ) 1 −! # 1 −! "" (x#) (! "" ) ! # (! "" ) 1 −! # 1 −! "" x# + (! "" ) 1 −! # ! $ 0 1 + +(1 −! $) +! $ +"" +# +, +"" + +# + +, Recall labeling rules: 1 −! "" ! "" = output = 1 −! "" x# , 1 −! , ! . ⋯(1 −! 0 ) + ! "" ! # ! , 1 −! . ⋯ ! 0 + ! "" 1 −! # 1 −! , ! . ⋯ (! 0 ) ⋮ + ! "" ! # 1 −! , ! . ⋯ (! 0 ) form of output Corresponds to the TRUE"
9	rows in the truth table of the Boolean function Exponents ≤1 due to “read-once” Assume read exactly once so that for each 3 (! $) or (1 −! $) appears in every row 8
10	"Algorithm for !""ROBP = “On input (), (+ [on variables ,), … , ,.] 1. Find a prime / ≥32. 2. Pick a random non-Boolean input assignment 3 = 3), … , 3. where each 34 ∈67. 3. Evaluate () and (+ on 3 by using arithmetization. 4. If () and (+ agree on 3 then accept. If they disagree then reject.” Claim: (1) () ≡(+ →Pr :) 3 = :+ 3 = 1 (2) () ≢(+ →Pr :) 3 = :+ 3 ≤⁄ ) ? Proof (1): If () ≡(+ then they agree on all Boolean inputs. Thus their functions have the same truth table. Thus their associated polynomials :) and :+ are identical. Thus :) and :+ always agree (even on non-Boolean inputs). Proof (2): If () ≢(+ then :) ≠:+ so : = :) −:+ ≠0. From Schwartz-Zippel, Pr :) 3 = :+ 3 ≤ ⁄ C. 7 ≤ ⁄ . ?. = ⁄ ) ?. (Note that D = 1.) !""ROBP ∈BPP :) and :+ each have the form: 1 −,) ,+ 1 −,? ,E ⋯(1"
11	−,.) + ,) ,+ ,? 1 −,E ⋯ ,. + ,) 1 −,+ 1 −,? ,E ⋯ (,.) ⋮ + ,) ,+ 1 −,? ,E ⋯ (,.) ,) 0 1 0 1 () ,E 0 1 0 1 (+ arithmetize :) :+ Check-in 24.2 Check-in 24.2 If the BPs were not read-once, the polynomials might have exponents ≥1. Where would the proof fail? (a) () ≡(+ implies they agree on all Boolean inputs (b) Agreeing on all Boolean inputs implies :) = :+ (c) Having :) = :+ implies :) and :+ always agree 9
12	"Algorithm for !""ROBP = “On input (), (+ [on variables ,), … , ,.] 1. Find a prime / ≥32. 2. Pick a random non-Boolean input assignment 3 = 3), … , 3. where each 34 ∈67. 3. Evaluate () and (+ on 3 by using arithmetization. 4. If () and (+ agree on 3 then accept. If they disagree then reject.” Claim: (1) () ≡(+ →Pr :) 3 = :+ 3 = 1 (2) () ≢(+ →Pr :) 3 = :+ 3 ≤⁄ ) ? Proof (1): If () ≡(+ then they agree on all Boolean inputs. Thus their functions have the same truth table. Thus their associated polynomials :) and :+ are identical. Thus :) and :+ always agree (even on non-Boolean inputs). Proof (2): If () ≢(+ then :) ≠:+ so : = :) −:+ ≠0. From Schwartz-Zippel, Pr :) 3 = :+ 3 ≤ ⁄ C. 7 ≤ ⁄ . ?. = ⁄ ) ?. (Note that D = 1.) !""ROBP ∈BPP :) and :+ each have the form: 1 −,) ,+ 1 −,? ,E ⋯(1"
13	−,.) + ,) ,+ ,? 1 −,E ⋯ ,. + ,) 1 −,+ 1 −,? ,E ⋯ (,.) ⋮ + ,) ,+ 1 −,? ,E ⋯ (,.) ,) 0 1 0 1 () ,E 0 1 0 1 (+ arithmetize :) :+ Check-in 24.3 Check-in 24.3 If :) and :+ were exponentially large expressions, would that be a problem for the time complexity? (a) Yes, but luckily they are polynomial in size. (b) No, because we can evaluate them without writing them down. 10
14	"Quick review of today 1. Simulated Read-once Branching Programs by polynomials 2. Gave probabilistic polynomial equality testing method 3. Showed !"" ROBP ∈BPP 11"
15	MIT OpenCourseWare https://ocw.mit.edu 18.404J / 18.4041J / 6.840J Theory of Computation Fall 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
16	"18.404/6.840 Lecture 23 Last time: - !""#$%↑ is EXPSPACE-complete - Thus !""#$%↑ ∉ PSPACE - Oracles and P versus NP Today: (Sipser §10.2) - Probabilistic computation - The class BPP - Branching programs 1"
17	"Probabilistic TMs Defn: A probabilistic Turing machine (PTM) is a variant of a NTM where each computation step has 1 or 2 possible choices. deterministic coin flip step ­ step each choice has 50% probability Pr[ branch ! ] = 2&' where ! has ( coin flips Pr[ "" accepts # ] = + Pr[ branch ! ] Pr[ "" rejects # ] = 1 − Pr[ "" accepts # ] b accepts computation tree for "" on # branch ! Defn: For 7 ≥0 say PTM "" decides language : with error probability 7 if for every #, Pr[ "" gives the wrong answer about # ∈: ] ≤7 i.e., # ∈: → Pr[ "" rejects # ] ≤7 # ∉: → Pr[ "" accepts # ] ≤7. 2"
18	"Defn: BPP = "" some poly-time PTM decides "" with error # = ⁄ % & } Amplification lemma: If '% is a poly-time PTM with error #% < ⁄ % ) then, for any 0 < #) < ⁄ % ), there is an equivalent poly-time PTM ') with error #). Can strengthen to make #) < 2−,-./ 0 . Proof idea: ') = “On input 1 1. Run '% on 1 for 2 times and output the majority response.” Details: Calculation to obtain 2 and the improved error probability. Significance: Can make the error probability so small it is negligible. The Class BPP 3"
19	"NP and BPP Computation trees for ! on "" "" ∈$ NP ≥1 accepting Few accepting Many rejecting BPP Many accepting Few rejecting all rejecting "" ∉$ Check-in 23.1 Check-in 23.1 Which of these are known to be true? Check all that apply. (a) BPP is closed under union. (b) BPP is closed under complement. (c) P ⊆BPP (d) BPP ⊆PSPACE 4"
20	"Example: Branching Programs Defn: A branching program (BP) is a directed, acyclic (no cycles) graph that has 1. Query nodes labeled !"" and having two outgoing edges labeled 0 and 1. 2. Two output nodes labeled 0 and 1 and having no outgoing edges. 3. A designated start node. BP # with query nodes !$, … , !' describes a Boolean function (: 0,1 ' →{0,1}: Follow the path designated by the query nodes’ outgoing edges from the start note until reach an output node. Example: For !$ = 1, !/ = 0, !0 = 1 we have ( 101 = 0 = output. BPs are equivalent if they describe the same Boolean function. Defn: 12BP = #$, #/ #$ and #/ are equivalent BPs (written #$ ≡#/) } Theorem: 12BP is coNP-complete (on pset 6) 12BP ∈BPP ? Unknown. That would imply NP ⊆BPP and would be surprising! Instead, consider a restricted problem. !$ !0 !$ !/ !/ !0 0 1 0 1 0 1 0 1 0 1 0 1 0 1 5"
21	"Read-once Branching Programs Defn: A BP is read-once if it never queries a variable more than once on any path from the start node to an output. Defn: !""ROBP = (), (+ () and (+ are equivalent read-once BPs} Theorem: !""ROBP ∈BPP .) ./ .) .+ .+ ./ 0 1 0 1 0 1 0 1 0 1 0 1 0 1 Not read-once Check-in 23.2 Check-in 23.2 Assuming (as we will show) that !""ROBP ∈BPP, can we use that to show !""BP ∈BPP by converting branching programs to read-once branching programs? (a) Yes, there is no need to re-read inputs. (b) No, we cannot do that conversion in general. (c) No, the conversion is possible but not in polynomial-time. 6"
22	"!""ROBP ∈BPP Theorem: !""ROBP ∈BPP Proof attempt: Let ( = “On input *+, *- 1. Pick . random input assignments and evaluate *+ and *- on each one. 2. If *+ and *- ever disagree on those assignments then reject. If they always agree on those assignments then accept.” What . to chose? If *+ ≡*- then they always agree so Pr[ ( accepts *+, *- ] = 1 If *+ ≢*- then want Pr[ ( accepts *+, *- ] ≤⁄ + 3 so want Pr[ ( rejects *+, *- ] ≥ ⁄ - 3 . But *+ and *- may disagree rarely, say in 1 of the 26 possible assignments. That would require exponentially many samples to have a good chance of finding a disagreeing assignment and thus would require . > ⁄ - 3 26. But then this algorithm would use exponential time. Try a different idea: Run *+ and *- on non-Boolean inputs. 8+ 0 1 0 1 *+ 89 0 1 0 1 *- 7"
23	"!"" !# !# 0 1 0 1 !$ !$ 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 Boolean Labeling Show by example: Input is !"" = 0, !# = 1, !$ = 1 The BP follows its execution path. Label all nodes and edges on the execution path with 1 and off the execution path with 0. Output the label of the output node 1. Alternative way to view BP computation Obtain the labeling inductively by using these rules: ' ' ∧!) ' ∧!) '"" '# '$ '"" ∨'# ∨'$ !) 0 1 Label edges from nodes Label nodes from incoming edges 8"
24	Arithmetization Method Method: Simulate ∧and ∨with + and ×. %& 0 1 ' ' (1 −%&) ' %& ', '- '. ', + '- + '. %, %- %- 0 1 0 1 %. %. 0 1 0 1 0 1 0 1 Replace Boolean labeling with arithmetical labeling Inductive rules: Start node labeled 1 ' ∧/ →'×/ = '/ ' → 1 −' ' ∨/ →' + / −'/ Works because the BP is acyclic. The execution path can enter a node at most one time. ' ∧%& ' ∧%& ', ∨'- ∨'. 9
25	"!"" !# !# 0 1 0 1 0 1 0 1 Non-Boolean Inputs Use the arithmetized interpretation of the BP’s computation to define its operation on non-Boolean inputs. Example: !"" = 2, !# = 3 Output = −7 !( 0 1 ) ) (1 −!() ) !( )"" )# )- )"" + )# + )- 1 −1 = 1 1 −2 1 2 = 2 2 8 = 2 + 6 2 = −1 1 −3 −3 = −1 3 2 3 = 6 2 1 −3 = −4 −1 −3 + −4 = −7 Recall labeling rules: Revised 4 for 56ROBP: “On input ;"", ;# 1. Pick a random non-Boolean input assignment. 2. Evaluate ;"" and ;# on that assignment. 3. If ;"" and ;# disagree then reject. If they agree then accept.” Correctness proof… after Thanksgiving. Check-in 23.3 Check-in 23.3 What is the output for this branching program using the arithmetized interpretation if !"" = 1, !# = < ? (a) (1 −<) (b) (< + 1) (c) < 10"
26	"Quick review of today 1. Defined probabilistic Turing machines 2. Defined the class BPP 3. Sketched the amplification lemma 4. Introduced branching programs and read-once branching programs 5. Started the proof that !""ROBP ∈BPP 6. Introduced the arithmetization method 11"
27	MIT OpenCourseWare https://ocw.mit.edu 18.404J / 18.4041J / 6.840J Theory of Computation Fall 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
28	18.404/6.840 Lecture 7 Last time: - Equivalence of variants of the Turing machine model a. Multi-tape TMs b. Nondeterministic TMs c. Enumerators - Church-Turing Thesis - Notation for encodings and TMs Today: (Sipser §4.1) - Decision procedures for automata and grammars 1
29	"TMs and Encodings – review A TM has 3 possible outcomes for each input !: 1. Accept ! (enter ""acc ) 2. Reject ! by halting (enter ""rej ) 3. Reject ! by looping (running forever) ( is T-recognizable if ( = *(,) for some TM ,. ( is T-decidable if ( = *(,) for some TM decider ,. halts on all inputs 〈/0, /2, … , /4〉 encodes objects /0, /2, … , /4 as a single string. Notation for writing a TM , is , = “On input ! [English description of the algorithm]” 2"
30	Acceptance Problem for DFAs Let $DFA = !, # ! is a DFA and ! accepts #} Theorem: $DFA is decidable Proof: Give TM *A−DFA that decides $DFA . *A−DFA = “On input , Shorthand: 1. Check that , has the form !, # where if not. On input !, # ! is a DFA and # is a string; reject 2. Simulate the computation of ! on #. 3. If ! ends in an accept state then accept. If not then reject.” input tape contains !, # - = ./, … , .1 , Σ = 0,1 , 5 = ⋯, ./, 7 = ⋯ , # = 01101 *A−DFA ! # .8 , 9 work tape with current state and input head location 3
31	Acceptance Problem for NFAs Let !NFA = &, ( & is a NFA and & accepts (} Theorem: !NFA is decidable Proof: Give TM *A−NFA that decides !NFA . *A−NFA = “On input &, ( 1. Convert NFA & to equivalent DFA &′. 2. Run TM *A−DFA on input &′, ( . [ Recall that *A−DFA decides !DFA ] 3. Accept if *A−DFA accepts. Reject if not.” New element: Use conversion construction and previously constructed TM as a subroutine. 4
32	Emptiness Problem for DFAs Let !DFA = & & is a DFA and ' & = ∅} Theorem: !DFA is decidable Proof: Give TM *E−DFA that decides !DFA . *E−DFA = “On input & [IDEA: Check for a path from start to accept.] 1. Mark start state. 2. Repeat until no new state is marked: Mark every state that has an incoming arrow from a previously marked state. 3. Accept if no accept state is marked. Reject if some accept state is marked.” 5
33	".EQ−DFA = “On input , [IDEA: Make DFA that accepts where and disagree.] 1. Construct DFA 2 where , 2 = , ( ∩, * ∪, ( ∩, * . 2. Run .E−DFA on 〈2〉. 3. Accept if .E−DFAaccepts. Reject if .E−DFA rejects.” , ( , * Symmetric difference Equivalence problem for DFAs Let !""DFA = { (, * | ( and * are DFAs and , ( = , * } Theorem: !""DFA is decidable Proof: Give TM .EQ−DFA that decides !""DFA . Check-in 7.1 6"
34	Corollary: Every CFL is decidable. Proof: Let ! be a CFL, generated by CFG '. Construct TM 34 = “on input ) 1. Run /A−CFG on ', ) . 2. Accept if /A−CFG accepts Reject if it rejects.” Acceptance Problem for CFGs Let !CFG = { ', ) | ' is a CFG and ) ∈, ' } Theorem: ACFG is decidable Proof: Give TM /A−CFG that decides !CFG . /A−CFG = “On input ', ) 1. Convert ' into CNF. Recall Chomsky Normal Form (CNF) only allows 2. Try all derivations of length 2|)| − 1. rules: 3. Accept if any generate ). A → BC Reject if not. B → b Check-in 7.2 Lemma 1: Can convert every CFG into CNF. Proof and construction in book. Can we conclude that !PDA is decidable? a) Yes. Lemma 2: If 6 is in CNF and ) ∈ ,(6) then b) No, PDAs may be nondeterministic. every derivation of ) has 2|)| − 1 steps. c) No, PDAs may not halt. Proof: exercise. Check-in 7.2 7
35	S a R T a Emptiness Problem for CFGs Let !CFG = { ' | ' is a CFG and ) ' = ∅} Theorem: !CFG is decidable Proof: ,E−CFG = “On input ' [IDEA: work backwards from terminals] 1. Mark all occurrences of terminals in '. S → RTa 2. Repeat until no new variables are marked R → R Tb Tb Mark all occurrences of variable A if A → B1B2 ⋯ B4 is a rule and all B5 were already marked. T → a 3. Reject if the start variable is marked. Accept if not.” 8
36	"Theorem: 0123(CFG is NOT decidable Proof: Homework. Equivalence Problem for CFGs Let !""CFG = { (, * | (, * are CFGs and , ( = ,(*) } Theorem: !""CFG is NOT decidable Proof: Next week. Let 0123(CFG = { ( | ( is an ambiguous CFG } Check-in 7.3 Why can’t we use the same technique we used to show !""DFA is decidable to show that !""CFG is decidable? a) Because CFGs are generators and DFAs are recognizers. b) Because CFLs are closed under union. c) Because CFLs are not closed under complementation and intersection. Check-in 7.3 9"
37	Acceptance Problem for TMs Let !TM = { &, ( | & is a TM and & accepts (} Theorem: !TM is not decidable Proof: Thursday. Theorem: !TM is T-recognizable Proof: The following TM + recognizes !TM + = “On input &, ( Turing’s original “Universal Computing Machine” 1. Simulate & on input (. 2. Accept if & halts and accepts. Description of &, input ( 3. Reject if & halts and rejects. + 4. Reject if & never halts.” Not a legal TM action. Von Neumann said + inspired the concept of a stored program computer. 10
38	Quick review of today 1. We showed the decidability of various problems about automata and grammars: !DFA , !NFA , &DFA , &'DFA , !CFG , &DFA 2. We showed that !TM is T-recognizable. 11
39	MIT OpenCourseWare https://ocw.mit.edu 18.404J / 18.4041J / 6.840J Theory of Computation Fall 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
40	18.404/6.840 Lecture 11 Last time: - The Computation History Method for proving undecidability - The Post Correspondence Problem is undecidable - Linearly bounded automata, !LBA is decidable - Configurations, Computation histories - %LBA and !&&CFG are undecidable Today: (Sipser §6.1 – §6.2) - Self-reproducing machines and The Recursion theorem - Short introduction to mathematical logic 1
41	Midterm exam 90 minutes length + 20 minutes for printing/scanning/uploading. Open book, postings, piazza, notes, and lecture videos, from this year. Covers through Recursion Theorem presented today. Will not include section on mathematical logic. Not permitted: Communication with anyone except course staff, other materials, internet searching. Not permitted: Providing information about the exam to anyone who hasn’t completed it. Please respect our honor system. 2
42	Self-reproduction Paradox Suppose a Factory makes Cars - Complexity of Factory > Complexity of Car (because Factory needs instructions for Car + robots, tools, … ) Can a Factory make Factories? - Complexity of Factory > Complexity of Factory? - Seems impossible to have a self-reproducing machine But, living things self-reproduce How to resolve this paradox? © Source unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/fairuse. Self-reproducing machines are possible! 3
43	"NO, would be circular reasoning. 〈1〉 A Self-Reproducing TM Theorem: There is a TM !""#$ which (on any input) halts with 〈!""#$〉 on the tape. Lemma: There is a computable function ': Σ∗ → Σ∗ such that ' , = 〈./〉 for every ,, where ./ is the TM ./ = “Print , on the tape and halt”. Proof: Straightforward. Proof of Theorem: !""#$ has two parts, 0 and 1. 0 1 1 = .〈3〉 ? 1 = “1. Compute '(tape contents) to get 0. 0 = .〈2〉 Compute 0 = .〈2〉 .〈2〉 from 1 on tape. 〈01〉 = 〈!""#$〉 !""#$ 2. Combine with 1 to get 01 = !""#$. 3. Halt with 〈!""#$〉 on tape.” Can implement in any programming language. 4"
44	"Write “Hello World” Hello World Write this sentence Write this sentence Write the following twice, the second time in quotes “Hello World” Hello World “Hello World” Cheating: TMs don’t have this self-reference primitive. English Implementation Check-in 11.1 Implementations of the Recursion Theorem have two parts, a Template and an Action. In the TM and English implementations, which is the Action part? (a) A and the upper phrase (b) A and the lower phrase (c) B and the upper phrase (d) B and the lower phrase. Write the following twice, the second time in quotes “Write the following twice, the second time in quotes” Write the following twice, the second time in quotes “Write the following twice, the second time in quotes” & % ' 〈)〉 Compute & = ' 〈)〉 from % on tape. !""#$ Note on Pset Problem 6: Don’t need to worry about quoting. 5 Check-in 11.1 &%"
45	"〈&!〉 The Recursion Theorem A compiler which implements “compute your own description” for a TM. Theorem: For any TM ! there is a TM "" where for all # R on input # operates in the same way as ! on input #, "" . "" Proof of Theorem: "" has three parts: %, &, and !. % & ! ! is given # % = (〈*+〉 (〈*+〉 & = “1. Compute -(tape contents after #) to get %. %&! = "" 2. Combine with &! to get %&! = "". 3. Pass control to ! on input #, "" .” Moral: You can use “compute your own description” in describing TMs. Check-in 11.2 Can we use the Recursion Theorem to design a TM ! where . ! = { ! } ? (a) Yes. (b) No. 6 Check-in 11.2 Compute % from tape"
46	Ex 1: !TM is undecidable - new proof Theorem: !TM is not decidable Proof by contradiction: Assume some TM $ decides !TM. Consider the following TM %: % = “On input ' 1. Get own description 〈%〉. 2. Use $ on input 〈%, '〉 to determine whether % accepts '. 3. Do the opposite of what $ says.” 7
47	Ex 2: Fixed-point Theorem Theorem: For any computable function !: Σ∗ → Σ∗ , there is a TM & such that ' & = '(*) where ! & = 〈*〉. In other words, consider ! to be a program transformation function. Then for some program &, its behavior is unchanged by !. Proof: Let & be the following TM. & = “On input . 1. Get own description 〈&〉. 2. Compute ! & and call the result 〈*〉. 3. Simulate * on ..” 8
48	"!""#TM . Ex 3: !""#TM is T-unrecognizable !& Defn: ! is a minimal TM if < ! →) !& ≠)(!). Thus, a minimal TM has the shortest description among all equivalent TMs. Let !""#TM = ! ! is a minimal TM }. Theorem: !""#TM is T-unrecognizable. Proof by contradiction: Assume some TM / enumerates Consider the following TM 0: 0 = “On input 1 1. Get own description 〈0〉. Check-in 11.3 Let 6 be an infinite subset of !""#TM . Is it possible that 6 is T-recognizable? (a) Yes. (b) No. 2. Run enumerator / until some TM 4 appears, where 0 < 4 . 3. Simulate 4 on 1.” Thus ) 0 = )(4) and 0 < 4 so 4 isn’t minimal, but 4 ∈ )(/), contradiction. 9 Check-in 11.3"
49	Other applications 1. Computer viruses. 2. A true but unprovable mathematical statement due to Kurt Gödel: “This statement is unprovable.” 10
50	"Intro to Mathematical Logic Goal: A mathematical study of mathematical reasoning itself. Formally defines the language of mathematics, mathematical truth, and provability. Gödel’s First Incompleteness Theorem: In any reasonable formal system, some true statements are not provable. Proof: We use two properties of formal proofs: 1) Soundness: If ! has a proof "" then ! is true. 2) Checkability: The language "", ! "" is a proof of statement !} is decidable. Checkability implies the set of provable statements {〈!〉| ! has a proof} is T-recognizable. SImilarly, if we can always prove ', ( ∈ *TM when it is true, then *TM is T-recognizable (false!). Therefore, some true statements of the form ', ( ∈ *TM are unprovable. Next, we use the Recursion Theorem to give a specific example of a true but unprovable statement. 11"
51	"→TM # accepts 0 →#, 0 ∈'TM is false →!"" cannot have a oof. →#, 0 ∉'TM →R accepts 0 →# found a proof that !"" is true "" is true. A True but Unprovable Statement Implement Gödel statement “This statement is unprovable.” Let !"" be the statement #, 0 ∈ 'TM where # is the following TM: # = “On any input 1. Obtain 〈#〉 and use it to obtain !"" . 2. For each possible proof - = -., -/, … Test if - is a proof that !"" is true. If yes, then accept. Otherwise, continue.” Theorem: (1) !"" has no proof (2) !"" is true !"" Proof: (1) If !"" has a proof pr →! (2) If !"" is false 12"
52	Quick review of today 1. Self-reference and The Recursion Theorem 2. Various applications. 3. Sketch of Gödel’s First Incompleteness Theorem in mathematical logic. 13
53	MIT OpenCourseWare https://ocw.mit.edu 18.404J / 18.4041J / 6.840J Theory of Computation Fall 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
54	"18.404/6.840 Lecture 21 Last time: - Log-space reducibility - L = NL? question - !""#$ is NL-complete - 2&""# is NL-complete - NL = coNL (unfinished) Today: (Sipser §9.1) - Finish NL = coNL - Time and Space Hierarchy Theorems 1"
55	"Theorem: If some NL-machine (log-space NTM) computes -./ℎ, then some NL-machine computes 8. Proof: “On input 〈1, 3〉 1. Let < ←0 2. For each node 7 3. If -./ℎ1, 3, 7 = YES, then < ←< + 1 4. If -./ℎ1, 3, 7 = NO, then continue 5. Output <” Next: Converse of above NL = coNL (part 1/4) Theorem (Immerman-Szelepcsényi): NL = coNL Proof: Show !""#$ ∈ NL Defn: NTM & computes function ': Σ∗ → Σ∗ if for all , 1) All branches of & on , halt with ' , on the tape or reject. 2) Some branch of & on , does not reject. Check-in 21.1 Let -./ℎ 1, 3, / = 5 YES, if 1 has a path from 3 to / Let 1 be the graph below. NO, if not What is the value of 8 = 8 1, 3 ? Let 6 = 6 1, 3 = 7 -./ℎ 1, 3, 7 = YES} 3 (a) 2 (e) 6 Let 8 = 8 1, 3 = |6| 1 = (b) 3 (f)"
56	7 1 6 (c) 4 (g) 8 6 = Reachable nodes 3 (d) 5 (h) 9 8 = # reachable 8 = |6| 2 Check-in 21.1
57	"NL = coNL (part 2/4) – key idea Theorem: If some NL-machine computes !, then some NL-machine computes ""#$ℎ. Proof: “On input 〈', ), $〉 where ' has + nodes 1. Compute ! 2. , ←0 3. For each node / 4. Nondeterministically go to (p) or (n) (p) Nondeterministically pick a path from ) to / of length ≤+. 5 ' If fail, then reject. ) If / = $, then output YES, else set , ←, + 1. (n) Skip / and continue. ! = |5| 5. If , ≠! then reject. 6. Output NO.” [found all ! reachable nodes and none were $} 3"
58	"NL = coNL (part 2/4) – key idea SIMPLIFIED!! Theorem: If some NL-machine computes !, then some NL-machine computes ""#$ℎ. Proof: “On input 〈', ), $〉 where ' has + nodes 1. Compute ! 2. , ←0 3. For each node / 4 ' 4. Nondeterministically pick a path from ) of length ≤+. If it ends at $ then output YES and stop. ) If it ends at /, set , ←, + 1. ! = |4| 5. If , ≠! then reject. 6. Output NO.” [found all ! reachable nodes and none were $} 4"
59	"NL = coNL (part 3/4) YES, if ( has a path * to % of length ≤1 Let #$%ℎ"" (, *, % = 8 NO, if not Let 6"" = 6"" (, * = / #$%ℎ"" (, *, / = YES} Let !"" = !"" (, * = |6""| Theorem: If some NL-machine computes !"", then some NL-machine computes #$%ℎ"" . Proof: “On input 〈(, *, %〉 1. Compute !"" ( 2. , ←0 3. For each node / 4. Nondeterministically go to (p) or (n) !"" = |6""| (p) Nondeterministically pick a path from * to / of length ≤1. If fail, then reject. If / = %, then output YES, else set , ←, + 1. (n) Skip / and continue. 5. If , ≠ !"" then reject. 6. Output NO” [found all !"" reachable nodes and none were %} 5 6"" *"
60	"NL = coNL (part 4/4) Theorem: If some NL-machine computes !"", then some NL-machine computes #$%ℎ""'(. Proof: “On input 〈*, ,, %〉 1. Compute ! 2. . ←0 3. For each node 1 4. Nondeterministically go to (p) or (n) * 7"" 7""'( (p) Nondeterministically pick a path from , to 1 of length ≤3. , If fail, then reject. If 1 has an edge to %, then output YES, else set . ←. + 1. (n) Skip 1 and continue. !"" = |7""| 5. If . ≠ !"" then reject. Hence :;<= ∈ NL !""'( = |7""'(| 6. Output NO.” [found all !"" reachable nodes “On input 〈*, ,, %〉 and none had an edge to %} 1. !? = 1. 2. Compute each !""'( from !"" for 3 = 1 to @. Corollary: Some NL-machine computes !""'( from !"" . 3. Accept if #$%ℎA(*, ,, %) = NO. 4. Reject if #$%ℎA(*, ,, %) = YES.” 6"
61	Review: Major Complexity Classes L ⊆ NL ⊆ P ⊆ NP ⊆ PSPACE ≠ Today The time and space hierarchy theorems show that if a TM is given more time (or space) then it can do more.* * certain restrictions apply. For example: TIME #$ ⊆, TIME #% [ ⊆, means proper subset ] SPACE #$ ⊆, SPACE #% 7
62	Space Hierarchy Theorem (1/2) Theorem: For any !: ℕ → ℕ (where ! satisfies a technical condition) there is a language % where % requires & ! ' space, i.e, 1) % is decidable in & ! ' space, and 2) % is not decidable in ( ! ' space On other words, SPACE ( ! ' ⊆, SPACE ! ' Notation: SPACE ( ! ' = {,| some TM . decides , in space ( ! ' } Proof outline: (Diagonalization) Give TM 0 where % 1) 0 runs in & ! ' space 2) 0 ensures that 1(0) ≠ 1(.) for SPACE ! ' every TM . that runs in ( ! ' space. SPACE ( ! ' Let % = 1(0). 8
63	pa 10 r 2 ste s or hasn’t halted.” 2. What if . loops? [' must always halt] FIX: Stop . if it runs for 25 6 steps. 3. How to compute #? FIX: Assume # is space constructible, i.e., can compute # within ,(# $ ) space. Nice functions like log $, log: $, $, $:, 26, … are all s ce constructible. Mark off # $ tape Space Hierarchy Theorem (2/2) / $ # $ ⋯ / ⋯ = 010110 ⋯ 10100000 # Hide me → ' 〈.〉 Goal: Exhibit ! ∈ SPACE # $ but ! ∉ SPACE & # $ Give ' where ! = )(') and 1) ' runs in , # $ space Issues: 2) ' ensures that )(') ≠ )(.) 1. What if . runs in & # $ space but has for every TM . that runs in & # $ space. a big constant? Then ' won’t have space ' = “On input / to simulate . when / is small. FIX: simulate . on infinitely many /. 3. Simulate* .
64	on / fo b) It accepts Accept if . rejects, c) It rejects Reject if . accepts 2. If / ≠ . ∗ for some TM 5 6 p ., reject. What happens when we run ' on input 〈'〉1000000 ? 1. Mark off #($) tape cells where $ = |/|. If ever try to use more tape, reject. Check-in 21.2 a) It loops d) We get a contradiction *Note: ' can simulate . with a constant factor e) Smoke comes out space overhead. 9 Check-in 21.2
65	Time Hierarchy Theorem (1/2) Theorem: For any !: ℕ → ℕ where ! is time constructible there is a language % where % requires & ! ' time, i.e, 1) % is decidable in & ! ' time, and 2) % is not decidable in ( ! ' / log ! ' time - . On other words, TIME ( ⊆, TIME ! ' /01 - . Proof outline: Give TM 3 where 1) 3 runs in & ! ' time 2) 3 ensures that 4(3) ≠ 4(8) for every TM 8 that runs in ( ! ' / log ! ' time . Let % = 4(3). 10
66	Time Hierarchy Theorem (2/2) Goal: Exhibit ! ∈ TIME # $ but ! ∉ TIME & # $ / log # $ ! = ,(.) where 1) . runs in 0 # $ time 2) . ensures that ,(.) ≠ ,(2) for every TM 2 that runs in & # $ / log # $ time. Why do we lose a factor of 789 : ; ? . = “On input 3 . must halt within 0 # $ time. 1. Compute #($). To do so, . counts the number of steps it uses 2. If 3 ≠ 2 10∗ for some TM 2, reject. and stops if the limit is exceeded. The counter 3. Simulate* 2 on 3 for # $ / log # $ steps. has size log # $ and is stored on the tape. It must be kept near the current head location. Accept if 2 rejects, Cost of moving it adds a 0 log # $ overhead Reject if 2 accepts or hasn’t halted.” factor. So to halt within 0 # $ time, . stops
67	*Note: . can simulate 2 with a log factor when the counter reaches # $ / log # $ . time overhead due to the step counter. 11
68	Recap: Separating Complexity Classes L ⊆ NL ≠ ⊆ P ⊆ NP ⊆ PSPACE Space Hierarchy Theorem NL ⊆ SPACE log& ' ⊆, SPACE ' ⊆ PSPACE 12 Check-in 21.3 Consider these two famous unsolved questions: 1. Does L = P? 2. Does P = PSPACE? What do the hierarchy theorems tell us about these questions? a) Nothing b) At least one of these has answer “NO” c) At least one of these has answer “YES” Check-in 21.3
69	Quick review of today 1. Finish NL = coNL 2. Space hierarchy theorem 3. Time hierarchy theorem 13
70	MIT OpenCourseWare https://ocw.mit.edu 18.404J / 18.4041J / 6.840J Theory of Computation Fall 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
71	"18.404/6.840 Lecture 25 Last time: - Schwartz-Zippel Theorem - !""ROBP ∈ BPP Today: (Sipser §10.4) - Interactive Proof Systems - The class IP - Graph isomorphism problem - coNP ⊆ IP (part 1) 1"
72	"Interactive Proofs – Introduction Illustration: Graph isomorphism testing Defn: Undirected graphs ! and "" are isomorphic if they are identical except for a permutation (rearrangement) of the nodes. 2"
73	"obvious unknown unknown unknown for a permutation (rearrangement) of the nodes. Interactive Proofs – Introduction Illustration: Graph isomorphism testing Defn: Undirected graphs ! and "" are isomorphic if they are identical except Defn: #$% = !, "" ! and "" are isomorphic graphs} #$% ∈ NP #$% ∈ P ? #$% is NP-complete ? #$% ∈ NP ? #$% ∈ NP therefore a Prover can convince a poly-time Verifier that ! and "" are isomorphic (if true). Even though #$% ∈ NP is unknown, a Prover can still convince a poly-time Verifier that ! and "" are not isomorphic (if true). Requires interaction and a probabilistic Verifier. 3"
74	"Interactive Proofs – informal model Probabilistic polynomial time TM © Sesame Workshop. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/fairuse. Professor = Verifier (V) Unlimited computation Graduate Students = Prover (P) © Source unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/fairuse. ! "" Professor wants to know if graphs ! and "" are isomorphic. - He asks his Students to figure out the answer. - But he doesn’t trust their answer. He must be convinced. If the Students claim that ! and "" are isomorphic, they can give the isomorphism and convince him. But what if they claim that ! and "" are not isomorphic? - The Professor randomly and secretly picks ! or "" and permutes it, then sends the result to the Students. - If Students can identify which graph the Professor picked reliably (repeat this 100 times), then he’s convinced. 4"
75	Interactive Proofs – formal model Two interacting parties Verifier (V): Probabilistic polynomial time TM Prover (P): Unlimited computational power Both P and V see input !. They exchange a polynomial number of polynomial-size messages. Then V accepts or rejects. Defn: Pr[ (V ↔ P) accepts ! ] = probability that V accepts when V interacts with P, given input !. Defn: IP = $ for some V and P (This P is an “honest” prover) ! ∈$ → Pr [ (V ↔ P) accepts ! ] ≥ )⁄* ! ∉$ → for any prover P, Pr [ (V ↔ P) , accepts ! ] ≤ .⁄* Think of ,P as a “crooked” prover trying to make V accept when it shouldn’t. An amplification lemma can improve the error probability from .⁄* to ./)0123 4 5
76	"If & and ( are not isomorphic then P can determine which graph V chose randomly. Thus Pr [ (V ↔P) accepts 〈&, (〉] = 1 ≥⁄ 1 2 If & and ( are isomorphic then any 3P has no way to tell which graph V chose randomly. So 3P has a 50% chance of answering correctly each time and a 25% chance of being correct twice. Thus Pr [ (V ↔3P) accepts 〈&, (〉] = ⁄ 4 5 < ⁄ 4 2. !""# ∈ IP Theorem: !""# ∈ IP Proof: Protocol for V and (the honest) P on input 〈&, (〉 1) Repeat twice: 2) V→P Randomly choose & or ( and permute to get +, then send + 3) P→V Compare + with & and (. Send “&” or “(” (V’s choice in step 2) 4) V accepts if P was correct both times. Otherwise V rejects. Check-in 25.1 Suppose we change the model to allow the Prover access to the Verifier’s random choices. Now consider the same protocol as described above. What language does it describe? (a)"
77	{〈&, (〉| & ≠(} (b) {〈&, (〉| & and ( are not isomorphic } (c) {〈&, (〉| & and ( are any two graphs } (d) ∅ Check-in 25.1 6
78	[ V is deterministic ] [ V ignores P ] [ We won’t prove. Idea: explore all possible interactions in poly space. ] Facts about IP – Checkin 25.2 Which of the following is true? Check all that apply a) NP ⊆ IP b) BPP ⊆ IP c) IP ⊆ PSPACE Surprising Theorem: PSPACE ⊆ IP so IP = PSPACE We will prove only a weaker statement: coNP ⊆ IP 7
79	"#""#$ problem Defn: #""#$ = &, ( Boolean formula & has exactly ( satisfying assignments} Let #& = the number of satisfying assignments of Boolean formula &. So #""#$ = &, ( ( = #&} Defn: Language * is NP-hard if # ≤, * for every # ∈ NP. (Note: * is NP-complete if * is NP-hard and * ∈ NP.) Theorem: #""#$ is coNP-hard Proof: Show ""#$ ≤. #""#$ / & = ⟨&, 0⟩ To show coNP ⊆ IP we will show #""#$ ∈ IP 8"
80	"Two useful facts #""#$ ∈ IP – notation #""#$ = ', ) Boolean formula ' has exactly ) satisfying assignments} Theorem: #""#$ ∈ IP Proof: First some notation. Assume ' has + variables ,-, … , ,/. Let '(0) be ' with ,- = 0 (0 substituted for ,-) 0 = FALSE and 1 = TRUE. Let ' 01 be ' with ,- = 0 and ,4 = 1. Let '(5- … 56) be ' with ,- = 5- , … , ,6 = 56 for 5-, … , 56 ∈ 0,1 . Call 5-, … , 56 presets. The remaining ,67-, … , ,/ stay as unset variables. Let #' = the number of satisfying assignments of '. Let #' 0 = the number of satisfying assignments of ' 0 . Let #'(5- … 56) = the number of satisfying assignments of '(5- … 56) 1. #'(5- Check-in 25.3 If #' = 9 and #' 0 = 6 then what do we know? a) #' 1 = 3 c) #' 00 ≤5 b) #' 1 = 15 d) none"
81	of these … 56) = Equivalently: #'(5- … 56) = 8 '(5- … 5/) 567-, … , 5/ ∈ 0,1 2. #'(5- … 5/) = '(5- … 5/) #' 5- … 560 + #' 5- … 561 9 Check-in 25.3
82	"#' #' 1 #' 10 #""#$ ∈ IP – 1st attempt Theorem: #""#$ ∈ IP Proof: Protocol for V and (the honest) P on input 〈', )〉 0) P sends #'; V checks ) = #' 1) P sends #' 0 , #' 1 ; V checks #' = #' 0 + #' 1 2) P sends #' 00 , #' 01 , #' 10 , #' 11 ; V checks #' 0 = #' 00 + #' 01 ) If ) ≠#' #' 1 = #' 10 + #' 11 0 −1 0 −1 ⋮ 0 = #' 0) P sends #' 0 ⋯0 , … , #' 1 ⋯1 ; V checks #' 0 ⋯0 = #' 0 ⋯00 + #' 0 ⋯01 ⋮ V checks #' 1 ⋯1 = #' 1 ⋯10 + #' 1 ⋯11 + #' 0 #' 1 0 0 + 1) V checks #' 0 ⋯0 = ' 0 ⋯0 + + ⋮ #' 00 #' 01 #' 10 #' 11 #' 1 ⋯1 = ' 1 ⋯1 ⋮ ⋮ ⋮ V accepts"
83	if all checks are correct. Otherwise V rejects. #' 0 ⋯0 ⋯ #' 1 ⋯1 = Problem: Exponential. How to fix? 10 ' 0 ⋯ 0 = ⋯ ≠ ' 1 ⋯ 1
84	"Idea for fixing #""#$ ∈ IP protocol ) ) = = #& #& + #& 0 #& 1 #& ,- + + Non-Boolean assignments to the variables of & #& 00 #& 01 #& 10 #& 11 #& ,-,. To be continued… + + + + ⋮ ⋮ ⋮ #& 0 ⋯0 ⋯ #& 1 ⋯1 #& ,- ⋯,/ & 0 ⋯ 0 = ⋯ = & 1 ⋯ 1 = & ,- ⋯,/ 11"
85	"Quick review of today 1. Introduced the interactive proof system model 2. Defined the class IP 3. Showed !""# ∈ IP 4. Started showing #""&' ∈ IP to prove that coNP ⊆ IP 12"
86	MIT OpenCourseWare https://ocw.mit.edu 18.404J / 18.4041J / 6.840J Theory of Computation Fall 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
87	18.404/6.840 Lecture 6 Last time: - Proving languages not Context Free - Turing machines - Recognizers and deciders - T-recognizable and T-decidable languages Today: (Sipser §3.2 – §3.3) - Equivalence of variants of the Turing machine model a. Multi-tape TMs b. Nondeterministic TMs c. Enumerators - Church-Turing Thesis - Notation for encodings and TMs 1
88	"Turing machine model – review head ˽ ˽ . . . a b a b b Finite read/write input tape control On input ! a TM "" may halt (enter #acc or #rej) ) is T-recognizable if ) = +("") for some TM "". or loop (run forever). ) is T-decidable if ) = +("") for some TM decider "". So "" has 3 possible outcomes for each input !: halts on all inputs 1. Accept ! (enter #acc ) Turing machines model general-purpose computation. 2. Reject ! by halting (enter #rej ) Q: Why pick this model? 3. Reject ! by looping (running forever) A: Choice of model doesn't matter. All reasonable models are equivalent in power. Virtues of TMs: simplicity, familiarity. 2"
89	Multi-tape Turing machines input tape Finite control . . . }work tapes, initially blank all tapes read/write Theorem: ! is T-recognizable iff some multi-tape TM recognizes ! Proof: (→) immediate. (←) convert multi-tape to single tape: & simulates ' by storing the contents of multiple tapes on a single tape in “blocks”. a a b b a . . . ˽ ˽ Record head positions with dotted symbols. multi-tape ' ˽ 1 0 1 . . . ˽ c c c a . . . . . . Some details of &: 1) To simulate each of '’s steps a. Scan entire tape to find dotted symbols. b. Scan again to update according to '’s (. single tape & … ˽ ˽ a a b b a # 1 0 1 # # c c c a c. Shift to add room as needed. 2) Accept/reject if ' does. 3
90	Nondeterministic Turing machines A Nondeterministic TM (NTM) is similar to a Deterministic TM except for its transition function !: Q×Γ → '( )×Γ× {L, R} ). Theorem: + is T-recognizable iff some NTM recognizes + Proof: (→) immediate. (←) convert NTM to Deterministic TM. Deterministic TM NTM . a a b a ˽ ˽ - 02 a a b a # 01 c b # 03 b c b ˽ ˽ Nondeterministic computation tree - simulates . by storing each thread’s tape in a for . on input /. separate “block” on its tape. Also need to store the head location, and the state for each thread, in the block. If a thread forks, then - copies the block. If a thread accepts then - accepts. accept 4 . . .
91	"← / Proof: ( ) Convert to equivalent TM . / = for input !: Simulate ' (on blank input). Whenever ' prints 0, test 0 = !. Accept if = and continue otherwise. Turing Enumerators ˽ ˽ ˽ ˽ ˽ ˽ ˽ . . . Finite control read/write tape – initially blank printer Defn: A Turing Enumerator is a deterministic TM with a printer. It starts on a blank tape and it can print strings !"" , !$ , !% , … possibly going forever. Its language is the set of all strings it prints. It is a generator, not a recognizer. For enumerator ' we say ( ' = ! ' prints !}. Theorem: A is T-recognizable iff + = ((') for some T-enumerator '. ' Proof: (→) Convert TM / to equivalent enumerator '. Check-in 6.1 ' = Simulate / on each !2 in Σ∗ = {6, 0,1,00,01,10, … } When converting TM / to enumerator ', If / accepts !2 then print !2 . does ' always print the strings in string order? Continue with next"
92	"!2 . a) Yes. Problem: What if / on !2 loops? b) No. Fix: Simulate / on !"" , !$ , … , !2 for 9 steps, for 9 = 1,2, … Print those !2 which are accepted. Image of the printer © Source unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/fairuse. Check-in 6.1 5"
93	Church-Turing Thesis ~1936 Alan Turing 1912–1954 Alonzo Church 1903–1995 = Algorithm Turing machine Intuitive Formal Instead of Turing machines, can use any other “reasonable” model of unrestricted computation: !-calculus, random access machine, your favorite programming language, … Big impact on mathematics. Check-in 6.2 Check-in 6.2 Which is the following is true about Alan Turing? Check all that apply. a) Broke codes for England during WW2. b) Worked in AI. c) Worked in Biology. d) Was imprisoned for being gay. e) Appears on a British banknote. Will appear in 2021 Photos of Alonzo Church and Alan Turing © Source unknown. Image of Alan Turing on the UK's £50 note © The Governor and Company of the Bank of England. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/fairuse. 6
94	Hilbert’s 10th Problem In 1900 David Hilbert posed 23 problems #1) Problem of the continuum ( Does set ! exist where ℕ< ! < |ℝ| ? ). #2) Prove that the axioms of mathematics are consistent. #10) Give an algorithm for solving Diophantine equations. Diophantine equations: Equations of polynomials where solutions must be integers. Example: 3'( −2'+ −+(, = 7 solution: ' = 1, + = 2, , = −2 Let 1 = 2 polynomial 2 '3, '(, … , '5 = 0 has a solution in integers) Hilbert’s 10th problem: Give an algorithm to decide 1. Matiyasevich proved in 1970: 1 is not decidable. Note: 1 is T-recognizable. David Hilbert 1862—1943 © Source unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/fairuse. 7
95	Notation for encodings and TMs Notation for encoding objects into strings - If ! is some object (e.g., polynomial, automaton, graph, etc.), we write 〈!〉to be an encoding of that object into a string. - If !$, !&, … , !( is a list of objects then we write 〈!$, !&, … , !(〉 to be an encoding of them together into a single string. Notation for writing Turing machines We will use high-level English descriptions of algorithms when we describe TMs, knowing that we could (in principle) convert those descriptions into states, transition function, etc. Our notation for writing a TM ) is ) = “On input + [English description of the algorithm]” Check-in 6.3 If , and - are strings, would ,- be a good choice for their encoding 〈,, -〉into a single string? a) Yes. b) No. Check-in 6.3 8
96	"TM – example revisited TM ! recognizing "" = a$b$c$ % ≥0 ! = “On input ( 1. Check if ( ∈a∗b∗c∗, reject if not. 2. Count the number of a’s, b’s, and c’s in (. 3. Accept if all counts are equal; reject if not.” High-level description is ok. You do not need to manage tapes, states, etc… 9"
97	"Problem Set 2 #5) Show ! is T-recognizable iff there is a decidable "" where ! = $ ∃& $, & ∈"" } $, & ∈Σ∗ 〈$, &〉is an encoding of the pair of strings $ and & into a single string. Think of "" as a collection of pairs of strings. $-axis &-axis ($, &) "" ! ! is a “projection” of "" $ 10"
98	Quick review of today 1. We showed that various TM variants (multi-tape, nondeterministic, enumerator) are all equivalent to the single-tape model. 2. Concluded that all “reasonable” models with unrestricted memory access are equivalent. 3. Discussed the Church-Turing Thesis: Turing machines are equivalent to “algorithms”. 4. Notation for encoding objects and describing TMs. 5. Discussed Pset 2 Problem 5. 11
99	MIT OpenCourseWare https://ocw.mit.edu 18.404J / 18.4041J / 6.840J Theory of Computation Fall 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
100	"18.404/6.840 Lecture 16 Last time: - NP-completeness - 3""#$ ≤P &'()*+ - 3""#$ ≤P ,#-.#$, Today: (Sipser §7.4) - Cook-Levin Theorem: ""#$ is NP-complete - 3""#$ is NP-complete 1"
101	today Or: P = NP previously ≤% *#+ ≤% 3*#+ ≤% (,-./0 NP ≤% */!*0+-*/1 ≤% 2#13#+2 ≤% /2#13#+2 NP NP-complete P recitation Quick Review Defn: ! is NP-complete if 1) ! ∈ NP 2) For all # ∈ NP, # ≤% ! If ! is NP-complete and ! ∈ P then P = NP. Importance of NP-completeness 1) Evidence of computational intractability. 2) Gives a good candidate for proving P ≠ NP. To show some language ( is NP-complete, show 3*#+ ≤% (. or some other previously shown NP-complete language 2 Check-in 16.1 The big sigma notation means summing over some set. 4 9 = 1 + 2 + ⋯+ > 56768 The big AND (or OR) notation has a similar meaning. For example, if ? = ?5 ⋯?8 and @ = @5 ⋯@8 are two strings of length >, when does the following hold? A ?7 = @7 = TRUE 56768 (a) Whenever ? and @ agree on some symbol. (b) Whenever ? = @. Check-in 16.1
102	"Cook-Levin Theorem (idea) Theorem: !""# is NP-complete Proof: 1) !""# ∈ %& (done) 2) Show that for each "" ∈ %& we have "" ≤( !""#: Let "" ∈ %& be decided by NTM ) in time *+ . Give a polynomial-time reduction , mapping "" to !""#. ,: Σ∗→ formulas , 1 = 〈45,7〉 1 ∈ "" iff 45,7 is satisfiable Idea: 45,7 simulates ) on 1. Design 45,7 to “say” ) accepts 1. Satisfying assignment to 45,7 is a computation history for ) on 1. 3"
103	"a - ) ⋯ Tableau for ! on "" Defn: An (accepting) tableau for NTM ! on "" is an #$×#$ table representing an computation history for ! on "" on an accepting branch of the nondeterministic computation. #$ #$ ""* ⋯"", ˽ … ˽ &' & ""( "") ← Start configuration for ! on "" Construct 45,7 to “say” ! accepts "". ⋮ 45,7 “says” a tableau for ! on "" exists. 45,7 = 4cell ∧ 4start ∧ 4move ∧ 4accept ⋯ &accept ⋯ ← Accepting configuration 4"
104	"Constructing !"",$: !start and !accept !"",$ “says” a tableau for , on - exists. !"",$ = !cell ∧!start ∧!move ∧!accept !cell done • !start = 45,5,67 ∧45,8,$9 ∧45,:,$; ∧⋯∧45,=>,˽ !accept = ?@ -5 -8 -: ⋯-= a ?A -8 ⋯ ⋯ ?accept ⋯ B 5CDC=> 4=>,D,6accept ˽ … ˽ ←Start configuration ←Accepting configuration 1 1 2 FG 3 ⋯ FG 1 ⋯ FG 6"
105	"Constructing !"",$: !move !"",$ “says” a tableau for ) on * exists. !"",$ = !cell ∧!start ∧!move ∧!accept 45 *6 *7 *8 ⋯*: a 4; *7 ⋯ ⋯ 4accept ⋯ 2×3 neighborhood Legal neighborhoods: consistent with )’s transition function Illegal neighborhoods: not consistent with )’s transition function a 4; b 48 a c a b c a b c a b c a b 4? a b c d b c a b c a d c a b c a 47 c a 4; c a b c a 4; c 48 d 4@ potential examples: examples: r s t v y z Legal C DE,FG6,r ∧DE,F,s ∧DE,FH6,t ∧DEH6,FG6,v ∧DEH6,F,y ∧DEH6,FH6,z !move = I 6JE,FJ:K • • • ˽ … ˽ Claim: If every 2×3 neighborhood is legal then tableau corresponds to a computation history. Says that the neighborhood at L, M is legal M L 7"
106	"Conclusion: !""# is NP-complete $% &' &( &) ⋯&+ a $, &( ⋯ ⋯ $accept ⋯ ˽ … ˽ 23 23 Summary: For "" ∈NP, decided by NTM 5, we gave a reduction 6 from "" to !""#: 6: Σ∗→formulas 6 & = 〈=>,@〉 & ∈"" iff =>,@ is satisfiable. =>,@ = =cell ∧=start ∧=move ∧=accept The size of =>,@ is roughly the size of the tableau for 5 on &, so size is I 23×23 = I 2(3 . Therefore 6 is computable in polynomial time. 8"
107	"3""#$ is NP-complete Theorem: 3""#$ is NP-complete Proof: Show ""#$ ≤& 3""#$ Give reduction ' converting formula ( to 3CNF formula (′, preserving satisfiability. (Note: ( and (′ are not logically equivalent) Example: Say ( = a ∧b ∨c ∧ a ∨b Tree structure for (: a b b c a ∧ ∧ ∨ ∨ -. -/ -0 -1 (2 = a ∧b →-. ∧ a ∧b →z. ∧ a ∧b →z. ∧ a ∧b →z. ∧ -. ∧c →-/ ∧ z. ∧c →-/ ∧ -. ∧c →-/ ∧ z. ∧c →z/ ⋮repeat for each -5 ∧(-1) Observe that a ∧b →c is logically equivalent to a ∨b ∨c a ∧b →c ↔ a ∧b ∨c ↔ a ∨b ∨c ↔ a ∨b ∨c Logical equivalence: # →9 and # ∨9 # ∧9 and # ∨9 a b a ∧b = c 1 1 1 0 1 0 1 0 0 0 0 0 a ∧b →c a ∧b →c a ∧b →c a ∧b →c Check-in 16.3 Check-in 16.3 If ( has : operations (∧and ∨), how many clauses"
108	has (’? (a) : + 1 (c) :/ (b) 4: + 1 (d) 2:/ a b a ∨b = c 1 1 1 0 1 1 1 0 1 0 0 0 a ∧b →c a ∧b →c a ∧b →c a ∧b →c 9
109	"Quick review of today 1. !""# is NP-complete 2. 3!""# is NP-complete 10"
110	MIT OpenCourseWare https://ocw.mit.edu 18.404J / 18.4041J / 6.840J Theory of Computation Fall 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
111	18.404/6.840 Lecture 12 Last time: - Self-reproducing machines and The Recursion Theorem - Applications: a) New proof that !TM is undecidable b) $%&TM is T-unrecognizable (and so is any infinite subset of $%&TM) c) True but unprovable statements Today: (Sipser §7.1) - Introduction to Complexity Theory - Complexity classes; the Class P 1
112	Intro to Complexity Theory Computability theory (1930s - 1950s): Is A decidable? Complexity theory (1960s - present): Is A decidable with restricted resources? (time/memory/…) Example: Let ! = a#b# $ ≥0 . Q: How many steps are needed to decide !? Depends on the input. We give an upper bound for all inputs of length '. Called “worst-case complexity”. 2
113	Big 1 and little 2 Defn: 3(() is + 4 ( if 3 ( ≤)4(() for some fixed ) independent of (. Defn: 3(() is 6 4 ( if 3 ( ≤74(() for all 7 > 0 and large (. ' a a a b b b ˽ b a --------------------------- # steps to decide ! = a#b# $ ≥ 0 Theorem: A 1-tape TM ' can decide ! where, on inputs of length (, ' uses at most )(* steps, for some fixed constant ). Terminology: ' uses +((*) steps. Proof: ' = “On input . 1. Scan input to check if . ∈ a ∗ b ∗ , reject if not. 2. Repeat until all crossed off. Scan tape, crossing off one a and one b. Reject if only a’s or only b’s remain. 3. Accept if all crossed off. ” 3 Analysis: + ( steps ++(() iterations ×+(() steps + ( + +((*) steps = +((*) steps Check-in 12.1 How much improvement is possible in the bound for this theorem about 1-tape TMs deciding !? (a) +((*)
114	is best possible. (b) +(( log () is possible. (c) +(() is possible. Check-in 12.1
115	' a a a b b b ˽ b b b a a a even (6) odd (3) odd (1) even (6) odd (3) odd (1) Deciding ! = a#b# $ ≥ 0 faster Theorem: A 1-tape TM ' can decide ! by using ((* log *) steps. Proof: ' = “On input / Analysis: 1. Scan tape to check if / ∈ a ∗ b ∗ . Reject if not. ( * steps 2. Repeat until all crossed off. +((log *) iterations Scan tape, crossing off every other a and b. ×((*) steps Reject if even/odd parities disagree. --------------------------------­ 3. Accept if all crossed off. ” ( * + ((* log *) steps = ((* log *) steps Further improvement? Not possible. Theorem: A 1-tape TM ' cannot decide ! by using 4(* log *) steps. You are not responsible for knowing the proof. 4 Parities odd (3) odd (1) a’s even (6) b’s even (6) odd (3) odd (1)
116	' a a a b b b ˽ b b b a a a a a a ˽ a a a ˽ ˽ ˽ ˽ ˽ ˽ ˽ ˽ ˽ ˽ ˽ ˽ Deciding ! = a#b# $ ≥0 even faster Theorem: A multi-tape TM ' can decide ! using ((*) steps. ' = “On input , Analysis: 1. Scan input to check if , ∈ a ∗ b ∗ , reject if not. ( * steps 2. Copy a’s to second tape. +((*) steps 3. Match b’s with a’s on second tape. +((*) steps 4. Accept if match, else reject. ” -----------------­ = ((*) steps 5
117	Model Dependence Number of steps to decide ! = a#b# $ ≥0 depends on the model. • 1-tape TM: '() log )) • Multi-tape TM: '()) Computability theory: model independence (Church-Turing Thesis) Therefore model choice doesn’t matter. Mathematically nice. Complexity Theory: model dependence But dependence is low (polynomial) for reasonable deterministic models. We will focus on questions that do not depend on the model choice. So… we will continue to use the 1-tape TM as the basic model for complexity. 6
118	. . . TIME 2; . . . TIME Complexity Classes Defn: Let !: ℕ→ℕ. Say TM % runs in time !(') if % always halts within !(') steps on all inputs of length '. Defn: TIME ! ' = {+| some deterministic 1-tape TM % decides + and % runs in time - ! ' } Example: Check-in 12.2 / = a0b0 < ∈ a, b ∗}. What is the smallest function ! TIME '9 such that + ∈ TIME ! ' ? 1 ≥0 ∈ TIME ' log ' Let + = <<ℛ TIME '8 TIME ' log ' (a) -(') Regular / (b) - ' log ' languages (c) -('8) (d) - '9 Check-in 12.2 7
119	"Multi-tape vs 1-tape time Theorem: Let ! "" ≥"". If a multi-tape TM decides $ in time !(""), then $ ∈ TIME !( "" . Proof: Analyze conversion of multi-tape to 1-tape TMs. ˽ ˽ . . . a a b b a ) * ˽ 1 0 1 . . . … ˽ ˽ a a b b a # 1 0 1 # # c c c a ˽ . . . 1-tape + ! "" . . . multi-tape c c c a To simulate 1 step of )’s computation, * uses + ! "" steps. So total simulation time is + ! "" × ! "" = + !( "" . Similar results can be shown for other reasonable deterministic models. 8"
120	"Relationships among models Informal Defn: Two models of computation are polynomially related if each can simulate the other with a polynomial overhead: So ! "" time → !$("") time on the other model, for some '. All reasonable deterministic models are polynomially related. • 1-tape TMs • multi-tape TMs • multi-dimensional TMs • random access machine (RAM) • cellular automata 9"
121	The Class P Defn: P = ⋃# TIME(%#) = polynomial time decidable languages • Invariant for all reasonable deterministic models • Corresponds roughly to realistically solvable problems + - Example: '()* = +, -, . + is a directed graph with a path from - to . } . Theorem: '()* ∈ P Proof: 1 = “On input 〈+, -, .〉 1. Mark ­ 2. Repeat until nothing new is marked: ≤% iterations To show polynomial time: For each marked node 4: × ≤% iterations Each stage should be clearly Scan + to mark all 5 where 4, 5 is an edge × 8 %9 steps polynomial and the total 3. Accept if . is marked. Reject if not. ------------------- number of steps polynomial. 8(%:) steps 10
122	"!""#$ and $""%!""#$ Example: $""%!""#$ = ', ), * ' is a directed graph with a path from ) to * and the path goes through every node of ' } Recall Theorem: !""#$ ∈ P Called a Hamiltonian path ' Question: $""%!""#$ ∈ P ? “On input ', ), * 1. Let - be the number of nodes in '. 2. For each path of length - in ': test if - is a Hamiltonian path from ) to *. Accept if yes. 3. Reject if all paths fail.” May be -! > 22 paths of length ­ so algorithm is exponential time not polynomial time. ) * Check-in 12.3 Is $""%!""#$ ∈ P ? (a) Definitely Yes. You have a polynomial-time algorithm. (b) Probably Yes. It should be similar to showing !""#$ ∈ P. (c) Toss up. (d) Probably No. Hard to beat the exponential algorithm. (e) Definitely No. You can prove it! Check-in 12.3 11"
123	"Quick review of today 1. Introduction to Complexity Theory 2. Which model to use? 1-tape-TMs 3. TIME ! "" complexity classes 4. The class P 5. #$%& ∈ P 12"
124	MIT OpenCourseWare https://ocw.mit.edu 18.404J / 18.4041J / 6.840J Theory of Computation Fall 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
125	18.404/6.840 Lecture 5 Last time: - Context free grammars (CFGs) - Context free languages (CFLs) - Pushdown automata (PDA) - Converting CFGs to PDAs Today: (Sipser §2.3, §3.1) - Proving languages not Context Free - Turing machines - T-recognizable and T-decidable languages 1
126	"Equivalence of CFGs and PDAs Recall Theorem: ! is a CFL iff some PDA recognizes ! Done. Need to know the fact, not the proof Corollaries: 1) Every regular language is a CFL. 2) If ! is a CFL and "" is regular then ! ∩ "" is a CFL. Proof sketch of (2): While reading the input, the finite control of the PDA for ! simulates the DFA for "". Note 1: If ! and "" are CFLs then ! ∩ "" may not be a CFL (will show today). Therefore the class of CFLs is not closed under ∩. Note 2: The class of CFLs is closed under ∪,∘,∗ (see Pset 2). 2"
127	Proving languages not Context Free Let ! = 0$1$2$ ' ≥0}. We will show that ! isn’t a CFL. Pumping Lemma for CFLs: For every CFL *, there is a + such that if , ∈* and , ≥+ then , = ./012 where 1) ./30132 ∈ * for all 4 ≥0 2) /1 ≠ ε 3) /01 ≤+ , = ≥+ . / 0 1 2 ∈* Informally: All long strings in * are pumpable and stay in *. ∈* 1 2 . / / ≤+ 0 1 3
128	"Pumping Lemma – Proof Pumping Lemma for CFLs: For every CFL !, there is a "" such that if # ∈! and # ≥ "" then # = '()*+ where 1) '(,)*,+ ∈ ! for all - ≥0 2) (* ≠ ε E 3) ()* ≤ "" Proof by picture: R R E R E R ' ( * + R R ) ( ) * Generates '(()**+ ' Generates ')+ + = '(1)*1+ = '(2)*2+ # = ' ( ) * + Long # → “cutting and pasting” argument tall parse tree 4"
129	…cutting and pasting …start with the smallest parse tree for ! …pick the lowest repetition of a variable Pumping Lemma – Proof details For ! ∈# where ! ≥%, we have ! = '()*+ where: 1) '(,)*,+ ∈ # for all - ≥0 2) (* ≠ ε 3) ()* ≤% Let 1 = the length of the longest right hand side of a rule (E → E+T) = the max branching of the parse tree E E Let ℎ= the height of the parse tree for !. E + T A tree of height ℎ and max branching 1 has at most 14 leaves. So ! ≤14 . 5 Let % = 1 + 1 where 8 = # variables in the grammar. 5 |5| So if ! ≥% > 1 then ! > 1 and so ℎ> 8 R R . Thus at least 8 + 1 variables occur in the longest path. ! = use ! > 1 5 set % = 1 5 + 1 ' ( ) * + So some variable ; must repeat on
130	a path. 5 want ℎ > 8
131	Proof by Contradiction: Assume (to get a contradiction) that ! is a CFL . The CFL pumping lemma gives * as above. Let + = 0,1,2, ∈!. Pumping lemma says that can divide + = ./012 satisfying the 3 conditions. Condition 3 ( /01 ≤*) implies that /01 cannot contain both 0s and 2s. So ./40142 has unequal numbers of 0s, 1s, and 2s. Thus ./40142 ∉!, violating Condition 1. Contradiction! Therefore our assumption (! is a CFL) is false. We conclude that ! is not a CFL . Example 1 of Proving Non-CF Pumping Lemma for CFLs: For every CFL 7, there is a * such that if + ∈7 and + ≥* then + = ./012 where 1) ./80182 ∈ 7 for all 9 ≥0 2) /1 ≠ ε 3) /01 ≤* Let ! = 0$1$2$ ' ≥0} Show: ! is not a CFL Check-in 5.1 Let 7; = 0$1$2< ', > ≥0} (equal #s of 0s and 1s) + = 00 ⋯0011 ⋯1122 ⋯22 Let 74 = 0<1$2$ ', > ≥ 0} (equal #s of 1s and
132	2s) . ≤* / 0 2 Observe that PDAs can recognize 7; and 74. What can we now conclude? 1 a) The class of CFLs is not closed under intersection. b) The Pumping Lemma shows that 7; ∪74 is not a CFL . c) The class of CFLs is closed under complement. Check-in 5.1 6
133	ut ./ can be pumped and stay inside !. Bad choice of .. Example 2 of Proving Non-CF Pumping Lemma for CFLs: For every CFL 8, there is a ­ such that if . ∈8 and . ≥- then . = 23456 where 1) 23:45:6 ∈ 8 for all ; ≥0 2) 35 ≠ ε 3) 345 ≤ ­ Let ! = ## # ∈Σ∗} . Σ = {0,1}. Show: ! is not a CFL. Assume (for contradiction) that ! is a CFL. The CFL pumping lemma gives - as above. Need to choose . ∈!. Which .? Try ./ = 001001 ∈ !. B Try .1 = 00100010 ∈ !. Show .1 cannot be pumped .1 = 23456 satisfying the 3 conditions. Condition 3 implies that 345 does not overlap two runs of 0s or two runs of 1s. Therefore, in 2314516, two runs of 0s or two runs of 1s have unequal length. So 2314516 ∉ ! violating Condition 1. Contradiction! Thus ! is not a CFL. 7 ./ = 000 ⋯ 001000 ⋯ 001 2 3 4
134	5 6 .1 = 0 ⋯01 ⋯10 ⋯01 ⋯1 2 3 5 6 4
135	Turing Machines (TMs) head ˽ ˽ a b a . . . b b Finite read/write input tape control 1) Head can read and write 2) Head is two way (can move left or right) 3) Tape is infinite (to the right) 4) Infinitely many blanks “˽“ follow input 5) Can accept or reject any time (not only at end of input) 8
136	TM – example TM recognizing ! = a#b#c# $ ≥0 ∗ 1) Scan right until ˽ while checking if input is in a ∗ b ∗ c , reject if not. 2) Return head to left end. head input tape 3) Scan right, crossing off single a, b, and c. ˽ ˽ a a a b b b c c c Finite 4) If the last one of each symbol, accept. control 5) If the last one of some symbol but not others, reject. 6) If all symbols remain, return to left end and repeat from (3). accept Check-in 5.2 How do we get the effect of “crossing off” with a Turing machine? a) We add that feature to the model. b) We use a tape alphabet Γ = {a, b, c, a, b, c, ˽ }. c) All Turing machines come with an eraser. Check-in 5.2 9
137	"TM – Formal Definition Defn: A Turing Machine (TM) is a 7-tuple ("", Σ, Γ, &, '(, 'acc , 'rej) Σ input alphabet Γ tape alphabet (Σ ⊆Γ) &: Q×Γ → ""×Γ× {L, R} (L = Left, R = Right) & ', a = (5, b, R) On input 6 a TM 7 may halt (enter 'acc or 'rej) Check-in 5.3 or 7 may run forever (“loop”). This Turing machine model is deterministic. So 7 has 3 possible outcomes for each input 6: How would we change it to be nondeterministic? 1. Accept 6 (enter 'acc ) a) Add a second transition function. 2. Reject 6 by halting (enter 'rej ) b) Change & to be &: Q×Γ → 8( ""×Γ× {L, R} ) 3. Reject 6 by looping (running forever) c) Change the tape alphabet Γ to be infinite. 10 Check-in 5.3"
138	"TM Recognizers and Deciders Let ! be a TM. Then "" ! = $ ! accepts $}. Say that ! recognizes & if & = ""(!). Defn: & is Turing-recognizable if & = ""(!) for some TM !. Defn: TM ! is a decider if ! halts on all inputs. Say that ! decides & if & = ""(!) and ! is a decider. Defn: & is Turing-decidable if & = ""(!) for some TM decider !. 11 T-recognizable T-decidable CFLs regular"
139	Quick review of today 1. Proved the CFL Pumping Lemma as a tool for showing that languages are not context free. 2. Defined Turing machines (TMs). 3. Defined TM deciders (halt on all inputs). 4. T-recognizable and T-decidable languages. 12
140	MIT OpenCourseWare https://ocw.mit.edu 18.404J / 18.4041J / 6.840J Theory of Computation Fall 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
141	18.404/6.840 Lecture 22 Last time: - Finished NL = coNL - Time and Space Hierarchy Theorems Today: (Sipser §9.2) - A “natural” intractable problem - Oracles and P versus NP 1
142	"PSPACE NL )*+, E 22 E #/ E #0 . . . . . . Review: Hierarchy Theorems Theorems: SPACE ! "" # ⊆, SPACE "" # for space constructible "". TIME ! "" # / log "" # ⊆, TIME "" # for time constructible "". TIM SPACE 22 TIM SPACE #/ SPACE #0 TIM TIME #. SPACE #. Check-in 22.1 Which of these are known to be true? Check all that apply. (a) TIME 22 ⊆, TIME 2234 TIME 2.2 Corollary: NL ⊆, PSPACE (b) TIME 22 ⊆, Implies )*+, ∉ NL because the polynomial-time reductions in (c) NTIME #. the proof that )*+, is PSPACE-complete can be done in log space. ⊆, PSPACE (d) NP ⊆, PSPACE 2 Check-in 22.1"
143	"Exponential Complexity Classes Defn: EXPTIME = ⋃"" TIME 2 $% EXPSPACE = ⋃"" SPACE 2 $% ≠ Time Hierarchy Theorem L ⊆ NL ≠ ⊆ P ⊆ NP ⊆ PSPACE ≠ ⊆ EXPTIME ⊆ EXPSPACE Space Hierarchy Theorem Defn: & is EXPTIME-complete if 1) & ∈ EXPTIME 2) For all ( ∈ EXPTIME, ( ≤* & Same for EXPSPACE-complete Theorem: If B is EXPTIME-complete then & ∉ P intractable Theorem: If B is EXPSPACE-complete then & ∉ PSPACE (and & ∉ P) Next will exhibit an EXPSPACE-complete problem 3"
144	"A “Natural” Intractable Problem Defn: !""REX = '(, '* '( and '* are equivalent regular expressions} Theorem: !""REX ∈ PSPACE Proof: Later (if time) or exercise (uses Savitch’s theorem). - Notation: If ' is a regular expression write '- to mean '' ⋯' (exponent is written in binary). Defn: !""/01↑ = '(, '* '( and '* are equivalent regular expressions with exponentiation} Theorem: !""/01↑ is EXPSPACE-complete Proof: 1) !""/01↑ ∈ EXPSPACE 2) If 3 ∈ EXPSPACE then 3 ≤5 !""/01↑ 1) Given regular expressions with exponentiation '( and '*, expand the exponentiation by using repeated concatenation and then use !""REX ∈ PSPACE. The expansion is exponentially larger, so gives an EXPSPACE algorithm for !""/01↑. 2) Let 3 ∈ EXPSPACE be decided by TM 6 in space 2 89 . Give a polynomial-time reduction : mapping 3 to !""/01↑. 4"
145	Pad all configurations with blanks to have length 2 -. 2 Showing ! ≤# $%&'(↑ Theorem: $%&'(↑ is EXPSPACE-complete Proof continued: Let ! ∈ EXPSPACE decided by TM + in space 2 -. . Give a polynomial-time reduction / mapping ! to $%&'(↑. / 0 = 23, 25 0 ∈! iff 6 23 = 6 25 Construct 23 so that 6 23 all strings except a rejecting computation history for + on 0. = Construct 25 = Δ∗ ( Δ is the alphabet for computation histories, i.e., Δ = Γ ∪% ∪ # ) • … ˽ ˽ ababa abababa IJ0305 ⋯0- # ⋯ # ⋯ # ⋯Ireject ⋯ Q3 = Qstart Q5 Qreject Check-in 22.2 Roughly estimate the size of the rejecting computation history for + on 0. (a) 2- (c) 25 T. (b) 2 -. Check-in 22.2 5 23 construction: 23 = 2<=>?@A=BA ∪ 2<=>?CDEF ∪ 2<=>?BFGFHA Rejecting computation history for + on 0: 2 -. 2 -. -.
146	2 AL ! ≤# $%&'(↑ (*+,-./0,10) Construct *2 to generate all strings except a rejecting computation history for 3 on 4. *2 = *+,-./0,10 ∪ *+,-.789: ∪ *+,-.1:;:<0 Rejecting computation history for 3 on 4: = >424? ⋯ 4A ˽ ⋯ 2 AL … ˽ # ababa abababa # ⋯ # ⋯ 2 AL = reject ⋯ H2 = Hstart H? Hreject M> = Δ.PQΔ∗ *+,-./0,10 generates all strings that do not start with Hstart = =>424? ⋯ 4A ˽ … ˽ M2 = ΔΔ.STΔ∗ = *+,-./0,10 = M> ∪M2 ∪M? ∪⋯ ∪MA ∪Mblanks ∪ M# M? ⋮ Δ?Δ.SUΔ∗ Remember: Δ is the alphabet for computation histories, i.e., Δ = Γ ∪% ∪ # ) MA = ΔAΔ.SWΔ∗ Notation: Δd = Δ ∪ {f} = ΔAX2Δ.YΔ∗ ˽ Δ.+ = Δ without b ? WL .(AX?)Δ.YΔ∗ MAX2 Mblanks = ΔAX2Δd ˽ ⋮ Δh = all strings of length 7 all strings of length \\ + 1 thru 2(AL) − 1 = Δ?(WL).2Δ.Y˽ Δ∗ Δh d = all strings of length 0 thru 7 M?(WL).2 M# = Δ?(WL)Δ.#Δ∗ 6
147	>?:8:@ ⋯ :B ⋯ >reject ⋯ # # # ⋯ ˽ … ˽ ababa ⋯ abababa 2 BM 2 BM 2 BM ! ≤# $%&'(↑ (*+,-./012 & *+,-.425267) Construct *8 to generate all strings except a rejecting computation history for 9 on :. *8 = *+,-.<7,47 ∪ *+,-./012 ∪ *+,-.425267 Rejecting computation history for 9 on :: I8 = Istart I@ Ireject 267 generates all strings that do not contain >re *+,-.425 ject ∗ *+,-.425267 = Δ.Oreject *+,-./012 generates all strings that contain an illegal 2×3 neighborhood 2 BM —2 U Δ∗ abc Δ@ VM .@ def Δ∗ ⋯ abc def ⋯ *+,-./012 = illegal a b c IS IST8 d e f 7
148	"Computation with Oracles Let ! be any language. Defn: A TM "" with oracle for !, written ""#, is a TM equipped with a “black box” that can answer queries “is $ ∈!?” for free. Example: A TM with an oracle for &!' can decide all ( ∈ NP in polynomial time. Defn: P# = ( ( is decidable in polynomial time with an oracle for !} Thus NP ⊆ P+#, NP = P+#,? Probably No because coNP ⊆ P+#, Defn: NP# = ( ( is decidable in nondeterministic polynomial time with an oracle for !} Recall MIN-FORMULA = 7 7 is a minimal Boolean formula } Example: MIN−FORMULA ∈ NP+#, “On input 7 1. Guess shorter formula 9 2. Use &!' oracle to solve the coNP problem: 7 and 9 are equivalent 3. Accept if 7 and 9 are equivalent. Reject if not.” 8"
149	"NO. Oracles and P versus NP Theorem: There is an oracle ! where P "" = NP "" Proof: Let ! = $%&' NP()*+ ⊆ NPSPACE = PSPACE ⊆ P()*+ Relevance to the P versus NP question Recall: We showed -%./0↑ ∉ PSPACE. Could we show 3!$ ∉ P using a similar method? Reason: Suppose YES. The Hierarchy Theorems are proved by a diagonalization. In this diagonalization, the TM 4 simulates some TM 5. If both TMs were oracle TMs 4"" and 5"" with the same oracle !, the simulation and the diagonalization would still work. Therefore, if we could prove P ≠ NP by a diagonalization, we would also prove that P "" ≠ NP "" for every oracle !. But that is false! 9 Check-in 22.3 Which of these are known to be true? Check all that apply. P7""( P7""( (a) = (b) NP7""( = coNP7""( (c) MIN-FORMULA ∈ P()*+ NP()*+ = coNP()*+ (d) Check-in 22.3"
150	"Quick review of today 1. Defined EXPTIME and EXPSPACE 2. Defined EXPTIME- and EXPSPACE-completeness 3. Showed !""#$%↑ is EXPSPACE-complete and thus !""#$%↑ ∉ PSPACE 4. Defined oracle TMs 5. Showed P( = NP( for some oracle * 6. Discussed relevance to the P vs NP question 10"
151	"!""REX ∈ PSPACE Theorem: !""REX ∈ PSPACE Proof: Show !""RE' ∈ NPSPACE “On input (), (+ [ assume alphabet Σ ] 1. Convert () and (+ to equivalent NFAs -) and -+ having .) and .+ states. 2. Nondeterministically guess the symbols of a string / of length 2123 14 and simulate -) and -+ on /, storing only the current sets of states of -) and -+. 3. If they ever disagree on acceptance then accept. 4. If always agree on acceptance then reject.” 11"
152	MIT OpenCourseWare https://ocw.mit.edu 18.404J / 18.4041J / 6.840J Theory of Computation Fall 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
153	"18.404/6.840 Lecture 18 Last time: - Space complexity - SPACE ! "" , NSPACE ! "" , PSPACE, NPSPACE - Relationship with TIME classes Today: (Sipser §8.3) - Review $%&&'(DFA ∈ PSPACE - Savitch’s Theorem: NSPACE ! "" ⊆ SPACE !. "" - PSPACE-completeness - /012 is PSPACE-complete 1"
154	Review: SPACE Complexity Defn: Let !: ℕ→ℕ where ! % ≥%. Say TM ' runs in space !(%) if ' always halts and uses at most !(%) tape cells on all inputs of length %. An NTM ' runs in space !(%) if all branches halt and each branch uses at most !(%) tape cells on all inputs of length %. SPACE ! % = {,| some 1-tape TM decides , in space . ! % } NSPACE ! % = {,| some 1-tape NTM decides , in space . ! % } PSPACE = ⋃1 SPACE(%1) “polynomial space” NPSPACE = ⋃1 NSPACE(%1) “nondeterministic polynomial space” Today: PSPACE = NPSPACE Or possibly: P = NP = coNP = PSPACE 2 PSPACE = NPSPACE coNP NP P
155	"AAAB AAAD AABA AAAC AABB AAAZ AAAA Review: !""##$%DFA ∈ PSPACE Theorem: !""##$%DFA ∈ SPACE(+,) Proof: Write . / 0 if there’s a ladder from . to 0 of length ≤2. Here’s a recursive procedure to solve the bounded DFA ladder problem: 3456#$#-!""##$%DFA = 3, ., 0, 2 3 a DFA and . / 0 by a ladder in !(3)} 3-! = “On input 3, ., 0, 2 Let : = . = |0|. 1. For 2 = 1, accept if ., 0 ∈ !(3) and differ in ≤1 place, else reject. 2. For 2 > 1, repeat for each > ∈ !(3) of length |.| 3. Recursively test . //, > and > //, 0 [division rounds up] 4. Accept both accept. 5. Reject [if all fail].” Σ B Test 3, ., 0 ∈ !""##$%DFA with 3-! procedure on input 3, ., 0, @ for @ = 2 ⁄ / , ⁄ / , ⁄ / G ⁄ / G Space analysis: Each recursive level uses space 4 + (to record >). Recursion depth is log @ = 4"
156	: = 4(+). 3−! Total space used is 4(+,). 3 WORK recurse AAAA AAAB AAAC AAAD AAAZ AABA AABB BOOK AAAA AAAB AAAC AAAD AAAZ AABA AABB ABLE AAAA AAAB AAAC AAAD AAAZ AABA AABB CALL recurse PLAY > . 0 > AAAB AABB AAAC AAAD AAAZ AABA AAAA AABB ABLE AAAA AABA AAAD BOOK AAAZ AAAB AAAC CALL
157	"recurse recurse PSPACE = NPSPACE Savitch’s Theorem: For ! ≥"", NSPACE ! ⊆ SPACE !% "" "" "" Proof: Convert NTM & to equivalent TM ', only squaring the space used. + For configurations () and (* of &, write () (* if can get from () to (* in ≤- steps. + Give recursive algorithm to test () (*: + = “On input (), (*, - [goal is to check () (*] !("") ˽ … ˽ GH8I ⋯ 8F ' 1. If - = 1, check directly by using &’s program and answer accordingly. 2. If - > 1, repeat for all configurations (234 that use !("") space. 3. Recursively test () +/% (234 and (234 +/% (* 4. If both are true, accept. If not, continue. aabaGPda⋯cab 5. Reject if haven’t yet accepted.” = Test if & accepts 8 by testing (9:;<: (;>>?@: where A = number of configurations = B ×! "" ×DE F Number of levels = log A = R ! "" . Total R !% space. Each recursion level stores 1 config = R"
158	"! "" space. "" ⋯ Gaccept ⋯ 4 - ⁄ + % ⁄ + %"
159	≤ ≤ Why % and not %'%()* when defining PSPACE-complete? - Reductions should be “weaker” than the class. Otherwise all problems in the class would be reducible to each other, and then all problems in the class would be complete. Theorem: +,!- is PSPACE-complete PSPACE-completeness Defn: ! is PSPACE-complete if 1) ! ∈ PSPACE 2) For all # ∈ PSPACE, # ≤% ! If ! is PSPACE-complete and ! ∈ P then P = PSPACE. Check-in 18.1 Knowing that +,!- is PSPACE-complete, what can we conclude if +,!- ∈ NP? Check all that apply. (a) P = PSPACE (b) NP = PSPACE (c) P = NP (d) NP = coNP 5 PSPACE-complete NP-complete PSPACE = NPSPACE NP P Think of complete problems as the “hardest” in their associated class. Check-in 18.1
160	"!""#$ is PSPACE-complete Recall: !""#$ = & & is a QBF that is TRUE} Examples: &( = ∀* ∃, * ∨, ∧ * ∨ , ∈!""#$ [TRUE] &0 = ∃, ∀* * ∨, ∧ * ∨ , ∉!""#$ [FALSE] Theorem: !""#$ is PSPACE-complete Proof: 1) !""#$ ∈ PSPACE • 2) For all 2 ∈ PSPACE, 2 ≤4 !""#$ Let 2 ∈ PSPACE be decided by TM 5 in space 67 . Give a polynomial-time reduction 8 mapping 2 to !""#$. 8: Σ∗→ QBFs 8 = = 〈&?,A〉 = ∈2 iff &?,A is TRUE Plan: Design &?,A to “say” 5 accepts =. &?,A simulates 5 on =. 6"
161	"Constructing !"",$: 1st try % on & Recall: A tableau for % on & represents a computation history for % on & when % accepts &. Rows of that tableau are configurations. % runs in space 45, its tableau has: - 45 columns (max size of a configuration) -8 - 6 rows (max number of steps) Constructing !"",$. Try Cook-Levin method. Then !"",$ will be as big as tableau. -8 But that is exponential: 45×6 . Too big! • 7 Tableau for % on & '( &) &* &+ ⋯&- a '. &* ⋯ ⋯ 'accept ⋯ ˽ … ˽ 45 6(-8)"
162	"- %& '( ') '* ⋯', a % ') ⋯ ⋯ %accept ⋯ ˽ … ˽ 34 5(,7) Tableau for ^ on ' Check-in 18.2 Why shouldn’t we be surprised that this construction fails? (a) We can’t define a QBF by using recursion. (b) It doesn’t use ∀ anywhere. (c) We know that `abc ∉ P. hide → Constructing !"",$: 2nd try For configs 9: and 9; construct !<=, <>, ? which “says” 9: ? 9; recursively. !<=, <>, ? = ∃9BCD !<=, <EFG, ?/) ∧ !<EFG, <>, ?/) ∃L(, L), ⋯ , 9M as in Cook-Levin ∃9BCD ! , , ?/J ∧ ! , , ?/J ∃9BCD ! , , ?/J ∧ ! , , ?/J ⋮ ! , , ( defined as in Cook-Levin ⋮ ∃9BCD[! , , ?/O ⋯ ] Size analysis: !"",$ = !<UVWXV, <WYYZ[V, \\ Each recursive level doubles number of QBFs. 7 ] = 5 , Number of levels is log 5 ,7 = T 34 . → Size is exponential. • 8 Check-in 18.2"
163	"Constructing !"",$: 3rd try !34, 35, 6 = ∃89:; !34, 3<=>, 6/2 ∧ !3<=>, 35, 6/2 , , J Check-in 18.3 Would this construction still work if N were nondeterministic? (a) Yes. (b) No. ∀(K ∈L) M ∀ 8B, 8C ∈ 8E, 89:; , 89:;, 8F !3G, 3H, 6/2 is equivalent to ⋮ ∀K K ∈L M !"",$ = !3OPQRP, 3QSSTUP, V ! defined as in Cook-Levin / W = - . Size analysis: Each recursive level adds %('() to the QBF. Number of levels is log - ./ = % '( . → Size is % '2( • '(×'( = % 9 Check-in 18.3"
164	"Quick review of today 1. !""##$%DFA ∈ PSPACE 2. Savitch’s Theorem: NSPACE * + ⊆ SPACE *- + 3. ./01 is PSPACE-complete 10"
165	MIT OpenCourseWare https://ocw.mit.edu 18.404J / 18.4041J / 6.840J Theory of Computation Fall 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
166	18.404/6.840 Lecture 4 Last time: - Finite automata → regular expressions - Proving languages aren’t regular - Context free grammars Today: (Sipser §2.2) - Context free grammars (CFGs) – definition - Context free languages (CFLs) - Pushdown automata (PDA) - Converting CFGs to PDAs 1
167	0 S 1 0 S 1 R ε 0S1 00S11 00R11 0011 Context Free Grammars (CFGs) #% Shorthand: S → 0S1 S → R S → 0S1 | R R →ε R →ε Recall that a CFG has terminals, variables, and rules. Example of #% generating a string Grammars generate strings 1. Write down start variable Tree of S S Resulting string “parse tree” 2. Replace any variable according to a rule substitutions Repeat until only terminals remain 3. Result is the generated string 4. !(#) is the language of all generated strings 5. We call !(#) a Context Free Language. ∈! #% ! #% = 0*1* , ≥0} 2
168	is called a derivati for so ! ution steps in ! on of - from ,. me CFG !. CFG – Formal Definition Defn: A Context Free Grammar (CFG) ! is a 4-tuple (#, Σ, &, ') # finite set of variables Σ finite set of terminal symbols & finite set of rules (rule form: # → # ∪Σ ∗ ) ' start variable For ,, - ∈ # ∪Σ ∗ write Check-in 4.1 1) , ⇒ ­ if can go from , to - with one substitution step in Which of these are valid CFGs? ∗ 2) , ⇒ - if can go from , to - with some number of substit 90: B → 0B1 | ε 91: S → 0S | S1 , ⇒,0 ⇒,1 ⇒⋯⇒,3 = - B1 → 1B R → RR If , = ' then it is a derivation of -. 0B → 0B ∗ a) 90 only 5 ! = 6 6 ∈Σ∗ and ' ⇒ 6} b) 91 only Defn: 8 is a Context Free Language (CFL) if 8 = 5(!)
169	c) Both 90 and 91 d) Neither Check-in 4.1 3
170	Observe that the parse tree contains additional informatio n, mbiguously ∈* '( , (a+a)×a, a, a+a+a, etc. E+T T+T×F F+F×a a+a×a E + T T T × F F F a a a a CFG – Example '( Parse E E → E+T | T tree T → T×F | F F → ( E ) | a ! = {E, T, F} Σ = {+, ×, (, ), a} $ = the 6 rules above Generates a+a×a % = E such as the precedence of × over + . If a string has two different parse trees then it is derived a and we say that the grammar is ambiguous. 4 E Resulting string Check-in 4.2 How many reasonable distinct meanings does the following English sentence have? The boy saw the girl with the mirror. (a) 1 (b) 2 (c) 3 or more Check-in 4.2
171	"Ambiguity !"" E → E+T | T T → T×F | F F → ( E ) | a !# E → E+E | E×E | ( E ) | a E E E Both !"" and !# recognize the same language, i.e., $ !"" = $ !# . However !"" is an unambiguous CFG and !# is ambiguous. E E a + a × a E E E E E 5"
172	Pushdown Automata (PDA) “head” a b a b a … a Finite input appears on a “tape” control c Schematic diagram for DFA or NFA (pushdown) d stack Schematic diagram for PDA d Operates like an NFA except can write-add or read-remove symbols from the top of stack. push pop Example: PDA for ! = 0$1$ & ≥0 1) Read 0s from input, push onto stack until read 1. 2) Read 1s from input, while popping 0s from stack. 3) Enter accept state if stack is empty. (note: acceptance only at end of input) 6
173	"PDA – Formal Definition Defn: A Pushdown Automaton (PDA) is a 6-tuple ("", Σ, Γ, &, '0, )) Σ input alphabet Γ stack alphabet &: Q×Σ.×Γ. → 0(""×Γ.) Accept if some thread is in the accept state & ', a, c = 45, d , 47, e at the end of the input string. Example: PDA for 9 = {;;ℛ| ; ∈ 0,1 ∗} Sample input: 0 1 1 1 1 0 1) Read and push input symbols. Nondeterministically either repeat or go to (2). The nondeterministic forks replicate the stack. 2) Read input symbols and pop stack symbols, compare. If ever ≠ then thread rejects. This language requires nondeterminism. Our PDA model is nondeterministic. 3) Enter accept state if stack is empty. (do in “software”) 7"
174	Converting CFGs to PDAs Theorem: If ! is a CFL then some PDA recognizes ! Proof: Convert !’s CFG to a PDA … E → E+T | T PDA T → … F → … CFG $% E → E+T | T IDEA: PDA begins with starting variable and guesses substitutions. T → T×F | F It keeps intermediate generated strings on stack. When done, compare with input. F → ( E ) | a E E T T Input: a + a × a + + + E E T T T × E+T E + T F T+T×F T T × F Problem! Access below the top of stack is cheating! F+F×a F F a Instead, only substitute variables when on the top of stack. a+a×a a a a If a terminal is on the top of stack, pop it and compare with input. Reject if ≠. 8
175	Converting CFGs to PDAs (contd) Theorem: If ! is a CFL then some PDA recognizes ! Proof construction: Convert the CFG for ! to the following PDA. 1) Push the start symbol on the stack. 2) If the top of stack is Variable: replace with right hand side of rule (nondet choice). Terminal: pop it and match with next input symbol. 3) If the stack is empty, accept. a + a × a Example: E E F T a + T T + + + + T × T T T T F 9 #$ E → E+T | T T → T×F | F F → ( E ) | a E E E+T E + T T+T×F T T × F F+F×a F F a a+a×a a a a
176	Equivalence of CFGs and PDAs Theorem: ! is a CFL iff* some PDA recognizes ! Done. In book. You are responsible for knowing it is true, but not for knowing the proof. * “iff” = “if an only if” means the implication goes both ways. So we need to prove both directions: forward (→) and reverse (←). Check-in 4.3 Is every Regular Language also a Context Free Language? (a) Yes (b) No (c) Not sure Check-in 4.3 10
177	Regular language Context Free language Regular languages Recap Recognizer DFA or NFA PDA Context Free languages Generator Regular expression Context Free Grammar 11
178	Quick review of today 1. Defined Context Free Grammars (CFGs) and Context Free Languages (CFLs) 2. Defined Pushdown Automata(PDAs) 3. Gave conversion of CFGs to PDAs. 12
179	MIT OpenCourseWare https://ocw.mit.edu 18.404J / 18.4041J / 6.840J Theory of Computation Fall 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
180	18.404/6.840 Lecture 2 Last time: (Sipser §1.1) - Finite automata, regular languages - Regular operations ∪,∘,∗ - Regular expressions - Closure under ∪ Today: (Sipser §1.2 – §1.3) - Nondeterminism - Closure under ∘ and ∗ - Regular expressions → finite automata Goal: Show finite automata equivalent to regular expressions 1
181	Problem Sets - 35% of overall grade - Problems are hard! Leave time to think about them. - Writeups need to be clear and understandable, handwritten ok. Level of detail in proofs comparable to lecture: focus on main ideas. Don’t need to include minor details. - Submit via gradescope (see Canvas) by 2:30pm Cambridge time. Late submission accepted (on gradescope) until 11:59pm following day: 1 point (out of 10 points) per late problem penalty. After that solutions are posted so not accepted without S3 excuse. - Optional problems: Don’t count towards grade except for A+. Value to you (besides the challenge): Recommendations, employment (future grading, TA, UROP) - Problem Set 1 is due in one week. 2
182	"Closure Properties for Regular Languages Theorem: If !"", !$ are regular languages, so is !""!$ (closure under ∘) Recall proof attempt: Let &"" = ()"", Σ, +"", ,"", -"") recognize !"" &$ = ()$, Σ, +$, ,$, -$) recognize !$ Construct & = (), Σ, +, ,0, -) recognizing !""!$ &"" &$ & should accept input 0 if 0 = 12 where &"" accepts 1 and &$ accepts 2. & 0 1 2 Doesn’t work: Where to split 0? Hold off. Need new concept. 3"
183	Nondeterminism doesn’t correspond to a physical machine we can build. However, it is useful mathematically. accept reject accept reject Nondeterministic Finite Automata a a !1 b a,ε #1 #2 #3 #4 b New features of nondeterminism: - multiple paths possible (0, 1 or many at each step) - ε-transition is a “free” move without reading input - Accept input if some path leads to accept Check-in 2.1 Example inputs: What does !' do on input aab ? - ab - aa (a) Accept - aba (b) Reject - abb (c) Both Accept and Reject Check-in 2.1 4
184	ac al tr sta sta a c p e n r t h p s t sta e ab i t s ti s e o t n f a t te te u s nction NFA – Formal Definition !1 a a #1 #2 b #3 a,ε #4 b Defn: A nondeterministic finite automaton (NFA) ! is a 5-tuple ((, Σ, +, #0, -) Ways to think about nondeterminism: Computational: Fork new parallel thread and accept if any thread leads to an accept state. - all same as before except + Mathematical: Tree with branches. - +: (×Σε →2 ( = 4 4 ⊆(} Accept if any branch leads to an accept state. power set Σ ∪{ε} Magical: Guess at each nondeterministic step - In the !7 example: + #7, a = {#7, #9} which way to go. Machine always makes the + #7, b = ∅ right guess that leads to accepting, if possible. 5
185	") ) ∈((4, 2) for some 4 ∈1} "" )8 )9 NFA Check-in 2.2 If "" has : states, how many states does ""′ have by this construction? (a) 2: (b) :< (c) 2= Converting NFAs to DFAs Theorem: If an NFA recognizes ! then ! is regular Proof: Let NFA "" = (%, Σ, (, )*, +) recognize ! Construct DFA ""′ = (%′, Σ, (′, )* . , +′) recognizing ! (Ignore the ε-transitions, can easily modify to handle them) IDEA: DFA ""′ keeps track of the subset of possible states in NFA "". ""′ Construction of /′: %′ = 0 % {)8,)9} (. 1, 2 = 1 ∈%′ )* . = {q*} +′ = 1 ∈%. 1 intersects +} DFA Check-in 2.2 6"
186	"Return to Closure Properties Recall Theorem: If !"", !$ are regular languages, so is !"" ∪!$ (The class of regular languages is closed under union) New Proof (sketch): Given DFAs &"" and &$ recognizing !"" and !$ &$ &"" ε ε & Construct NFA & recognizing !"" ∪!$ Nondeterminism parallelism vs guessing 7"
187	"Closure under ∘ (concatenation) Theorem: If ""#, ""% are regular languages, so is ""#""% Proof sketch: Given DFAs &# and &# recognizing ""# and ""% Construct NFA & recognizing ""#""% & &% &# ε ε & should accept input ' if ' = )* where &# accepts ) and &% accepts *. ' = ) * Nondeterministic &′ has the option to jump to &% when &# accepts. 8"
188	"#′ should accept input % if % = '(') … '+ where , ≥0 and # accepts each '/ % = '( ') '0 '1 Closure under ∗ (star) Theorem: If "" is a regular language, so is ""∗ Proof sketch: Given DFA # recognizing "" Construct NFA #′ recognizing ""∗ #′ ε # ε ε Make sure #′ accepts ε Check-in 2.3 If # has 2 states, how many states does #′ have by this construction? (a) 2 (b) 2 + 1 (c) 22 Check-in 2.3 9"
189	"Regular Expressions → NFA Theorem: If "" is a regular expr and # = % "" then # is regular Proof: Convert "" to equivalent NFA &: If "" is atomic: Equivalent & is: ) Example: "" = ) for ) ∈Σ Convert a ∪ ab ∗ to equivalent NFA "" = ε a a: "" = ∅ b b: a ε b If "" is composite: ab: a "" = "". ∪""/ a ∪ ab: ε a ε b "" = "". ∘""/ Use closure constructions ε } ∗ a ∪ ab ∗ : ε "" = "". a ε ε a ε b ε 10 ε"
190	Quick review of today 1. Nondeterministic finite automata (NFA) 2. Proved: NFA and DFA are equivalent in power 3. Proved: Class of regular languages is closed under ∘,∗ 4. Conversion of regular expressions to NFA Check-in 2.4 Recitations start tomorrow online (same link as for lectures). They are optional, unless you need more help. You may attend any recitation(s). Which do you think you’ll attend? (you may check several) (a) 10:00 (b) 11:00 (c) 12:00 (d) 1:00 (e) 2:00 (f) I prefer a different time (please Check-in 2.4 post on piazza, but no promises) 11
191	MIT OpenCourseWare https://ocw.mit.edu 18.404J / 18.4041J / 6.840J Theory of Computation Fall 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
192	18.404/6.840 Intro to the Theory of Computation Instructor: Mike Sipser TAs: - Fadi Atieh, Damian Barabonkov, - Alex Dimitrakakis, Thomas Xiong, - Abbas Zeitoun, and Emily Liu 1
193	18.404 Course Outline Computability Theory 1930s – 1950s - What is computable… or not? - Examples: program verification, mathematical truth - Models of Computation: Finite automata, Turing machines, … 2 Complexity Theory 1960s – present - What is computable in practice? - Example: factoring problem - P versus NP problem - Measures of complexity: Time and Space - Models: Probabilistic and Interactive computation
194	Course Mechanics Zoom Lectures - Live and Interactive via Chat - Live lectures are recorded for later viewing Zoom Recitations - Not recorded - Two convert to in-person Homework bi-weekly – 35% - Review concepts and more examples - More information to follow - Optional unless you are having difficulty Participation can raise low grades - Attend any recitation Midterm (15%) and Final exam (25%) - Open book and notes Text Check-in quizzes for credit – 25% - Introduction to the Theory of Computation - Distinct Live and Recorded versions Sipser, 3rd Edition US. (Other editions ok but - Complete either one for credit within 48 hours are missing some Exercises and Problems). - Initially ungraded; full credit for participation 3
195	Course Expectations Prerequisites Prior substantial experience and comfort with mathematical concepts, theorems, and proofs. Creativity will be needed for psets and exams. Collaboration policy on homework - Allowed. But try problems yourself first. - Write up your own solutions. - No bibles or online materials. 4
196	Role of Theory in Computer Science 1. Applications 2. Basic Research 3. Connections to other fields 4. What is the nature of computation? 5
197	Let’s begin: Finite Automata 0 1 !1 *1 *2 *3 0,1 1 0 Input: finite string Output: Accept or Reject States: *1 *2 *3 Computation process: Begin at start state, 1 Transitions: read input symbols, follow corresponding transitions, Accept if end with accept state, Reject if not. Start state: Examples: 01101 → Accept Accept states: 00101 → Reject !1 accepts exactly those strings in # where # = {&| & contains substring 11}. Say that # is the language of !1 and that !1 recognizes # and that # = -(!1). 6
198	Finite Automata – Formal Definition Defn: A finite automaton ! is a 5-tuple (#, Σ, &, '0, )) # finite set of states Σ finite set of alphabet symbols Example: & transition function &: #×Σ → # a & (', .) = 0 means ' 0 0 '0 start state !1 1 0,1 1 ) set of accept states '1 '2 '3 0 !1 = (#, Σ, &, '1, )) & = 0 1 # = {'1, '2, '3} '1 '1 '2 Σ = {0, 1} '2 '1 '3 ) = {'3} '3 '3 '3 7
199	Finite Automata – Computation Strings and languages - A string is a finite sequence of symbols in Σ - A language is a set of strings (finite or infinite) - The empty string ε is the string of length 0 Recognizing languages - The empty language ø is the set with no strings - :(#) = {$| # accepts $} - :(#) is the language of # Defn: # accepts string $ = $1$2 … $) each $* + Σ - # recognizes :(#) if there is a sequence of states ,0, ,1, ,2, , … , ,) + / where: - ,0 = 00 - ,* = 1(,345, $*) for 1 ≤ * ≤) Defn: A language is regular if some - ,) + 8 finite automaton recognizes it. 8
200	"Regular Languages – Examples 0 1 ""1 81 82 83 0,1 1 0 More examples: ! ""# = {&| & contains substring 11} = 5 Let 6 = & & has an even number of 1s} Therefore 5 is regular 6 is regular (make automaton for practice). Let 7 = & & has equal numbers of 0s and 1s} 7 is not regular (we will prove). Goal: Understand the regular languages 9"
201	Regular Expressions Regular operations. Let !, # be languages: - Union: ! ∪# = & & ∈! or & ∈ #} - Concatenation: ! ∘# = *+ * ∈! and + ∈ #} = !# - Star: !∗= *- … */ each *0 ∈! for 1 ≥ 0} Note: ε ∈ !∗ always Example. Let ! = {good, bad} and # = {boy, girl}. - ! ∪# = {good, bad, boy, girl} - ! ∘# = !# = {goodboy, goodgirl, badboy, badgirl} - !∗= {ε, good, bad, goodgood, goodbad, badgood, badbad, goodgoodgood, goodgoodbad, … } Regular expressions - Built from Σ, members Σ, ∅, ε [Atomic] - By using ∪,∘,∗ [Composite] Examples: - 0 ∪1 ∗= Σ∗ gives all strings over Σ - Σ∗1 gives all strings that end with 1 - Σ∗11Σ∗ = all strings that contain 11 = : ;­ Goal: Show finite automata equivalent to regular expressions 10
202	"&$ 1 &"" , Closure Properties for Regular Languages Theorem: If !"", !$ are regular languages, so is !"" ∪!$ (closure under ∪) Proof: Let &"" = ()"", Σ, +"", ,"", -"") recognize !"" &$ = ()$, Σ, +$, ,$, -$) recognize !$ Construct & = (), Σ, +, ,0, -) recognizing !"" ∪!$ & should accept input 0 if either &"" or &$ accept 0. Components of 2: Check-in 1.1 ) = )""×)$ In the proof, if &"" and &$ are finite automata = ,"", ,$ ,"" ∈ )"" and ,$ ∈ )$} where &"" has 8"" states and &$ has 8$ states ,6 = (,"", ,$) Then how many states does & have? (a) 8"" + 8$ + ,, 1 , 7 = +"" ,, 7 , +$ 1, 7 (b) 8"" $ + 8$ $ - = -""×-$ NO! [gives intersection] (c) 8""×8$ - = -""×)$ ∪ )""×-$ Check-in 1.1 11"
203	"Closure Properties continued Theorem: If !"", !$ are regular languages, so is !""!$ (closure under ∘) Proof: Let &"" = ()"", Σ, +"", ,"", -"") recognize !"" &$ = ()$, Σ, +$, ,$, -$) recognize !$ Construct & = (), Σ, +, ,0, -) recognizing !""!$ & should accept input 0 if 0 = 12 where &"" accepts 1 and &$ accepts 2. &$ &"" & 0 1 2 Doesn’t work: Where to split 0? 12"
204	Quick review of today 1. Introduction, outline, mechanics, expectations 2. Finite Automata, formal definition, regular languages 3. Regular Operations and Regular Expressions 4. Proved: Class of regular languages is closed under ∪ 5. Started: Closure under ∘ , to be continued… 13
205	MIT OpenCourseWare https://ocw.mit.edu 18.404J / 18.4041J / 6.840J Theory of Computation Fall 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
206	"18.404/6.840 Lecture 15 Last time: - NTIME ! "" , NP - P vs NP problem - Dynamic Programming, #CFG ∈ P - Polynomial-time reducibility Today: (Sipser §7.5) - NP-completeness 1"
207	"! "" ' Quick Review Defn: ! is polynomial time reducible to "" (! ≤$ "") if ! ≤% "" by a reduction function that is computable in polynomial time. Theorem: If ! ≤$ "" and "" ∈ P then ! ∈ P. ' is computable in polynomial time NP = All languages where can verify membership quickly P = All languages where can test membership quickly ? P versus NP question: Does P = NP? P NP P = NP (!) = + + is a satisfiable Boolean formula} Cook-Levin Theorem: (!) ∈ P → P = NP Proof plan: Show that every ! ∈ NP is polynomial time reducible to (!). 2"
208	"≤"" Example: 3$%& and '()*+, Defn: A Boolean formula - is in Conjunctive Normal Form (CNF) if it has the form - = / ∨1 ∨2 ∧ / ∨4 ∨2 ∨5 ∧⋯∧ (2 ∨5) clause clause literals Literal: a variable or a negated variable Clause: an OR (∨) of literals. CNF: an AND (∧) of clauses. 3CNF: a CNF with exactly 3 literals in each clause. 3$%& = ­ - is a satisfiable 3CNF formula} Defn: A 9-clique in a graph is a subset of k nodes all directly connected by edges. 3-clique '()*+, = ;, 9 graph ; contains a 9-clique} Will show: 3$%& ≤"" '()*+, 4-clique 5-clique 3"
209	"3""#$ ≤& '()*+, conclusion - = / ∨1 ∨2 ∧ / ∨1 ∨4 ∧ / ∨2 ∨5 ∧⋯∧ 7 ∨8 ∨9 Claim: - is satisfiable iff : has a ;-clique (→) Take any satisfying assignment to -. Pick 1 true literal in each clause. The corresponding nodes in G are a ;-clique because they don’t have forbidden edges. (←) Take any ;-clique in :. It must have 1 node in each clause. Set each corresponding literal TRUE. That gives a satisfying assignment to -. The reduction > is computable in polynomial time. Corollary: '()*+, ∈P →3""#$ ∈P : ; > = = # clauses / 1 2 / 1 4 / 2 5 7 8 9 . . . Check-in 15.1 Check-in 15.1 Does this proof require 3 literals per clause? (a) Yes, to prove the claim. (b) Yes, to show it is in poly time. (c) No, it works for any size clauses. 5"
210	NP-completeness Defn: ! is NP-complete if 1) ! ∈NP 2) For all # ∈NP, # ≤% ! If ! is NP-complete and ! ∈P then P = NP. Cook-Levin Theorem: '#( is NP-complete Proof: Next lecture; assume true Importance of NP-completeness 1) Showing ! is NP-complete is evidence of computational intractability. 2) Gives a good candidate for proving P ≠NP. ≤% '#( ≤% 3'#( ≤% +,-./0 NP To show some language + is NP-complete, show 3'#( ≤1 +. or some other previously shown NP-complete language today next lecture ≤% 2#34#(2 Check-in 15.2 Check-in 15.2 What language that we’ve previously seen is most analogous to '#(? (a) #TM (b) 0TM (c) 0616 8 ≥0} 6
211	"!""#$""%! is NP-complete Theorem: !""#$""%! is NP-complete Proof: Show 3'""% ≤) !""#$""%! (assumes 3'""% is NP-complete) Idea: “Simulate” variables and clauses with “gadgets” * = ,- ∨,/ ∨,0 ∧ ,- ∨,/ ∨,2 ∧⋯∧ variable gadget . . . Zig-zag clause gadget 4 〈6, 8, 9〉 ,- 8 Zag-zig Corresponds to setting ,- TRUE Corresponds to setting ,- FALSE 7"
212	"Construction of ! ""# . . . . . . . . . . . . ""$ ""% ! & ' ( = ""# ∨""$ ∨""+ ∧ ""# ∨""$ ∨""- ∧⋯∧ ""% . . . . . . Claim: ( is satisfiable iff ! has a Hamiltonian path from & to '. (→) Take any satisfying assignment to (. Make corresponding zig-zags and zag-zigs through variable gadgets from & to '. Make detours to visit the clause nodes 01. (←) Take any Hamiltonian path from & to '. Show it must be zig-zags and zag-zigs with detours to visit all 01. Get corresponding truth asst. It must satisfy ( because path visits all 01. The reduction 3 is computable in polynomial time. 0# 0$ 04 . . . 0# 0$ 04 5 variables 6 clauses ""# positive in 0# ""# negated in 0$ ""$ negated in 0# Check-in 15.3 Would this construction still work if we made ! undirected by changing all the arrows to lines? In other words, would this construction show that the undirected Hamiltonian path problem is"
213	NP-complete? (a) Yes, the construction would still work. (b) No, the construction depends on ! being directed. Check-in 15.3 8
214	"Quick review of today 1. NP-completeness 2. !""# and 3!""# 3. 3!""# ≤& '""()""#' 4. 3!""# ≤& *+,-./ 5. Strategy for proving NP-completeness: Reduce from 3!""# by constructing gadgets that simulate variables and clauses. 9"
215	MIT OpenCourseWare https://ocw.mit.edu 18.404J / 18.4041J / 6.840J Theory of Computation Fall 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
216	"18.404/6.840 Lecture 19 Last time: - Review !""##$%DFA ∈ PSPACE - Savitch’s Theorem: NSPACE * + ⊆ SPACE *- + - ./01 is PSPACE-complete Today: (Sipser §8.3 – §8.4) - Games and Quantifiers - The Formula Game - Generalized Geography is PSPACE-complete - Logspace: L and NL 1"
217	New York Kansas Pla ter which ended the previous place. No repeats allowed. As Pla Boston Nebraska Arkansas Alaska yers take turns picking places that start with the let sume two players: yer I and Player II Games and Complexity Geography game Check-in 19.1 Let ! be the graph below. Which player has a winning strategy in the Generalized Geography game starting at node $? (a) Player I ! = (b) Player II $ (c) Neither player I (d) Both players The first player stuck (= cannot move) loses. 2 Kalamazoo San Oregon Francisco Generalized Geography Game Played on any directed graph. Players take turns picking nodes Oklahoma that form a simple path. The first player stuck loses. Defn: !! = !, $ Player I has a forced win in Generalized Geography on graph ! starting at node $}. “forced win” also called a “winning strategy” means that the player will win if both players play optimally. Theorem: !! is PSPACE-complete Check-in 19.1
218	Games and Quantifiers - The Formula Game Given QBF ! = ∃$% ∀$' ∃$( ⋯ ∃/∀ $+ ⋯ ∧⋯∧ ⋯ There are two Players “∃” and “∀”. Player ∃ assigns values to the ∃-quantified variables. Player ∀ assigns values to the ∀-quantified variables. The players choose the values according to the order of the quantifiers in !. After all variables have been assigned values, we determine the winner: Check-in 19.2 Player ∃ wins if the assignment satisfies -. Which player has a winning Player ∀ wins if not. strategy in the formula game on Claim: Player ∃ has a forced win in the formula game on ! iff ! is TRUE. ! = ∃$ ∀6 $ ∨6 ∧ $ ∨6 Therefore ! Player ∃ has a forced win on !} = /012. (a) ∃-player Next: show /012 ≤4 55. (b) ∀-player (c) Neither player Check-in 19.2 3
219	!! is PSPACE-complete Theorem: !! is PSPACE-complete Proof: 1) !! ∈ PSPACE (recursive algorithm, exercise) 2) #$%& ≤( !! Give reduction ) from #$%& to !!. ) * = 〈!, .〉 Construct ! to mimic the formula game on *. ! has Players I and II Player I plays role of ∃-Player in *. Ditto for Player II and the ∀-Player. ⋯ ∧ ⋯ ∧ ⋯ ) * = ∃23 ∀24 ∃25 ⋯ ∃/∀ 28 assume in cnf ! = 4
220	"( & & Constructing the !! graph ! Illustrate construction by example Say "" = ∃%& ∀%( ∃%) ⋯ ∀%+ [ ( %& ∨%( ∨%) ) ∧(%& ∨%( ∨%1) ∧⋯∧( ⋯) ] ! = 3( 3+ Endgame ∀ ∃ should win if assignment satisfied all clauses 3+ ∀ should win if some unsatisfied clause Implementation ∃ ∀ picks clause node claimed unsatisfied ∃ picks literal node claimed to satisfy the clause liar will be stuck TRUE FALSE ∀ ⋯ 3 3 %) % %( %& %( %1 %( ⋮ %5 %& 3& ∃ ∀ ∀ I = ∃ II = ∀ ∃ ∀ ∃ ∃ ∀ ∃ 6 ∃ 6 %& %& 3& 3( ∀ 5"
221	Log space To define sublinear space computation, do not count input as part of space used. Use 2-tape TM model with read-only input tape. Defn: L = SPACE log $ NL = NSPACE log $ read-only input tape does not count towards space used Log space can represent a constant number of pointers into the input. count cells used here read/write work tape Examples 1. %%ℛ % ∈ Σ∗} ∈ L ababbaaaaaaaaaabbaba 2. +,-. ∈ NL 1 log $ Work tape tracks corresponding locations NL Nondeterministically select the nodes in the input tape. of a path connecting / to 0. L L = NL? Unsolved 6
222	"Log space properties Theorem: L ⊆ P Proof: Say "" decides # in space $ log ( . Defn: A configuration for "" on ) is *, ,-, ,., / where * is a state, ,- and ,. are the tape head positions, and / is the tape contents. The number of such configurations is 0 ×(×$ log ( ×23 456 7 = $((:) for some <. Therefore "" runs in polynomial time. ,­ Conclusion: # ∈ P * ,. Theorem: NL ⊆ SPACE log. ( / Proof: Savitch’s theorem works for log space 7"
223	"P? .466783 ./ .1 NL L P Unsolved NL properties Theorem: NL ⊆ P Proof: Say NTM "" decides # in space $ log ( . Defn: The configuration graph )*,, for "" on - has )*,, nodes: all configurations for "" on ­ edges: edge from ./ →.1 if ./ can yield .1 in 1 step. .23453 Claim: "" accepts - iff the configuration graph )*,, has a path from .23453 to .466783 Polynomial time algorithm 9 for #: 9 = “On input ­ 1. Construct the )*,,. 2. Accept if there is a path from .23453 to .466783. Reject if not.” L = 8 Check-in 19.3 We showed that ;#9< ∈ NL. What is the best we know about the deterministic space complexity of ;#9<? (a) ;#9< ∈ PSPACE (b) ;#9< ∈ SPACE(() (c) ;#9< ∈ SPACE log@ ( (d) ;#9< ∈ SPACE log ( Check-in 19.3"
224	Quick review of today 1. The Formula Game 2. Generalized Geography is PSPACE-complete 3. Log space: L and NL 4. Configuration graph 5. NL ⊆ P 9
225	MIT OpenCourseWare https://ocw.mit.edu 18.404J / 18.4041J / 6.840J Theory of Computation Fall 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
226	"18.404/6.840 Lecture 26 Last time: - Interactive Proof Systems - The class IP - Graph isomorphism problem, !""# ∈ IP - #""&' ∈ IP (part 1) Today: (Sipser §10.4) - Arithmetization of Boolean formulas - Finish #""&' ∈ IP and conclude that coNP ⊆ IP 1"
227	Review: Interactive Proofs Two interacting parties Verifier (V): Probabilistic polynomial time TM Prover (P): Unlimited computational power Both P and V see input !. They exchange a polynomial number of polynomial-size messages. Then V accepts or rejects. Defn: Pr[ (V ↔ P) accepts ! ] = probability that V accepts when V interacts with P, given input !. Defn: IP = $ for some V and P (This P is an “honest” prover) ! ∈$ → Pr [ (V ↔ P) accepts ! ] ≥ )⁄* Think of ,P as a “crooked” prover trying ! ∉$ → for any prover P, Pr [ (V ↔ P) , accepts ! ] ≤ .⁄* } to make V accept when it shouldn’t. Equivalently: IP = $ for some V ! ∈$ → ∃P Pr [ (V ↔ P) accepts ! ] ≥ )⁄* Here, we emphasize how P is similar ! ∉$ → ∄P Pr [ (V ↔ P) accepts ! ] ≥ .⁄* } to the certificate for NP-languages. An amplification lemma can improve the error probability from .⁄* to .1)2345
228	6 2
229	"1. #+(71 … 78) = #+ 71 … 780 + #+ 71 … 781 2. #+(71 … 73) = +(71 … 73) Two identities coNP ⊆ IP Surprising Theorem: IP = PSPACE IP ⊆ PSPACE: standard simulation, similar to NP ⊆ PSPACE PSPACE ⊆ IP: show ""#$% ∈ IP, we won’t prove coNP ⊆ IP: weaker but similar, show #()"" ∈ IP (#()"" is coNP-hard) #()"" = +, ­ Boolean formula + has exactly - satisfying assignments} Theorem: #()"" ∈ IP Proof: First some notation. Assume + has / variables 01, … , 03. Let +(0) be + with 01 = 0 (0 substituted for 01) 0 = FALSE and 1 = TRUE. Let +(71 … 78) be + with 01 = 71 , … , 08 = 78 for 71, … , 78 ∈ 0,1 . Call 71, … , 78 presets. The remaining 08:1, … , 03 stay as unset variables. Let #+ = the number of satisfying assignments of +. Let #+ 0 = the number of satisfying assignments of + 0 . Let #+(71 … 78)"
230	= the number of satisfying assignments of +(71 … 78) Check-in 26.1 Let + = 01 ∨ 0= ∧ 01 ∨ 0= Check all that are true: a) #+ = 1 b) #+ = 2 c) #+ 0 = 1 d) #+ 0 = 2 e) #+ 00 = 0 f) #+ 00 = 1 3 Check-in 26.1
231	") #' 10 #' 1 #' #""#$ ∈ IP – 1st attempt Theorem: #""#$ ∈ IP Proof: Protocol for V and (the honest) P on input 〈', )〉 0) P sends #'; V checks ) = #' 1) P sends #' 0 , #' 1 ; V checks #' = #' 0 + #' 1 2) P sends #' 00 , #' 01 , #' 10 , #' 11 ; V checks #' 0 = #' 00 + #' 01 red = #' 1 = #' 10 + #' 11 0 −1 0 −1 ) ≠#' ⋮ incorrect 0 = 0) P sends #' 0 ⋯0 , … , #' 1 ⋯1 ; V checks #' 0 ⋯0 = #' 0 ⋯00 + #' 0 ⋯01 V checks #' 1 ⋯1 = #' 1 ⋯10 + #' 1 ⋯11 #' 1 ⋯1 = ' 1 ⋯1 #' 00 #' 01 #' 10 #' 11 V accepts if all checks are correct. Otherwise V rejects. ⋮ ⋮ ⋮ #' 0 ⋯0 ⋯ #' 1 ⋯1 #' 0 #' 1 #' ⋮"
232	+ 0 0 + 1) V checks #' 0 ⋯0 = ' 0 ⋯0 ⋮ + + Problem: Exponential. Will fix. ' 0 ⋯ 0 = ⋯ ≠ = ' 1 ⋯ 1 4
233	"Idea for fixing #""#$ ∈ IP protocol ) ) = = #& #& + #& 0 #& 1 #& ,- + + Non-Boolean assignments to the variables of & #& 00 #& 01 #& 10 #& 11 #& ,-,. + + + + ⋮ ⋮ ⋮ #& 0 ⋯0 ⋯ #& 1 ⋯1 #& ,- ⋯,/ & 0 ⋯ 0 = ⋯ = & 1 ⋯ 1 = & ,- ⋯,/ 5"
234	"Important: For Boolean 0 … 1 the values of 7 /0 … /1 and #7(/0 … /1) are unchanged from the previous definition. We have extended these functions to non-Boolean values Arithmetizing Boolean formulas Simulate ∧ and ∨ with + and × / ∧4 → /×4 = /4 / → 1 −/ / ∨4 → / + 4 −/4 7 →89 degree(89) ≤7 Let !"" = 0,1, … , ( −1 for prime ( > 2, be a finite field (+, × mod () and let /0, … , /1 ∈ !"" Let 7 /0 … /1 = 89 where ;0⋯;1 = /0 ⋯/1 and remaining ;1=0, … , ;, stay as unset variables. Let #7(/0 … /1) = A 7(/0 … /,) /1=0, … , /, ∈ {0,1} identities still true 1. #7(/0 … /1) = #7 /0 … /10 + #7 /0 … /11 / / Check-in 26.2 Let 7 = ;0 ∨ ;D ∧ ;0 ∨ ;D . Check all that are true: a) 89 = ;0 + ;D − ;0;D 1 − ;0 + 1 −"
235	;D − 1 − ;0 1 − ;D b) 89 = ;0 + ;D 1 − ;0 + 1 − ;D c) 89 = ;0 + ;D − 2;0;D 2. #7(/0 … /,) = 7(/0 … /,) 6 Check-in 26.2
236	"[P needs to show 5 is correct] [P needs to show #' 454: is correct] 1) P sends #' #""#$ ∈ IP – version 1 Theorem: #""#$ ∈ IP Proof: Protocol for V and (the honest) P on input 〈', )〉 0) P sends #'; V checks ) = #' V checks #' = #' 4 6, is correct ] #' 0 + #' 1 [by evaluating polynomial for #' , ] V[P nds se needsrat ndom ∈ ' o show45# 1) P sends #' 0 ,as a polynomial in 7 [sends coefficients – recall deg -. ≤|' , #' 1 ; V checks,#' = #' 0 + #' 1 | ] 2) P sends #' 45, as a polynomial in , V checks #'(45) po ng y [ 5 5 = #' 4 0 + #' 4 1 b evaluati lynomial for #' 45, ] V sends random 4: ∈67 ⋮ Recall #'(@5 … @B) = C '(@5 … @>) <) P sends #' 45 ⋯ 4>?5, as a polynomial in , @BD5, … , @> ∈ {0,1} V"
237	checks #'(45 ⋯ 4>?5) = #' 45 ⋯ 4>?50 + #' 45 ⋯ 4>?51 V sends random 4> ∈67 < + 1) V checks #' 45 ⋯4> = ' 45 ⋯4> V accepts if all checks are correct. Otherwise V rejects. 7
238	"#"" #"" % = 3%' −5%'*+ + ⋯+ 7 #"" /+% = ⋯ #"" /+/0% = ⋯ #"" /+ ⋯/1*+% = ⋯ accept #"" $ 1 #"" /+ #"" /+0 #"" /+/0 #"" /+/01 #"" /+ ⋯/1*+ #"" /+ ⋯/1*+1 #"" /+ ⋯/1 #456 ∈ IP – version 2 Input 〈"", $〉 Verifier checks Prover sends Verifier sends #"" #"" % = 3%' − 5%'*+ + ⋯ + 7 #"" /+% = ⋯ #"" /+/0% = ⋯ #"" /+ ⋯ /1*+% = ⋯ #"" = $ + /+ /0 /1 reject #"" 0 #"" #"" 1 #"" /+ + #"" /+0 #"" /+1 If $ is correct, V will accept. #"" /+/0 If $ is wrong, V probably will + reject, whatever P does. #"" /+/00 #"" /+/01 ⋮ #"" /+ ⋯/1*+ + #"" /+ ⋯ /1*+0 #"" /+ ⋯ /1*+1 #"" /+ ⋯/1 "" /+ ⋯/1 = 8"
239	"Check-in 26.3 P = NP ? a) YES. Deep learning will do !""# ∈ P, but we won’t understand how. b) NO. But we will never prove it. c) NO. We will prove it but only after 100 years d) NO. We will prove it in ' years, 20 ≤ ' ≤ 100 e) NO. We will prove it in ' years, 1 ≤ ' < 20 f) NO. One of us is writing up the proof now… 9 Check-in 26.3"
240	"Quick review of today Finished #""#$ ∈ IP and coNP ⊆ IP Additional subjects: 18.405/6.841 Advanced complexity F2021 18.425/6.875 Cryptography F2021 6.842 Randomness and Computation ? Good luck on the final! Best wishes for the holidays and the New Year! 10"
241	MIT OpenCourseWare https://ocw.mit.edu 18.404J / 18.4041J / 6.840J Theory of Computation Fall 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
242	"18.404/6.840 Lecture 14 (midterm replaced lecture 13) Last time: - TIME ! "" - P = ⋃% TIME(""%) - ()*+ ∈ P Today: (Sipser §7.2 – §7.3) - NTIME ! "" - NP - P vs NP problem - Dynamic Programming - Polynomial-time reducibility 1"
243	"Unsolved Problem Quick Review Defn: TIME ! "" = {%| some deterministic 1-tape TM ' decides % and ' runs in time ( ! "" } Defn: P = ⋃+ TIME(""+) = polynomial time decidable languages ./01 = 2, 4, ! 2 is a directed graph with a path from 4 to ! } Theorem: ./01 ∈ P 2 1/'./01 = 2, 4, ! 2 is a directed graph with a path from 4 to ! 4 ! that goes through every node of 2 } 1/'./01 ∈ P ? [connection to factoring] 2"
244	Nondeterministic Complexity In a nondeterministic TM (NTM) decider, all branches halt on all inputs. Defn: An NTM runs in time !(#) if all branches halt within !(#) steps on all inputs of length #. Defn: NTIME ! # = {'| some 1-tape NTM decides ' and runs in time ( ! # } Defn: NP = ⋃* NTIME(#*) = nondeterministic polynomial time decidable languages • Invariant for all reasonable nondeterministic models • Corresponds roughly to easily verifiable problems 3 Computation tree for NTM on input +. ! # all branches halt within !(#) steps . . .
245	"!""#$""%! ∈NP Theorem: !""#$""%! ∈NP Proof: “On input 〈(, *, +〉(Say ( has - nodes.) 1. Nondeterministically write a sequence ./, .0, … , .2 of - nodes. 2. Accept if ./ = * .2 = + each (.5, .56/) is an edge and no .5 repeats. 3. Reject if any condition fails.” Computation of M on 〈(, *, +〉 ⋮ Guess bits of ./ Guess bits of .2 ⋮ ⋮ Guess bits of .0 ⋮ Check ./, .0, … , .2 works ⋯ acc/rej acc/rej 4"
246	"!""#$""%&'(% ∈NP Defn: !""#$""%&'(% = + + is not prime and + is written in binary} = + + = ,- for integers ,, - > 1, + in binary} Theorem: !""#$""%&'(% ∈NP Proof: “On input + 1. Nondeterministically write , where 1 < , < +. 2. Accept if , divides + with remainder 0. Reject if not.” Note: Using base 10 instead of base 2 wouldn’t matter because can convert in polynomial time. Bad encoding: write number 3 in unary: 14 = 111 ⋯1 4 , exponentially longer. Theorem (2002): !""#$""%&'(% ∈P We won’t cover this proof. 5"
247	"Intuition for P and NP NP = All languages where can verify membership quickly P = All languages where can test membership quickly Examples of quickly verifying membership: - !""#$""%!: Give the Hamiltonian path. - &'#$'()%*(: Give the factor. The Hamiltonian path and the factor are called short certificates of membership. P ⊆NP Question: P = NP? Famous unsolved problem (Cook 1971). Conjecture: P ≠ NP. Some problems are NP and not in P. Hard to prove the conjecture because polynomial-time algorithms are powerful. Example: Show ""CFG ∈P. NP P Check-in 14.1 Check-in 14.1 Let !""#$""%! be the complement of !""#$""%!. So 0, 2, 3 ∈!""#$""%! if 0 does not have a Hamiltonian path from 2 to 3. Is !""#$""%! ∈NP? (a) Yes, we can invert the accept/reject output of the NTM for !""#$""%!. (b) No, we cannot give a short certificate for a graph not to have a Hamiltonian path. (c) I don’t know. 6"
248	Recall !CFG Recall: !CFG = { ', ) | ' is a CFG and ) ∈, ' } Theorem: !CFG is decidable Proof: .A−CFG = “On input ', ) 1. Convert ' into Chomsky Normal Form. 2. Try all derivations of length 2|)| −1. 3. Accept if any generate ). Reject if not. Theorem: !CFG ∈NP Proof: “On input ', ) 1. Nondeterministically pick some derivation of length 2|)| −1. 2. Accept if it generates ). Reject if not. Chomsky Normal Form (CNF): A →BC B →b Let’s always assume ' is in CNF. 7
249	Attempt to show !CFG ∈P Theorem: !CFG ∈P Proof attempt: Recursive algorithm & tests if ' generates (, starting at any specified variable R. & = “On input 〈', (, R〉 1. For each way to divide ( = -. and for each rule R →ST 2. Use & to test 〈', -, S〉and 〈', ., T〉 3. Accept if both accept 4. Reject if none of the above accepted.” Then decide !CFG by starting from '’s start variable. & is a correct algorithm, but it takes non-polynomial time. (Each recursion makes 0(2) calls and depth is roughly log 2.) Fix: Use recursion + memory called Dynamic Programming (DP) Observation: String ( of length 2 has 0(27) substrings (8 ⋯(: therefore there are only 0(27) possible sub-problems 〈', -, S〉to solve. S T R ( - . 8
250	DP shows !CFG ∈P Theorem: !CFG ∈P Proof : Use DP (Dynamic Programming) = recursion + memory. & = “On input 〈), +, R〉 same as before S T R + - . 1. For each way to divide + = -. and for each rule R →ST 2. Use & to test 〈), -, S〉and 〈), ., T〉 3. Accept if both accept 4. Reject if none of the above accepted.” Then decide !CFG by starting from G’s start variable. Total number of calls is 0(23) so time used is polynomial. Alternately, solve all smaller sub-problems first: “bottom up” Check-in 14.2 Check-in 14.2 Suppose 5 is a CFL. Does that imply that 5 ∈P? (a) Yes (b) No. 9
251	!CFG ∈P & Bottom-up DP Theorem: !CFG ∈P Proof : Use bottom-up DP. & = “On input 〈), +〉 1. For each +- and variable R Solve 〈), +-, R〉by checking if R →+- is a rule. 2. For / = 2, … , 2 and each substring 3 of + where 3 = / and variable R Solve 〈), 3, R〉by checking for each R →ST and each division 3 = 45 if both 〈), 4, S〉and 〈), 5, T〉were positive. 3. Accept if 〈), +, S〉is positive where S is the original start variable. 4. Reject if not.” Total number of calls is 6(28) so time used is polynomial. Often, bottom-up DP is shown as filling out a table. Solve for substrings of length 1 Solve for substrings of length / by using previous answers for substrings of length < /. 10
252	Satisfiability Problem Defn: A Boolean formula ! has Boolean variables (TRUE/FALSE values) and Boolean operations AND (∧), OR (∨), and NOT (¬). Defn: ! is satisfiable if ! evaluates to TRUE for some assignment to its variables. Sometimes we use 1 for True and 0 for False. Example: Let ! = & ∨' ∧(& ∨') (Notation: & means ¬&) Then ! is satisfiable (x=1, y=0) Defn: *+, = ! ! is a satisfiable Boolean formula} Theorem (Cook, Levin 1971): *+, ∈P →P = NP Proof method: polynomial time (mapping) reducibility Check-in 14.3 Check-in 14.3 Is *+, ∈NP? (a) Yes. (b) No. (c) I don’t know. (d) No one knows. 11
253	"Polynomial Time Reducibility Defn: ! is polynomial time reducible to "" (! ≤$ "") if ! ≤% "" by a reduction function that is computable in polynomial time. Theorem: If ! ≤$ "" and "" ∈P then ! ∈P. ! "" ' ' is computable in polynomial time ≤$ ≤% NP P (!) Idea to show (!) ∈P →P = NP !TM decidable T-recognizable Analogy with !TM 12"
254	"Quick review of today 1. NTIME ! "" and NP 2. #$%&$'# and ()%&)*+',* ∈NP 3. P versus NP question 4. $CFG ∈P via Dynamic Programming 5. The Satisfiability Problem *$' 6. Polynomial time reducibility 13"
255	MIT OpenCourseWare https://ocw.mit.edu 18.404J / 18.4041J / 6.840J Theory of Computation Fall 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
256	18.404/6.840 Lecture 20 Last time: - Games and Quantifiers - Generalized Geography is PSPACE-complete - Logspace: L and NL Today: (Sipser §8.4) - Review NL ⊆ P - Review NL ⊆ SPACE log% & - NL-completeness - NL = coNL 1
257	Work tape tracks n n a . Review: log space Model: 2-tape TM with read-only input tape for defining sublinear space computation. Defn: L = SPACE log $ NL = NSPACE log $ doesn’t count towards space used input tape read-only Log space can represent a constant number of pointers into the input. count cells used here Examples 1 log $ work tape read/write 1. %%ℛ % ∈ Σ∗} ∈ L 2ababbaaaaaaaaaabbaba = 45, 47 , 48, 499 , … , / = ⋯, 0 = ⋯ input tape 2. +,-. ∈ NL correspo di g locations Work tape tracks the current node on Nondeterministically select the nodes in the input t pe of a path connecting / to 0. the guessed path. NL L L = NL? Unsolved 2
258	"Review: L ⊆ P Theorem: L ⊆ P Proof: Say "" decides # in space $ log ( . Defn: A configuration for "" on ) is *, ,-, ,., / where * is a state, ,- and ,. are the tape head positions, and / is the work tape contents. The number of such configurations is 0 ×(×$ log ( ×23 456 7 = $((:) for some <. ,­ Therefore "" runs in polynomial time. Conclusion: # ∈ P * read-only input ,. / 3"
259	recurse recurse Review: NL ⊆ SPACE log% & Theorem: NL ⊆ SPACE log% & Proof: Savitch’s theorem works for log space Each recursion level stores 1 config = : log & space. :(log &) '()* ⋯ ), ˽ … ˽ Number of levels = log 2 = : log & . Total : log% & space. 2 = 45 678 , aaba'9da⋯cab ⋯ 'accept ⋯ 4
260	"Review: NL ⊆ P Theorem: NL ⊆ P Proof: Say NTM "" decides # in space $ log ( . Defn: The configuration graph )*,, for "" on - has nodes: all configurations for "" on ­ edges: edge from ./ → .1 if ./ can yield .1 in 1 step. Claim: "" accepts - iff the configuration graph )*,, configuration graph )*,, .23453 .466783 iff "" accepts ­ has a path from .23453 to .466783 Polynomial time algorithm 9 for #: 9 = “On input ­ 1. Construct )*,,. [polynomial size] 2. Accept if there is a path from .23453 to .466783. ./ .1 NL P Reject if not.” L = P? Unsolved L 5"
261	Defn: ! is NL-complete if 1) ! ∈NL 2) For all # ∈NL, # ≤% ! Log-space reducibility NL-completeness Check-in 20.1 If - is a log-space transducer that computes ., then for inputs 3 of length &, how long can . 3 be? (a) at most ' log & (d) at most 27 8 (b) at most '(&) (e) any length (c) at most polynomial in & - Defn: A log-space transducer is a TM with three tapes: 1. read-only input tape of size & 2. read/write work tape of size '(log &) 3. write-only output tape A log-space transducer - computes a function .: Σ∗ → Σ∗ if - on input 3 halts with . 3 on its output tape for all 3. Say that . is computable in log-space. Defn: # is log-space reducible to ! (# ≤% !) if # ≤4 ! by a reduction function that is computable in log-space. 6 read-only input read/write work ' log & write-only output Theorem: If # ≤% ! and ! ∈ L then # ∈ L Proof: TM for
262	# = “On input 3 1. Compute .(3) 2. Run decider for ! on . 3 . Output same.” BUT we don’t have space to store .(3). So, (re-)compute symbols of .(3) as needed. Check-in 20.1
263	"= 〈16 7 89: <: 8 =>?:〉 !""#$ is NL-complete Theorem: !""#$ is NL-complete Proof: 1) !""#$ ∈ NL • . Give a log-space reduction mapping "" to !""#$. 2) For all "" ∈ NL, "" ≤' !""#$ Let "" ∈ NL be decided by NTM ( in space ) log - . [Modify ( to erase work tape and move heads to left end upon accepting.] , , ; , ;= 16,7 89:;<: 8;==>?: . / = 1, 3, 4 / ∈ "" iff 1 has a path from 3 to 4 . / = Here is a log-space transducer # to compute in log-space. 8A 8B . read-only input # = “on input / / 1. For all pairs 8A, 8B of configurations of ( on /. 2. Output those pairs which are legal moves for (. read/write work 8A 8B # ) log - 3. Output 89:;<: and 8;==>?:.” write-only output (16,7= 8D, 8E , 8F, 8GG , … ) (89:;<: = ⋯) (8;==>?: = ⋯) 7"
264	"2""#$ is NL-complete Theorem: 2""#$ is NL-complete Proof: 1) Show 2""#$ ∈ NL good exercise 2) Show &#$' ≤) 2""#$ Give log-space reduction f from &#$' to 2""#$. * +, -, . = 〈1〉 For each node 3 in + put a variable 45 in 1. For each edge (3, 7) in +, put a clause (45 → 4:) in 1 [equivalent to 45 ∨4: ]. In addition put the clauses (4< ∨ 4<) and (4= → 4<) in 1. Show + has an path from - to . iff 1 is unsatisfiable. (→) Follow implications to get a contradiction. (←) If + has no path from - to ., then assign all 45 TRUE where 3 is reachable from -, and all other variables FALSE. That gives a satisfying assignment to 1. Straightforward to show * is computable in log-space. 8"
265	"Theorem: If some NL-machine (log-space NTM) computes -./ℎ, then some NL-machine computes 8. Proof: “On input 〈1, 3〉 1. Let < ←0 2. For each node 7 3. If -./ℎ1, 3, 7 = YES, then < ←< + 1 4. If -./ℎ1, 3, 7 = NO, then continue 5. Output <” Next: Converse of above NL = coNL (part 1/4) Theorem (Immerman-Szelepcsényi): NL = coNL Proof: Show !""#$ ∈ NL Defn: NTM & computes function ': Σ∗ → Σ∗ if for all , 1) All branches of & on , halt with ' , on the tape or reject. 2) Some branch of & on , does not reject. Check-in 20.2 Consider the statements: YES, if 1 has a path from 3 to / Let -./ℎ 1, 3, / = 5 NO, if not (1) !""#$ ∈ NL, and -./ℎ 1, 3, 7 = YES} (2) Some NL-machine computes the -./ℎ function. Let 6 = 6 1, 3 = 7 Let 8 = 8 1, 3 = |6| What implications can we prove easily? 1 6 (a) (1) → (2)"
266	only 6 = Reachable nodes 3 (b) (2) → (1) only 8 = # reachable (c) Both implications 8 = |6| (d) Neither implication 9 Check-in 20.2
267	"NL = coNL (part 2/4) – key idea Theorem: If some NL-machine computes !, then some NL-machine computes ""#$ℎ. Proof: “On input 〈', ), $〉 1. Compute ! 2. + ←0 3. For each node . 4. Nondeterministically go to (p) or (n) (p) Nondeterministically pick a path from ) to . of length ≤0. 5 ' If fail, then reject. ) If . = $, then output YES, else set + ←+ + 1. (n) Skip . and continue. ! = |5| 5. If + ≠! then reject. 6. Output NO.” [found all ! reachable nodes and none were $} 10"
268	"NL = coNL (part 3/4) YES, if ( has a path * to % of length ≤1 Let #$%ℎ"" (, *, % = 8 NO, if not Let 6"" = 6"" (, * = / #$%ℎ"" (, *, / = YES} Let !"" = !"" (, * = |6""| Theorem: If some NL-machine computes !"", then some NL-machine computes #$%ℎ"" . Proof: “On input 〈(, *, %〉 1. Compute !"" ( 2. , ←0 3. For each node / 4. Nondeterministically go to (p) or (n) !"" = |6""| (p) Nondeterministically pick a path from * to / of length ≤1. If fail, then reject. If / = %, then output YES, else set , ←, + 1. (n) Skip / and continue. 5. If , ≠ !"" then reject. 6. Output NO” [found all !"" reachable nodes and none were %} 11 6"" *"
269	"* , 7"" !"" = |7""| 7""'( Hence :;<= ∈NL “On input 〈*, ,, %〉 1. !? = 1. 2. Compute each !""'( from !"" for 3 = 1 to @. 3. Accept if #$%ℎA(*, ,, %) = NO. 4. Reject if #$%ℎA(*, ,, %) = YES.” NL = coNL (part 4/4) Theorem: If some NL-machine computes !"", then some NL-machine computes #$%ℎ""'(. Proof: “On input 〈*, ,, %〉 1. Compute ! 2. . ←0 3. For each node 1 4. Nondeterministically go to (p) or (n) (p) Nondeterministically pick a path from , to 1 of length ≤3. If fail, then reject. If 1 has an edge to %, then output YES, else set . ←. + 1. (n) Skip 1 and continue. Check-in 20.3 5. If . ≠ !"" then reject. Can we now show 2E;< is NL-complete? 6. Output NO.” [found all !"" reachable nodes (a) No. and none had an edge to %} (b) Yes. Corollary: Some NL-machine computes !""'( from !"" . Yes: :;<= ≤F :;<= & :;<= ≤F 2E;< So :;<= ≤F 2E;< thus"
270	:;<= ≤F 2E;< 12 Check-in 20.3
271	"Quick review of today 1. Log-space reducibility 2. L = NL? question 3. !""#$ is NL-complete 4. 2&""# is NL-complete 5. NL = coNL 13"
272	MIT OpenCourseWare https://ocw.mit.edu 18.404J / 18.4041J / 6.840J Theory of Computation Fall 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
273	18.404/6.840 Lecture 9 Last time: - !TM is undecidable - The diagonalization method - !TM is T-unrecognizable - The Reducibility Method, preview Today: (Sipser §5.1, §5.3) - The Reducibility Method for proving undecidability and T-unrecognizability. - General reducibility - Mapping reducibility 1
274	The Reducibility Method If we know that some problem (say !TM) is undecidable, we can use that to show other problems are undecidable. Defn: $!%&TM = (, * ( halts on input *} Recall Theorem: $!%&TM is undecidable Proof by contradiction, showing that !TM is reducible to $!%&TM: Assume that $!%&TM is decidable and show that !TM is decidable (false!). Let TM , decide $!%&TM. Construct TM - deciding !TM. - = “On input (, * 1. Use , to test if ( on * halts. If not, reject. 2. Simulate ( on * until it halts (as guaranteed by ,). 3. If ( has accepted then accept. If ( has rejected then reject. TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 2
275	"Reducibility – Concept If we have two languages (or problems) ! and "", then ! is reducible to "" means that we can use "" to solve !. Example 1: Measuring the area of a rectangle is reducible to measuring the lengths of its sides. Example 2: We showed that !NFA is reducible to !DFA . Example 3: From Pset 2, PUSHER is reducible to 'CFG . (Idea- Convert push states to accept states.) If ! is reducible to "" then solving "" gives a solution to !. - then "" is easy →! is easy. - then ! is hard →"" is hard. this is the form we will use 3 Check-in 9.1 Is Biology reducible to Physics? (a) Yes, all aspects of the physical world may be explained in terms of Physics, at least in principle. (b) No, some things in the world, maybe life, the brain, or consciousness, are beyond the realm pf Physics. (c) I’m on the fence on this question! Check-in 9.1"
276	!TM is undecidable Let !TM = { & | & is a TM and ( & = ∅} Theorem: !TM is undecidable Proof by contradiction. Show that +TM is reducible to !TM. Assume that !TM is decidable and show that +TM is decidable (false!). Let TM , decide !TM. Construct TM - deciding +TM. - = “On input &, / 1. Transform & to new TM &0 = “On input 1 1. If 1 ≠/, reject. 2. else run & on / 3. Accept if & accepts.” 2. Use , to test whether ((&0) = ∅ 3. If YES [so & rejects /] then reject. If NO [so & accepts /] then accept. &0 works like & except that it always rejects strings 1 where 1 ≠/. if & accepts / So ( &0 = 5 / ∅ if & rejects / 4
277	Mapping Reducibility Defn: Function !: Σ∗ → Σ∗ is computable if there is a TM & where & on input ' halts with !(') on its tape, for all strings '. Defn: * is mapping-reducible to + (* ≤- +) if there is a computable function ! where ' ∈* iff ! ' ∈+. ' ! ' * ! + Example: *TM ≤- 1TM The computable reduction function ! is !( 2, ' ) = 24 Recall TM 24 = “On input 9 1. If 9 ≠ ', reject. Because 2, ' ∈ *TM iff 24 ∈1TM 2. else run 2 on ' ( 2 accepts ' iff 5 24 ≠∅ ) 3. Accept if 2 accepts.” 5
278	Mapping Reductions - properties Theorem: If ! ≤# $ and $ is decidable then so is ! Proof: Say TM % decides $. Construct TM & deciding !: & = “On input ( 1. Compute )(() 2. Run % on )(() to test if ) ! ) $ ( ∈$ 3. If % halts then output same result.” Corollary: If ! ≤# $ and ! is undecidable then so is $ Theorem: If ! ≤# $ and $ is T-recognizable then so is ! Proof: Same as above. Corollary: If ! ≤# $ and ! is T-unrecognizable then so is $ Check-in 9.2 Suppose ! ≤# $. What can we conclude? Check all that apply. (a) $ ≤# ! (b) ! ≤# $ (c) None of the above Check-in 9.2 6
279	"Mapping vs General Reducibility Mapping Reducibility of ! to "": Translate !-questions to ""-questions. - A special type of reducibility - Useful to prove T-unrecognizability ! ' "" (General) Reducibility of ! to "": Use "" solver to solve !. - May be conceptually simpler ! solver Check-in 9.3 - Useful to prove undecidability We showed that if ! ≤& "" and "" solver "" is T-recognizable then so is !. Noteworthy difference: Is the same true if we use - ! is reducible to ! general reducibility instead of mapping reducibility? - ! may not be mapping reducible to !. (a) Yes For example !TM ≰& !TM (b) No Check-in 9.3 7"
280	"Reducibility – Templates To prove ! is undecidable: - Show undecidable "" is reducible to !. (often "" is ""TM ) - Template: Assume TM % decides !. Construct TM & deciding "". Contradiction. To prove ! is T-unrecognizable: - Show T-unrecognizable "" is mapping reducible to !. (often "" is ""TM) - Template: give reduction function '. 8"
281	!TM is T-unrecognizable Recall !TM = { & | & is a TM and ( & = ∅} Theorem: !TM is T-unrecognizable Proof: Show +TM ≤- !TM Reduction function: . &, 0 = &1 Recall TM &1 = “On input 3 1. If 3 ≠0, reject. Explanation: &, 0 ∈ +TM iff &1 ∈!TM 2. else run & on 0 & rejects 0 iff ( &1 = ∅ 3. Accept if & accepts.” +TM . !TM 9
282	"!""TM and !""TM are T-unrecognizable !""TM = &', &) &' and &) are TMs and * &' = *(&)) } Theorem: Both !""TM and !""TM are T-unrecognizable Proof: (1) .TM ≤0 !""TM (2) .TM ≤0 !""TM For any 1 let 23 = “On input 4 23 acts on all inputs the way & acts on 1. 1. Ignore 4. 2. Simulate & on 1.” (1) Here we give 5 which maps .TM problems (of the form &, 1 ) to !""TM problems (of the form 2', 2) ). 5 &, 1 = 〈23, 2reject〉 2reject is a TM that always rejects. (2) Similarly 5 &, 1 = 〈23, 2accept 〉 2accept always accepts. 10"
283	"Reducibility terminology Why do we use the term “reduce”? When we reduce ! to "", we show how to solve ! by using "" and conclude that ! is no harder than "". (suggests the ≤$ notation) Possibility 1: We bring !’s difficulty down to ""’s difficulty. Possibility 2: We bring ""’s difficulty up to !’s difficulty. 11"
284	Quick review of today 1. Introduced The Reducibility Method to prove undecidability and T-unrecognizability. 2. Defined mapping reducibility as a type of reducibility. 3. !TM is undecidable. 4. !TM is T-unrecognizable. 5. !$TM and !$TM are T-unrecognizable. 12
285	MIT OpenCourseWare https://ocw.mit.edu 18.404J / 18.4041J / 6.840J Theory of Computation Fall 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
286	"18.404/6.840 Lecture 17 Last time: - Cook-Levin Theorem: !""# is NP-complete - 3!""# is NP-complete Today: (Sipser §8.1 – §8.2) - Space complexity - SPACE % & , NSPACE % & - PSPACE, NPSPACE - Relationship with TIME classes - Examples 1"
287	An NTM ' runs in space !(%) if all branches halt and each branch uses at most !(%) tape cells on all inputs of length %. Defn: SPACE ! % = {,| some deterministic 1-tape TM ' decides , and ' runs in space . ! % } NSPACE ! % = {,| some nondeterministic 1-tape TM ' decides , and ' runs in space . ! % } PSPACE = ⋃1 SPACE(%1) “polynomial space” NPSPACE = ⋃1 NSPACE(%1) “nondeterministic polynomial space” SPACE Complexity Defn: Let !: ℕ→ℕ where ! % ≥%. Say TM ' runs in space !(%) if ' always halts and uses at most !(%) tape cells on all inputs of length %. Check-in 17.1 We define space complexity for multi-tape TMs by taking the sum of the cells used on all tapes. Do we get the same class PSPACE for multi-tape TMs? (a) No. (b) Yes, converting a multi-tape TM to single-tape only squares the amount of space used. (c) Yes, converting a multi-tape TM to single-tape only increases the amount of space used by a
288	constant factor. Check-in 17.1 2
289	"Relationships between Time and SPACE Complexity Theorem: For ! "" ≥"" 1) TIME ! "" ⊆ SPACE ! "" 2) SPACE ! "" ⊆ TIME 2& ' ( = ⋃+ TIME ,' ( Proof: 1) A TM that runs in !("") steps cannot use more than !("") tape cells. 2) A TM that uses !("") tape cells cannot use more than ,' ( time without repeating a configuration and looping (for some ,). Corollary: P ⊆ PSPACE Theorem: NP ⊆ PSPACE [next slide] 3"
290	"NP ⊆ PSPACE Theorem: NP ⊆ PSPACE Proof: 1. ""#$ ∈ PSPACE 2. If # ≤' ( and ( ∈ PSPACE then # ∈ PSPACE PSPACE Defn: coNP = # # ∈ NP} *#+,#$* ∈ coNP coNP NP $#-$./.01 = 2 all assignments satisfy 2} ∈ coNP coNP ⊆ PSPACE (because PSPACE = coPSPACE) Or possibly: P P = PSPACE ? Not known. P = NP = coNP = PSPACE 4"
291	"TRUE FALSE Example: !""#$ Defn: A quantified Boolean formula (QBF) is a Boolean formula with leading exists (∃&) and for all (∀&) quantifiers. All variables must lie within the scope of a quantifier. A QBF is TRUE or FALSE. Check-in 17.2 Examples: () = ∀& ∃+ & ∨+ ∧ & ∨+ (. = ∃+ ∀& & ∨+ ∧ & ∨+ How is 23! a special case of !""#$? (a) Remove all quantifiers. Defn: !""#$ = ( ( is a QBF that is TRUE} (b) Add ∃ and ∀ quantifiers. Thus () ∈ !""#$ and (. ∉ !""#$. (c) Add only ∃ quantifiers. Theorem: !""#$ ∈ PSPACE (d) Add only ∀ quantifiers. 5 Check-in 17.2"
292	"!""#$ ∈ PSPACE Theorem: !""#$ ∈ PSPACE Proof: “On input 〈'〉 1. If ' has no quantifiers, then ' has no variables so either ' = True or ' = False. Output accordingly. 2. If ' = ∃+ , then evaluate , with + = TRUE and + = FALSE recursively. Accept if either accepts. Reject if not. 3. If ' = ∀+ , then evaluate , with + = TRUE and + = FALSE recursively. Accept if both accept. Reject if not.” Space analysis: Each recursive level uses constant space (to record the + value). The recursion depth is the number of quantifiers, at most . = | ' |. So !""#$ ∈ SPACE(.) 6"
293	"Example: Ladder Problem A ladder is a sequence of strings of a common length where WORK consecutive strings differ in a single symbol. PORK A word ladder for English is a ladder of English words. PORT SORT Let ! be a language. A ladder in ! is a ladder of strings in !. SOOT Defn: ""!##$%DFA = *, ,, ­ * is a DFA and ""(*) contains SLOT a ladder 01, 02, … , 04 where 01 = , and 04 = -}. PLOT Theorem: ""!##$%DFA ∈ NPSPACE PLOY PLAY PLAY 7"
294	"!""##$%DFA ∈ NPSPACE Theorem: !""##$%DFA ∈ NPSPACE Proof idea: Nondeterministically guess the sequence from * to +. Careful- (a) cannot store sequence, (b) must terminate. Proof: “On input ,, *, + 1. Let . = * and let 0 = |*|. 4 WORK 2. Repeat at most 2 times where 2 = Σ . ≤2 PORK 3. Nondeterministically change one symbol in .. PORT 4. Reject if . ∉ !(,). SORT SOOT 5. Accept if . = +. SLOT 6. Reject [exceeded 2 steps]. * 8 :(8) ˽ ˽ PLOT PLOY PLAY Space used is for storing . and 2. !""##$%DFA ∈ NSPACE(8). + . 2 Theorem: !""##$%DFA ∈ PSPACE (!) 8"
295	"WORK PLAY @ AAAA AAAB AAAC AAAD AAAZ AABA AABB ABLE recurse recurse ⁄ G , ⁄ G , !""##$%DFA ∈ PSPACE Theorem: !""##$%DFA ∈ SPACE(+,) Proof: Write . / 0 if there’s a ladder from . to 0 of length ≤2. Here’s a recursive procedure to solve the bounded DFA ladder problem: 3456#$#-!""##$%DFA = 3, ., 0, 2 3 a DFA and . / 0 by a ladder in !(3)} 3-! = “On input 3, ., 0, 2 Let : = . = |0|. 1. For 2 = 1, accept if ., 0 ∈ !(3) and differ in ≤1 place, else reject. 2. For 2 > 1, repeat for each > of length |.| Check-in 17.3 3. Recursively test . //, > and > //, 0 [division rounds up] Find an English word ladder 4. Accept both accept. connecting MUST and VOTE. 5. Reject [if all fail].” (a) Already did it. B Test 3, ., 0 ∈ !""##$%DFA with 3-! procedure on input 3, ., 0, @ for @ = Σ (b) I will. Space analysis: Each recursive level"
296	uses space 4 + (to record >). Recursion depth is log @ = 4 : = 4(+). Total space used is 4(+,). 9 Check-in 17.3
297	"Quick review of today 1. Space complexity 2. SPACE ! "" , NSPACE ! "" 3. PSPACE, NPSPACE 4. Relationship with TIME classes 5. $%&' ∈ PSPACE 6. )*++,-DFA ∈ NSPACE("") 7. )*++,-DFA ∈ SPACE(""3) 10"
298	MIT OpenCourseWare https://ocw.mit.edu 18.404J / 18.4041J / 6.840J Theory of Computation Fall 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
299	18.404/6.840 Lecture 8 Last time: - Decision procedures for automata and grammars !DFA , !NFA , &DFA , &'DFA , !CFG , &CFG are decidable !TM is T-recognizable Today: (Sipser §4.2) - !TM is undecidable - The diagonalization method - !TM is T-unrecognizable - The reducibility method - Other undecidable languages 1
300	Recall: Acceptance Problem for TMs Let !TM = { &, ( | & is a TM and & accepts (} Today’s Theorem: !TM is not decidable Proof uses the diagonalization method, so we will introduce that first. 2
301	"& ≠ ( → # & ≠ # ( Range (#) = "" “surjective” The Size of Infinity How to compare the relative sizes of infinite sets? Cantor (~1890s) had the following idea. Defn: Say that set ! and "" have the same size if there is a one-to-one and onto function #: ! → "" We call such an # a 1-1 correspondence “injective” Informally, two sets have the same size if we can pair up their members. This definition works for finite sets. Apply it to infinite sets too. #: © Source unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/fairuse. 3"
302	"- - - 1 0 2 1 3 1 4 2 5 2 6 3 7 3 ⋮ ⋮ 1 1/1 2 2/1 3 1/2 4 3/1 5 3/2 6 2/3 7 1/3 ⋮ ⋮ Countable Sets Let ℕ = {1,2,3, … } and let ℤ = {… , −2, −1,0,1,2, … } Defn: A set is countable if it is finite or it has the same size as ℕ. Both ℤ and ℚ"" are countable. 4 ℚ"" 1 2 3 4 … 1 1/1 1/2 1/3 1/4 2 2/1 2/2 2/3 2/4 … 3 3/1 3/2 3/3 3/4 4 4/1 4/2 4/3 4/4 ⋮ ⋮ Show ℕand ℤhave the same size Let ℚ"" = 1⁄2 3, 4 ∈ℕ} Show ℕand ℚ"" have the same size 4 6(4) 1 0 2 -1 3 1 4 -2 5 2 6 -3 7 3 ⋮ ⋮ ℕ ℤ 4 6(4) 1 1/1 2 2/1 3 1/2 4 3/1 5 3/2 6 2/3 7 1/3 ⋮ ⋮ ℕ ℚ"""
303	2.718281828… 3.141592653… 0.000000000… 1.414213562… 0.142857242… 0.207879576… 1.234567890… ⋮ 7 4 0 2 5 9 8 7≠4 ≠0 ≠ ≠5 ≠9 ≠8 ℝ is Uncountable – Diagonalization Let ℝ= all real numbers (expressible by infinite decimal expansion) Theorem: ℝ is uncountable Proof by contradiction via diagonalization: Assume ℝ is countable So there is a 1-1 correspondence #: ℕ → ℝ Demonstrate a number + ∈ℝ that is missing from the list. + = 0.8516182… ≠ 2 differs from the ' th number in the ' th digit so cannot be the ' th number for any '. Hence + is not paired with any '. It is missing from the list. Therefore # is not a 1-1 correspondence. 5 ' #(') 1 7 2.718281828… 2 4 3.141592653… 3 0 0.000000000… 4 2 1.414213562… 5 6 7 ⋮ ⋮ 0.142857242… 5 0.207879576… 9 1.234567890… 8 Diagonalization
304	Σ∗ { ', 0, 1, 00, 01, 10, 11, 000, … 0 ∈ℒ { 0, 00, 01, … 4 0 .0 1 0 1 1 0 0 0 … ℝ is Uncountable – Corollaries Let ℒ= all languages Corollary 1: ℒ is uncountable Proof: There’s a 1-1 correspondence from ℒ to ℝ so they are the same size. Observation: Σ∗ = {', 0,1,00,01,10,11,000, … } is countable. Let ℳ= all Turing machines Observation: ℳ is countable. Because . . is a TM} ⊆ Σ∗ . Corollary 2: Some language is not decidable. Because there are more languages than TMs. We will show some specific language 0TM is not decidable. Check-in 8.1 Hilbert’s 1st question asked if there is a set of intermediate size between ℕ and ℝ. Gödel and Cohen showed that we cannot answer this question by using the standard axioms of mathematics. How can we interpret their conclusion? (a) We need better axioms to describe reality. (b) Infinite sets have no mathematical reality so Hilbert’s 1st question has no answer. Check-in 8.1 6
305	acc rej acc acc . . . rej rej rej rej acc acc acc acc . . . rej rej acc acc ⋮ rej acc rej rej ? !TM is undecidable Recall !TM = { &, ( | & is a TM and & accepts (} Theorem: !TM is not decidable Proof by contradiction: Assume some TM + decides !TM. Accept if & accepts ( So + on &, ( = , Why is this proof a diagonalization? Reject if not Use + to construct TM - - = “On input 〈&〉 1. Simulate + on input 〈&, & 〉 2. Accept if + rejects. Reject if + accepts.” - accepts 〈&〉 iff & doesn’t accept & . - accepts 〈-〉 iff - doesn’t accept - . Contradiction. 7 〈&0〉〈&1〉〈&2〉〈&3〉 . . . 〈-〉 &0 ac acc rej acc acc . . . &1 rej re rej rej rej &2 acc acc ac acc acc . . . &3 rej rej acc ac acc ⋮ ⋮ - rej acc rej rej ? All TM descriptions: All TMs
306	Check-in 8.2 Recall the Queue Automaton (QA) defined in Pset 2. It is similar to a PDA except that it is deterministic and it has a queue instead of a stack. Let !QA = { &, ( | & is a QA and & accepts (} Is !QA decidable? (a) Yes, because QA are similar to PDA and !PDA is decidable. (b) No, because “yes” would contradict results we now know. (c) We don’t have enough information to answer this question. 8 Check-in 8.2
307	- = decidable T-recognizable Complement of T recognizable co-T-recognizable !TM !TM !TM is T-unrecognizable Theorem: If ! and ! are T-recognizable then ! is decidable Proof: Let TM $% and $& recognize ! and !. Construct TM ' deciding !. ' = “On input ) 1. Run $% and $& on ) in parallel until one accepts. 2. If $% accepts then accept. If $& accepts then reject.” Corollary: !TM is T-unrecognizable Proof: !TM is T-recognizable but also undecidable Check-in 8.3 From what we’ve learned, which closure properties can we prove for the class of T-recognizable languages? Choose all that apply. (a) Closed under union. (b) Closed under intersection. (c) Closed under complement. (d) Closed under concatenation. (e) Closed under star. Check-in 8.3 9
308	The Reducibility Method Use our knowledge that !TM is undecidable to show other problems are undecidable. Defn: $!%&TM = (, * ( halts on input *} Theorem: $!%&TM is undecidable Proof by contradiction, showing that !TM is reducible to $!%&TM: Assume that $!%&TM is decidable and show that !TM is decidable (false!). Let TM , decide $!%&TM. Construct TM - deciding !TM. - = “On input (, * 1. Use , to test if ( on * halts. If not, reject. 2. Simulate ( on * until it halts (as guaranteed by ,). 3. If ( has accepted then accept. If ( has rejected then reject. TM - decides !TM, a contradiction. Therefore $!%&TM is undecidable. 10
309	Quick review of today 1. Showed that ℕ and ℝ are not the same size to introduce the Diagonalization Method. 2. #TM is undecidable. 3. If # and # are T-recognizable then # is decidable. 4. #TM is T-unrecognizable. 5. Introduced the Reducibility Method to show that &#'(TM is undecidable. 11
310	MIT OpenCourseWare https://ocw.mit.edu 18.404J / 18.4041J / 6.840J Theory of Computation Fall 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
311	18.404/6.840 Lecture 3 Last time: - Nondeterminism - NFA → DFA - Closure under ∘ and ∗ - Regular expressions → finite automata Today: (Sipser §1.4 – §2.1) - Finite automata → regular expressions - Proving languages aren’t regular - Context free grammars We start counting Check-ins today. Review your email from Canvas. Homework due Thursday. 1
312	"DFAs → Regular Expressions Recall Theorem: If "" is a regular expressipn and # = % "" then # is regular Proof: Conversion "" → NFA & → DFA &′ & Regular Finite expression "" automaton Recall: we did a ∪ ab ∗ as an example Today’s Theorem: If # is regular then # = % "" for some regular expr "" Proof: Give conversion DFA & → "" WAIT! Need new concept first. 2"
313	Generalized NFA Defn: A Generalized Nondeterministic Finite Automaton (GNFA) is similar to an NFA, but allows regular expressions as transition labels a a ∗ b ∗ ab !1 #1 #2 For convenience we will assume: b ε - One accept state, separate from the start state ∅ - One arrow from each state to each state, except a ∪ b aab a) only exiting the start state #3 #4 b) only entering the accept state ε We can easily modify a GNFA to have this special form. 3
314	"GNFA → Regular Expressions Lemma: Every GNFA ! has an equivalent regular expression "" Proof: By induction on the number of states # of ! Basis (# = 2): ( ! = Remember: ! is in special form Let "" = ( GNFA GNFA # states # −1 states 4 -state GNFA Induction step (# > 2): Assume Lemma true for # − 1 states and prove for # states IDEA: Convert #-state GNFA to equivalent # − 1"
315	! −1 states ! states $ $ %& %' %& %' () (* (+ (, () (* ∗(+ ∪(, !-state GNFA → (!—1)-state GNFA Check-in 3.1 We just showed how to convert GNFAs to regular expressions but our goal was to show that how to convert DFAs to regular expressions. How do we finish our goal? (a) Show how to convert DFAs to GNFAs (b) Show how to convert GNFAs to DFAs (c) We are already done. DFAs are a type of GNFAs. Thus DFAs and regular expressions are equivalent. 1. Pick any state $ except the start and accept states. 2. Remove $. 3. Repair the damage by recovering all paths that went through $. 4. Make the indicated change for each pair of states %&, %' . Check-in 3.1 5
316	0101 ∉* 0110 Sometimes intuition works, but it can also be wrong. ] ] Non-Regular Languages How do we show a language is not regular? - Remember, to show a language is regular, we give a DFA. - To show a language is not regular, we must give a proof. - It is not enough to say that you couldn’t find a DFA for it, therefore the language isn’t regular. Two examples: Here Σ = {0,1}. 1. Let ( = ) ) has equal numbers of 0s and 1s} Intuition: ( is not regular because DFAs cannot count unboundedly. Intuition: * is not regular because DFAs cannot count unboundedly. However * is regular! 2. ∈* ] ] ) ) ] Let * = has equal numbers of 01 and 10 substrings} Moral: You need to give a proof. 6
317	"is regular → every long s is also tring in ! can be pumped and the result stays in !. be the number of states in 0. Pick # ∈! where # ≥"". ' ( ) 0 12 # The path that 0 foll when reading #. accepted Method for Proving Non-regularity Pumping Lemma: For every regular language !, there is a number "" (the “pumping length”) such that if # ∈! and # ≥ "" then # = '() where 1) '(*) ∈ ! for all + ≥0 (* = (( ⋯( 2) ( ≠ ε '( ≤ "" 3) + } Informally: ! Proof: Let DFA 0 recognize !. Let "" ' ( ) # = 12 12 0 will repeat a state 12 when reading because # is so long. ' ( ( ) 12 12 12 Check-in 3.2 The Pumping Lemma depends on the fact that if 0 has "" states and it runs for more than "" steps then 0 will enter some state at least twice. We call that fact: (a) The Pigeonhole Principle"
318	(b) Burnside's Counting Theorem (c) The Coronavirus Calculation Check-in 3.2 7
319	Example 1 of Proving Non-regularity Pumping Lemma: For every regular language 1, there is a ) such that if * ∈ 1 and * ≥ ) then * = -./ where 1) -.2/ ∈ 1 for all 3 ≥ 0 .2 = .. ⋯ . 2) . ≠ ε 3) -. ≤ ) 0$1$ Let ! = & ≥ 0} Show: ! is not regular Proof by Contradiction: Assume (to get a contradiction) that ! is regular. The pumping lemma gives ) as above. Let * = 0+1+ ∈ !. Pumping lemma says that can divide * = -./ satisfying the 3 conditions. But -../ has excess 0s and thus -../ ∉ ! contradicting the pumping lemma. Therefore our assumption (! is regular) is false. We conclude that ! is not regular. 8 * = 000 ⋯ 000111 ⋯ 111 / . ≤ ) -
320	"But that 2 can be pumped and stay inside &. Bad choice. Example 2 of Proving Non-regularity Pumping Lemma: For every regular language 6, there is a "" such that if 2 ∈6 and 2 ≥ "" then 2 = $%# where 1) $%8# ∈ 6 for all 9 ≥0 %8 = %% ⋯% 2) % ≠ ε 3) $% ≤ "" Let & = (( ( ∈Σ∗} . Say Σ∗ = {0,1}. Show: & is not regular 2 = 000 ⋯ 000000 ⋯ 000 ≤"" $ % # Proof by Contradiction: % = 00 Assume (for contradiction) that & is regular. The pumping lemma gives "" as above. Need to choose 2 ∈&. Which 2? 2 = 000 ⋯ 001000 ⋯ 001 Try 2 = 0303 ∈&. # ≤ "" $ % Try 2 = 031031 ∈ &. Show cannot be pumped 2 = $%# satisfying the 3 conditions. $%%# ∉ & Contradiction! Therefore & is not regular. 9"
321	Example 3 of Proving Non-regularity Variant: Combine closure properties with the Pumping Lemma. Let ! = # # has equal numbers of 0s and 1s} Show: ! is not regular Proof by Contradiction: Assume (for contradiction) that ! is regular. We know that 0∗1∗ is regular so ! ∩ 0∗1∗ is regular (closure under intersection). But ) = ! ∩0∗1∗ and we already showed ) is not regular. Contradiction! Therefore our assumption is false, so ! is not regular. 10
322	) / } 3 rules R,S 0,1 S Example of ') generating a string S 0 S 1 0 S 1 R ε S 0S1 00S11 00R11 0011 % ' = 0-1- ≥0 In '): Tree of substitutions Resulting string ∈% ') Context Free Grammars ') S → 0S1 S → R } (Substitution) Rules R →ε Rule: Variable → string of variables and terminals Variables: Symbols appearing on left-hand side of rule Terminals: Symbols appearing only on right-hand side Start Variable: Top left symbol Grammars generate strings 1. Write down start variable 2. Replace any variable according to a rule Repeat until only terminals remain 3. Result is the generated string 4. %(') is the language of all generated strings. 11 Check-in 3.3 (a) 001101 (b) 000111 (c) 1010 (d) ε '3 S → RR R → 0R1 R →ε Check all of the strings that are in %('3): Check-in 3.3
323	Quick review of today 1. Conversion of DFAs to regular expressions Summary: DFAs, NFAs, regular expressions are all equivalent 2. Proving languages not regular by using the pumping lemma and closure properties 3. Context Free Grammars 12
324	MIT OpenCourseWare https://ocw.mit.edu 18.404J / 18.4041J / 6.840J Theory of Computation Fall 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
325	18.404/6.840 Lecture 10 Last time: - The Reducibility Method for proving undecidability and T-unrecognizability - General reducibility - Mapping reducibility Today: (Sipser §5.2) - The Computation History Method for proving undecidability - The Post Correspondence Problem is undecidable - Linearly bounded automata - Undecidable problems about LBAs and CFGs 1
326	"Remember To prove some language ! is undecidable, show that "" TM (or any known undecidable language) is reducible to !. 2"
327	Revisit Hilbert’s 10th Problem Recall ! = 〈$〉 polynomial $ &', &), … , &+ = 0 has integer solution) Hilbert’s 10th problem (1900): Is ! decidable? Theorem (1971): No Proof: Show -TM is reducible to !. [would take entire semester] Do toy problem instead which has a similar proof method. Toy problem: The Post Correspondence Problem. Method: The Computation History Method. 3
328	a b a a b a a a a b a b a b a a b a a a a b a b Problem: Given !, is there a match? Theorem: Undecidable! Let !1! = ! ! has a match } Proof: Show 3TM is reducible to !1!. First: the Computation History Method. Post Correspondence Problem Given a collection of pairs of strings as dominoes: ! = #$ , #' , … , #) %$ %' %) a match is a finite sequence of dominos in ! (repeats allowed) where the concatenation of the *’s = the concatenation of the +’s. # #, #, , Match = $ ' … - where *.$*.' ⋯ *.- = +.$+.' ⋯ +.­ %,$ %, %, ' - ab baab ba abab Check-in 10.1 Example: ! = , , , aba aba aa b baab ba ab Let !6 = , , aaba ab ba Does !6 have a match? Match: • (a) Yes. (b) No. Check-in 10.1 4
329	"TM Configurations Defn: A configuration of a TM is a triple ("", $, %) where "" = the state, $ = the head position, % = tape contents representing a snapshot of the TM at a point in time. 6 ˽ ˽ … ""* a a a a a a b b b b b Configuration: (""*, 6, aaaaaabbbbb) %' %( Encoding as a string: aaaaa""*abbbbb Encode configuration ("", $, %) as the string %'""%( where % = %'%( and the head position is on the first symbol of %(. 5"
330	"TM Computation Histories Defn: An (accepting) computation history for TM ! on input "" is a sequence of configurations #$, #&, … , #accept that ! enters until it accepts. Encode a computation history #$, #&, … , #accept as the string #$ # #& # ⋯ # #accept where each configuration #/ is encoded as a string. A computation history for #$ # #& # #0 # ⋯ # #accept ! on "" = ""$""& ⋯""3. Here say 7 12, ""$ = (14, a, R) 12""$""& ⋯ ""3 # a14""& ⋯""3 # ac15""0 ⋯""3 # ⋯ # ⋯ 1accept ⋯ and 7 14, ""& = (15, c, :). 6"
331	Linearly Bounded Automata Defn: A linearly bounded automaton (LBA) is a 1-tape TM that cannot move its head off the input portion of the tape. LBA a a b a a b a Tape size adjusts to length of input. Let !LBA = &, ( LBA & accepts ( } Theorem: !LBA is decidable Proof: (idea) If & on ( runs for long, it must be cycling. Decider for !LBA: Claim: For inputs of length ), an LBA can have .A−LBA = “On input &, ( only * ×)× Γ - different configurations. 1. Let ) = |(|. Therefore, if an LBA runs for longer, it must repeat some 2. Run & on ( for * ×)× Γ - steps. configuration and thus will never halt. 3. If has accepted, accept. 4. If it has rejected or is still running, reject.” must be looping 7
332	No pe 4 0 additional ta is needed so is an LBA. &1,2 = “On input 3 1. Check if 3 begins 45# where 5 is start config of . on . 2. Check that each 4785 legally follows from 47 for each 9. 3. Check that final configuration is accepting. 4. Accept if all checks pass. Reject if any fail.” !LBA is undecidable Let !LBA = & & is an LBA and ' & = ∅ } Theorem: !LBA is undecidable Proof: Show )TM is reducible to !LBA. Uses the computation history method. Assume that TM , decides !LBA Construct TM - deciding )TM - = “on input ., 0 1. Construct LBA &1,2 which tests whether its input 3 is an accepting Check-in 10.2 computation history for . on 0, and only accepts 3 if it is. What do you think of the Computation 2. Use , to determine whether ' &1,2 = ∅. History Method? Check all that apply. 3. Accept if no. Reject if yes.” (a) Cool ! (b) Just another theorem. &1,2 :;050< ⋯0> #
333	a:?0< ⋯ 0> # ac:@0A ⋯ 0> # ⋯ # ⋯ :accept ⋯ (c) I’m baffled. (d) I wish I was in 6.046. 45 4< 4A ⋯ 4accept Check-in 10.2 8
334	"!""! is undecidable Recall !""! = ! ! has a match } Theorem: !""! is undecidable Proof: Show %TM is reducible to !""!. Uses the computation history method. () Technical assumption: Match must start with . Can fix this assumption. *) Assume that TM + decides !""! Construct TM , deciding %TM , = “on input -, / 1. Construct PCP instance !0,1 where a match corresponds to a computation history for - on /. 2. Use + to determine whether !0,1 has a match. 3. Accept if yes. Reject if no.” 9"
335	"and put : : in !"",$ and # # also # # ˽ ,accept ## # # 4B # # 4B 2 2 3 # 4 4F 2 3 # # 4accept # # # 4accept # # # ˽ # Constructing !"",$ Make !"",$ where a match is a computation history for % on &. # ' )( ( = #,-$(⋯$/# (starting domino) For each 0, 1 ∈ Γ and ( ( ( ( 4, 5 ∈6 where 7 4, 0 = (5, 1, R) Check-in 10.3 ,-: ( ( What else can we now conclude? put in !"",$ ;-< ( ( Choose all that apply. (Handles right moves. Similar for left moves.) (a) !G! is T-unrecognizable. Ending dominos to allow a match if % accepts: (b) !G! is T-unrecognizable. :(,accept ,accept :( ( (c) Neither of the above. ,accept ,accept ( Illustration: 2 2 3 # Match completed! & = 223 . . . . . . … one detail needed. 7 4B, 2 = (4F, 4, R) # ⋯ 4accept ⋯ # 10 Check-in 10.3"
336	"9 !""""CFG is undecidable Let !""""CFG = ' is a CFG and "" ' = Σ∗} ' Theorem: !""""CFG is undecidable Proof: Show !TM is reducible to !""""PDA via the computation history method. Assume TM R decides !""""PDA and construct TM 0 deciding !TM. 0 = “On input 1, 3 1. Construct PDA 45,6 which tests whether its input 7 is an accepting computation history for M on w, and only accepts 7 if it is NOT. 2. Use 8 to determine whether "" = Σ∗. 45,6 3. Accept if no. Reject if yes.” Nondeterministically push some 9: and pop to compare with 9:;<. 45,6 operation: Accept if invalid step of M, or if start wrong, or if end isn’t accepting. # a>C3@ ⋯ 3= # # # 45,6 3= >?3<3@ ⋯ 3= @ 9@ ℛ ac>D3E ⋯ 3= ⋯ ⋯ >accept ⋯ 3 ⋮ @ 9< 9E ⋯ 9accept 3< Reverse even-numbered 9: to allow comparing with 9:;< via stack. >? 11"
337	"Computation History Method - recap Computation History Method is useful for showing the undecidability of problems involving testing for the existence of some object. ! Is there an integral solution (to the polynomial equation)? ""LBA Is there some accepted string (for the LBA)? &'& Is there a match (for the given dominos)? ())CFG Is there some rejected string (for the CFG)? In each case, the object is the computation history in some form. 12"
338	Quick review of today 1. Defined configurations and computation histories. 2. Gave The Computation History Method to prove undecidability. 3. !LBA is decidable. 4. %LBA is undecidable. 5. &'& is undecidable. 6. !((CFG is undecidable. 13
339	"̿ - - - Eliminating the technical assumption !"" Technical assumption: Match must start with # . "" Fix this assumption as follows. Let $ = !"" , !' , … , !) where we require match to start with # !"" . #"" #' #) "" !"" !"" !' !) Create new $′ = , , , … , , . . . #"" #"" #' #) For any string / = /0, … , /1, let ⋆/ = ∗/0 ∗/4 ∗⋯∗/1 / ⋆ = /0 ∗/4 ∗⋯∗/1 ∗ ⋆/ ⋆ = ∗/0 ∗/4 ∗⋯∗/1 ∗ ⋆!"" ⋆!"" ⋆!' ⋆!) ∗$ Then let $6 = ⋆#""⋆, #""⋆, #'⋆, … , #)⋆, $8 14"
340	MIT OpenCourseWare https://ocw.mit.edu 18.404J / 18.4041J / 6.840J Theory of Computation Fall 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
341	                                 
342	"         ! ""  #$% %&    '(  )    ""*% +#!& ## +  #  *    % &$  ,$& $#"" (+ # + !%  * - ./ #!  *%+ #+ $ !""        "
343	 0 &% &!  #$+# & !# (++ % &$  ( 1+12  1 3 #4 1 2  1  5  %+   #$(&   6  #& 7#+ $#   ! +  #& *8* #* *        (  %   9  3 #8+ * !  #  #:# !* #   +*  #   $  %  &!  ' len(observed)−1 ∑ (observed[i]−predicted[i])2 i=0    ;
344	 , < - ( 1* !!+  4  %'( 5  = & + #    *   #& + +&     !2   3 #+&  #  (% &&     9  >    % #   $  %  &!  ' len(observed)−1 ∑ (observed[i]−predicted[i])2 i=0    ?
345	" % (   ) ""  # &    ' • + %  #%  %*   1%# • .(  +#   #!   (+  +# & + %A#$&+ #$ • , $(*   +#! ""B  C! $*  #B%/C •   (  %   • (  9 (        @"
346	*)   &!  '    
347	 % pylab.polyfit   + %'(* +# %   - . #4  ( D 5!& +!  #%#% &*E  % pylab.polyval (    #*E( &  + (  $   model1 = pylab.polyfit(xVals, yVals, 1) pylab.plot(xVals, pylab.polyval(model1, xVals), 'r--', label = ’Linear Model')    F
348	(  $      G
349	$+ , - ).    model2 = pylab.polyfit(xVals, yVals, 2) pylab.plot(xVals, pylab.polyval(model2, xVals), 'r--', label = 'Quadratic Model')    H 2) l2
350	"/  0 *   "" 12 (     "
351	  +  *'( (   *  I - J ( & %/ I  K     I - .%#+  + $4(! $#  (   +5! 4#:# +  $5 ( & # +$(+ - . # !  (  &  B%/ C   3   ) (  4        $ E %  *    L   &  6    #&  μ + & 
352	 3   ) (  4    
353	" "" ""     *(8   A    I -   !""8 *%   #I  K    #(  - (!  $+ $#     (  K ""  #$%  1+1 - (!  # #+ ( + #     - (!  #3#+ $ - (!  # #+#$  >( %+ ( 3), 3 1       ;"
354	" A# *+ $#   M #+  + ( & $4(K*N 5  6 $+# +++%  J (+1% ( # 0# 0  ,,   5 6  ""     ? Images of particle trajectory, load-bearing arch, football pass center of mass diagram © sources unknown. All rights reserved. This content is excluded from out Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/."
355	-7 ,,   3     def genNoisyParabolicData(a, b, c, xVals, fName): yVals = [] for x in xVals: theoreticalVal = a*x**2 + b*x + c yVals.append(theoreticalVal + random.gauss(0, 35)) f = open(fName,'w') f.write('x y\\n') for i in range(len(yVals)): f.write(str(yVals[i]) + ' ' + str(xVals[i]) + '\\n') f.close() #parameters for generating data xVals = range(-10, 11, 1) a, b, c = 3, 0, 0 genNoisyParabolicData(a, b, c, xVals, ’Mystery Data.txt')    @ .+ ( %*2  $#! *     * B%CI x + c + random.gauss(0, 35))
356	$+ $8  7     degrees = (2, 4, 8, 16) random.seed(0) xVals1, yVals1 = getData('Dataset 1.txt') models1 = genFits(xVals1, yVals1, degrees) testFits(models1, degrees, xVals1, yVals1, 'DataSet 1.txt') pylab.figure() xVals2, yVals2 = getData('Dataset 2.txt') models2 = genFits(xVals2, yVals2, degrees) testFits(models2, degrees, xVals2, yVals2, 'DataSet 2.txt')     g genFits( models1 testFits( ' g genFits( models2 testFits(
357	(      9    F
358	(      :    G
359	" BOC'( $   * + % !  ""  (   (   * I     (#+    (   - K   + +   #     - ,   (  # *# $+ ( !         ""  ( %*  # -  +    ( ( - 6 $+#   3 + # - E   &*  .   !(  9 -   9;   ) (     H"
360	 0   (!   - + J   # + J - + J  # + J   #$(  % (    (    >%/   #$+(  9%  *   (     <        
361	   pylab.figure() testFits(models1, degrees, xVals2, yVals2, 'DataSet 2/Model 1') pylab.figure() testFits(models2, degrees, xVals1, yVals1, 'DataSet 1/Model 2')      s1, S s2, s2, s2, s1, s1,
362	      9      :    
363	      :      9    ;
364	" P #%  % !%    ""*%   ?  * 4  ""   # *  ! 3 #  &   /*5!% #  *     +& '(   + *   (!  *# #Q%    ( !$(#   %  <   0     ?"
365	    0      @
366	 * (B%/ C   (   (   !%   (  I     #   +*   (   (I -  (     (I  .+    !#:#   *%9   O  +  *!#     * (/   - *B%/ C & !%  *B%/ C     )   ,    
367	( = /  0  6  $      F xVals = (0,1,2,3) yVals = xVals pylab.plot(xVals, yVals, label = 'Actual values') a,b,c = pylab.polyfit(xVals, yVals, 2) print('a =', round(a, 4), 'b =', round(b, 4), 'c =', round(c, 4)) estYVals = pylab.polyval((a,b,c), xVals) pylab.plot(xVals, estYVals, 'r--', label ='Predictive values') print('R-squared = ', rSquared(yVals, estYVals)) *DR%R# *DR R *D 12  D  xVals = (0,1,2,3) yVals = xVals pylab.plot(xVals, yVals, label = 'Actual values') py p , y , a,b,c = pylab.polyfit(xVals, yVals, 2) print('a =', round(a, 4), 'b =', round(b, 4), 'c =', round(c, 4)) a b c pylab polyfit(xVals yVals 2) estYVals = pylab.polyval((a,b,c), xVals) pylab.plot(xVals, estYVals, 'r--', label ='Predictive values') i ( print(' d ' 'R-squared = ', S d rSquared( Vals yV , estYVals)) estYVals pylab polyval((a b c) xVals) , ( , ))
368	6  *) 6          G xVals = xVals + (20,) yVals = xVals pylab.plot(xVals, yVals, label = 'Actual values') estYVals = pylab.polyval((a,b,c), xVals) pylab.plot(xVals, estYVals, 'r--', label = 'Predictive values') print('R-squared = ', rSquared(yVals, estYVals)) (20,) 12  D 
369	             H xVals = (0,1,2,3) yVals = (0,1,2,3.1) pylab.plot(xVals, yVals, label = 'Actual values') model = pylab.polyfit(xVals, yVals, 2) print(model) estYVals = pylab.polyval(model, xVals) pylab.plot(xVals, estYVals, 'r--', label = 'Predicted values') print('R-squared = ', rSquared(yVals, estYVals)) 12  DHHH? *DR%R# *D@RH@@R@ ,3) ,3.1) als yV
370	6  *) 6          ; xVals = xVals + (20,) yVals = xVals estYVals = pylab.polyval(model, xVals) print('R-squared = ', rSquared(yVals, estYVals)) pylab.figure() pylab.plot(xVals, estYVals) 12  DF (20,)
371	 D*%*4E!*E! 5  3 -   ( .  (     ;  12  DHHGG
372	 6  #$&%  *+    #%/  #      >     >     ; J( *  J(  * 
373	"  (& *1#& '(    (  .#  ""+  "" *  #     (  S # (  :# *#   % - >      % #*  % # - B& * ( %  %!%    C8>%    )  8 -      ;;"
374	 .%#+ *  #$(  +!# ((  # # - =       ( -   #  &  - .#   +  - $  $%( #  1    (  7 )   ,    ;?
375	"!    3) 3       ;@ T  $#$(  O  % K""  % &  *  (!  (    $ #$#  +  ( ,  %%* 3  3 (+ O &   9 # #8%#% ""    ! #%  (& ( "
376	" # 1& $  ( # #+ # *  .+! &11 # & $  .+ ( (! ""1+# & $  1 1 (& $  3 + - #   ) ,    ;"
377	"$ #..   <   0  Let D be the original data set testResults = [] for i in range(len(D)): training = D[:].pop(i) model = buildModel(training) testResults.append(test(model, D[i])) Average testResults  ""1+& *    >   & ( + J $$ ""2  9   ""1 !   (    ;F"
378	!  !     Let D be the original data set n be the number of random samples usually n between 20% and 50% k be number of trials testResults = [] for i in range(k) randomly select n elements for testSet, keep rest for training model = buildModel(training) testResults.append(test(model, testSet)) Average testResults     ;G
379	" ""<   * (     ,& +  H   ( @  0+ #*   * &  +$ - = #   *%  -  ++ -  + - #  12      12  + #   * *      1, ?     ;H"
380	* 1     class tempDatum(object): def __init__(self, s): info = s.split(',') self.high = float(info[1]) self.year = int(info[2][0:4]) def getHigh(self): return self.high def getYear(self): return self.year    ?
381	!     def getTempData(): inFile = open('temperatures.csv') data = [] for l in inFile: data.append(tempDatum(l)) return data    ? 
382	    def getYearlyMeans(data): years = {} for d in data: try: years[d.getYear()].append(d.getHigh()) except: years[d.getYear()] = [d.getHigh()] for y in years: years[y] = sum(years[y])/len(years[y]) return years    ?
383	  6    data = getTempData() years = getYearlyMeans(data) xVals, yVals = [], [] for e in years: xVals.append(e) yVals.append(years[e]) pylab.plot(xVals, yVals) pylab.xlabel('Year') pylab.ylabel('Mean Daily High (C)') pylab.title('Select U.S. Cities')    ?;
384	) 3)        ??
385	 0  @ )   numSubsets = 10 dimensions = (1, 2, 3, 4) rSquares = {} for d in dimensions: rSquares[d] = []    ?@
386	     def splitData(xVals, yVals): toTrain = random.sample(range(len(xVals)), len(xVals)//2) trainX, trainY, testX, testY = [],[],[],[] for i in range(len(xVals)): if i in toTrain: trainX.append(xVals[i]) trainY.append(yVals[i]) else: testX.append(xVals[i]) testY.append(yVals[i]) return trainX, trainY, testX, testY    ?
387	    !  for f in range(numSubsets): trainX,trainY,testX,testY = splitData(xVals, yVals) for d in dimensions: model = pylab.polyfit(trainX, trainY, d) #estYVals = pylab.polyval(model, trainX) estYVals = pylab.polyval(model, testX) rSquares[d].append(rSquared(testY, estYVals)) print('Mean R-squares for test data') for d in dimensions: mean = round(sum(rSquares[d])/len(rSquares[d]), 4) sd = round(numpy.std(rSquares[d]), 4) print('For dimensionality', d, 'mean =', mean, 'Std =', sd)    ?F
388	  %   - K (& ( 12   - ,& $#   - ,  !   Mean R-squares for test data For dimensionality 1 mean = 0.7535 Std = 0.0656 For dimensionality 2 mean = 0.7291 Std = 0.0744 For dimensionality 3 mean = 0.7039 Std = 0.0684 For dimensionality 4 mean = 0.7169 Std = 0.0777    ?G
389	 P& $ #   +(     - , ((    (( !& $   ( ( # %$#% (+ & $#    ,  A    - K   & + # +   - UFGG @?@ !G;FH?@@F! FH;F ;F@FF?@!FG?;;GG@F?; H! F ?G@; ?!@FGGH;@F;@F?G! F @?G@@GH;!F?;@GFF ?H;! FH; ?@@;F@ ?G@F!FFH;G@G;HH?F V - .+ *  !(   !  (& # 3 ##   % &  *+   3), 7 )     0      ?H @!FG?;;GG@F?; H! ?!@FGGH;@F;@F?G! ;! F?;@GFF ?H;!
390	" #    (  # & -  (+  & &   # & +#%    #& #   &  &N4 +5  12   &  - K (  *B%/ C%# + ""+& '(  # *+% -  *%  # + - & $ - ,  # * 3    # ( =     @"
391	MIT OpenCourseWare https://ocw.mit.edu 6.0002 Introduction to Computational Thinking and Data Science Fall 2016 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
392	Lecture 6: Monte Carlo Simulation 6.0002 LECTURE 6 1
393	Relevant Reading Sections 15-1 ̄ 15.4 • Chapter 16 6.0002 LECTURE 6 2
394	A Little History Ulam, recovering from an illness, was playing a lot of solitaire Tried to figure out probability of winning, and failed Thought about playing lots of hands and counting number of wins, but decided it would take years Asked Von Neumann if he could build a program to simulate many hands on ENIAC 6.0002 LECTURE 6 3 Image of ENIAC programmers © unknown.This content is excluded from our Creative Commons license. For more information,see https://ocw.mit.edu/help/faq-fair-use/.
395	Monte Carlo Simulation A method of estimating the value of an unknown quantity using the principles of inferential statistics Inferential statistics ◦ Population: a set of examples ◦ Sample: a proper subset of a population ◦ Key fact: a random sample tends to exhibit the same properties as the population from which it is drawn Exactly what we did with random walks 6.0002 LECTURE 6 4
396	An Example Given a single coin, estimate fraction of heads you would get if you flipped the coin an infinite number of times Consider one flip How confident would you be about answering 1.0? 6.0002 LECTURE 6 5
397	Flipping a Coin Twice Do you think that the next flip will come up heads? 6.0002 LECTURE 6 6
398	Flipping a Coin 100 Times Now do you think that the next flip will come up heads? 6.0002 LECTURE 6 7
399	Flipping a Coin 100 Times Do you think that the probability of the next flip coming up heads is 52/100? Given the data, ϭ̪ϫ̠ ̜͗̍ͅ best estimate But confidence 6.0002 LECTURE 6 should be low 8
400	Why the Difference in Confidence? Confidence in our estimate depends upon two things Size of sample (e.g., 100 versus 2) Variance of sample (e.g., all heads versus 52 heads) As the variance grows, we need larger samples to have the same degree of confidence 6.0002 LECTURE 6 9
401	Roulette No need to simulate, since answers obvious Allows us to compare simulation results to actual probabilities 6.0002 LECTURE 6 10 Image of roulette wheel © unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.
402	Class Definition class FairRoulette(): def __init__(self): self.pockets = [] for i in range(1,37): self.pockets.append(i) self.ball = None self.pocketOdds = len(self.pockets) - 1 def spin(self): self.ball = random.choice(self.pockets) def betPocket(self, pocket, amt): if str(pocket) == str(self.ball): return amt*self.pocketOdds else: return -amt def __str__(self): return 'Fair Roulette' 6.0002 LECTURE 6 11
403	Monte Carlo Simulation def playRoulette(game, numSpins, pocket, bet): totPocket = 0 for i in range(numSpins): game.spin() totPocket += game.betPocket(pocket, bet) if toPrint: print(numSpins, 'spins of', game) print('Expected return betting', pocket, '=',\\ str(100*totPocket/numSpins) + '%\\n') return (totPocket/numSpins) game = FairRoulette() for numSpins in (100, 1000000): for i in range(3): playRoulette(game, numSpins, 2, 1, True) 6.0002 LECTURE 6 12
404	100 and 1M Spins of the Wheel 100 spins of Fair Roulette Expected return betting 2 = -100.0% 100 spins of Fair Roulette Expected return betting 2 = 44.0% 100 spins of Fair Roulette Expected return betting 2 = -28.0% 1000000 spins of Fair Roulette Expected return betting 2 = -0.046% 1000000 spins of Fair Roulette Expected return betting 2 = 0.602% 1000000 spins of Fair Roulette Expected return betting 2 = 0.7964% 6.0002 LECTURE 6 13
405	Law of Large Numbers In repeated independent tests with the same actual probability p of a particular outcome in each test, the chance that the fraction of times that outcome occurs differs from p converges to zero as the number of trials goes to infinity Does this imply that if deviations from expected behavior occur, these deviations are likely to be evened out by opposite deviations in the future? 6.0002 LECTURE 6 14
406	Gambler’s Fallacy ϮŎ August 18, 1913, at the casino in Monte Carlo, black came up a record twenty-six times in succession ̐ϭ̆ ̜̍ͅϿή̪̪ή̑Ϩ ϩ ̐ϴϪή̜ή̑ ͑Β̠ Β ̆ήΒ̜-panicky rush to bet on red, beginning about the time black had come up a phenomenal fifteen ̪ϭ̅ή̠Ϩϯ -- Huff and Geis, How to Take a Chance Probability of 26 consecutive reds • 1/67,108,865 Probability of 26 consecutive reds when previous 25 rolls were red • 1/2 6.0002 LECTURE 6 15
407	Regression to the Mean Following an extreme random event, the next random event is likely to be less extreme If you spin a fair roulette wheel 10 times and get 100% reds, that is an extreme event (probability = 1/1024) It is likely that in the next 10 spins, you will get fewer than 10 reds ◦ But the expected number is only 5 So, if you look at the average of the 20 spins, it will be closer to the expected mean of 50% reds than to the 100% of the first 10 spins 6.0002 LECTURE 6 16
408	Casinos Not in the Business of Being Fair 6.0002 LECTURE 6 17
409	Two Subclasses of Roulette class EuRoulette(FairRoulette): def __init__(self): FairRoulette.__init__(self) self.pockets.append('0') def __str__(self): return 'European Roulette' class AmRoulette(EuRoulette): def __init__(self): EuRoulette.__init__(self) self.pockets.append('00') def __str__(self): return 'American Roulette' 6.0002 LECTURE 6 18
410	Comparing the Games Simulate 20 trials of 1000 spins each Exp. return for Fair Roulette = 6.56% Exp. return for European Roulette = -2.26% Exp. return for American Roulette = -8.92% Simulate 20 trials of 10000 spins each Exp. return for Fair Roulette = -1.234% Exp. return for European Roulette = -4.168% Exp. return for American Roulette = -5.752% Simulate 20 trials of 100000 spins each Exp. return for Fair Roulette = 0.8144% Exp. return for European Roulette = -2.6506% Exp. return for American Roulette = -5.113% Simulate 20 trials of 1000000 spins each Exp. return for Fair Roulette = -0.0723% Exp. return for European Roulette = -2.7329% 6.0002 LECTURE 6 Exp. return for American Roulette = -5.212% 19
411	Sampling Space of Possible Outcomes Never possible to guarantee perfect accuracy through sampling Not to say that an estimate is not precisely correct Key question: ◦ How many samples do we need to look at before we can have justified confidence on our answer? Depends upon variability in underlying distribution 6.0002 LECTURE 6 20
412	Standard deviation simply the square root of the variance Outliers can have a big effect Standard deviation should always be considered relative to mean Quantifying Variation in Data 6.0002 LECTURE 6 1 (X)  (x )2 X xX 21
413	For Those Who Prefer Code def getMeanAndStd(X): mean = sum(X)/float(len(X)) tot = 0.0 for x in X: tot += (x - mean)**2 std = (tot/len(X))**0.5 return mean, std 6.0002 LECTURE 6 22
414	Confidence Levels and Intervals Instead of estimating an unknown parameter by a single value (e.g., the mean of a set of trials), a confidence interval provides a range that is likely to contain the unknown value and a confidence that the unknown value lays within that range ϮϴϪή ̜ῄ̪̜̆ ̍̆ Οή̪̪ϭ̆Ϡ Β ̙̍Πϼή̪ ϭͼϼ ̪ϭ̅ή̠ ϭ̆ E̜̙̍ͅήΒ̆ roulette is -3.3%. The margin of error is +/- 3.5% with a 95% level of confidenceϨϯ What does this mean? If I were to conduct an infinite number of trials of 10k bets each, ◦ My expected average return would be -3.3% ◦ My return would be between roughly -6.8% and +0.2% 95% of the time 6.0002 LECTURE 6 23
415	Empirical Rule Under some assumptions discussed later ◦ ~68% of data within one standard deviation of mean ◦ ~95% of data within 1.96 standard deviations of mean ◦ ~99.7% of data within 3 standard deviations of mean 6.0002 LECTURE 6 24
416	Applying Empirical Rule resultDict = {} games = (FairRoulette, EuRoulette, AmRoulette) for G in games: resultDict[G().__str__()] = [] for numSpins in (100, 1000, 10000): print('\\nSimulate betting a pocket for', numTrials, 'trials of', numSpins, 'spins each') for G in games: pocketReturns = findPocketReturn(G(), 20, numSpins, False) mean, std = getMeanAndStd(pocketReturns) resultDict[G().__str__()].append((numSpins, 100*mean, 100*std)) print('Exp. return for', G(), '=', str(round(100*mean, 3)) + '%,', '+/- ' + str(round(100*1.96*std, 3)) + '% with 95% confidence') 6.0002 LECTURE 6 25
417	Results Simulate betting a pocket for 20 trials of 1000 spins each Exp. return for Fair Roulette = 3.68%, +/- 27.189% with 95% confidence Exp. return for European Roulette = -5.5%, +/- 35.042% with 95% confidence Exp. return for American Roulette = -4.24%, +/- 26.494% with 95% confidence Simulate betting a pocket for 20 trials of 100000 spins each Exp. return for Fair Roulette = 0.125%, +/- 3.999% with 95% confidence Exp. return for European Roulette = -3.313%, +/- 3.515% with 95% confidence Exp. return for American Roulette = -5.594%, +/- 4.287% with 95% confidence Simulate betting a pocket for 20 trials of 1000000 spins each Exp. return for Fair Roulette = 0.012%, +/- 0.846% with 95% confidence Exp. return for European Roulette = -2.679%, +/- 0.948% with 95% confidence Exp. return for American Roulette = -5.176%, +/- 1.214% with 95% confidence 6.0002 LECTURE 6 26
418	Assumptions Underlying Empirical Rule The mean estimation error is zero The distribution of the errors in the estimates is normal 6.0002 LECTURE 6 27
419	Defining Distributions Use a probability distribution Captures notion of relative frequency with which a random variable takes on certain values ◦ Discrete random variables drawn from finite set of values ◦ Continuous random variables drawn from reals between two numbers (i.e., infinite set of values) For discrete variable, simply list the probability of each value, must add up to 1 C̪̍̆ϭ̠̆̍ͅͅ ΠΒ̠ή ̪̜ϭΠϼϭή̜ϥ ΠΒ̆ϫ̪ ῄ̆̅ή̜Β̪ή ̙̜̍ΟΒΟϭϿϭ̪͗ for each of an infinite set of values 6.0002 LECTURE 6 28
420	PDF’s Distributions defined by probability density functions (PDFs) Probability of a random variable lying between two values Defines a curve where the values on the x-axis lie between minimum and maximum value of the variable Area under curve between two points, is probability of example falling within that range 6.0002 LECTURE 6 29
421	Normal Distributions 6.0002 LECTURE 6 e  1 n! n0   ~68% of data within one standard deviation of mean ~95% of data within 1.96 standard deviations of mean ~99.7% of data within 3 standard deviations of mean 30
422	MIT OpenCourseWare https://ocw.mit.edu 6.0002 Introduction to Computational Thinking and Data Science Fall 2016 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
423	                            1
424	"   !"" # $ %! !""&' ( % !"" $ )  % %! ( % !""    % %""  )$$ !""###$ %      "
425	" %   #  %     # * +!)  ,%% # -%!)% "") %  % (  # .! %% %    ""%!)%   %        , # /"" ,     %  )  %+ !%)   %    0   +  &    '     &"
426	"        # ()  ""%  %+ ""    )     ) %% $     )%  1  )  !)    ()      !""###*+   2"
427	"/$  % $ !"" 3$    ,  - !) - %%4 (  ,    -    '"
428	"  ) ""%)    ""%  """"%+ Experimental devices that help us to understand something that has happened or to predict the future 5 6   % 3   %  % 3 )%   %         Images © sources unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use."
429	3  3'27%  $) 8 .'  .     /0 1    9
430	"  ) ""%)    ""%  """"%+ Experimental devices that help us to understand something that has happened or to predict the future    3   %  % 3 )%   %        : Images © sources unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use."
431	2         +  An objective function that is to be maximized or minimized, e.g., # Minimize time spent traveling from New York to Boston A set of constraints (possibly empty) that must be honored, e.g., # Cannot spend more than $100 # Must be in Boston before 5:00PM   ; Images © sources unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use.
432	3  -     Images © sources unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use.
433	"3  -  <)"" +%   ""1 ""    )  "",  ,"" !)  ! <))% %, ,  )$$"" !)  ! - !)"" """" )$$ ,  """" % +"" 4  +   # = ,  ,% # )) $  %,  ,%   Images © sources unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use."
434	/ 1 4 '  3  -     Images © sources unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use.
435	" ""    !  1     "",  ,     ""  % ""$ ""  /+11$%"" 1  "" $ + % %  ""% $""+     /+11$%"" 1 )    """"    ,*$ 1     , *$ 1     , #5* 3  - 6 7     &"
436	#5* 3  - 6 7     2
437	" )   %% %   $  ""    !1  %% )  $"" $  ""    %% ""    + %%$""   ""  %)   "" %% "" &( ""    ""  ! "" + %) ""%   8 7  &    '"
438	"-  4   %% # /+11$%"" 1 )    """"    ,*$ 1     ,*$ 1     , - ! % $$+ %)   "" +4 # /  ! $$ !)         ( %1$""   "" $ 1""   $ 64 # 191'11:1;12 12;19&1'1&9  9       "
439	"/% 1 = ,  ,%  ""%! % >) ?    & 2  8   +   9"
440	"while knapsack not full put “best” available item in knapsack >)""      4 # @ + %) % #   + # -"" + %)=) / &     &  '   :"
441	"<)  )     % <),"" )""!) + %) $$$ 11 !)%, )  ""  % >)!)"" +  % ) 11!) ?   )  "" 9'  %   "" ""     ,  ,% & :    ;"
442	"? %,   ""  )   ""    &                . %) :; ; & ' ; 9; ;   % & '2 ': &'2 &' ' ;' ;'"
443	  7 class Food(object): def __init__(self, n, v, w): self.name = n self.value = v self.calories = w def getValue(self): return self.value def getCost(self): return self.calories def density(self): return self.getValue()/self.getCost() def __str__(self): return self.name + ': <' + str(self.value)\\ + ', ' + str(self.calories) + '>'   
444	"8    7 def buildMenu(names, values, calories): """"""names, values, calories lists of same length. name a list of strings values and calories lists of numbers returns list of Foods"""""" menu = [] for i in range(len(values)): menu.append(Food(names[i], values[i], calories[i])) return menu   "
445	"    7:  / def greedy(items, maxCost, keyFunction): """"""Assumes items a list, maxCost >= 0, keyFunction maps elements of items to numbers"""""" itemsCopy = sorted(items, key = keyFunction, reverse = True) result = [] totalValue, totalCost = 0.0, 0.0 for i in range(len(itemsCopy)): if (totalCost+itemsCopy[i].getCost()) <= maxCost: result.append(itemsCopy[i]) totalCost += itemsCopy[i].getCost() totalValue += itemsCopy[i].getValue() return (result, totalValue)   &"
446	&   / def greedy(items, maxCost, keyFunction): itemsCopy = sorted(items, key = keyFunction, reverse = True) result = [] totalValue, totalCost = 0.0, 0.0 for i in range(len(itemsCopy)): if (totalCost+itemsCopy[i].getCost()) <= maxCost: result.append(itemsCopy[i]) totalCost += itemsCopy[i].getCost() totalValue += itemsCopy[i].getValue() return (result, totalValue)   2  
447	;  / def testGreedy(items, constraint, keyFunction): taken, val = greedy(items, constraint, keyFunction) print('Total value of items taken =', val) for item in taken: print(' ', item)   '
448	;  / def testGreedys(maxUnits): print('Use greedy by value to allocate', maxUnits, 'calories') testGreedy(foods, maxUnits, Food.getValue) print('\\nUse greedy by cost to allocate', maxUnits, 'calories') testGreedy(foods, maxUnits, lambda x: 1/Food.getCost(x)) print('\\nUse greedy by density to allocate', maxUnits, 'calories') testGreedy(foods, maxUnits, Food.density) testGreedys(800)    4
449	"%  )    ! ) $) # lambda A 1 1B C0A C # )  $)$ )   +!""  !1 ""   % 6 %  %    D?E) def       9"
450	;  / def testGreedys(foods, maxUnits): print('Use greedy by value to allocate', maxUnits, 'calories') testGreedy(foods, maxUnits, Food.getValue) print('\\nUse greedy by cost to allocate', maxUnits, 'calories') testGreedy(foods, maxUnits, lambda x: 1/Food.getCost(x)) print('\\nUse greedy by density to allocate', maxUnits, 'calories') testGreedy(foods, maxUnits, Food.density) names = ['wine', 'beer', 'pizza', 'burger', 'fries', 'cola', 'apple', 'donut', 'cake'] values = [89,90,95,100,90,79,50,10] calories = [123,154,258,354,365,150,95,195] foods = buildMenu(names, values, calories) testGreedys(foods, 750) )    :
451	"3F)$% %%!G %H""  ? % !  !%  % %%! % %) *  !!  ! % !  4 # ! I ! 7$ 1 8 2/  &)+   ;"
452	" ! %    )  %%!$$ >)   % ! !% ""  %) # D?+,"" ""   *""%)?%%%, $ )%! % %)      /   &"
453	MIT OpenCourseWare https://ocw.mit.edu 6.0002 Introduction to Computational Thinking and Data Science Fall 2016 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
454	Lecture 13: Classification 6.0002 LECTURE 13 1
455	Announcements Reading ◦ Chapter 24 ◦ Section 5.3.2 (list comprehension) Course evaluations ◦ Online evaluation now through noon on Friday, December 16 6.0002 LECTURE 13 2
456	Supervised Learning Regression ◦ Predict a real number associated with a feature vector ◦ E.g., use linear regression to fit a curve to data Classification ◦ Predict a discrete value (label) associated with a feature vector 6.0002 LECTURE 13 3
457	An Example (similar to earlier lecture) Features Label Name Egg-laying Scales Poisonous Cold­ blooded Number legs Reptile Cobra 1 1 1 1 0 1 Rattlesnake 1 1 1 1 0 1 Boa 0 1 0 1 0 1 constrictor Chicken 1 1 0 1 2 0 Guppy 0 1 0 0 0 0 Dart frog 1 0 1 0 4 0 Zebra 0 0 0 0 4 0 Python 1 1 0 1 0 1 Alligator 1 1 0 1 4 1 6.0002 LECTURE 13 4
458	Distance Matrix Code for producing this table posted 6.0002 LECTURE 13 5
459	Using Distance Matrix for Classification Simplest approach is probably nearest neighbor Remember training data When predicting the label of a new example ◦ Find the nearest example in the training data ◦ Predict the label associated with that example X 6.0002 LECTURE 13 6
460	Distance Matrix Label R R R ~R ~R ~R 6.0002 LECTURE 13 7
461	An Example 6.0002 LECTURE 13 8
462	K-nearest Neighbors X 6.0002 LECTURE 13 9
463	An Example 6.0002 LECTURE 13 10
464	Advantages and Disadvantages of KNN Advantages ◦ Learning fast, no explicit training ◦ No theory required ◦ Easy to explain method and results Disadvantages ◦ Memory intensive and predictions can take a long time ◦ Are better algorithms than brute force ◦ No model to shed light on process that generated data 6.0002 LECTURE 13 11
465	The Titanic Disaster RMS Titanic sank in the North Atlantic the morning of 15 April 1912, after colliding with an iceberg. Of the 1,300 passengers aboard, 812 died. (703 of 918 crew members died.) Database of 1046 passengers ◦ Cabin class ◦ 1st, 2nd, 3rd ◦ Age ◦ Gender 6.0002 LECTURE 13 12
466	Is Accuracy Enough If we predict “died”, accuracy will be >62% or passenger and >76% for crew members Consider a disease that occurs in 0.1% of population ◦ Predicting disease-free has an accuracy of 0.999 6.0002 LECTURE 13 13
467	Other Metrics sensitivity = recall specificity = precision 6.0002 LECTURE 13 14
468	Testing Methodology Matters Leave-one-out Repeated random subsampling 6.0002 LECTURE 13 15
469	Leave-one-out 6.0002 LECTURE 13 16
470	Repeated Random Subsampling 6.0002 LECTURE 13 17
471	Repeated Random Subsampling 6.0002 LECTURE 13 18
472	Let’s Try KNN 6.0002 LECTURE 13 19
473	Results Average of 10 80/20 splits using KNN (k=3) Accuracy = 0.766 Sensitivity = 0.67 Specificity = 0.836 Pos. Pred. Val. = 0.747 Average of LOO testing using KNN (k=3) Accuracy = 0.769 Sensitivity = 0.663 Specificity = 0.842 Pos. Pred. Val. = 0.743 Considerably better than 62% Not much difference between experiments 6.0002 LECTURE 13 20
474	Logistic Regression Analogous to linear regression Designed explicitly for predicting probability of an event ◦ Dependent variable can only take on a finite set of values ◦ Usually 0 or 1 Finds weights for each feature ◦ Positive implies variable positively correlated with outcome ◦ Negative implies variable negatively correlated with outcome ◦ Absolute magnitude related to strength of the correlation Optimization problem a bit complex, key is use of a log function—won’t make you look at it 6.0002 LECTURE 13 21
475	Class LogisticRegression fit(sequence of feature vectors, sequence of labels) Returns object of type LogisticRegression coef_ Returns weights of features predict_proba(feature vector) Returns probabilities of labels 6.0002 LECTURE 13 22
476	Building a Model 6.0002 LECTURE 13 23
477	Applying Model 6.0002 LECTURE 13 24
478	List Comprehension expr for id in L Creates a list by evaluating expr len(L) times with id in expr replaced by each element of L 6.0002 LECTURE 13 25
479	Applying Model 6.0002 LECTURE 13 26
480	Putting It Together 6.0002 LECTURE 13 27
481	Results Average of 10 80/20 splits LR Accuracy = 0.804 Sensitivity = 0.719 Specificity = 0.859 Pos. Pred. Val. = 0.767 Average of LOO testing using LR Accuracy = 0.786 Sensitivity = 0.705 Specificity = 0.842 Pos. Pred. Val. = 0.754 6.0002 LECTURE 13 28
482	Compare to KNN Results Average of 10 80/20 splits using KNN (k=3) Accuracy = 0.744 Sensitivity = 0.629 Specificity = 0.829 Pos. Pred. Val. = 0.728 Average of LOO testing using KNN (k=3) Accuracy = 0.769 Sensitivity = 0.663 Specificity = 0.842 Pos. Pred. Val. = 0.743 Average of 10 80/20 splits LR Accuracy = 0.804 Sensitivity = 0.719 Specificity = 0.859 Pos. Pred. Val. = 0.767 Average of LOO testing using LR Accuracy = 0.786 Sensitivity = 0.705 Specificity = 0.842 Pos. Pred. Val. = 0.754 Performance not much difference Logistic regression slightly better Also provides insight about variables 6.0002 LECTURE 13 29
483	Looking at Feature Weights Be wary of reading too much into the weights Features are often correlated model.classes_ = ['Died' 'Survived'] For label Survived C1 = 1.66761946545 C2 = 0.460354552452 C3 = -0.50338282535 age = -0.0314481062387 male gender = -2.39514860929 6.0002 LECTURE 13 30
484	Changing the Cutoff Try p = 0.1 Try p = 0.9 Accuracy = 0.493 Accuracy = 0.656 Sensitivity = 0.976 Sensitivity = 0.176 Specificity = 0.161 Specificity = 0.984 Pos. Pred. Val. = 0.444 Pos. Pred. Val. = 0.882 6.0002 LECTURE 13 31
485	ROC (Receiver Operating Characteristic) 6.0002 LECTURE 13 32
486	Output 6.0002 LECTURE 13 33
487	MIT OpenCourseWare https://ocw.mit.edu 6.0002 Introduction to Computational Thinking and Data Science Fall 2016 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
488	Lecture: Sampling and Standard Error 6.0002 LECTURE 8 1
489	Announcements §Relevant reading: Chapter 17 §No lecture Wednesday of next week! 6.0002 LECTURE 8 2
490	Recall Inferential Statistics §Inferential statistics: making inferences about a populations by examining one or more random samples drawn from that population §With Monte Carlo simulation we can generate lots of random samples, and use them to compute confidence intervals §But suppose we can’t create samples by simulation? ◦ “According to the most recent poll Clinton leads Trump by 3.2 percentage points in swing states. The registered voter sample is 835 with with a margin of error of plus or minus 4 percentage points.” – October 2016 6.0002 LECTURE 8 3
491	Probability Sampling §Each member of the population has a nonzero probability of being included in a sample §Simple random sampling: each member has an equal chance of being chosen §Not always appropriate ◦Are MIT undergraduates nerds? ◦Consider a random sample of 100 students 6.0002 LECTURE 8 4
492	Stratified Sampling §Stratified sampling ◦Partition population into subgroups ◦Take a simple random sample from each subgroup 6.0002 LECTURE 8 5
493	Stratified Sampling §When there are small subgroups that should be represented §When it is important that subgroups be represented proportionally to their size in the population §Can be used to reduced the needed size of sample ◦Variability of subgroups less than of entire population §Requires care to do properly §Well stick to simple random samples 6.0002 LECTURE 8 6
494	Data §From U.S. National Centers for Environmental Information (NCEI) §Daily high and low temperatures for ◦21 different US cities ◦ALBUQUERQUE, BALTIMORE, BOSTON, CHARLOTTE, CHICAGO, DALLAS, DETROIT, LAS VEGAS, LOS ANGELES, MIAMI, NEW ORLEANS, NEW YORK, PHILADELPHIA, PHOENIX, PORTLAND, SAN DIEGO, SAN FRANCISCO, SAN JUAN, SEATTLE, ST LOUIS, TAMPA ◦1961 – 2015 ◦421,848 data points (examples) §Let’s use some code to look at the data 6.0002 LECTURE 8 7
495	New in Code §numpy.std is function in the numpy module that returns the standard deviation §random.sample(population, sampleSize) returns a list containing sampleSize randomly chosen distinct elements of population ◦Sampling without replacement 6.0002 LECTURE 8 8
496	Histogram of Entire Population 6.0002 LECTURE 8 σ = ~9.4 9
497	Histogram of Random Sample of Size 100 6.0002 LECTURE 8 σ = ~10.4 10
498	Means and Standard Deviations §Population mean = 16.3 §Sample mean = 17.1 §Standard deviation of population = 9.44 §Standard deviation of sample = 10.4 §A happy accident, or something we should expect? §Let’s try it 1000 times and plot the results 6.0002 LECTURE 8 11
499	New in Code §pylab.axvline(x = popMean, color = 'r') draws a red vertical line at popMean on the x-axis §There’s also a pylab.axhline function 6.0002 LECTURE 8 12
500	Try It 1000 Times ± 6.0002 LECTURE 8 13
501	± Try It 1000 Times What’s the 95% confidence interval? 16.28 +- 1.96*0.94 14.5 - 18.1 Includes population mean, but pretty wide Mean of sample Means = 16.3 Suppose we want a Standard deviation of sample means = 0.94 tighter bound? 6.0002 LECTURE 8 14
502	Getting a Tighter Bound §Will drawing more samples help? ◦ Let’s try increasing from 1000 to 2000 ◦ Standard deviation goes from 0.943 to 0.946 §How about larger samples? ◦ Let’s try increasing sample size from 100 to 200 ◦ Standard deviation goes from 0.943 to 0.662 6.0002 LECTURE 8 15
503	95% level. Error Bars, a Digression §Graphical representation of the variability of data §Way to visualize uncertainty When confidence intervals don’t overlap, we can conclude that means are statistically significantly different at 6.0002 LECTURE 8 https://upload.wikimedia.org/wikipedia/commons/1/1d/Pulse_Rate_Error_Bar_By_Exercise_Level.png 16
504	Let’s Look at Error Bars for Temperatures pylab.errorbar(xVals, sizeMeans, yerr = 1.96*pylab.array(sizeSDs), fmt = 'o', label = '95% Confidence Interval') 6.0002 LECTURE 8 17
505	Sample Size and Standard Deviation 6.0002 LECTURE 8 18
506	Larger Samples Seem to Be Better §Going from a sample size of 50 to 600 reduced the confidence interval from about 1.2C to about 0.34C. §But we are now looking at 600*100 = 600k examples ◦What has sampling bought us? ◦Absolutely Nothing! ◦Entire population contained ~422k samples 6.0002 LECTURE 8 19
507	What Can We Conclude from 1 Sample? §More than you might think §Thanks to the Central Limit Theorem 6.0002 LECTURE 8 20
508	Recall Central Limit Theorem §Given a sufficiently large sample: ◦1) The means of the samples in a set of samples (the sample means) will be approximately normally distributed, ◦2) This normal distribution will have a mean close to the mean the population, and ◦3) The variance of the sample means will be close to the variance of the population divided by the sample size. §Time to use the 3rd feature §Compute standard error of the mean (SEM or SE) 6.0002 LECTURE 8 21
509	Standard Error of the Mean σ SE = n def sem(popSD, sampleSize): return popSD/sampleSize**0.5 §Does it work? 6.0002 LECTURE 8 22
510	Testing the SEM sampleSizes = (25, 50, 100, 200, 300, 400, 500, 600) numTrials = 50 population = getHighs() popSD = numpy.std(population) sems = [] sampleSDs = [] for size in sampleSizes: sems.append(sem(popSD, size)) means = [] for t in range(numTrials): sample = random.sample(population, size) means.append(sum(sample)/len(sample)) sampleSDs.append(numpy.std(means)) pylab.plot(sampleSizes, sampleSDs, label = 'Std of ' + str(numTrials) + ' means') pylab.plot(sampleSizes, sems, 'r--', label = 'SEM') pylab.xlabel('Sample Size') pylab.ylabel('Std and SEM') pylab.title('SD for ' + str(numTrials) + ' Means and SEM') 6.0002 LECTURE 8 pylab.legend() 23
511	Standard Error of the Mean σ SE = n But, we don’t know standard deviation of population How might we approximate it? 6.0002 LECTURE 8 24
512	Sample SD vs. Population SD 6.0002 LECTURE 8 25
513	The Point §Once sample reaches a reasonable size, sample standard deviation is a pretty good approximation to population standard deviation §True only for this example? ◦Distribution of population? ◦Size of population? 6.0002 LECTURE 8 26
514	Looking at Distributions def plotDistributions(): uniform, normal, exp = [], [], [] for i in range(100000): uniform.append(random.random()) normal.append(random.gauss(0, 1)) exp.append(random.expovariate(0.5)) makeHist(uniform, 'Uniform', 'Value', 'Frequency') pylab.figure() makeHist(normal, 'Gaussian', 'Value', 'Frequency') pylab.figure() makeHist(exp, 'Exponential', 'Value', 'Frequency') 6.0002 LECTURE 8 27
515	Three Different Distributions random.random() random.gauss(0, 1) 6.0002 LECTURE 8 random.expovariate(0.5) 28
516	Does Distribution Matter? 6.0002 LECTURE 8 Skew, a measure of the asymmetry of a probability distribution, matters 29
517	Does Population Size Matter? 6.0002 LECTURE 8 30
518	To Estimate Mean from a Single Sample §1) Choose sample size based on estimate of skew in population §2) Chose a random sample from the population §3) Compute the mean and standard deviation of that sample §4) Use the standard deviation of that sample to estimate the SE §5) Use the estimated SE to generate confidence intervals around the sample mean Works great when we choose independent random samples. Not always so easy to do, as political pollsters keep learning. 6.0002 LECTURE 8 31
519	Are 200 Samples Enough? numBad = 0 for t in range(numTrials): sample = random.sample(temps, sampleSize) sampleMean = sum(sample)/sampleSize se = numpy.std(sample)/sampleSize**0.5 if abs(popMean - sampleMean) > 1.96*se: numBad += 1 print('Fraction outside 95% confidence interval =', numBad/numTrials) Fraction outside 95% confidence interval = 0.0511 6.00.2X LECTURE 32
520	MIT OpenCourseWare https://ocw.mit.edu 6.0002 Introduction to Computational Thinking and Data Science Fall 2016 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
521	                                 
522	"          !""       "
523	"  #$  % &""!  '() "" )* % +  '(, !- !*  ! "" ! $, !- !)  % &""!  '(.-  / !* % +  '(  . !!!0!*  1! $ -   !0, !- !)    !(2 #$ (!              3"
524	"!  ""         4 !$  22    !   $!!!!  ! !!!   $!!  !!! !(4( $! 0$ 2  ! k ≈35,000N / m  k ≈1N / m 0 52     4$!!$! !  Images of suspension spring and slinky © sources unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/."
525	 6574  8 0$  !. 0   $!!! $9 #$% & '    5                  53;                  !2! 4 $!(  ! !< Images of suspension spring © source unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.
526	 6574  4576=  45 >$= (   $    6 
527	    Distance (m) Mass (kg) 0.0865 0.1 0.1015 0.15 0.1106 0.2 0.1279 0.25 0.1892 0.3 0.2695 0.35 0.2888 0.4 0.2425 0.45 0.3465 0.5 0.3225 0.55 0.3764 0.6 0.4263 0.65 0.4562 0.7    7
528	def plotData(fileName): xVals, yVals = getData(fileName) xVals = pylab.array(xVals) yVals = pylab.array(yVals) xVals = xVals*9.81 #acc. due to gravity pylab.plot(xVals, yVals, 'bo', label = 'Measured displacements') labelPlot()  $  &$  !       8
529	 $  &$  !       9
530	" 0/ . ! 2(0/ / !.) '$!!*  !-$.  2.) ' ! *    00  ./!(0 0"" $!  !! 2/?       @ 0/ )A -.2  - (00 /  .$$B!  C! !(00 / ! ! $ 2  -  2! $ 2! !2 $   $!  !!$$B ( ) *        0"
531	           1 X P Y Which should we choose? D-  ! )  !0   E. 2 .F. (.-   ! $! !  - 
532	  42$ 9 % !!. -$! $) 2 )!.- ! % + $$B!0  ! $$B.  &  +  ,- * (    len(observed)−1 ∑ (observed[i]−predicted[i])2 i=0    2
533	" $$B! )A -.2  - (0 / .2   )!.- ! !  $$ $.   !     / "" $  !- 2  $   *   &  +   len(observed)−1 ∑ (observed[i]−predicted[i])2 i=0    3"
534	"  ! $ 2/ $) 2 7B $!   $ 22 $ # % ( H (  $) % ( 2$( 7-.   2 "" $ ! ! 2 ""$  #$ ! % #I) % &) #I)#I  ./  ' !  0  , 1 2    4"
535	" +$ #$  % !7  "" $ ( (!$   2  '00)!/J *  6. ! 2 ! 00 !  "" $   $ . !2   2. !  #$(!, K  2!  . ! !  . !!$$B  L     ) $  M""  $!2  !(  !$   0 N!$ '0 "" !0* *   &  +   len(observed)−1 ∑ (observed[i]−predicted[i])2 i=0    5"
536	" O 0!!"" ) .!)  2  - !  /! "" $ /!  pylab.polyfit(observedX, observedY, n)  6! H ! 2 "" $  2(  .!)! !!, !/2  )!. % 5?)!   ""5#I) % 5?)!)  ""5#I)#I  /(     6"
537	"  /3  def fitData(fileName): xVals, yVals = getData(fileName) xVals = pylab.array(xVals) yVals = pylab.array(yVals) xVals = xVals*9.81 #get force pylab.plot(xVals, yVals, 'bo', label = 'Measured points') labelPlot() a,b = pylab.polyfit(xVals, yVals, 1) estYVals = a*pylab.array(xVals) + b print('a =', a, 'b =', b) pylab.plot(xVals, estYVals, 'r', label = 'Linear fit, k = ' + str(round(1/a, 5))) pylab.legend(loc = 'best')    7   .!   ""!    1"
538	0   4  ! (     18
539	0    /*  def fitData1(fileName): xVals, yVals = getData(fileName) xVals = pylab.array(xVals) yVals = pylab.array(yVals) xVals = xVals*9.81 #get force pylab.plot(xVals, yVals, 'bo', label = 'Measured points') labelPlot() model = pylab.polyfit(xVals, yVals, 1) estYVals = pylab.polyval(model, xVals) pylab.plot(xVals, estYVals, 'r', label = 'Linear fit, k = ' + str(round(1/model[0], 5))) pylab.legend(loc = 'best')    19
540	!       0
541	(  &      1
542	&% / # !5    model2 = pylab.polyfit(xVals, yVals, 2) pylab.plot(xVals, pylab.polyval(model2, xVals), 'r--', label = 'Quadratic Model')  !!!- #$  2 !! ( . 0 /J  '! !0/)!) *    2 2) l2
543	6      , 78 (     3
544	  -.     C)! !! #'   ! (  9    4
545	" 6!2  - 2 $.)   .)   O.. ( .!!-$ 2 .    / .!)P!-$!9  + 02 /)""$$B$!,  ( A !.  !! 2/)"" 4   : *  ! !     5"
546	     +    def aveMeanSquareError(data, predicted): error = 0.0 for i in range(len(data)): error += (data[i] - predicted[i])**2 return error/len(data) estYVals = pylab.polyval(model1, xVals) print('Ave. mean square error for linear model =', aveMeanSquareError(yVals, estYVals)) estYVals = pylab.polyval(model2, xVals) print('Ave. mean square error for quadratic model =', aveMeanSquareError(yVals, estYVals))    6 L.$!,  2  $  5 3::3: ; L.$!,  2 , - $  5;GGG:
547	" M!,   !2 2  $0 K $  !2 !$  !2 2 J!! 2)!  !! 2/9 % C!;G 9  8 4 0(! !  )   !    C!0 ! H  2$- ( (   ,       7  !-$! D) "" $!  E$! . ! & . ! μ!$ 2$! . !"
548	" ; .   def rSquared(observed, predicted): error = ((predicted - observed)**2).sum() meanError = error/len(observed) return 1 - (meanError/numpy.var(observed))    28 C$ "" . 4 •  $ !! $ 2!,  ! • 1.)"" $) 2!$ !.!.! $7!, 7  • 1 $ !. -$! $) 2!$ ! • + $++=. !!$! - "
549	" Q"" $!-$-  !' $ * 0.) "" 2  . !'  $ *( !     -  2.) ""!! 2 )"" !-!-  $   .)""/  L 0""!)00/)""  !! !  % C2 5($  # !  2.) ""  % C2 5(!  - !)0. !  )""$      % C2 5;($  # ! 2.) ""  : <    29"
550	    (   def genFits(xVals, yVals, degrees): models = [] for d in degrees: model = pylab.polyfit(xVals, yVals, d) models.append(model) return models def testFits(models, degrees, xVals, yVals, title): pylab.plot(xVals, yVals, 'o', label = 'Data') for i in range(len(models)): estYVals = pylab.polyval(models[i], xVals) error = rSquared(yVals, estYVals) pylab.plot(xVals, estYVals, label = 'Fit of degree '\\ + str(degrees[i])\\ + ', R2 = ' + str(round(error, 5))) pylab.legend(loc = 'best') pylab.title(title)    30
551	#' = (    0       31
552	 =   ! (  9    32
553	MIT OpenCourseWare https://ocw.mit.edu 6.0002 Introduction to Computational Thinking and Data Science Fall 2016 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
554	Op#miza#on Problems, John Gu7ag MIT Department of Electrical Engineering and Computer Science 6.0002 LECTURE 2 1
555	§ Chapter 13 Relevant Reading for Today’s Lecture 6.0002 LECTURE 2 2
556	The Pros and Cons of Greedy § Easy to implement § Computa<onally eﬃcient § But does not always yield the best solu<on ◦ Don’t even know how good the approxima<on is 6.0002 LECTURE 2 3 Ques<on 1
557	§ 1. Enumerate all possible combina<ons of items. § 2. Remove all of the combina<ons whose total units exceeds the allowed weight. § 3. From the remaining combina<ons choose any one whose value is the largest. Brute Force Algorithm 6.0002 LECTURE 2 4
558	§ The tree is built top down star<ng with the root § The ﬁrst element is selected from the s<ll to be considered items ◦ If there is room for that item in the knapsack, a node is constructed that reﬂects the consequence of choosing to take that item. By conven<on, we draw that as the leS child ◦ We also explore the consequences of not taking that item. This is the right child § The process is then applied recursively to non-leaf children § Finally, chose a node with the highest value that meets constraints Search Tree Implementa#on 6.0002 LECTURE 2 5
559	A Search Tree Enumerates Possibili#es 6.0002 LECTURE 2 6 Take Don’tTake LeS-ﬁrst, depth-ﬁrst enumera<on Val = 170 Cal = 766 Val = 120 Cal = 766 Val = 140 Cal = 508 Val = 90 Cal = 145 Val = 80 Cal = 612 Val = 30 Cal = 258 Val = 50 Cal = 354 Val = 0 Cal = 0
560	6.0002 LECTURE 2 7 Image © source unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use.
561	§ Time based on number of nodes generated § Number of levels is number of items to choose from § Number of nodes at level i is 2i § So, if there are n items the number of nodes is ◦ ∑𝑖=0↑𝑖=𝑛▒​2↑𝑖 ◦ I.e., O(​2↑𝑛+1 ) § An obvious op<miza<on: don’t explore parts of tree that violate constraint (e.g., too many calories) ◦ Doesn’t change complexity § Does this mean that brute force is never useful? ◦ Let’s give it a try Computa#onal Complexity 6.0002 LECTURE 2 8
562	"Header for Decision Tree Implementa#on 6.0002 LECTURE 2 9 def maxVal(toConsider, avail): """"""Assumes toConsider a list of items, avail a weight Returns a tuple of the total value of a solution to 0/1 knapsack problem and the items of that solution""""” toConsider. Those items that nodes higher up in the tree (corresponding to earlier calls in the recursive call stack) have not yet considered avail. The amount of space still available"
563	Body of maxVal (without comments) 6.0002 LECTURE 2 10 if toConsider == [] or avail == 0: result = (0, ()) elif toConsider[0].getUnits() > avail: result = maxVal(toConsider[1:], avail) else: nextItem = toConsider[0] withVal, withToTake = maxVal(toConsider[1:], avail - nextItem.getUnits()) withVal += nextItem.getValue() withoutVal, withoutToTake = maxVal(toConsider[1:], avail f withVal > withoutVal: result = (withVal, withToTake + (nextItem,)) else: result = (withoutVal, withoutToTake) eturn result oes not actually build search tree ) i r D Local variable result records best solu<on found so far
564	§ With calorie budget of 750 calories, chose an op<mal set of foods from the menu Try on Example from Lecture 1 6.0002 LECTURE 2 11 Food wine beer pizza burger fries coke apple donut Value 89 90 30 50 90 79 90 10 calories 123 154 258 354 365 150 95 195
565	§ Gave us a befer answer § Finished quickly § But 28 is not a large number ◦ We should look at what happens when we have a more extensive menu to choose from Search Tree Worked Great 6.0002 LECTURE 2 12
566	Code to Try Larger Examples 6.0002 LECTURE 2 13 import random def buildLargeMenu(numItems, maxVal, maxCost): items = [] for i in range(numItems): items.append(Food(str(i), random.randint(1, maxVal), random.randint(1, maxCost))) return items for numItems in (5,10,15,20,25,30,35,40,45,50,55,60): items = buildLargeMenu(numItems, 90, 250) testMaxVal(items, 750, False)
567	§ In theory, yes § In prac<ce, no! § Dynamic programming to the rescue Is It Hopeless? 6.0002 LECTURE 2 14
568	Some<mes a name is just a name “The 1950s were not good years for mathema<cal research… I felt I had to do something to shield Wilson and the Air Force from the fact that I was really doing mathema<cs... What <tle, what name, could I choose? ... It's impossible to use the word dynamic in a pejora<ve sense. Try thinking of some combina<on that will possibly give it a pejora<ve meaning. It's impossible. Thus, I thought dynamic programming was a good name. It was something not even a Congressman could object to. So I used it as an umbrella for my ac<vi<es. -- Richard Bellman Dynamic Programming? 6.0002 LECTURE 2 15
569	Recursive Implementa#on of Fibonnaci 6.0002 LECTURE 2 16 def fib(n): if n == 0 or n == 1: return 1 else: return fib(n - 1) + fib(n - 2) fib(120) = 8,670,007,398,507,948,658,051,921
570	Call Tree for Recursive Fibonnaci(6) = 13 6.0002 LECTURE 2 17 ﬁb(6) ﬁb(5) ﬁb(4) ﬁb(3) ﬁb(2) ﬁb(1) ﬁb(0) ﬁb(1) ﬁb(2) ﬁb(1) ﬁb(0) ﬁb(3) ﬁb(2) ﬁb(1) ﬁb(0) ﬁb(1) ﬁb(4) ﬁb(3) ﬁb(2) ﬁb(1) ﬁb(0) ﬁb(1) ﬁb(2) ﬁb(1) ﬁb(0)
571	§ Trade a <me for space § Create a table to record what we’ve done ◦Before compu<ng ﬁb(x), check if value of ﬁb(x) already stored in the table ◦If so, look it up ◦If not, compute it and then add it to table ◦Called memoiza<on Clearly a Bad Idea to Repeat Work 6.0002 LECTURE 2 18
572	"Using a Memo to Compute Fibonnaci 6.0002 LECTURE 2 19 def fastFib(n, memo = {}): """"""Assumes n is an int >= 0, memo used only by recursive calls Returns Fibonacci of n"""""" if n == 0 or n == 1: return 1 try: return memo[n] except KeyError: result = fastFib(n-1, memo) +\\ fastFib(n-2, memo) memo[n] = result return result"
573	§ Op<mal substructure: a globally op<mal solu<on can be found by combining op<mal solu<ons to local subproblems ◦For x > 1, ﬁb(x) = ﬁb(x - 1) + ﬁb(x – 2) § Overlapping subproblems: ﬁnding an op<mal solu<on involves solving the same problem mul<ple <mes ◦Compute ﬁb(x) or many <mes When Does It Work? 6.0002 LECTURE 2 20
574	§ Do these condi<ons hold? What About 0/1 Knapsack Problem? 6.0002 LECTURE 2 21 Ques<ons 2 and 3
575	Search Tree 6.0002 LECTURE 2 22 Take Don’tTake Val = 170 Cal = 766 Val = 120 Cal = 766 Val = 140 Cal = 508 Val = 90 Cal = 145 Val = 80 Cal = 612 Val = 30 Cal = 258 Val = 50 Cal = 354 Val = 0 Cal = 0 Op<mal substructure? Overlapping subproblems?
576	A Diﬀerent Menu 6.0002 LECTURE 2 23 Take Don’t Take
577	Need Not Have Copies of Items 6.0002 LECTURE 2 24 Item Value Calories a 6 3 b 7 3 c 8 2 d 9 5
578	§ Each node = <taken, leS, value, remaining calories> Search Tree 6.0002 LECTURE 2 25
579	§ Given remaining weight, maximize value by choosing among remaining items § Set of previously chosen items, or even value of that set, doesn’t mafer! What Problem is Solved at Each Node? 6.0002 LECTURE 2 26
580	Overlapping Subproblems 6.0002 LECTURE 2 27
581	§ Add memo as a third argument ◦def fastMaxVal(toConsider, avail, memo = {}): § Key of memo is a tuple ◦(items leS to be considered, available weight) ◦Items leS to be considered represented by len(toConsider) § First thing body of func<on does is check whether the op<mal choice of items given the the available weight is already in the memo § Last thing body of func<on does is update the memo Modify maxVal to Use a Memo 6.0002 LECTURE 2 28
582	Performance 6.0002 LECTURE 2 29 len(items) 2**len(items) Number of calls 2 4 7 4 16 25 8 256 427 16 65,536 5,191 32 4,294,967,296 22,701 64 18,446,744,073,709 42,569 ,551,616 128 Big 83,319 256 Really Big 176,614 512 Ridiculously big 351,230 1024 Absolutely huge 703,802
583	§ Problem is exponen<al § Have we overturned the laws of the universe? § Is dynamic programming a miracle? § No, but computa<onal complexity can be subtle § Running <me of fastMaxVal is governed by number of dis<nct pairs, <toConsider, avail> ◦Number of possible values of toConsider bounded by len(items) ◦Possible values of avail a bit harder to characterize ◦Bounded by number of dis<nct sums of weights ◦Covered in more detail in assigned reading How Can This Be? 6.0002 LECTURE 2 30
584	§ Many problems of prac<cal importance can be formulated as op<miza<on problems § Greedy algorithms oSen provide adequate (though not necessarily op<mal) solu<ons § Finding an op<mal solu<on is usually exponen<ally hard § But dynamic programming oSen yields good performance for a subclass of op<miza<on problems— those with op<mal substructure and overlapping subproblems ◦Solu<on always correct ◦Fast under the right circumstances Summary of Lectures 1-2 6.0002 LECTURE 2 31
585	The “Roll-over” Op#miza#on Problem 6.0002 LECTURE 2 32 Score = ((60 – (a+b+c+d+e))*F + a*ps1 + b*ps2 + c*ps3 + d*ps4 + e*ps5 Objec<ve: Given values for F, ps1, ps2, ps3, ps4, ps5 Find values for a, b, c, d, e that maximize score Constraints: a, b, c, d, e are each 10 or 0 a + b + c + d + e ≥ 20
586	MIT OpenCourseWare https://ocw.mit.edu 6.0002 Introduction to Computational Thinking and Data Science Fall 2016 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
587	Lecture 4: Stochastic Thinking and Random Walks ϲ͘ϬϬϬϮ [ĞĐƚƵƌĞ ϰ 1
588	Relevant Reading Pages 235-238 Chapter 14 6.0002 LECTURE 4 2
589	The World is Hard to Understand Uncertainty is uncomfortable But certainty is usually unjustified 6.0002 LECTURE 4 3
590	Newtonian Mechanics Every effect has a cause The world can be understood causally 6.0002 LECTURE 4 4
591	Copenhagen Doctrine Copenhagen Doctrine (Bohr and Heisenberg) of causal nondeterminism ◦ At its most fundamental level, the behavior of the physical world cannot be predicted. ◦ Fine to make statements of the form “x is highly likely to ◦ occur,” but not of the form “x is certain to occur.” Einstein and Schrödinger objected ◦ “God does not play dice.” -- Albert Einstein 6.0002 LECTURE 4 5
592	Does It Really Matter Did the flips yield 2 heads 2 tails 1 head and 1 tail? 6.0002 LECTURE 4 ϲ
593	The Moral The world may or may not be inherently unpredictable But our lack of knowledge does not allow us to make accurate predictions Therefore we might as well treat the world as inherently unpredictable Predictive nondeterminism 6.0002 LECTURE 4 7
594	"Stochastic Processes An ongoing process where the next state might depend on both the previous states and some random element def rollDie(): """""" returns an int between 1 and 6"""""" def rollDie(): """""" returns a randomly chosen int between 1 and 6"""""" 6.0002 LECTURE 4 8"
595	"Implementing a Random Process import random def rollDie(): """"""returns a random int between 1 and 6"""""" return random.choice([1,2,3,4,5,6]) def testRoll(n = 10): result = '' for i in range(n): result = result + str(rollDie()) print(result) 6.0002 LECTURE 4 9"
596	Probability of Various Results Consider testRoll(5) How probable is the output 11111? 6.0002 LECTURE 4 10
597	Probability Is About Counting Count the number of possible events Count the number of events that have the property of interest Divide one by the other Probability of 11111? ◦ 11111, 11112, 11113, /, 11121, 11122, /, 66666 ◦ 1/(6**5) ◦ ~0.0001286 6.0002 LECTURE 4 11
598	Three Basic Facts About Probability Probabilities are always in the range 0 to 1. 0 if impossible, and 1 if guaranteed. If the probability of an event occurring is p, the probability of it not occurring must be When events are independent of each other, the probability of all of the events occurring is equal to a product of the probabilities of each of the events occurring. 6.0002 LECTURE 4 12
599	Independence Two events are independent if the outcome of one event has no influence on the outcome of the other Independence should not be taken for granted 6.0002 LECTURE 4 13
600	Will One of the Patriots and Broncos Lose? Patriots have winning percentage of 7/8, Broncos of 6/8 Probability of both winning next Sunday is 7/8 * 6/8 = 42/64 Probability of at least one losing is 1 – 42/64 = 22/64 What about Sunday, December 18 ◦ Outcomes are not independent ◦ Probability of one of them losing is much closer to 1 than to 22/64! 6.0002 LECTURE 4 14
601	A Simulation of Die Rolling def runSim(goal, numTrials, txt): total = 0 for i in range(numTrials): result = '' for j in range(len(goal)): result += str(rollDie()) if result == goal: total += 1 print('Actual probability of', txt, '=', round(1/(6**len(goal)), 8)) estProbability = round(total/numTrials, 8) print('Estimated Probability of', txt, '=', round(estProbability, 8)) runSim('11111', 1000, '11111') 6.0002 LECTURE 4 15
602	Output of Simulation Actual probability = 0.0001286 Estimated Probability = 0.0 Actual probability = 0.0001286 Estimated Probability = 0.0 How did I know that this is what would get printed? Why did simulation give me the wrong answer? Let’s try 1,000,000 trials 6.0002 LECTURE 4 16
603	Morals Moral 1: It takes a lot of trials to get a good estimate of the frequency of occurrence of a rare event. We’ll talk lots more in later lectures about how to know when we have enough trials. Moral 2: One should not confuse the sample probability with the actual probability Moral 3: There was really no need to do this by simulation, since there is a perfectly good closed form answer. We will see many examples where this is not true. But simulations are often useful. 6.0002 LECTURE 4 17
604	The Birthday Problem What’s the probability of at least two people in a group having the same birthday If there are 367 people in the group? What about smaller numbers? If we assume that each birthdate is equally likely 366! ◦ 1­  366𝑁∗ 366−𝑁 ! Without this assumption, VERY complicated shoutkey.com/niece 6.0002 LECTURE 4 18
605	Approximating Using a Simulation def sameDate(numPeople, numSame): possibleDates = range(366) birthdays = [0]*366 for p in range(numPeople): birthDate = random.choice(possibleDates) birthdays[birthDate] += 1 return max(birthdays) >= numSame 6.0002 LECTURE 4 19
606	Approximating Using a Simulation def birthdayProb(numPeople, numSame, numTrials): numHits = 0 for t in range(numTrials): if sameDate(numPeople, numSame): numHits += 1 return numHits/numTrials for numPeople in [10, 20, 40, 100]: print('For', numPeople, 'est. prob. of a shared birthday is', birthdayProb(numPeople, 2, 10000)) numerator = math.factorial(366) denom = (366**numPeople)*math.factorial(366-numPeople) print('Actual prob. for N = 100 =', 1 - numerator/denom) Suppose we want the probability of 3 people sharing 6.0002 LECTURE 4 20
607	Why 3 Is Much Harder Mathematically For 2 the complementary problem is “all birthdays distinct” For 3 people, the complementary problem is a complicated disjunct ◦ All birthdays distinct or ◦ One pair and rest distinct or ◦ Two pairs and rest distinct or ◦/ But changing the simulation is dead easy 6.0002 LECTURE 4 21
608	But All Dates Are Not Equally Likely Are you exceptional? 6.0002 LECTURE 4 Chart 22 Chart © Matt Stiles / The Daily Viz. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.
609	Another Win for Simulation Adjusting analytic model a pain Adjusting simulation model easy def sameDate(numPeople, numSame): possibleDates = 4*list(range(0, 57)) + [58]\\ + 4*list(range(59, 366))\\ + 4*list(range(180, 270)) birthdays = [0]*366 for p in range(numPeople): birthDate = random.choice(possibleDates) birthdays[birthDate] += 1 return max(birthdays) >= numSame 6.0002 LECTURE 4 23
610	Simulation Models A description of computations that provide useful information about the possible behaviors of the system being modeled Descriptive, not prescriptive Only an approximation to reality “All models are wrong, but some are useful.” – George Box 6.0002 LECTURE 4 24
611	Simulations Are Used a Lot To model systems that are mathematically intractable To extract useful intermediate results Lend themselves to development by successive refinement and “what if” questions Start by simulating random walks 6.0002 LECTURE 4 25
612	Why Random Walks? Random walks are important in many domains ◦Understanding the stock market (maybe) ◦Modeling diffusion processes ◦Etc. Good illustration of how to use simulations to understand things Excuse to cover some important programming topics ◦Practice with classes ◦More about plotting 6.0002 LECTURE 4 26
613	Brownian Motion Is a Random Walk Robert Brown 1827 Louis Bachelier Albert 1900 Einstein 1905 6.0002 LECTURE 4 Images of Robert Brown and Albert Einstein are in the public domain. Image of Louis Bachelier © unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/. 27
614	Drunkard’s Walk 6.0002 LECTURE 4 28
615	One Possible First Step 6.0002 LECTURE 4 29
616	Another Possible First Step 6.0002 LECTURE 4 30
617	Yet Another Possible First Step 6.0002 LECTURE 4 31
618	Last Possible First Step 6.0002 LECTURE 4 32
619	Possible Distances After Two Steps 6.0002 LECTURE 4 Image of Pythagoras © unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/ . 33
620	Expected Distance After 100,000 Steps? Need a different approach to problem Will use simulation But not until the next lecture 6.0002 LECTURE 4 34
621	MIT OpenCourseWare https://ocw.mit.edu 6.0002 Introduction to Computational Thinking and Data Science Fall 2016 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
622	Lecture 12: Clustering 6.0002 LECTURE 12 1
623	Reading §Chapter 23 6.0002 LECTURE 12 2
624	Machine Learning Paradigm §Observe set of examples: training data §Infer something about process that generated that data §Use inference to make predictions about previously unseen data: test data §Supervised: given a set of feature/label pairs, find a rule that predicts the label associated with a previously unseen input §Unsupervised: given a set of feature vectors (without labels) group them into “natural clusters” 6.0002 LECTURE 12 3
625	Clustering Is an Optimization Problem §Why not divide variability by size of cluster? ◦ Big and bad worse than small and bad §Is optimization problem finding a C that minimizes dissimilarity(C)? ◦ No, otherwise could put each example in its own cluster §Need a constraint, e.g., ◦ Minimum distance between clusters ◦ Number of clusters 6.0002 LECTURE 12 4
626	Two Popular Methods §Hierarchical clustering §K-means clustering 6.0002 LECTURE 12 5
627	Hiearchical Clustering 1. Start by assigning each item to a cluster, so that if you have N items, you now have N clusters, each containing just one item. 2. Find the closest (most similar) pair of clusters and merge them into a single cluster, so that now you have one fewer cluster. 3. Continue the process until all items are clustered into a single cluster of size N. What does distance mean? 6.0002 LECTURE 12 6
628	Linkage Metrics §Single-linkage: consider the distance between one cluster and another cluster to be equal to the shortest distance from any member of one cluster to any member of the other cluster §Complete-linkage: consider the distance between one cluster and another cluster to be equal to the greatest distance from any member of one cluster to any member of the other cluster §Average-linkage: consider the distance between one cluster and another cluster to be equal to the average distance from any member of one cluster to any member of the other cluster 6.0002 LECTURE 12 7
629	Example of Hierarchical Clustering 6.0002 LECTURE 12 8 BOS NY CHI DEN SF SEA BOS 0 206 963 1949 3095 2979 NY 0 802 1771 2934 2815 CHI 0 966 2142 2013 DEN 0 1235 1307 SF 0 808 SEA 0 {BOS} {NY} {CHI} {DEN} {SF} {SEA} {BOS, NY} {CHI} {DEN} {SF} {SEA} {BOS, NY, CHI} {DEN} {SF} {SEA} {BOS, NY, CHI} {DEN} {SF, SEA} {BOS, NY, CHI, DEN} {SF, SEA} {BOS, NY, CHI} {DEN, SF, SEA} or Single linkage Complete linkage
630	Clustering Algorithms §Hierarchical clustering ◦ Can select number of clusters using dendogram ◦ Deterministic ◦ Flexible with respect to linkage criteria ◦ Slow ◦ Naïve algorithm n3 ◦ n2 algorithms exist for some linkage criteria §K-means a much faster greedy algorithm ◦ Most useful when you know how many clusters you want 6.0002 LECTURE 12 9
631	K-means Algorithm randomly chose k examples as initial centroids while true: create k clusters by assigning each example to closest centroid compute k new centroids by averaging examples in each cluster if centroids don’t change: break What is complexity of one iteration? k*n*d, where n is number of points and d time required to compute the distance between a pair of points 6.0002 LECTURE 12 10
632	An Example 6.0002 LECTURE 12 11
633	K = 4, Initial Centroids 6.0002 LECTURE 12 12
634	Iteration 1 6.0002 LECTURE 12 13
635	Iteration 2 6.0002 LECTURE 12 14
636	Iteration 3 6.0002 LECTURE 12 15
637	Iteration 4 6.0002 LECTURE 12 16
638	Iteration 5 6.0002 LECTURE 12 17
639	Issues with k-means §Choosing the “wrong” k can lead to strange results ◦ Consider k = 3 §Result can depend upon initial centroids ◦ Number of iterations ◦ Even final result ◦ Greedy algorithm can find different local optimas 6.0002 LECTURE 12 18
640	How to Choose K §A priori knowledge about application domain ◦ There are two kinds of people in the world: k = 2 ◦ There are five different types of bacteria: k = 5 §Search for a good k ◦ Try different values of k and evaluate quality of results ◦ Run hierarchical clustering on subset of data 6.0002 LECTURE 12 19
641	Unlucky Initial Centroids 6.0002 LECTURE 12 20
642	Converges On 6.0002 LECTURE 12 21
643	Mitigating Dependence on Initial Centroids Try multiple sets of randomly chosen initial centroids Select “best” result best = kMeans(points) for t in range(numTrials): C = kMeans(points) if dissimilarity(C) < dissimilarity(best): best = C return best 6.0002 LECTURE 12 22
644	An Example §Many patients with 4 features each ◦ Heart rate in beats per minute ◦ Number of past heart attacks ◦ Age ◦ ST elevation (binary) §Outcome (death) based on features ◦ Probabilistic, not deterministic ◦ E.g., older people with multiple heart attacks at higher risk §Cluster, and examine purity of clusters relative to outcomes 6.0002 LECTURE 12 23
645	Data Sample HR Att STE Age Outcome P000:[ 89. 1. 0. 66.]:1 P001:[ 59. 0. 0. 72.]:0 P002:[ 73. 0. 0. 73.]:0 P003:[ 56. 1. 0. 65.]:0 P004:[ 75. 1. 1. 68.]:1 P005:[ 68. 1. 0. 56.]:0 P006:[ 73. 1. 0. 75.]:1 P007:[ 72. 0. 0. 65.]:0 P008:[ 73. 1. 0. 64.]:1 P009:[ 73. 0. 0. 58.]:0 P010:[ 100. 0. 0. 75.]:0 P011:[ 79. 0. 0. 31.]:0 P012:[ 81. 0. 0. 58.]:0 P013:[ 89. 1. 0. 50.]:1 P014:[ 81. 0. 0. 70.]:0 6.0002 LECTURE 12 24
646	Class Example 6.0002 LECTURE 12 25
647	Class Cluster 6.0002 LECTURE 12 26
648	Class Cluster, cont. 6.0002 LECTURE 12 27
649	Evaluating a Clustering 6.0002 LECTURE 12 28
650	Patients Z-Scaling Mean = ? Std = ? 6.0002 LECTURE 12 29
651	kmeans 6.0002 LECTURE 12 30
652	Examining Results 6.0002 LECTURE 12 31
653	Result of Running It Test k-means (k = 2) Cluster of size 118 with fraction of positives = 0.3305 Cluster of size 132 with fraction of positives = 0.3333 Like it? Try patients = getData(True) Test k-means (k = 2) Cluster of size 224 with fraction of positives = 0.2902 Cluster of size 26 with fraction of positives = 0.6923 Happy with sensitivity? 6.0002 LECTURE 12 32
654	How Many Positives Are There? Total number of positive patients = 83 Test k-means (k = 2) Cluster of size 224 with fraction of positives = 0.2902 Cluster of size 26 with fraction of positives = 0.6923 6.0002 LECTURE 12 33
655	A Hypothesis §Different subgroups of positive patients have different characteristics §How might we test this? §Try some other values of k 6.0002 LECTURE 12 34
656	Testing Multiple Values of k Test k-means (k = 2) Cluster of size 224 with fraction of positives = 0.2902 Cluster of size 26 with fraction of positives = 0.6923 Test k-means (k = 4) Cluster of size 26 with fraction of positives = 0.6923 Cluster of size 86 with fraction of positives = 0.0814 Cluster of size 76 with fraction of positives = 0.7105 Cluster of size 62 with fraction of positives = 0.0645 Test k-means (k = 6) Cluster of size 49 with fraction of positives = 0.0204 Cluster of size 26 with fraction of positives = 0.6923 Cluster of size 45 with fraction of positives = 0.0889 Cluster of size 54 with fraction of positives = 0.0926 Cluster of size 36 with fraction of positives = 0.7778 Cluster of size 40 with fraction of positives = 0.675 Pick a k 6.0002 LECTURE 12 35
657	MIT OpenCourseWare https://ocw.mit.edu 6.0002 Introduction to Computational Thinking and Data Science Fall 2016 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
658	"%$ 6' #%( # & %  % !&#"" $%'!""' '%  "" ""% "" "" #!$,'% "" Q>KKKM N L"
659	" -""' "" #%#/5& ',%  1*)LM>M Q>KKKM N M"
660	"#!$,'(#""  # &  .*"".(/0#0#',3/3)./0)0#5*.')/*'4 ,.1',.*'(/  5#*55*3'(,0#$) *.(',.*'(*  #**/$)""5#00*0$)0*)*,1($81*),.*'(< )#*55*3'/$""),.*"".(0*/*'4$0  *55)00*'**&0'//* (*'/''"".,#/ Q>KKKM N N"
661	" 0* )*/E4.1/F W $""#0#4,.*,.1///*$05$0#0#(  0* ""/E./F#*)/$/1)""* ,$.* )*/ W )$.0E"".,#F W $.0E$"".,#F W *3.E,.)0F)/1)1*)E#$'F)*/ W )5$""#0*.5$""#0  '5& %$ 2 Q>KKKM N O     "
662	" '5& %$ 2  0* )*/E4.1/F W $""#0#4,.*,.1///*$05$0#0#(  0* ""/E./F#*)/$/1)""* ,$.* )*/ W )$.0E"".,#F W $.0E$"".,#F W *3.E,.)0F)/1)1*)E#$'F)*/ W )5$""#0*.5$""#0 Q>KKKM N P LK LM N"
663	" / %$ &2  *,03.3/ 3'.'1*)/#$,/(*)"")11/ W $''$)&/05).$/) *)*) W *50#0*(/$)(*'3'..'00**))*0#. W )/0.'.'1*)/#$,/ Q>KKKM N Q"
664	"%&4"" !$#%'""'$  &  /,$'&$)* $.0"".,#$)5#$#)7,$.*  )*/$/*))07/$)""',0# W ''0#/.#0./53/0*/*'4&),/& ,.*'( Q>KKKM N R"
665	" / %$ &%#&,  *.'$/ 3''* )05*.&//*).'1*)/#$,/ W *(,30.)05*.&/ W .)/,*.01*))05*.&/ W $))$')05*.&/ W 5.*.50.)05*.&/ W *'$1')05*.&/ W .$($)')05*.&/ W *$')05*.&/ W 0>  Q>KKKM N S )'7/$/* @$8.* 8A= C/$8* )*. 0/)3(.* /)/ $)5#$##.0./#./$'*""3 C*'*.* '3/0./. 0/)03.' $)0.1*)/5$0##*0#.30)*0 *0#./ Wizard of Oz dialogue map © Mapr.com. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use."
666	" / %$ &%#&,  5$''/0#0)*0*)'7*"".,#/,03. .'1*)/#$,/$)*))0)05*.&/* '()0/<0#7 '/*/3,,*.0$) .)*)0#*//0.303./ W $)$)""/-3)/* '$)&/05)'()0/D$/0#. ,0# .*(0* W $)$)""0#'/06,)/$4,0#05)'()0/E& /#*.0/0,0#,.*'(F W .11*)$)""0#"".,#$)0*/0/* *))0'()0/ E&"".,#,.11*),.*'(F W $)$)""0#(*/0 $)0570*/,.0/0/*  *))0'()0/E&0#($)C30B(6C *5,.*'(F Q>KKKM N T"
667	%$  #%/-&  !-%// Q>KKKM N LK 0DSLPDJHVRXUFHXQNQRZQ$OOULJKWVUHVHUYHG7KLVFRQWHQWLVH[FOXGHGIURPRXU&UHDWLYH &RPPRQVOLFHQVH)RUPRUHLQIRUPDWLRQVHHKWWSV RFZPLWHGXKHOSIDTIDLUXVH
668	"*"" % '# &   *'.*/7/0(3/$)""$"".,# W */=,*$)0/5#..*/)*.(0 W ""/=*))1*)/05),*$)0/ W #""#/5$""#0 W 6,01(0*""0 .*(/*3.)*0*/1)1*))* *.0#0"" W $/0)05)/*3.)/1)1*))*/ W 4.""/,* 0.4'05)/*3.)/1)1*))*/  *'4"".,#*,1($81*),.*'( W #*.0/05$""#0,0#05)(7#*3/)(7*  LL Q>KKKM N  ,PDJHVVRXUFHVXQNQRZQ$OOULJKWVUHVHUYHG7KLVFRQWHQWLVH[FOXGHGIURPRXU &UHDWLYH &RPPRQVOLFHQVH)RUPRUHLQIRUPDWLRQVHHKWWSV RFZPLWHGXKHOSIDTIDLUXVH"
669	" %&'$#%'&# %$  #%/  .$""/* +)$""/."" ELRNPF  *//$'0*0& 5'&0#0 0.4.//#*  0#R.$""/ 60'7*); 0DSLPDJHVRXUFHXQNQRZQ$OOULJKWVUHVHUYHG7KLVFRQWHQWLVH[FOXGHGIURPRXU&UHDWLYH &RPPRQVOLFHQVH)RUPRUHLQIRUPDWLRQVHHKWWSV RFZPLWHGXKHOSIDTIDLUXVH Q>KKKM N LM"
670	"#"" %, %5& #  #$/'))*  #.$"")3)$.0""  *'/0.0/57$..'4)00$'/ W $8* $/')/ W )""0#* .$""/  /0#.,0#0#0*)0$)/#""60'7*); W   Q>KKKM N LN"
671	"!$ !""("" "",& ""  %$ &  3$'$)"""".,#/ W */ W ""/ W 10#$)""0*""0#.0*(&"".,#/  /$)"""".,#/ W .#$)"" *.,0#/05))*/ W .#$)"" *.*,1(',0#/05))*/ Q>KKKM N LO"
672	" && # class Node(object): def __init__(self, name): """"""Assumes name is a string"""""" self.name = name def getName(self): return self.name def __str__(self): return self.name Q>KKKM N LP"
673	" &&  class Edge(object): def __init__(self, src, dest): """"""Assumes src and dest are nodes"""""" self.src = src self.dest = dest def getSource(self): return self.src def getDestination(self): return self.dest def __str__(self): return self.src.getName() + '->’\\ + self.dest.getName() Q>KKKM N LQ"
674	"#!!#""$%&""'(#""&# %$ &  $"".,#$/$.0"".,# W ""/,//$)*)$.1*)*)'7  %)7(0.$6 W *5/=/*3.)*/ W *'3()/=/1)1*))*/ W ''G/<HUL$ 0#.$/)"" .*(/0* UK*0#.5$/ W *00#0$)$"".,#<(0.$6$/ /7((0.$  %)7'$/0 W //*$05$0##)*'$/0* /1)1*))*/ Q>KKKM N LR"
675	" && %$ 3$%'9 class Digraph(object): """"""edges is a dict mapping each node to a list of its children""""” def __init__(self): self.edges = {} def addNode(self, node): if node in self.edges: raise ValueError('Duplicate node') else: self.edges[node] = [] def addEdge(self, edge): src = edge.getSource() dest = edge.getDestination() if not (src in self.edges and dest in self.edges): raise ValueError('Node not in graph') self.edges[src].append(dest) Q>KKKM N LS mapping each node list"
676	 && %$ 3$%': def childrenOf(self, node): return self.edges[node] def hasNode(self, node): return node in self.edges def getNode(self, name): for n in self.edges: if n.getName() == name: return n raise NameError(name) def __str__(self): result = '' for src in self.edges: for dest in self.edges[src]: result = result + src.getName() + '->'\\ + dest.getName() + '\\n' return result[:-1] #omit final newline Q>KKKM N LT
677	" && %$ class Graph(Digraph): def addEdge(self, edge): Digraph.addEdge(self, edge) rev = Edge(edge.getDestination(), edge.getSource()) Digraph.addEdge(self, rev)  .,#*/)*0#4$.1*)'$07//*$05$0#)"" W ""/''*5,//""$)$0#.$.1*)  #7$/.,#/3'//* $"".,#;  ((.0#/3/1031*).3'; W '$)0*5*.&/*..0'73/$)"")$)/0)* 0# /3,.07,<$0/#*3''/*5*.&*..0'75#))$)/0)*  0#/307,$//3/1030 *.0#$)/0)* 0#/3,.07,  )7,.*"".(0#05*.&/5$0#$"".,#5$'''/*5*.&5$0# .,#E30)*0F Q>KKKM N MK"
678	" &&  %$ $(! 0(#""%# !  #*.0/0,0# .*()L0*)M W #*.0/0/-3)* ""//3#0#0 W *3.)**  ./0""$/)L W /1)1*)* '/0""$/)M W *.""/<L)M<$)0#/-3)<$ M *''*5/L$)0# /-3)<0#/*3.* M$/0#/1)1*)* L  #*.0/05$""#0,0# W $)$($80#/3(* 0#5$""#0/* 0#""/$)0#,0# Q>KKKM N ML"
679	"#! #%'&'' %# !&  $)$)"".*30 .*(*)$070*)*0#.  /$"")$)""*((3)$1*))05*.&/  $)$)"",0# *.(*'3'0#.*3""##($' '7.$)0#  ? Q>KKKM N MM ,PDJHVVRXUFHVXQNQRZQ$OOULJKWVUHVHUYHG7KLVFRQWHQWLVH[FOXGHGIURPRXU&UHDWLYH &RPPRQVOLFHQVH)RUPRUHLQIRUPDWLRQVHHKWWSV RFZPLWHGXKHOSIDTIDLUXVH"
680	"                    ! !  ""  "" # $ # $ #% & '(   '(     '    '!( "" !' ""(   # $'  ""'"
681	, '  %$ def buildCityGraph(graphType): g = graphType() for name in ('Boston', 'Providence', 'New York', 'Chicago', 'Denver', 'Phoenix', 'Los Angeles'): #Create 7 nodes g.addNode(Node(name)) g.addEdge(Edge(g.getNode('Boston'), g.getNode('Providence'))) g.addEdge(Edge(g.getNode('Boston'), g.getNode('New York'))) g.addEdge(Edge(g.getNode('Providence'), g.getNode('Boston'))) g.addEdge(Edge(g.getNode('Providence'), g.getNode('New York'))) g.addEdge(Edge(g.getNode('New York'), g.getNode('Chicago'))) g.addEdge(Edge(g.getNode('Chicago'), g.getNode('Denver'))) g.addEdge(Edge(g.getNode('Chicago'), g.getNode('Phoenix'))) g.addEdge(Edge(g.getNode('Denver'), g.getNode('Phoenix'))) g.addEdge(Edge(g.getNode('Denver'), g.getNode(’New York'))) g.addEdge(Edge(g.getNode('Los Angeles'), g.getNode('Boston'))) Q>KKKM N MO
682	" "" "" '  #%'&''  '""*.$0#(L<,0#C ./0/.#EF  $($'.0*'!C ./0,0#C ./0(0#** )3(.1)"" /.#0.E 03.MF  $)$ .)$/0#0"".,#($""#0#47'/</*5 (3/0&,0.&* 5#0)*/5#44$/$00*4*$ ""*$)""$)$) )$0'**,/ Q>KKKM N MP *00#05.3/$)""$4$C)C*)-3.=$ 5) ),0# .*(/*3.0*)$)0.($0)*<),0# .*(0# $)0.($0)*0*0#/1)1*)<0#*($)1*)$/,0# .*(/*3.0*/1)1*)"
683	"$'  %&'%  0.00)$)$1')*  *)/$.''0#""/0#0'40#0)*<$)/*( *..  *''*50# ./0""<)#&0*/$ 0""*')*  )*0<.,00#,.*// .*()5)*  *)1)33)1'$0#. )""*')*<*..3)*30*  *,1*)/ W #).3)*30* *,1*)/<&0.&0*0#,.4$*3/)* )0.70#)60""<.,1)""0#$/,.*// Q>KKKM N MQ"
684	$'  %&'% 78 def DFS(graph, start, end, path, shortest, toPrint = False): path = path + [start] if toPrint: print('Current DFS path:', printPath(path)) if start == end: return path for node in graph.childrenOf(start): if node not in path: #avoid cycles if shortest == None or len(path) < len(shortest): newPath = DFS(graph, node, end, path, shortest, toPrint) if newPath != None: shortest = newPath elif toPrint: print('Already visited', node) return shortest def shortestPath(graph, start, end, toPrint = False): return DFS(graph, start, end, [], None, toPrint) '' .*( 0/.3./$*)/0.0,.*,.'7 5.,,. 3)1*)= shortestPath       Q>KKKM N MR
685	&' def testSP(source, destination): g = buildCityGraph(DiGraph) sp = shortestPath(g, g.getNode(source), g.getNode(destination) toPrint = True) if sp != None: print('Shortest path from', source, 'to', destination, 'is', printPath(sp)) else: print('There is no path from', source, 'to', destination) testSP('Boston', ’Chicago') Q>KKKM N MS
686	""".!$  Q>KKKM N MT */0*) */0*) .*4$) .*4$) 5*.& 5*.& #$""* #$""* )4. )4. #*)$6 #*)$6 */)""'/ */)""'/ %)7 $/0 */0*)=.*4$)<5*.& .*4$)=*/0*)<5*.& 5*.&=#$""* #$""*=)4.<#*)$6 )4.=#*)$6<5*.& */)""'/=*/0*) #*)$6="
687	",'$,'7  #'##&'#""8 3..)0,0#=#$""* 3..)0,0#=#$""*CV)4. 3..)0,0#=#$""*CV)4.CV#*)$6 3..)0,0#=#$""*CV)4.CV5*.& '.74$/$0#$""* 3..)0,0#=#$""*CV#*)$6 #.$/)*,0# .*(#$""*0**/0*) Q>KKKM N NK */0*) */0*) .*4$) .*4$) 5*.& 5*.& #$""* #$""* )4. )4. #*)$6 #*)$6 */)""'/ */)""'/"
688	",'$,'7#&'#""'# #"" .8 3..)0,0#=*/0*) 3..)0,0#=*/0*)CV.*4$) '.74$/$0*/0*) 3..)0,0#=*/0*)CV.*4$)CV5*.& 3..)0,0#=*/0*)CV.*4$)CV5*.&CV#$""* 3..)0,0#=*/0*)CV.*4$)CV5*.&CV#$""*CV)4. 3..)0,0#=*/0*)CV.*4$)CV5*.&CV#$""*CV)4.CV#*)$6*3),0# '.74$/$05*.& 3..)0,0#=*/0*)CV.*4$)CV5*.&CV#$""*CV#*)$6*3)/#*.0.,0# 3..)0,0#=*/0*)CV5*.& 3..)0,0#=*/0*)CV5*.&CV#$""* 3..)0,0#=*/0*)CV5*.&CV#$""*CV)4. 3..)0,0#=*/0*)CV5*.&CV#$""*CV)4.CV#*)$6*3)@/#*.0.A,0# '.74$/$05*.& 3..)0,0#=*/0*)CV5*.&CV#$""*CV#*)$6*3)/#*.0.,0# #*.0/0,0# .*(*/0*)0*#*)$6$/*/0*)CV5*.&CV#$""*CV)4.CV#*)$6 Q>KKKM N NL"
689	"%'  %&'%  0.00)$)$1')*  *)/$.''0#""/0#0'40#0)*<$)/*( *..  *''*50# ./0""<)#&0*/$ 0""*')*  )*0<0.70#)60"" .*(0#3..)0)*  *)1)33)1'$0#. )""*')*<*..3)*30*  *,1*)/ W #).3)*30* ""*,1*)/<(*40*)60)*0 /($/0) .*(/0.0<).,0 W #).3)*30* )**,1*)/<(*40*)60'4'$)0# "".,#E'')*/*)/0, 3.0#. .*(/0.0F<).,0 Q>KKKM N NM"
690	" #% ' !:4%' 6%&'% 78 def BFS(graph, start, end, toPrint = False): initPath = [start] pathQueue = [initPath] while len(pathQueue) != 0: #Get and remove oldest element in pathQueue tmpPath = pathQueue.pop(0) if toPrint: print('Current BFS path:', printPath(tmpPath)) lastNode = tmpPath[-1] if lastNode == end: return tmpPath for nextNode in graph.childrenOf(lastNode): if nextNode not in tmpPath: newPath = tmpPath + [nextNode] pathQueue.append(newPath) return None Q>KKKM N NN ; 6,'*.'',0#/5$0#)#*,/ *. 6,'*.$)"")7,0#5$0#(*.0#))#*,/"
691	",'$,'7#&'#""'# #"" .8 3..)0,0#=*/0*) 3..)0,0#=*/0*)CV.*4$) 3..)0,0#=*/0*)CV5*.& 3..)0,0#=*/0*)CV.*4$)CV5*.& 3..)0,0#=*/0*)CV5*.&CV#$""* 3..)0,0#=*/0*)CV.*4$)CV5*.&CV#$""* 3..)0,0#=*/0*)CV5*.&CV#$""*CV)4. 3..)0,0#=*/0*)CV5*.&CV#$""*CV#*)$6 #*.0/0,0# .*(*/0*)0*#*)$6$/*/0*)CV5*.&CV#$""*CV#*)$6 Q>KKKM N NO"
692	"3..)0,0#=*/0*) 3..)0,0#=*/0*)CV.*4$) 3..)0,0#=*/0*)CV5*.& 3..)0,0#=*/0*)CV.*4$)CV5*.& 3..)0,0#=*/0*)CV5*.&CV#$""* 3..)0,0#=*/0*)CV.*4$)CV5*.&CV#$""* 3..)0,0#=*/0*)CV5*.&CV#$""*CV)4. 3..)0,0#=*/0*)CV5*.&CV#$""*CV#*)$6 #*.0/0,0# .*(*/0*)0*#*)$6$/*/0*)CV5*.&CV#$""*CV#*)$6 */0*) */0*) .*4$) .*4$) 5*.& 5*.& #$""* #$""* )4. )4. #*)$6 #*)$6 */)""'/ */)""'/ ,'$,'7#&'#""'# #"" .8 Q>KKKM N NP *00#05 /&$,,0# 0#0.4$/$0/ )*"
693	" '#,' ' #%'&''  )00*($)$($80#/3(* 0#5$""#0/* 0#""/< )*00#)3(.* ""/  )/$'7(*$ 0**0#$/  ))*0</$)/#*.0/05$""#0,0#(7#4 (*.0#)0#($)$(3()3(.* #*,/ Q>KKKM N NQ"
694	"$  .,#/.**' W /0570*.0(*'* ()70#$)""/ W ,03..'1*)/#$,/(*)""*%0/ W )7$(,*.0)0,.*'(/),*//"".,# *,1($81*),.*'(/5'.7&)*5#*50*/*'4  ,0#C ./0).0#C ./0/.#.$(,*.0)0 '""*.$0#(/ W )3/0*/*'4()7,.*'(/ Q>KKKM N NR"
695	MIT OpenCourseWare https://ocw.mit.edu 6.0002 Introduction to Computational Thinking and Data Science Fall 2016 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
696	Lecture 14: Classification, Statistical Sins 6.0002 LECTURE 14 1
697	Announcements §Reading ◦ Chapter 21 §Course evaluations ◦ Online evaluation now through noon on Friday, December 16 §Will be making study code for final exam available later today 6.0002 LECTURE 14 2
698	Compare to KNN Results (from Monday) Average of 10 80/20 splits using KNN (k=3) Accuracy = 0.744 Sensitivity = 0.629 Specificity = 0.829 Pos. Pred. Val. = 0.728 Average of LOO testing using KNN (k=3) Accuracy = 0.769 Sensitivity = 0.663 Specificity = 0.842 Pos. Pred. Val. = 0.743 Average of 10 80/20 splits LR Accuracy = 0.804 Sensitivity = 0.719 Specificity = 0.859 Pos. Pred. Val. = 0.767 Average of LOO testing using LR Accuracy = 0.786 Sensitivity = 0.705 Specificity = 0.842 Pos. Pred. Val. = 0.754 Performance not much difference Logistic regression slightly better Logistic regression provides insight about variables 6.0002 LECTURE 14 3
699	Looking at F eature Weights model.classes_ = ['Died' 'Survived'] For label Survived Be wary of reading too C1 = 1.66761946545 much into the weights C2 = 0.460354552452 Features are often C3 = -0.50338282535 correlated age = -0.0314481062387 male gender = -2.39514860929 L1 regression tends to drive one variable to zero L2 (default) regression spreads weights across variables 6.0002 LECTURE 14 4
700	Correlated Features, a n Example §c1 + c2 + c3 = 1 ◦ I.e., values are not independent ◦ Is being in 1st class good, or being in the other classes bad? §Suppose we eliminate c1? 6.0002 LECTURE 14 5
701	Comparative Results Original Features Average of 20 80/20 splits LR Accuracy = 0.778 Sensitivity = 0.687 Specificity = 0.842 Pos. Pred. Val. = 0.755 model.classes_ = ['Died' 'Survived'] For label Survived C1 = 1.68864047459 C2 = 0.390605976351 C3 = -0.46270349333 age = -0.0307090135358 male gender = -2.41191131088 Modified Features Average of 20 80/20 splits LR Accuracy = 0.779 Sensitivity = 0.674 Specificity = 0.853 Pos. Pred. Val. = 0.765 model.classes_ = ['Died' 'Survived'] For label Survived C2 = -1.08356816806 C3 = -1.92251427055 age = -0.026056041377 male gender = -2.36239279331 6.0002 LECTURE 14 6
702	Changing the Cu toff Try p = 0.1 Try p = 0.9 Accuracy = 0.493 Accuracy = 0.656 Sensitivity = 0.976 Sensitivity = 0.176 Specificity = 0.161 Specificity = 0.984 Pos. Pred. Val. = 0.444 Pos. Pred. Val. = 0.882 6.0002 LECTURE 14 7
703	ROC (Receiver Operating Characteristic) 6.0002 LECTURE 14 8
704	Output 6.0002 LECTURE 14 9
705	There a re Th ree Ki nds of L ies LIES DAMNED LIES and STATISTICS 6.0002 LECTURE 14 10
706	Humans and Statistics Human Mind Statistics 6.0002 LECTURE 14 11 Image of brain © source unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.
707	Humans and Statistics “If you can't prove what you want to prove, demonstrate something else and pretend they are the same thing. In the daze that follows the collision of statistics with the human mind, hardly anyone will notice the difference.” – Darrell Huff 6.0002 LECTURE 14 12 Image of brain © source unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.
708	Anscombe’s Quartet §Four groups each containing 11 x, y pairs 6.0002 LECTURE 14 13
709	Summary Statistics §Summary statistics for groups identical ◦Mean x = 9.0 ◦Mean y = 7.5 ◦Variance of x = 10.0 ◦Variance of y = 3.75 ◦Linear regression model: y = 0.5x + 3 §Are four data sets really similar? 6.0002 LECTURE 14 14
710	Let’s Plot the Data Moral: Statistics about the data is not the same as the data Moral: Use visualization tools to look at the data itself 6.0002 LECTURE 14 15
711	Lying with Pictures 6.0002 LECTURE 14 16
712	Telling the Truth with Pictures Moral: Look carefully at the axes labels and scales 6.0002 LECTURE 14 17
713	Lying with Pictures Moral: Ask whether the things being compared are actually comparable 6.0002 LECTURE 14 18 Screenshot of Fox News © 20th / 21st Century Fox. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.
714	Garbage In, Garbage Out “On two occasions I have been asked [by members of Parliament], ‘Pray, Mr. Babbage, if you put into the machine wrong figures, will the right answers come out?’ I am not able rightly to apprehend the kind of confusion of ideas that could provoke such a question.” – Charles Babbage (1791-1871) 6.0002 LECTURE 14 19
715	Calhoun’s R esponse t o Errors i n Data “there were so many errors they balanced one another, and led to the same conclusion as if they were all correct.” Was it the case that the measurement errors are unbiased and independent of each of other, and therefore almost identically distributed on either side of the mean? No, later analysis showed that the errors were not random but systematic. “it was the census that was insane and not the colored people.”— James Freeman Clarke Moral: Analysis of bad data can lead to dangerous conclusions. 6.0002 LECTURE 14 20
716	Sampling §All statistical techniques are based upon the assumption that by sampling a subset of a population we can infer things about the population as a whole §As we have seen, if random sampling is used, one can make meaningful mathematical statements about the expected relation of the sample to the entire population §Easy to get random samples in simulations §Not so easy in the field, where some examples are more convenient to acquire than others 6.0002 LECTURE 14 21
717	Non-representative Sampling §“Convenience sampling” not usually random, e.g., ◦Survivor bias, e.g., course evaluations at end of course or grading final exam in 6.0002 on a strict curve ◦Non-response bias, e.g., opinion polls conducted by mail or online §When samples not random and independent, we can still do things like computer means and standard deviations, but we should not draw conclusions from them using things like the empirical rule and central limit theorem. §Moral: Understand how data was collected, and whether assumptions used in the analysis are satisfied. If not, be wary. 6.0002 LECTURE 14 22
718	MIT OpenCourseWare https://ocw.mit.edu 6.0002 Introduction to Computational Thinking and Data Science Fall 2016 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
719	Lecture 5: Random Walks 6.0002 LECTURE 5 1
720	Relevant Reading §Chapter 11 §Chapter 14 6.0002 LECTURE 5 2
721	Why Random Walks? §Random walks are important in many domains ◦Understanding the stock market (maybe) ◦Modeling diffusion processes ◦Etc. §Good illustration of how to use simulations to understand things §Excuse to cover some important programming topics ◦Practice with classes ◦Practice with plotting 6.0002 LECTURE 5 3
722	Drunkard’s Walk 6.0002 LECTURE 5 4
723	One Possible First Step 6.0002 LECTURE 5 5
724	Another Possible First Step 6.0002 LECTURE 5 6
725	Yet Another Possible First Step 6.0002 LECTURE 5 7
726	Last Possible First Step 6.0002 LECTURE 5 8
727	Possible Distances After Two Steps 6.0002 LECTURE 5 9
728	Expected Distance After 100,000 Steps? §Need a differentapproachto problem §Will use simulation 6.0002 LECTURE 5 10
729	Structure of Simulation §Simulate one walks of k steps §Simulate n such walks §Report average distance from origin 6.0002 LECTURE 5 11
730	First, Some Useful Abstractions §Location—a place §Field—a collection of places and drunks §Drunk—somebody who wanders from place to place in a field 6.0002 LECTURE 5 12
731	"Class Location, part 1 class Location(object): Immutable type def __init__(self, x, y): """"""x and y are floats"""""" self.x = x self.y = y def move(self, deltaX, deltaY): """"""deltaX and deltaY are floats"""""" return Location(self.x + deltaX, self.y + deltaY) def getX(self): return self.x def getY(self): return self.y 6.0002 LECTURE 5 13"
732	Class Location, continued def distFrom(self, other): xDist = self.x - other.getX() yDist = self.y - other.getY() return (xDist**2 + yDist**2)**0.5 def __str__(self): return '<' + str(self.x) + ', '\\ + str(self.y) + '>' 6.0002 LECTURE 5 14
733	"Class Drunk class Drunk(object): def __init__(self, name = None): """"""Assumes name is a str"""""" self.name = name def __str__(self): if self != None: return self.name return 'Anonymous' Not intended to be useful on its own A base class to be inherited 6.0002 LECTURE 5 15"
734	Two Subclasses of Drunk §The “usual” drunk, who wanders around at random §The “masochistic” drunk, who tries to move northward 6.0002 LECTURE 5 16
735	Two Kinds of Drunks import random class UsualDrunk(Drunk): def takeStep(self): stepChoices = [(0,1), (0,-1), (1, 0), (-1, 0)] return random.choice(stepChoices) class MasochistDrunk(Drunk): def takeStep(self): stepChoices = [(0.0,1.1), (0.0,-0.9), (1.0, 0.0), (-1.0, 0.0)] return random.choice(stepChoices) Immutable or not? 6.0002 LECTURE 5 17
736	Class Field, part 1 class Field(object): def __init__(self): self.drunks = {} def addDrunk(self, drunk, loc): if drunk in self.drunks: raise ValueError('Duplicate drunk') else: self.drunks[drunk] = loc def getLoc(self, drunk): if drunk not in self.drunks: raise ValueError('Drunk not in field') return self.drunks[drunk] 6.0002 LECTURE 5 18
737	Class Field, continued def moveDrunk(self, drunk): if drunk not in self.drunks: raise ValueError('Drunk not in field') xDist, yDist = drunk.takeStep() #use move method of Location to get new location self.drunks[drunk] =\\ self.drunks[drunk].move(xDist, yDist) Immutable or not? 6.0002 LECTURE 5 19
738	"Simulating a Single Walk def walk(f, d, numSteps): """"""Assumes: f a Field, d a Drunk in f, and numSteps an int >= 0. Moves d numSteps times; returns the distance between the final location and the location at the start of the walk."""""" start = f.getLoc(d) for s in range(numSteps): f.moveDrunk(d) return start.distFrom(f.getLoc(d)) 6.0002 LECTURE 5 20"
739	"Simulating Multiple Walks def simWalks(numSteps, numTrials, dClass): """"""Assumes numSteps an int >= 0, numTrials an int > 0, dClass a subclass of Drunk Simulates numTrials walks of numSteps steps each. Returns a list of the final distances for each trial"""""" Homer = dClass() origin = Location(0, 0) distances = [] for t in range(numTrials): f = Field() f.addDrunk(Homer, origin) distances.append(round(walk(f, Homer, numTrials), 1)) return distances 6.0002 LECTURE 5 21"
740	"Putting It All Together def drunkTest(walkLengths, numTrials, dClass): """"""Assumes walkLengths a sequence of ints >= 0 numTrials an int > 0, dClass a subclass of Drunk For each number of steps in walkLengths, runs simWalks with numTrials walks and prints results"""""" for numSteps in walkLengths: distances = simWalks(numSteps, numTrials, dClass) print(dClass.__name__, 'random walk of', numSteps, 'steps') print(' Mean =', round(sum(distances)/len(distances), 4)) print(' Max =', max(distances), 6.0002 LECTURE 5 22 'Min =', min(distances))"
741	Let’s Try It drunkTest((10, 100, 1000, 10000), 100, UsualDrunk) UsualDrunk random walk of 10 steps Mean = 8.634 Max = 21.6 Min = 1.4 UsualDrunk random walk of 100 steps Mean = 8.57 Max = 22.0 Min = 0.0 UsualDrunk random walk of 1000 steps Mean = 9.206 Max = 21.6 Min = 1.4 UsualDrunk random walk of 10000 steps Mean = 8.727 Max = 23.5 Min = 1.4 Plausible? 6.0002 LECTURE 5 23
742	Let’s Try a Sanity Check §Try on cases where we think we know the answer ◦ A very important precaution! 6.0002 LECTURE 5 24
743	Sanity Check drunkTest((0, 1, 2) 100, UsualDrunk) UsualDrunk random walk of 0 steps Mean = 8.634 Max = 21.6 Min = 1.4 UsualDrunk random walk of 1 steps Mean = 8.57 Max = 22.0 Min = 0.0 UsualDrunk random walk of 2 steps Mean = 9.206 Max = 21.6 Min = 1.4 distances.append(round(walk(f, Homer, numTrials), 1)) 6.0002 LECTURE 5 25
744	Let’s Try It drunkTest((10, 100, 1000, 10000), 100, UsualDrunk) UsualDrunk random walk of 10 steps Mean = 2.863 Max = 7.2 Min = 0.0 UsualDrunk random walk of 100 steps Mean = 8.296 Max = 21.6 Min = 1.4 UsualDrunk random walk of 1000 steps Mean = 27.297 Max = 66.3 Min = 4.2 UsualDrunk random walk of 10000 steps Mean = 89.241 Max = 226.5 Min = 10.0 6.0002 LECTURE 5 26
745	And the Masochistic Drunk? random.seed(0) simAll((UsualDrunk, MasochistDrunk), (1000, 10000), 100) UsualDrunk random walk of 1000 steps Mean = 26.828 Max = 66.3 Min = 4.2 UsualDrunk random walk of 10000 steps Mean = 90.073 Max = 210.6 Min = 7.2 MasochistDrunk random walk of 1000 steps Mean = 58.425 Max = 133.3 Min = 6.7 MasochistDrunk random walk of 10000 steps Mean = 515.575 Max = 694.6 Min = 377.7 6.0002 LECTURE 5 27
746	Visualizing the Trend §Simulate walks of multiple lengths for each kind of drunk §Plot distance at end of each length walk for each kind of drunk 6.0002 LECTURE 5 28
747	Pylab §NumPy adds vectors, matrices, and many high-level mathematical functions §SciPy adds mathematical classes and functions useful to scientists §MatPlotLib adds an object-oriented API for plotting §PyLab combines the other libraries to provide a MATLAB- like interface ® 6.0002 LECTURE 5 29 ââ
748	plot §The first two arguments to pylab.plot must be sequences of the same length. §First argument gives x-coordinates. §Second argument gives y-coordinates. §Many optional arguments §Points plotted in order. In default style, as each point is plotted, a line is drawn connecting it to the previous point. 6.0002 LECTURE 5 30
749	6.0002 LECTURE 5 31 Example import pylab xVals = [1, 2, 3, 4] yVals1 = [1, 2, 3, 4] pylab.plot(xVals, yVals1, 'b-', label = 'first') yVals2 = [1, 7, 3, 5] pylab.plot(xVals, yVals2, 'r--', label = 'second') pylab.legend()
750	Details and Many More Examples §Assigned reading §Video of Prof. Grimson’s lecture from 6.00x.1 §Code for this lecture §matplotlib.org/api/pyplot_summary.html §www.scipy.org/Plotting_Tutorial You should learn how to produce the plots that I will show you 6.0002 LECTURE 5 32
751	Distance Trends 6.0002 LECTURE 5 33
752	Ending Locations 6.0002 LECTURE 5 34
753	Fields with Wormholes 6.0002 LECTURE 5 35
754	A Subclass of Field, part 1 class OddField(Field): def __init__(self, numHoles = 1000, xRange = 100, yRange = 100): Field.__init__(self) self.wormholes = {} for w in range(numHoles): x = random.randint(-xRange, xRange) y = random.randint(-yRange, yRange) newX = random.randint(-xRange, xRange) newY = random.randint(-yRange, yRange) newLoc = Location(newX, newY) self.wormholes[(x, y)] = newLoc 6.0002 LECTURE 5 36
755	A Subclass of Field, part 2 def moveDrunk(self, drunk): Field.moveDrunk(self, drunk) x = self.drunks[drunk].getX() y = self.drunks[drunk].getY() if (x, y) in self.wormholes: self.drunks[drunk] = self.wormholes[(x, y)] 6.0002 LECTURE 5 37
756	Spots Reached During One Walk 6.0002 LECTURE 5 38
757	Summary §Point is not the simulations themselves, but how we built them §Started by defining classes §Built functions corresponding to ◦ One trial, multiple trials, result reporting §Made series of incremental changes to simulation so that we could investigate different questions ◦ Get simple version working first ◦ Did a sanity check! ◦ Elaborate a step at a time §Showed how to use plots to get insights 6.0002 LECTURE 5 39
758	MIT OpenCourseWare https://ocw.mit.edu 6.0002 Introduction to Computational Thinking and Data Science Fall 2016 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
759	                        
760	         
761	"                 !""#""$""#""#""#%""  &  "" '(  )  *"" '  "" ) (""  +""   !,   (  ) ""  *  ' ) -'""     -')    '  !+ .( ' ""/0 ) 1'  !+ ' ""/02'1    $"
762	"!      ""  3& '/1 ' +. &   0  ' & . 4   0  0   . '  & (  &  * .(  &'5 !                 36' 7 898:  ! '     .&2 '""  * 0  & '/-1 !+  2)   *     6.0002 LECTURE 11 Slide "
763	"!      ""  64  .   .;)*    6.0002 LECTURE 11 Slide"
764	"#$ %    "" ' <(  !3'(  &   & =( 0   !' )* ! '  ) & !' *  & ><(  !=  && '  & +'( 0   !' )** &  (   !(* ( ( * !3' & + -   '& && '( & '?  6.0002 LECTURE 11 Slide "
765	&  '    6(  ( (   @)  &-'5 ' ' & +& ')      A * '     & '0 ( )   *  5  ,  '&    6.0002 LECTURE 11 Slide 
766	" @)  &-'5   +& ')      & '0 ( )   *  5   B(   ' ! 6  5  &&C)"".   )     *  !   5  &&  7   ): ' /17  )&  : &  '    6.0002 LECTURE 11 Slide  A )*"") )*  ( ""     A  '  &  ( "")*(( ,  (  &  *"
767	" D '  E  ,  ! E'""""  ! ) )** & (    5 !  'FGH 'H""%""I !  FGH H""%$"" I !  0 0FGH 0 0H""%#""9I ! ' FGH' H""% "" 8I ! )?FGH)?H""%#""%9I  '5 !  FGH H""%%""$$9I !   FGH  H""#""$9I ! ' FGH' H""%$""$ I ! *FGH*H""%%""$9I ! 0FGH0H""%""$9I  (     )       J"
768	* +        K
769	" L    /'*1 &-'""   &(  (""/1""  ! 6'* '  6  0 0 M   "") N0 )70F: ! ,00'7 'O:-' ! '')*''<  ) ''7 )P( &( :  '   -' ! A ' -' -' ! (   (         Q"
770	 ) &   !     $
771	 ) &   #     R
772	"  $  * & %,+     9 +&     M & )P"" )"
773	   !   +      S
774	" > )  &""  .  )&  ! 6)P    '-* &)&  +-'"" ="" . 7     &':)     L-'  ""T     L-')   ""'*     M& (  &(  - .       U"
775	"   !   +      V >    )  "" )    &    "
776	" 6        '  E    ')0""    '    &*' 0   ' ! blount = ['blount', 72, 250] ! white = ['white', 70, 205] %  /$       W"
777	%  /$       QJ
778	  * +         
779	.   +        Q
780	" L  '-' &' ' 5  ' )  )  "")*     &)*  ! ()     ' )   &' & '   ! * ) ) &* ""  / .;1 ! X'0      M/&  ( 1 /&( 1 ! (.)            Y"
781	     ( '   (  &&  ='& &    @)P( &(     @('<( ' & '  %   0 1 6.0002 LECTURE 11 Slide 2 * E- 0
782	" A &* )(  ! /3'   "") '&1 > X - A ! -')*&   & <(  ! 6 +   -'& '  ""  &)P""   3 ! 6 '&*&"""">,3""  '' -7 &  : ! @''  ."""")' ""*    L '-'<(  &&   ! 62 2E  ( 76E : -     6.0002 LECTURE 11 Slide 2"
783	                )      Z ?0      Z X     A  A   Z 0   A A  E  3    A  R Z =&   A  A R E  6'    A   E  ,*    A   Z % (      S Features Label +(' 5 • E  & '(  <
784	                )      Z ?0      Z X     A  A   Z 0   A A  E  3    A  R Z =&   A  A R E  6'    A   E  ,*    A   Z % (      U Features Label +(' 5 • * • D • +    •  )   • E 
785	"                )      Z ?0      Z X     A  A   Z 0   A A  E  3    A  R Z =&   A  A R E  6'    A   E  ,*    A   Z % (      V Features Label +(' 5 • * • D • +    •  )   • E  ' 5 • D •  )   • E  X  N.' ""))  ( E  .' "
786	                )      Z ?0      Z X     A  A   Z 0   A A  E  3    A  R Z =&   A  A R E  6'    A   E  ,*    A   Z % (      W Features Label ' 5 • D •  )   • E 
787	"                )      Z ?0      Z X     A  A   Z 0   A A  E  3    A  R Z =&   A  A R E  6'    A   E  ,*    A   Z % (     YJ Features Label ' 5 • D •  )   • E  ' 5 • D •  )   • D R 3  N.' "") ) ( E  .' "
788	                )      Z ?0      Z X     A  A   Z 0   A A  E  3    A  R Z =&   A  A R E  6'    A   E  ,*    A   Z % (      $K Features Label ' 5 • D •  )   • D R
789	                )      Z ?0      Z X     A  A   Z 0   A A  E  3    A  R Z =&   A  A R E  6'    A   E  ,*    A   Z % (      $ Features Label ' 5 • D •  )   • D R E 7*: *     *&* '  * 7 (& :   [Q
790	"                )      Z ?0      Z X     A  A   Z 0   A A  E  3    A  R Z =&   A  A R E  6'    A   E  ,*    A   Z % (      $Y Features Label > ' 5 • D •  )   E &"") &( 7*.   ( *) :\\ '& (  7'* *) ''(: =&   A  A R E  6'    A   E  ,  A   Z"
791	" A5 ! =  &    '*    . ! =.  ' )  -'7 ('*) .   : ! =    ( '  & M '  &&  "" ' .(  &  /       +$ -      $["
792	" L0 & '-' ( & & )*&  &  @ *  (& ' 2 ( ' )  & -'"" 5 ! )*-'  ''  7)  :""  ! . .& &-' ('* M7) : (  & -'& '  (       &$ %                 6.0002 LECTURE 11 Slide 3   -'  &  "
793	2$2   len dist X X p = ∑abs X k −X k p  p k= p = 1: Manhattan Distance p = 2: Euclidean Distance 6.0002 LECTURE 11 Slide 3 E  ' )  &       O      # 6 $ ?=  R +   •  • • •  •  • 62$ **  '\\?'* ) & M '    ')
794	      &$ %                6.0002 LECTURE 11 Slide 3 Images of rattlesnake, dart frog, boa constrictor © sources unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.
795	"      &$ %                6.0002 LECTURE 11 Slide 3   ""?0 )    '   ""*   & "
796	 alligator = Animal('alligator', [1,1,0,1,4])  animals.append(alligator)  compareAnimals(animals, 3) %  %    6.0002 LECTURE 11 Slide 3 Image of alligator © source unknown. All rights reserved. This content is excluded from our Creative Commons license. For more information, see https://ocw.mit.edu/help/faq-fair-use/.
797	" alligator = Animal('alligator', [1,1,0,1,4])  animals.append(alligator)  compareAnimals(animals, 3) %  %   6.0002 LECTURE 11 Slide  3    &  0  *O • 3  M& '& $&""& ')  *& • X /1& ' R""  &   • /1 '    ( *  0 *O"
798	* & ) -                       6.0002 LECTURE 11 Slide 4 Feature Engineering Matters E    0  &  '0' 
799	" +-& ""  -' &  '5  L )  ""* .  & -'  !    & .(  &  ! E       L )  ""''(& /)1) -'"")P    '-* &&7 N .: ! E    )   (  &&    )*.&  3 3 *3       RQ"
800	" '     5  =') -'    &&      '-* &'  ! 6. ') & ! '-* &(& ! L    .; )'7-' ""  '-(&:     !        RY"
801	" 6  0 0 M   "") N0 ) ! ,00'7 'O:-' ! '')*''<  ) ''7 )P( &( :  '   -' ! A ' -' -' ! (   +5 ! D      )') &O ! D   )&"")  'O        R["
802	  * +        R9
803	-4   *3     R
804	" L . )  & M &) -' !  0& '&7) :  !  0& '  '-&7)P  :  !  (' ! A 0-'""'P *  )   +5 ! D      2.;  O ! D   '& 'O ! D   )&O .        RU"
805	" 3?' ''<    ! 6' .;         .   6.0002 LECTURE 11 Slide 4 B &"" )*  & ' X  "
806	 ) 3          6.0002 LECTURE 11 Slide 4
807	$ '+         6.0002 LECTURE 11 Slide 
808	    5   6 6.0002 LECTURE 11 Slide 5
809	 %& ) '  ! L)?O   . '   O   %  )    6.0002 LECTURE 11 Slide 5
810	"%   (   6.0002 LECTURE 11 Slide 5  ! ""  # ! $ %&  ""'#$ $()##"
811	% )       6.0002 LECTURE 11 Slide 5  * ! *  * ! ) %&  )'#$ $(+
812	"               6  ' 59%  = ' 59#  '-' ""5%   '-' ""(5%#  Z   /( *1 /.*1 ,         &    ,           9]  *  * P "
813	" '    * &)  '  & & '  ! 6  )  ""  . ('*  0  !    & ))* -' )*     &&^    & '') -' ^  L  '-' &' "" 02'  L  '-' &.""0 ) '   )     9S"
814	MIT OpenCourseWare https://ocw.mit.edu 6.0002 Introduction to Computational Thinking and Data Science Fall 2016 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
815	        
816	         !         
817	"    !  dist, numSamples = [], 1000000 for i in range(numSamples): dist.append(random.gauss(0, 100)) weights = [1/numSamples]*len(dist) v = pylab.hist(dist, bins = 100, weights = [1/numSamples]*len(dist)) pylab.xlabel('x') pylab.ylabel('Relative Frequency') print('Fraction within ~200 of mean =', sum(v[0][30:70]))   """
818	""" $% &''( )$* Fraction within ~200 of mean = 0.957147   #"
819	$  +    )$*! ) + ,  +-.. ,  $ % ,., (/(  . ( ,  ,  & % ,..'0' +  ('   -.- # $%& '   1
820	def gaussian(x, mu, sigma): factor1 = (1.0/(sigma*((2*pylab.pi)**0.5))) factor2 = pylab.e**-(((x-mu)**2)/(2*sigma**2)) return factor1*factor2 xVals, yVals = [], [] mu, sigma = 0, 1 x = -4 while x <= 4: xVals.append(x) yVals.append(gaussian(x, mu, sigma)) x += 0.05 pylab.plot(xVals, yVals) pylab.title('Normal Distribution, mu = ' + str(mu)\\ + ', sigma = ' + str(sigma)) # $   !              
821	"""   &, +/( ' 2 + 30,,  %  ,   % 4%.  - ')$*"
822	5%)+ +%+  %  % +%- %'+-6   '  -  7  %- 7  '- .  -0 7  '- ''  -0  7 '  '  '' +-,   - 0 (%' 0  %- %'+-6    '  7 &''(  7        8
823	() (   import scipy.integrate def gaussian(x, mu, sigma) … def checkEmpirical(numTrials): for t in range(numTrials): mu = random.randint(-10, 10) sigma = random.randint(1, 10) print('For mu =', mu, 'and sigma =', sigma) for numStd in (1, 1.96, 3): area = scipy.integrate.quad(gaussian, mu-numStd*sigma, mu+numStd*sigma, (mu, sigma))[0] print(' Fraction within', numStd, 'std =', round(area, 4))   9
824	" * :9-: *%. :8 *%.9 :91 *%."" :99 "" * :/-:1 *%. :8 *%.9 :91 *%."" :99 "" * :-: *%. :8 *%.9 :91 *%."" :99 ""   "
825	;%%  < =%%  '' ! )  !    
826	'% .>    ?  % '  .   + 2 =0+   +  7 % %6  +'  50.+'%  .>2 *  !     
827	"?% .-  - '0      ' &%   ''  +( (  + ),   """
828	" , % + -' @ !  '  '   ' !. ''( + +  0 !   . ,%   '' 0 ""! ,% ' . %  ,% '' ,+'   -(  -( & -'   #"
829	()  -      def plotMeans(numDice, numRolls, numBins, legend, color, style): means = [] for i in range(numRolls//numDice): vals = 0 for j in range(numDice): vals += 5*random.random() means.append(vals/float(numDice)) pylab.hist(means, numBins, color = color, label = legend, weights = pylab.array(len(means)*[1])/len(means), hatch = style) return getMeanAndStd(means) mean, std = plotMeans(1, 1000000, 19, '1 die', 'b', '*') print('Mean of rolling 1 die =', str(mean) + ',', 'Std =', std) mean, std = plotMeans(50, 1000000, 19, 'Mean of 50 dice', 'r', '//') print('Mean of rolling 50 dice =', str(mean) + ',', 'Std =', std) pylab.title('Rolling Continuous Dice') pylab.xlabel('Value') pylab.ylabel('Probability') pylab.legend()   1
830	"""    A  -:#9 191 11805 :##""9#1"""" A  -1%:#99811 9805 :#88  ##1"
831	-   numTrials = 1000000 numSpins = 200 game = FairRoulette() means = [] for i in range(numTrials): means.append(findPocketReturn(game, 1, numSpins, False)[0]) pylab.hist(means, bins = 19, weights = [1/len(means)]*len(means)) pylab.xlabel('Mean Return') pylab.ylabel('Probability') pylab.title('Expected Return Betting a Pocket 200 Times')   
832	* # ) $    8
833	3B.'    , '' 3 .+- ''  - % + -'      .  '%  . %' -% %,  .    9
834	Pi 6.0002 LECTURE 7 21 circumference diameter = Π area = Π*radius2
835	"(  #    # 8C9! :"" Image of the Rhind Papyrus is in the public domain. Source: Wikimedia Commons."
836	"/00112 “And he made a molten sea, ten cubits from the one brim to the other: it was round all about, and his height was five cubits: and a line of thirty cubits did compass it round about.” —1 Kings 7.23   """
837	"/3112&(' ""C D'DC   #"
838	/41112&* 5'   1 & :E:# &% :F :F                                       
839	/4112    '@CC...+  %C.%2,:GAA3HI83G
840	6  6   
841	7 * 5.(  def throwNeedles(numNeedles): inCircle = 0 for Needles in range(1, numNeedles + 1, 1): x = random.random() y = random.random() if (x*x + y*y)**0.5 <= 1.0: inCircle += 1 return 4*(inCircle/float(numNeedles))   8
842	7 * 5.( 8 9 def getEst(numNeedles, numTrials): estimates = [] for t in range(numTrials): piGuess = throwNeedles(numNeedles) estimates.append(piGuess) sDev = stdDev(estimates) curEst = sum(estimates)/len(estimates) print('Est. = ' + str(curEst) +\\ ', Std. dev. = ' + str(round(sDev, 6))\\ + ', Needles = ' + str(numNeedles)) return (curEst, sDev)   9
843	"7 * 5.( 8 9 def estPi(precision, numTrials): numNeedles = 1000 sDev = precision while sDev >= precision/2: curEst, sDev = getEst(numNeedles, numTrials) numNeedles *= 2 return curEst estPi(0.005, 100)   """
844	""" Est. = 3.1484400000000012, Std. dev. = 0.047886, Needles = 1000 Est. = 3.1391799999999987, Std. dev. = 0.035495, Needles = 2000 Est. = 3.1410799999999997, Std. dev. = 0.02713, Needles = 4000 Est. = 3.141435, Std. dev. = 0.016805, Needles = 8000 Est. = 3.141355, Std. dev. = 0.0137, Needles = 16000 Est. = 3.1413137500000006, Std. dev. = 0.008476, Needles = 32000 Est. = 3.141171874999999, Std. dev. = 0.007028, Needles = 64000 Est. = 3.1415896874999993, Std. dev. = 0.004035, Needles = 128000 Est. = 3.1417414062499995, Std. dev. = 0.003536, Needles = 256000 Est. = 3.14155671875, Std. dev. = 0.002101, Needles = 512000   """
845	"= %' %-. =, ,% - 3%0 ,' . %  ,   *  (   ( -2   """
846	"91J .  0..  ,  '. """" #""8 18 1""#1 # 8 12 K' + 91%  ,    ."""" #""8 18 1""#1 # 8 12 ?  %  + %% ?   +     %                  7   """""
847	"  * def throwNeedles(numNeedles): inCircle = 0 for Needles in range(1, numNeedles + 1, 1): x = random.random() y = random.random() if (x*x + y*y)**0.5 <= 1.0: inCircle += 1 return 2*(inCircle/float(numNeedles))   ""#"
848	"  -0 7 )%>% --00 % + % %   %'  +. 7 )%> ' . 7 * % '  . 7 A ' + +* K+-   -( :   ""1"
849	"7 &;'   """
850	"  #     """
851	MIT OpenCourseWare https://ocw.mit.edu 6.0002 Introduction to Computational Thinking and Data Science Fall 2016 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
852	Lecture 15: Statistical Sins and Wrapup 6.0002 LECTURE 15 1
853	Announcements §Course evaluations ◦ Online evaluation now through noon on Friday, December 16 §Final exam on Monday! 6.0002 LECTURE 15 2
854	"                ! "" # $ !#$# % &   '$ $ $ $( )# #*   + $ , - Graph © National Review. All rights reserved. This content is excluded from our Creative Commons license. For more information, see http://ocw.mit.edu/help/faq-fair-use/"
855	";""<""& ,01 $="" ;/% !""###$% &'()*+' ,- R G.045S %)0/8C462% 6<2% @L 4F71% 6. %257D78462 P02P.1620./1% 345/21"""
856	">=""'? @$= '5A'7/58,/ '2,&6-09 G.045S %B.8M6 C.8K/12 K5/C6/467.81% ;76< 6028?1"" !""###$% &'()*+' ,- - (<.12%4 8% 78620345 C.81716286 %;76< P<28.D28.8% E278= %C.817?202?"""
857	But At Least the Ar ctic I ce I sn’t Melting “Yesterday, April 14th, the Arctic had more sea ice than it had on April 14,1989 – 14.511 million square kilometres vs 14.510 million square kilometres, according to the National Snow and Ice Data Center of the United States, an official source.” Lawrence Solomon, Financial Post, April 15, 2013 6.0002 LECTURE 15 6 Moral Cherry picking image © source unknown. All rights reserved. This content is excluded from our Creative Commons license. See https://ocw.mit.edu/help/faq-fair-use/.
858	A Comforting Statistic §99.8% of the firearms in the U.S. will not be used to commit a violent crime in any given year §How many privately owned firearms in U.S.? §~300,000,000 §300,000,000*0.002 = 600,000 6.0002 LECTURE 15 7
859	A Not So Comforting Statistic “Mexican health officials suspect that the swine flu outbreak has caused more than 159 deaths and roughly 2,500 illnesses.” CNN, April 29, 2009 How many deaths per year from seasonal flu in U.S.? About 36,000 6.0002 LECTURE 15 8
860	Relative to What? §Skipping lectures increases your probability of failing 6.0002 by 50% §From 0.5 to 0.75 §From 0.005 to 0.0075 §Moral: Beware of percentage change when you don’t know the denominator 6.0002 LECTURE 15 10
861	Cancer Cl usters §A cancer cluster is defined by the CDC as “a greater­ than-expected number of cancer cases that occurs within a group of people in a geographic area over a period of time” §About 1000 “cancer clusters” per year are reported to health authorities in the U.S. §Vast majority are deemed not significant 6.0002 LECTURE 15 11
862	A Hypothetical Example §Massachusetts is about 10,000 square miles §About 36,000 new cancer cases per year §Attorney partitioned state into 1000 regions of 10 squares miles each, and looked at distribution of cases ◦Expected number of cases per region: 36 §Discovered that region 111 had 143 new cancer cases over a 3 year period! ◦More than 32% greater than expected §How worried should residents be? 6.0002 LECTURE 15 12
863	How Likely Is it Just Bad Luck? 6.0002 LECTURE 15 13
864	How Likely Is it Just Bad Luck? A variant of cherry picking called multiple hypothesis testing 6.0002 LECTURE 15 14
865	The Bot tom Line §When drawing inferences from data, skepticism is merited. §But remember, skepticism and denial are different. §“Doubt, indulged and cherished, is in danger of becoming denial; but if honest, and bent on thorough investigation, it may soon lead to full establishment of the truth.” – Ambrose Bierce 6.0002 LECTURE 15 17
866	6.0002 Ma jor Topics §Optimization problems §Stochastic thinking §Modeling aspects of the world §Becoming a better programmer ◦Exposure to a few extra features of Python and some useful libraries ◦Practice, practice, practice 6.0002 LECTURE 15 18
867	Optimization Problems §Many problems can be formulated in terms of ◦Objective function ◦Set of constraints §Greedy algorithms often useful ◦But may not find optimal solution §Many optimization problems inherently exponential ◦But dynamic programming often works ◦And memoization a generally useful technique §Examples: knapsack problems, graph problems, curve fitting, clustering 6.0002 LECTURE 15 19
868	Stochastic Thinking §The world is (predictably) non-deterministic §Thinking in terms of probabilities is often useful §Randomness is a powerful tool for building computations that model the world §Random computations useful even when for problems that do not involve randomness ◦E.g., integration 6.0002 LECTURE 15 20
869	Modeling the World §Models always inaccurate ◦Provide abstractions of reality §Deterministic models, e.g., graph theoretic §Statistical models ◦Simulation models: Monte Carlo simulation ◦Models based on sampling ◦Characterizing accuracy is critical ◦Central limit theorem ◦Empirical rule ◦Machine learning ◦Unsupervised and supervised §Presentation of data ◦Plotting ◦Good and bad practices 6.0002 LECTURE 15 21
870	What’s Next f or You? §Many of you have worked very hard ◦Rest of the staff and I appreciate it §Only you know your return on investment ◦Take a look at early problem sets ◦Think about what you’d be willing tackle now §Remember that you can write programs to get answers §There are other CS courses you are prepared to take ◦6.009, 6.005, 6.006, 6.034 §Find and interesting UROP §Minor in CS §Major in CS 6.0002 LECTURE 15 22
871	MIT OpenCourseWare https://ocw.mit.edu 6.0002 Introduction to Computational Thinking and Data Science Fall 2016 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms.
872	Introduction to Algorithms: 6.006 Massachusetts Institute of Technology Instructors: Erik Demaine, Jason Ku, and Justin Solomon Lecture 9: Breadth-First Search Lecture 9: Breadth-First Search New Unit: Graphs! • Quiz 1 next week covers lectures L01 - L08 on Data Structures and Sorting • Today, start new unit, lectures L09 - L14 on Graph Algorithms Graph Applications • Why? Graphs are everywhere! • any network system has direct connection to graphs • e.g., road networks, computer networks, social networks • the state space of any discrete system can be represented by a transition graph • e.g., puzzle & games like Chess, Tetris, Rubik’s cube • e.g., application workﬂows, speciﬁcations Graph Deﬁnitions G1 0 1 2 3 G2 0 1 2 G3 a b s c d e f g • Graph G = (V, E) is a set of vertices V and a set of pairs of vertices E ⊆ V × V . • Directed edges are ordered pairs, e.g., (u, v) for u, v ∈ V • Undirected edges are unordered pairs, e.g., {u, v} for u, v ∈
873	V i.e., (u, v) and (v, u) • In this class, we assume all graphs are simple: – edges are distinct, e.g., (u, v) only occurs once in E (though (v, u) may appear), and – edges are pairs of distinct vertices, e.g., u =6 v for all (u, v) ∈ E     |V | |V | – Simple implies |E| = O(|V |2), since |E| ≤ for undirected, ≤ 2 for directed 2 2
874	2 Lecture 9: Breadth-First Search Neighbor Sets/Adjacencies • The outgoing neighbor set of u ∈ V is Adj+(u) = {v ∈ V | (u, v) ∈ E} • The incoming neighbor set of u ∈ V is Adj−(u) = {v ∈ V | (v, u) ∈ E} • The out-degree of a vertex u ∈ V is deg+(u) = |Adj+(u)| • The in-degree of a vertex u ∈ V is deg−(u) = |Adj−(u)| • For undirected graphs, Adj−(u) = Adj+(u) and deg−(u) = deg+(u) • Dropping superscript defaults to outgoing, i.e., Adj(u) = Adj+(u) and deg(u) = deg+(u) Graph Representations • To store a graph G = (V, E), we need to store the outgoing edges Adj(u) for all u ∈ V • First, need a Set data structure Adj to map u to Adj(u) • Then for each u, need to store Adj(u) in another data structure called an adjacency list • Common to use direct access array or hash table for Adj, since want lookup fast by vertex • Common to use array or linked list for each
875	Adj(u) since usually only iteration is needed1 • For the common representations, Adj has size Θ(|V |), while each Adj(u) has size Θ(deg(u)) P • Since u∈V deg(u) ≤ 2|E| by handshaking lemma, graph storable in Θ(|V | + |E|) space • Thus, for algorithms on graphs, linear time will mean Θ(|V | + |E|) (linear in size of graph) Examples • Examples 1 and 2 assume vertices are labeled {0, 1, . . . , |V | − 1}, so can use a direct access array for Adj, and store Adj(u) in an array. Example 3 uses a hash table for Adj. Ex 1 (Undirected) | Ex 2 (Directed) | Ex 3 (Undirected) G1 = [ | G2 = [ | G3 = { [2, 1], # 0 | [2], # 0 | a: [s, b], b: [a], [2, 0, 3], # 1 | [2, 0], # 1 | s: [a, c], c: [s, d, e], [1, 3, 0], # 2 | [1], # 2 | d: [c, e, f], e: [c, d, f], [1, 2], # 3 |
876	] | f: [d, e], g: [], ] | | } • Note that in an undirected graph, connections are symmetric as every edge is outgoing twice 1A hash table for each Adj(u) can allow checking for an edge (u, v) ∈ E in O(1)(e) time
877	3 Lecture 9: Breadth-First Search Paths • A path is a sequence of vertices p = (v1, v2, . . . , vk) where (vi, vi+1) ∈ E for all 1 ≤ i < k. • A path is simple if it does not repeat vertices2 • The length `(p) of a path p is the number of edges in the path • The distance δ(u, v) from u ∈ V to v ∈ V is the minimum length of any path from u to v, i.e., the length of a shortest path from u to v (by convention, δ(u, v) = ∞ if u is not connected to v) Graph Path Problems • There are many problems you might want to solve concerning paths in a graph: • SINGLE PAIR REACHABILITY(G, s, t): is there a path in G from s ∈ V to t ∈ V ? • SINGLE PAIR SHORTEST PATH(G, s, t): return distance δ(s, t), and a shortest path in G = (V, E) from s ∈ V to t ∈ V • SINGLE SOURCE
878	SHORTEST PATHS(G, s): return δ(s, v) for all v ∈ V , and a shortest-path tree containing a shortest path from s to every v ∈ V (deﬁned below) • Each problem above is at least as hard as every problem above it (i.e., you can use a black-box that solves a lower problem to solve any higher problem) • We won’t show algorithms to solve all of these problems • Instead, show one algorithm that solves the hardest in O(|V | + |E|) time! Shortest Paths Tree • How to return a shortest path from source vertex s for every vertex in graph? • Many paths could have length Ω(|V |), so returning every path could require Ω(|V |2) time • Instead, for all v ∈ V , store its parent P (v): second to last vertex on a shortest path from s • Let P (s) be null (no second to last vertex on shortest path from s to s) • Set of parents comprise a shortest paths tree with O(|V |) size! (i.e., reversed shortest paths back
879	to s from every vertex reachable from s) 2A path in 6.006 is a “walk” in 6.042. A “path” in 6.042 is a simple path in 6.006.
880	4 Lecture 9: Breadth-First Search Breadth-First Search (BFS) • How to compute δ(s, v) and P (v) for all v ∈ V ? • Store δ(s, v) and P (v) in Set data structures mapping vertices v to distance and parent • (If no path from s to v, do not store v in P and set δ(s, v) to ∞) • Idea! Explore graph nodes in increasing order of distance • Goal: Compute level sets Li = {v | v ∈ V and d(s, v) = i} (i.e., all vertices at distance i) • Claim: Every vertex v ∈ Li must be adjacent to a vertex u ∈ Li−1 (i.e., v ∈ Adj(u)) • Claim: No vertex that is in Lj for some j < i, appears in Li • Invariant: δ(s, v) and P (v) have been computed correctly for all v in any Lj for j < i • Base case (i = 1): L0 = {s}, δ(s, s) = 0, P (s) = None • Inductive Step: To compute Li: – for every vertex u in
881	Li−1: ∗ for every vertex v ∈ Adj(u) that does not appear in any Lj for j < i: · add v to Li, set δ(s, v) = i, and set P (v) = u • Repeatedly compute Li from Lj for j < i for increasing i until Li is the empty set • Set δ(s, v) = ∞ for any v ∈ V for which δ(s, v) was not set • Breadth-ﬁrst search correctly computes all δ(s, v) and P (v) by induction • Running time analysis: – Store each Li in data structure with Θ(|Li|)-time iteration and O(1)-time insertion (i.e., in a dynamic array or linked list) – Checking for a vertex v in any Lj for j < i can be done by checking for v in P – Maintain δ and P in Set data structures supporting dictionary ops in O(1) time (i.e., direct access array or hash table) – Algorithm adds each vertex u to ≤ 1 level and spends O(1) time for each v ∈ Adj(u) P – Work upper bounded by O(1)
882	× deg(u) = O(|E|) by handshake lemma u∈V – Spend Θ(|V |) at end to assign δ(s, v) for vertices v ∈ V not reachable from s – So breadth-ﬁrst search runs in linear time! O(|V | + |E|) • Run breadth-ﬁrst search from s in the graph in Example 3
883	MIT OpenCourseWare https://ocw.mit.edu 6.006 Introduction to Algorithms Spring 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms
884	Introduction to Algorithms: 6.006 Massachusetts Institute of Technology Instructors: Erik Demaine, Jason Ku, and Justin Solomon Lecture 3: Sorting Lecture 3: Sorting Set Interface (L03-L08) Container build(X) len() given an iterable X, build set from items in X return the number of stored items Static find(k) return the stored item with key k Dynamic insert(x) delete(k) add x to set (replace item with key x.key if one already exists) remove and return the stored item with key k Order iter ord() find min() find max() find next(k) find prev(k) return the stored items one-by-one in key order return the stored item with smallest key return the stored item with largest key return the stored item with smallest key larger than k return the stored item with largest key smaller than k • Storing items in an array in arbitrary order can implement a (not so efﬁcient) set • Stored items sorted increasing by key allows: – faster ﬁnd min/max (at ﬁrst and last index of array) – faster ﬁnds via binary search: O(log n) Set Operations O(·) Container Static Dynamic
885	Order Data Structure build(X) find(k) insert(x) delete(k) find min() find max() find prev(k) find next(k) Array n n n n n Sorted Array n log n log n n 1 log n • But how to construct a sorted array efﬁciently?
886	2 Lecture 3: Sorting Sorting • Given a sorted array, we can leverage binary search to make an efﬁcient set data structure. • Input: (static) array A of n numbers • Output: (static) array B which is a sorted permutation of A – Permutation: array with same elements in a different order – Sorted: B[i − 1] ≤ B[i] for all i ∈{1, . . . , n} • Example: [8, 2, 4, 9, 3] → [2, 3, 4, 8, 9] • A sort is destructive if it overwrites A (instead of making a new array B that is a sorted version of A) • A sort is in place if it uses O(1) extra space (implies destructive: in place ⊆ destructive) Permutation Sort • There are n! permutations of A, at least one of which is sorted • For each permutation, check whether sorted in Θ(n) • Example: [2, 3, 1] →{[1, 2, 3], [1, 3, 2], [2, 1, 3], [2, 3, 1], [3, 1, 2], [3, 2, 1]} 1 def permutation_sort(A): 2 ’’’Sort A’’’ 3 for B in
887	permutations(A): # O(n!) 4 if is_sorted(B): # O(n) 5 return B # O(1) • permutation sort analysis: – Correct by case analysis: try all possibilities (Brute Force) – Running time: Ω(n! · n) which is exponential :( Solving Recurrences • Substitution: Guess a solution, replace with representative function, recurrence holds true • Recurrence Tree: Draw a tree representing the recursive calls and sum computation at nodes • Master Theorem: A formula to solve many recurrences (R03)
888	3 Lecture 3: Sorting Selection Sort • Find a largest number in preﬁx A[:i + 1] and swap it to A[i] • Recursively sort preﬁx A[:i] • Example: [8, 2, 4, 9, 3], [8, 2, 4, 3, 9], [3, 2, 4, 8, 9], [3, 2, 4, 8, 9], [2, 3, 4, 8, 9] 1 def selection_sort(A, i = None): # T(i) 2 ’’’Sort A[:i + 1]’’’ 3 if i is None: i = len(A) - 1 # O(1) 4 if i > 0: # O(1) 5 j = prefix_max(A, i) # S(i) 6 A[i], A[j] = A[j], A[i] # O(1) 7 selection_sort(A, i - 1) # T(i - 1) 8 9 def prefix_max(A, i): # S(i) 10 ’’’Return index of maximum in A[:i + 1]’’’ 11 if i > 0: # O(1) 12 j = prefix_max(A, i - 1) # S(i - 1) 13 if A[i] < A[j]: # O(1) 14 return j # O(1) 15 return i # O(1) • prefix max analysis: – Base case: for i = 0, array has one element, so index of max is
889	i – Induction: assume correct for i, maximum is either the maximum of A[:i] or A[i], returns correct index in either case. – S(1) = Θ(1), S(n) = S(n − 1) + Θ(1) ∗ Substitution: S(n) = Θ(n), cn = Θ(1) + c(n − 1) =⇒ 1 = Θ(1) P n−1 ∗ Recurrence tree: chain of n nodes with Θ(1) work per node, i=0 1 = Θ(n) • selection sort analysis: – Base case: for i = 0, array has one element so is sorted – Induction: assume correct for i, last number of a sorted output is a largest number of the array, and the algorithm puts one there; then A[:i] is sorted by induction – T (1) = Θ(1), T (n) = T (n − 1) + Θ(n) ∗ Substitution: T (n) = Θ(n2), cn2 = Θ(n) + c(n − 1)2 =⇒ c(2n − 1) = Θ(n) P n−1 ∗ Recurrence tree: chain of n nodes with Θ(i) work per node, i=0 i = Θ(n2)
890	4 Lecture 3: Sorting Insertion Sort • Recursively sort preﬁx A[:i] • Sort preﬁx A[:i + 1] assuming that preﬁx A[:i] is sorted by repeated swaps • Example: [8, 2, 4, 9, 3], [2, 8, 4, 9, 3], [2, 4, 8, 9, 3], [2, 4, 8, 9, 3], [2, 3, 4, 8, 9] 1 def insertion_sort(A, i = None): # T(i) 2 ’’’Sort A[:i + 1]’’’ 3 if i is None: i = len(A) - 1 # O(1) 4 if i > 0: # O(1) 5 insertion_sort(A, i - 1) # T(i - 1) 6 insert_last(A, i) # S(i) 7 8 def insert_last(A, i): # S(i) 9 ’’’Sort A[:i + 1] assuming sorted A[:i]’’’ 10 if i > 0 and A[i] < A[i - 1]: # O(1) 11 A[i], A[i - 1] = A[i - 1], A[i] # O(1) 12 insert_last(A, i - 1) # S(i - 1) • insert last analysis: – Base case: for i = 0, array has one element so is sorted – Induction: assume correct for i, if A[i] >= A[i - 1], array is
891	sorted; otherwise, swapping last two elements allows us to sort A[:i] by induction – S(1) = Θ(1), S(n) = S(n − 1) + Θ(1) =⇒ S(n) = Θ(n) • insertion sort analysis: – Base case: for i = 0, array has one element so is sorted – Induction: assume correct for i, algorithm sorts A[:i] by induction, and then insert last correctly sorts the rest as proved above – T (1) = Θ(1), T (n) = T (n − 1) + Θ(n) =⇒ T (n) = Θ(n2)
892	5 Lecture 3: Sorting Merge Sort • Recursively sort ﬁrst half and second half (may assume power of two) • Merge sorted halves into one sorted list (two ﬁnger algorithm) • Example: [7, 1, 5, 6, 2, 4, 9, 3], [1, 7, 5, 6, 2, 4, 3, 9], [1, 5, 6, 7, 2, 3, 4, 9], [1, 2, 3, 4, 5, 6, 7, 9] 1 def merge_sort(A, a = 0, b = None): # T(b - a = n) 2 ’’’Sort A[a:b]’’’ 3 if b is None: b = len(A) # O(1) 4 if 1 < b - a: # O(1) 5 c = (a + b + 1) // 2 # O(1) 6 merge_sort(A, a, c) # T(n / 2) 7 merge_sort(A, c, b) # T(n / 2) 8 L, R = A[a:c], A[c:b] # O(n) 9 merge(L, R, A, len(L), len(R), a, b) # S(n) 10 11 def merge(L, R, A, i, j, a, b): # S(b - a = n) 12 ’’’Merge sorted L[:i] and R[:j] into A[a:b]’’’ 13 if a < b: # O(1) 14 if
893	(j <= 0) or (i > 0 and L[i - 1] > R[j - 1]): # O(1) 15 A[b - 1] = L[i - 1] # O(1) 16 i = i - 1 # O(1) 17 else: # O(1) 18 A[b - 1] = R[j - 1] # O(1) 19 j = j - 1 # O(1) 20 merge(L, R, A, i, j, a, b - 1) # S(n - 1) • merge analysis: – Base case: for n = 0, arrays are empty, so vacuously correct – Induction: assume correct for n, item in A[r] must be a largest number from remaining preﬁxes of L and R, and since they are sorted, taking largest of last items sufﬁces; remainder is merged by induction – S(0) = Θ(1), S(n) = S(n − 1) + Θ(1) =⇒ S(n) = Θ(n) • merge sort analysis: – Base case: for n = 1, array has one element so is sorted – Induction: assume correct for k < n, algorithm sorts smaller halves by induction, and then merge merges into a sorted array as
894	proved above. – T (1) = Θ(1), T (n) = 2T (n/2) + Θ(n) ∗ Substitution: Guess T (n) = Θ(n log n) cn log n = Θ(n) + 2c(n/2) log(n/2) =⇒ cn log(2) = Θ(n) ∗ Recurrence Tree: complete binary tree with depth log2 n and n leaves, level i has 2i Plog2 n Plog2 n nodes with O(n/2i) work each, total: i=0 (2i)(n/2i) = i=0 n = Θ(n log n)
895	MIT OpenCourseWare https://ocw.mit.edu 6.006 Introduction to Algorithms Spring 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms
896	Introduction to Algorithms: 6.006 Massachusetts Institute of Technology Instructors: Erik Demaine, Jason Ku, and Justin Solomon Lecture 17: Dyn. Prog. III Lecture 17: Dyn. Prog. III Dynamic Programming Steps (SRT BOT) 1. Subproblem deﬁnition subproblem x ∈ X • Describe the meaning of a subproblem in words, in terms of parameters • Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence • Often multiply possible subsets across multiple inputs • Often record partial state: add subproblems by incrementing some auxiliary variables 2. Relate subproblem solutions recursively x(i) = f(x(j), . . .) for one or more j < i • Identify a question about a subproblem solution that, if you knew the answer to, reduces the subproblem to smaller subproblem(s) • Locally brute-force all possible answers to the question 3. Topological order to argue relation is acyclic and subproblems form a DAG 4. Base cases • State solutions for all (reachable) independent subproblems where relation breaks down 5. Original problem • Show how to compute solution to original problem from solutions to subproblem(s) • Possibly use parent pointers
897	to recover actual solution, not just objective function 6. Time analysis P • work(x), or if work(x) = O(W ) for all x ∈ X, then |X| · O(W ) x∈X • work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time Recall: DAG Shortest Paths [L15] • Subproblems: δ(s, v) for all v ∈ V • Relation: δ(s, v) = min{δ(s, u) + w(u, v) | u ∈ Adj−(v)} ∪ {∞} • Topo. order: Topological order of G
898	2 Lecture 17: Dyn. Prog. III Single-Source Shortest Paths Revisited 1. Subproblems • Expand subproblems to add information to make acyclic! (an example we’ve already seen of subproblem expansion) • δk(s, v) = weight of shortest path from s to v using at most k edges • For v ∈ V and 0 ≤ k ≤|V | 2. Relate • Guess last edge (u, v) on shortest path from s to v • δk(s, v) = min{δk−1(s, u) + w(u, v) | (u, v) ∈ E} ∪{δk−1(s, v)} 3. Topological order • Increasing k: subproblems depend on subproblems only with strictly smaller k 4. Base • δ0(s, s) = 0 and δ0(s, v) = ∞ for v 6= s (no edges) • (draw subproblem graph) 5. Original problem • If has ﬁnite shortest path, then δ(s, v) = δ|V |−1(s, v) • Otherwise some δ|V |(s, v) < δ|V |−1(s, v), so path contains a negative-weight cycle • Can keep track of parent pointers to subproblem that minimized recurrence 6. Time • # subproblems: |V | × (|V | +
899	1) • Work for subproblem δk(s, v): O(degin(v)) |V | |V | X X X O(degin(v)) = O(|E|) = O(|V | · |E|) k=0 v∈V k=0 This is just Bellman-Ford! (computed in a slightly different order)
900	3 Lecture 17: Dyn. Prog. III All-Pairs Shortest Paths: Floyd–Warshall • Could deﬁne subproblems δk(u, v) = minimum weight of path from u to v using at most k edges, as in Bellman–Ford • Resulting running time is |V | times Bellman–Ford, i.e., O(|V |2 · |E|) = O(|V |4) • Know a better algorithm from L14: Johnson achieves O(|V |2 log |V | + |V | · |E|) = O(|V |3) • Can achieve Θ(|V |3) running time (matching Johnson for dense graphs) with a simple dy­ namic program, called Floyd–Warshall • Number vertices so that V = {1, 2, . . . , |V |} 1. Subproblems • d(u, v, k) = minimum weight of a path from u to v that only uses vertices from {1, 2, . . . , k} ∪{u, v} • For u, v ∈ V and 1 ≤ k ≤|V | 2. Relate • x(u, v, k) = min{x(u, k, k − 1) + x(k, v, k − 1), x(u, v, k − 1)} • Only constant branching! No longer guessing previous
901	vertex/edge 3. Topological order • Increasing k: relation depends only on smaller k 4. Base • x(u, u, 0) = 0 • x(u, v, 0) = w(u, v) if (u, v) ∈ E • x(u, v, 0) = ∞ if none of the above 5. Original problem • x(u, v, |V |) for all u, v ∈ V 6. Time • O(|V |3) subproblems • Each O(1) work • O(|V |3) in total • Constant number of dependencies per subproblem brings the factor of O(|E|) in the running time down to O(|V |).
902	4 Lecture 17: Dyn. Prog. III Arithmetic Parenthesization • Input: arithmetic expression a0 ∗ 1 a1 ∗ 2 a2 · · · ∗ n−1 an−1 where each ai is an integer and each ∗ i ∈{+, ×} • Output: Where to place parentheses to maximize the evaluated expression • Example: 7 + 4 × 3 + 5 → ((7) + (4)) × ((3) + (5)) = 88 • Allow negative integers! • Example: 7 + (−4) × 3 + (−5) → ((7) + ((−4) × ((3) + (−5)))) = 15 1. Subproblems • Sufﬁcient to maximize each subarray? No! (−3) × (−3) = 9 > (−2) × (−2) = 4 • x(i, j, opt) = opt value obtainable by parenthesizing ai ∗ i+1 · · · ∗ j−1 aj−1 • For 0 ≤ i < j ≤ n and opt ∈{min, max} 2. Relate • Guess location of outermost parentheses / last operation evaluated • x(i, j, opt) = opt {x(i, k, opt0) ∗ k x(k, j, opt00)) | i < k < j; opt0 , opt00 ∈{min, max}} 3.
903	Topological order • Increasing j − i: subproblem x(i, j, opt) depends only on strictly smaller j − i 4. Base • x(i, i + 1, opt) = ai, only one number, no operations left! 5. Original problem • X(0, n, max) • Store parent pointers (two!) to ﬁnd parenthesization (forms binary tree!) 6. Time 2) • # subproblems: less than n · n · 2 = O(n • work per subproblem O(n) · 2 · 2 = O(n) • O(n3) running time
904	5 Lecture 17: Dyn. Prog. III Piano Fingering • Given sequence t0, t1, . . . , tn−1 of n single notes to play with right hand (will generalize to multiple notes and hands later) • Performer has right-hand ﬁngers 1, 2, . . . , F (F = 5 for most humans) • Given metric d(t, f, t0, f 0) of difﬁculty of transitioning from note t with ﬁnger f to note t0 with ﬁnger f 0 – Typically a sum of penalties for various difﬁculties, e.g.: – 1 < f < f 0 and t > t0 is uncomfortable – Legato (smooth) play requires t =6 t0 (else inﬁnite penalty) – Weak-ﬁnger rule: prefer to avoid f 0 ∈{4, 5} – {f, f 0} = {3, 4} is annoying • Goal: Assign ﬁngers to notes to minimize total difﬁculty • First attempt: 1. Subproblems • x(i) = minimum total difﬁculty for playing notes ti, ti+1, . . . , tn−1 2. Relate • Guess ﬁrst ﬁnger: assignment f for ti • x(i) = min{x(i + 1) + d(ti,
905	f, ti+1, ?) | 1 ≤ f ≤ F } • Not enough information to ﬁll in ? • Need to know which ﬁnger at the start of x(i + 1) • But different starting ﬁngers could hurt/help both x(i + 1) and d(ti, f, ti+1, ?) • Need a table mapping start ﬁngers to optimal solutions for x(i + 1) • I.e., need to expand subproblems with start condition
906	6 Lecture 17: Dyn. Prog. III • Solution: 1. Subproblems • x(i, f) = minimum total difﬁculty for playing notes ti, ti+1, . . . , tn−1 starting with ﬁn­ ger f on note ti • For 0 ≤ i < n and 1 ≤ f ≤ F 2. Relate • Guess next ﬁnger: assignment f 0 for ti+1 • x(i, f) = min{x(i + 1, f 0) + d(ti, f, ti+1, f 0) | 1 ≤ f 0 ≤ F } 3. Topological order • Decreasing i (any f order) 4. Base • x(n − 1, f) = 0 (no transitions) 5. Original problem • min{x(0, f) | 1 ≤ f ≤ F } 6. Time • Θ(n · F ) subproblems • Θ(F ) work per subproblem • Θ(n · F 2) • No dependence on the number of different notes!
907	7 Lecture 17: Dyn. Prog. III Guitar Fingering • Up to S = number of strings different ways to play the same note • Redeﬁne “ﬁnger” to be tuple (ﬁnger playing note, string playing note) • Throughout algorithm, F gets replaced by F · S • Running time is thus Θ(n · F 2 · S2) Multiple Notes at Once • Now suppose ti is a set of notes to play at time i • Given a bigger transition difﬁculty function d(t, f, t0, f 0) • Goal: ﬁngering fi : ti →{1, 2, . . . , F } specifying how to ﬁnger each note (including which P n−1 string for guitar) to minimize i=1 d(ti−1, fi−1, ti, fi) • At most T F choices for each ﬁngering fi, where T = maxi |ti| – T ≤ F = 10 for normal piano (but there are exceptions) – T ≤ S for guitar • Θ(n · T F ) subproblems • Θ(T F ) work per subproblem • Θ(n · T 2F ) time • Θ(n) time for T,
908	F ≤ 10 Video Game Appliactions • Guitar Hero / Rock Band – F = 4 (and 5 different notes) • Dance Dance Revolution – F = 2 feet – T = 2 (at most two notes at once) – Exercise: handle sustained notes, using “where each foot is” (on an arrow or in the middle) as added state for sufﬁx subproblems
909	MIT OpenCourseWare https://ocw.mit.edu 6.006 Introduction to Algorithms Spring 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms
910	Introduction to Algorithms: 6.006 Massachusetts Institute of Technology Instructors: Erik Demaine, Jason Ku, and Justin Solomon Lecture 15: Recursive Algorithms Lecture 15: Recursive Algorithms How to Solve an Algorithms Problem (Review) • Reduce to a problem you already know (use data structure or algorithm) Search Data Structures Sort Algorithms Graph Algorithms Array Insertion Sort Breadth First Search Linked List Selection Sort DAG Relaxation (DFS + Topo) Dynamic Array Merge Sort Dijkstra Sorted Array Counting Sort Bellman-Ford Direct-Access Array Radix Sort Johnson Hash Table AVL Sort AVL Tree Heap Sort Binary Heap • Design your own recursive algorithm – Constant-sized program to solve arbitrary input – Need looping or recursion, analyze by induction – Recursive function call: vertex in a graph, directed edge from A → B if B calls A – Dependency graph of recursive calls must be acyclic (if can terminate) – Classify based on shape of graph Class Graph Brute Force Decrease & Conquer Divide & Conquer Dynamic Programming Star Chain Tree DAG Greedy/Incremental Subgraph – Hard part is thinking inductively to construct recurrence on subproblems – How
911	to solve a problem recursively (SRT BOT) 1. Subproblem deﬁnition 2. Relate subproblem solutions recursively 3. Topological order on subproblems (⇒ subproblem DAG) 4. Base cases of relation 5. Original problem solution via subproblem(s) 6. Time analysis
912	2 Lecture 15: Recursive Algorithms Merge Sort in SRT BOT Framework • Merge sorting an array A of n elements can be expressed in SRT BOT as follows: – Subproblems: S(i, j) = sorted array on elements of A[i : j] for 0 ≤ i ≤ j ≤ n – Relation: S(i, j) = merge(S(i, m), S(m, j)) where m = b(i + j)/2c – Topo. order: Increasing j − i – Base cases: S(i, i + 1) = [A[i]] – Original: S(0, n) – Time: T (n) = 2 T (n/2) + O(n) = O(n lg n) • In this case, subproblem DAG is a tree (divide & conquer) Fibonacci Numbers • Suppose we want to compute the nth Fibonacci number Fn • Subproblems: F (i) = the ith Fibonacci number Fi for i ∈{0, 1, . . . , n} • Relation: F (i) = F (i − 1) + F (i − 2) (deﬁnition of Fibonacci numbers) • Topo. order: Increasing i • Base cases: F (0) = 0, F (1) = 1 • Original prob.: F
913	(n) 1 def fib(n): 2 if n < 2: return n # base case 3 return fib(n - 1) + fib(n - 2) # recurrence • Divide and conquer implies a tree of recursive calls (draw tree) • Time: T (n) = T (n − 1) + T (n − 2) + O(1) > 2T (n − 2), T (n) = Ω(2n/2) exponential... :( • Subproblem F (k) computed more than once! (F (n − k) times) • Can we avoid this waste?
914	3 Lecture 15: Recursive Algorithms Re-using Subproblem Solutions • Draw subproblem dependencies as a DAG • To solve, either: – Top down: record subproblem solutions in a memo and re-use (recursion + memoization) – Bottom up: solve subproblems in topological sort order (usually via loops) • For Fibonacci, n + 1 subproblems (vertices) and < 2n dependencies (edges) • Time to compute is then O(n) additions 1 # recursive solution (top down) 2 def fib(n): 3 memo = {} 4 def F(i): 5 if i < 2: return i # base cases 6 if i not in memo: # check memo 7 memo[i] = F(i - 1) + F(i - 2) # relation 8 return memo[i] 9 return F(n) # original 1 # iterative solution (bottom up) 2 def fib(n): 3 F = {} 4 F[0], F[1] = 0, 1 # base cases 5 for i in range(2, n + 1): # topological order 6 F[i] = F[i - 1] + F[i - 2] # relation 7 return F[n] # original • A subtlety is that Fibonacci numbers grow to
915	Θ(n) bits long, potentially ≫ word size w • Each addition costs O(dn/we) time • So total cost is O(ndn/we) = O(n + n2/w) time
916	4 Lecture 15: Recursive Algorithms Dynamic Programming • Weird name coined by Richard Bellman – Wanted government funding, needed cool name to disguise doing mathematics! – Updating (dynamic) a plan or schedule (program) • Existence of recursive solution implies decomposable subproblems1 • Recursive algorithm implies a graph of computation • Dynamic programming if subproblem dependencies overlap (DAG, in-degree > 1) • “Recurse but re-use” (Top down: record and lookup subproblem solutions) • “Careful brute force” (Bottom up: do each subproblem in order) • Often useful for counting/optimization problems: almost trivially correct recurrences How to Solve a Problem Recursively (SRT BOT) 1. Subproblem deﬁnition subproblem x ∈ X • Describe the meaning of a subproblem in words, in terms of parameters • Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence • Often record partial state: add subproblems by incrementing some auxiliary variables 2. Relate subproblem solutions recursively x(i) = f(x(j), . . .) for one or more j < i 3. Topological order to argue relation is acyclic and subproblems form a DAG 4. Base cases • State
917	solutions for all (reachable) independent subproblems where relation breaks down 5. Original problem • Show how to compute solution to original problem from solutions to subproblem(s) • Possibly use parent pointers to recover actual solution, not just objective function 6. Time analysis P • work(x), or if work(x) = O(W ) for all x ∈ X, then |X| · O(W ) x∈X • work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time 1This property often called optimal substructure. It is a property of recursion, not just dynamic programming
918	5 Lecture 15: Recursive Algorithms DAG Shortest Paths • Recall the DAG SSSP problem: given a DAG G and vertex s, compute δ(s, v) for all v ∈ V • Subproblems: δ(s, v) for all v ∈ V • Relation: δ(s, v) = min{δ(s, u) + w(u, v) | u ∈ Adj−(v)} ∪ {∞} • Topo. order: Topological order of G • Base cases: δ(s, s) = 0 • Original: All subproblems P • Time: O(1 + | Adj−(v)|) = O(|V | + |E|) v∈V • DAG Relaxation computes the same min values as this dynamic program, just – step-by-step (if new value < min, update min via edge relaxation), and – from the perspective of u and Adj+(u) instead of v and Adj−(v) Bowling • Given n pins labeled 0, 1, . . . , n − 1 • Pin i has value vi • Ball of size similar to pin can hit either – 1 pin i, in which case we get vi points – 2 adjacent pins i and i + 1, in which case we get
919	vi · vi+1 points • Once a pin is hit, it can’t be hit again (removed) • Problem: Throw zero or more balls to maximize total points • Example: [ −1, 1 , 1 , 1 , 9, 9 , 3 , −3, −5 , 2, 2 ]
920	6 Lecture 15: Recursive Algorithms Bowling Algorithms • Let’s start with a more familiar divide-and-conquer algorithm: – Subproblems: B(i, j) = maximum score starting with just pins i, i + 1, . . . , j − 1, for 0 ≤ i ≤ j ≤ n – Relation: ∗ m = b(i + j)/2c ∗ Either hit m and m + 1 together, or don’t ∗ B(i, j) = max{vm · vm+1 + B(i, m) + B(m + 2, j), B(i, m + 1) + B(m + 1, j)} – Topo. order: Increasing j − i – Base cases: B(i, i) = 0, B(i, i + 1) = max{vi, 0} – Original: B(0, n) – Time: T (n) = 4 T (n/2) + O(1) = O(n2) • This algorithm works but isn’t very fast, and doesn’t generalize well (e.g., to allow for a bigger ball that hits three balls at once) • Dynamic programming algorithm: use sufﬁxes – Subproblems: B(i) = maximum score starting with just pins i, i + 1, . . . , n − 1, for 0
921	≤ i ≤ n – Relation: ∗ Locally brute-force what could happen with ﬁrst pin (original pin i): skip pin, hit one pin, hit two pins ∗ Reduce to smaller sufﬁx and recurse, either B(i + 1) or B(i + 2) ∗ B(i) = max{B(i + 1), vi + B(i + 1), vi · vi+1 + B(i + 2)} – Topo. order: Decreasing i (for i = n, n − 1, . . . , 0) – Base cases: B(n) = B(n + 1) = 0 – Original: B(0) – Time: (assuming memoization) ∗ Θ(n) subproblems · Θ(1) work in each ∗ Θ(n) total time • Fast and easy to generalize! • Equivalent to maximum-weight path in Subproblem DAG: B0 B1 B2 B3 · · · Bn max{v0, 0} max{v1, 0} max{v2, 0} v0 · v1 v1 · v2 v2 · v3
922	7 Lecture 15: Recursive Algorithms Bowling Code • Converting a SRT BOT speciﬁcation into code is automatic/straightforward • Here’s the result for the Bowling Dynamic Program above: 1 # recursive solution (top down) 2 def bowl(v): 3 memo = {} 4 def B(i): 5 if i >= len(v): return 0 # base cases 6 if i not in memo: # check memo 7 memo[i] = max(B(i+1), # relation: skip pin i 8 v[i] + B(i+1), # OR bowl pin i separately 9 v[i] * v[i+1] + B(i+2)) # OR bowl pins i and i+1 together 10 return memo[i] 11 return B(0) # original 1 # iterative solution (bottom up) 2 def bowl(v): 3 B = {} 4 B[len(v)] = 0 # base cases 5 B[len(v)+1] = 0 6 for i in reversed(range(len(v))): # topological order 7 B[i] = max(B[i+1], # relation: skip pin i 8 v[i] + B(i+1), # OR bowl pin i separately 9 v[i] * v[i+1] + B(i+2)) # OR bowl pins i and i+1 together 10 return B[0] # original How to Relate Subproblem Solutions • The
923	general approach we’re following to deﬁne a relation on subproblem solutions: – Identify a question about a subproblem solution that, if you knew the answer to, would reduce to “smaller” subproblem(s) ∗ In case of bowling, the question is “how do we bowl the ﬁrst couple of pins?” – Then locally brute-force the question by trying all possible answers, and taking the best ∗ In case of bowling, we take the max because the problem asks to maximize – Alternatively, we can think of correctly guessing the answer to the question, and di­ rectly recursing; but then we actually check all possible guesses, and return the “best” • The key for efﬁciency is for the question to have a small (polynomial) number of possible answers, so brute forcing is not too expensive • Often (but not always) the nonrecursive work to compute the relation is equal to the number of answers we’re trying
924	MIT OpenCourseWare https://ocw.mit.edu 6.006 Introduction to Algorithms Spring 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms
925	Restrictions SSSP Algorithm Graph Weights Name Running Time O(·) General Unweighted BFS |V | + |E| DAG Any DAG Relaxation |V | + |E| General Non-negative Dijkstra Bellman-Ford |V | log |V | + |E| General Any Introduction to Algorithms: 6.006 Massachusetts Institute of Technology Instructors: Erik Demaine, Jason Ku, and Justin Solomon Lecture 14: Johnson’s Algorithm Lecture 14: Johnson’s Algorithm Previously |V | · |E| All-Pairs Shortest Paths (APSP) • Input: directed graph G = (V, E) with weights w : E → Z • Output: δ(u, v) for all u, v ∈ V , or abort if G contains negative-weight cycle • Useful when understanding whole network, e.g., transportation, circuit layout, supply chains... • Just doing a SSSP algorithm |V | times is actually pretty good, since output has size O(|V |2) – |V | · O(|V | + |E|) with BFS if weights positive and bounded by O(|V | + |E|) – |V | · O(|V | + |E|) with DAG Relaxation if acyclic – |V | · O(|V | log |V | + |E|) with Dijkstra
926	if weights non-negative or graph undirected – |V | · O(|V | · |E|) with Bellman-Ford (general) • Today: Solve APSP in any weighted graph in |V | · O(|V | log |V | + |E|) time
927	2 Lecture 14: Johnson’s Algorithm Approach • Idea: Make all edge weights non-negative while preserving shortest paths! • i.e., reweight G to G0 with no negative weights, where a shortest path in G is shortest in G0 • If non-negative, then just run Dijkstra |V | times to solve APSP • Claim: Can compute distances in G from distances in G0 in O(|V |(|V | + |E|)) time – Compute shortest-path tree from distances, for each s ∈ V 0 in O(|V | + |E|) time (L11) – Also shortest-paths tree in G, so traverse tree with DFS while also computing distances – Takes O(|V | · (|V | + |E|)) time (which is less time than |V | times Dijkstra) • But how to make G0 with non-negative edge weights? Is this even possible?? • Claim: Not possible if G contains a negative-weight cycle • Proof: Shortest paths are simple if no negative weights, but not if negative-weight cycle • Given graph G with negative weights but no negative-weight cycles, can we make edge weights non-negative while preserving shortest
928	paths? Making Weights Non-negative • Idea! Add negative of smallest weight in G to every edge! All weights non-negative! :) • FAIL: Does not preserve shortest paths! Biases toward paths traversing fewer edges :( • Idea! Given vertex v, add h to all outgoing edges and subtract h from all incoming edges • Claim: Shortest paths are preserved under the above reweighting • Proof: – Weight of every path starting at v changes by h – Weight of every path ending at v changes by −h – Weight of a path passing through v does not change (locally) • This is a very general and useful trick to transform a graph while preserving shortest paths!
929	3 Lecture 14: Johnson’s Algorithm • Even works with multiple vertices! • Deﬁne a potential function h : V → Z mapping each vertex v ∈ V to a potential h(v) • Make graph G0: same as G but edge (u, v) ∈ E has weight w0(u, v) = w(u, v)+h(u)−h(v) • Claim: Shortest paths in G are also shortest paths in G0 • Proof: Pk – Weight of path π = (v0, . . . , vk) in G is w(π) = i=1 w(vi−1, vi) Pk – Weight of π in G0 is: i=1 w(vi−1, vi) + h(vi−1) − h(vi) = w(π) + h(v0) − h(vk) – (Sum of h’s telescope, since there is a positive and negative h(vi) for each interior i) – Every path from v0 to vk changes by the same amount – So any shortest path will still be shortest Making Weights Non-negative • Can we ﬁnd a potential function such that G0 has no negative edge weights? • i.e., is there an h such that w(u, v) + h(u) − h(v) ≥ 0 for
930	every (u, v) ∈ E? • Re-arrange this condition to h(v) ≤ h(u) + w(u, v), looks like triangle inequality! • Idea! Condition would be satisﬁed if h(v) = δ(s, v) and δ(s, v) is ﬁnite for some s • But graph may be disconnected, so may not exist any such vertex s... :( • Idea! Add a new vertex s with a directed 0-weight edge to every v ∈ V ! :) • δ(s, v) ≤ 0 for all v ∈ V , since path exists a path of weight 0 • Claim: If δ(s, v) = −∞ for any v ∈ V , then the original graph has a negative-weight cycle • Proof: – Adding s does not introduce new cycles (s has no incoming edges) – So if reweighted graph has a negative-weight cycle, so does the original graph • Alternatively, if δ(s, v) is ﬁnite for all v ∈ V : – w0(u, v) = w(u, v) + h(u) − h(v) ≥ 0 for every (u, v) ∈ E by triangle inequality! – New weights in
931	G0 are non-negative while preserving shortest paths!
932	4 Lecture 14: Johnson’s Algorithm Johnson’s Algorithm • Construct Gx from G by adding vertex x connected to each vertex v ∈ V with 0-weight edge • Compute δx(x, v) for every v ∈ V (using Bellman-Ford) • If δx(x, v) = −∞ for any v ∈ V : – Abort (since there is a negative-weight cycle in G) • Else: – Reweight each edge w0(u, v) = w(u, v) + δx(x, u) − δx(x, v) to form graph G0 – For each u ∈ V : ∗ Compute shortest-path distances δ0(u, v) to all v in G0 (using Dijkstra) ∗ Compute δ(u, v) = δ0(u, v) − δx(x, u) + δx(x, v) for all v ∈ V Correctness • Already proved that transformation from G to G0 preserves shortest paths • Rest reduces to correctness of Bellman-Ford and Dijkstra • Reducing from Signed APSP to Non-negative APSP • Reductions save time! No induction today! :) Running Time • O(|V | + |E|) time to construct Gx • O(|V ||E|) time for Bellman-Ford • O(|V | + |E|) time to
933	construct G0 • O(|V | · (|V | log |V | + |E|)) time for |V | runs of Dijkstra • O(|V |2) time to compute distances in G from distances in G0 • O(|V |2 log |V | + |V ||E|) time in total
934	MIT OpenCourseWare https://ocw.mit.edu 6.006 Introduction to Algorithms Spring 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms
935	Introduction to Algorithms: 6.006 Massachusetts Institute of Technology Instructors: Erik Demaine, Jason Ku, and Justin Solomon Lecture 2: Data Structures Lecture 2: Data Structures Data Structure Interfaces • A data structure is a way to store data, with algorithms that support operations on the data • Collection of supported operations is called an interface (also API or ADT) • Interface is a speciﬁcation: what operations are supported (the problem!) • Data structure is a representation: how operations are supported (the solution!) • In this class, two main interfaces: Sequence and Set Sequence Interface (L02, L07) • Maintain a sequence of items (order is extrinsic) • Ex: (x0, x1, x2, . . . , xn−1) (zero indexing) • (use n to denote the number of items stored in the data structure) • Supports sequence operations: Container build(X) len() given an iterable X, build sequence from items in X return the number of stored items Static iter seq() get at(i) set at(i, x) return the stored items one-by-one in sequence order return the ith item replace the ith item with x Dynamic
936	insert at(i, x) delete at(i) insert first(x) delete first() insert last(x) delete last() add x as the ith item remove and return the ith item add x as the ﬁrst item remove and return the ﬁrst item add x as the last item remove and return the last item • Special case interfaces: stack insert last(x) and delete last() queue insert last(x) and delete first()
937	2 Lecture 2: Data Structures Set Interface (L03-L08) • Sequence about extrinsic order, set is about intrinsic order • Maintain a set of items having unique keys (e.g., item x has key x.key) • (Set or multi-set? We restrict to unique keys for now.) • Often we let key of an item be the item itself, but may want to store more info than just key • Supports set operations: Container build(X) len() given an iterable X, build sequence from items in X return the number of stored items Static find(k) return the stored item with key k Dynamic insert(x) delete(k) add x to set (replace item with key x.key if one already exists) remove and return the stored item with key k Order iter ord() find min() find max() find next(k) find prev(k) return the stored items one-by-one in key order return the stored item with smallest key return the stored item with largest key return the stored item with smallest key larger than k return the stored item with largest key smaller than k • Special case interfaces:
938	dictionary set without the Order operations • In recitation, you will be asked to implement a Set, given a Sequence data structure. Array Sequence • Array is great for static operations! get at(i) and set at(i, x) in Θ(1) time! • But not so great at dynamic operations... • (For consistency, we maintain the invariant that array is full) • Then inserting and removing items requires: – reallocating the array – shifting all items after the modiﬁed item Data Operation, Worst Case O(·) Container Static Dynamic Structure build(X) get at(i) set at(i,x) insert first(x) delete first() insert last(x) delete last() insert at(i, x) delete at(i) Array n 1 n n n
939	3 Lecture 2: Data Structures Linked List Sequence • Pointer data structure (this is not related to a Python “list”) • Each item stored in a node which contains a pointer to the next node in sequence • Each node has two ﬁelds: node.item and node.next • Can manipulate nodes simply by relinking pointers! • Maintain pointers to the ﬁrst node in sequence (called the head) • Can now insert and delete from the front in Θ(1) time! Yay! • (Inserting/deleting efﬁciently from back is also possible; you will do this in PS1) • But now get at(i) and set at(i, x) each take O(n) time... :( • Can we get the best of both worlds? Yes! (Kind of...) Data Operation, Worst Case O(·) Container Static Dynamic Structure build(X) get at(i) set at(i,x) insert first(x) delete first() insert last(x) delete last() insert at(i, x) delete at(i) Linked List n n 1 n n Dynamic Array Sequence • Make an array efﬁcient for last dynamic operations • Python “list” is a dynamic array • Idea! Allocate extra space so reallocation does
940	not occur with every dynamic operation • Fill ratio: 0 ≤ r ≤ 1 the ratio of items to space • Whenever array is full (r = 1), allocate Θ(n) extra space at end to ﬁll ratio ri (e.g., 1/2) • Will have to insert Θ(n) items before the next reallocation • A single operation can take Θ(n) time for reallocation • However, any sequence of Θ(n) operations takes Θ(n) time • So each operation takes Θ(1) time “on average”
941	4 Lecture 2: Data Structures Amortized Analysis • Data structure analysis technique to distribute cost over many operations • Operation has amortized cost T (n) if k operations cost at most ≤ kT (n) • “T (n) amortized” roughly means T (n) “on average” over many operations • Inserting into a dynamic array takes Θ(1) amortized time • More amortization analysis techniques in 6.046! Dynamic Array Deletion • Delete from back? Θ(1) time without effort, yay! • However, can be very wasteful in space. Want size of data structure to stay Θ(n) • Attempt: if very empty, resize to r = 1. Alternating insertion and deletion could be bad... • Idea! When r < rd, resize array to ratio ri where rd < ri (e.g., rd = 1/4, ri = 1/2) • Then Θ(n) cheap operations must be made before next expensive resize 1 rd+1 • Can limit extra space usage to (1 + ε)n for any ε > 0 (set rd = , ri = ) 1+ε 2 • Dynamic arrays only support dynamic last operations in Θ(1) time
942	• Python List append and pop are amortized O(1) time, other operations can be O(n)! • (Inserting/deleting efﬁciently from front is also possible; you will do this in PS1) Data Operation, Worst Case O(·) Container Static Dynamic Structure build(X) get at(i) set at(i,x) insert first(x) delete first() insert last(x) delete last() insert at(i, x) delete at(i) Array n 1 n n n Linked List n n 1 n n Dynamic Array n 1 n 1(a) n
943	MIT OpenCourseWare https://ocw.mit.edu 6.006 Introduction to Algorithms Spring 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms
944	Introduction to Algorithms: 6.006 Massachusetts Institute of Technology Instructors: Erik Demaine, Jason Ku, and Justin Solomon Lecture 7: Binary Trees II: AVL Lecture 7: Binary Trees II: AVL Last Time and Today’s Goal Sequence Data Structure Operations O(·) Container Static Dynamic build(X) get at(i) set at(i,x) insert first(x) delete first() insert last(x) delete last() insert at(i, x) delete at(i) Binary Tree n h h h h AVL Tree n log n log n log n log n Set Data Structure Operations O(·) Container Static Dynamic Order build(X) find(k) insert(x) delete(k) find min() find max() find prev(k) find next(k) Binary Tree n log n h h h h AVL Tree n log n log n log n log n log n Height Balance • How to maintain height h = O(log n) where n is number of nodes in tree? • A binary tree that maintains O(log n) height under dynamic operations is called balanced – There are many balancing schemes (Red-Black Trees, Splay Trees, 2-3 Trees, . . . ) – First proposed balancing scheme was the AVL Tree (Adelson-Velsky
945	and Landis, 1962) Rotations • Need to reduce height of tree without changing its traversal order, so that we represent the same sequence of items • How to change the structure of a tree, while preserving traversal order? Rotations! 1 _____<D>__ rotate_right(<D>) __<B>_____ 2 __<B>__ <E> => <A> __<D>__ 3 <A> <C> / \\ / \\ <C> <E> 4 / \\ / \\ /___\\ <= /___\\ / \\ / \\ 5 /___\\ /___\\ rotate_left(<B>) /___\\ /___\\ • A rotation relinks O(1) pointers to modify tree structure and maintains traversal order
946	2 Lecture 7: Binary Trees II: AVL Rotations Sufﬁce • Claim: O(n) rotations can transform a binary tree to any other with same traversal order. • Proof: Repeatedly perform last possible right rotation in traversal order; resulting tree is a canonical chain. Each rotation increases depth of the last node by 1. Depth of last node in ﬁnal chain is n − 1, so at most n − 1 rotations are performed. Reverse canonical rotations to reach target tree. • Can maintain height-balance by using O(n) rotations to fully balance the tree, but slow :( • We will keep the tree balanced in O(log n) time per operation! AVL Trees: Height Balance • AVL trees maintain height-balance (also called the AVL Property) – A node is height-balanced if heights of its left and right subtrees differ by at most 1 – Let skew of a node be the height of its right subtree minus that of its left subtree – Then a node is height-balanced if its skew is −1, 0, or 1 • Claim: A binary tree with height-balanced
947	nodes has height h = O(log n) (i.e., n = 2Ω(h)) • Proof: Sufﬁces to show fewest nodes F (h) in any height h tree is F (h) = 2Ω(h) F (h) ≥ 2h/2 F (0) = 1, F (1) = 2, F (h) = 1+F (h−1)+F (h−2) ≥ 2F (h−2) =⇒ • Suppose adding or removing leaf from a height-balanced tree results in imbalance – Only subtrees of the leaf’s ancestors have changed in height or skew – Heights changed by only ±1, so skews still have magnitude ≤ 2 – Idea: Fix height-balance of ancestors starting from leaf up to the root – Repeatedly rebalance lowest ancestor that is not height-balanced, wlog assume skew 2
948	3 Lecture 7: Binary Trees II: AVL • Local Rebalance: Given binary tree node <B>: – whose skew 2 and – every other node in <B>’s subtree is height-balanced, – then <B>’s subtree can be made height-balanced via one or two rotations – (after which <B>’s height is the same or one less than before) • Proof: – Since skew of <B> is 2, <B>’s right child <F> exists – Case 1: skew of <F> is 0 or Case 2: skew of <F> is 1 ∗ Perform a left rotation on <B> 1 __<B>______ ______<F>____ 2 <A> ___<F>___ __<B>___ <G> 3 / \\ <D> <G> => <A> <D> / \\ 4 /___\\ / \\ / \\ / \\ / \\ / \\ 5 /___\\ / \\ /___\\ /___\\ /_____\\ 6 /_____\\ /_____\\ /_____\\ ∗ Let h = height(<A>). Then height(<G>) = h + 1 and height(<D>) is h + 1 in Case 1, h in Case 2 ∗ After rotation: · the skew of <B> is either 1 in Case 1 or 0 in Case 2, so <B> is height
949	balanced · the skew of <F> is −1, so <F> is height balanced · the height of <B> before is h + 3, then after is h + 3 in Case 1, h + 2 in Case 2 – Case 3: skew of <F> is −1, so the left child <D> of <F> exists ∗ Perform a right rotation on <F>, then a left rotation on <B> 1 __<B>___________ _____<D>______ 2 <A> _____<F>__ __<B>__ __<F>__ 3 / \\ __<D>__ <G> => <A> <C> <E> <G> 4 /___\\ <C> <E> / \\ / \\ /_\\ /_\\ / \\ 5 /_\\ /_\\ /___\\ /___\\ /___\\ /___\\ /___\\ 6 /___\\ /___\\ ∗ Let h = height(<A>). Then height(<G>) = h while height(<C>) and height(<E>) are each either h or h − 1 ∗ After rotation: · the skew of <B> is either 0 or −1, so <B> is height balanced · the skew of <F> is either 0 or 1, so <F> is height balanced · the skew of <D> is 0, so D is height balanced · the height of <B> is
950	h + 3 before, then after is h + 2
951	4 Lecture 7: Binary Trees II: AVL • Global Rebalance: Add or remove a leaf from height-balanced tree T to produce tree T 0 . Then T 0 can be transformed into a height-balanced tree T 00 using at most O(log n) rotations. • Proof: – Only ancestors of the affected leaf have different height in T 0 than in T – Affected leaf has at most h = O(log n) ancestors whose subtrees may have changed – Let <X> be lowest ancestor that is not height-balanced (with skew magnitude 2) – If a leaf was added into T : ∗ Insertion increases height of <X>, so in Case 2 or 3 of Local Rebalancing ∗ Rotation decreases subtree height: balanced after one rotation – If a leaf was removed from T : ∗ Deletion decreased height of one child of <X>, not <X>, so only imbalance ∗ Could decrease height of <X> by 1; parent of <X> may now be imbalanced ∗ So may have to rebalance every ancestor of <X>, but at most h = O(log n) of
952	them • So can maintain height-balance using only O(log n) rotations after insertion/deletion! • But requires us to evaluate whether possibly O(log n) nodes were height-balanced Computing Height • How to tell whether node <X> is height-balanced? Compute heights of subtrees! • How to compute the height of node <X>? Naive algorithm: – Recursively compute height of the left and right subtrees of <X> – Add 1 to the max of the two heights – Runs in Ω(n) time, since we recurse on every node :( • Idea: Augment each node with the height of its subtree! (Save for later!) • Height of <X> can be computed in O(1) time from the heights of its children: – Look up the stored heights of left and right subtrees in O(1) time – Add 1 to the max of the two heights • During dynamic operations, we must maintain our augmentation as the tree changes shape • Recompute subtree augmentations at every node whose subtree changes: – Update relinked nodes in a rotation operation in O(1) time (ancestors don’t change) – Update
953	all ancestors of an inserted or deleted node in O(h) time by walking up the tree
954	5 Lecture 7: Binary Trees II: AVL Steps to Augment a Binary Tree • In general, to augment a binary tree with a subtree property P, you must: – State the subtree property P(<X>) you want to store at each node <X> – Show how to compute P(<X>) from the augmentations of <X>’s children in O(1) time • Then stored property P(<X>) can be maintained without changing dynamic operation costs Application: Sequence • For sequence binary tree, we needed to know subtree sizes • For just inserting/deleting a leaf, this was easy, but now need to handle rotations • Subtree size is a subtree property, so can maintain via augmentation – Can compute size from sizes of children by summing them and adding 1 Conclusion • Set AVL trees achieve O(lg n) time for all set operations, except O(n log n) time for build and O(n) time for iter • Sequence AVL trees achieve O(lg n) time for all sequence operations, except O(n) time for build and iter Application: Sorting • Any Set data structure deﬁnes a sorting algorithm: build
955	(or repeatedly insert) then iter • For example, Direct Access Array Sort from Lecture 5 • AVL Sort is a new O(n lg n)-time sorting algorithm
956	MIT OpenCourseWare https://ocw.mit.edu 6.006 Introduction to Algorithms Spring 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms
957	Introduction to Algorithms: 6.006 Massachusetts Institute of Technology Instructors: Erik Demaine, Jason Ku, and Justin Solomon Lecture 20: Course Review Lecture 20: Course Review 6.006: Introduction to Algorithms • Goals: 1. Solve hard computational problems (with non-constant-sized inputs) 2. Argue an algorithm is correct (Induction, Recursion) 3. Argue an algorithm is “good” (Asymptotics, Model of Computation) – (effectively communicate all three above, to human or computer) • Do there always exist “good” algorithms? – Most problems are not solvable efﬁciently, but many we think of are! – Polynomial means polynomial in size of input – Pseudopolynomial means polynomial in size of input AND size of numbers in input – NP: Nondeterministic Polynomial time, polynomially checkable certiﬁcates – NP-hard: set of problems that can be used to solve any problem in NP in poly-time – NP-complete: intersection of NP-hard and NP How to solve an algorithms problem? • Reduce to a problem you know how to solve – Search/Sort (Q1) ∗ Search: Extrinsic (Sequence) and Intrinsic (Set) Data Structures ∗ Sort: Comparison Model, Stability, In-place – Graphs (Q2) ∗ Reachability, Connected
958	Components, Cycle Detection, Topological Sort ∗ Single-Source / All-Pairs Shortest Paths • Design a new recursive algorithm – Brute Force – Divide & Conquer – Dynamic Programming (Q3) – Greedy/Incremental
959	2 Lecture 20: Course Review Next Steps • (U) 6.046: Design & Analysis of Algorithms • (G) 6.851: Advanced Data Structures • (G) 6.854: Advanced Algorithms 6.046 • Extension of 6.006 – Data Structures: Union-Find, Amortization via potential analysis – Graphs: Minimum Spanning Trees, Network Flows/Cuts – Algorithm Design (Paradigms): Divide & Conquer, Dynamic Programming, Greedy – Complexity: Reductions • Relax Problem (change deﬁnition of correct/efﬁcient) – Randomized Algorithms ∗ 6.006 mostly deterministic (hashing) ∗ Las Vegas: always correct, probably fast (like hashing) ∗ Monte Carlo: always fast, probably correct ∗ Can generally get faster randomized algorithms on structured data – Numerical Algorithms/Continuous Optimization ∗ 6.006 only deals with integers ∗ Approximate real numbers! Pay time for precision – Approximation Algorithms ∗ Input optimization problem (min/max over weighted outputs) ∗ Many optimization problems NP-hard ∗ How close can we get to an optimal solution in polynomial time? • Change Model of Computation – Cache Models (memory hierarchy cost model) – Quantum Computer (exploiting quantum properties) – Parallel Processors (use multiple CPUs instead of just one) ∗ Multicore, large shared memory
960	∗ Distributed cores, message passing
961	3 Lecture 20: Course Review Future Courses Model Application • Computation / Complexity (6.045, 6.840, 6.841) • Biology (6.047) • Randomness (6.842) • Game Theory (6.853) • Quantum (6.845) • Cryptography (6.875) • Distributed / message passing (6.852) • Vision (6.819) • Multicore / shared memory (6.816, 6.846) • Graphics (6.837) • Graph and Matrix (6.890) • Geometry (6.850) • Constant Factors / Performance (6.172) • Folding (6.849)
962	MIT OpenCourseWare https://ocw.mit.edu 6.006 Introduction to Algorithms Spring 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms
963	Introduction to Algorithms: 6.006 Massachusetts Institute of Technology Instructors: Erik Demaine, Jason Ku, and Justin Solomon Lecture 6: Binary Trees I Lecture 6: Binary Trees I Previously and New Goal Sequence Data Structure Operations O(·) Container Static Dynamic build(X) get at(i) set at(i,x) insert first(x) delete first() insert last(x) delete last() insert at(i, x) delete at(i) Array n 1 n n n Linked List n n 1 n n Dynamic Array n 1 n 1(a) n Goal n log n log n log n log n Set Data Structure Operations O(·) Container Static Dynamic Order build(X) find(k) insert(x) delete(k) find min() find max() find prev(k) find next(k) Array n n n n n Sorted Array n log n log n n 1 log n Direct Access Array u 1 1 u u Hash Table n(e) 1(e) 1(a)(e) n n Goal n log n log n log n log n log n How? Binary Trees! • Pointer-based data structures (like Linked List) can achieve worst-case performance • Binary tree is pointer-based data structure with three pointers per node • Node representation:
964	node.{item, parent, left, right} • Example: 1 2 3 4 5 ________<A>_____ __<B>_____ <C> __<D> <E> <F> node | item | parent | left | right | <A> | A | - | <B> | <C> | <B> B <A> <C> <D> | | | | | <C> | C | <A> | - | - | <D> | D | <B> | <F> | - | <E> | E | <B> | - | - | <F> F <D> - - | | | | |
965	2 Lecture 6: Binary Trees I Terminology • The root of a tree has no parent (Ex: <A>) • A leaf of a tree has no children (Ex: <C>, <E>, and <F>) • Deﬁne depth(<X>) of node <X> in a tree rooted at <R> to be length of path from <X> to <R> • Deﬁne height(<X>) of node <X> to be max depth of any node in the subtree rooted at <X> • Idea: Design operations to run in O(h) time for root height h, and maintain h = O(log n) • A binary tree has an inherent order: its traversal order – every node in node <X>’s left subtree is before <X> – every node in node <X>’s right subtree is after <X> • List nodes in traversal order via a recursive algorithm starting at root: – Recursively list left subtree, list self, then recursively list right subtree – Runs in O(n) time, since O(1) work is done to list each node – Example: Traversal order is (<F>, <D>, <B>, <E>, <A>, <C>) • Right now, traversal order has
966	no meaning relative to the stored items • Later, assign semantic meaning to traversal order to implement Sequence/Set interfaces Tree Navigation • Find ﬁrst node in the traversal order of node <X>’s subtree (last is symmetric) – If <X> has left child, recursively return the ﬁrst node in the left subtree – Otherwise, <X> is the ﬁrst node, so return it – Running time is O(h) where h is the height of the tree – Example: ﬁrst node in <A>’s subtree is <F> • Find successor of node <X> in the traversal order (predecessor is symmetric) – If <X> has right child, return ﬁrst of right subtree – Otherwise, return lowest ancestor of <X> for which <X> is in its left subtree – Running time is O(h) where h is the height of the tree – Example: Successor of: <B> is <E>, <E> is <A>, and <C> is None
967	3 Lecture 6: Binary Trees I Dynamic Operations • Change the tree by a single item (only add or remove leaves): – add a node after another in the traversal order (before is symmetric) – remove an item from the tree • Insert node <Y> after node <X> in the traversal order – If <X> has no right child, make <Y> the right child of <X> – Otherwise, make <Y> the left child of <X>’s successor (which cannot have a left child) – Running time is O(h) where h is the height of the tree • Example: Insert node <G> before <E> in traversal order 1 _____<A>__ ________<A>__ 2 __<B>__ <C> => __<B>_____ <C> 3 __<D> <E> __<D> __<E> 4 <F> <F> <G> • Example: Insert node <H> after <A> in traversal order 1 ________<A>___ ________<A>_____ 2 __<B>_____ <C> => __<B>_____ __<C> 3 __<D> __<E> __<D> __<E> <H> 4 <F> <G> <F> <G> • Delete the item in node <X> from <X>’s subtree – If <X> is a leaf, detach from parent and return – Otherwise, <X> has a child
968	∗ If <X> has a left child, swap items with the predecessor of <X> and recurse ∗ Otherwise <X> has a right child, swap items with the successor of <X> and recurse – Running time is O(h) where h is the height of the tree – Example: Remove <F> (a leaf) 1 ________<A>_____ ________<A>_____ 2 __<B>_____ __<C> => __<B>_____ __<C> 3 __<D> __<E> <H> <D> __<E> <H> 4 <F> <G> <G> – Example: Remove <A> (not a leaf, so ﬁrst swap down to a leaf) 1 ________<A>_____ ________<E>_____ _____<E>_____ 2 __<B>_____ __<C> => __<B>_____ __<C> => __<B>__ __<C> 3 <D> __<E> <H> <D> __<G> <H> <D> <G> <H> 4 <G> <A>
969	4 Lecture 6: Binary Trees I Application: Set • Idea! Set Binary Tree (a.k.a. Binary Search Tree / BST): Traversal order is sorted order increasing by key – Equivalent to BST Property: for every node, every key in left subtree ≤ node’s key ≤ every key in right subtree • Then can ﬁnd the node with key k in node <X>’s subtree in O(h) time like binary search: – If k is smaller than the key at <X>, recurse in left subtree (or return None) – If k is larger than the key at <X>, recurse in right subtree (or return None) – Otherwise, return the item stored at <X> • Other Set operations follow a similar pattern; see recitation Application: Sequence • Idea! Sequence Binary Tree: Traversal order is sequence order • How do we ﬁnd ith node in traversal order of a subtree? Call this operation subtree at(i) • Could just iterate through entire traversal order, but that’s bad, O(n) • However, if we could compute a subtree’s size in O(1), then can solve in O(h) time –
970	How? Check the size nL of the left subtree and compare to i – If i < nL, recurse on the left subtree – If i > nL, recurse on the right subtree with i0 = i − nL − 1 – Otherwise, i = nL, and you’ve reached the desired node! • Maintain the size of each node’s subtree at the node via augmentation – Add node.size ﬁeld to each node – When adding new leaf, add +1 to a.size for all ancestors a in O(h) time – When deleting a leaf, add −1 to a.size for all ancestors a in O(h) time • Sequence operations follow directly from a fast subtree at(i) operation • Naively, build(X) takes O(nh) time, but can be done in O(n) time; see recitation
971	5 Lecture 6: Binary Trees I So Far Set Data Structure Operations O(·) Container Static Dynamic Order build(X) find(k) insert(x) delete(k) find min() find max() find prev(k) find next(k) Binary Tree n log n h h h h Goal n log n log n log n log n log n Sequence Data Structure Operations O(·) Container Static Dynamic build(X) get at(i) set at(i,x) insert first(x) delete first() insert last(x) delete last() insert at(i, x) delete at(i) Binary Tree n h h h h Goal n log n log n log n log n Next Time • Keep a binary tree balanced after insertion or deletion • Reduce O(h) running times to O(log n) by keeping h = O(log n)
972	MIT OpenCourseWare https://ocw.mit.edu 6.006 Introduction to Algorithms Spring 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms
973	Introduction to Algorithms: 6.006 Massachusetts Institute of Technology Instructors: Erik Demaine, Jason Ku, and Justin Solomon Lecture 4: Hashing Lecture 4: Hashing Review Data Structure Operations O(·) Container Static Dynamic Order build(X) find(k) insert(x) delete(k) find min() find max() find prev(k) find next(k) Array n n n n n Sorted Array n log n log n n 1 log n • Idea! Want faster search and dynamic operations. Can we find(k) faster than Θ(log n)? • Answer is no (lower bound)! (But actually, yes...!?) Comparison Model • In this model, assume algorithm can only differentiate items via comparisons • Comparable items: black boxes only supporting comparisons between pairs • Comparisons are <, ≤, >, ≥, =, =6 , outputs are binary: True or False • Goal: Store a set of n comparable items, support find(k) operation • Running time is lower bounded by # comparisons performed, so count comparisons! Decision Tree • Any algorithm can be viewed as a decision tree of operations performed • An internal node represents a binary comparison, branching either True or False • For a
974	comparison algorithm, the decision tree is binary (draw example) • A leaf represents algorithm termination, resulting in an algorithm output • A root-to-leaf path represents an execution of the algorithm on some input • Need at least one leaf for each algorithm output, so search requires ≥ n + 1 leaves
975	2 Lecture 4: Hashing Comparison Search Lower Bound • What is worst-case running time of a comparison search algorithm? • running time ≥ # comparisons ≥ max length of any root-to-leaf path ≥ height of tree • What is minimum height of any binary tree on ≥ n nodes? • Minimum height when binary tree is complete (all rows full except last) • Height ≥dlg(n + 1)e − 1 = Ω(log n), so running time of any comparison sort is Ω(log n) • Sorted arrays achieve this bound! Yay! • More generally, height of tree with Θ(n) leaves and max branching factor b is Ω(logb n) • To get faster, need an operation that allows super-constant ω(1) branching factor. How?? Direct Access Array • Exploit Word-RAM O(1) time random access indexing! Linear branching factor! • Idea! Give item unique integer key k in {0, . . . , u − 1}, store item in an array at index k • Associate a meaning with each index of array • If keys ﬁt in a machine word, i.e. u ≤ 2w
976	, worst-case O(1) ﬁnd/dynamic operations! Yay! • 6.006: assume input numbers/strings ﬁt in a word, unless length explicitly parameterized • Anything in computer memory is a binary integer, or use (static) 64-bit address in memory • But space O(u), so really bad if n ≪ u... :( • Example: if keys are ten-letter names, for one bit per name, requires 2610 ≈ 17.6 TB space • How can we use less space? Hashing • Idea! If n ≪ u, map keys to a smaller range m = Θ(n) and use smaller direct access array • Hash function: h(k) : {0, . . . , u − 1} →{0, . . . , m − 1} (also hash map) • Direct access array called hash table, h(k) called the hash of key k • If m ≪ u, no hash function is injective by pigeonhole principle
977	3 Lecture 4: Hashing • Always exists keys a, b such that h(a) = h(b) → Collision! :( • Can’t store both items at same index, so where to store? Either: – store somewhere else in the array (open addressing) ∗ complicated analysis, but common and practical – store in another data structure supporting dynamic set interface (chaining) Chaining • Idea! Store collisions in another data structure (a chain) • If keys roughly evenly distributed over indices, chain size is n/m = n/Ω(n) = O(1)! • If chain has O(1) size, all operations take O(1) time! Yay! • If not, many items may map to same location, e.g. h(k) = constant, chain size is Θ(n) :( • Need good hash function! So what’s a good hash function? Hash Functions Division (bad): h(k) = (k mod m) • Heuristic, good when keys are uniformly distributed! • m should avoid symmetries of the stored keys • Large primes far from powers of 2 and 10 can be reasonable • Python uses a version of this with some additional mixing • If u
978	≫ n, every hash function will have some input set that will a create O(n) size chain • Idea! Don’t use a ﬁxed hash function! Choose one randomly (but carefully)!
979	4 Lecture 4: Hashing Universal (good, theoretically): hab(k) = (((ak + b) mod p) mod m) • Hash Family H(p, m) = {hab | a, b ∈{0, . . . , p − 1} and a 6= 0} • Parameterized by a ﬁxed prime p > u, with a and b chosen from range {0, . . . , p − 1} • H is a Universal family: Pr {h(ki) = h(kj )} ≤ 1/m ∀ki =6 kj ∈{0, . . . , u − 1} h∈H • Why is universality useful? Implies short chain lengths! (in expectation) • Xij indicator random variable over h ∈H: Xij = 1 if h(ki) = h(kj ), Xij = 0 otherwise P • Size of chain at index h(ki) is random variable Xi = j Xij • Expected size of chain at index h(ki) ( ) X X X E {Xi} = E Xij = E {Xij } = 1 + E {Xij } h∈H h∈H h∈H h∈H j j j= 6 i X = 1 + (1) Pr {h(ki) = h(kj )}
980	+ (0) Pr {h(ki) =6 h(kj )} h∈H h∈H j6=i X ≤ 1 + 1/m = 1 + (n − 1)/m j6=i • Since m = Ω(n), load factor α = n/m = O(1), so O(1) in expectation! Dynamic • If n/m far from 1, rebuild with new randomly chosen hash function for new size m • Same analysis as dynamic arrays, cost can be amortized over many dynamic operations • So a hash table can implement dynamic set operations in expected amortized O(1) time! :) Data Structure Operations O(·) Container Static Dynamic Order build(X) find(k) insert(x) delete(k) find min() find max() find prev(k) find next(k) Array n n n n n Sorted Array n log n log n n 1 log n Direct Access Array u 1 1 u u Hash Table n(e) 1(e) 1(a)(e) n n
981	MIT OpenCourseWare https://ocw.mit.edu 6.006 Introduction to Algorithms Spring 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms
982	Introduction to Algorithms: 6.006 Massachusetts Institute of Technology Instructors: Erik Demaine, Jason Ku, and Justin Solomon Lecture 16: Dyn. Prog. Subproblems Lecture 16: Dyn. Prog. Subproblems Dynamic Programming Review • Recursion where subproblem dependencies overlap, forming DAG • “Recurse but re-use” (Top down: record and lookup subproblem solutions) • “Careful brute force” (Bottom up: do each subproblem in order) Dynamic Programming Steps (SRT BOT) 1. Subproblem deﬁnition subproblem x 2 X • Describe the meaning of a subproblem in words, in terms of parameters • Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence • Often multiply possible subsets across multiple inputs • Often record partial state: add subproblems by incrementing some auxiliary variables 2. Relate subproblem solutions recursively x(i) = f(x(j), . . .) for one or more j < i • Identify a question about a subproblem solution that, if you knew the answer to, reduces the subproblem to smaller subproblem(s) • Locally brute-force all possible answers to the question 3. Topological order to argue relation is acyclic and subproblems form a DAG 4. Base cases
983	• State solutions for all (reachable) independent subproblems where relation breaks down 5. Original problem • Show how to compute solution to original problem from solutions to subproblem(s) • Possibly use parent pointers to recover actual solution, not just objective function 6. Time analysis P • x2X work(x), or if work(x) = O(W) for all x 2 X, then |X| · O(W) • work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time
984	2 Lecture 16: Dyn. Prog. Subproblems Longest Common Subsequence (LCS) • Given two strings A and B, ﬁnd a longest (not necessarily contiguous) subsequence of A that is also a subsequence of B. • Example: A = hieroglyphology, B = michaelangelo • Solution: hello or heglo or iello or ieglo, all length 5 • Maximization problem on length of subsequence 1. Subproblems • x(i, j) = length of longest common subsequence of sufﬁxes A[i :] and B[j :] • For 0  i  |A| and 0  j  |B| 2. Relate • Either ﬁrst characters match or they don’t • If ﬁrst characters match, some longest common subsequence will use them • (if no LCS uses ﬁrst matched pair, using it will only improve solution) • (if an LCS uses ﬁrst in A[i] and not ﬁrst in B[j], matching B[j] is also optimal) • If they do not match, they cannot both be in a longest common subsequence • Guess whether A[i] or B[j] is not in LCS ⇢ x(i + 1, j + 1) + 1 if
985	A[i] = B[j] • x(i, j) = max{x(i + 1, j), x(i, j + 1)} otherwise • (draw subset of all rectangular grid dependencies) 3. Topological order • Subproblems x(i, j) depend only on strictly larger i or j or both • Simplest order to state: Decreasing i + j • Nice order for bottom-up code: Decreasing i, then decreasing j 4. Base • x(i, |B|) = x(|A|, j) = 0 (one string is empty) 5. Original problem • Length of longest common subsequence of A and B is x(0, 0) • Store parent pointers to reconstruct subsequence • If the parent pointer increases both indices, add that character to LCS
986	3 Lecture 16: Dyn. Prog. Subproblems 6. Time • # subproblems: (|A| + 1) · (|B| + 1) • work per subproblem: O(1) • O(|A| · |B|) running time 1 2 3 4 5 6 7 8 9 10 def lcs(A, B): a, b = len(A), len(B) x = [[0] * (b + 1) for _ in range(a + 1)] for i in reversed(range(a)): for j in reversed(range(b)): if A[i] == B[j]: x[i][j] = x[i + 1][j + 1] + 1 else: x[i][j] = max(x[i + 1][j], x[i][j return x[0][0] + 1])
987	4 Lecture 16: Dyn. Prog. Subproblems Longest Increasing Subsequence (LIS) • Given a string A, ﬁnd a longest (not necessarily contiguous) subsequence of A that strictly increases (lexicographically). • Example: A = carbohydrate • Solution: abort, of length 5 • Maximization problem on length of subsequence • Attempted solution: – Natural subproblems are preﬁxes or sufﬁxes of A, say sufﬁx A[i :] – Natural question about LIS of A[i :]: is A[i] in the LIS? (2 possible answers) – But then how do we recurse on A[i + 1 :] and guarantee increasing subsequence? – Fix: add constraint to subproblems to give enough structure to achieve increasing property 1. Subproblems • x(i) = length of longest increasing subsequence of sufﬁx A[i :] that includes A[i] • For 0  i  |A| 2. Relate • We’re told that A[i] is in LIS (ﬁrst element) • Next question: what is the second element of LIS? – Could be any A[j] where j > i and A[j] > A[i] (so increasing) – Or A[i] might be the last element of LIS •
988	x(i) = max{1 + x(j) | i < j < |A|, A[j] > A[i]} [ {1} 3. Topological order • Decreasing i 4. Base • No base case necessary, because we consider the possibility that A[i] is last 5. Original problem • What is the ﬁrst element of LIS? Guess! • Length of LIS of A is max{x(i) | 0  i < |A|} • Store parent pointers to reconstruct subsequence
989	5 Lecture 16: Dyn. Prog. Subproblems 6. Time • # subproblems: |A| • work per subproblem: O(|A|) • O(|A|2) running time • Exercise: speed up to O(|A| log |A|) by doing only O(log |A|) work per subproblem, via AVL tree augmentation 1 def lis(A): 2 a = len(A) 3 x = [1] * a 4 for i in reversed(range(a)): 5 for j in range(i, a): 6 if A[j] > A[i]: 7 x[i] = max(x[i], 1 + x[j]) 8 return max(x)
990	− − − − − − − − 6 Lecture 16: Dyn. Prog. Subproblems Alternating Coin Game • Given sequence of n coins of value v0, v1, . . . , vn 1 • Two players (“me” and “you”) take turns • In a turn, take ﬁrst or last coin among remaining coins • My goal is to maximize total value of my taken coins, where I go ﬁrst • First solution exploits that this is a zero-sum game: I take all coins you don’t 1. Subproblems • Choose subproblems that correspond to the state of the game • For every contiguous subsequence of coins from i to j, 0  i  j < n • x(i, j) = maximum total value I can take starting from coins of values vi, . . . , vj 2. Relate • I must choose either coin i or coin j (Guess!) • Then it’s your turn, so you’ll get value x(i + 1, j) or x(i, j 1), respectively • To ﬁgure out how much value I get, subtract this from
991	total coin values Pj Pj 1 • x(i, j) = max{vi + vk x(i + 1, j), vj + vk x(i, j 1)} k=i+1 k=i 3. Topological order • Increasing j i 4. Base • x(i, i) = vi 5. Original problem • x(0, n 1) • Store parent pointers to reconstruct strategy 6. Time • # subproblems: ⇥(n2) • work per subproblem: ⇥(n) to compute sums • ⇥(n3) running time Pj • Exercise: speed up to ⇥(n2) time by precomputing all sums k=i vk in ⇥(n2) time, via dynamic programming (!)
992	− − − − 7 Lecture 16: Dyn. Prog. Subproblems • Second solution uses subproblem expansion: add subproblems for when you move next 1. Subproblems • Choose subproblems that correspond to the full state of the game • Contiguous subsequence of coins from i to j, and which player p goes next • x(i, j, p) = maximum total value I can take when player p 2 {me, you} starts from coins of values vi, . . . , vj 2. Relate • Player p must choose either coin i or coin j (Guess!) • If p = me, then I get the value; otherwise, I get nothing • Then it’s the other player’s turn • x(i, j, me) = max{vi + x(i + 1, j, you), vj + x(i, j 1, you)} • x(i, j, you) = min{x(i + 1, j, me), x(i, j 1, me)} 3. Topological order • Increasing j i 4. Base • x(i, i, me) = vi • x(i, i, you) = 0 5. Original problem • x(0, n 1, me) • Store parent pointers
993	to reconstruct strategy 6. Time • # subproblems: ⇥(n2) • work per subproblem: ⇥(1) • ⇥(n2) running time
994	8 Lecture 16: Dyn. Prog. Subproblems Subproblem Constraints and Expansion • We’ve now seen two examples of constraining or expanding subproblems • If you ﬁnd yourself lacking information to check the desired conditions of the problem, or lack the natural subproblem to recurse on, try subproblem constraint/expansion! • More subproblems and constraints give the relation more to work with, so can make DP more feasible • Usually a trade-off between number of subproblems and branching/complexity of relation • More examples next lecture
995	MIT OpenCourseWare https://ocw.mit.edu 6.006 Introduction to Algorithms Spring 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms
996	Introduction to Algorithms: 6.006 Massachusetts Institute of Technology Instructors: Erik Demaine, Jason Ku, and Justin Solomon Lecture 11: Weighted Shortest Paths Lecture 11: Weighted Shortest Paths Review • Single-Source Shortest Paths with BFS in O(|V | + |E|) time (return distance per vertex) • Single-Source Reachability with BFS or DFS in O(|E|) time (return only reachable vertices) • Connected components with Full-BFS or Full-DFS in O(|V | + |E|) time • Topological Sort of a DAG with Full-DFS in O(|V | + |E|) time • Previously: distance = number of edges in path Today: generalize meaning of distance Weighted Graphs • A weighted graph is a graph G = (V, E) together with a weight function w : E → Z • i.e., assigns each edge e = (u, v) ∈ E an integer weight: w(e) = w(u, v) • Many applications for edge weights in a graph: – distances in road network – latency in network connections – strength of a relationship in a social network • Two common ways to represent weights computationally: – Inside graph representation: store
997	edge weight with each vertex in adjacency lists – Store separate Set data structure mapping each edge to its weight • We assume a representation that allows querying the weight of an edge in O(1) time Examples G1 G2 a e b f c g d h 6 8 −2 5 9 −5 7 3 2 −1 −4 1 4 a e b f c g d h 6 8 −2 5 9 −5 7 3 2 −1 −4 1 4
998	2 Restrictions SSSP Algorithm Graph Weights Name Running Time O(·) Lecture General Unweighted BFS |V | + |E| L09 L11 (Today!) L12 L13 DAG Any DAG Relaxation |V | + |E| General Any Bellman-Ford Dijkstra |V | · |E| General Non-negative Lecture 11: Weighted Shortest Paths Weighted Paths • The weight w(π) of a path π in a weighted graph is the sum of weights of edges in the path • The (weighted) shortest path from s ∈ V to t ∈ V is path of minimum weight from s to t • δ(s, t) = inf{w(π) | path π from s to t} is the shortest-path weight from s to t • (Often use “distance” for shortest-path weight in weighted graphs, not number of edges) • As with unweighted graphs: – δ(s, t) = ∞ if no path from s to t – Subpaths of shortest paths are shortest paths (or else could splice in a shorter path) • Why inﬁmum not minimum? Possible that no ﬁnite-length minimum-weight path exists • When? Can occur if there is a negative-weight
999	cycle in the graph, Ex: (b, f, g, c, b) in G1 • A negative-weight cycle is a path π starting and ending at same vertex with w(π) < 0 • δ(s, t) = −∞ if there is a path from s to t through a vertex on a negative-weight cycle • If this occurs, don’t want a shortest path, but may want the negative-weight cycle Weighted Shortest Paths Algorithms • Next four lectures: algorithms to ﬁnd shortest-path weights in weighted graphs • (No parent pointers: can reconstruct shortest paths tree in linear time after. Next page!) • Already know one algorithm: Breadth-First Search! Runs in O(|V | + |E|) time when, e.g.: – graph has positive weights, and all weights are the same – graph has positive weights, and sum of all weights at most O(|V | + |E|) • For general weighted graphs, we don’t know how to solve SSSP in O(|V | + |E|) time • But if your graph is a Directed Acyclic Graph you can! |V | log |V | + |E|
1000	3 Lecture 11: Weighted Shortest Paths Shortest-Paths Tree • For BFS, we kept track of parent pointers during search. Alternatively, compute them after! • If know δ(s, v) for all vertices v ∈ V , can construct shortest-path tree in O(|V | + |E|) time • For weighted shortest paths from s, only need parent pointers for vertices v with ﬁnite δ(s, v) • Initialize empty P and set P (s) = None • For each vertex u ∈ V where δ(s, v) is ﬁnite: – For each outgoing neighbor v ∈ Adj+(u): ∗ If P (v) not assigned and δ(s, v) = δ(s, u) + w(u, v): · There exists a shortest path through edge (u, v), so set P (v) = u • Parent pointers may traverse cycles of zero weight. Mark each vertex in such a cycle. • For each unmarked vertex u ∈ V (including vertices later unmarked): – For each v ∈ Adj+(u) where v is marked and δ(s, v) = δ(s, u) + w(u, v): ∗ Unmark vertices in cycle containing v by traversing
1001	parent pointers from v ∗ Set P (v) = u, breaking the cycle • Exercise: Prove this algorithm correctly computes parent pointers in linear time • Because we can compute parent pointers afterward, we focus on computing distances DAG Relaxation • Idea! Maintain a distance estimate d(s, v) (initially ∞) for each vertex v ∈ V , that always upper bounds true distance δ(s, v), then gradually lowers until d(s, v) = δ(s, v) • When do we lower? When an edge violates the triangle inequality! • Triangle Inequality: the shortest-path weight from u to v cannot be greater than the shortest path from u to v through another vertex x, i.e., δ(u, v) ≤ δ(u, x)+ δ(x, v) for all u, v, x ∈ V • If d(s, v) > d(s, u) + w(u, v) for some edge (u, v), then triangle inequality is violated :( • Fix by lowering d(s, v) to d(s, u) + w(u, v), i.e., relax (u, v) to satisfy violated constraint • Claim: Relaxation is safe: maintains that each d(s, v) is weight of
1002	a path to v (or ∞) ∀v ∈ V • Proof: Assume d(s, v0) is weight of a path (or ∞) for all v0 ∈ V . Relaxing some edge (u, v) sets d(s, v) to d(s, u) + w(u, v), which is the weight of a path from s to v through u.
1003	4 Lecture 11: Weighted Shortest Paths • Set d(s, v) = ∞ for all v ∈ V , then set d(s, s) = 0 • Process each vertex u in a topological sort order of G: – For each outgoing neighbor v ∈ Adj+(u): ∗ If d(s, v) > d(s, u) + w(u, v): · relax edge (u, v), i.e., set d(s, v) = d(s, u) + w(u, v) • Example: Run DAG Relaxation from vertex a in G2 Correctness • Claim: At end of DAG Relaxation: d(s, v) = δ(s, v) for all v ∈ V • Proof: Induct on k: d(s, v) = δ(s, v) for all v in ﬁrst k vertices in topological order – Base case: Vertex s and every vertex before s in topological order satisﬁes claim at start – Inductive step: Assume claim holds for ﬁrst k0 vertices, let v be the (k0 + 1)th – Consider a shortest path from s to v, and let u be the vertex preceding v on path – u occurs before v in topological order, so d(s,
1004	u) = δ(s, u) by induction – When processing u, d(s, v) is set to be no larger (≤) than δ(s, u) + w(u, v) = δ(s, v) – But d(s, v) ≥ δ(s, v), since relaxation is safe, so d(s, v) = δ(s, v) • Alternatively: – For any vertex v, DAG relaxation sets d(s, v) = min{d(s, u)+w(u, v) | u ∈ Adj−(v)} – Shortest path to v must pass through some incoming neighbor u of v – So if d(s, u) = δ(s, u) for all u ∈ Adj−(v) by induction, then d(s, v) = δ(s, v) Running Time • Initialization takes O(|V |) time, and Topological Sort takes O(|V | + |E|) time P • Additional work upper bounded by O(1) × deg+(u) = O(|E|) u∈V • Total running time is linear, O(|V | + |E|)
1005	MIT OpenCourseWare https://ocw.mit.edu 6.006 Introduction to Algorithms Spring 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms
1006	Introduction to Algorithms: 6.006 Massachusetts Institute of Technology Instructors: Erik Demaine, Jason Ku, and Justin Solomon Lecture 1: Introduction Lecture 1: Introduction The goal of this class is to teach you to solve computation problems, and to communicate that your solutions are correct and efﬁcient. Problem • Binary relation from problem inputs to correct outputs • Usually don’t specify every correct output for all inputs (too many!) • Provide a veriﬁable predicate (a property) that correct outputs must satisfy • 6.006 studies problems on large general input spaces • Not general: small input instance – Example: In this room, is there a pair of students with same birthday? • General: arbitrarily large inputs – Example: Given any set of n students, is there a pair of students with same birthday? – If birthday is just one of 365, for n > 365, answer always true by pigeon-hole – Assume resolution of possible birthdays exceeds n (include year, time, etc.) Algorithm • Procedure mapping each input to a single output (deterministic) • Algorithm solves a problem if it returns a correct
1007	output for every problem input • Example: An algorithm to solve birthday matching – Maintain a record of names and birthdays (initially empty) – Interview each student in some order ∗ If birthday exists in record, return found pair! ∗ Else add name and birthday to record – Return None if last student interviewed without success
1008	2 Lecture 1: Introduction Correctness • Programs/algorithms have ﬁxed size, so how to prove correct? • For small inputs, can use case analysis • For arbitrarily large inputs, algorithm must be recursive or loop in some way • Must use induction (why recursion is such a key concept in computer science) • Example: Proof of correctness of birthday matching algorithm – Induct on k: the number of students in record – Hypothesis: if ﬁrst k contain match, returns match before interviewing student k + 1 – Base case: k = 0, ﬁrst k contains no match – Assume for induction hypothesis holds for k = k0, and consider k = k0 + 1 – If ﬁrst k0 contains a match, already returned a match by induction – Else ﬁrst k0 do not have match, so if ﬁrst k0 + 1 has match, match contains k0 + 1 – Then algorithm checks directly whether birthday of student k0 + 1 exists in ﬁrst k0 Efﬁciency • How fast does an algorithm produce a correct output? – Could measure time, but want
1009	performance to be machine independent – Idea! Count number of ﬁxed-time operations algorithm takes to return – Expect to depend on size of input: larger input suggests longer time – Size of input is often called ‘n’, but not always! – Efﬁcient if returns in polynomial time with respect to input – Sometimes no efﬁcient algorithm exists for a problem! (See L20) • Asymptotic Notation: ignore constant factors and low order terms – Upper bounds (O), lower bounds (Ω), tight bounds (Θ) ∈, =, is, order – Time estimate below based on one operation per cycle on a 1 GHz single-core machine – Particles in universe estimated < 10100 input constant logarithmic linear log-linear quadratic polynomial exponential n Θ(1) Θ(log n) Θ(n) Θ(n log n) Θ(n2) Θ(nc) 2Θ(nc) 1000 1 ≈ 10 1000 ≈ 10,000 1,000,000 1000c 21000 ≈ 10301 Time 1 ns 10 ns 1 µs 10 µs 1 ms 103c−9 s 10281 millenia
1010	3 Lecture 1: Introduction Model of Computation • Speciﬁcation for what operations on the machine can be performed in O(1) time • Model in this class is called the Word-RAM • Machine word: block of w bits (w is word size of a w-bit Word-RAM) • Memory: Addressable sequence of machine words • Processor supports many constant time operations on a O(1) number of words (integers): – integer arithmetic: (+, -, *, //, %) – logical operators: (&&, ||, !, ==, <, >, <=, =>) – (bitwise arithmetic: (&, |, <<, >>, ...)) – Given word a, can read word at address a, write word to address a • Memory address must be able to access every place in memory – Requirement: w ≥ # bits to represent largest memory address, i.e., log2 n – 32-bit words → max ∼ 4 GB memory, 64-bit words → max ∼ 16 exabytes of memory • Python is a more complicated model of computation, implemented on a Word-RAM Data Structure • A data structure is a way to store non-constant data, that supports
1011	a set of operations • A collection of operations is called an interface – Sequence: Extrinsic order to items (ﬁrst, last, nth) – Set: Intrinsic order to items (queries based on item keys) • Data structures may implement the same interface with different performance • Example: Static Array - ﬁxed width slots, ﬁxed length, static sequence interface – StaticArray(n): allocate static array of size n initialized to 0 in Θ(n) time – StaticArray.get at(i): return word stored at array index i in Θ(1) time – StaticArray.set at(i, x): write word x to array index i in Θ(1) time • Stored word can hold the address of a larger object • Like Python tuple plus set at(i, x), Python list is a dynamic array (see L02)
1012	4 Lecture 1: Introduction 1 def birthday_match(students): 2 ’’’ 3 Find a pair of students with the same birthday 4 Input: tuple of student (name, bday) tuples 5 Output: tuple of student names or None 6 ’’’ 7 n = len(students) # O(1) 8 record = StaticArray(n) # O(n) 9 for k in range(n): # n 10 (name1, bday1) = students[k] # O(1) 11 # Return pair if bday1 in record 12 for i in range(k): # k 13 (name2, bday2) = record.get_at(i) # O(1) 14 if bday1 == bday2: # O(1) 15 return (name1, name2) # O(1) 16 record.set_at(k, (name1, bday1)) # O(1) 17 return None # O(1) Example: Running Time Analysis • Two loops: outer k ∈{0, . . . , n − 1}, inner is i ∈{0, . . . , k} P n−1 • Running time is O(n) + k=0 (O(1) + k · O(1)) = O(n2) • Quadratic in n is polynomial. Efﬁcient? Use different data structure for record! How to Solve an Algorithms Problem 1. Reduce to a problem you already know (use data
1013	structure or algorithm) Search Problem (Data Structures) Sort Algorithms Static Array (L01) Insertion Sort (L03) Linked List (L02) Selection Sort (L03) Dynamic Array (L02) Merge Sort (L03) Sorted Array (L03) Counting Sort (L05) Direct-Access Array (L04) Radix Sort (L05) Hash Table (L04) AVL Sort (L07) Balanced Binary Tree (L06-L07) Heap Sort (L08) Binary Heap (L08) 2. Design your own (recursive) algorithm • Brute Force • Decrease and Conquer • Divide and Conquer • Dynamic Programming (L15-L19) • Greedy / Incremental Shortest Path Algorithms Breadth First Search (L09) DAG Relaxation (L11) Depth First Search (L10) Topological Sort (L10) Bellman-Ford (L12) Dijkstra (L13) Johnson (L14) Floyd-Warshall (L18)
1014	MIT OpenCourseWare https://ocw.mit.edu 6.006 Introduction to Algorithms Spring 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms
1015	Restrictions SSSP Algorithm Graph Weights Name Running Time O(·) Lecture General Unweighted BFS |V | + |E| L09 L11 L12 (Today!) L13 DAG Any DAG Relaxation |V | + |E| General Any Bellman-Ford Dijkstra |V | · |E| General Non-negative Introduction to Algorithms: 6.006 Massachusetts Institute of Technology Instructors: Erik Demaine, Jason Ku, and Justin Solomon Lecture 12: Bellman-Ford Lecture 12: Bellman-Ford Previously • Weighted graphs, shortest-path weight, negative-weight cycles • Finding shortest-path tree from shortest-path weights in O(|V | + |E|) time • DAG Relaxation: algorithm to solve SSSP on a weighted DAG in O(|V | + |E|) time • SSSP for graph with negative weights – Compute δ(s, v) for all v ∈ V (−∞ if v reachable via negative-weight cycle) – If a negative-weight cycle reachable from s, return one Warmups • Exercise 1: Given undirected graph G, return whether G contains a negative-weight cycle • Solution: Return Yes if there is an edge with negative weight in G in O(|E|) time :O • So for this lecture, we restrict our discussion to directed graphs • Exercise
1016	2: Given SSSP algorithm A that runs in O(|V |(|V | + |E|) time, show how to use it to solve SSSP in O(|V ||E|) time • Solution: Run BFS or DFS to ﬁnd the vertices reachable from s in O(|E|) time – Mark each vertex v not reachable from s with δ(s, v) = ∞ in O(|V |) time – Make graph G0 = (V 0, E0) with only vertices reachable from s in O(|V | + |E|) time – Run A from s in G0 . – G0 is connected, so |V 0| = O(|E0|) = O(|E|) so A runs in O(|V ||E|) time • Today, we will ﬁnd a SSSP algorithm with this running time that works for general graphs! |V | log |V | + |E|
1017	2 Lecture 12: Bellman-Ford Simple Shortest Paths • If graph contains cycles and negative weights, might contain negative-weight cycles :( • If graph does not contain negative-weight cycles, shortest paths are simple! • Claim 1: If δ(s, v) is ﬁnite, there exists a shortest path to v that is simple • Proof: By contradiction: – Suppose no simple shortest path; let π be a shortest path with fewest vertices – π not simple, so exists cycle C in π; C has non-negative weight (or else δ(s, v) = −∞) – Removing C from π forms path π0 with fewer vertices and weight w(π0) ≤ w(π) • Since simple paths cannot repeat vertices, ﬁnite shortest paths contain at most |V | − 1 edges Negative Cycle Witness • k-Edge Distance δk(s, v): the minimum weight of any path from s to v using ≤ k edges • Idea! Compute δ|V |−1(s, v) and δ|V |(s, v) for all v ∈ V – If δ(s, v) =6 −∞, δ(s, v) = δ|V |−1(s, v), since a shortest path is simple (or nonexistent)
1018	– If δ|V |(s, v) < δ|V |−1(s, v) ∗ there exists a shorter non-simple path to v, so δ|V |(s, v) = −∞ ∗ call v a (negative cycle) witness – However, there may be vertices with −∞ shortest-path weight that are not witnesses • Claim 2: If δ(s, v) = −∞, then v is reachable from a witness • Proof: Sufﬁces to prove: every negative-weight cycle reachable from s contains a witness – Consider a negative-weight cycle C reachable from s P 0 – For v ∈ C, let v0 ∈ C denote v’s predecessor in C, where v∈C w(v , v) < 0 – Then δ|V |(s, v) ≤ δ|V |−1(s, v0)+w(v0, v) (RHS weight of some path on ≤|V | vertices) P P P P – So δ|V |(s, v) ≤ δ|V |−1(s, v0) + w(v0, v) < δ|V |−1(s, v) v∈C v∈C v∈C v∈C – If C contains no witness, δ|V |(s, v) ≥ δ|V |−1(s, v) for all v ∈ C, a contradiction
1019	3 Lecture 12: Bellman-Ford Bellman-Ford • Idea! Use graph duplication: make multiple copies (or levels) of the graph • |V | + 1 levels: vertex vk in level k represents reaching vertex v from s using ≤ k edges • If edges only increase in level, resulting graph is a DAG! • Construct new DAG G0 = (V 0, E0) from G = (V, E): – G0 has |V |(|V | + 1) vertices vk for all v ∈ V and k ∈{0, . . . , |V |} – G0 has |V |(|V | + |E|) edges: ∗|V | edges (vk−1, vk) for k ∈{1, . . . , |V |} of weight zero for each v ∈ V ∗|V | edges (uk−1, vk) for k ∈{1, . . . , |V |} of weight w(u, v) for each (u, v) ∈ E • Run DAG Relaxation on G0 from s0 to compute δ(s0, vk) for all vk ∈ V 0 • For each vertex: set d(s, v) = δ(s0, v|V |−1) • For each witness u ∈ V
1020	where δ(s0, u|V |) < δ(s0, u|V |−1): – For each vertex v reachable from u in G: ∗ set d(s, v) = −∞ Example G G0 a b c d 6 3 −5 −1 −4 a0 b0 d0 c0 a1 b1 d1 c1 a2 b2 d2 c2 a3 b3 d3 c3 a4 b4 d4 c4 −5 6 −4 −1 3 0 0 0 0 δ(a0, vk) k \\ v a b c d 0 0 ∞ ∞ ∞ 1 0 −5 6 ∞ 2 0 −5 −9 9 3 0 −5 −9 −6 4 0 −7 −9 −6 δ(a, v) 0 −∞ −∞ −∞
1021	4 Lecture 12: Bellman-Ford Correctness • Claim 3: δ(s0, vk) = δk(s, v) for all v ∈ V and k ∈{0, . . . , |V |} • Proof: By induction on k: – Base case: true for all v ∈ V when k = 0 (only v0 reachable from s0 is v = s) – Inductive Step: Assume true for all k < k0, prove for k = k0 δ(s0, vk0 ) = min{δ(s0, uk0−1) + w(uk0−1, vk0 ) | uk0−1 ∈ Adj−(vk0 )} = min{{δ(s0, uk0−1) + w(u, v) | u ∈ Adj−(v)} ∪{δ(s0, vk0−1)}} = min{{δk0−1(s, u) + w(u, v) | u ∈ Adj−(v)} ∪{δk0−1(s, v)}} (by induction) = δk0 (s, v) • Claim 4: At the end of Bellman-Ford d(s, v) = δ(s, v) • Proof: Correctly computes δ|V |−1(s, v) and δ|V |(s, v) for all v ∈ V by Claim 3 – If δ(s, v) =6 −∞, correctly sets d(s, v) = δ|V |−1(s, v) = δ(s, v) – Then sets d(s, v) = −∞ for any v reachable from a witness; correct by
1022	Claim 2 Running Time • G0 has size O(|V |(|V | + |E|)) and can be constructed in as much time • Running DAG Relaxation on G0 takes linear time in the size of G0 • Does O(1) work for each vertex reachable from a witness • Finding reachability of a witness takes O(|E|) time, with at most O(|V |) witnesses: O(|V ||E|) • (Alternatively, connect super node x to witnesses via 0-weight edges, linear search from x) • Pruning G at start to only subgraph reachable from s yields O(|V ||E|)-time algorithm Extras: Return Negative-Weight Cycle or Space Optimization • Claim 5: Shortest s0 − v|V | path π for any witness v contains a negative-weight cycle in G • Proof: Since π contains |V | + 1 vertices, must contain at least one cycle C in G – C has negative weight (otherwise, remove C to make path π0 with fewer vertices and w(π0) ≤ w(π), contradicting witness v) • Can use just O(|V |) space by storing only δ(s0, vk−1) and δ(s0, vk) for each k from
1023	1 to |V | • Traditionally, Bellman-Ford stores only one value per vertex, attempting to relax every edge in |V | rounds; but estimates do not correspond to k-Edge Distances, so analysis trickier • But these space optimizations don’t return a negative weight cycle
1024	MIT OpenCourseWare https://ocw.mit.edu 6.006 Introduction to Algorithms Spring 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms
1025	Introduction to Algorithms: 6.006 Massachusetts Institute of Technology Instructors: Erik Demaine, Jason Ku, and Justin Solomon Lecture 19: Complexity Lecture 19: Complexity Decision Problems • Decision problem: assignment of inputs to YES (1) or NO (0) • Inputs are either NO inputs or YES inputs Problem s-t Shortest Path Does a given G contain a path from s to t with weight at most d? Negative Cycle Does a given G contain a negative weight cycle? Longest Simple Path Does a given G contain a simple path with weight at least d? Subset Sum Does a given set of integers A contain a subset with sum S? Tetris Can you survive a given sequence of pieces in given board? Chess Can a player force a win from a given board? Halting problem Does a given computer program terminate for a given input? Decision • Algorithm/Program: constant-length code (working on a word-RAM with Ω(log n)-bit words) to solve a problem, i.e., it produces correct output for every input and the length of the code is independent of the instance size •
1026	Problem is decidable if there exists a program to solve the problem in ﬁnite time Decidability • Program is ﬁnite (constant) string of bits, i.e., a nonnegative integer ∈ N. Problem is function p : N →{0, 1}, i.e., inﬁnite string of bits. • (# of programs |N|, countably inﬁnite) ≪ (# of problems |R|, uncountably inﬁnite) • (Proof by Cantor’s diagonalization argument, probably covered in 6.042) • Proves that most decision problems not solvable by any program (undecidable) • E.g., the Halting problem is undecidable (many awesome proofs in 6.045) • Fortunately most problems we think of are algorithmic in structure and are decidable Decidable Decision Problems R problems decidable in ﬁnite time (‘R’ comes from recursive languages) EXP problems decidable in exponential time 2nO(1) (most problems we think of are here) P problems decidable in polynomial time nO(1) (efﬁcient algorithms, the focus of this class) • These sets are distinct, i.e., P $ EXP $ R (via time hierarchy theorems, see 6.045) • E.g., Chess is in EXP \\ P
1027	2 Lecture 19: Complexity Nondeterministic Polynomial Time (NP) • P is the set of decision problems for which there is an algorithm A such that, for every input I of size n, A on I runs in poly(n) time and solves I correctly • NP is the set of decision problems for which there is a veriﬁcation algorithm V that takes as input an input I of the problem and a certiﬁcate bit string of length polynomial in the size of I, so that: – V always runs in time polynomial in the size of I; – if I is a YES input, then there is some certiﬁcate c so that V outputs YES on input (I, c); and – if I is a NO input, then no matter what certiﬁcate c we choose, V always output NO on input (I, c). • You can think of the certiﬁcate as a proof that I is a YES input. If I is actually a NO input, then no proof should work. Problem Certiﬁcate Veriﬁer s-t Shortest Path Negative Cycle Longest Simple
1028	Path Subset Sum Tetris A path P from s to t A cycle C A path P A set of items A0 Sequence of moves Adds the weights on P and checks whether ≤ d Adds the weights on C and checks whether < 0 Checks whether P is a simple path with weight ≥ d Checks whether A0 ∈ A has sum S Checks that the moves allow survival • P ⊆ NP: The veriﬁer V just solves the instance ignoring any certiﬁcate • NP ⊆ EXP: Try all possible certiﬁcates! At most 2nO(1) of them, run veriﬁer V on all • Open: Does P = NP? NP = EXP? • Most people think P $ NP ($ EXP), i.e., generating solutions harder than checking • If you prove either way, people will give you lots of money ($1M Millennium Prize) • Why do we care? If can show a problem is hardest problem in NP, then problem cannot be solved in polynomial time if P 6= NP • How do we relate difﬁculty of problems? Reductions!
1029	3 Lecture 19: Complexity Reductions • Suppose you want to solve problem A • One way to solve is to convert A into a problem B you know how to solve • Solve using an algorithm for B and use it to compute solution to A • This is called a reduction from problem A to problem B (A → B) • Because B can be used to solve A, B is at least as hard as A (A ≤ B) • General algorithmic strategy: reduce to a problem you know how to solve A Conversion B Unweighted Shortest Path Integer-weighted Shortest Path Longest Path Give equal weights Subdivide edges Negate weights Weighted Shortest Path Unweighted Shortest Path Shortest Path • Problem A is NP-hard if every problem in NP is polynomially reducible to A • i.e., A is at least as hard as (can be used to solve) every problem in NP (X ≤ A for X ∈ NP) • NP-complete = NP ∩ NP-hard • All NP-complete problems are equivalent, i.e., reducible to each other • First NP-complete
1030	problem? Every decision problem reducible to satisfying a logical circuit, a problem called “Circuit SAT”. • Longest Simple Path and Tetris are NP-complete, so if any problem is in NP \\ P, these are • Chess is EXP-complete: in EXP and reducible from every problem in EXP (so ∈/ P)
1031	4 Lecture 19: Complexity Examples of NP-complete Problems • Subset Sum from L18 (“weakly NP-complete” which is what allows a pseudopolynomial­ time algorithm, but no polynomial algorithm unless P = NP) • 3-Partition: given n integers, can you divide them into triples of equal sum? (“strongly NP-complete”: no pseudopolynomial-time algorithm unless P = NP) • Rectangle Packing: given n rectangles and a target rectangle whose area is the sum of the n rectangle areas, pack without overlap – Reduction from 3-Partition to Rectangle Packing: transform integer ai into 1 × ai rect- P angle; set target rectangle to n/3 × ( i ai) /3 • Jigsaw puzzles: given n pieces with possibly ambiguous tabs/pockets, ﬁt the pieces together – Reduction from Rectangle Packing: use uniquely matching tabs/pockets to force build­ ing rectangles and rectangular boundary; use one ambiguous tab/pocket for all other boundaries • Longest common subsequence of n strings • Longest simple path in a graph • Traveling Salesman Problem: shortest path that visits all vertices of a given graph (or deci­ sion version: is minimum weight ≤ d)
1032	• Shortest path amidst obstacles in 3D • 3-coloring given graph (but 2-coloring ∈ P) • Largest clique in a given graph • SAT: given a Boolean formula (made with AND, OR, NOT), is it every true? E.g., x AND NOT x is a NO input • Minesweeper, Sudoku, and most puzzles • Super Mario Bros., Legend of Zelda, Pok´emon, and most video games are NP-hard (many are harder)
1033	MIT OpenCourseWare https://ocw.mit.edu 6.006 Introduction to Algorithms Spring 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms
1034	Restrictions SSSP Algorithm Graph Weights Name Running Time O(·) Lecture General Unweighted BFS |V | + |E| L09 L11 L12 L13 (Today!) DAG Any DAG Relaxation |V | + |E| General Any Bellman-Ford Dijkstra |V | · |E| General Non-negative Introduction to Algorithms: 6.006 Massachusetts Institute of Technology Instructors: Erik Demaine, Jason Ku, and Justin Solomon Lecture 13: Dijkstra’s Algorithm Lecture 13: Dijkstra’s Algorithm Review • Single-Source Shortest Paths on weighted graphs • Previously: O(|V | + |E|)-time algorithms for small positive weights or DAGs • Last time: Bellman-Ford, O(|V ||E|)-time algorithm for general graphs with negative weights • Today: faster for general graphs with non-negative edge weights, i.e., for e ∈ E, w(e) ≥ 0 |V | log |V | + |E| Non-negative Edge Weights • Idea! Generalize BFS approach to weighted graphs: – Grow a sphere centered at source s – Repeatedly explore closer vertices before further ones – But how to explore closer vertices if you don’t know distances beforehand? :( • Observation 1: If weights non-negative, monotonic distance increase along shortest paths – i.e., if vertex
1035	u appears on a shortest path from s to v, then δ(s, u) ≤ δ(s, v) – Let Vx ⊂ V be the subset of vertices reachable within distance ≤ x from s – If v ∈ Vx, then any shortest path from s to v only contains vertices from Vx – Perhaps grow Vx one vertex at a time! (but growing for every x is slow if weights large) • Observation 2: Can solve SSSP fast if given order of vertices in increasing distance from s – Remove edges that go against this order (since cannot participate in shortest paths) – May still have cycles if zero-weight edges: repeatedly collapse into single vertices – Compute δ(s, v) for each v ∈ V using DAG relaxation in O(|V | + |E|) time
1036	2 Lecture 13: Dijkstra’s Algorithm Dijkstra’s Algorithm • Named for famous Dutch computer scientist Edsger Dijkstra (actually D¨ykstra!) • Idea! Relax edges from each vertex in increasing order of distance from source s • Idea! Efﬁciently ﬁnd next vertex in the order using a data structure • Changeable Priority Queue Q on items with keys and unique IDs, supporting operations: Q.build(X) initialize Q with items in iterator X Q.delete min() remove an item with minimum key Q.decrease key(id, k) ﬁnd stored item with ID id and change key to k • Implement by cross-linking a Priority Queue Q0 and a Dictionary D mapping IDs into Q0 • Assume vertex IDs are integers from 0 to |V | − 1 so can use a direct access array for D • For brevity, say item x is the tuple (x.id, x.key) • Set d(s, v) = ∞ for all v ∈ V , then set d(s, s) = 0 • Build changeable priority queue Q with an item (v, d(s, v)) for each vertex v ∈ V • While Q not empty,
1037	delete an item (u, d(s, u)) from Q that has minimum d(s, u) – For vertex v in outgoing adjacencies Adj+(u): ∗ If d(s, v) > d(s, u) + w(u, v): · Relax edge (u, v), i.e., set d(s, v) = d(s, u) + w(u, v) · Decrease the key of v in Q to new estimate d(s, v) • Run Dijkstra on example
1038	3 Lecture 13: Dijkstra’s Algorithm Example Delete v from Q s c d a b δ(s, v) s 0 0 Correctness a ∞ 10 7 7 7 d(s, v) b ∞ ∞ 11 10 9 9 c ∞ 3 3 d 2 G ∞ 10 ∞ 1 5 s a b c d 4 7 5 8 3 2 5 • Claim: At end of Dijkstra’s algorithm, d(s, v) = δ(s, v) for all v ∈ V • Proof: – If relaxation sets d(s, v) to δ(s, v), then d(s, v) = δ(s, v) at the end of the algorithm ∗ Relaxation can only decrease estimates d(s, v) ∗ Relaxation is safe, i.e., maintains that each d(s, v) is weight of a path to v (or ∞) – Sufﬁces to show d(s, v) = δ(s, v) when vertex v is removed from Q ∗ Proof by induction on ﬁrst k vertices removed from Q ∗ Base Case (k = 1): s is ﬁrst vertex removed from Q, and d(s, s) = 0 = δ(s, s) ∗ Inductive Step: Assume true
1039	for k < k0, consider k0th vertex v0 removed from Q ∗ Consider some shortest path π from s to v0, with w(π) = δ(s, v0) ∗ Let (x, y) be the ﬁrst edge in π where y is not among ﬁrst k0 − 1 (perhaps y = v0) ∗ When x was removed from Q, d(s, x) = δ(s, x) by induction, so: d(s, y) ≤ δ(s, x) + w(x, y) relaxed edge (x, y) when removed x = δ(s, y) subpaths of shortest paths are shortest paths ≤ δ(s, v 0) non-negative edge weights 0) ≤ d(s, v relaxation is safe ≤ d(s, y) v 0 is vertex with minimum d(s, v 0) in Q ∗ So d(s, v0) = δ(s, v0), as desired
1040	4 Lecture 13: Dijkstra’s Algorithm Running Time • Count operations on changeable priority queue Q, assuming it contains n items: Operation Time Occurrences in Dijkstra Q.build(X) (n = |X|) Q.delete min() Q.decrease key(id, k) Bn Mn Dn 1 |V | |E| • Total running time is O(B|V | + |V | · M|V | + |E| · D|V |) • Assume pruned graph to search only vertices reachable from the source, so |V | = O(|E|) Priority Queue Q0 Q Operations O(·) Dijkstra O(·) n = |V | = O(|E|) on n items build(X) delete min() decrease key(id, k) Array n n 1 |V |2 Binary Heap n log n(a) log n |E| log |V | Fibonacci Heap n log n(a) 1(a) |E| + |V | log |V | • If graph is dense, i.e., |E| = Θ(|V |2), using an Array for Q0 yields O(|V |2) time • If graph is sparse, i.e., |E| = Θ(|V |), using a Binary Heap for Q0 yields O(|V | log |V |) time • A Fibonacci Heap is theoretically good in all
1041	cases, but is not used much in practice • We won’t discuss Fibonacci Heaps in 6.006 (see 6.854 or CLRS chapter 19 for details) • You should assume Dijkstra runs in O(|E|+|V | log |V |) time when using in theory problems Summary: Weighted Single-Source Shortest Paths Restrictions SSSP Algorithm Graph Weights Name Running Time O(·) General Unweighted BFS |V | + |E| DAG Any DAG Relaxation |V | + |E| General Non-negative Dijkstra Bellman-Ford |V | log |V | + |E| |V | · |E| General Any • What about All-Pairs Shortest Paths? • Doing a SSSP algorithm |V | times is actually pretty good, since output has size O(|V |2) • Can do better than |V | · O(|V | · |E|) for general graphs with negative weights (next time!)
1042	MIT OpenCourseWare https://ocw.mit.edu 6.006 Introduction to Algorithms Spring 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms
1043	Introduction to Algorithms: 6.006 Massachusetts Institute of Technology Instructors: Erik Demaine, Jason Ku, and Justin Solomon Lecture 18: Pseudopolynomial Lecture 18: Pseudopolynomial Dynamic Programming Steps (SRT BOT) 1. Subproblem deﬁnition subproblem x ∈ X • Describe the meaning of a subproblem in words, in terms of parameters • Often subsets of input: preﬁxes, sufﬁxes, contiguous substrings of a sequence • Often multiply possible subsets across multiple inputs • Often record partial state: add subproblems by incrementing some auxiliary variables • Often smaller integers than a given integer (today’s focus) 2. Relate subproblem solutions recursively x(i) = f(x(j), . . .) for one or more j < i • Identify a question about a subproblem solution that, if you knew the answer to, reduces the subproblem to smaller subproblem(s) • Locally brute-force all possible answers to the question 3. Topological order to argue relation is acyclic and subproblems form a DAG 4. Base cases • State solutions for all (reachable) independent subproblems where relation breaks down 5. Original problem • Show how to compute solution to original problem from solutions to
1044	subproblem(s) • Possibly use parent pointers to recover actual solution, not just objective function 6. Time analysis P • work(x), or if work(x) = O(W ) for all x ∈ X, then |X| · O(W ) x∈X • work(x) measures nonrecursive work in relation; treat recursions as taking O(1) time
1045	2 Lecture 18: Pseudopolynomial Rod Cutting • Given a rod of length L and value v(`) of rod of length ` for all ` ∈{1, 2, . . . , L} • Goal: Cut the rod to maximize the value of cut rod pieces • Example: L = 7, v = [0, 1, 10, 13, 18, 20, 31, 32] ` = 0 1 2 3 4 5 6 7 • Maybe greedily take most valuable per unit length? • Nope! arg max` v[`]/` = 6, and partitioning [6, 1] yields 32 which is not optimal! • Solution: v[2] + v[2] + v[3] = 10 + 10 + 13 = 33 • Maximization problem on value of partition 1. Subproblems • x(`): maximum value obtainable by cutting rod of length ` • For ` ∈{0, 1, . . . , L} 2. Relate • First piece has some length p (Guess!) • x(`) = max{v(p) + x(` − p) | p ∈{1, . . . , `}} • (draw dependency graph) 3. Topological order • Increasing `: Subproblems x(`) depend only
1046	on strictly smaller `, so acyclic 4. Base • x(0) = 0 (length-zero rod has no value!) 5. Original problem • Maximum value obtainable by cutting rod of length L is x(L) • Store choices to reconstruct cuts • If current rod length ` and optimal choice is `0, remainder is piece p = ` − `0 • (maximum-weight path in subproblem DAG!) 6. Time • # subproblems: L + 1 • work per subproblem: O(`) = O(L) • O(L2) running time
1047	3 Lecture 18: Pseudopolynomial Is This Polynomial Time? • (Strongly) polynomial time means that the running time is bounded above by a constant- degree polynomial in the input size measured in words • In Rod Cutting, input size is L + 1 words (one integer L and L integers in v) • O(L2) is a constant-degree polynomial in L + 1, so YES: (strongly) polynomial time 1 # recursive 2 x = {} 3 def cut_rod(l, v): 4 if l < 1: return 0 # base case 5 if l not in x: # check memo 6 for piece in range(1, l + 1): # try piece 7 x_ = v[piece] + cut_rod(l - piece, v) # recurrence 8 if (l not in x) or (x[l] < x_): # update memo 9 x[l] = x_ 10 return x[l] 1 # iterative 2 def cut_rod(L, v): 3 x = [0] * (L + 1) # base case 4 for l in range(L + 1): # topological order 5 for piece in range(1, l + 1): # try piece 6 x_ =
1048	v[piece] + x[l - piece] # recurrence 7 if x[l] < x_: # update memo 8 x[l] = x_ 9 return x[L] 1 # iterative with parent pointers 2 def cut_rod_pieces(L, v): 3 x = [0] * (L + 1) # base case 4 parent = [None] * (L + 1) # parent pointers 5 for l in range(1, L + 1): # topological order 6 for piece in range(1, l + 1): # try piece 7 x_ = v[piece] + x[l - piece] # recurrence 8 if x[l] < x_: # update memo 9 x[l] = x_ 10 parent[l] = l - piece # update parent 11 l, pieces = L, [] 12 while parent[l] is not None: # walk back through parents 13 piece = l - parent[l] 14 pieces.append(piece) 15 l = parent[l] 16 return pieces
1049	4 Lecture 18: Pseudopolynomial Subset Sum • Input: Sequence of n positive integers A = {a0, a1, . . . , an−1} P • Output: Is there a subset of A that sums exactly to T ? (i.e., ∃A0 ⊆ A s.t. a∈A0 a = T ?) • Example: A = (1, 3, 4, 12, 19, 21, 22), T = 47 allows A0 = {3, 4, 19, 21} • Optimization problem? Decision problem! Answer is YES or NO, TRUE or FALSE • In example, answer is YES. However, answer is NO for some T , e.g., 2, 6, 9, 10, 11, . . . 1. Subproblems • x(i, t) = does any subset of A[i :] sum to t? • For i ∈{0, 1, . . . , n}, t ∈{0, 1, . . . , T } 2. Relate • Idea: Is ﬁrst item ai in a valid subset A0? (Guess!) • If yes, then try to sum to t − ai ≥ 0 using remaining items • If no, then try to sum to t using remaining items
1050	 x(i + 1, t − A[i]) if t ≥ A[i] • x(i, t) = OR x(i + 1, t) always 3. Topological order • Subproblems x(i, t) only depend on strictly larger i, so acyclic • Solve in order of decreasing i 4. Base • x(i, 0) = YES for i ∈{0, . . . , n} (space packed exactly!) • x(n, t) = NO for j ∈{1, . . . , T } (no more items available to pack) 5. Original problem • Original problem given by x(0, T ) • Example: A = (3, 4, 3, 1), T = 6 solution: A0 = (3, 3) • Bottom up: Solve all subproblems (Example has 35)
1051	Lecture 18: Pseudopolynomial 5 • Top down: Solve only reachable subproblems (Example, only 14!) 6. Time • # subproblems: O(nT ), O(1) work per subproblem, O(nT ) time
1052	6 Lecture 18: Pseudopolynomial Is This Polynomial? • Input size is n + 1: one integer T and n integers in A • Is O(nT ) bounded above by a polynomial in n + 1? NO, not necessarily • On w-bit word RAM, T ≤ 2w and w ≥ lg(n + 1), but we don’t have an upper bound on w • E.g., w = n is not unreasonable, but then running time is O(n2n), which is exponential Pseudopolynomial • Algorithm has pseudopolynomial time: running time is bounded above by a constant- degree polynomial in input size and input integers • Such algorithms are polynomial in the case that integers are polynomially bounded in input size, i.e., nO(1) (same case that Radix Sort runs in O(n) time) • Counting sort O(n + u), radix sort O(n logn u), direct-access array build O(n + u), and Fibonacci O(n) are all pseudopolynomial algorithms we’ve seen already • Radix sort is actually weakly polynomial (a notion in between strongly polynomial and pseudopolynomial): bounded above by a constant-degree polynomial in the input size mea­
1053	sured in bits, i.e., in the logarithm of the input integers • Contrast with Rod Cutting, which was polynomial – Had pseudopolynomial dependence on L – But luckily had ≥ L input integers too – If only given subset of sellable rod lengths (Knapsack Problem, which generalizes Rod Cutting and Subset Sum — see recitation), then algorithm would have been only pseudopolynomial Complexity • Is Subset Sum solvable in polynomial time when integers are not polynomially bounded? • No if P 6= NP. What does that mean? Next lecture!
1054	7 Lecture 18: Pseudopolynomial Main Features of Dynamic Programs • Review of examples from lecture • Subproblems: – Preﬁx/sufﬁxes: Bowling, LCS, LIS, Floyd–Warshall, Rod Cutting (coincidentally, re­ ally Integer subproblems), Subset Sum – Substrings: Alternating Coin Game, Arithmetic Parenthesization – Multiple sequences: LCS – Integers: Fibonacci, Rod Cutting, Subset Sum Pseudopolynomial: Fibonacci, Subset Sum * – Vertices: DAG shortest paths, Bellman–Ford, Floyd–Warshall • Subproblem constraints/expansion: – Nonexpansive constraint: LIS (include ﬁrst item) – 2× expansion: Alternating Coin Game (who goes ﬁrst?), Arithmetic Parenthesization (min/max) – Θ(1)× expansion: Piano Fingering (ﬁrst ﬁnger assignment) – Θ(n)× expansion: Bellman–Ford (# edges) • Relation: – Branching = # dependant subproblems in each subproblem – Θ(1) branching: Fibonacci, Bowling, LCS, Alternating Coin Game, Floyd–Warshall, Subset Sum – Θ(degree) branching (source of |E| in running time): DAG shortest paths, Bellman– Ford – Θ(n) branching: LIS, Arithmetic Parenthesization, Rod Cutting – Combine multiple solutions (not path in subproblem DAG): Fibonacci, Floyd– Warshall, Arithmetic Parenthesization • Original problem: – Combine multiple subproblems: DAG shortest paths, Bellman–Ford, Floyd–Warshall, LIS, Piano Fingering
1055	MIT OpenCourseWare https://ocw.mit.edu 6.006 Introduction to Algorithms Spring 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms
1056	Introduction to Algorithms: 6.006 Massachusetts Institute of Technology Instructors: Erik Demaine, Jason Ku, and Justin Solomon Lecture 10: Depth-First Search Lecture 10: Depth-First Search Previously • Graph deﬁnitions (directed/undirected, simple, neighbors, degree) • Graph representations (Set mapping vertices to adjacency lists) • Paths and simple paths, path length, distance, shortest path • Graph Path Problems – Single Pair Reachability(G,s,t) – Single Source Reachability(G,s) – Single Pair Shortest Path(G,s,t) – Single Source Shortest Paths(G,s) (SSSP) • Breadth-First Search (BFS) – algorithm that solves Single Source Shortest Paths – with appropriate data structures, runs in O(|V | + |E|) time (linear in input size) Examples G1 a d b e c f G2 a d b e c f
1057	2 Lecture 10: Depth-First Search Depth-First Search (DFS) • Searches a graph from a vertex s, similar to BFS • Solves Single Source Reachability, not SSSP. Useful for solving other problems (later!) • Return (not necessarily shortest) parent tree of parent pointers back to s • Idea! Visit outgoing adjacencies recursively, but never revisit a vertex • i.e., follow any path until you get stuck, backtrack until ﬁnding an unexplored path to explore • P (s) = None, then run visit(s), where • visit(u) : – for every v ∈ Adj(u) that does not appear in P : ∗ set P (v) = u and recursively call visit(v) – (DFS ﬁnishes visiting vertex u, for use later!) • Example: Run DFS on G1 and/or G2 from a Correctness • Claim: DFS visits v and correctly sets P (v) for every vertex v reachable from s • Proof: induct on k, for claim on only vertices within distance k from s – Base case (k = 0): P (s) is set correctly for s and s is visited – Inductive step:
1058	Consider vertex v with δ(s, v) = k0 + 1 – Consider vertex u, the second to last vertex on some shortest path from s to v – By induction, since δ(s, u) = k0, DFS visits u and sets P (u) correctly – While visiting u, DFS considers v ∈ Adj(u) – Either v is in P , so has already been visited, or v will be visited while visiting u – In either case, v will be visited by DFS and will be added correctly to P Running Time • Algorithm visits each vertex u at most once and spends O(1) time for each v ∈ Adj(u) P • Work upper bounded by O(1) × deg(u) = O(|E|) u∈V • Unlike BFS, not returning a distance for each vertex, so DFS runs in O(|E|) time
1059	3 Lecture 10: Depth-First Search Full-BFS and Full-DFS • Suppose want to explore entire graph, not just vertices reachable from one vertex • Idea! Repeat a graph search algorithm A on any unvisited vertex • Repeat the following until all vertices have been visited: – Choose an arbitrary unvisited vertex s, use A to explore all vertices reachable from s • We call this algorithm Full-A, speciﬁcally Full-BFS or Full-DFS if A is BFS or DFS • Visits every vertex once, so both Full-BFS and Full-DFS run in O(|V | + |E|) time • Example: Run Full-DFS/Full-BFS on G1 and/or G2 G1 a d b e c f G2 a d b e c f Graph Connectivity • An undirected graph is connected if there is a path connecting every pair of vertices • In a directed graph, vertex u may be reachable from v, but v may not be reachable from u • Connectivity is more complicated for directed graphs (we won’t discuss in this class) • Connectivity(G): is undirected graph G connected? • Connected Components(G): given undirected graph
1060	G = (V, E), return partition of V into subsets Vi ⊆ V (connected components) where each Vi is connected in G and there are no edges between vertices from different connected components • Consider a graph algorithm A that solves Single Source Reachability • Claim: A can be used to solve Connected Components • Proof: Run Full-A. For each run of A, put visited vertices in a connected component
1061	4 Lecture 10: Depth-First Search Topological Sort • A Directed Acyclic Graph (DAG) is a directed graph that contains no directed cycle. • A Topological Order of a graph G = (V, E) is an ordering f on the vertices such that: every edge (u, v) ∈ E satisﬁes f(u) < f(v). • Exercise: Prove that a directed graph admits a topological ordering if and only if it is a DAG. • How to ﬁnd a topological order? • A Finishing Order is the order in which a Full-DFS ﬁnishes visiting each vertex in G • Claim: If G = (V, E) is a DAG, the reverse of a ﬁnishing order is a topological order • Proof: Need to prove, for every edge (u, v) ∈ E that u is ordered before v, i.e., the visit to v ﬁnishes before visiting u. Two cases: – If u visited before v: ∗ Before visit to u ﬁnishes, will visit v (via (u, v) or otherwise) ∗ Thus the visit to v ﬁnishes before visiting u – If v visited before u:
1062	∗ u can’t be reached from v since graph is acyclic ∗ Thus the visit to v ﬁnishes before visiting u Cycle Detection • Full-DFS will ﬁnd a topological order if a graph G = (V, E) is acyclic • If reverse ﬁnishing order for Full-DFS is not a topological order, then G must contain a cycle • Check if G is acyclic: for each edge (u, v), check if v is before u in reverse ﬁnishing order • Can be done in O(|E|) time via a hash table or direct access array • To return such a cycle, maintain the set of ancestors along the path back to s in Full-DFS • Claim: If G contains a cycle, Full-DFS will traverse an edge from v to an ancestor of v. • Proof: Consider a cycle (v0, v1, . . . , vk, v0) in G – Without loss of generality, let v0 be the ﬁrst vertex visited by Full-DFS on the cycle – For each vi, before visit to vi ﬁnishes, will visit vi+1 and ﬁnish – Will consider
1063	edge (vi, vi+1), and if vi+1 has not been visited, it will be visited now – Thus, before visit to v0 ﬁnishes, will visit vk (for the ﬁrst time, by v0 assumption) – So, before visit to vk ﬁnishes, will consider (vk, v0), where v0 is an ancestor of vk
1064	MIT OpenCourseWare https://ocw.mit.edu 6.006 Introduction to Algorithms Spring 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms
1065	Introduction to Algorithms: 6.006 Massachusetts Institute of Technology Instructors: Erik Demaine, Jason Ku, and Justin Solomon Lecture 5: Linear Sorting Lecture 5: Linear Sorting Review • Comparison search lower bound: any decision tree with n nodes has height ≥dlg(n+1)e−1 • Can do faster using random access indexing: an operation with linear branching factor! • Direct access array is fast, but may use a lot of space (Θ(u)) • Solve space problem by mapping (hashing) key space u down to m = Θ(n) • Hash tables give expected O(1) time operations, amortized if dynamic • Expectation input-independent: choose hash function randomly from universal hash family • Data structure overview! • Last time we achieved faster ﬁnd. Can we also achieve faster sort? Data Structure Operations O(·) Container Static Dynamic Order build(X) find(k) insert(x) delete(k) find min() find max() find prev(k) find next(k) Array n n n n n Sorted Array n log n log n n 1 log n Direct Access Array u 1 1 u u Hash Table n(e) 1(e) 1(a)(e) n n
1066	"2 Lecture 5: Linear Sorting Comparison Sort Lower Bound • Comparison model implies that algorithm decision tree is binary (constant branching factor) • Requires # leaves L ≥ # possible outputs • Tree height lower bounded by Ω(log L), so worst-case running time is Ω(log L) • To sort array of n elements, # outputs is n! permutations • Thus height lower bounded by log(n!) ≥ log((n/2)n/2) = Ω(n log n) • So merge sort is optimal in comparison model • Can we exploit a direct access array to sort faster? Direct Access Array Sort • Example: [5, 2, 7, 0, 4] • Suppose all keys are unique non-negative integers in range {0, . . . , u − 1}, so n ≤ u • Insert each item into a direct access array with size u in Θ(n) • Return items in order they appear in direct access array in Θ(u) • Running time is Θ(u), which is Θ(n) if u = Θ(n). Yay! 1 def direct_access_sort(A): 2 ""Sort A assuming items have distinct non-negative keys"" 3 u = 1"
1067	+ max([x.key for x in A]) # O(n) find maximum key 4 D = [None] * u # O(u) direct access array 5 for x in A: # O(n) insert items 6 D[x.key] = x 7 i = 0 8 for key in range(u): # O(u) read out items in order 9 if D[key] is not None: 10 A[i] = D[key] 11 i += 1 • What if keys are in larger range, like u = Ω(n2) < n2? • Idea! Represent each key k by tuple (a, b) where k = an + b and 0 ≤ b < n • Speciﬁcally a = bk/nc < n and b = (k mod n) (just a 2-digit base-n number!) • This is a built-in Python operation (a, b) = divmod(k, n) • Example: [17, 3, 24, 22, 12] ⇒ [(3,2), (0,3), (4,4), (4,2), (2,2)] ⇒ [32, 03, 44, 42, 22](n=5) • How can we sort tuples?
1068	3 Lecture 5: Linear Sorting Tuple Sort • Item keys are tuples of equal length, i.e. item x.key = (x.k1, x.k2, x.k2, . . .). • Want to sort on all entries lexicographically, so ﬁrst key k1 is most signiﬁcant • How to sort? Idea! Use other auxiliary sorting algorithms to separately sort each key • (Like sorting rows in a spreadsheet by multiple columns) • What order to sort them in? Least signiﬁcant to most signiﬁcant! • Exercise: [32, 03, 44, 42, 22] =⇒ [42, 22, 32, 03, 44] =⇒ [03, 22, 32, 42, 44](n=5) • Idea! Use tuple sort with auxiliary direct access array sort to sort tuples (a, b). • Problem! Many integers could have the same a or b value, even if input keys distinct • Need sort allowing repeated keys which preserves input order • Want sort to be stable: repeated keys appear in output in same order as input • Direct access array sort cannot even sort arrays having repeated keys! • Can we modify direct access array sort to admit multiple keys in
1069	"a way that is stable? Counting Sort • Instead of storing a single item at each array index, store a chain, just like hashing! • For stability, chain data structure should remember the order in which items were added • Use a sequence data structure which maintains insertion order • To insert item x, insert last to end of the chain at index x.key • Then to sort, read through all chains in sequence order, returning items one by one 1 def counting_sort(A): 2 ""Sort A assuming items have non-negative keys"" 3 u = 1 + max([x.key for x in A]) # O(n) find maximum key 4 D = [[] for i in range(u)] # O(u) direct access array of chains 5 for x in A: # O(n) insert into chain at x.key 6 D[x.key].append(x) 7 i = 0 8 for chain in D: # O(u) read out items in order 9 for x in chain: 10 A[i] = x 11 i += 1"
1070	"4 Lecture 5: Linear Sorting Radix Sort • Idea! If u < n2 , use tuple sort with auxiliary counting sort to sort tuples (a, b) • Sort least signiﬁcant key b, then most signiﬁcant key a • Stability ensures previous sorts stay sorted • Running time for this algorithm is O(2n) = O(n). Yay! • If every key < nc for some positive c = logn(u), every key has at most c digits base n • A c-digit number can be written as a c-element tuple in O(c) time • We sort each of the c base-n digits in O(n) time • So tuple sort with auxiliary counting sort runs in O(cn) time in total • If c is constant, so each key is ≤ nc, this sort is linear O(n)! 1 def radix_sort(A): 2 ""Sort A assuming items have non-negative keys"" 3 n = len(A) 4 u = 1 + max([x.key for x in A]) # O(n) find maximum key 5 c = 1 + (u.bit_length() // n.bit_length()) 6 class Obj: pass 7 D = [Obj() for a"
1071	in A] 8 for i in range(n): # O(nc) make digit tuples 9 D[i].digits = [] 10 D[i].item = A[i] 11 high = A[i].key 12 for j in range(c): # O(c) make digit tuple 13 high, low = divmod(high, n) 14 D[i].digits.append(low) 15 for i in range(c): # O(nc) sort each digit 16 for j in range(n): # O(n) assign key i to tuples 17 D[j].key = D[j].digits[i] 18 counting_sort(D) # O(n) sort on digit i 19 for i in range(n): # O(n) output to A 20 A[i] = D[i].item Algorithm Time O(·) In-place? Stable? Comments Insertion Sort 2 n Y Y O(nk) for k-proximate Selection Sort 2 n Y N O(n) swaps Merge Sort n log n N Y stable, optimal comparison Counting Sort n + u N Y O(n) when u = O(n) Radix Sort n + n log (u) n N Y O(n) when u = O(nc)
1072	MIT OpenCourseWare https://ocw.mit.edu 6.006 Introduction to Algorithms Spring 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms
1073	Introduction to Algorithms: 6.006 Massachusetts Institute of Technology Instructors: Erik Demaine, Jason Ku, and Justin Solomon Lecture 8: Binary Heaps Lecture 8: Binary Heaps Priority Queue Interface • Keep track of many items, quickly access/remove the most important – Example: router with limited bandwidth, must prioritize certain kinds of messages – Example: process scheduling in operating system kernels – Example: discrete-event simulation (when is next occurring event?) – Example: graph algorithms (later in the course) • Order items by key = priority so Set interface (not Sequence interface) • Optimized for a particular subset of Set operations: build(X) build priority queue from iterable X insert(x) add item x to data structure delete max() remove and return stored item with largest key find max() return stored item with largest key • (Usually optimized for max or min, not both) • Focus on insert and delete max operations: build can repeatedly insert; find max() can insert(delete min()) Priority Queue Sort • Any priority queue data structure translates into a sorting algorithm: – build(A), e.g., insert items one by one in input order
1074	– Repeatedly delete min() (or delete max()) to determine (reverse) sorted order • All the hard work happens inside the data structure • Running time is Tbuild + n · Tdelete max ≤ n · Tinsert + n · Tdelete max • Many sorting algorithms we’ve seen can be viewed as priority queue sort: Priority Queue Operations O(·) Priority Queue Sort Data Structure build(A) insert(x) delete max() Time In-place? Dynamic Array n 1(a) n 2 n Y Sorted Dynamic Array n log n n 1(a) 2 n Y Set AVL Tree n log n log n log n n log n N Goal n log n(a) log n(a) n log n Y Selection Sort Insertion Sort AVL Sort Heap Sort
1075	2 Lecture 8: Binary Heaps Priority Queue: Set AVL Tree • Set AVL trees support insert(x), find min(), find max(), delete min(), and delete max() in O(log n) time per operation • So priority queue sort runs in O(n log n) time – This is (essentially) AVL sort from Lecture 7 • Can speed up find min() and find max() to O(1) time via subtree augmentation • But this data structure is complicated and resulting sort is not in-place • Is there a simpler data structure for just priority queue, and in-place O(n lg n) sort? YES, binary heap and heap sort • Essentially implement a Set data structure on top of a Sequence data structure (array), using what we learned about binary trees Priority Queue: Array • Store elements in an unordered dynamic array • insert(x): append x to end in amortized O(1) time • delete max(): ﬁnd max in O(n), swap max to the end and remove • insert is quick, but delete max is slow • Priority queue sort is selection sort! (plus some copying) Priority Queue:
1076	Sorted Array • Store elements in a sorted dynamic array • insert(x): append x to end, swap down to sorted position in O(n) time • delete max(): delete from end in O(1) amortized • delete max is quick, but insert is slow • Priority queue sort is insertion sort! (plus some copying) • Can we ﬁnd a compromise between these two array priority queue extremes?
1077	3 Lecture 8: Binary Heaps Array as a Complete Binary Tree • Idea: interpret an array as a complete binary tree, with maximum 2i nodes at depth i except at the largest depth, where all nodes are left-aligned 1 d0 ______O____ 2 d1 ____O____ __O__ 3 d2 __O__ __O O O 4 d3 O O O • Equivalently, complete tree is ﬁlled densely in reading order: root to leaves, left to right • Perspective: bijection between arrays and complete binary trees 1 Q = [0,1,2,3,4,5,6,7,8,9] 2 d0 0 -> ______0____ 3 d1 1 2 -> ____1____ __2__ 4 d2 3 4 5 6 -> __3__ __4 5 6 5 d3 7 8 9 -> 7 8 9 • Height of complete tree perspective of array of n item is dlg ne, so balanced binary tree Implicit Complete Tree • Complete binary tree structure can be implicit instead of storing pointers • Root is at index 0 • Compute neighbors by index arithmetic: left(i) = 2i + 1 right(i) = 2i + 2   i − 1 parent(i) = 2
1078	4 Lecture 8: Binary Heaps Binary Heaps • Idea: keep larger elements higher in tree, but only locally • Max-Heap Property at node i: Q[i] ≥ Q[j] for j ∈{left(i), right(i)} • Max-heap is an array satisfying max-heap property at all nodes • Claim: In a max-heap, every node i satisﬁes Q[i] ≥ Q[j] for all nodes j in subtree(i) • Proof: – Induction on d = depth(j) − depth(i) – Base case: d = 0 implies i = j implies Q[i] ≥ Q[j] (in fact, equal) – depth(parent(j)) − depth(i) = d − 1 < d, so Q[i] ≥ Q[parent(j)] by induction – Q[parent(j)] ≥ Q[j] by Max-Heap Property at parent(j) • In particular, max item is at root of max-heap Heap Insert • Append new item x to end of array in O(1) amortized, making it next leaf i in reading order • max heapify up(i): swap with parent until Max-Heap Property – Check whether Q[parent(i)] ≥ Q[i] (part of Max-Heap Property at parent(i)) – If not, swap items Q[i] and Q[parent(i)], and recursively max heapify up(parent(i)) •
1079	Correctness: – Max-Heap Property guarantees all nodes ≥ descendants, except Q[i] might be > some of its ancestors (unless i is the root, so we’re done) – If swap necessary, same guarantee is true with Q[parent(i)] instead of Q[i] • Running time: height of tree, so Θ(log n)!
1080	5 Lecture 8: Binary Heaps Heap Delete Max • Can only easily remove last element from dynamic array, but max key is in root of tree • So swap item at root node i = 0 with last item at node n − 1 in heap array • max heapify down(i): swap root with larger child until Max-Heap Property – Check whether Q[i] ≥ Q[j] for j ∈{left(i), right(i)} (Max-Heap Property at i) – If not, swap Q[i] with Q[j] for child j ∈{left(i), right(i)} with maximum key, and recursively max heapify down(j) • Correctness: – Max-Heap Property guarantees all nodes ≥ descendants, except Q[i] might be < some descendants (unless i is a leaf, so we’re done) – If swap is necessary, same guarantee is true with Q[j] instead of Q[i] • Running time: height of tree, so Θ(log n)! Heap Sort • Plugging max-heap into priority queue sort gives us a new sorting algorithm • Running time is O(n log n) because each insert and delete max takes O(log n) • But often include two improvements to this
1081	sorting algorithm: In-place Priority Queue Sort • Max-heap Q is a preﬁx of a larger array A, remember how many items |Q| belong to heap • |Q| is initially zero, eventually |A| (after inserts), then zero again (after deletes) • insert() absorbs next item in array at index |Q| into heap • delete max() moves max item to end, then abandons it by decrementing |Q| • In-place priority queue sort with Array is exactly Selection Sort • In-place priority queue sort with Sorted Array is exactly Insertion Sort • In-place priority queue sort with binary Max Heap is Heap Sort
1082	6 Lecture 8: Binary Heaps Linear Build Heap • Inserting n items into heap calls max heapify up(i) for i from 0 to n − 1 (root down): n−1 n−1 X X worst-case swaps ≈ depth(i) = lg i = lg(n!) ≥ (n/2) lg(n/2) = Ω(n lg n) i=0 i=0 • Idea! Treat full array as a complete binary tree from start, then max heapify down(i) for i from n − 1 to 0 (leaves up): n−1 n−1   X X n n n n worst-case swaps ≈ height(i) = (lg n−lg i) = lg = Θ lg √ = O(n) n! n(n/e)n i=0 i=0 • So can build heap in O(n) time • (Doesn’t speed up O(n lg n) performance of heap sort) Sequence AVL Tree Priority Queue • Where else have we seen linear build time for an otherwise logarithmic data structure? Sequence AVL Tree! • Store items of priority queue in Sequence AVL Tree in arbitrary order (insertion order) • Maintain max (and/or min) augmentation: node.max = pointer to node in subtree of node with maximum
1083	key – This is a subtree property, so constant factor overhead to maintain • find min() and find max() in O(1) time • delete min() and delete max() in O(log n) time • build(A) in O(n) time • Same bounds as binary heaps (and more) Set vs. Multiset • While our Set interface assumes no duplicate keys, we can use these Sets to implement Multisets that allow items with duplicate keys: – Each item in the Set is a Sequence (e.g., linked list) storing the Multiset items with the same key, which is the key of the Sequence • In fact, without this reduction, binary heaps and AVL trees work directly for duplicate-key items (where e.g. delete max deletes some item of maximum key), taking care to use ≤ constraints (instead of < in Set AVL Trees)
1084	MIT OpenCourseWare https://ocw.mit.edu 6.006 Introduction to Algorithms Spring 2020 For information about citing these materials or our Terms of Use, visit: https://ocw.mit.edu/terms
1085	[SQUEAKING] [RUSTLING] [CLICKING] MICHAEL SIPSER: OK, everyone. Let's get started. Welcome back to Theory of Computation lecture number six. So we have been looking at a number of different models of computation. And last lecture actually was an important one for us, because we shifted gears from our restricted models, finite automata, pushdown automata, and their associated generative models, regular expressions, and context-free grammars to Turing machines, which are going to be the model that we're going to-- which is the model that we're going to be sticking with for the rest of the semester, because that's going to be our model, as we're going to argue today, for a general purpose computer. So in a sense, everything we've been doing up till now or up until that point has been kind of a warm up. But it's been nevertheless has gotten a chance for us to introduce some important concepts that are used in practice and also will serve as good examples for us moving forward. And also just to get kind of in a sense on the same
1086	page. So what we're going to be doing today is looking at the Turing machine model in a little bit more depth. One can define Turing machines in all sorts of different ways. But it's going to turn out not to matter, because all of those different ways are going to be equivalent to one another. And so we are going to stick with the very simplest version, the one we've already defined, namely the simple one tape Turing machine. But we're going to basically justify that by looking at some of these other models and proving equivalence. So we will look at multi-tape Turing machines, we'll look at non-deterministic Turing machines, and we'll look at another model which is slightly different but it's still based on Turing machines called an enumerator. And we'll show that those all in the end give you the same class of languages. And so in that sense, they're all equivalent to one another. And that's going to be-- serve as a kind of a motivator, kind of in a sense recapitulate some of the
1087	history of the subject, and going to lead to our discussion of what's called the Church Turing thesis. So we will get to that in due course. And we'll also talk about some notation for notations for Turing machines and for encoding objects to feed into Turing machines as input, but we'll get to that shortly as well. So let's move on, then.
1088	we did with Turing machines. And just want to make sure we're all together on that. It's a very important concept for us this term. So the Turing machine model looks like there's going to be this finite control. There's a tape with a head that can read and write on the tape, can move in both directions. The tape is infinite to one side and so on, as I mentioned last time. The output of the Turing machine is either going to be a halt, accepting or rejecting, or loop that the machine may run forever. With three possible outcomes for any particular input. The machine may accept that input by entering q accept. May halt and reject by entering q reject. And it might reject by looping, which means it just never gets to the accept state or it never gets any halting state. It just goes forever. But we still consider that to be rejecting the input, just it's rejecting by looping. And as we defined last time, a language is Turing recognizable, or as we typically
1089	write, T recognizable, if it's the language of some Turing machine, the collection of accepted strings from that Turing machine. Again, just as before, the machine may accept 0 strings, one string, many strings, but it always has one language, the collection of all accepted strings. Now, if you have a decider, which is a machine that never loops, which always halts on every input, then we say its language is a decidable language. So we'll say a language is Turing decidable or simply decidable if it's the language of some decider, which is a Turing machine that always halts on all inputs. So we have those two distinct notions, Turing recognizable languages and Turning decidable languages. Now, as we're going to argue this lecture, Turing machines are going to be our model of a general purpose computer. So that's the way we're going to think of computers as Turing machines. And why Turing machines? Why didn't we pick something else? Well, the fact is, it doesn't matter. And that's going to be the point of this lecture. All reasonable
1090	models of general purpose computation, unrestricted computation in the sense of not limited memory, are all going to be-- all have been shown, all the models that we've ever encountered have all been shown to be equivalent to one another. And so you're free to pick any one you like. And so for this course, we're going to pick Turing machines because they're very simple to argue about mathematically, and also they have some element of familiarity in that they feel like-- well, they're more familiar than some of the other models that have been proposed that are out there, such as rewriting systems, lambda calculus, and so on. Turing machines feel like a primitive kind of computer. And in that sense, they have a certain familiarity. OK, so let's start talking about variations on the Turing machine model. And we're going to argue that it doesn't make any difference. And then this is going to be kind of a precursor to a discussion of a bit of the history of the subject that we're gonna get to in the
1091	second half of the lecture. So a multi-tape Turing machine is a Turing machine, as you might imagine, that has more than one-- well, has one or possibly more tapes. And so a single tape Turing machine would be a special version of a multi-tape Turing machine. That's OK. But you might have more than one tape, as I've shown in this diagram. Now, how do we actually use a multi-tape Turing machine? Well, you present the-- and we're going to see these coming up for convenience. Sometimes it's nice to be working with multiple tapes. So we're going to see these later on in the semester a couple of times as well. But for now, we're setting the model up so that the input is going to be presented on a special input tape. So that's where the input appears, and it's going to be followed by blanks, just as we had before. And now we have these potentially other tapes, possibly other tapes, which we call them work tapes where the machine can write other stuff as it
1092	wishes. And those tapes are going to be initially blank. So just all blanks on them. All of the tapes are going to be read and write. So you can write on the input tape. Obviously you can read off on the input tape, and you can read and write on the other tapes as well. So what we want to first establish that by having these additional tapes, you don't get additional power for the machine in the sense that you're not going to have-- you won't have additional languages that you can recognize by virtue of having these additional tapes. I mean, you can imagine that having more tapes will allow you to do more things. For example, if you have a pushdown automaton with two stacks, you can do more languages than you can with one stack. So it's conceivable that by having more tapes, you can do more languages than you could with one tape. But in fact, that's not the case. One tape is as good as having many tapes. And we're going to prove
1093	that. We're going to quickly sketch through the proof of that fact. So the theorem is that a language is Turing recognizable. And when we say Turing recognizable, for now we mean just with one tape. So that's the way we've defined it. So a language is Turing recognizable if and only if some multi-tape Turing machine recognizes that language. So really another way of saying that is if you have a language that you can do with a single tape, you can do it with a multi-tape and vice versa. So one direction of that is immediate, because a single tape Turing machine is already a multi-tape Turing machine that just so happens to have one tape. So the forward direction of that is-- there's nothing to say. That's just immediately true. But if we want to prove the reverse, then we're going to have to do some work. And the work is going to be showing how do you convert a multi-tape Turing machine to a single tape Turing machine. So if we have something that's recognized by
1094	a multi-tape Turing machine, it's still Turing recognizable. And what that means is that you can do it with a single tape Turing machine. So we have to show how to do the conversion. And I'll show you that I think in a convincing way but without getting into too much detail. So here is an image of a multi-tape Turing machine during the course of its input. So we've already started it off. Initially it starts off with the other tapes, the work tapes being all blank. But now it's processed for a while and the head on the input tape now has moved off from its starting position at the left end. It's somewhere in the middle. It's written stuff on the other tapes. And what we want to do is show how to represent that same information on a single tape Turing machine in a way which allows the single tape Turing machine to carry out the steps of the multi-tape Turing machine but using only a single tape by virtue of some kind of a data
1095	structure which allows for the simulation to go forward. So how is the single tape Turing machine going to be simulating, going to be carrying out the same effect of having these multiple tapes on the multi-tape Turing machine? So here's a picture of the single tape Turing machine. It just has one tape. By the way, I should mention that all of the tapes are infinite to the right in the multi-tape Turing machine, just as we had for the single tape Turing machine. And now with this single tape Turing machine, it's going to represent the information that's present on these multiple tapes but using only the single tape. And the way I'm choosing to do that is going to be particularly simple. I'm going to just divide up, so here I'm saying it in words. It's going to simulate m by storing the contents of the multi-tape on the single tape in separate blocks. So I'm basically going to divide up the single tape Turing machines tape into separate regions where each one of those regions is
1096	going to have the information that was on one of the tapes in the multi-tape machine. So for example, on the first tape it's got a, a, b, a. Well, that's going to appear here in that first block on the single tape Turing machine. Sort of seeing it float down to suggest that it's coming from this multi-tape Turing machine. But that's really been developed by the simulation that the single tape Turing machine has. Obviously the single tape Turing machine doesn't have any direct access to the multi-tape machine. But it's going to be simulating. So this is how we're showing the data is being stored on the single tape machines tape. So in the second block, it's going to have the contents of the second tape of the Turing multi-tape machine. And the final region of the single tapes, the final block so-called of the single tape's tape is going to have-- the single tape machine's tape-- it's going to have the rest of the contents of the last tape of m. And then it's going to
1097	be followed by the same infinitely many blanks that each of these tapes are going to have following the portion that they may have written during the course of their computation. So that's what the single tape Turing machine's tape is going to look like during the course of its computation. It's going to have the information represented in these blocks. Capturing all of the information that the multi-tape Turing machine has in a perhaps somewhat less convenient way, because the multi-tape Turing machine, we didn't really make this explicit. And in part because it doesn't really matter, we didn't say exactly how the multi tape machine operates. What I have in mind is that the multi-tape Turing machine can read and move all of its heads from all of its heads in one step. So in a single step of the multi-tape machine, it can obtain the information that's underneath each of its heads, feed that in through its transition function, and then together with the state of the multi-tape machine decide how to change each of those locations
1098	and then how to move each one of those heads. So it's kind of operating on all of the tapes in parallel. So now how does the actual steps of the simulation of the single tape-- by the single tape machine, how does it go? So first of all, besides storing the contents of each of the tapes in S's single tape, there's some additional information that it needs to record. Namely, M has a head for each one of its tapes. But S has just a single head. And each of M's heads could be in some different location. In this case, as I've shown it, on the first tape, its head is in location three. On the second tape, it's in location two. On the third tape, it's on location-- on the last tape, it's in location one. So where were we? We were simulating the multi-tape Turing machine with the single tape Turing machine. And we had to keep track of where the heads are. And so we're going to do that by writing the locations on
1099	those blocks. So we're going to have a special dot, as I've shown here, to represent the location of the head in that very first block. So the head's on the b. I'm going to dot the b. And I'm going to do the same thing for the locations of the other heads. And how am I getting that effect? Well, we've seen something like that before, where we just expand the tape alphabet of S to allow for these dotted symbols as well as the irregular symbols. We also have expanded it to include the delimiter markers that separate the blocks from one another, which I'm writing as a pound sign. So we can just get that effect simply by expanding the tape alphabet of S. A few more details of S that are just worth looking at, just to make sure we're kind of all understanding what's happening. So for every time M takes one step, S has actually a lot of work to do. Because one step of M can read and move all of those heads
1100	all at one shot. S has to scan the entire tape to see what's underneath those in effect virtual heads, which are the locations of the dotted symbols. It has to see what's underneath each one of those heads to see how to update its state to the next state. And then it has to scan again to change the location, change the contents of those tape locations, and also to move the head left or right by effectively now moving the dot left or right. So that's pretty straightforward. There's one complication that can occur, however, which is that what happens if on one of the tapes, let's say, M starts writing more content than you have room in that block to store that information? So if M, it has 1, 0, 1, suppose M after a few steps moves its head into the originally blank portion of the tape and writes another symbol there. We have to put that symbol somewhere, because we have to record all that information. And the block is full. So what do we
1101	do? Well, in that case, S goes to a little interrupt routine and moves, shifts all of the symbols to the right one place to open up a location here where it can write a new symbol for continuing the simulation. So with that in mind, S can maintain the current contents of each of of M's tapes. And let me just note that here. Shift to add room is needed. And that's all that happens during the course of the simulation. And of course, if S as it's simulating M observes that M comes to an accept or reject state, S should do the same. So that's our description of how the single tape
1102	Let's turn to non-deterministic machines. Now, if you remember for finite, and I hope you do, for finite automata, we had equivalence between non-deterministic and deterministic. Finite automata. For pushdown automata, we did not have the equivalence. We didn't prove that, but we just stated it as a fact. There are certain languages that you can do with non-deterministic pushdown automata, which is the model we typically hold as our standard. So that some things you can do with non-deterministic automata that you cannot do with deterministic pushdown automata. You really need the non-determinism. They're not equivalent. For Turing machines, we're going to get the equivalence back. So we'll show that anything you can do with a non-deterministic Turing machine in terms of language recognition, you can also do with a deterministic Turing machine. So remember, we kind of mentioned this briefly last time, the non-deterministic Turing machine looks exactly like a deterministic Turing machine except for the transition function where we have this power set, which allows for multiple different outcomes at a given step instead of just a
1103	single outcome that you would have in a deterministic machine. So we represent that with this power set here applied to the possibilities that the machine would have as the next step. So now we're going to prove a very similar theorem, that A is Turing recognizable by an ordinary one tape Turing machine. That kind of goes without saying, since that's how we defined it. It's Turing recognizable if and only of some non-deterministic Turing machine recognizes the language. Again, remember we're using non-determinism in the way we always do. Namely that a non-deterministic machine accepts if there is some branch or some thread of its computation ends up at an accept. Other branches might go forever or might reject part of the way through. But acceptance always overrules then if any branch accepts. That's how non-determinism works for us. So now the forward direction of this is, again, just like before, immediate because a deterministic Turing machine is a special kind of non-deterministic Turing machine which never branches non-deterministically on any of its steps. So that forward direction
1104	is immediate. The backwards definition is where we're going to have to do some work converting our non-deterministic Turing machine to a deterministic Turing machine. And we'll do so as follows. We'll take a non-deterministic Turing machine. Here is our picture. And we're going to now imagine its computation in terms of a tree. And so here is the non-deterministic computation tree for n on some input w. So n for non-deterministic. Here is the tree. Somewhere down here it might end up accepting. And as I mentioned, that is going to be defining the overall computation to be accepting if there is some place here that's accepting. And the only way it can be non-accepting computation if there is no accept that occurs anywhere. And somehow if you're going to convert this non-deterministic machine to a deterministic machine, the deterministic machine is going to have to get that same effect. It doesn't have the non-determinism. So how does it manage that? Well, it's really going to be carrying out the simulation kind of as you would imagine doing it
1105	yourself if you were told you had to simulate a non-deterministic Turing machine, which is you're going to search that tree of possibilities looking to see if you find and accept. If you do, then you accept. If you don't, well, maybe you'll go forever or maybe you'll manage to search the entire tree, and then you will say, no, I accept, no, I reject. So let's just see, again, what the data structure of that deterministic machine's tape is going to look like. So the way this simulation is going to carry out, and you could program this in a host of different ways. And in fact, the textbook has a somewhat different simulation. But I think this one here lends itself a little bit better and maybe it's a little simpler for description in this setting. But there's lots of different ways of improving these things. So m is going to simulate n kind of a little bit similar to the previous simulation. It's going to break the tape up into blocks, and it's going to now store
1106	in each block a different thread at a particular point in time of n's computation. So you imagine where m is going to be simulating n sort of doing the same parallelism but getting the effect of the parallelism not through the non-determinism but by maintaining copies of each of the threads on its tape and then updating them accordingly. So the idea is, I think, not too complicated. So let's just see some of the details here. So here populating those blocks with the contents of n's tape on different threads. Maybe that corresponds to n's tape after the fifth step of n on each of those threads. You have these three possibilities, let's say, written down as three different blocks. Now, remember in the case of the multi-tape simulation, we needed to record some extra information. In particular, we had to record the location of the heads by using those dotted symbols. We're going to do that again because each one of these threads might have their head in some different location. But we're going to have to
1107	do more. So let's do one thing at a time. We're going to store the head location. Here they are all written down as dotted symbols. But now there's something that goes further. Because in a multi-tape case, there was one global state that the multi-tape machine was in, of course, at any given time. It's just that one has one finite control. It's in one state. But in the case of the non-deterministic machine that we're simulating now, each thread can be in a different state. So whereas before, we could keep track of the multi-tape machine's state inside the single tape machine's finite control. Now there could be many, many different states to keep track of. So you won't be able to store that in a finite control anymore, because there could be some huge number of threads active at any given stage. And some of them can be one state. Others can be in different state. And how do you keep track of all that? So we're going to have to use the tape. We're going to
1108	actually write down which state a given thread is in on that block. And we'll do that. I'll show it like this. So writing down the state of each thread in the block by writing down symbols which correspond to those states. So we're actually in a sense writing the states down right on top of the block using symbols that correspond to those states. So again, we're getting that effect by increasing the tape alphabet of M to include symbols that correspond to each of its states. And we're going to write those symbols down. So here's the symbol for state q8 that says, well, that very first thread of n's computation is in state q8. It's in this third position on its tape. The head is on the third position there. And the tape contents is a, a, b, a. That's how we represent that thread of the computation including the state. So M is going to carry out that step by step maintaining that information on its tape. Again, similar to before, there might be some special
1109	situations arising. So for example, n is non-deterministic. So a thread might fork into two threads. What do we do then? Well, sort of the reasonable thing. If there's a forking thread, M then copies that block, makes two copies of the block to correspond, or however many copies you need, to correspond to the possibilities that that thread is branching into. So you want to represent them all on different blocks of M's tape. All right? And then if M ever finds out that on one of the threads it's entering the accept state, it can just shut down the whole computation at that point and say accept. So perhaps a little elaborate, but I think conceptually, hopefully, not too bad. Now, let's move on then to talk about somewhat of a different looking-- well, sort of a different model, in a way, which has some historical significance and sometimes is a helpful way to look at Turing recognizability. And incidentally, you have a homework problem on this model called an enumerator or Turing enumerator.
1110	First of all, we're going to enhance the Turing machine model. It's going to now have just a single tape. But it's going to also have a printer. So we're now adding in this new device into the Turing machine called a printer. And the Turing machine has tape as before, except we never provide any input to the machine. The tape always starts out fully blank. It's only used for reading and writing. Only used for work. It's not where you present the input. So how do you talk about the language of the machine? Well, the way you work this machine is you take this enumerator. It's a deterministic Turing machine with a printer, as I mentioned. You started off in blank tape. And it runs and runs and runs and periodically it can print a string under some sort of program control, which I'm not going to spell out for you. But you can imagine you might have to define the machine in such a way that when it goes into a certain print state, we're not
1111	going to set that all up, then whatever string is in a certain region of the tape maybe from the start point up into the head location, that gets printed out on the printer. And then it can print out other strings in due course. And so periodically, you think of this printer as printing out a string under the control of the Turing machine enumerator. And so these print strings, these strings that could print out w1, w2, they appear. And the machine might possibly go forever and print infinitely many strings. Or it might go forever and only print finitely many strings. Or it might stop after a while by entering a halting state. Accepting or rejecting is irrelevant, but it enters a halting state. And then the strings that it's print out, the finitely many strings it printed out,
1112	Now, the language of the machine is the collection of all strings that it ever prints out. So we're defining language in a somewhat different way here. It's not the strings that it accepts. It's the strings that it prints. So we think of this machine almost a little bit analogous to the regular expression or the grammar in the sense that it's a generative model. It produces the language rather than accepts the strings in the language. It's not really a recognizer. It's a generator. And the language of the machine, as writing over here, for an enumerator here, we say its language is a collection of strings that it prints. Now we will show that a language is Turing recognizable in the previous sense recognized by some ordinary Turing machine if and only if it's the language of some enumerator. And actually this is kind of a little bit of an interesting proof. You have to do some work. It's an if only if. Now neither direction is immediate. You're going to have to do some work in
1113	both directions. One direction is a little harder than the other. We'll start off with the easier direction. Let's say we have an enumerator. Hopefully you got this concept of this Turing machine which periodically prints strings when you started it off on the empty tape. So now what I'm going to construct for you is that Turing machine recognizer defined from the enumerator. So this recognizer is going to be simulating the enumerator. So basically that recognizer is going to launch the enumerator. It's going to start off simulating it. Now, if you want, if it's convenient, we could use several tapes. We can use one tape to simulate the recognizer and you have other tapes available for convenience if you want, because we already showed multi-tape and single tape are equivalent. So if you want, you can think of M as having multiple tapes. It's not going to really be that relevant to my conversation. But you're going to simulate E starting on the blank input, as you're supposed to. And then you're going to see whenever E
1114	prints in x, you're going to see if x is the same as the input to the recognizer. You get the idea? So we have a recognizer. It has an input string, maybe like 1, 1, 0, 1. And I want to know. I want to accept that string if it's one of the strings that the enumerator E prints out, because that's what the recognizer do. It's supposed to accept all the strings that the enumerator prints out. So I got this 1, 1, 0, 1. What do I do? I fire up that numerator, I get it going, and I start watching the strings it prints out, comparing them with my input string, 1, 1, 0, 1. If I ever see it print out a 1, 1, 0, 1, great. I know I can accept, because I know it's in the enumerator's language. But if I compare and compare and compare, I never see the enumerator ever printing out my input string 1, 1, 0, 1. Well, I just keep simulating. If E halts, well then I can
1115	halt and reject if I've never seen that string coming out as an output. If E doesn't halt, well, I'm just not going to halt either. I'm going to go forever. But then I'm going to be rejecting my input by looping. So that's the proof of converting in this backward direction, which is the easier direction. Now let's look at the forward direction, which has a certain wrinkle in it that we're going to have to get to. So now we're going to be building our enumerator to simulate our recognizer. And the way we'll do that is the enumerator has to print out all of the strings that the recognizer would ever accept. So you kind of do the obvious thing. You're going to take-- the enumerator is going to start simulating the recognizer M on all possible strings. Sort of one by one, doing them in parallel, taking turns. Maybe we didn't make this so explicit. But you can sort of timeshare among several different possibilities. Sort of like having different blocks for the machine. The enumerator
1116	is going to run the recognizer on-- well, let's just say it does it sequentially. It runs it on the empty string. It runs it on the string 0. It runs it on the string one. Runs it on the string 0, 0. These are all the possible strings of sigma star. You run on all of them. And whenever the enumerator-- uh oh. This is wrong. So whenever M accepts, then print-- I can't write very well. Print w, wi. Oops. OK. So I'm going to just say it in words. I'm want to simulate M on each wi. Whenever you notice M accepting wi, you just print out wi. Because you want to print out all of the strings that M accepts. Now, there is a problem here. So hopefully you're not confused by this typo. Doing it sequentially like I just described doesn't quite work. So let me just back that up here. Doing it sequentially doesn't quite work, because M might get stuck looping on one of the wi's. Like maybe when I feed 0 into
1117	M, M goes forever. Because M is rejecting 0 by looping. But maybe it also accepts this next string in the list, the string one. I'll never get to one by just feeding the strings into M one by one like this. What I really have to do is run all of the strings in M in parallel. And the way I'm going to indicate that is I want to simulate M on w1 to wi for i steps for each possible i. So I'm going to run M on more and more strings for more and more steps. And every time I notice that M accepts something, I print it out. So I will fix this in the version of the file that I publish on the website. So if you're still not getting it, you can look there. But just to make things even worse, I have a check in, which is going to be about this one little point here. So I got a question. Where do we get the wi strings? The wi strings are simply
1118	the list of all strings in sigma star. So under program control, we can make M go through every possible string. Like if you had an odometer, you're going to first get to the empty string. Then you go to the string 0, then the string one. You can write a program which is going to do that. And the Turing machine can similarly write code to do that, to get to each possible string one by one. And then that's what the enumerator is doing. It's obtaining each of those strings and then feeding them into M, seeing what M does. What I'm trying to get at here is that it's not good to feed them in, run M to completion on each one before going to the next one. You really kind of have to do them all in parallel to avoid the problem of getting stuck on one string that M is looping on. All right. So this is relevant to your homework, in fact. If I convert em to an enumerator in this way, does that
1119	enumerator always print the strings out in string order. String order is this order here. Having the shorter strings coming up before the longer strings and within strings of a certain length, just doing them in lexicographical order. So hopefully you follow that. But since these are not correct, this doesn't matter for us. Let me launch that poll. I'll see how random the answer is here. So a fair amount of confusion. If you're confused, obviously you're in good company there. About to shut this down. Five seconds to go. OK, ending it now. All right. So the correct answer, as the majority of you did get, is in fact that the order is not going to be respected here when E prints things out. It might print out some things later in the order before earlier things in the order. What's going to control when E is going to print it out? If M accepts some strings more quickly in fewer steps, then E might end up printing out that string earlier in the list than some other
1120	string that might be a shorter string. Because the order in which E is going to now identify that M is accepting those strings depends upon the speed with which M is actually doing the accepting. So this is relevant to one of your homeworks, because what you're going to have to show is that if you start with a decidable language instead of a recognizable language, then you can make an enumerator, which always prints out things in order, in the string order. And vice versa. And if you have an enumerator which prints that things out in string order, then the language is decidable. So need to think about that. One direction is a fairly simple modification of what I just showed. The other direction is a little bit of more work.
1121	So that's an interesting question. So one question is because sigma has an infinite-- sigma star is infinite, if I understand this question correctly, which says it's an infinite number of strings here. How does the machine even get started because it has to go through and enumerate all of it? No, it's not first writing down all of those strings. Because yeah, you can't write down-- you can't do this infinite step of writing down all the strings. What I had in mind is you're going to take each string in turn. First you're going to take the first string on the list of sigma star, run M on that string, and then the next string in sigma star, run it on that string, and so on, string after string. And so you're never going to have infinitely many strings to deal with. It's just going to be more and more strings as you're going along. And the question I was trying to get at is whether you're going to run each one to completion before you get to
1122	the next one or you're going to kind of try to do them all in parallel, which is what you need to do to prove this there. Won't there be infinitely many wi? Yes, so there are a-- similar question. Infinitely many wi. There are infinitely many wi. But it's just an infinite loop that we're in. One by one, you're taking care of more and more wi as you're going. Let's see here. Yes. So another question is are we running all the strings in parallel? Yes, we are running all of the strings in parallel. But it's running them in parallel, but these are-- we're not defining a parallel Turing machine. It's running them in parallel using time sharing. It runs a little bit in this block, runs a little bit in that block and another block, and sort of shifts around and sort of does a few steps of each. And that's how it's getting the effect of the parallelism. Question is would the enumerator essentially have a print tape and a work tape? Yeah, you can
1123	think of it as having a print tape. However you want to formalize it. It doesn't matter. I mean, I'm being a little whimsical with attaching it to a picture of a real printer. But yeah, you think conceptually you can have a print tape. However you like to think about it is fine. How can we directly say that without knowing the program of the printer? We don't have to get into the structure of the printer. The printer is just something where you say print a string and a string comes out. That's all we know about the printer, and that's all we need to know. So there's no program for the printer. Sorry if I'm not understanding your question. But the question literally says, how can we say that without knowing the name of the printer? So if the machine is decidable, why does it have to print all strings in order? For example, if one string is shorter, can it be decided later? Well, yeah. The reason why we want-- so the question is, if the
1124	machine is decidable, why does it have to print all strings in order? Because that's what I'm asking you to do in the problem. If you read the problem, I think it's number five on the P set. That's what I'm asking you to do. That's why you have to print it in order. Otherwise you wouldn't have to worry about printing in order. It's just because I'm asking you to. OK, so I think we're out of time. Let us move back into our material.
1125	Second half, Church-Turing thesis. So Church, this is going back into the bit of the history of the subject back to the 1930s. Back then people were interested in formulating the notion of what do we mean by algorithm. They didn't even call it algorithm. Some people call it procedure. Some people called it effective procedure. Some people called it effective calculation. But people had in their minds-- mathematicians have been dealing for centuries, thousands of years, with procedures for doing things. That's a very natural thing. And mathematical logicians, in particular Church and Turing, Turing somebody surely obviously you've heard of, Church maybe not. Church was Turing's thesis advisor, in fact. And they both were coming out of the mathematical logic field of mathematics and trying to use mathematical logic to formalize this intuitive notion of what we have had for centuries about what a procedure is, what is an algorithm. And back in those days, they came up with different ways of formalizing it. So here we had this notion of algorithm, which is kind of intuitive concept.
1126	Turing proposed Turing machine as a way of capturing that in a formal way, a mathematically precise way. Other people came up with other ways of doing it. And back then, it wasn't obvious that all of those different formulations would end up giving you equivalent concepts, equivalent notions. And in fact, they proved in fairly elaborate detail that the different methods that people came up with, there was the lambda calculus, there was rewriting systems, there were several methods that were proposed for formalizing this notion, and they all turned out to be equivalent to one another. Today that seems kind of obvious, even though I went to some effort to prove that just to give you a feeling for how those things go. If you have programs, if you have Pascal and Java, say, and thinking about what you can do mathematically in those-- I'm not talking about their ability to interface with Windows and so on, but just the mathematical capabilities. The capability of doing mathematical calculations or functions with a Pascal program or a Java program.
1127	It would be absurd to think there's some program that you can write in Java that you can't write in Pascal or Python. And the reason is we know you can compile Python into Java and you can compile Java back into Python. That tells you that the two systems, two programming languages are equivalent in power. That wasn't obvious from the get go to these folks. So they observed that all of the different efforts that came at formalizing algorithm, all were equivalent to one another. That was kind of a breakthrough moment when they realized that all of the ways that they've come up with, and once they got the idea, they realized all reasonable ways of doing it are always going to be equivalent. And so that suggested that they've really captured this notion of algorithm by any one of those methods, say a Turing machine. And that's what they took. You can't prove that, because algorithms are an intuitive notion. But the fact that we're able to capture that in a formal way, that's what we
1128	call today the Church-Turing thesis.
1129	So any of these methods captured the notion of algorithm as we described. And that has had a big impact on mathematics. Just give me one second here. All right. Here's a check in on this one. So you know Alan Turing. So here are some facts which may or may not be true about Alan Turing. So now you get to pick all of the ones that apply based on your knowledge. Obviously this is more for fun or historical interest. But let's launch that poll. See how much you know about Mr. Turing. Check all that apply. OK, almost done? Please let's wrap it up. I think that's everybody. OK, two seconds. Please get credit for doing this. End polling. In fact, it's kind of interesting here. You all do know that he was a code breaker. He worked, in fact, was part of a team, I think led the team, which broke the German code during World War II. The Turing test is a famous thing for how do you characterize when you have an intelligent machine.
1130	So he definitely worked in AI. He worked in biology as well. He has a paper less well known to computer scientists. But if you look him up on Wikipedia, where I get all my information, he actually, and I knew this anyway, he has a very famous paper, an influential paper, on how, for example, spots arise on leopards and stripes on tigers and so on. Gave a kind of mathematical model for that which actually proves-- actually is quite-- does capture things in an accurate way, as was shown subsequent to that. Was imprisoned for being gay. In fact, as far as I know from his history, he was not in prison for being gay. He was convicted of being gay and was given a choice to go to prison or to take chemicals to cure him from being gay. And he opted not to go to prison and take the chemicals. And sadly, he committed suicide two years after that. So he was treated very badly by British society and British government despite having the great work
1131	that he had done. And you might think that he has been honored by appearing on a British banknote. That's also not true. But the good news is he's not currently on a British banknote, but he's going to be on a British banknote starting next year. So that's along with Winston Churchill and a number of other notable Brits. He's going to be on the 50 pound banknote.
1132	So as I mentioned, the Church-Turing was important for mathematics. And it has to do with these Hilbert problems. I don't know how many of you have encountered that. David Hilbert was widely considered to be the perhaps the greatest mathematician of his day. And every four years, mathematicians get together for an international congress, well, the International Congress of Mathematicians. That's been going on for over 100 years. And he was invited to the 1900 meeting to give a talk about anything he wanted. And what he decided to do during that presentation is present 23 problems that would be a challenge for mathematicians for the coming century. And we're running a little short on time, so I'm not going to go into them. Some of these we'll talk about later. But the 10th problem here is about algorithms. The 10th problem on Hilbert's list called Hilbert's 10th problem is a problem about algorithms. And it says give an algorithm for solving what are called Diophantine equations. He didn't call it an algorithm. He called it some finite procedure
1133	or something like that. But what are Diophantine equations? I'm glad you asked. Diophantine equations. What are they? Well, they're very simple. They're just polynomial equations, like does this polynomial equal some constant, for example. But where you're looking for the solutions, the polynomials are variables. You're looking for the solutions, but you're only allowing the solutions to be integers. So here's an example. So I give you this polynomial. Here I'm setting it equal to 7. And I want to solve that equation. So it has these three variables, x, y, and z. So you have to find a solution there. But I'm only going to allow you to have plug in integers. And in fact, there is a solution in integers. 1, 2, and minus 2. If you plug it in, you'll see it works. All right. Now, the general problem that Hilbert was addressing is suppose I give you a polynomial. Let's say it's set to 0. So we're looking for roots of the polynomial. But just some polynomial equation. You can always put it in this
1134	form. And I want to know does it have a solution in integers? And what I'm looking for is a procedure which will tell me yes or no. I want to know. Give an algorithm to answer that question for a given polynomial. Or using the language of this course, defining this in terms of a language, decide this language. Give a Turing machine which will decide yes or no for any given polynomial. Yes there is a solution in integers. No, there is no solution in integers. That was what Hilbert asked in his 10th problem. Give an algorithm. Now, as we know now, it took seven years to get the answer that there is no such algorithm. It's an undecidable problem. And we'll talk about that a little bit later in the term. But D is not a decidable language. Now, there was no hope of coming up with that answer in 1900 or even in 1910, because we didn't have a formal idea of what an algorithm is. That had to wait until the Church-Turing thesis told
1135	us that algorithms really are Turing machines, that there is a formal way of saying what an algorithm is. And once you had that notion, then you could prove that there is no Turing machine. But before that, you had only this vague notion, intuitive notion of what an algorithm is. And so there was no hope of ever answering that, because in fact, the answer is there is no such algorithm. Now, I'll give this as a little exercise to you. We're a little bit running short on time. But this language D is in fact a recognizable language. So I would suggest you think about that offline. But basically, you can try plugging in different values for these variables. And if you ever find that it evaluates to 0, then you can accept. But otherwise, you just have to keep going and looking. So showing recognizability is very simple, but decidability is false. Now let's talk a little bit about encodings for Turing machines. So we're going to be working-- encodings and Turing machines. So we're now going
1136	to be working with Turing machines going forward. The input to those Turing machines might be polynomials, might be strings. They might be other things too. We might want to feed automata into the Turing machines. So the Turing machine can answer questions about the automata. Well, don't forget, Turing machines take as their input just strings. So we have to think about how we're going to represent something more complicated like an automaton as a string. And I'm not going to get into the details of that. You could spell it out in detail. But I think that's not too interesting to get into that. We're just going to develop a notation that says if you have some object, it could be a polynomial. There could be an automaton. It could be a graph. It could be whatever you're working with. A table. I'm going to write that O in these brackets to mean an encoding of that object into a string. And then you can feed the string into the Turing machine. So that's how we're going to
1137	be thinking of presenting Turing machines with more complicated objects and strings as input, because we're just going to represent them as strings using ways in which I'm sure you're all familiar. I mean, that's how you deal with representing stuff when you write your programs anyway. But just to make it formal and that's the way we're going to write it down in these brackets. And if you have a list of several objects that you want to present together to a Turing machine, we'll just write them together within brackets like this. Now, for writing Turing machines down, going forward, we're going to be using high level English descriptions. We're not going to be worrying about managing-- like the stuff we've been doing up till now, I'm not going to ask you to do it. We're not going to do that anymore, and I'm not going to ask you to do it. Managing where stuff goes on the tapes and all that stuff, that's too low level. Because really now that we have the Church-Turing thesis, we're really
1138	interested in talking about algorithms. We're not that interested in talking about Turing machines, per se. We're interested in algorithms and what the power of computation is. So we're going to only be talking about Turing machines now in a higher level way. And only when we need to prove something about capabilities, we're going to come back to Turing machines and we're going to be proving things about their limitations and so on. So our notation for running Turing machines is going to be-- we're basically going to put the Turing machine inside these quotation marks. And we're going to know that we could in principle write out the Turing machine in a precise way in terms of states and transition function and so on, but we'll never actually go ahead and do that lengthy exercise. So quick check in here. So one of the features-- well, OK, let me not give this away. So if x and y are strings, I want to now have a way of presenting two strings as a single string as input to
1139	my machine, because I always think of my machine as getting a single input. So would you suggest one way of combining two strings into one which would be a good encoding is just to concatenate those two strings together. Would that be the way you would do it? Is that a good way to do it or not such a good way to do it? So let's see here. I can get to that next. And think of what you would want to have happen in a good encoding. Ready, set, sold. Share results. Yeah. I think most of you get the idea that this is not a good way of combining two strings into one, because the problem is it's kind of ambiguous in a sense. If you combine two strings this way, what's important in an encoding is that the machine when it gets the encoding, it can decode them back into the original objects. And if you're just going to be sticking the two strings together, you don't know where one string ends and the next
1140	string begins. And so it's not going to be a good way of combining things. You should find a little bit more clever way of either introducing another symbol or doing something a little bit more sophisticated, which would allow you to be able to do the decoding as well as the encoding in a unique way. So getting back to that notation for a Turing machine. So here is the machine we've already seen once before for a to the k, b to the k, c to the k. I would write it now more simply than managing all of the tapes that we had the first time around, which we did last lecture. I would just say we give it an input w, check if w's of the right form with the things in the right order. Reject if it's not. Count the number of a's b's and c's in w. Accept if all the counts are equal and reject if not. That's going to be good enough to be writing things at that higher level when you're
1141	going to be writing your algorithm descriptions. You just have to make sure that whatever you're doing you can implement. You don't want to be doing tests which are impossible or doing infinitely much work in one stage. That's not good. But as long as it's clear that what you're doing is doing only a finite amount of work in every stage and it's something that you could really implement, you can write it in a high level. I wanted to spend a few minutes talking about problem set two, but we're a little bit running out of time here. Particularly there was this problem number five where you show that a language is Turing recognizable if and only if there's a decidable D. Where C is Turing recognizable where D is now a collection of pairs. We've got some questions about the notation, which I've hopefully answered now. So C is a set of x's such that there exists a string you can pair it with. So that the string xy is in D. Let me try to give
1142	you a picture of that. So I want to think of D as a collection of pairs of strings. And it might be helpful to think of D kind of on the axes here. So if we have a pair of strings xy, which I have not yet packaged into a single string, I'm thinking of them as a pair of two objects at this moment, think of D as-- so just the x part is just below here on the x-axis. D you might just conceptually want to think of it as a collection of pairs. So it's like a subset of all of these pairs. And C is all of the x's that correspond to any pair in here. Sometimes we call that the projection, because it's all the things that are below or the shadow. If you had a light sitting up here, it's all the things that are kind of underneath a D. So I've written C here kind of a little thicker, if you can see that. So that's the C language. And there's two
1143	directions here. One is a lot easier than the other. If I give you a decidable D and I want to test whether something's in C, so I'll give you an x, I want to know is x in C? Well, you now have to test is there some y that I can pair with x where the pair is in D? So you can start looking for that y. If you ever find one, you know that x is in C. There are infinitely many y's to look for. But don't forget, you're only looking for a recognizer for C. So on the rejecting side, you're allowed to go forever. So I'm kind of giving you a way to think about the easy direction. The hard direction, you need to think about how are you going to come up with that decidable D. If I give you C, you have to find a decidable D. And now you're bringing something down lower. You're starting with a recognizable language and a decidable language, which is going to sort of be
1144	counterpart to that and in a sense is a simpler language. And the way it becomes simpler is that y is going to help you determine whether x is in C. And I guess the thing that I'll leave you with is, and maybe we can talk about this a little bit more on Tuesday, I'll try to leave a little more time if you want to test if something is in C, x is in C, but I don't want to let you go forever anymore, because I want to be a decidable language. And I'm going to use y to help you. What information would help you guarantee you get the right answer for x being in C? But that you would have to be sure you're getting the right answer. So y could just be the answer. But then you don't know that that's-- you have to be convinced that you have the right answer. y just saying what it is, I mean, y could say that x is in D even when it's not true. x
1145	is in C even when that's not true. So what information would allow you to check that x is in C? What would be helpful information to check that x is in C where you would avoid ever having to go forever? A little bit too rushed here for that to be helpful. Anyway, let's just conclude what we've done. Just brief summary here. And I don't want to keep you over time. So I'll just leave this up on the board. I will see if there's any-- so the lecture is over and you can take off as you wish. I will stick around for a couple of minutes. I have another meeting soon, but I'll try to answer some chats. All right. People are commenting about this movie about Turing, The Imitation Game. If you haven't seen that, I recommend it. And is it a good idea to make y to be equal to the repeated looped string? Hm. I'm not sure about that. Thank you, everybody, for sending your kind notes. Church-Turing thesis. The question is is
1146	it in the book? Yes. It's in the book. Kind of similar to what I've already said, but yes. OK, this is a good question here. The Church-Turing thesis. Somebody asked me, is it proved in the book? There's nothing to prove. The Church-Turing thesis is an equivalence between the intuitive and the formal. You can't prove something like that. You can just make-- it's really in a sense a hypothesis that the only thing you'll ever be able to compute is something that you can do with a Turing machine. I mean, that has something to do with the nature of the physical world. And I don't really think that's what people had in mind. It's that the kinds of things that we normally think of being able to do with a procedure mathematically is exactly the kinds of things that you can do with a Turing machine. So somebody's pointing out, trying to be helpful here, maybe these folks are asking about equivalents of various different computation models being proved in the book, not the Church-Turing thesis itself.
1147	Well, I mean, the things that we proved in lecture are also proved in the book. About the equivalence of single tape machines, multi-tape machines, non-deterministic machines, those are all proved in the book. I mean, there's lots of models out there. So we could spend a lot of time proving equivalences. And there are books that do spend a lot of time proving equivalences. But I think what we've given is probably enough. That's a good question. If you give an algorithm, you don't need to give the actual machine going forward unless you're explicitly asked to. But yes, you don't have to give the states and transitions anymore. OK. So it's a little after 4:00. I think I'm going to move on to my next meeting. So thank you for being here, and I will see you on Tuesday.
1148	okay hello everybody we'll get started um so um just recapping what we did [Music] a in the last lecture on tuesday we um had a it was kind of a two is the second part of a two lecture sequence on the hierarchy theorem higher hierarchy theorems for time and space and using the hierarchy theorems to show that there are that there is a problem which is intractable that's provably outside of polynomial time and that was this equivalence problem for regular expressions with exponentiation and then we had a short discussion about oracles and the possibility that similar methods might you might be used to show that satisfiability is outside of p which would then of course solve the p versus mp problem and argued that um it seems unlikely um this kind of a meta theorem not not a well uh well-defined notion but seems unlikely that the methods that were used for proving the um uh the intractability of um equivalence of regular expressions with exponentiation could be used to solve p versus np at
1149	least um the the diagonalization method kind of in a pure form whatever that means uh that's not going to be um enough so today we're going to shift gears again begin a somewhat different topic which is really kind of um going to be our uh again a few lectures on probabilistic computation which is going to wrap round out the semester for us um and we're going to start by talking about a different model of computation which allows for uh probabilis probabilism in the measuring the amount of probabilism or measuring the probability allowing for probabilism in the computation define an associated complexity class uh this class bpp and then start to start the discussion of an example um about something called branching programs okay um so uh with that in mind um
1150	a uh so we're gonna start off by defining the notion of a probabilistic turing machine or ptm um a probabilistic turing machine is a lot like the way we have thought about non-deterministic touring machines in that it's a kind of a machine that can have multiple choices multiple ways to go in its computation so there's not just going to be a fixed uh deterministic path um of its computation but there's going to be a tree of possibilities um and for our purposes we're going to limit the branching in that tree to be either um a step of the computation where there's no branching where it's a deterministic step uh as shown over here um so every step of the way leads uniquely to the next step or there might be some steps which have a choice and we're only going to allow for these purposes uh to keep life simple um having only uh a choice among two possibilities um and we'll associate to that uh um the notion of a probability that each choice
1151	will have a 50 50 chance of getting taken and this kind of corresponds with the way some of us or some of you think about non-determinism which is not exactly right up and up until this point is that the machine is kind of taking a random branch it really we don't think about it randomly until now now we're going to think about the machine as actually taking sort of picking a random choice among all the different branches that it could make um and picking the choice kind of uniformly by flipping a coin every time it has an option of which way to go uh now you could define i'm getting a question here uh the uh a machine that has several different ways to more than two ways to go and then you would need to have a three-way coin a four-way coin and so on and you could define it all of that that way as well but it doesn't end up giving you anything different or anything uh interesting or new for uh
1152	for the kinds of things we're going to be discussing so and it's just going to be simpler to keep the discussion limited to the case where the machine can only have two possibilities um if it's going to be having a choice at all or or just one possibility when there's no choice okay so um so now we're going to have to talk about the probability of a the machine taking a sum branch of its computation so you imagine here here is the same computation tree that we've seen before in the case of ordinary non-deterministic machines where you have m on w there could be several different ways to go and there might be some particular branch but now we want to talk about the probability that the machine actually ends up picking that branch and it's going to be um uh you know when we talk about uh the machine having a choice of ways to go we're going to associate that with a coin flip so we're going to call that a coin flip
1153	step when the machine has a possibility of ways to go and so on a particular branch the probability of that branch occurring is going to be one over two to the number of coin flips coin flip states on that branch and the reason for i mean this is kind of the the the definition that makes sense um in that if you imagine looking at the computation tree here and here is the branch that we're focusing on um of interest every time there's a coin flip on that branch there's a 50 50 chance of taking a different branch or staying on that branch so the more coin flips there are on some particular branch the less likely that branch would be the one that the machine actually actually ends up taking taking and so it's going to be one over two to the number of coin flips and that's the way we're defining it now once we have that notion we can also talk about the probability that the machine ends up accepting because each as
1154	before each of these branches is going to end up at an accept state or reject state i'm thinking about this only in terms of deciders and the probability of the machine accepting here is just going to be the sum over all probabilities of the branches that end up accepting so just add up all of those probabilities of a branch leading to an accept and we'll call that the probability that the machine accepts its input [Music] and the probability that the machine rejects is going to be one minus the probability that it accepts because it's going to the machine um on every branch is either either going to do one or the other okay um now if you're thinking about a particular language that the machine is trying to decide this probabilistic machine now is trying to decide um you know on on each input some of the branches of the machine may not may give the correct answer they're going to accept when the input is in the language other branches may give the wrong
1155	answer they may reject when the input is in the language and vice versa so there's going to be a possibility of error now in the machine in any particular branch it might actually give the wrong answer and what we're going to say is bound that error over all possible inputs um and so and uh we'll say that the machine for any epsilon greater than or equal to zero um we will say that the machine decides the language with error probability epsilon if that's the worst that can possibly happen you know if every um for every input the machine gives the wrong answer with probability at most epsilon um equivalently if you like to spell it out a little bit more you know a little differently for strings that are in the language the probability that the machine rejects that input is going to be at most epsilon and for strings in the language the probability of for strings not in the language the probability that accepts is a most epsilon so again this is the
1156	machine doing the the thing that it's not supposed to be doing for things in the language it should be rejecting very rarely for things not in the language it should be accepting very rarely and that's what this bound is doing for you okay um [Music] so let's just see uh so we'll talk about so i'm getting some questions here about um um so let me just look at these one second here the yeah so probability zero so there's a possibility that the machine have might have a probability zero say of accepting that means there are no branches that end up accepting or probability zero of rejecting there were no rejecting branches um but i think we're going to talk in a minute about the connection between this and and the standard notion of np um so just hold off on that for a second uh also about what what about the you know the um the possibility that the machine is you know being a decider or running in a certain amount of time um
1157	so we will look at time-bounded machines in a second um on the next slide or two um talking about machines that run in polynomial time so that means all branches have to halt within some polynomial number of steps um so that's where we're going but for the time being we're only looking at the siders where the machine has to hold on every branch but some branches might run for a long time but for now we're not going to be thinking about machines that have branches that run um forever where all of our machines are deciders so they they hold on every
1158	don't i move on so let's define now the class bpp using this notion of a probabilistic turing machine which is now going to be running in polynomial time so bpp is going to be another one of these complexity classes a collection of languages like p and np and p space and so on and um but it's going to be now associated with the capabilities of these probabilistic machines the kinds of languages that they can do so we'll say the class bpp is the set of languages a such that there's some probabilistic polynomial time during machines so all branches have to halt within you know to the k for some k so some polynomial time polynomial time probabilistic turing machine decides a with error possibility at most one-third so in other words when it's accepting for some for strings in the language the machine has to reject with at most one-third so saying it equivalently for strings in the language it has to accept with two-thirds probability and for strings not in the language it has
1159	to reject what two-thirds probability at least in both cases um okay somehow ended up with didn't check my animation here but okay that's fine so there is a um uh now if you look at the one-third here in the definition uh you know it seems strange to define a complexity class in terms of some arbitrary constant like one-third why didn't we use one-quarter you know or uh you know one-tenth in the definition of bpp and say the machine has to get have an error with at most one tenth or one hundredth uh well it doesn't matter and that's the point of this uh next statement called the amplification lemma which says that um you can always if you have a machine that's running in a certain uh a polynomial time that's running within this with a certain error which it is most one-half if you have an error one-half it's not interesting because the machine could just flip a coin for every uh input and it could get uh the right answer with it with
1160	probability one-half so probability one-half is not interesting you have to have probability strictly less than one-half for the machine to actually be doing something that's meaningful about that language so um if you have a probabilistic turing machine that has error let's say epsilon one which is at most one half which is less than one half then you can convert that to any error probability you want for some other polynomial time probabilistic turing machine so you can make that error which maybe starts out as one-third and you can drive that error down to one out of one over or google um and seriously you can really make the error extremely extremely small using a very simple procedure and and that's simply this so if you're starting out with a machine that has an error possibility of one-third say so that means two-thirds of the time it's going to get the right answer and at most one-third of the time at least two-thirds of the time the right answer most one-third of the time the the incorrect
1161	answer whether that's accepting or rejecting um and now you want to get that answer down to be something much that error down to something much smaller um the the idea is you just you're going to take that machine and you're going to run it multiple times it's kind of with independent runs if that me if you want to think about it you sort of more formally speaking but it's sort of intuitive you're just going to run the machine uh tossing your coins um uh instead of just running it once you're going to run the machine 100 times or or a million times but you can do that so it's a constant factor and even a thousand times is going to be enough to increase your confidence in the result tremendously because if you run the machine a thousand times and 600 of those times the mach the machine accepts and 400 of the time the machine rejects um uh it's very powerful evidence that this machine is biased toward accepting that it's accepting most of
1162	the time um so it's um was uh if it had an error probability of most one-third um uh the the probability that you're seeing it except 600 times when really two-thirds of the time it's rejecting overall is extremely unlikely um and you can calculate that uh which we're not going to bother to do but it's a routine probability calculation uh to show that the the probability that if you run it a whole bunch of times and you see the majority coming up um which is not the not the right answer that's extremely the the probability of that is extremely small um so i'm not saying that very clearly but um the the the the method here is you're going to take your original machine which has error probability one-third or whatever it whatever it is some you know you know maybe has error probability 49 and you run it uh for a large number of times and then you take the majority vote and it you're kind of sampling the the outcomes of this machine
1163	and if you take enough samples it's overwhelmingly likely since you're just doing them uniformly you're taking those samples uniformly it's overwhelmingly likely that you're going to be seeing the predominant one come up more often um and exactly what that right value is we're not going to bother to calculate but that's something that you know if you i will i'll refer you to the textbook or you know that's the kind of thing that comes up in any elementary probability book and it's sort of very intuitive so i don't want to spend the time and do that calculation which is not all that interesting um uh okay so just one quick question here that i'm getting what happens if you bound if the error is greater than a half i don't think that because we're bounding the error so we're not saying the error actually is one you know like sixty percent on everything because then if you knew the error was sixty percent guaranteed you can always just flip the flip your answer around and get
1164	your um error to be 40 but you know i'm saying the error is that most whatever epsilon is and so um if it's you're saying the error is at most 60 percent it doesn't tell you anything um okay um [Music] uh another question is does the amplification lemma also justify that the choice of model with binary branching choices is equivalent to any other perhaps you could say that um because you can change those you know if you had through a three-way branching um you can simulate that with two-way branching to any accuracy that you want um you know not going to get it down to zero but you're going to get it very close um so it's maybe it's the amplification level maybe it's
1165	so the way that it's helpful to think about this class let's let's contrast it with the other model of non-deterministic computation that we have is non-determinism is np uh so non-deterministic then the model of non-deterministic polynomial time computation was np um the other class and um so the way it's i think one way to look at to think about non-determinism in the case of np is for strings in the language for your np turing machine there's at least one accepting branch so i'm indicating the accepting ones in green and the non-accepting one the rejecting branches in red so you could have almost all of the branches be rejecting branches um for strings in the language as long as there is at least one accepting branch that's just the way non-determinism works the accepting branch overrules all the all of the others it's only when you're not in the language that you that all of the branches turn out to have to be rejecting that's when the rejecting sort of you know it's it has no
1166	accepting branch to overroll it um but the situation for bpp is a little different it is is different um there it's kind of majority majority rules so um in the case for strings in the language you you need to have a large or you know the the overwhelming majority of the branches have to be accepting and for strings not in the language the overwhelming majority have to be rejecting what you're not going to allow in the case of bpp is kind of you know an in-between uh state where it's sort of 50-50 um or very very close to 50-50 um those kinds of machines are not don't qualify as uh deciding a language in bpp they always have to kind of lean one way or lean the other way for every input otherwise you won't be able to do the amplification so need to have some bias um away from in half in in accepting or rejecting um so let me so i was going to ask a check-in i think at this point yes
1167	let's so just thinking about bpp i hope i was clear so if there's questions about that i think i've somehow didn't i'm not sure i described it totally well here um so i'm going to ask a few questions about ppp but if you have any questions for me first go ahead um okay why don't we just run the check-in um let me launch this and then i can answer questions as you're asking did i start that yeah okay so you have to um check all of these that you think are true um can you think of non-deterministic turing machines as try all branches at once and get the right answer um and bp is guess only one or uh i guess only one branch i don't know um you know i would say a little differently i would say i i would think of non-determinism as you can still just try one branch but you always guess the right one um so there's some sort of a you know magical power that allows you always
1168	to guess the right answer if there's a right guess uh if you're in the language uh in the case of bpp you're going to be um picking a random branch no matter what and you know that the random branch is likely to give the right answer but not guaranteed and the implication the amplification limit tells you you can arrange things so that it's extremely likely that the random branch is going to give you the right answer okay let's see how we doing on our uh check-in here um got a lot of vote we've got a lot of support for all candidates um and um i'll give you give you another uh a little bit of time here because there's a bunch of questions almost like four check-ins at once um but we have two more check real check-ins coming later um okay so why don't we uh come and let's uh give another 10 seconds and then i'm going to stop closing down one two three close okay so uh we've got a lot of
1169	support here uh and in fact that's good because all of them are true um some of them are easier to see than others so first of all c is very easy to see um because that that's a going to be a machine that has the correct answer all of it all of the time so that's error probability zero um on both accepting and rejecting um this is a little harder d is a little bit harder to see that's in p space but you know you could calculate for every branch um what its probability is and you can just go through all the branches and add up all those probabilities in a p-space machine so um you have to think about a little bit but d is not too hard to see either closure under complement if you just take your your bpp machine and you flip the answer on every branch um that's typically doesn't work in non-determined ordinary non-determinism but it does work here because it's going to change a bias toward accepting into
1170	a bias toward rejecting and vice versa so bpp is closed under compliment uh and closure under union it kind of follows from the amplification level as long as you can make the probability extremely small then you can just run the two different machines and even though the they each might make a mistake cumulatively the total the probability that each one of them that either of them will make a mistake is still small and so you can just run to the two machines and take the or of the responses that they get and it's still very likely to give the right answer for the union okay um
1171	uh so what i'm going to do now for the rest of the lecture uh is and it's actually going to spill over into the lecture after thanksgiving because this is going to introduce an important method for us is to look at an example of a problem that's in bpp um i love to teach things by using examples um and so this is a very good example because it has a lot of meat to it and it's a very interesting example in general proving things in bpp which are not trivially there because they're already in p they tend to be uh somewhat more involved than um uh some of the other algorithms we've seen so there are no simple examples of problems in bpp which are not already in p um so this is uh one example that we're going to go through of a problem in bpp that's not known to bnp of course things could collapse down um but uh uh as star as far as we know this is um not this language
1172	is not in p so let's let's see what the language is has to do with these things called branching programs the branching program is a structure that looks like this so let's understand what the pieces are first of all it's a graph directed graph and uh we're not we're not going to allow and there is are no cycles allowed in this graph it's a directed acyclic graph um so you can no loops allowed and the nodes are in two categories there are query nodes which are labeled with a variable letter and output nodes which are labeled either zero or one and lastly there is a one of the query nodes is going to be or one of the nodes is going to be designated as a start
1173	and so what you do is the way um this is a model of computation um and the way we actually use a branching program is we have some assignment to the variables that's going to be the input so you take all of the the variables there are three variables in this case um x1 x2 and x3 you assign you give them some truth assignment um so x let's let's say zeros and one so x1 is zero x1 is one or whatever and once you have the truth assignment you start at the start variable and you and you look at its label and you see what value the input has assigned to that variable so if x1 assigned a one you're going to follow down the one branch but assigned to zero you follow you go down the zero branch and then when you get down to the next node that's another variable that you're going to have to query depending upon what the input assignment is and you're just going to continue that process because
1174	there are no cycles you're going to end up at one of the output nodes because all of the variable nodes all the all the query nodes have two outgoing edges one labeled zero one labeled one so you're gonna eventually end up at an output node and that's going to be the output of the branching program so we'll do let's do a quick example so if x1 is 1 x2 is 0 and x3 is 1. so we again we start at the start variable the start node that has the indicated with the arrow coming in from nowhere so you're going to start at x1 uh the node labeled x1 so you have to look and see what is x1 in the input it's a 1. so you're going to follow down the one branch now you see the next node oh that's an x3 see what's x3 in the input x3 is a 1. so you go down to one branch again now you have an x2 node take a look at the input x2 is
1175	a zero you follow the zero branch now you're at an output branch output node so that's a zero and that's the output of the of the of this computation so um writing it this way and thinking about it as a boolean function which maps you know strings of zeros and ones we have f of one zero one representing those that assign that assignment that equals zero that was the output and uh that's the output of this computation okay um so important to underst we're going to spend a lot of time you know talking about branching programs so it's critical to understand this model i think it's fairly simple but if you didn't get it please ask we can easily correct up any misunderstanding at this point it's not exactly the same as a dfa dfas for one thing can take inputs of any length um this this has inputs of some particular length where the branching program has some fixed number of variables this one has three so this only takes inputs of length three
1176	um so there's maybe some connection to thinking these estates and so on but it's a different model so now we'll say that two branching programs um okay let me just ask one more question not all nodes need to be used right um yeah there's no requirement that all nodes need to be used and that even could be inaccessible nodes i'm not preventing that uh that could be okay um so on the particular branch certainly you're not gonna you know when you're executing this branching program on an input obvious certainly you're to have a path that's going to only use some part of the tree part of the graph but there might be some paths that can can never occur you know so if you went down x equal to one here and then x three was zero now you're re-reading x one so you'd never you could you wouldn't go down this branch unless you i think all of the branches in this particular branching program could get used but i didn't check that so
1177	maybe i'm wrong um okay so let's continue two branching programs may may or may not compute the same function um we'll say they're equivalent if they do now two branching programs can be equivalent even though they superficially look different from one another and we're interested in the computational problem of given two of these branching programs do they compute the same function do they in other words do they always give the same answer um on the setting of the input uh so we'll define the associated language equivalence problem for branching programs says that you're given two of these branching programs and they're equivalent to be in the language we're going to sometimes write equivalence using the mathematical notation of the three lined equals equal sign the equivalence sign okay that means they compute the same they always give the same answer now that problem turns out to be cohen p complete i've asked you to show on your homework i believe um this is not a super hard reduction um it's the in comp complete by
1178	the way is the complement of an mp complete problem or equivalently it's a problem to which all co np problems are polynomial time reducible and it's in coin [Music] so uh this is coin p complete and that's for you to show um but that has an important significance for us right now um because if you if you know looking at the question of whether this problem is in bpp the fact that it's coin co np complete suggests that the answer is no because if a co np complete or np complete problem more in bpp because everything else in np or cmp is reducible to that problem then all of those np or co-np problems would be in bpp for the exactly the same reason that we've seen before um and that's not known to be the case and not believed to be the case um so uh we don't expect that a co-mp complete problem is going to be in bpp um that would be you know an amazing uh and surprising uh uh result
1179	so um because i i hope i made it clear in my previous um you know in previous discussion that you know the bpp from a practical standpoint is very close to being like p um because you can make the error probability of the machine so incredibly low um that you know it's a comparable uh you know if you run the machine and the error probability is like one over google um then it's sort of even greater than the probability that some alpha particle came in and flipped the value of what some internal uh memory cell in your in your computation so if you have an extremely low error probability it's pretty good from a practical standpoint um so it would be amazing if np problems were solvable in bpp um so this is not the language we're going to use as our example we're going to look at a related restricted version of this problem about equivalence for branching programs and that i'm going to introduce right now okay any questions here don't see any
1180	questions um fading out uh okay
1181	so we're going to talk about branching programs that are what are called read once read once branching programs and those are simply branching programs that are not allowed to re-read an input that they've previously read so for example is this branching program a read once branching program no this branching program is not a read once branching program because um you can find a path that's going to cause you to read the same variable more than once so it's not going to be a read once um so over here let's not read once because there's two occurrences of an x1 on the same branch now you might ask why would anybody want to do that because you've already read the value of x1 well i mean in the case of this particular branching program there might be a value because you could have got to this x x1 branch by going this way or that way um but that's a separate question if we restrict our attention to read once branching programs then the problem of
1182	testing equivalence becomes uh very different in character and in fact we're going to give a probabilistic algorithm uh a bpp algorithm to solve that problem so the equivalence problem for read once branching programs which are not allowed to re-read variables on any path um that's interestingly going to be solvable with a probabilistic uh polynomial time algorithm you know with a small error probability um so i'm going to run a check in now but let's make sure we're all together on this so i got a good question here can every boolean function be described by a branching program yes that's an easy exercise but you can make branch branching programs are um they may be large uh you can describe any boolean function with some branching program that's not hard to show um other questions are we all together on understanding what read once means and branching programs and all that stuff this is a good time to ask if you're not um okay so let's do the check-in so as i pointed out we will
1183	show that the equivalence for read once branching programs is solvable in bpp can we use that to solve the general case for branching programs by converting branch general branching programs to read once branching programs and then run running the read once test so what do you think okay i'm seeing a lot of uh correct answers here um so let's let's wrap this one one up quickly um another 10 seconds please okay ready are we all ready one two three closing all right yes most of you have uh answered correctly um well answer a is not a very good answer because we already commented on the previous slide that we don't know how to do the general case in bpp so it would be kind of surprising if right here i'm saying yes we could do it by using the restricted case so you know i think a better answer would be to one of the no's but as i did comment you can always convert you can always do any uh boolean function uh with
1184	a well maybe i didn't say it for read once branching programs but you even read once branching programs can do any compute any boolean function um so the the conversion is possible but in general will not be polynomial time and you can if you imagine you've been trying to do the conversion over here you could convert this branching program to read once um but you'd have to basically separate the two uh um you know instead of re-reading the x1 you could remember that x1 value but then you would not be you couldn't reconverge over here you'd have to keep those two those two threads of the those two branches of the computation apart those two paths apart from one another and already the branching program would start to increase in size by doing that um and um so in general conversion converting is possible but it requires a big expansion a big increase in the size and then we will not allow a polynomial time algorithm anymore even in probabilistic in the
1185	okay um so now let's start to look at the possibility of showing that this equivalence problem is solvable in bpp and it's going to take us in kind of a strange direction but let's let's try to get our intuition going first by doing something which seems like the most obvious obvious approach um so here uh so we're gonna give a an algorithm now um uh which is going to be an attempt it's not going to work but nevertheless it's going to have the germ of the right idea or the or the not the germ but the beginning of the right way to think about it so here are the two branching read once branching programs are b1 and b2 and i want to see do they compute the same function or not um so one thing you might try is just running them on a bunch of randomly selected assignments or inputs all right so you're going to you can just um take two randomness input assignments just take x1 flip a coin to say
1186	it's one of zero x do the same for x two and so on um then you get some input assignment you run the two branching programs on that assignment and maybe that doesn't give you know even if they agree it doesn't give you a lot of confidence that you got the right answer uh that they're really equivalent so you do it a hundred times whatever some some number of times um and of course if they uh ever disagree on some assignment on one of those assignments then you know they're not equivalent and you can immediately reject um but uh what i'd like to say is if they agree on those you know hundred tries those hundred assignments there then there then they are um uh at least i'll i haven't found a place where they disagree so i'm gonna say that they're equivalent is that a reasonable thing uh to do well it might be uh it depends on k um so the critical thing is what value of k should you pick which is
1187	going to be big enough to allow us to draw the conclusion that if you run it for k times and you never see a difference then you can conclude with good confidence that the two branching programs are equivalent because you've tried to look for a difference and you never found one well the thing is is that um k is going to have to be pretty big uh so looking at it this way if the two branching programs were equivalent then certainly they're always going to give the same value um so the probability that the machine accepts is going to be one and that's good because we want for this is a case when we're in the language we want the probability of acceptance to be high and here the probability of acceptance is actually one so it's always going to accept when the two uh branching programs were equivalent but what happens when the branching programs are not equivalent now we want the probability of rejection to be high the probability of acceptance should be
1188	very low um right so if if they're not equivalent we want the probability that the machine rejects is going to be high if they're not equivalent because that that's what the correct answer is well the only way the machine is going to reject if it finds um a place where the two branching programs disagree but but those two branching programs even though not equivalent might disagree rarely they might only disagree on one input assignment out of the two to the end possibilities so these two inequivalent branching programs might agree almost everywhere just except at one place and then that's enough for them not to be equivalent but the problem is that if you're just going to do random sampling um the likelihood of finding that one exceptional place where the two disagree is very low you're going to have to do an enormous number of samples before you're likely to actually to to to find that uh that point of difference um and so um in order to be confident that you're going to find
1189	that difference if there is one you're going to have to do exponentially many samples and you don't have time to do that with a polynomial time algorithm um you're just going to have to flip too many coins you have to run too many different samples different assignments through these two machines and um because they're almost they're different but they're almost the same um so we're going to need to find a different method and um the the idea is we're going to run these two branching programs in some crazy way instead of running them on zeros and ones that we've been we've been doing it so far we're going to feed in values for the variables which are non-boolean they are going to be going to set x1 to 2 x3 to 7 x 4 to 15. of course that doesn't seem to make any sense but it's nevertheless going to turn out to be useful a useful thing to do and it's going to give us some insight into the equivalence or equivalence of these
1190	branching programs um
1191	yeah we're at the break here so why don't i i'm getting some questions coming in which is great um i will answer those questions but why don't i start off our uh break and then um okay okay so there's a question about whether these this machine runs deterministically or not so which machine are we talking about so the branching programs themselves that they'd run deterministically you give them an assignment to the um to the input variables that's going to determine a path through each branching program which is eventually going to output a zero or a one and you want to know do those two branching programs always give the same value no matter what the input was but the branching programs themselves were deterministic um now the machine that's trying to make the determination of whether those two branching programs are equivalent that machine that we're going to be arguing is going to be a probabilistic machine so it's a kind of non-deterministic machine that's going to have different possible ways to go depending upon
1192	the outcome if it's of its coin tosses so it you can think of as non-determinist you know non-determinism in the ordinary sense about how like that it has a tree of possibilities but um now you know the way we're thinking about acceptance is different you know that instead of accepting if there's just one uh accept branch the machine for it to accept um has to have a majority of the branches be accepting um and uh you know so it's it's there's some similarities but some differences with the usual way we think of non-determinism so what's the motivation behind introducing this type of turing machine well i mean there's a lot i guess there are two motivations uh probabilistic algorithms sometimes called monte carlo algorithms um uh turn out to be useful in practice for a variety of things and um so that led to um people to think about them in the context of complexity um they're related in some ways to quantum computers which are also probabilistic in in a somewhat different way um
1193	but they also have a very nice um uh um uh formulation in complexity theory so complexity theorists like to think about probabilistic computation because i mean you can do interesting things with probabilistic machines and the complexity classes associated are also interesting so as you'll see it leads us in an interesting direction uh to consider how to solve this problem this read once branching program problem equivalence with a probabilistic machine it's just just an interesting um algorithm that we're going to come up with um so in our pro in our proof attempt where did we use the probabilistic nature for bpp because we're running the two branching programs on a random input um i mean so you know you have your two branching programs you pick a random input to run those two branching programs and you see what they do that's where that's why it's probabilistic when you're thinking about random behavior of the machine it's a um that's a probabilistic machine so each branch of the machine is going to be like the way
1194	we normally think about non-determinism somebody's asking whether we think of the complexity of the machine in terms of all of the branches of the machine or um each branch separately it's we always think about for non-deterministic machines each branch separately um i'm not totally sure i understand the question there so are all the inputs built in and we randomly choose one through coin flips not sure i understand that question either we're given as input the two branching programs and then we flip coins you know kind of using our non-determinism you can think about it equivalent in terms of coin flips to choose the values of the variables so now we have a set of variable inputs to the values of the variables and we use that to um as input to the branching programs to see what whether they to see what answers they give and we in particular whether they give the same answer on that randomly chosen uh input let's move on um all right so now sort of moving us toward um
1195	the actual bpp algorithm for uh um read once branching program equivalence testing um we have to think about a different way to um we need an alternate way of thinking about the computation of a branching program it's going to look very similar but it's going to lead us in a direction that's going to allow us to talk about this um these non-boolean inputs that i refer to um just kind of where we're going we're going to be simulating branching programs with polynomials if that helps you sort of as an overarching plan but we'll we'll get there a little slowly so okay here's a branching program read once branching program um we're not going to use the read once feature uh just yet but we'll that'll come later but anyway here's a branching program um and um uh oh here's my branch and i put crashed here start that again um okay so we take an input um whatever it is um and thinking about the computation of the branching process so we're not thinking about
1196	the algorithm right now we're just thinking about branching programs for the minute we're going to get back to the algorithm later so the branching program follows a path as i indicated when you have a particular input your x1 is 0 x2 is 1 x3 is 1 so the output is going to be 1 in this case okay so the way i want to think about this a little differently is i want to label all of the nodes and all of the edges uh with a value that tells me whether or not this yellow path went through that node or edge it's going to be just a doing the same but you may think this is no difference at all but i want to label all the all of the things on the yellow path i'm going to label them or the one and all of the things that are not on the yellow path i'm going to label with a zero so i'm keeping those trying to keep those labels apart from the original branching
1197	program which are written in white these labels are written yellow but these labels have to do with the execution of the branching program on an input so once i have an input that's going to determine a one or a zero label for every node and edge now if we want to look at the output from this branching program after we have that labeling we only have to look at the label of the one output node because that's if that one has a one on it that means that the path went through that one and so therefore we should output output output uh the output is one um uh so i'm going to give you another way of assigning that instead of just coming finding the path first and then coming up with the labeling afterward i'm going to give you a different way of coming up with that labeling kind of building it up inductively starting at the start node and building up that labeling you'll see what i mean by my example so if
1198	i have a label on this node so i already know whether or not the path went through that node you know label 1 means the path went through it label 0 means the path doesn't it does not go through it [Music] that's going to tell me how to label the two outgoing edges so if i'm if i've already labeled this with a where a is a zero or one then uh what what expression should i use um to how do under what circumstances will i label what's what's the right label for this one outgoing edge here well if a is zero that means the pair we know the path did not go through this node so there's no way it could go through that edge similarly if x i is a zero that means even if we did go through that node the path would go through the other edge other outgoing edge and not to this one so that tells us that the boolean expression which describes the value the label of this uh
1199	node in the execution is going to be the and of the the value on the node and the um the query variable of that node now think about what's the right way to label the other edge the the execution value of the other edge again you have to have go through this node so a has to be one but now you want x i to be 0 in order to go through that edge so that means it's going to be a and the complement of x i okay so this is going to just tell me this i'm writing a formula for how we're labeling these uh these edges based on the label of the of the parent node similarly if i have a bunch of edges where i already know the values the labels uh the execution levels there let's say so i have a1 a2 and a3 what is the right label to put on this node um well if any one of those is a one that means the path went through that
1200	edge and so therefore it's going to go through that node so that tells us that the label to put on that node is the or of the labels on the incoming edges okay questions on this so now this is kind of setting the stage for starting to think about this um more toward polynomials instead instead of using a boolean algebra so um quite i'm getting question how do we know what the execution path is which nodes to label we're going to be labeling all of the nodes so we start off with labeling the uh did i say that here we should we start up i didn't say but i should have we label the the start node with one that because the path always goes through the start node so without even talking about a path we just label the start node 1. maybe we'll do an example of this also but now once we label this star this node 1 we have an expression that tells us how to label the two outgoing um
1201	the two outgoing edges this edge and that edge um and i'm doing it without knowing the values of the variables i'm doing it kind of i'm just making an expression uh which is going to describe what those labels would be once you tell me what the input assignment is okay so i'm just sort of it's almost like a symbolic execution here i'm just writing down the different expressions for how to calculate what these things should be um let's let me um maybe this will become clearer as we continue so the poll now this is the big idea of this proof um we're going to use something called arithmetization we're going to convert from thinking about things in the boolean world to thinking about things in the arithmetical world where we you have arithmetic over integers let's say for now um so instead of ands and ors we're going to be talking about pluses and times um and uh we're going to the way we're going to make the bridge is bishop by showing how to
1202	simulate the ands and ors the hand and or operations with the plus and times operations um so um assuming one means true and zero means false if you have the expression a and b as a boolean expression we can represent that as a times b using arithmetic because um it has it computes exactly the same value when we have um the boolean representation of true and false uh being one and zero so you know one and one is one and one times one is one and anything else you know one and zero zero and one zero and zero if you if you applied the times operator you're going to get the same value so times is very much like and in this sense okay we're going to write it as just a b usually without the time symbol so if we have a complement how would we simulate that with arithmetic well again here we're just flipping one and zero in using the complement operation that's going to be the same as subtracting the value
1203	from one that also flips it from uh between one and zero um how about or if you have a or b well um it's slightly more complicated because you use a plus b um but you have to subtract off the product because what you want is this this simulation should be give you exactly the same value so what if you have one or one you want that to be a one a one answer you don't want it to be a two so you have to subtract off the product um uh and the goal is is to have a faithful simulation of the and and or by using plus and times so you get exactly the same answers out when you put in boolean values here okay so um just to say where we're going what this is going to um you know it sounds it's superficially we haven't really done anything um this is but um what this is going to enable us to do is plug in values which are not boolean because you
1204	know it doesn't make sense to talk about it makes sense to talk about one and zero but it doesn't make sense to talk about two and three but it does talk it makes sense to talk about two times three and that's going to be a useful um okay so let's just see um remember that that that um that inductive labeling procedure that i described before um where i labeled gave the execution labels on the edges depending upon the label of the parent node and which node which variable is being queried um so if i know that this value is an a but now the uh okay so i'm just going to write this down using uh arithmetic instead of using boolean uh operations uh so before we have this was a an a and x i if you remember from the previous slide um now what are we going to use instead because we're going to use this conversion here instead of and we're going to use multiplication that's just a times x i what
1205	about on this side here was a and the complement of x i now the complement of x i is one minus x i in the uh arithmetically so this becomes a times one minus x i okay um similarly here we did the or to get the label on the node from its the labels of its incoming edges now we're going to do something a little strange um because we have a formula here for or but for technical reasons that will come up later this is not a convenient representation for us what i'm going to use instead of this one i'm just going to simply say just take the sum why is that good enough in this case this is still going to be a faithful representation and give the right answer all of the time and that's because for our branching programs read once or otherwise read once is not coming in yet for our branching programs they're a cyclic so they can never enter a node on two different paths there's at most one
1206	way to come into a node uh um on a path through the on an execution path through the branching program if it comes in through uh through to this edge um there's no way for it to for this edge to also have a path because that means you have to go out and come back and and have a cycle in the branching program which is disallowed so at most one of these edges can have the path go through it so at most one of these a's can be a one the others are going to be zero and therefore just taking the sum is going to give us a value of either 0 or 1 but it's never going to give a value higher and so you don't have to subtract off these product terms okay a little bit complicated here if you didn't totally get that um don't worry for now you know we're um you know more concerned that you get the the big picture of what's going on um okay so um i
1207	think we're almost um let me just see how far we are yeah so i'm just going to work through an example and i think that'll bring us uh let's just see any questions here not seeing any it means you're either all totally understanding or or you're totally lost i never can tell um so feel free to ask a question if you're even if you're confused um you know i'll do my best okay maybe this example might help um so now what we're going to do is using this sort of arithmetical view of the way i branching program's computation um you know is executed when when we're running it uh um you know an input through it um this is going to allow us now to give a meaning to running the branching program on non-boolean inputs so maybe this example will illustrate that um so let's just take this particular branching program here okay um this branching program it's just on two variables x1 and x2 and actually computes a familiar function this is the
1208	exclusive or function if you look at it for a minute you'll see that this is going to give you x1 exclusive or x2 so it's going to be one if either of the x1 or x2 are one but it's going to be zero if they're both one that's what this branching program computes now but let's take a look um at running this branching program instead of on the usual boolean values let's run it on x1 equal to 2 and x2 equal to 3. now uh um you know a common confusion might be that you're looking you know when you do the x1 query you're looking for another outgoing edge which is labeled two no that's not what i'm doing what i'm doing here is i'm somehow uh through this execution by assigning these other values i'm kind of blending together the computation of x x uh 1 equal to 0 and x1 equal to 1 together i don't know if that makes any sense but let's look through the example um so first of all
1209	these are the labeling rules that i had from uh the previous slide when i used plus and times instead of and or okay now i'm going to show you how to use that to label the nodes and edges of this graph based on this input and that'll determine an output would be the value on the uh the one node okay so we always start out by labeling the start node with one that's just the rule um and uh okay sorry let's let's think about it together before i blurt out the answer what's going to be the label on this edge so this is one of the outgoing edges uh from a node that already has a label so that's going to be this case here and what we do is if we take we take the label of that node and since it's a one edge that's outgoing we multiply that label by um the value of uh that uh variable of the the assignment to that variable so x1 is two so we take
1210	the the it's good this the a here is one x1 is a assigned to two so it's going to be one times two is going to be the value the execution value we put on this edge so it's going to be 2. what's going to be the value we put on the other edge the other edge the 0 outgoing edge from x1 so once you think about that for a second so now we're going to use this expression it's a times 1 minus x i and so x i again is two so one minus x i is one minus two um does that mean that's how complementary but okay let's say that so it's one minus 2 so that's minus 1 times the label 1 here so you get minus 1 as the label on this edge now keep in mind that if i had plugged in and this is very important if i had plugged in boolean values here i would be getting out the same boolean values that you would get just by
1211	following through the path you know the things on the path would be one the things off the path would be zero um but uh but with what's kind of uh what's happening here is that there's still a meaning when the inputs are not boolean so let's continue here how about what's going to be the value on this node so think with me i think it will help you so now we're using this rule here we add up all the values on the incoming edges there's only one incoming edge which is value two so that means this guy's going to get a two and similar on this one this guy's going to get a minus one now let's take a look at this edge so this is a the zero outgoing edge from a node label two with with label x2 so this is the zero outgoing edge the node the label is two so it's going to be two times one minus the x2 value x2 is 3 so 1 minus 3 is minus 2.
1212	it's going to be 2 times -2 which is minus 4. so similarly you can get the value here the value on the the one outgoing edge is going to be 2 times x the x2 value which is 3 so that's going to be 6. and these two here uh um so you know now we have a minus one and the outgoing is a it's a it's a zero edge so it's one minus three and here it's going to be one times minus three no 1 times 3 i'm sorry 1 times 3. um so you get the out the answer is minus 3. so now what's the label on the zero output edge so you have to add in add up the two incoming edges here so we have uh this this edge here was a two this edge coming in here is a six so it's going to be two plus six it's eight and what about this edge this node here this is an important node because this is going to be the output
1213	so it has um uh you know minus three coming in and a minus four coming in so you add those together you get a minus seven i mean you may wonder what what the world is going on here um just a lot of mumbo jumbo uh but we're gonna make sense of all this not today uh we're gonna have to argue why this is what the meaning that we're gonna get out of this is gonna be um but the point point is that this is going to lead to a new algorithm for testing this is again getting back to what we were doing this is the equivalence problem for read once branching programs so now what the new algorithm is going to do is going to pick a random non-boolean assignment so it's going to randomly assign values to the x's and to some non-boolean values instead of zeros and ones we're going to plug in random integer values we'll make that clear next time what's what this what the domain is going to be
1214	um [Music] and then once we have that non-boolean assignment we're going to value b1 and b2 and if they disagree out there in that extended domain then we have to show that they're not equivalent and will reject and we'll also show that if they were equivalent then even when we evaluate them then we have to show that if if they're not equivalent that they're very likely to to have a difference in the non-boolean uh domain and so um if they agree it it it gives you evidence that the two are really equivalent um so the completeness proof will come after thanksgiving so with that um i'm gonna wish you all a nice uh break um oh we have a check in here sorry oh yeah this is a good one i don't know how if you're following me uh but um if i plug in one for x1 and y for x2 does it do the inputs in the assignment need to be distinct no it could be the same value i could be uh
1215	two and two here that's perfectly valid but here i'm going to plug in 1 for x1 i'm going to plug in a variable for x2 y and i'm going to do the whole calculation that i just did and now what's going to be the output and i mean this looks like a pain to figure out you could do it it looks like a pain but let me give you a big hint um remember that this thing is supposed to be calculating the original branching program calculates the exclusive or function and that means when i plug in um a boolean value i should get the exclusive or value coming out so if i already know that x1 is one which of these is consistent with getting a value uh that the exclusive or function would compute so let me launch the poll on that so we're at a time so let's just let this run for another 10 seconds okay i'm going to close this ready um yes indeed a is the right answer because that's
1216	one if i know that one variable is one then the exclusive or is going to be the complement of the other variable which is one minus y so that's what you would get if you calculated this um because this is what we did today and um feel free to ask questions so let me just so we're going to spend a good chunk i'll review this what we've done so far but then we're going to carry it forward and spend a good chunk of tuesday's lecture after the thanksgiving break uh proving that this uh procedure that i just subscribed worked and works and it's um it's an interesting but somewhat you know it's not such an easy proof uh so we're going to spend the try to do it slowly and clearly and then um but this notion of arithmetization is going to be this is this was you know it's it's an important notion in complexity and so um we'll we'll see it again coming up in another proof afterwards in about interactive proof systems
1217	okay um so please ask questions so the output is the value of the one output one state yes that was a question i got other questions somebody's saying minus seven is not the xor of two and three what is the xor of two and three so by the way i i should say we kind of ran a little short on time i'm not saying that we discovered some fundamental new truth about xor here um because that would be bizarre it really depends on the arbitrary decision that we made to say true is one and false is zero we could have come up with a different representation for true and false and then you would get a different value for xor coming out of that you know from the arithmetization that i just described um but uh for this particular way of representing true and false that's how xor and this particular branching program that's how uh what how xor evaluates the the remainder of the proof so somebody's asking which is it which is true
1218	the fundamental theorem of algebra which talks about polynomials and the number of roots that you can have that's going to be that's going to be critical um uh so the that is the fundamental theorem of algebra that's where we're going good good question well you know so the somebody's complaining that you know we're not taking the digit binary representation of two and three and taking the bit by bit um xor well that's i'm not you know binary representation is not a part of this we're thinking of these as two elements of a field um of a finite field which we'll talk about later represent the binary representation is isn't is not is not entering into this discussion um so talk about why just doing the sum is enough um i think that was so why is it i mean here it is why is just doing the sum when i'm looking at the um the how to describe the value of this node based upon the values of all the incoming nodes and remember the
1219	point of the the starting point of this is that we have to faithfully represent the boolean logic with the arithmetic and then we're going to use that and extend it to non-boolean values but as a starting point we have to faithfully represent the boolean values now the boolean values on the incoming edges at most one of them can be can be a one because the ones correspond to the edges of the execution path and you can't make an execution path um that's going to have two branches that's going to go through a node twice because then you have a loop and we don't have there's no cycles allowed okay so i think where it's at four um i want to say farewell to all you all have a great uh week and i'll see you when you get back
1220	so we've been talking about p and np and the time complexity classes and today we're going to shift gear we're going to talk about uh space complexity or memory complexity as uh space complexity is what complexity theorists uh usually refer refer to it as um and um you know time and space are the two basic most basic measures of complexity that uh that we consider and so um today we're going to look at the the second of those two um the space complexity uh so we will define a lot of this is going to be by analogy with what we did for time complexity we're going to define complexity classes we'll talk about polynomial space and non-deterministic polynomial space um see how those classes connect up with the time complexity classes that we've already defined and we'll do some examples that will be setting us up for our further discussion about space complexity next week so we're going to talk about first of all what it means for a turing machine to run in a
1221	certain certain amount of space and that's simply going to be counting the number of cells that the turing machine scans over on its tape during the course of its computation you might be reading that cell might be writing on that cell but the total number of cells that it actually um visits um of course visiting the same cell multiple times only counts once because space can be reused but we're going to count the number of cells that the turing machine visits during the course of its computation and then define the space utilization by analogy with what we did for time so we'll say a turing machine runs in a certain amount of space f n we'll say if first of all it has to always hold so all of the machines are deciders and it uses at most that much uh tape that much that it visits that number of cells on all inputs of length n so just like we said for time complexity the machine has to run within t of n time
1222	on all inputs of length n here it's going to have to use at most f of n cells on all inputs of length n in order for it to be running in space f n okay a tape cell is simply a little square of the tape where you can write a symbol okay answering a question that good question that came in from the chat so um you know uh i'm not sure we have i have a diagram for that but the um in each of the little squares on the tape are going to be the tape cells generally we're going to be sticking to one tape turing machines but i'll make a brief remark about multi-tape during machining shortly better take cells sorry uh on all inputs of length n uh so return now okay so that's for deterministic uh turing machines for non-deterministic touring machines we will say uh that it also runs in a certain amount of space so for a non-deterministic machine it has to use at most that many tape cells
1223	on each branch of its computation separately you don't add up the total number of cells used across all of the branches just like we don't add up the total amount of time the machine uses across all of its branches for the machine to be running in say space n squared it has to be using it most n squared cells or order n squared cells on each one of its non-deterministic branches separately there might be exponentially many branches but that's okay but on each branch it's going to be using at most n squared or order n squared cells importantly though that still the machine has to be a decider it's not enough to be looping forever and using a small amount of space it could do that but that's not going to count toward the machine contributing to its um space complexity of that language so for the machine to be running in a certain amount of space we say that the machine holds on all of its branches and each one of its branches uses
1224	at most that much space okay again i can see lots of typos here thank you um i messed this all up today uh some non-deterministic good thank you um all right so we're going to define the space complexity classes analogous to this time complexity classes so these are languages that you can do with machines that run within that space bound so um space f n you can think of space n squared um is all of the languages that a deterministic one tape turing machine um can do within uh can decide within by using in most n-squared tape cells or order n-squared tape cells similarly the non-deterministic space complexity class are all of the languages that are non-deterministic one tape turing machine can decide running within that amount of space okay and lastly we have a polynomial space so that's the union over all polynomial space bounds of the space complexity class and non-deterministic polynomial space it's the same for all of the non-deterministic uh polynomial space classes okay so i think i do have a
1225	check-in on this
1226	which talks about uh multi-tape turing machines so we could define space complexity for multi-tape turing machines just as we've been doing which is we did for one tape turning machines and then define the associated space complexity classes and then define the class p space but that would be for multi-turing machines now for time uh remember that the class p that you would get from multitape turing machines is exactly the same as the class p that we got for one tape turing machines um that was part of the nice quality of the class p it's robust in that sense a natural so how about for p space um what do you think do we get the same class um no maybe or yes because we can convert a multi-tape turning machine to a single tape turning machine by only squaring the amount of space um that was what happened with time as you remember or maybe we can do even better converting a multi-tape touring machine to single tape only increases it by by less by
1227	say a constant factor here remember how this is how we're defining space complexity for multi-tape turing machines we're taking the sum of all the cells used on all of the tapes all right so let's launch that poll and see what you think hopefully this is not too hard um yeah i think most of you have got the idea though some of you are i worry sometimes about some of the answers that i get i don't know if you're serious or you're really com badly confused but anyway let's let's wrap this up another 10 seconds or so let's call okay i'm gonna end it yeah i mean i uh i think answer b is a reasonable answer in fact uh answer c is the correct answer uh you can if you just look at the same simulation from multi-tape to single tape and how much space overhead that simulation introduces um it's only linear you're basically just taking all of the tapes of the multitape machine and writing them down next to one another obviously you
1228	know ignoring all the infinite infinitely many blanks we're just taking the active portion of the tapes writing them down next to each other so the total amount used is just going to be the sum on the single tape of what was used on each of the individual multitapes in the original machine so there's just a linear cost overhead by converting from multi-tape to single tape when you're looking at space the amount of memory that's used for time remember there was some additional overhead because we had to be uh updating um where the virtual heads were and that uh cost extra time to move our single head around to do that but for space the amount of time that's introduced is not as irrelevant we're only looking at the amount of memory and so that's a um link going to just uh you know the overhead on that is very low i would do worry about the folks who are answering a for example in this uh for this question you should be rethinking what's what
1229	what's really going on here um uh so okay um now let us um
1230	and compare uh the time and space complexity classes you know or time and space complexity how do they relate to one another and so first of all we're going to point out um let's uh start out here t of n is going to be represent some bound either on the time or the amount of space and generally at least up till this point um and most of the mostly going forward though there's going to be one variation on that a little later but we're going to be focusing on uh bounds which are at least big enough to either read the input or at least hold the input that's why we we refer to t of n being at least n um so now if we look at uh the time complexity class t of n think of that t of n like typically would be say n squared maybe and the things that you can do in n squared time i claim you can also do in n squared space um and basically um it's
1231	just using the very same machine suppose you have a machine that runs in n squared time how could it possibly use say n square n cubed space if it's running only in n square time even if it tries to use as much state as it possibly could as many tape cells as it possibly could and you know sending its head cruising out um into the blind portion of the tape chewing up as much uh as many tape cells as it possibly can in in n squared time it's only going to be able to use n squared space so the very same machine that runs in t of n time is also going to run in t event space um so this containment here follows you know really without doing um any work at all um so just re restating that here um a uh turing machine that runs in t of n steps cannot use more than t of n tape cells okay so right now we're focusing on we could prove some analogous statements
1232	about non-deterministic complexity um but let's focus here on the deterministic complexity now let's look at going the other direction suppose we have a turing machine that uses t of n space now does that immediately imply it's using only t of n and time and that's uh not so clear and in fact probably not true because a space appears to be much more powerful than time and within a certain amount of space you can run for much longer than that same amount of time um so how long could you run so what which you can show is that if you're running uh within a certain amount of space t event space let's say n squared space for example the amount of time you could use is going to be exponential in n squared a 2 to the order n squared sometimes we also write that as the union of c to the um n squared by sort of pulling down that constant here if you want well it's also just to understand what we mean by
1233	order t of n up in the exponent it means that the union over c to the t of n for all c either of these are just completely equivalent so whichever one you're more comfortable with but why is this going to be true why does a turing machine that runs in say um uh say n squared space use at most uh uh two to the order n squared time and that's because if you look at how many possible configurations the machine can have remember that a configuration is is essentially the contents of the tape this is also the head position and the state but the dominant um uh the dominant aspect of a configuration is the tape and so how many different tape contents can you have well it's going to be exponential in the saw in the length of that tape because you know each cell can have some fixed number of symbols in it if a machine repeats a configuration it's going to go forever which we're forbidding um in uh you know
1234	in the in these machines because they're all going to be deciders so they can only run um uh for an amount of time which is bounded by the number of configurations that the machine can have and so the machine can have you know if it's running in t of n space then the amount of time that it could be running is going to be at most some constant to the t of n or two to the order of t events saying the same thing uh uh you know unless it's going to repeat a configuration and end up looping okay so these are the two fundamental connections between time and space time is contained within the same amount of space space is contained within that amount of time exponentiated okay um so one car reliary of that is that the class p is contained within p space similarly np is going to be contained within an np space for the very same reason um okay is this um understandable you know this is this is a
1235	good place or in a moment to have one more line to to to to tell you about but leading into the next slide so if you understand the definitions of what we've done so far all of the the the this is a this is a fairly straightforward theorem and the and the corollary is immediate okay so um anything that you can do in n squared time you can do an n squared space and so for if anything you can do in polynomial time you can also do in polynomial space yes c somebody's asking me you know what is the c c is essentially going to be the size of the tape alphabet um because that's going to govern how many different configurations you have there's a slight extra uh factor it's like you know slight extra factor for the tape um the the head location and also the um state but uh the the main thing is going to be the number of tape symbols and the length of the tape okay but what's going
1236	to come next is we're going to prove something more powerful than this corollary that p is contained in p space because not only is p contained in p space but np is also contained in p space and for that we're going to have to do more work so somebody's asking me about the number of states the number of states is going to be indep is fixed depend upon depending on the machine only so um they it doesn't depend upon the uh depend up on n so it could in most affect the number configurations by a constant factor and those constant factors are going to be absorbed within the definitions of these uh complexity classes because that's how we would define them to be um uh you know ignoring the constant factors but you know why don't we just take a you know this may be a good place to pause for a second and see if there's any questions because you know i think for some of you this may be um straightforward but you
1237	know i i think it's less common to be measuring thinking about uh the amount of memory as a complexity measure um so this is perhaps a little less familiar some of you have seen measuring time and other classes but remember measuring the the amount of space that the algorithm uses probably is a little less familiar and maybe that's it's worth spending a moment or two answering questions about that so i'm not sure i understand the question that just came in but i'll i'll read it out there is it possible that a turing machine can loop forever absolutely but a turing machine that loops forever does not count as one that runs within the space bound to run within the space bound the machine must halt on every input it has to be a decider we're only considering deciders here so is it possible that turn machine can look forever yes isn't the turing machine we're talking about a member of space and thus a decider um not totally sure i understand the question but if
1238	a turing machine is not halting on all inputs it's not a decider that's our definition um are we good and we're not getting very many questions here so i'm assuming you're all with me or so lost you don't even know what to ask which is not good um so be bold if you're confused throw our question out there because i'm i i don't want to race through this lecture since it's it's maybe a little less
1239	um as promised i'm going to show you now that np not only p as is kind of happens immediately but np is contained as a subset of a p space so that is oh i didn't get a question i moved on before i answered this question can i explain part two of the proof again part two okay let's just do it um uh if something runs in a certain amount of space you have to just think about how many different configurations the machine can have within that amount of space remember the configurations that we defined way back at lbas um so the number of configurations the machine can have depends on how much space it's allocated like the lbas they had a fixed number of configurations and we gave a calculation for that um which is basically an exponential in the amount of space that's how many configurations the machine can have so if the machine is not a is not looping if it's a decider it can never repeat a configuration and that's going
1240	to tell us how long the machine can possibly run for you know it's a it's it's it's important to understand i'm not sure if i knew how to say that
1241	okay getting back now to proving that np is a subset of p space so now we're going to have to do something that's sort of in a way uh different from what we did on the previous slide because now it's not going to be enough to work with the same machine before when we were converting we're showing that a certain amount of time time classes contained within a spaceclass it was by virtue of the very same machine by just showing that if it's running within a certain amount of time then it has to be running within that same amount of sp within that same amount of space um or in terms of the space it was in the x given a certain amount of space it has to be running that same machine within a certain amount of time here we're going to mixing non-determinism and determinism so we're going to have to take a machine that's in uh an np type machine a non-deterministic polynomial time machine and convert it into a deterministic machine
1242	that doesn't use a whole lot of space so there's a difference in the character of this theorem because we have to introduce a new machine um and the way we're going to prove that um i i'm going to take advantage of some of the things we've already shown to prove this one could also prove it a little bit more directly and maybe it's worth understanding making sure you understand both proofs so the first thing i'm going to observe is that sat our np complete language um the satisfiability language itself is a member of p space and the reason for that is um when you're given a formula and now you want to test if that formula is satisfiable one way to do it the most obvious way to do it is try all assignments one by one and see if any of them satisfy the formula now that's going to take a lot of time but how much space does it use i have in mind reusing the space every time we try the next
1243	assignment think of going through all of the assignments the way an odometer would work just trying every possible assignment but reusing the space where you're going to write that assignment down um sort of incrementing it like like a number um written in binary if you wish um going through all the possible assignments every time you get in the next assignment you plug it into the formula and see if the formula is satisfied if it is then you can accept immediately if not you go on to the next assignment and only when you've gone through all the assignments in that way and none of them have satisfied the formula then you can reject so how much space does that use that doesn't use a whole lot of space because you're reusing the space um to write down one assignment after the next okay it's only going to be using an amount of space which is big enough to hold an assignment which is basically linear because it's the size of the number of variables of the
1244	formula so that's going to be a linear amount of space to solve the satisfiability problem and so the satisfiability problem is certainly in p space um step one step two is we're going to take advantage of what we know about reducibility um so if a is polynomial time reducible to b we've already commented we didn't say this exactly in this way but you know it's still going to follow that anything you can do in a certain amount of time you can also do in that amount of space because there's a very same machine um doesn't can't use any more space than the amount of time it was allocated so if a is polynomial time reducible to b it's also going to be reducible in polynomial space the a polynomial space machine could do the reduction so that means if a is polynomial time reducible to b and b is in polynomial space then a is also in polynomial space but we know because satisfiability is np-complete that every language of np is reducible to sat
1245	so put sat in place of b every np language is polynomial time reducible to sat and we now know that sat is in p space so therefore every language in np is in p space because they're all polynomial time reducible to set okay so just by using some of the technology we've developed namely the notion of completeness sort of shows us some of its power that if you want to conclude something about an entire class an entire complexity class if you have a complete problem for that complexity class often it's enough just to work with the complete problem and then everything else by virtue of the reducibility is going to inherit the same property it doesn't work in all cases but in many of the cases as long as the um you know the reducibility can be computed by the um by the the type of procedure you're working with um then you can then it follows uh you know you could also prove this more directly i think it's in some ways a little
1246	clumsy or a little bit um less elegant but you can say well let me just take my um uh take a language that's in np it has a non-deterministic polynomial time algorithm and then give a deterministic polynomial space algorithm simulates that np algorithm just by going through all the different branches but making sure that going through all those different branches you're reusing the space and not using new space every time you're going through a different branch and you can arrange things if you're just a little bit careful to do it that way so you could give a direct simulation in polynomial space of any uh np turing machine so that i mean
1247	so now let's also this furthermore is going to allow us to conclude some additional languages are in p space let's define a class we have not yet seen though maybe you've seen this i think we've talked about this this notion of uh co before um i think we talked about co-touring reducib co touring recognizable um so uh the class those are the class of languages whose complements are turning recognizable and the same for co and p this is the class of languages whose complements are in np so you take the complement of every language that's in np and now you get all the languages that are in this class co np complement of np um so for example the complement of the hand handpath problem so all the graphs which don't have hamiltonian paths from uh you know esthetic so the the the non-hamiltonian uh graph uh the non-hamiltonian path
1248	um well here's a language we haven't i'm not going to define uh as in terms of its complement it's a the tautology problem so these are the problem language these are all formulas or these are the formulas where all assignments satisfy the formula all assignments make the formula true um so a tautology is a statement that's always true so no matter how you plug in the variables so the the tautology tautology language is in co-np um because it's complement which is the non-tautologies those are the formulas for which um there's some assignment which makes it false so that's going to be clearly an np language so tautology is a co and p language okay um now one thing that we get immediately from the theorem as a corollary really should write this as a corollary is that cohen p is also a subset of p space and the reason for that is and this is something that you know it's um again easy but make sure you understand it is that p space itself is
1249	closed under complement because it is defined in terms of deterministic machines and deterministic machines you can always flip the answer and get a machine of the same type which um uh uh will decide the complementary language so for deterministic machines deterministic deciders i should say um you can always flip the answer um now so here we have anything that's in p space it has a deterministic polynomial time a polynomial space uh machine and so its complementary line which is also going to be in p space so p space and cos base p co p space are equal and so that's why coen p uh is going to be in p space it's going to be a subset of p space okay i hope that's not getting mixed up by all of the
1250	uh here is maybe a picture maybe that'll be helpful uh of how the world looks for the time and spice uh complexity classes um so far uh so we have p is a subset of np it's also a subset of co np um again for the same reason that p and co p are equal we never never even really talk about copy because it's the same as p um uh but np and cohen p that those are two classes where we don't know whether they're equal or not uh because an np machine um you know you can't necessarily complement the behavior of an np machine and end up with an np machine so a question how do we know that cohen p is a complete class of problems i didn't say that there's anything about completeness and cohen p is just a collection of languages i'm not saying it's anything any particular feature about it in fact it does have a complete problem just like np has a complete complete problem the complements and i'm
1251	not going to prove this right here but though it's pretty straightforward complements of all the np-complete languages are going to be co-np-complete languages um and um so uh so i'm getting so okay so let's i will answer some of the questions about or about possible alternate worlds this is how we believe the world looks like with each one of these regions being separated from one another including this little corner of the world here np and intersect co-np which is not um there might be languages in here which are not in p and we actually believe there are such languages but again all of this is conjectural um and even whether p and p space are the same or different is an un is an open question we don't even know the answer to that which is perhaps even more shocking that we don't know how to solve pnn you know proved p different from np that we don't know how to prove p different from p space which seems to be a much bigger class
1252	uh it would be incredible that anything you can do with a polynomial amount of space uh you can also do with a polynomial amount of time um but i don't know how to prove that they're different and in fact so this is how the world could look um everything could collapse down p could equal p space and then all of these classes would be the same um and i should also mention i don't have this as another diagram here but just to answer you know there's also another pos there's other possibilities for example um p could equal np without it being equal to p space and then you'd have a different looking venn diagram here where there'd be just two classes p np and co np would all be the same p space would be different that's possible at least we have no idea uh had a head of m a a lot of these things can collapse in in various ways um and you just have to make sure that you you know there
1253	are some collapses that obviously could not uh occur like p if p equals np it's also going to equal cohen p um so you can't get some there are obviously some crazy collapses which could not uh happen that p collapsing p and np being the same but different from cohen b that can't happen but um avoiding some obvious contradictory situations everything else is possible so somebody said so well here's a question let me just answer a few of these did we use the completeness of co np to show that cohen p is a subset of co-p space no we didn't do it that way we showed that uh co-np um uh well let's see didn't we is that fair um well i i suppose you know np of subset of p space immediately implies because he's complementing both sides that cohen p is a subset of copy space so you don't have to deal with the complete problems on the other side that's too complicated to get into here but you don't you don't need
1254	to talk about co-empty complete problems um though again those are very simple to to get from np complete problems um let's see what else is here uh are there np complete problems that are in co-np so the answer to that is no not as far as well i mean there would be if there was an np complete problem in co-np then all of np would be in cohen p and they would be equal so we suspect the np complete problems are not in co and p but don't know how to prove that so why is tautology in cohen p so here is tautology sits in this class here the reason is that its complementary language is an np the complement of tautology are the languages where there is some assignment which makes the formula false so with a with an np machine you can just guess that assignment and check that it makes the formula false so the complement of tautology is an np language and so tautology is a co-np language um okay uh
1255	so somebody's asking about p space and np-space and how do those relate to one another so that's looking ahead um to what we're going to be doing next week but i'll give you a preview an old but at the time surprising theorem was that piece base and np space actually are equal so there this analogy with time breaks down so polynomial space and non-deterministic polynomial space do turn out to be equal the most obvious way of proving of trying to simulate an np an np space machine would be give you an exponential deterministic space algorithm uh so we'll go through that but there is an algorithm which collapses non-deterministic polynomial space down to deterministic polynomial space which again at the time was kind of surprising uh and so last question i'll take here is there some equivalent concept to the idea of a certificate for co-np yes there is a notion of a certificate but now it's going to be a certificate that you're not in the language instead of a certificate that you're in
1256	the language and then again works for the very same reason that we had certificates for np languages where you had certificate for membership for cohenp you have a certificate for non-membership i don't know if there's no other certificate for membership in co mp
1257	okay so now we're going to introduce we're going to look at some important examples these are examples that we're going to um i'm going to give you two examples first one called tqbf and then we're going to have a second example both of those we're going to one of them is going to be an example of a problem in p space the other one is going to be an example of a problem in np space um and it's these are going to be important languages for us so they're not just going to serve as examples for today but you know um they're going to be useful languages for us later on so just
1258	so to understand tqbf you have to understand um what are called quantified boolean formulas or qbfs so those are boolean formulas just like the ones we've been seeing we've been talking about with boolean variables and the ands ors and and negated variables um but now you're going to add quantifiers exist quantifiers for all quantifiers if you haven't seen quantifiers you you need to go back and re you know review those um you know i think that we already kind of introduced talked about them briefly earlier in the in the term but um this is part of the basic math that you need to know maybe you'll not comfortable with them you'll pick it up somewhat during the course of the today's and the next few lectures but anyway uh so if you have a boolean formula formula i'll give you some examples that has exist and for all quantifiers one of the requirement for it to be a qbf is that all of the variables have to be within the scope of one of the
1259	quantifiers so you all of the variables of the formula have to be quantified by one of the quantifiers and the we're going to assume the quantifiers are in front are sort of leading quantifiers in front of the rest of the uh of the of the rest of the expression so because all of the variables have been quantified then a quantified boolean formula is going to be either true or false following the meaning of the quantifiers um and again some of this may become clear as we do some examples uh okay so here are some examples coming so here is one here is a qbf so all of the variables the which are just x and y they both appear in front of uh next to some quantifier so that's going to be that's a requirement uh if we have a qbf and so this says for all x there exists a y this expression holds so we need to kind of unpack that and understand what it means it says for every x for every
1260	for every way of assigning a boolean value to x so uh x is going to be either true or false there exists a way of assigning a boolean value for y to make this true determined to to make the rest of the expression hold true um and we'll go through that but let's let's uh contrast that with the second example where i invert the order of the quantifiers because that's going to be important for the meaning of the formula so if i say for every x there is a y which makes this the rest of it true that says well no matter how i set x there's going to be a way to set y to make this true so that says well if i set x to true it's got to be some way to set y to make to make the the the remaining expression hold um so if i said x to true what should i set y to be um well uh if i said x to be true and maybe
1261	i said y to be true well then this this clause is uh satisfied but this clause won't be satisfied so setting y to be true is not it won't work but for every x i'm only need to show there exists some y so if i pick x to be true i can say y to be false um and now this one is this one holds and this one holds and the formula holds but i have to make sure that that's going to be the case for both settings of x because i'm saying for all x so if i said x not a false because i already showed that it works for x equal to true if i set x to false if i set now y to be true this is going to hold so this expression is true because it is the case that for every way to set x there is a way to set y so this part holds let's look at let's compare that with this case is there some way
1262	to set y such that no matter how i said x this is going to hold and that's not going to be true no matter what you pick for y um there is going to be some way to set x to make this false so does it resist a y such that every x makes us true no if you try x equal to true it's not going to work if you try x equal to false it's not going to work so this second fi2 expression quantified qbf is false okay we're going to be playing with these a lot so it's important to understand how this this quantification works um so tqbf is the problem of testing whether one of these qbfs is true or phrased as a language it's the collection of true qb true qbfs and that's where we get the um uh the uh acronym tqbf not acronym the the the abbreviation tqbf for the true quantified boolean formulas so going back to that example p1 is a true quantified boolean formula and v2
1263	is not a true quantified building formula so that's why p1 is in the language v2 is not in the language now our computational problem is to test whether quantified boolean formulas are true or not and now we can do in polynomial space oh there's a check in first i claim that sat is a special case of tqbf why is that how can we um think of sat as a special case if i give you a sat formula how can i see that as also a tqbf problem if you want to test if that formula is true what would you say remove all the quantifiers or add some quantifiers and what kind of quantifiers maybe um uh how is sat just testing a formula satisfiable a special case of this what i claim is a more general problem of solving these tqbf problems okay closing down let's call yes indeed you know satisfiability so c is correct when you're talking about a satisfiability problem you're saying is there a satisfying assignment another way of writing that
1264	down is take the boolean formula represent take that boolean formula and put exists in front of all the variables saying the is there a is there exists does there exist a way to set x1 and x2 and x3 and x4 to make the formula true make your formula hold so um sat is a special case by adding exist quantifiers of a tqbf problem
1265	okay so why is this problem in p space as i claimed and for that we're going to give a simple recursive algorithm um in any uh a quantified boolean formula now if you want to test if it's true or not you know we're going to basically strip off the leading quantifiers so if it's an exist quantifier we'll remove it and plug in true and false associated to its variable and then solve those problems recursively okay so this is just going to be a recursive procedure for solving tqbf problems operating by stripping off the the quantifiers in front and uh getting smaller and smaller formulas but now we're going to be plugging in uh values true and false um instead of relying on the quantifier uh to um uh to to to uh give us the meaning of the formula okay so first of all if there are no quantifiers then there are no variables because all variables have to be bound within quantifiers and in that case the uh that quantified boolean formula has to
1266	simply be the statement true or the statement false and so you're going to output accordingly because that's all it can be if you have no variables um if the formula starts with an exist quantifier what you're going to do so here psi is the remainder of the formula after you strip off that exist quantifier so you're going to evaluate psi now but take that variable that was bound by the exist and just plug in true um or and false respectively so you're going to get two two now new problems um and uh run them uh and evaluate them using the same procedure recursively uh but now with x plugged in for true plugged in for x and also then with false plug in for x and get the answers for those two cases and if either one of them ended up accepting then you're going to accept because you know there exists a value uh for x which makes the whole thing true because you you you just recursively showed that there was such a
1267	value you know either true or false the thing is has accepted and if both of them fail then you're going to reject and the very same idea if you have a for all quantifier you're going to evaluate the remainder of the formula again with x equal to true and false so as two subproblems but now you're going to require them both to accept because that's the meaning of for all that both assignments to x have to make the formula true so you're going to evaluate them recursively and accept both of them are true as determined by your recursive your recursion okay so how much space does this use um i'm not going to go through this in great detail but uh each recursive level uses just a constant amount of space so every time you do a recursion you have to remember that uh that value uh that assignment to that to that variable you want to think of recursion as being implemented on a stack so you're just going to pop push on the
1268	stack that value of that variable which is that true or false so basically it's one bit of memory uh that you're going to require every time you're going down the recursion you just have to remember what um you know which case you're working on whether x equal to true or x equal to false uh and um so each recursive level just involves constant space and the depth of the recursion you know how far how much might you have to remember well it's going to be at most one for every quantifier um because that's you know you're stripping them off as you're going down the recursion so that's going to be at most the length of the formula that says most of the number of quantifiers you can have and so uh the total amount of space used by this is going to be um just n order n okay so this problem is solved in uh in n space and so that's why it's in p space okay i think that's all i wanted to
1269	say about this okay if we've got the tape and a turning machine as memory in a modern computer what does the finite control correspond to the finite control corresponds to just a finite additional memory um the tape is an unlimited amount of memory uh or if we're putting bounds you know the amount of tape is going to be say n squared memory where n is the length of n n is the length of the input so um yeah they're both memories but um the finite control is it doesn't grow with n so that's going to be just a you know some constant amount of memory what would be the time complexity of this album time complexity would be bad it's going to be exponential so you'd have to just double check that but it's going to be something like 2 to the number of variables that you have two to the number of quantifiers plus some small overhead for evaluating the formula multiple time but it's going to be exponential um that's going to answer
1270	for you so someone is asking going back again to co-np and how do we know there exists a problem in cohen p that is co and p complete we didn't define even what that means but uh co-np-complete means we're going to start seeing other examples of completeness for different complexity classes in particular one of one thing that's going to happen on tuesdays we'll see a problem that's complete for p space in fact it's going to be tq tqbf sort of looking ahead is going to be a piece based complete problem but we even have to have the notion of what we mean by uh complete for these other classes and in the case of co np a problem is co and p complete if it's in in co np and every other co np problem is polynomial time reducible to it so just exactly the same as we have for np just plugging in co np instead and you just have to work through the logic but it's pretty straightforward the complement of any np
1271	complete problem is going to be a co-np-complete problem using that definition um uh so just i i don't want to go through through that those simple steps but you just can go and verify that offline that that's going to be true and i think we're going to probably talk about that later in the semester too um so another question how does the tqbf algorithm ah that is a good question here um why is the tqbf algorithm that i just described in p space doesn't the thing every time i'm doing the recursion doesn't things branch out so that i end up using exponential space critical thing which i don't i actually don't think i mentioned which i think is important to observe is that when you're doing those two recursive calls when you set x equal to true and set x equal to false after you've determined that the the answer for when you set x equal to true now you reuse that space that very same space to test what happens when you have x
1272	equal to false so that's that's the power of space which makes it different from time is that it can be reused so after you've got the answer for when you have x equal to true now you free up that space that's no longer needed anymore you just remember the answer and now you see what happens when you have x equal to false using that same space so there's no exponential blow-up that's that's an important point i'm glad you gave me the chance to to say it so somebody's asking about defining time of an undetermined turing machine to the maximum time of each branch well that's sort of what we have done maybe i don't understand your question but you'll have to ask it after after um afterwards because i want to i don't want to be delaying any more than we that we have so we're going to we're going to go back and um move on here
1273	okay second example um and this one is a kind of a fun example but it's also going to be an important one for us um it's called the latter problem now so you may have seen something called the word ladder but in general a ladder is a sequence of strings which are all of the same length but where consecutive strings differ in a single symbol um so so for example if you have a word letter for english it's going to be a ladder where all the words are english all of the um strings are english words so here's an example i thought i fixed that okay here is here is a a word ladder for english and maybe you've seen these suppose i want to try to get from work to play but all of the intermediate uh strings should be english words with four letters that differ from their previous one in only a single letter and i want to somehow change the word work to the word play so i don't know if
1274	you know so for example i can change work to pork so here's just one letter difference um which looks like it's an improvement because now i have the i'm agree an agreement on the play um but sometimes you know you might change it you might have a good change and then you have to undo it later which i think actually happens here um so pork then this port but then we gave up that progress we made port to sort to suit to slot you understand again you understand what i'm doing here each case i'm just changing a single letter but all of these words all of these have to be legitimate english words of length four plot ploy and then play okay so that's what a word lighter in english would be of course you can do it in different languages and i'm going to talk about it abstractly where instead of having any natural human language as being the uh test for a word b for being a string being legitimate i'm going to
1275	define a um any old language uh let's let's say it's a is going to be some language some set of strings and the and the those are going to be the legal strings that can be in the ladder so a ladder in a is a lot of strings that are all members of a um and now the the latter dfa problem is a is going to be the language of some dfa so i'm giving you b um and so i want and then a start string and an n string so this is like work and play u and v are like work and play so where b is a dfa and its language has a ladder that goes from u to v here are the intermediate strings okay and all right um so um i'm going to show you that this latter dfa problem is in np space okay and it's not this is not super hard because basically uh well let's just actually look at the slide here the way it's going to work
1276	is it's not deterministically going to guess that sequence from u to v so if i if i'm trying to get from work to play imagine those i'm going to be using this as um you know in place of the uh the of the language of my fine art automaton just because this is easier to talk about but imagine these are being strings that are that are accepted by that that dfa um so now i'm trying to get from my string u to the string v and i want to test can i get there by some uh changing one letter at a time but staying as strings that are accepted by the dfa um i'm just going to guess that sequence non-deterministically but i have to make sure careful of two things um i don't want to guess the sequence solid in advance because that sequence might be exponentially long you have to calculate how long it could possibly be but you might might you know you might change to one symbol then change it to
1277	a different symbol then change it back to that original symbol or so the the only bound that you can write down is the number of possible strings that you can have of that length um so it might be exponential uh you don't want to write down that whole thing because that's going to be exceeding your space bound but what you don't need to you're just going to guess them one at a time forgetting about the previous ones just keep guessing the next uh one in the sequence and only remembering that one and seeing if uh you're ever get to the the string your you your target string but then when you do that you have to make sure that you don't end up going forever um because that's not allowed in your uh in your um in your np space algorithm uh so you're going to have to keep a counter to make sure that if you go beyond that bound which is going to be the maximum number of strings you could possibly have
1278	then you're going to just shot that branch of the non-determinism off you're going to just reject on that branch okay so here is i'm going to write to say this here here is my non-deterministic uh you know polynomial space procedure um i'm given my language my dfab and my start and end strings i let y equal the start string write down the length of my strings that i'm going to have to keep in mind all the way through and then i'm going to just repeat the following t times where t is the maximum length as can be which is the the size of the alphabet of these of these things to the nth power where m is the length of those strings uh and i'm just going to not deterministically change one symbol at a time making sure that i'm staying in the language so rejecting immediately if that change introduced a string outside the language and accepting if that string that i get by changing that single symbol is now my target um and
1279	if i've gone through my bound and i haven't managed to reach that target then i'm just going to reject and we just have to observe that this algorithm doesn't use too much space so if you imagine what we need here here's my input unv which is of length n and the total amount of space i just have to remember the current y um and um and also my counter t my counter up to t so um each of those can be written down with it with uh essentially in space so the total amount is going to be order n space um so that shows that uh this latter dfa problem is actually in non-deterministic space n not deterministic linear space um and what we're going to show next um is that this language is actually solvable in deterministic space and this is kind of perhaps a bit of a surprise okay um so what's the size of the input the size of the input is uh going to be what it takes to write down
1280	the uh the dfa and the uh the two strings u and v um so uh um here uh yeah i mean i i should have also included as part of the input the the description of b itself but um uh so but that's going to even work in my favor because um so this this is slightly incorrect because b itself has to appear as part of the input so apologies for that but still the amount of uh space used is going to be order n um because these are going to be actually less than n um so let me jump be so we don't run out of time for the lecture we can save additional questions for afterward i'll stick around for a few minutes i just really have one more slide here um and that is proving this theorem that ladder can be done in deterministically in polynomial space and that's going to be important as a kind of a preview of what we're going to be doing on tuesday and you know if
1281	this goes a little fast i'll go over it again on tuesday so let's just see how it goes so i'm going to show the same ladder dfa problem is solvable deterministically in polynomial space and but this time it's going to be in squared space instead of non-deterministically in end space so there's going to be some cost but it's only going to be a squaring so remember what the problem is you know i'm giving you that dfa and giving you two strings in the language of that dfa and i want to know can i get from one the first string to the second string by changing one symbol at a time but always making sure that the strings are along the way are accepted by that dfa okay so i'm going to introduce notation saying can i get from string u to v by a ladder but now i'm limiting how many steps i can take so i'm writing u to v but doing it only within b b intermediate strings b steps so is there
1282	a ladder from u to v of length at most b that's what it means to write this notation down so i'm going to uh give you a recursive procedure to solve the bounded ladder problem where it's just like the before but now i'm going to say not only does there a ladder from u to v but there's a ladder of length at most b okay so that's going to allow me to solve the latter problem recursively by shrinking the size of b um uh okay so um let's how is this going to work uh um well here's going to be the idea so here is my u and my v um and the procedure is going to work by instead of non-deterministically guessing the steps that take me from work to play because i don't have non-determinism anymore i have to operate deterministically what i'm going to do is work instead of um i'm going to instead of going from looking at the very first thing that follows from from you i'm going to jump
1283	right to the middle and try every possible middle string oh i have no clue even what that middle string should look like so i'm going to try all possibilities in the sequence but then i'm going to use once i have one of those possibilities i'm going to recursively try to solve the problem by splitting that now but i'm now going to divide that b value in half okay so here is the maximum value we can have this is the t from the previous slide which is the maximum length um and i uh here i'm going to try every possible intermediate let's start off with a all a's um and now i cut the problem in half can i get from work to all a's and all a's to play well very first thing i should check is making sure that all a's in fact is a string uh in the language and if we're thinking of the languages sort of you know matching it's like english all a's is not a legitimate word so you
1284	try the next one aab and this is how it's going to work but now you're going to be instead of using english you're going to feed it into the finite automaton just one after the next trying every possibility until you know like a clock like a like an odometer trying them all until eventually you find a string that's in the language sort of i'm representing that by an english word able maybe that's the first word that you would have found and then once you find that you're gonna can i get from work to able and able to play recursively reusing the space again but now where the bound is cut in half okay so that's that's the whole album so um just going through it quickly and we'll do this again um uh here is my dfa going from u to v within b steps first of all oh this is bad uh t should not be one b this should be b if b is one um can i quickly fix that uh so
1285	these t's should be b's my apologies um so if t is one if b is one then they have to d then i'm only allowed a a ladder of length one now i just check at the media directly do you and v different in just in one place if yes then accept else i reject uh if it's greater than one now i'm going to do this procedure that i described i'm going to try for each possible w uh in the middle um i'm gonna try that w test whether i can get from u to w in half the number of steps and from w to v in half the number of steps and except if they both accept um and if trying all possible w's none of them work then i know that there's no way to get from u to v and b steps and so then i reject okay and then to do the original problem which was not the bounded ladder problem i just do the bounded line i do the bounded
1286	ladder problem where i put in t which is the maximum possible length that it could be to get from work to play out to get from u to v okay so the space analysis um well i'm kind of out of time here so we're going to go through this again next time we have a very quick so let me skip that uh analysis i'll review this next time i have a very quick check-in i just want to get to you get get here um find an english word letter that connects the word must to the word vote you can think about that i mean i it's not that hard to come up with such a word ladder uh so i encourage you to think about that also to think about voting which is also important that's coming up um okay another five seconds here um okay i'm gonna end this so make sure you get your credit for the check-in okay so uh we're at the end of the hour um into the end of
1287	the night end of the 80 minutes anyway uh so this is what we did today um and looks like i ran over by a minute so my apologies and but i'll stick around here um if any of you have any further questions so but otherwise uh lecture is over uh see you guys do we know anything about ladder for other kinds of languages i i don't know um uh interesting question whether you can say uh some nice things about the latter um the latter um problem in other in other cases i don't know okay why is t here this value of t sigma to the m the maximum length of a um of a word letter so what did what first of all we have to m maybe i should have written this down m is the the the length of the words uh sigma is the alphabet of the words um so the number of possible different words is sigma to the m these are all possible words that there could possibly be so
1288	uh there's no reason in a word like or ever to repeat the word because you can just find a shorter word ladder that still does the job of connecting to connecting a start in the end so you can just cut out that middle part um the repeated part so in that case the longest possible word letter is going to be the total number of possible words that you can have which is going to be sigma the size of sigma to the m explain again why cohen p is a subset of p space um well maybe i'll say it this way take the why is why is every co np language also in pd space well take the complement of your co-mp language that's an np language an np language is in p space because we proved that that's what we proved um uh but if a language is in p space its complement is also in p space because for a deterministic procedure you can just flip the answer of the machine um so now
1289	you get you know if so if b language b is in cohen p its complement b b complement is an np which is in p space but now so b complement is in p space so now p space you can invert the answer and now b is also in p space i hope that helps um somebody's giving me the answer to get from uh uh must to vote but you know i i i've seen an answer and that's you know there are online tools that will answer word letters um so you just plug in the two you know where the start and the finish and it'll give you the word ladder and then the one that this person is sent me is the one you get from that that tool so i suspect it didn't find it himself i i actually uh before lecture i actually saw that on my own besides the one that i know the one that the one that the tool will give you so that tool gives one in uh
1290	i think five steps and i found one on my own of six steps it's not that hard but yeah must most lost lose rose wrote and vote i think maybe that's seven steps um anyway you see you can solve the for short words you can solve these generally pretty quickly on your own um what else what else can i do for you um do we need to worry about coming back to a previously visited word visited word on the construction on this page no we don't have to worry about coming back to a previously visited word all you need to worry about is making sure that you bound how long you're going to go for and that's where the previously visited issue comes in you know if the um [Music] if the word letter that you found repeats some word well then there would would have been a shorter word ladder that would have also worked but uh you know it still shows that it's possible to get from the uh the start word to
1291	the finish word um if you if you're if you have a repeated one in between so that that doesn't matter we don't have to worry about that if you did then it would be a problem so i think i will it's four or five i think i want to head out uh see you all guys and i'm going to join my tas in the meeting shortly so bye-bye thank you for being here
1292	[SQUEAKING] [RUSTLING] [CLICKING] MICHAEL SIPSER: So, welcome, everybody, to the Fall 2020 online Introduction to the Theory of Computing 18.404/6.840. My name is Mike Sipser.
1293	So let me just tell you what the course is about. Basically, it's going to be in two halves. We're going to be talking about what are the capabilities and limitations of computers-- of computer algorithms, really, computation. And the two parts of the course are more or less divided in half. The first half of the course is going to talk about a subject called computability theory, which it really asks what you can compute with an algorithm in principle. That's-- was an active area of research in the earlier part of the 20th century. It's pretty much closed off as a research subject these days, mainly because they answered all of their big questions. And so a mathematical field really only stays vital when it has problems to solve, and they really solved all of their interesting problems-- for the most part, not 100%. But for the most part, it sort of finished off in the 1950s-- just to say a little bit more about what we're going to talk about there. When you're interested to know what
1294	kinds of problems you can solve with an algorithm-- there are problems that you might want to solve that you just can't solve. For example, given a specification for a computer problem you want to solve, whatever that specification might be-- say your algorithm actually is a sorting algorithm, for example-- and you want to write down that specification and have an automatic verifier that's going to check whether a program meets the specification. Well, that's just in principle impossible. You cannot make a verifier which is going to answer, in all cases, whether or not a program meets a certain specification. So with things like that, we will prove this semester. Questions about mathematical truth-- if you're given a mathematical statement, is it true or is it false? It'd be great if you can write a computer program that would answer that problem. Well, it would not be great if you were a mathematician, because that would put us all out of business. But you can imagine that might be a nice thing to have, but you can't. I
1295	mean, there is no algorithm which can answer that question. Well, along the way, we're going to introduce models of computation, like finite automata, which we'll see today, Turing machines, and some other models that we'll see along the way. The second half of the course, which is going to be after the midterm, we're going to shift gears and talk about complexity theory, which is instead of looking at what's computable in principle, you're going to look at what's computable in practice, so things that you can solve in a reasonable amount of time. And, for example, I'm sure many of you are aware of the factoring problem, which has connections to the RSA cryptosystem, cryptography, and asks whether you can factor big numbers quickly. That's a problem we don't know the answer to. We just don't know how to factor big numbers quickly. But it's possible that there are algorithms out there that we haven't discovered yet that can do so. It's connected with this very famous problem in the intersection of computer science and mathematics called the
1296	P versus NP problem, which many of you may have heard of. We'll talk about that. We'll spend a lot of time on that this term. And along the way, we'll talk about different measures of complexity, of computation, time and space, time and memory, theoretical memory, electrical space. That's going to be a big part of the course in the complexity theory part-- introduce other models of computation,
1297	Talk about the expectations of the course. First of all, prerequisites. There are a bunch of prerequisites listed, 6.042, 18.062 , or maybe some other subject as well. The real thing is that this is a math class. This is a class where-- and it's not a beginning math class, this is a moderate-to-advanced math class. And I'm expecting people to have had some prior experience, of a substantial nature, with mathematical theorems and proofs. We'll start off slow, but we're going to ramp up pretty fast. So if you haven't really got the idea or gotten comfortable with doing proofs, coming up with proofs to mathematical statements, that's going to be a concern. I would just be monitoring yourself and seeing how you're doing. Because the homeworks and the exams are going to count on your being able to produce proofs, and so you're going to be struggling if that's going to be a real-- something that you haven't had experience with. And let me talk a little bit about the role of theory in computer science. This is
1298	a theory class, as you know. So before we jump into the material, I just thought it would be worth it for you to give you at least my perspective on the role of theoretical computer science within the field. So I've been in computer science for a long time. I go back-- I'm sure I'm getting to be a dinosaur here-- but I go back to the days when you had punch cards. That's what we did when I was an undergraduate. And, obviously, things are very different now. And you can argue that computer science as a discipline has matured, and sort of the basic stuff has all been solved. Well, I would say there's a certain truth to that, but there's a certain way in which I would say that's not true. I think we're still at the very beginning, at least in certain respects, of computer science as a discipline. For one thing, there are a lot of things that we do, a lot of things relating to computation, that we just don't know the answer
1299	to-- very fundamental things. Let's take as an example, how does the brain work? Obviously, the brain computes in a certain fashion. And we've made good progress, you can argue, with machine learning and all of those things that have very-- very powerful and doing very cool things. But I would also say that at some deeper level, the methods that we have so far don't allow us to understand creativity. We're not close to being able to create a computer program that can do mathematics or that can do many of the creative kinds of things that human beings can do. I think machine learning, powerful as it is, is really successful only for a very narrow set of tasks. And so I think there's probably something deeper and more fundamental going on that we're missing. That would be my hunch. Now, whether something like theoretical computer science is going to give you an answer there-- or this kind of theory, or some kind of theory-- I think some kind of theory has at least a decent shot at
1300	playing a role in helping us to understand computation in a deeper way. And the fact that we can't understand something as basic as, can you factor a big number quickly or not? You can't really say you understand computation until you can answer questions like that. So I would argue that we have a really very primitive understanding of computation at this stage and that there is a lot that has yet to be discovered, not just on the technological side, but just on the very fundamental theoretical side that has a real shot at playing a role in affecting the practice of how we use computers. And so I think for that reason-- again, I'm not sure what kind of theory is going to be the most useful, but the theory we're going to cover in this course is a particularly elegant theory, and it has already paid off in many applications and in terms of our understanding of computation. And I think, at least as a starting point, it's a good subject to learn. Certainly, I enjoy
1301	it, and I've spent a good chunk of my career doing that.
1302	So we're going to talk about models of computation, as I mentioned. We want to try to understand computers, and we want to understand what computers can do. But computers in the real world are pretty complicated objects, and they're really not nice to talk about mathematically. So we're going to talk about abstract models of computers that are much simpler but really capture-- just like models in general-- capture the important aspects of the thing we're trying to understand. And so we're going to look at several different kinds of models that vary in their capabilities and the way they approximate the real computers that we deal with every day. And for starters, we're going to look at a very simple model called the finite automaton. And that's going to represent-- you can think of it as representing a computer that has a very small amount of memory and a very limited and small amount of memory. And we're going to look at the capabilities of those kinds of machines. And what's nice about them is that you can
1303	understand them very well. And so more powerful models that we're going to look at later are going to be harder to understand in as deep a way. But for these, we can develop a very comprehensive theory. And so that's what we're going to do for the next lecture and a half. So I'm starting off with an example. I'm presenting a finite automaton as a diagram-- we call it a state diagram. It has these circles and lines and labels on the lines and also on these circles. So what's going on here? So this is a finite automaton. I'm giving it the name M1.
1304	So in this case, there were three states, q1, q2, and q3. Those are the labels there. There are arrows connecting states with each other. So these we'll call transitions. And they're going to tell you how to compute with this device. And there's going to be a specially-designated starting state, which has an arrow coming in from nowhere. And there are other specially-designated states called accepting states, and that's going to have to do with how the machine computes. But those are the ones that have these double circles. And so talking about the way it computes, the idea is pretty simple. The input is going to be some finite string of 0's and 1's, in this case. We might have other types of symbols that are allowed for other automata, but the example that I have here, it's going to be 0's and 1's. And the way you compute with the thing is you first put your finger-- which I can't do on Zoom, so I'll use the pointer-- you put your pointer on the starting state, the
1305	one that has the arrow coming in from nowhere. First, you put your pointer there. And then are you start reading symbols from the input, one after the next. So let's take an example here, 01101. So you start reading those symbols, and you follow those transitions. So you go 0-- and you go back to the same state. Then you go-- the next symbol is a 1, so you go over to this state, from q1 to q2. Now you have another one that comes in. So now you're starting at q2, you have another one, so you follow its associated transition. So if you notice, every state has an outgoing transition for 1 and another outgoing transition for 0. So there's always somewhere to go every time you read symbols from the input. So now you're at q2. You read that next, that third symbol, which is a 1. That's going to take you over to q3. And now you have a 0, which loops you back to where you were, and another 1, which loops you back
1306	to where you were. And because you ended up at an accept, you say we accept that string. So that's going to be the output of this finite automaton. For each string, it's either going to accept it or reject it. So it's just a binary decision that is going to be made. It's sort of like a 1 or a 0 output, but we're calling it accept or reject. So this one here, because it ended up at the accepting state, is accepted. But if you look at the second example, 00101, so you're going to have 0, 0, 1, 0, 1. Now we ended up at q2. That's not an accepting state. So therefore, we say we reject this input. OK? Very simple. And now, for example, one of the questions you might want to ask, given one of these things, is, well, which are exactly those strings that the machine accepts? And a little bit of thought will help you understand that the only strings which are going to take you over to q3 are those strings
1307	that have a 11 appearing somewhere along the way, two consecutive 1's, and you will end up at the accepting state. I encourage you to think about that for a minute if not immediately obvious. But those are the strings that are going to be accepted by this machine. And we call that collection of strings the language of the machine. So that set A of those strings that have a 11, for this particular machine, is the language of M1. We also say that M1 recognizes that language, recognizes A. And in terms of notation, we write that A is L of M1. A is the language of M1. So the language of a machine is exactly the set of strings that machine accepts. OK? So one of the first things we're going to want to be able to do is take a machine and understand what its language is, what's the set of strings that that machine accepts. Another thing we might want to do is, given a language, build a machine which recognizes that language. And then
1308	understanding, what are the class of languages? Can you get any language from some machine, or are there going to be some languages that you can do and other languages that you cannot do? So those are the kinds of questions we're going to be asking about these finite automata. What kinds of things can those machines do, and what can they not do? OK. Here's our next check-in. So wake up, everybody who's not paying attention. A check-in is coming. So we have more questions, though I can't keep-- are these three statements equivalent? What three statements? AUDIENCE: At the bottom of the slide. MICHAEL SIPSER: Oh, oh, oh, oh, oh, yes. Those three are equivalent. A is the language-- yeah, those mean the same thing. Not only are they equivalent, but they're just different ways of saying the same thing. That M1 recognizes the language is the same as saying that's the language of the machine and that A equals that L of M. That's all the same way of saying they all-- six of one, half a
1309	dozen of the other. It's two ways of saying the same thing. OK, so let's pop up our poll and get that started. Whoops. Still showing the old one-- oh, here we go. Move it to the next question. OK. OK, so you understand the question here? Where do we end up after we read 101? What state are we in? Do we end up in state q1, q2, or q3? OK? Go fast. This is a-- OK, so I think we got pretty much converged here. I think almost everybody got it right. The answer is indeed that you ended up in state q2. Because you go 1, 0, 1, and that's where you ended up, in state q2. So is this string accepted? No, because you didn't end up at an accept state. So this machine rejects 101. OK, let's keep going. So now-- yeah.
1310	OK, so now we gave it this informal idea of a finite automaton. We're going to have to try to get a formal definition now, which is going to be a more mathematical way of saying the same thing that I just said. And the reason for having a formal definition is, for one thing, it allows us to be very precise. Then we'll know exactly what we mean by a finite automaton, and it should answer any questions about what counts and what doesn't count. It also is a way of providing notation. So it'll help us describe finite automata. And sometimes there might be an automaton where the picture is just too big, so you might want to be able to describe it in some mathematical terminology rather than by giving a picture. Or maybe you're going to be asked to give a family of automata, where there is going to be a parameter, N, associated with the class of languages you're trying to describe with the automaton. And then it'll be more helpful to describe it in
1311	this formal notation rather than as a kind of a picture, because it might be infinitely many pictures that are being needed. So maybe examples of that will come up now. So a finite automaton, we call it a 5-tuple. Don't be put off by that. A 5-tuple is just a list of five things. So a finite automaton, in our definition, is going to have five components. It's going to have Q, which is going to be a finite set of states, so it's going to be a finite set, which we'll designate as the states of the automaton. Sigma is the alphabet symbols of the automaton, another finite set. Delta is the transition function. That tells us how the automaton moves from state to state. Those describes how those transition arrows-- those arrows which connected the states with each other-- it describes them in a mathematical way instead in terms of a picture. And the way I'm doing that is with a function. So delta is a function which takes two things. So I'm hoping you've seen this
1312	notation before. I'll help you through it once, but this is the kind of thing I would expect you to have seen already. So we have Q cross sigma. So I'm going to give delta a state and an alphabet symbol. So Q is states, sigma is alphabet symbols. So you're going to get a state and an alphabet symbol, and it's going to give you back a state. So describing it kind of a little bit more detail, delta, if you give it state q and symbol a equals r, that means q, when you read an a, you go to r. So that's the way this picture gets translated into a mathematical function, which describes those transitions. And then now q0 is going to be the starting state. That's the one with the arrow coming in from nowhere. And F is the set of accepting states. So there's only going to be one starting state, but there might be several different-- or possibly even 0-- accepting states. That's all legal when we have a finite automaton. And so
1313	in terms of using the notation-- going back to the machine that we just had from the previous slide, which I've given you here again-- let me show you how I would describe this using this notation that comes out of the definition. So here is M1 again. It's this 5-tuple where Q now is the set-- q1, q2, q3-- that's the set of states. The input alphabet is 0, 1. It might vary in other automata. And f is the set q3, which has only the element q3, because this has just one accept state, q3. So I hope that's helpful. Oh, of course, I forgot the transition function, which here I'm describing as a table. So the transition function says if you have a state and an input alphabet, you can look up in the table where you're supposed to go under the transition function according to the state and the alphabet symbol that you're given. So, for example, if we were in state q2 here getting a 0, then q2 goes back to q1 so that q2
1314	on 0 is q1. But q2 on 1 here is q3. OK? So that's how that table captures this picture. OK? And it's just a function. It's a way of representing a function, a finite function, in terms of this table here. So I realize, for some of you, this may be slow. We will ramp up in speed, but I'm trying to get us all together in terms
1315	OK, so now let's talk about some more the computation, so strings and languages. A string is just a finite sequence of symbols from the alphabet. This class is not going to talk about infinite strings. All of our strings are going to be finite. There's other mathematical theories of automata and so on that talk about infinite inputs and infinite strings. We're not going to talk about that. Maybe rarely, we'll make it very clear, we'll talk about an infinite string, but that's going to be an exception. And a language is a set of strings. That's the traditional way that people in this subject refer to a set of strings. They call it a language-- really because the subject had its roots in linguistics, actually. And they were talking about-- they're trying to understand languages, human languages. So this is just a historical fact, and that's the terminology that's stuck. OK, so two special string-- a special string and a special language. The empty string is the string of length 0. This is a totally legitimate string that
1316	you are going to run into now and then. And there's the empty language, which is the set with no strings. These are not the same. They're not even of the same type of object. So don't confuse them with one another. I mean, you can have a set, a language, which has just one element, which is the empty string. That is not the empty set. That is a set-- that is not the empty language. That is a language that has one element in it, namely, the empty string. So those are separate things. OK, so here's a little bit of a mouthful here on the slide, defining what it means for an automaton to accept its input-- accepts its input string w. And we can define that formally. And it's a little technical looking, it's really not that bad. So if you have your input string w, which you can write as a sequence of symbols in the alphabet-- w1, w2, dot dot dot, wn, so like 01001. I'm just writing it out symbol by symbol here.
1317	So what does it mean for the machine to accept that input? So that means that there's a sequence of states in the machine, sequence of states of members of Q. So a sequence from Q, these are the states of the machine that satisfy these three properties down here. First of all-- and I'm thinking about the sequence that the machine goes through as it's processing the input w. So when does it accept w? If that sequence has the feature that it starts at the start state, each state legally follows the previous state according to the transition function. So that says the i-th member of the sequence is obtained by looking at the previous one-- the i minus first member of that sequence, the i minus first state in that sequence-- and then looking at what happens when you take the i-th input symbol. So as you look at the previous state and the next input symbol, you should get the next state. That's all that this is saying. And this should happen for each one of
1318	these guys. And lastly, for this to be accepted, the very last member here, where we ended up at the end of the input-- so you only care about this at the end of the input-- you have to be in an accepting state. So you can mathematically capture this notion of going along this path. And that's what-- I'm just trying to illustrate that we could describe all this very formally-- I'm not saying that's the best way to think about it all the time-- but that it can be done. And I think that's something worth appreciating. OK. So now in terms of, again, getting back-- we've said this once already, but in terms of the languages that the machine recognizes, it's the collection of strings that the machine accepts. Every machine accepts-- it might accept many strings, but it always recognizes one particular language, even if the machine accepts no strings-- then it recognizes the empty language. So a machine always recognizes one language, but it may have many, many strings that it's accepting. And we call
1319	that language the language of the machine. And we say that M recognizes that language. These three things mean the same thing. OK? And now important definition-- I try to reserve the most important things or the highlighted things to be in this light blue color, if you can see that. We say a language is a regular language if there's some finite automaton that recognizes it. OK? So there are going to be some languages that have associated to them finite automata that actually solve those languages, that recognize those languages. But there might be other languages-- and we'll see examples-- where you just can't solve them. You can't recognize them with a finite automaton. Those languages will not be regular languages. The regular ones are the ones that you can do with a finite automaton. That's the traditional terminology.
1320	Let's go on from there. So let's do a couple of examples. Here, again, is that same-- getting to be an old friend, that automaton M1. Remember, its language here is the set of strings that have the substring 11. That is that language A. Now, what do we know about A from the previous slide? Think with me. Don't just listen. A is a regular language now, because it's recognized by some automaton. So whenever you find an automaton for a language, a finite automaton for language, we know that that language is a regular language. So let's look at a couple of more examples. So if you take the language-- let's call this one B, which is the strings that have an even number of 1's in them. So like the string 1101, would that be in B? No, because it has an odd number of 1's. So the string 1111 has four 1's in it. That's an even number, so that string would be in B. The 0's don't matter for this language. So strings that have
1321	an even number of 1's, that's a regular language. And the way you would know that is you would have to make a finite automaton that recognizes that language. And I would encourage you to go and make that automaton. You can do it with two states. It's a very simple automaton. But if you haven't had practice with these, I encourage you to do that. And actually, there are lots of examples that I ask you to solve at the end of chapter 1 in the book, and you definitely should spend some time playing with it if you have not yet seen finite automata before. You need to get comfortable with these and be able to make them. So we're going to start making some of them, but we're going to be talking about it at a sort of a more abstract level in a minute. Basically, the reason why you can solve this problem, you can make a finite automaton which recognizes the language B, is because that finite automaton is going to keep track of the
1322	parity of the number of 1's it's seen before. This has two states, one of them remembering that it's seen an odd number of 1's so far, the other one remembering it's seen an even number of 1's before. And that's going to be typical for these automata, finite automata. There's going to be several different possibilities that you may have to keep track of as you're reading the input, and there's going to be a state associated with each one of those possibilities. So if you're designing an automaton, you have to think about-- as you're processing the input-- what things you have to keep track of. And you're going to make a state for each one of those possibilities. OK? So you need to get comfortable with that. Let's look at another example, the language C where the inputs have an equal number of 0's and 1's. That turns out to be not a regular language. So, in other words, what that means is there's no way to recognize that language with a finite automaton. You just can't
1323	do it. That's beyond the capabilities of finite automata. And that's a statement we will prove later. OK. And our goal over the next lecture or so is to understand the regular languages, which you can do in a very comprehensive way.
1324	So first, we're going to introduce this concept of regular expressions-- which, again, these are things you may have run into in one way or another before. So we're going to introduce something called the regular operations. Now, I'm sure you're familiar with the arithmetical operations, like plus and times. Those apply to numbers. The operations we're going to talk about are operations that apply to languages. So they're going to take, let's say, two languages, you apply an operation, you're going to get back another language. Like the union operation, for example, that's one you probably have seen before. The union of two languages here is a collection of strings that are in either one or the other. But there are other operations, which you may not have seen before, that we're going to look at-- the concatenation operation, for example. So that says you're going to take a string from the first language and another string from the second language and stick them together. And it's called concatenating them. And you do that in all possible ways, and
1325	you're going to get the concatenation language from these two languages that you're starting with, A and B. The symbol we use for concatenation is this little circle. But often, we don't. We just suppress that and we write the two languages next to one another with the little circle implied.
1326	And the last of the regular operations is the so-called star operation, which is a unary operation. It applies to just a single language. And so what you do is now you're going to take-- to get a member of the star language, you're going to take a bunch of strings in the original language, A, you stick them together. Any number of members of A, you stick them together, and that becomes an element of the star language. And we'll do an example in a second if you didn't get that. But one important element is that when you have the star language, you can also allow it to stick zero elements together, and then you get the empty string. So that's always a member of the star language, the empty string. OK, so let's look at some examples. Let's say A is the language-- these are two strings here-- good, bad. And B is the language boy, girl. Now, if we take the union of those two, we get good, bad, boy, girl. That's kind of what you'd
1327	expect. And now let's take a look at the concatenation. Now, if you concatenate the A and the B language, you're going to get all possible ways of having an A string followed by all possible ways of having a B string. So you can get goodboy, goodgirl, badboy, badgirl. Now, looking at the star, well, that applies to just one language. So let's say it's the good, bad language from A. And so the A star that you get from that is all possible ways of sticking together the strings from A. So using no strings, you always get the empty string. That's always guaranteed to be a member of A. And then just taking one element of A, you get good, or another element, bad. But now two elements of A, you get goodgood or goodbad, and so on. Or three elements of A, goodgoodgood, goodgoodbad. And so, in fact, A star is going to be an infinite language if A itself contains any non-empty member. So if A is the empty language or if A contains just
1328	the language empty string, then A star will be not an infinite language. It'll just be the language empty string. But otherwise, it'll be an infinite language. I'm not even sure-- OK. I'm not-- [LAUGHS] I'm ignoring the chat here. I'm hoping people are getting-- are you guys are getting your questions answered by our TAs? How are we doing, Thomas? AUDIENCE: One question is, are the slides going to be posted? MICHAEL SIPSER: Are the slides going to be posted? Well, the whole lecture is going to be recorded. Is it helpful to have the slides separately? I can post the slides. Sure. Remind me if I don't, but I'll try to do that. Yes, it is helpful. I will do that. Yeah. Yeah, I will post the slides. Just, Thomas, it's your job to remind me. AUDIENCE: OK. MICHAEL SIPSER: All right, good. So we talked about the regular operations. Let's talk about the regular expressions. So regular expressions are-- just like you have the arithmetical operations, then you can get arithmetical expressions, like 1 plus 3 times
1329	7. So now we're going to make expressions out of these operations. First of all, you have, the more atomic things, the building blocks of the expressions, which are going to be like elements of sigma, elements of the alphabet or the sigma itself as an alphabet symbol, or the empty language or the empty string. These are going to be the building blocks for the regular expressions. We'll do an example in a second. And then you combine those basic elements using the regular operations of union, concatenation, and star. So these are the atomic expressions, these are the composite expressions. So, for example, if you look at the expression 0 union 1 star-- so we can also write that as sigma star. Because if sigma is 0 and 1, then sigma star is the same thing as 0 union 1-- sigma is the same as 0 union 1. And that just gives all possible strings over sigma. So this is something you're going to see frequently. Sigma star means this is the language of all strings over the
1330	alphabet we're working with at that moment. Now, if you take sigma star 1, you just concatenate 1 onto all of the elements of sigma star, and that's going to give you all strings that end with a 1. Technically, you might imagine writing this with braces around the 1, but generally, we don't do that. We just-- single element sets, single element strings, we write without the braces, because it's clear enough without them, and it gets messy with them. So sigma star 1 is all strings that end with 1. Or, for example, you take sigma star 11 sigma star, that is all strings that contain 11. And we already saw that language once before. That's the language of that other machine that we presented one or two slides back. OK? Right. Yeah, but in terms of readings-- by the way, sorry, I don't know if it's helpful to you for me to do these interjections-- but the readings are listed also on the homework. So if you look at the posted homework 1, it tells you which
1331	chapters you should be reading now. And also, if you look at the course schedule, which is also on the home page, it has the whole course plan and which readings are for which dates. So it's all there for you. And so our goal here-- this is not an accident that sigma star 11 sigma star happens to be the same language as we saw before from the language of that finite automaton M1. In fact, that's a general phenomenon. Anything you can do with a regular expression, you can also do with a finite automaton and vice versa. They are equivalent in power with respect to the class of languages they describe. And we'll prove that. OK? So if you step back for a second and just let yourself appreciate this, it's kind of an amazing thing. Because finite automata, with the states and transitions, and the regular expressions, with these operations of union, concatenation, and star, they look totally different from one another. They look like they have nothing to do with one another. But, in fact,
1332	they both describe exactly the regular languages, the same class of languages. And so it's kind of a cool fact that you can prove, that these two very different looking systems actually are equivalent to one another. Can we get empty string from empty set? Yeah. There are a bunch of exotic cases, by the way. So empty language star is the language which has just the empty string. If you don't get that, chew on that one. But that is true.
1333	OK, let's move on. OK, let's talk about closure properties now. We're going to start doing something that has a little bit more meat to it, in terms of we're going to have our first theorem of the course coming here. And this is not a baby theorem. This is actually-- there's going to be some meat to this. And you're going to have to not totally-- this is not a toy. We're proving something that has real substance. And the statement of this theorem says that the regular languages are closed, that really, the class of regular languages are closed under union, closed under the union operation. So what do I mean by that? So when you say a collection of objects is closed under some operation, that means applying that operation to those objects leaves you in the same class of objects. Like the positive integers, the natural numbers, that's closed under addition. Because when you add two positive integers, you get back a positive integer. But they're not closed under subtraction. Because 2 minus 4, you get
1334	something which is not a positive integer. So closed means you leave yourself in the collection. And the fact is that if you look at all the regular languages-- these are the languages that the finite automata can recognize-- they are closed under the union operation. So if you start off with two regular languages and you apply the union, you get back another regular language. And that's what the statement of this theorem is. I hope that's clear enough in the way I've written it. If A1 and A2 are regular, then A1 union A2 is also regular. That's what the statement of this is. And it's just simply that-- that's proving that the class of regular language is closed under union. So we're going to prove that. So how do you prove such a thing? So the way we're going to prove that is you start off with what we're assuming. So our hypothesis is that we have two regular languages. And we have to prove our conclusion, that the union is also regular. Now, the hypothesis that
1335	they're regular, you have to unpack that and understand, what does that get you? And them being regular means that there are finite automata that recognize those languages. So let's give those two finite automata names. So M1 and M2 are the two final automata that recognize those two languages, A1 and A2. That's what it means, that they're regular, that these automata exist. So let's have those two automata, M1 and M2, using the components as we've described, the respective state sets, input alphabet, transition functions, the two starting states and the two collections of accepting states. Here I'm assuming that they're over the same alphabet. You could have automata which operate over different alphabets. It's not interesting to do that. It doesn't add anything. The proof would be exactly the same. So let's just not overcomplicate our lives and focus on the more interesting case, so assuming that the two input alphabets are going to be the same. And from these two automata, we have to show that this language here, the union, is also a regular language.
1336	And we're going to do that by constructing the automaton which recognizes the union. That's really the only thing that we can do. So we're going to build an automaton out of M1 and M2 which recognizes the union language A1 union A2. And the task of M is that it should accept its input if either M1 or M2 accept. And now what I'd like you to think about doing that, how in the world are we going to come up with this finite automaton M? And the way we do that is to think about, how would you do that union language? If I ask you-- I give you two automata, M1 and M2, and I say, here's an input, w. Is w in the union language? That's the job that M is supposed to solve. And I suggest you try to figure out how you would solve it first. I mean, this is a good strategy for solving a lot of the problems in this course. Put yourself in the place of the machine you're trying to
1337	build. And so if you want to try to figure out how to do that, a natural thing is, well, you take w, you feed it into M1, and then you feed it into M2. And if M1 accepts it, great, then you know it's in the union. And if not, you try it out in M2 and see if M2 accepts it. Now, you have to be a little careful, because you want to have a strategy that you can also implement in a finite automaton. And a finite automaton only gets one shot at looking at the input. You can't sort of rewind the input. You feed it first into M1 and then you feed it into M2 and operate in a sequential way like that. That's not going to be allowed in the way finite automata work. So you're going to have to take it to the next level, be a little bit more clever. And instead of feeding it first into M1 and then and then into M2, you feed them into both in parallel. So
1338	you take M1 and M2, and you run them both in parallel on the input w, keeping track of which state each of those two automata are in. And then at the end, you see if either one of those machines is in an accepting state, and then you accept. So that's the strategy we're going to employ in building the finite automaton M out of M1 and M2.
1339	Here is the automaton we're trying to build. We don't know how it's going to look like yet. And yeah, so kind of getting ahead of myself, but here is a strategy, as I just described, for M. M is going to keep track of which state that M1 is in and which state M2 is in at any given moment. As we're reading the symbols of w, we're going to feed that into M1 and also into M2. And so the possibilities we have to keep track of in M are all the pairs of states that are in M1 and M2, because you're going to really be tracking M1 and M2 simultaneously. So you have to remember which state M1 is in and also which state M2 is in. And so that really corresponds to what pair of states to remember, one from M1 and one from M2, and that's why I've indicated it like that. So M1 is in state q, M2 is in state r at some given point in time. And that's going to correspond
1340	to M being in the pair q comma r. That's just the label of this particular state of m that we're going to apply here. OK? And then M is going to accept if either M1 and M2 is an accepting state. So it's going to be if either q or r is an accepting state, we're going to make this into an accepting state too. OK? Whoops. There we go. So let's describe this formally instead of by a picture, because we can do it both ways. And sometimes it's better to do it one way and sometimes the other way. So now if we take-- the components of M now are the pairs of states from M1 and M2. Again, I'm writing this out literally, explicitly here, but you should make sure you're comfortable with this cross product notation. So this is the collection of pairs of states, q1 and q2, where q1 is in the state of the first machine, q2 is the state of the second machine. The start state is you start at the two
1341	start states of the two machines. So this is q1, q2-- probably I should have not reused the Q notation. I should have called these r's-- now that I'm looking at that. But, anyway, I hope you're not confused by reusing this. q1 and q2 here are the specific start states of the two machines. These are just two other states, representative states of those machines. Now, the transition function for the new machine is going to be built out of the transition functions from the previous machines. So when I have a pair, q, r, and I have the symbol a, where do we go? Which new pair do we get? Well, we just update the state from M1 and update the state from M2 according to their respective transition functions, and that's what's shown over here. Now let's take a look at the accepting states for M. The natural thing to do is look at the set of pairs of states, where we have a pair of states-- a pair of accepting states, one from the first machine
1342	and one from the second machine. But if you're thinking with me, you realize that this is not the right thing. What is DFAs? Did I would call them DFA somewhere? Oh, somebody else is probably doing that in the chat. The DFA-- careful what notation you're using. We haven't introduced DFAs yet. We'll do that next on Thursday. But these are DFAs. These are just finite automata, Deterministic Finite Automata. That's why the D. Anyway, so this is actually not right, because if you think about what this is saying, it says that both components have to be accepting. And you want either one to be accepting. So this is not good. This would be the wrong way of defining it. That actually gives the intersection language. And really, kind of along the way, it's proving closure under intersection, which we don't care about but might be useful to have in our back pocket sometime in the future. In order to get closure under a union, we have to write it this slightly more complicated looking way, which says
1343	the pair, what you want to have is either the first state is an accepting state and then any state for the second element, or any state for the first element and an accepting state for the second element. That's what it means to have the union, to be doing the union. OK? So let's do-- oh, here's a quick check-in. So let's do another poll here. We thought we were done with these. Again-- oh, here we go. So it was too complicated to write it out in the polls, so I actually put it up on the slide for you. So all I'm asking is that if M1 has k1 states and M2 has k2 states, how many states does M have? Is it the sum, the sum of the squares, or the product? OK, you have to think about the states of M, what do they look like? And come on, guys. All right, ending the poll, sharing results. Yes, indeed, it is-- most of you got it correct. It is C, the product. Because when you
1344	look at the number of pairs of states from M1 and M2, you need all possible pairs. And so it's the number of states in M1 times the number of states in M2. So make sure you understand that and think about that so that you're following and get this.
1345	So we have another five minutes or so. Let's start thinking about closure under concatenation. So if we have two regular languages, so is the concatenation language. We're going to try to prove that. We won't finish, but we'll at least get our creative juices going about it. So we're going to do the same scheme here. We're going to take two machines for A1 and A2 and build a machine for the concatenation language out of those two. So here are the two machines for A1 and A2 written down. And now here is the concatenation language. And I'm going to propose to you a strategy-- which is not going to work, but it still is going to be a good intuition to have. So what I'm going to do is I'm going to make a copy of-- OK, let's understand what M is supposed to do first. So M should accept its input. So think about this. M is doing the concatenation language. So it's given a string. And it has to answer, is it in the concatenation
1346	language A1A2 or not? So it should accept it if there's some way to divide w into two pieces where M1 accepts the first piece and M2 accepts the second piece. So here would be the picture. OK? And now we have to try to make a machine which is going to solve this intuition. So how would you do that yourself? I'm giving you w. And you can simulate M1 and M2. So the natural thing is you're going to start out by simulating M1 for a while and then shift into simulating M2 for a while, because that's what's supposed to be happening as you're processing the input. So I'm going to suggest that in terms of the diagram like this. So we have here M1 and M2 copied here. And what I propose doing is connecting M1 to M2 so that when M1 has accepted its input, we're going to jump to M2, because that's perhaps the first part of w. And now we're going to have M2 process the second part of w. So the way
1347	I'm going to implement that is by declassifying the start state of M2, having transition symbols from the accepting states of M1 to M2, and then removing these guys here as accepting states. And we would have to figure out what sort of labels to apply here. But, actually, this reasoning doesn't work. It's tempting, but flawed. Because-- what goes wrong? What happens is that-- it might be that when M1 has accepted an initial part of w and then it wants M2 to accept the rest, it might fail because M2 doesn't accept the rest. And what you might have been better off doing is waiting longer in M1, because there might have been some other later place to split w, which is still valid. Splitting w in the first place where you have M1 accepting an initial part may not be the optimal place to split w. You might want to wait later, and then you'll have a better chance of accepting w. So I'm not sure if you quite follow that. But, in fact, it doesn't work.
1348	The question is where to split w, and it's challenging, because how do you know where to split w? Because it depends upon what-- it depends on y, and you haven't seen y yet. So when you try to think about it that way, it looks hopeless. But, in fact, it's still true. And we'll see how to do that on Thursday. So just to recap what we did today, we did our introductory stuff, we defined finite automata, regular languages. We defined the regular operations and expressions. We showed that the regular languages are closed under union. We started closure under intersection, to be continued.
1349	[SQUEAKING] [RUSTLING] [CLICKING] MICHAEL SIPSER: Greetings, everybody. Welcome to our last lecture of the term. We have survived a semester online in 18.404 and we are going to conclude our last topic today, which is interactive proof systems that we started last time. And with the big-- well, the big theorem of interactive proof systems is that IP equals PSPACE. And we're going to give the main idea for that in a slightly weaker theorem, as we'll see. So why don't we jump in? So we have been doing interactive proofs. We gave an example of showing that the graph isomorphism problem, the complement of that is an IP, as I hope you remember. We had that interaction with the approver and a verifier. We're going to go through it quickly. Not that protocol, but just the setup. And then we're going to finish by showing that this number SAT problem is an IP and should conclude that coNP is a subset of IP. All right, so let's go for it. Yes.
1350	So just remember, interactive proof systems, there are these two parties, the prover and the verifier. The prover has unlimited computational ability. I kind of model that as an army of students perhaps who can-- where we don't-- they can work all night. They can use computational resources. And the prover, however, we're not going to measure the computational power of the prover. That's unlimited. And so the prover can do things like find certificates. It can test whether things are satisfiable. It can factor numbers. We don't care. It can do whatever we'd like and there is no charge for the prover's computational demands. OK. So the setup we had was the prover and the verifier. Both see the input. The exchange of polynomial number of messages. And then the verifier accepts or rejects. And we had this notion of the probability that the verifier ends up accepting when paired with a particular prover. And what we want is that for strings in a language, that probability should be high for some prover. And for strings not in the
1351	language, that probability should be low no matter what the prover does. So there's nothing the prover can do. And the way it kind of suggests that at any prover. But whatever the prover's strategy cannot make the verifier accept with high probability. Just doesn't have enough information or it doesn't-- it's just not able to make the verifier accept with high probability. You might think of the prover as trying to make the verifier accept. So the P tilde is a crooked prover. I don't think that went down very well with everybody. So I have it here. Another way of looking at it, maybe it looks a little bit more like NP here where IP is the collection of languages where there's a verifier, just like we had. You can think of NP as having a verifier which can check certificates. Here the prover is going to be like the certificate so that for strings in the language, there's a prover which can interact with the verifier and make it accept a high probability. And you're not in
1352	the language, there is no prover, which can interact with the verifier and make the verifier accept with even more than low probability. What's important is this gap, just like with BPP, between acceptance or rejection. And that gap is there because we want to be able to use the amplification lemma. And if there was no gap, then you wouldn't be able to amplify and make the probability of acceptance extremely high when you want it to be in the language, when you're in the language, and extremely low when you're not in the language. OK. So I hope that refreshes your memory as to how that works.
1353	well, through what we did last time. But let's set the stage for that. So the surprising theorem, as I mentioned, is that IP equals PSPACE. One direction of that is a fairly standard simulation. With PSPACE, you can basically work your way through the tree of possibilities for an interactive proof protocol. And you can calculate the probability that the verifier would end up accepting if you had the best possible prover that would try to make the verifier accept. And you can just do that calculation. It's in the book. You're not going to be responsible for knowing that, actually. We haven't covered it in lecture. But it's not very hard. A little technical, I suppose. The other direction is the interesting one, and that's the direction we're going to be moving toward today. We won't quite get there, but the way it works is that to show that everything in PSPACE, which is kind of amazing, is contained with an IP. So everything in PSPACE can be done with an interactive proof system. And the way that
1354	is done is by using a PSPACE complete problem, TQBF, and showing that that problem itself is an IP. But we're not going to prove that. That would be sort of the next thing we would prove if we had a little bit more time. But we're going to be satisfied with just the somewhat weaker but very similar statement that coNP is contained in IP here. Again, still very surprising, because you have to be able to show, for example, that a formula is not satisfiable with a prover. How can a prover convince a verifier that a formula is not satisfiable? Showing that it is satisfiable, you just give the certificate, which is the satisfying assignment. But how do you show something's not satisfiable? It's unexpected. And the proof of that is pretty much similar, slightly is one kind of technical point which we don't have to get into. So it's slightly easier but very much in the same spirit. So remember this number set problem is you're given a formula and a number, and that number is
1355	supposed to be exactly the number of satisfying assignments of the formula. So in particular, a formula's unsatisfiable, then it would be paired with the number 0. And that's why the number set problem is coNP-hard, because you can easily reduce the unsatisfiability to number set. An unsatisfiability is coNP complete. OK, so remember we introduced this notation last time. This is going to be critical for understanding this proof. So let's go through it once again.
1356	So if you have some formula, what I'd like to do is preset some of the variables of that formula. So that's going to be a formula on m variables x1 to xm. And I'd like to preset the first i variables to zeros or ones as I wish. So I'm going to indicate that by phi with 0 means I'm setting x1 to 0 and the rest of the variables remain variables. And more generally, phi of i values a1 to ai, which to start off with are going to be just zeros and ones, just Boolean values. That's going to be the formula with those first x1 to set to a1 dot, dot, dot xi set to ai for those i constants, which were zeros and ones. I'm going to call those presets, because we're presetting some of the variables in the formula. And the rest of the variables we're going to leave as variables. So we get a new formula on fewer variables by doing this pre-setting process. And we're going to get to do the same
1357	thing in terms of counting the number of satisfying assignments. So remember the notation number phi is the number of satisfying assignments. Number phi with a preset of 0 is the number of satisfying assignments when you've set x1 to 0. And no phi of a1 to ai is where you set the first i variables to those i values. And then you're going to look at the number of satisfying assignments with those presets in mind. So there were two facts. I'm going to call them identities, because we're going to rely on those and we're going to actually extend those to the non Boolean case, as we'll see shortly. So these two identities say that, first of all, if I preset, I think understanding the first one is clear just by thinking about it in the case where i equals 0. So this is the case where the number of satisfying assignments altogether is the number of satisfying assignments when I've set x1 to 0 plus the number of satisfying assignments when I've set x1 to 1. And
1358	this just generalizes that when I look at having already preset the first i variables. So if I preset the first i variables to these i values, the number of satisfying assignments I get there is the number of satisfying assignments I get with those presets plus the next variable being set either to 0 or to 1. And then you add those up. The same idea. And lastly, if I set all of the variables to values, so I have no variables left, and I look at the number of satisfying assignments consistent with that fully set variables, so there's no variables left, everything is set, everything is preset, that's just whether or not those values have satisfied the formula already or not. So this is going to be equal to 0 or 1, the number of consistent satisfying assignments with those m presets where m is a number of variables is just whether those m values satisfy the formula, in which case, I get 1, or they don't satisfy the formula, in which case, I get a 0.
1359	Critical to understand these in the Boolean case, because we're going to generalize this to the non Boolean case, and it's going to be just more abstract. The formulas are going to look the same. We're going to have to kind of-- we're going to lose the intuition that those things correspond to satisfying assignments. Or counting the number of satisfying assignments. All right. So let's have a quick check-in here. So we're just going to do an example to hope to nail this in, this idea. So here's a particular formula phi. And now remember, number phi is the number of satisfying assignments. So phi, the number of satisfying assignments where I've set x1 to 0 and so on. And here I'm really kind of giving you two options in each row for the value. Now you have to check all that are true. So it's really going to be at most one per row, presumably. All right. Let's see if you're with me here. So the number of satisfying assignments for altogether, well, there are two ways of
1360	satisfying this formula. This is really like exclusive or. So either x1 is 1, x2 is 0, or x1 is 0 and x2 is 1. So one of the variables has to be true. The other one has to be false. And then you're going to end up satisfying both clauses, as you can easily see. So b is correct in the first line. Now, if I'm going to already commit to saying the first variable is set to 0, now how many satisfying assignments can there be? Well, the second variable just has to be set to 1 in order to satisfy. So now there's going to be only one satisfying assignment consistent with setting the first variable to 0. Now if I set both variables to 0, now how many satisfying assignments can there be consistent with that assignment? There can be 0, because in order to satisfy this formula, one of the variables has to be 0. The other one has to be 1. If I'm presenting them both to 0, there's not going to be any
1361	satisfying assignments, because 0, 0 not satisfy the formula.
1362	Oh well. All right. Let's first go over the protocol we attempted for number SAT last week on Thursday. So we're given the input, the formula, and a k. And remember what we want to happen. We want the verifier to end up accepting with high probability when k is the correct value and with low probability when k is not the correct value. Now, this is going to be, as you may remember from last time, this is going to end up being a flawed protocol, because it's exponential. We're only allowed to have a polynomial size protocol. But just looking ahead in this protocol, the verifier is going to end up accepting with probability 1 for an honest prover and with probability 0 no matter what the prover tries to do. So for any prover, the verifier cannot be made to accept. So this is kind of an extreme case where there's not going to end up being any probabilities. But it's an exponential protocol. So in that sense, it doesn't do what we need. So let's go
1363	through it, because it really sets us up for the polynomial protocol with the non Boolean values. All right. So first the prover sends-- let's just look at it and not rush it. The prover sends the number of satisfying assignments according to the prover. The verifier checks that is equal to k. And I think it's best to understand this first with the case that the input is in the language. So k is correct and we have an honest prover. And then we'll understand what happens if k is not in the language. And we'll see that no matter what the prover tries to do, the verifier is going to end up not accepting. And again, this is just a setup for the real protocol. So this is kind of a dopey protocol. You're going to think, what in the world, why am I doing this? It seems like I'm making something that's very simple complicated, but it's really just the framework that I'm putting together.
1364	All right. So the proof is going to send the claim for the number of satisfying assignments, which in the honest case is going to be the correct value. The verifier checks that it matches the input. Now the verifier says, well, I want to be convinced that your claim is correct. So the prover is going to justify that claim by saying, well, the total number of satisfying assignments is whatever it is, 100 because the number when I have x1 set to 0 is 60. And the number when I have x1 set to 1 is 40. And that adds up to 100, which is what you would need to have happen. So the verifier checks that the sum is correct and then says, well, now how do I know those two values are right? So then the prover unpacks it one level further. So breaks those two down by justifying that phi 0 was correct, that value 60 was correct, by saying, well, now if I set the next variable, x2 to 0 and 1, that's going
1365	to have to add up to phi 0. So maybe to get 60, I had 50 and 10. And to get 40 for number phi of one, I had 20 and 20. So these I have to add up. So each level justifies the preceding level. We're going to have that happen again. Now, the prover says, well, I mean, I need to be convinced. I don't trust you. I need to be convinced that these values are correct. So level by level, the prover is going to be setting more and more of the variables in all the possible ways until it gets down to the very bottom where it's setting the variables in all possible ways. So exponentially many settings here. And the verifier now checks that the previous round was correct. So that's where we set only the first m minus 1, the very last variable hadn't yet been set. So checks all of those 2 to the n minus 1 possible settings in terms of the new settings that we got where we set those m
1366	minus 1 settings, but we extended it by 0 and by 1. Again, this is the same identity that we used from before. And now that the prover has sent all of those possible values, the verifier needs to be sure that those are still correct. But the thing is that at this point, those are all zeros and ones because they all say whether that assignment satisfies the formula or doesn't satisfy the formula. So the verifier can check those directly. Checks each of those, whether just by plugging into the formula and seeing does it satisfy the formula or not. So each one of these is a 0, 1 value, which is supposed to correspond to whether the formula was satisfied or not. Those all are correct and everything else along the way has been correct. The verifier is going to accept. Otherwise if at any point one of those checks failed, the verifier has already rejected or at this point it just rejects. So that is the protocol, the exponential protocol. And I'm not sure if this
1367	is helpful to you or not, but I like to think of it sort of as a tree of possibilities. So these yellow values are what the prover is sending. So the prover first sends the number of satisfying assignments all together. The verifier in white is checking-- are doing these checks. So it checks that it equals k. And then the prover sends the next level. The verifier checks that the addition works out. Then the prover unpacks it further, assigns values to the first two variables, and the verifier checks that just the assignments, just a single variable are consistent with that and so on. And to assign all m variables and then it checks directly with the formula. Now, what happens-- and here is the case. It's going to be important to understand in both here and in the non Boolean case. What happens if we had an incorrect value for the input? And what I want to show you is that the prover is going to-- I want to show you that the verifier is going
1368	to end up rejecting in this case with certainty. Later on it's just going to reject with high probability. But for this protocol, it's going to accept with certainty. And why is that? Because first of all, if the prover, if k was wrong, so I'm indicating the wrong values in red. If k was wrong, so it did not equal the number of satisfying assignments, if the prover sends the correct value, the verifier is just going to say it doesn't match up. I reject right away. So what can the prover possibly do to prevent the verifier from accepting? You're going to see that there's nothing you can do. But later on, there's a chance that the prover can get lucky. But here there's nothing you can do. Let's try to humor me and see-- let the prover try to manage to keep the verifier going as long as possible. So the prover in order to prevent the verifier from rejecting at the beginning would have to lie about the number of satisfying assignments. But then the prover
1369	is going to say, well, OK, you're claiming there's only 99 satisfying assignments. Prover doesn't know what the right real answer is. But we know it was 100, let's say. But let's say k was equal to 99. The prover claimed it's 99 now. And so the verifier says, OK, well, it's 99. Convince me of that. So now the prover is going to have to say the number of satisfying assignments for 0 and the number of satisfying assignments for 1, they have to add up. At least one of those has to be wrong, because you can't have the two correct values adding up to the false value. So a lie here has to yield a lie in at least one of those two places. And then a lie there is going to have to yield a lie in one of those two places, just like each lie kind of forces more lies. As you know, you're trying to lie. The story gets more and more complicated in order to try to justify all this. And so in
1370	the end, you're going to get an inequality. And the verifier is going to end up rejecting. Somewhere along the line, there's going to have to be an inequality, if not along the way then at the very end when the verifier does the check itself. Because one of those, you could trace that down, there's going to be lies and lies and lies and then there's going to be at the very bottom one of these values is going to be wrong. And when the verifier checks them all, it's going to find out that there is an inequality there. And so one of those checks is going to fail. So I'm getting one question here. Why is this any better than just checking all possible assignments without a prover? It isn't. The only reason I'm doing this is to get us ready for the arithmetized protocol where we have non Boolean values coming in. So questions on this? I think it's important to understand this one. Don't ask the question why. The why is just going to be
1371	we are getting ourselves ready for something later, which you don't know yet. But I want you to understand it for what it is, even if it seems unnecessarily complicated. OK, so let's keep going. So how are we going to fix that protocol so it's not exponential? So again, here is a picture of that exponential protocol. And we have that exponential blow up occurring because at every stage, each value is going to be justified in terms of two values at the next stage. So it's going to be exponentially many values after a while. So instead, we're going to try to justify each value here in terms of just a single value at the next stage. But it's not going to be good enough just to pick either the 0 or the 1 at random. Because it might be each-- there might be just a single course of lies going through here. And the only way you would be to catch that would be to guess correctly at each stage which was the lie. And then you
1372	would catch it at the end. If you're just going to be randomly picking zeros and ones, you're not going to have a high probability of catching the prover when it's lying. And so that's not going to be good enough. The input might be the wrong value and you might have a prover which just has one path of lies, and then your probability, you would still have a high probability of accepting in that case, even though the input was wrong. It's not what you want. When the input is wrong, you have to have only a tiny chance, a very small chance of accepting. So the way we're going to achieve that is by having these-- instead of picking a 0 or a 1 for these random values, we're going to have non Boolean assignments to the variables. And we have to make sense of that. And we've already seen an example of that. It's going to be very much the same. All right. Are we all together here? So this is a place where we could
1373	try, if you have a question, we can try to answer that. Are we good? Let's keep moving. OK, so how are we going to arithmetize Boolean formulas? It's, again, the same idea we had before. Simulating ands and ors with plus and times. So we had this from before, same exact picture. Actually it's even simpler, because now we're going to be using the true simulation of or instead of some kind of a special case simulation of or, which we had in the branching program case. So these faithfully do what and and or does when you plug in 0 for false and 1 for true. So that means that we can take an entire formula and arithmetize it. The formula built out of ands and ors and negations. And you're going to get a polynomial that comes out. And that polynomial, what's going to be important for us is not going to be of extremely high degree. The actual degree is going to be at most the length of the formula in terms of the number of
1374	symbols it has. You can check that on your own. But for now you can just trust me. The degree of the polynomial, because it only goes up during the multiplications, but the degree doesn't become too big. And we're going to be doing-- and I don't want this to be a confusing issue here. We're going to be doing-- but we have to be correct. I don't want to be cheating here. So all of the arithmetic is going to be done in a field. So we have to do plus and times mod some number, which turns out needs to be a prime number for reasons I'm not going to get into. But it doesn't really matter. It's just modular arithmetic. And that's one thing that enables us to pick random values in a natural way, because there's only finitely many values in the field. And so you're just going to pick one at random. But here we want to be able to represent-- it's going to be more important for us to have a larger field, because
1375	we want to be able to represent the number of satisfying assignments which can be a number between 0 and 2 to the m. So we have to have a field which has at least 2 to the m elements in it so that we can in a sensible way write down those numbers. Let's not get caught up with that. But we can try to answer those questions offline if you want. But just think about it for this first pass. We're doing the arithmetic mod sum prime. So now we have the same notion of presets as we had before. So if we have a formula and we preset some of the values but now those values may be non Boolean values. We may be plugging in values for the formula. Not just zeros and ones, but we might be plugging in sevens or 23's or whatever. And the formula is going to in order to have a value, a meaning to that, we're going to treat that formula as the polynomial from the arithmetization. And just plug
1376	in those values into the polynomial and see what the polynomial does for you. So here we're going to be presetting some of the values of the formula like we did before. And now it's going to be the same thing. But now in the polynomial, we're going to be pre-assigning some of the values of the variables to these a's from the field. And the remaining variables are going to stay as unset. Now we have to give an interpretation. So the new polynomial here. So I'm getting a question. Well, maybe I better take this. Let me hold off on that for now what the degree is. I'll answer the questions in a second. So now remember from before, number phi was the number of satisfying assignments when I preset the first i values. It no longer makes sense to talk about satisfying assignments, because these values may no longer be Booleans. So I'm going to have to write this formally as I'm going to plug in those values, those i values, for the first i variables. And
1377	the remaining are variables which I have not set. I'm going to assign them to zeros and ones in all possible ways. Only to zeros and ones. Because what I want to have, you might think, well, why aren't we assigning these to other values in the field? Well, because what I'm aiming at is that if I were to plug in zeros and ones at this point into the polynomial, I'm supposed to get exactly the same values as I had before, because I'm simulating and's and or's. So I'm just extending the definition, the evaluation into a new realm. But I shouldn't change the values on the old Boolean realm. So I'm going to be adding up the unassigned, the unset variables in all possible Boolean ways. And the first i values could be non Boolean values. So you have to just accept this as an abstract notion. No longer has an interpretation as satisfying assignments. So as I said, what's important is that if I happen to put Boolean values in now, then phi and number phi
1378	give the same values as they would have before. Because the polynomial acts identically to the formula on Boolean values. OK. So this is what I'm repeating what I said. And there's another point that also you have to check, which is that the identities that we had earlier that connected up what happens when I set the first i values and I set the first i plus 1 values, those still hold. So if I set the first i values now to possibly some non Boolean assignment, that's what I get when I extend those values to one more variable being assigned. But I just need to assign that variable to 0 and to 1 and add those up because of the way I've defined things over here. So I've assigned those variables to zeros-- the unset variable to zeros and ones when I'm defining the number phi function. And then lastly, when I assign everything now to possibly non Boolean values, that's going to be-- there's no longer anything to add up. So I'm going to get exactly
1379	the same as I got from before when I-- so assigning number phi of totally preset input, it's the same as phi with a totally preset input. Because in that case, there are no variables left to add up over. So there's just one. I just get one single. I sum it as just one element in it. So I got a question here for earlier. What happens to the degrees of the polynomials? Well, the degree of number phi is going to be at most the degree of phi, because I'm just adding things up. And addition doesn't change degrees. As I preset values, the number of variables goes down, but the degree may not necessarily go down. So the question was I got are the new polynomials having lower degrees? Not necessarily. They have fewer variables but not a smaller degree. So let's do this check. Let's see if that-- now again, this is I think I have messed up on this. Well, there's one of these that's-- I'll give it away in part. There's only one of
1380	them that was true anyway. So you can check the one that's true according to the way we've defined it. So this is a little bit of a trick question here, as I'll explain. But there's only one of them that faithfully does the arithmetization as I described on this page. And that's the one you should check. So remember, over here this is the formula. This is the recipe for how I'm doing the arithmetization. This whole process here. So one of these lines, one of these, a, b, or c, corresponds to doing that. I'm going to close this down. So are we all in? Yeah. So a is the correct answer. A does the arithmetization according to the recipe that I just described. Because if you look at x1 or x2, we can just check it in the very first part of the polynomial. x1 or x2. Well, it's x1 plus x2 minus the product x1 x2. So you can just see it right there. The others don't have that. And similarly for x1 bar and x2
1381	bar. It becomes 1 minus x1, 1 minus x2, and then the product of those. So a is pretty straightforward as the arithmetization of phi. Now, in fact, any of those would work. I don't want to confuse you here. But any of those would have worked, because they all agree on the Boolean assignment. And that's all that really matters. So if you have any-- all I care about is that they agree. The formula agrees with the polynomial and the Boolean cases, and these all happen to agree and zeros and ones. Doesn't matter though. I put those there just in case you tried it by just substitution of zeros and ones in. You might have picked the wrong thing. OK. So let's take a break here, and then we will see about how to go about fixing the protocol after the break. All right. So also happy to take any questions. We haven't really done a whole lot. We basically, this has all been review of what we did last time. But let me start the timer.
1382	But feel free to ask questions. I'll tell you where we're going. This whole proof really comes down to understanding one line, which is going to be in the second half. So I'm really kind of-- this is all big setup here to get you ready to be able to understand that one. I'll tell you when it's coming. So you won't have to worry that you'll miss it. But that line is not easy to understand. So I think it's important to get all of the framework and all of the context all set up for you so then you can understand that line and hopefully you see that line and understand it. OK, so the important fact. So let's go back. You wanted to see the important fact. OK. So this is what I was saying before. If I plug in Boolean values into the arithmetization, I get the same exact thing as I would have if I applied the Boolean operations before I did the arithmetization. So plus and times in the arithmetization give a faithful simulation
1383	of and and or according to these little formulas. That's all I'm saying with this. And so if I plug in Boolean values for the a's I get exactly the same as I would have gotten before I did the arithmetization. Because the arithmetization is a faithful simulation. Not sure how else to say it. Let's see. What does the or rule now-- why does the or rule now contain the minus ab term while the previous instance of arithmetization didn't? Remember in the case of branching programs, we didn't need the minus ab term over here. And that was because we could argue that it was a disjoint or in the case of the branching programs. I don't want to get confusing by trying to explain why that was. But in that earlier case, we never took an or of two ones. It was an of 0, 0 or possibly 0, 1 or possibly 1, 0. So therefore we never had to deal with a case when we had an or of a 1, 1. And here we can
1384	have that. So we have to subtract off that ab term, because otherwise we'd have-- if we just had a plus b, then the 1, 1 case, we would end up with a 2. And that would not be a faithful simulation of the or operation, because 1 or 1 should be just 1, not 2. So this is a good question here. Do all the numbers need to be zeros and ones? I'm not sure how negation would work with larger numbers. The negation, you just blindly follow it. Even though we're going to be plugging in non Boolean values, it's going to be 1 minus 7. So you're going to get minus 6. You have to do that mod P, mod Q, whatever that value you get. But you can no longer think about it as negation in the former sense. Now it just becomes a formal thing. You're just plugging along doing what the polynomial says. Numbers are coming out. You think this is just nonsense. But the thing is it's going to have a meaning that's
1385	going to be useful to us. That's what this protocol is going to show. So you can't think about it as negation anymore. It's just negation becomes 1 minus x in the arithmetized world and you just have to live with that. Let's see. Another question here. If all the phi are equivalent for Boolean inputs in the check in, so this is back into this check in here, so if all of the-- yeah. So the question is if they're all equivalent in the Boolean case, why is only a correct? Because I defined P sub phi in a particular way. And so this was the value you got if you follow the way I define P sub phi. The others would work, they just weren't the way I defined it. Any other questions here? We should probably move on. Can arithmetization be used in other contexts? Offhand, I don't know. There are these two cases where arithmetization works. Whether there are other cases too, I'm actually not sure. OK, so let's move on. So our timer is up.
1386	The candle has burned down. OK. So this was-- OK, here we go. This is the real protocol. So I'm going to present it to you the way I did before. Let's think about it with the case first where the input is in the language and we have an honest prover. So we start off the same way. The prover sends phi, sends number phi. Which in the old sense was the number of satisfying assignments. It actually still is, because since we're not presetting anything, there's no non Booleans in the picture yet. So this is going to be the same value as before. The verifier checks that k equals number phi. So that's why we have to have a big enough field there, so that we can represent numbers up to the number of potential number of satisfying assignments. But that's a side note. But anyway, this is exactly what we did before. No change. The number of satisfying assignments if you like. Now, let's just see. Let's remember. And this is one of those cases where
1387	not having a big blackboard hampers us. So I'm just going to remind you what we did last time. But I'm going to change this. So remember before P sent-- and unpacked at one level. Sent the number of satisfying assignments said number phi of 0 and number phi of 1. And then we did that check to justify the previous value, which the verifier doesn't necessarily trust. OK. Fasten your seatbelts, everybody. This is the whole proof in the next line. But it's a doozy. All right. P is going to send phi of z as a polynomial in z. It's going to send just a single object. But that object is an entire polynomial. And the way it's going to send that is by sending the coefficients of that polynomial. So let's digest that statement. So first of all, let's understand the value of doing that. So if I can send the entire polynomial phi sub z represented as a polynomial, I can plug in 0 and 1 into that polynomial and allow the verifier to do the
1388	check that it needs to do to demonstrate that number phi is correct. So it's going to check that number phi is number phi of 0 plus number phi of 1. But instead of getting those values directly from the prover, it's going to take that polynomial it got and evaluate that polynomial at 0 and 1. And just to remember, let's go back and remember how we defined-- defined number phi to make sure that we understand what it means to have a polynomial here. So remember, here we're just taking the very first value. But you are OK with putting a constant 0 or 1 and then adding up over all possible extensions, all possible Boolean extensions to that. And maybe it's OK to put in a non Boolean value here, like 7. And then you take the remaining variables and assign them zeros and ones in all possibilities and add it up. Now I'm going to do something even a little wilder. I'm going to put in a variable for a1. Some symbolic, if you want, symbolic
1389	value. So I'm going to put in a value z for a1. So now I plug in z for a1 here. And a2 through am are going to be zeros and ones in all possible ways. So I just get a polynomial in z. The other variables get assigned and added up over the various Boolean assignments. And now I get some polynomial. So I get some expression in z. That's just going to be a single variable polynomial. Whose degree is it going to be? At most the degree of number phi. So degree is not going to be too big. So it sends the coefficients so the degree of that is not too big. So there are not too many coefficients to send. So the coefficients are in terms of the xi's. No. I'm not sure what the mean-- the coefficients are not in terms-- the xi's are gone at this point. The xi's, we've added up the xi's being assigned to zeros and ones in all possible ways. So there are no other variables left. There's only
1390	z. So I'm going to do the same protocol in a more pictorial way in a minute. So you're going to see this whole thing twice. But try to get it. You'll have two chances to get this. Try to get it. Try hard each time. So I've got send phi of z as a polynomial in z. Now, that's going to be enough for me to figure out what number phi of 0 and number phi of 1 is, because I plug it in for 0 and 1 for z. But now I can figure out what number phi of 2 is also, because I can plug 2 in for z or number phi of 7. I plug 7 in for z. So let's stop here and see are there other questions. So is the size of number phi-- I don't understand. This question about the size of no phi. Is it 2 to the m? No, it's not 2 to the m, because the degree of that polynomial, number phi of z, I mean, it's a very large
1391	expression if you want to initially-- yes, it's going to be an exponentially big sum. But the prover adds it all up for you, and you're just going to have at most a small number of coefficients, because the polynomial is only of a certain degree. And a polynomial in one variable of degree d has at most d or d plus 1 coefficients to worry about. So it's not that many coefficients as an expression. So shouldn't the summation take 2 to the m time? I'm not caring about the prover's time. The prover has a lot of work to do. But the prover sends phi of z. So yes, the prover has an exponential job. I don't care. The verifier needs to be able to check it in polynomial time. And that checking is going to, well, we'll have to see. How does the verifier know that that polynomial is right? That's a question maybe you should be asking. Yeah. I'm getting lots of questions about how much time the prover needs to take. Yeah, the prover is
1392	going to have to spend exponential time to figure out that polynomial. That's all right. We don't care about the prover's time. Yeah. So the summation here is going to be adding up polynomials. That is correct. I'm happy to spend time, because really here this is the whole proof. You have to understand. Well, we have to understand why this works. But we kind of understand half of it, because knowing that polynomial is enough to-- if you could certify that that was the correct polynomial for number phi of z, then we can use that polynomial to confirm the previous value, what number phi was, because you just plug in zeros and ones for z, and you add it up. But now how are we going to justify that the polynomial is correct? Because this looks like even a worse job. Now we have a whole bunch of coefficients and have to make sure all of those coefficients are right. And so instead of just two values, now we have d values where d is the degree of
1393	that polynomial, which could be at most the length of the formula. So here is the next idea. So the prover needs to show that phi of z is correct. The way it's going to do that, so even before we do that, so phi of z is going to be some polynomial. Now, the prover may be lying, may be sending the wrong polynomial. How does the prover convince the verifier that the polynomial is the right polynomial? Well, that seems like a tough job. So what it's going to do is remember that the-- so there is a correct polynomial that you would get by plugging in to this expression for the correct value. So there's some correct polynomial. The prover may be sending some incorrect polynomial. So now we have the correct polynomial and the possibly incorrect polynomial. And the point is those two can only agree in a small number of places by that fact we proved a couple of lectures back regarding polynomials. So two different polynomials can agree only rarely. So what we're going
1394	to do, the way the prover is going to justify that this polynomial was the correct one, is by evaluating it at a random place and then demonstrating that that value you get is a correct value. If the polynomial was the wrong polynomial, then evaluating it at a random place is probably going to disagree with the correct polynomial at that place, because they can only agree rarely. So the prover is going to demonstrate that by evaluating that polynomial at a random place, that value you get is going to be the correct value, and it's going to continue to do that in the way, using the same protocol, as we'll see. So that's where we're going. So in order to show that phi of z is correct, the verifier now gets to pick a random value in the field. And the prover is going to show that evaluating that polynomial at r1 is correct. Remember this looks a lot like what we had from before where we were showing that number phi of 0 is correct and
1395	number phi of 1 is correct. Now we're trying to show that number phi of r1, this random value from the field is correct. So the way we're going to do that is now by unpacking it one level down. And we're going to be using that identity, because this value here is going to be equal to number phi of r1 comma 0 plus number phi of r1 comma 1. But we don't want to send both of those. So we're going to send them combined into a polynomial of number phi of r1 of z as a polynomial in z. This is a new polynomial in z. So now if you understood the previous line, then hopefully this one won't be too hard to swallow. Because now we're going to check the identity, but here by evaluating the polynomial again but one level at the next level. So this is perhaps a good place to take questions, because this is the-- this is really what I spent all the time setting things up for so that you would
1396	be ready to get this thing hopefully without-- and hopefully be able to appreciate it and understand it. So I'm not getting questions. Let's move on a little further. So now again, the prover had sent this polynomial in stage two. Now the verifier needs to be sure that that polynomial is correct. So it's going to evaluate that new polynomial at a random location. So by picking a random value r2 in the field. And now we need to show that this value is correct, because if that polynomial had been the wrong polynomial, it disagreed with the correct polynomial almost everywhere. And by picking a random place, it's probably not going to be the right value and so on. Until we get to the end where we have almost all of the values have been picked, and so we have one last value to select a 0 and 1. This corresponds to the n-th. It would be great if I could put both pictures on your screen, but I can't. So this very much corresponds to what happened
1397	in the exponential protocol but just along sort of this arithmetization single path. So it checks that the previous value is correct in terms of expanding it with 0 and 1. But again, the 0 and 1 comes from evaluating the polynomial. And now the verifier needs to be convinced that that polynomial was right. So it picks a random value, but now it doesn't rely on the prover anymore. It's going to see whether that assignment that it gets by evaluating the polynomial with that random value rn plugged in is the same as what I get by evaluating the polynomial for the formula itself that the verifier can do directly. Because this is now a polynomial now just plugging into the formula and using the arithmetization to get a value out. So this was the last line of the identity. We had those two identities. So this is the second identity. And we had to check that this is correct. So I'm going to show this to you in a picture. Not sure it'll help if you're confused.
1398	But why don't we take some questions on this? So as I said, I'm going to give you two chances to understand this. Because I know it's tough. Especially with the constraints of Zoom, this is a particularly challenging idea to explain. OK, so let's see. So the benefit of this approach is that the prover only sends one item for each depth level instead of multiple items. That's right. But that one item is the polynomial. So that captures all of the values for the entire field. But taking advantage of the arithmetization, that one polynomial has a lot of information in it. And what's nice is that you can check that polynomial by just evaluating it at one random place. You can check that that polynomial is correct. So I'm getting another question here. Where does this come from here? V checks that this here. So this where does this-- so you have to look-- to understand where this is coming from, you have to-- we're at the n-th round now. So you have to look back like
1399	at round two. V has to check that phi of r1, which comes from the end of the first round. So this checks that this phi of r1 is correct because that was how we justified the polynomial with just a single variable. The very first polynomial was correct. A little hard to say. But this comes from the previous round, this guy here. So this is the polynomial for the current round. This is the value from the previous round. All right. More questions. So why doesn't this run in exponential time? Another question I'm getting. Doesn't V need to check twice at each layer? Yes. The verifier needs to check-- gets two values, but those two values come from the one polynomial. So there's no blow up anymore. Those two values. Maybe you'll see it in the picture that I'm going to show. So maybe just hold that question. Maybe this will become clearer in the diagram. So another question. Does this work because the polynomial kind of encodes all the possible values together? I think that's sort
1400	of true. It sort of mixes them all together into one object. Then you have to check that one object, which can be done with this sort of random probing of it. So this is another good question that we'll see explained in the next slide. So similarly in attempt one, the prover can keep lying by picking polynomials by continuing to pick polynomials, by lying about the polynomials. But eventually it's going to get caught, because this value is going to be the wrong value. If the polynomial in the previous stage and the m minus-- if a polynomial that the prover sent in the m stage is the wrong polynomial, then you evaluate it, you're going to get the wrong value probably. And so then that wrong value is not going to match the correct value, which is you can read off yourself by reading the formula. I think we need to move on to the next slide. All right. So same proof, version two, but looks different. Again, the input is that. Here is what the prover
1401	sends. Here is what the verifier sends. I'm going to sort of whimsically design this as a telephone chat where they're sending each other messages through messaging. So the prover sends the number phi to start off with. And then off on the side, these are the checks that the verifier is going to be doing. So here in our first round of the chat, the prover is going to send phi of z. Remember this is just a polynomial in not too many coefficients. So it's a polynomial in one variable. The degree is small. So there are not too many coefficients here. So this is just pretending this is what it might look like. So from that polynomial, the verifier can plug in 0 and 1 and see that that adds up. Now the verifier, to check that this polynomial is correct, it picks a random value to evaluate this polynomial on. And so now it's going to have to check that this is correct. So this is nothing to check. You're just writing this down in anticipation
1402	of the next check. Now, the prover to justify that this value is right, that this polynomial is right, so we evaluate-- the prover in order to check that this value is right is going to send the polynomial for the next level. Now, we can from that, we can plug in 0 and 1 for z. See if that adds up. And now to be sure that this polynomial is right, we evaluate it at a random place, calculate that value, and then have to see that this value is correct. So now we expand to one level further. We take a polynomial for the next variable. And we see that adds up. OK, I'm not sure whether this is helping or not. But we keep doing that until we get to the very last round with a prover sending a polynomial. Make sure that this adds up correctly. And the verifier to see that this polynomial is right picks a random value and evaluates it and now checks that this agrees with the formula. Because we've now assigned
1403	all of the variables. And then we can check this number phi directly in terms of the phi, because they have to agree. And so the verifier would accept if everything checks out. Let's see what happens. So this answer will answer some questions. Why don't I walk through what happens if the input was wrong. And we'll see how the verifier is likely to catch the prover but not guaranteed to catch the prover in this case. So if k was correct, the verifier will accept with the honest prover. But if k was wrong, so I'm going to, again, indicate the wrong values in red. I want to show you that the verifier is almost certainly going to accept but not guaranteed. So did I say that wrong? So if k is wrong, the verifier is going to probably reject, but it's not guaranteed to reject. So first of all, if the prover does not lie, does not send the wrong value for number phi, The verifier is certainly going to reject, because it's not going to get
1404	any quality there. So the prover has to lie. Say if k was 99 but the real value was 100, the prover if it says 100, the verifier's going to reject immediately. So the prover's going to say, well, let's see what the prover can do to make the verifier hopefully accept from the prover's standpoint. So the prover is going to send 99. Well, the verifier says, OK, 99, fine. Convince me. So the prover-- now one of these two is going to be wrong. Because the two correct values can't add up to the wrong value. So one of these is wrong. So that means the prover had to send the wrong polynomial. Because the correct polynomial would evaluate the correct answers here. So the prover had to send the wrong polynomial. So now when we evaluate it at a random place, chances are this is going to be the wrong-- this is not going to be the same value that the correct polynomial would have given you. The prover could get lucky. The verifier might have just
1405	happened to pick a place where the correct polynomial and the incorrect polynomial agree. In that place, the prover will think, huh, I'm saved. Now I can act like the honest prover from this point on and the verifier will never catch me. It's sort of a little bit analogous to the situation maybe-- I'm trying to see if you really studied the whole course. So I'm giving you an exam by picking sort of random places there. But maybe you just studied a few facts from the course. You might get lucky. I might happen to ask just about those facts. And then you give the appearance of having studied everything, but you really didn't. So here the prover might send the wrong polynomial, but the verifier just queries that at the place where it happens to agree with the correct polynomial, and the prover just gets lucky. And the verifier is going to accept, in that case. But there are very few of those. So that's why the prover is almost certainly to be caught if it tries
1406	to lie. But not guaranteed. So just tracing this down. If this was a lie, then one of those two has to be a lie. So therefore, the next polynomial has to be a lie. And so we continue. So then the next value is almost certainly going to be a lie. Not guaranteed. And so then one of those two values has to be a lie. At least one has to be a lie. Therefore, the polynomial has to be a lie and so on until-- unless the prover got lucky along the way somewhere, which is very unlikely, even though it has a several opportunities. We've arranged it so that the chance of getting lucky is tiny at each stage. So even though he has a few chances, there's still going to be a tiny chance that you're going to get lucky somewhere. And so this is wrong, then chances are that's wrong. And so therefore, this is going to be a disagreement. And the verifier at that point when it doesn't agree is going to reject. Unless
1407	the prover got lucky somewhere along the way, which is unlikely. So I don't know if you had-- so that's all I was going to say about this proof. I don't know if you had any questions on it, but let's just see. OK. So do we have any questions I can answer? How the prover gets-- how does a prover get number-- how does the prover get number phi of z? So you have to-- why is number phi of z have no other variables? You have to go back and look at the definition of number phi of a. Because you add up over all the other variables. So now instead of a, we're plugging a variable for that. But you're still adding up over the other variables. So this is a function in just one variable, because it-- the original thing was a polynomial. This is also going to be polynomial. I think we're starting to run low on time. So this is our very last check in for the semester here. So of course there's one
1408	natural question to ask you all. And for our very last check in, as we're in our last couple of minutes of the course or at least the lectures, does P equal NP? What do you think? Will maybe PB equal NPB solved by a deep learning algorithm? Or maybe we'll never prove it. Give me your best guess. We're kind of running out of time. So let's not think too hard here. Another five seconds. All right. Ending polling. I'll share that with you. Oh, I did share. So what did we get? D here. We will prove it in somewhere between 20 and 100 years from now. That seems to be the majority opinion. I don't know. I hope it'll be sooner than that, because I'd like to see the answer. But we don't know. Yeah, if you can prove P different from NP, I'll give you an A+. You won't have to take the final. But you better be sure you're right. All right. So that is our quick review. We finished number set in IP and
1409	therefore that coNP is a subset of IP. If you're interested in further pursuit of this material, I got a couple of questions on that. These are some courses you may want to look at. I know I checked with Ryan Williams. He's planning to teach Advanced Complexity fall 2021. So that's going to be the most natural follow-on subject to this one. There's the crypto classes also are kind of make use of some of the same ideas. And there's, of course, also randomness computation that Ronitt Rubinfeld teaches. If I didn't check with her. I'm not sure the next time she's going to be teaching that. And good luck on the final and best wishes. And I'm going to have office hours. So if you have any questions, happy to answer those. But otherwise, see you all. Good luck. Thank you for the comments. Yeah, I enjoyed having you all as students. It was a fun time. A lot of work, but it was a fun time. I've always been intrigued by the P versus NP problem, and
1410	I proved a kind of a-- I proved the exponential complexity of computing the parity function in a certain weak model of computation. So parity function is obviously very trivial function. But for the parity function, if you can't count, whatever that means, but there is a model you can kind of set up where you can't count. Then parity requires exponential complexity. And surprisingly, not easy to prove. But that's probably the theorem that I'm most known for. Anyway. But that would be a topic for another day. Another question. Why not include Myhill-Nerode theorem. I don't know. That's a theorem about finite automata and all of those ways of characterizing the regular languages. That seems kind of a technical theorem. I don't see much point in covering it. And another question that some of my colleagues ask me is why don't I have Rice's theorem, which sort of provides a kind of a machine for proving undecidability. And I don't know. I think that you can use Rice's theorem without understanding how to prove undecidability. It's like checking
1411	off a box. Checking some boxes and then you conclude something's undecided. I'd rather have somebody understand it rather than be able to use some powerful tool. Can we understand that proof about the parity function that I just alluded to? It's super hard. With the knowledge from this class, I think you can. That theorem relies on a certain technique which we didn't cover called the probabilistic method, which is a kind of an amazing method. Not hard to explain, but basically you show that something exists by showing that the probability that a random object has the property you're looking for is more than 0. And so therefore, the thing that you're looking for that has that property has to exist. There are lots of examples of that these days. But it's kind of an amazing method. So we use that method. Do I think quantum computing can solve useful problems beyond the capability of computers? I have no idea whether one can really build a quantum computer. It seems to be always 20 years off at least
1412	to doing one that factors. And I've been literally I remember people 20 years ago saying it's 20 years off. So I don't think it's converging. I'm skeptical that they'll ever build a quantum computer that can factor. I'll go out on a limb and say that. But that's controversial. And whether it can solve other useful problems, I'm not sure what other useful problems are there. Well, I guess they're simulating quantum systems. So maybe that might be possible. All right. I think I'm going to end this now. But thank you, everybody. Take care. Bye bye.
1413	[SQUEAKING] [RUSTLING] [CLICKING] PROFESSOR: All righty, why don't we get started. So welcome back. Nice to see you all. And what have we been doing in theory of computation? We have been talking about Turing machines and about the power of Turing machines. We started at the beginning by showing a bunch of decidability theorems that exhibit the power of Turing machines to calculate properties of finite automata, context free grammars, and so on in some cases. And last lecture, we talked about the limitations of the power of Turing machines by proving undecidability theorems. So we showed that this language A TM, the acceptance problem for Turing machines itself is an undecidable problem. That was the first of many undecidable problems that we're going to encounter. And though we proved the undecidability of A TM using the diagonalization method as hopefully you remember, we're going to introduce a new method which
1414	called the reducibility method, which is the way other problems are typically shown to be undecidable. And so we're going to stick with that for this lecture and also next lecture. We're going to be talking about undecidability. And I think there's going to be a few additional discussions after that. But this is one of the important themes of the course is to understand that threshold between decidability and undecidability, or the limitations of computation, OK. So today, as I mentioned, we're going to talk about the reducibility method for proving problems undecidable and also for proving problems non-turing recognizable, Turing unrecognizable. We're going to introduce this notion of a reducibility in general. And we'll also talk about a very specific kind of reducibility called the mapping reducibility. So today as promised, we're going to talk about using reducibilities to prove problems are undecidable, or unrecognizable. So that's going to be our general method, oops, make myself smaller, thank you. I always forget. Thank you for the reminder. So using reducibilities to prove problems are undecidable, or unrecognizable, and
1415	the basic way that works is we're going to leverage another some problem we already know is undecidable say, or unrecognizable to prove other problems are unrecognizable. So we did a quick example of that last time. We're going to go over that example again just to set the stage. And then we're going to talk about that in greater detail. So as you recall from last time, we had this problem HALT TM, which is the problem of testing for a given Turing machine and an input to that Turing machine, whether the Turing machine halts, either accepting or rejecting, but just whether it halts. Which is a somewhat different problem, closely related obviously, but somewhat different than the A TM problem, which is just testing whether the Turing machine accepts. We already showed that A TM is undecidable. Now, conceivably, HALT TM might be decidable. You know, it's not exactly the same problem. But we're going to show that HALT TM is likewise undecidable. We did this last time, but I'm just going over it again. I'm going
1416	to likewise show that HALT TM is undecidable. We could go back to the diagonalization method and do it from scratch. But generally, that's not what's done. Generally what people do is they use a reducibility from a known undecidable problem. And so what we're going to show is a proof by contradiction which says that if HALT TM were decidable, then A TM would also be decidable. And we know it isn't. And that's by virtue of what we call a reducibility from A TM to HALT TM. And I'll explain with the terminology. And we'll have a chance to play with the concept all lecture long. So we're going to see all sorts of different variations. So as I said, we'll assume HALT TM is decidable and use that to show that A TM is decidable, which we know is not true. So quickly going through it because we did it already once before, we're going to assume that HALT TM is decidable. Let's say Turing machine R is the decider. And now we're going to show that
1417	ATM is decidable by constructing a Turing machine S, which uses R to decide A TM. That's going to be our contradiction. So here is the machine S. You have to keep in mind what the goal of S is. We're going to design S to solve A TM, which we know is not decidable. So don't get confused by that. We're aiming for a contradiction. So we're going to use S as typically-- well, there might be other variations. But for now, S is going to be used to decide A TM. So we can try to figure out, how can we decide A TM. And the way we're going to do it is use our HALT TM tester that we assumed to have. And we'll first take our M and w, where we're trying to determine, does M accept w? And we'll first test whether M halts on w. If it doesn't, we're done. Because it couldn't be accepting w, M couldn't be accepting w if it's not even just halting on w. So if R reports doesn't
1418	hold, we can reject right off. But even if R says it does halt, we're still in good shape because now we can run M on w until completion because R has promised us that it's going to halt. R is stated. And R is assumed to be correct. R is stated that M halts on w, so now we don't have to worry about getting into a loop, which we're not allowed to do since we're making a decider. We're trying to decide A TM here. But now we can run them on w to completion. We can find out what M does on w. And then we can act accordingly. So we're using the HALT TM decider to decide A TM. That's the name of the game here, OK? And that's a contradiction. And so therefore our assumption that HALT TM was decidable had to be false. So it's undecidable. OK? Important to understand this because this is sort of the prototype for all of the other undecidability proofs that we're going to do going forward. OK, so
1419	we can just take a few seconds here. If there's something that you're not getting about this, it's a good time to ask. Not seeing many messages here, or any, so why don't we go on? But if you ask, I can get to it next slide too, all right. Here we go. So here's the concept of reducibility. And I know, I've taught this course, many times. I know where the bumpy places are in terms of people struggling with material. The concept of reducibility is a bit tricky. So don't feel bad if you don't get it right away. You know, so that's why I'm going to try to go slowly in this lecture to make sure we're all together on understanding
1420	OK, so the concept of reducibility is that we say one problem is reducible to another, say A reducible to B. It means that you can use B to solve A. That's what it means for A to be reducible to B. OK, so I'm going to give a bunch of sort of informal examples of that, or easy examples of that. And then we'll start to use it for real. So example 1, this is sort of really outside material from the course. But I think it's something you can appreciate. You know, everybody knows you can measure the area of a rectangle by measuring the lengths of the two sides, measuring the length and width of the rectangle. So in other words, if you had the problem of determining the area, you could reduce that problem to the problem of measuring the length and width of the rectangle. So here, we're taking one problem and reducing it to another problem. You know, it's conceivable that measuring the length and width is easier than it would be to measure
1421	the area directly by somehow covering the space with tiles, is one way of measuring it. But it tells you, you don't have to do that. The problem of measuring the area is easier than covering with tiles. You can just measure the length and width and you're done. So reducibility is a way of making problems easier by translating them into some easier problem. So here's another example that we've already seen. We didn't call it a reducibility. But if you remember back a couple of weeks ago, we were talking about the languages A NFA, and A DFA, the acceptance problems for NFAs and DFAs. And we gave a way of solving the A DFA problem. As you remember, the Turing machine simulated the finite automaton. And we solved the NFA problem not by doing it directly but by converting the NFA to a DFA and then using the solution for A DFA. In effect, what we were doing was we were reducing the A NFA problem to the A DFA problem. So let's do another example. Here's
1422	a problem. Here's an example that you again, probably didn't think about it this way.
1423	the problem of determining whether a pushdown automaton ever pushes on its stack for any input. I know a bunch of you were struggling with that problem working on it, hopefully solving it in one way or another. So there's one way to solve it is in effect by reducing the pusher problem to the E CFG the emptiness for CFG which is the equivalent to the emptiness for PDAs. I mean, this is the solution I had in mind, which is a particularly simple and short solution. Of course, not the only solution. You can take your pushdown automaton where you're trying to determine if it ever pushes. And you can take the states that are about to make a push. And instead of making them make a push, you make them accept states. And you get rid of the original accept states. So now you've converted this automaton to one that accepts every time the original push on automaton pushes. And it accepts, and then has to move to the end of the input, of course. So it
1424	goes into an accept state and moves to the end of the input. So every time the original machine was about to push, the new machine that you're just creating here is going to go into an accept state at the end of the input. Now to test whether the original machine ever uses stack, it's enough to test whether the new machine ever accepts an S string. OK, so that's a way. I don't want to overcomplicate this right here and get you thinking about the homework again. But this is a way of reducing one problem to another problem. And if you don't quite get this one, just focus on the other two examples. I don't want to spend time on the homework set 2 right now. So we can address that all separately if you want. It's also the solution that's written up in the solution set that's posted on the home page by the way. OK, so getting back to let's see, thinking about reducibility. What I have in mind, again, this is sort of rephrasing
1425	it, but I'm trying to hammer it in that if A is reducible to B, then solving B gives a solution to A. Because that's what happens in each of these examples. Now, how are we going to use that? We're going to use that in the following two ways. One is to observe that, if A is reducible to B and B is an easy problem, then A must also be easy because we have a way of converting A problems into B problems. We have a way of solving A using B. So B is easy. Then now you can solve A too easily. Because you can solve A using B, which is easy. Maybe that's clearest up here in example 1, where measuring the area might seem at first glance hard. You could have to walk out over the whole area. But it's not hard because you only have to measure the length and the width. So the fact that B is easy tells you that A is easy. But actually, this is not the way we're
1426	going to be using it most typically. We're going to be most typically using it in the second version, which is a little bit more convoluted. But this is the way you're going to have to get used to this. So if A is reducible to B, and you know A is hard, undecidable, unrecognizable, whatever the form of hard you care about, if you know A is hard, and A is reducible to B, then that tells you B also has to be hard. Why? Because if B were easy, then A would be easy. But we're assuming that A is hard. So B also has to be hard. OK, so I'm inverting the logic here. But this is logically equivalent. So you have to mull that over a bit. So why don't you think about that. And let me just take a few questions on the chat and don't forget the TAs are there too. So they're happy to answer your questions. Don't make them sit there lonely, all right. So somebody is asking, is it possible that
1427	A is reducible to B and that B is also reducible to A? So that's a good question. That can certainly happen. In that case in a certain sense, A and B are going to be equivalent. So solving 1 is going to be just as easy or hard as solving the other one, OK? So they're going to be equivalent from the perspective of the difficulty of solving them. So somebody is asking-- and this is a perennial confusion-- so in the previous slide here, I think I'll just flip back to it here. So which direction are we doing? Are we reducing A TM to HALT TM or HALT TM to A TM? The way it's written on the slide is what I have in mind. Here we're reducing A TM to HALT TM because we're using HALT TM to solve A TM. And that's reducing A TM to HALT TM. Just like here, measuring the area is reducible to measuring the lengths of the sides, we're using measuring the length of the sides to solve the area.
1428	So we're reducing the area to the lengths, the area to the length of the sides. But I know you're going to have to play with it, digest it, get used to it. All right, OK, so let's continue. OK, so as I said, this latter one because the focus on this course is mainly on the limitations of computation. So we're going to be looking at ways of showing problems or difficulty. It could be difficult in principle, like undecidable. Or it could be difficult in terms of complexity, which is what we're going to focus on in the second half.
1429	the concept of reducibility. So reducibility is going to be a theme. You've got to get comfortable with reducibility, OK. So we're going to be focusing more on the notion that if you reduce A to B, and you know A is hard, that tells you B is also hard. OK, so I'm going to say that a few times during the course of today's lecture to try to help you get it. All right, here's a check in. A little bit sort of off to the side. But I thought it was a fun check in more. The question is, some people say biology is reducible to physics. Well, maybe everything is reducible to physics since physics tells you about the laws of the universe. And biology is part of the universe. So my question to you is, do you think? And there's no right answer here.
1430	biology reducible to physics? Maybe yes, or maybe there are some things like consciousness which cannot be reduced to physics. Or maybe we don't know. So I'm curious to know your thoughts. But it does kind of use in a sense the notion of reducible in the spirit of what I have in mind here. In the sense that if you could fully understand physics, would that allow you to fully understand biology? OK, here we are. We're almost-- kind of interesting, though not too unexpected I suppose. So we are, I think, just about done. 5 seconds, pick anything if you want to get credit for this and you haven't selected yet. Ready to go, ending polling. Here are the results. And as I say, there's no right answer here. But if I had been in the class, I would have picked B. But I'm not surprised, especially in an MIT crowd that A is the winner, all right. Let's continue. OK, so now we're going to use reducibility again. This is going to be yet another example like
1431	the HALT TM example, but a little bit harder. And we're going to be doing this. You know, next lecture, we're going to be doing more reducibilities but much harder. So we really got to get really comfortable, all right.
1432	So E TM is the emptiness problem for Turing machines. Is this language empty? I'm just going to give you a machine. I want to know, is this language empty or not? Does it accept something or is this language empty? That's going to be undecidable, no surprise, proof by contradiction. And we're going to show that A TM is reducible to E TM. So these things often take a very similar form. And I'm going to try to use the same form. So if you're feeling shaky on it, at least you'll get the form of the way the solution goes and that will help you maybe plug-in to solve problems, OK.
1433	that E TM is decidable, opposite of what we've been trying to show. And then show that A TM is decidable, which you know is false. So we'll say we have a decider for A TM, R, using the same letters on purpose here just to try to get the pattern for you, so R deciding E TM. Construct S deciding A TM, OK. So now, let's think about it together for a minute before I just put it up there. So S, I'm trying to make a decider for A TM, using my decider for the emptiness problem, OK? So we have R, which can tell us whether M's language is empty. So why don't we just, I don't know, stick M into that emptiness tester and see what it says? I'm not saying this is the solution, but this is how one might think about coming up with the solution. So are you with me? We're going to take M, we have an emptiness tester. Let's take M and plug it into R, see what R says. R
1434	is going to come back and tell us whether M's language is empty or not. Now, one of those answers will make us happy. Why? Suppose R tells us that M's language is empty. Why is that good? With that, we're done. Because S is trying to figure out, we're trying to figure out exactly, somebody told me the answer which is correct. Because now we can reject. If M's language is empty, it's clearly not accepting w because it's not accepting anything. So if R says M's language is empty, then we're good. The only problem is we also say M's language is not empty. And then what do we know? Well, not much, not much that's useful for testing whether M accepts w. We just know M accepts something. But that something may or may not be w. OK, so what do we do? Well, the problem is that M is possibly accepting all sorts of strings besides w, which are kind of mucking up the works. They're interfering with the solution that we like. We'd like to
1435	be able to use R on M to tell us whether M is accepting w. But M is accepting other things. And that's making the picture complicated. So what I propose we do, why don't we modify M so that it never accepts anything besides w? The very first thing M does in the modified form is it looks at its input and sees whether it's different from w. If it's different from w, it immediately rejects.
1436	and we feed it into the emptiness tester. Now the emptiness tester is going to give us the information we're looking for because if the emptiness tester says the modified machines language is empty, well, we know that M is not accepting w because we haven't changed how M behaves when it's given w. But if R says M's language is not empty, well, then it must be that M is accepting w. Because we've already filtered out all of the other possibilities when we've modified the machine. So let me repeat that on the slide and write it down a little bit more formally. So what I'm going to do is I'm going to transform M to a new Turing machine. I'm going to call it M sub w to emphasize the fact that this new machine depends on W. It's going to actually have w built into as part of the rules of the machine. So for a different w, we're going to end up with a different machine here. So this is a machine whose structure is
1437	going to depend on knowing w. And that machine is going to be very much like the original machine M, except that when it gets an input, let's say it's called X now, that machine is going to compare X with w and reject if it's not equal. Otherwise, if X is equal to w, it's going to run M on w as before. So it's not going to change the behavior when the input is w. It's only going to change the behavior when the input is something different than w, and then it's going to reject, all right. So I'm going to look at two aspects of this. First, let's understand the language of this new machine. And then we'll also talk about how we go about doing this transformation. So first of all, just for emphasis, so Mw works just like M. It has all the rules of M in it, except some extra rules. It always at the very first step, it tests whether X is equal to w or not. And if it's not equal
1438	to, it rejects. Not equal to, reject. So the language of that new machine is either going to be just the string w when M accepts w because everything else is filtered out. Or the empty set if M rejects something. So it's important that you understand the behavior, at least, of this new machine. It's just like M except filtering out all of the inputs which are not w. Those are going to be automatically rejected. So it's also important that S be able to make this transformation. But I claim that you'll have to accept this if you don't totally see it. But the transformation is simply taking M and adding some new rules, some new transitions and states so that the very first thing that M sub w does is it just has a sequence of moves where it's checking that the input string is equal to w or not. And if it's not equal to w, it just rejects. So it's easy to modify M. You could easily write a program which would modify the states
1439	and transitions of M to make it do that test at the beginning. So I'm not going to elaborate on those kinds of things in the future. But just for the very first time, I just want to make sure you understand that we're not doing anything fishy here. This is a completely legitimate thing for S to be able to do. So S can modify M to this new machine Mw, which filters that new machine, filters out all strings except for w and rejects them. So S takes that new machine, and what is it going to do with it? Is it ever going to run that machine? No. This machine is built not for running. This machine is built for feeding into R. Because as you remember, feeding M into R had the problem that M might accept things besides w. And that confuses the result that we get from R in the sense that it's not useful. But if we feed Mw into R, now we're good because if the information about whether Mw's language is
1440	empty from over here tells us whether or not M accepts w. If Mw's language is not empty, then M accepts w. If M's language is empty, M rejects w. OK, so starting to get some good questions here. Let me just finish the description of S. So somebody is asking here. So this is an excellent question.
1441	How do we know that Mw halts on w, or whatever? We don't. Mw may not halt on w. We don't care. We're never going to run Mw on anything. We're going to take Mw as a machine, and we're going to feed it into R as a description. We are going to take the description of Mw and feed it into R. Then it's R's problem. But R has been assumed to answer emptiness testing. So we just took the original machine, modified it so that the only possible thing it could accept is w. And now feed it into the emptiness tester to see whether its language is empty or not. Now if its language is not empty, it has to be accepting w because it's built not to accept anything else. So we don't care whether Mw might end up looping. We're never going to run Mw. I acknowledge, it's a leap for many of you. So you're going to have to mull it over. So we're going to use R to test whether Mw's language is
1442	empty. If yes, that means that M rejects w. So then we're going to reject, if we know that Mw's language is empty, that must have been that M rejected w. So now as an A TM decider, which is what S is, S is supposed to reject, which is what we have here in the description. And if no, that means the language is not empty. So M accepts w, and so therefore we're accepting. So there's a little bit of a twist here also. OK, so let's take some more. I'm expecting some questions here.
1443	determine if the language is decidable? I mean, that's what we're doing. You can show a language is decidable by exhibiting a Turing machine which decides it. And you can show a language is not decidable, which is what we're doing here by proving that it's not possible for a Turing machine to decide it. You know, we did that first with A TM. We got that contradiction by diagonalization. And here we're doing a reducibility to show as the method of proof, all right. Let's continue. So now we're going to talk about a special kind. So far we talked about reducibility. We didn't define it in a precise way because there are several different ways to get at the notion of reducibility precisely. And I'm going to introduce a one version, which is a little bit more restrictive. I mean, somewhat more restrictive and a little bit different way of looking at it than we have been doing so far. But there were going to be some benefits to looking at this particular kind of reducibility, which we're
1444	calling mapping reducibility. It's going to have several benefits for us immediately and down the road. But this is also a little technical so don't get scared off. It might look complicated at first. But we'll try to unpack it for you, OK. So first of all, we have to first of all talk about the notion of a computable function. So generally when we've had Turing machines, they're doing yes, no. They're doing accept, reject kinds of things. So it's like a function, just sort of a computing, sort of a binary function. For here, we're going to want to talk about Turing machines that are computing a function which converts one string to another string. So it's mapping from strings to strings. And it could be like the function which reverses the string, for example. That's one possible function you could be having here. But there's of course zillions of possible functions here. And we're going to talk about functions that you can compute with the Turing machine. And that basically means you provide the input to the
1445	function as input to the Turing machine. And the output of the function, the value of the function comes out as the output of the Turing machine, which let's just say it leaves that value on its tape when it halts. It halts with the value of the function on the tape. But just, we're thinking about algorithms here. Come up with your favorite method of thinking about algorithms. It has an input and an output. And the algorithm just computes the function by taking as input w, and the output is f of w. It doesn't have to be a Turing machine. Just any algorithm that can compute something is good enough. They are all equivalent. And now we're going to use this notion of a function that you can compute to define a kind of reducibility called mapping reducibility. I'm going to say that A is mapping reducible to B, written with this less than or equal to sub M symbol. And you're going to see that a lot. It's on the homework also by the way. If
1446	there is some computable function as I just described, where whenever w is in A, f of w is in B. And the way to think about it is with this picture. So A and B are languages, written like, here's A and here's B. And now there are strings. So w might be in A. It might be out of A. And you think of you're trying to solve A. You're trying to decide membership in A. So you want to test whether w is in A or not. A mapping reducible is a function which maps things from this space over to that space in a way that strings that are in A get mapped to strings that are in B. So if you start out with w in A, f of w is in B. And if w is not in A, then f of w is not in B. Pictorially it's a simple idea. We'll have to make sure we understand why this fits with our concept of reducibility. But we'll do that. But anyway, let's
1447	first understand just what we're doing here. We're just coming up with a function that can do this kind of a mapping. It sort of translates problems which inputs which may or may not be in A into other strings which may or may not be in B. But sort of maintaining the same membership property. So if you start out with something in A, when you apply f, you're going to end up with something in B. And conversely, if you're not in A, then you won't be in B, OK? Somebody is asking, so just a couple of questions here. Not necessarily 1-to-1? No, so the function doesn't have to be 1-to-1. There could be multiple things that map to the same point.
1448	And is there any restriction on the alphabet? No. So before we actually get into the example, let me try to give you a sense about why we call this a reducibility. And the reason is, suppose we have such an f which can do the mapping as I described. And we also have a way of deciding membership in B. So B is decidable. So that's going to tell us right away that A is decidable. Because if you have some input, and you want to know, is it an A or not, you can now apply f and test whether f of w is in B. So the test of w is in A, you're going to instead test whether f of w is in B. And we're assuming that shows that A is reducible to B. So if you could solve the B problem, that also gives you a way to solve the A problem. So again, we're going to say this several times in several different ways. So if you didn't quite get it yet, don't
1449	panic. So here is going to be an example. Sort of building on what we just showed last time in the previous slide, A TM, we're going to show how A TM is actually mapping reducible to the complement of E TM. And the complement is necessary here. The computable function that we're going to give, which is basically, the computable function is going to translate problems about A TM to problems about E TM because we're mapping reducing A TM to the complement of E TM. So what we're doing here is with mapping M and w to the machine Mw. Kind of in a way, we're boiling out the essence, boiling down to the essence of the proof that we gave in the previous slide. This is really the core of the proof. This translation of Mw where you want to know, is M accepting w to a new machine Mw where you're testing whether Mw's language is empty. And so remember Mw from before. It's the machine that filters out all the non-w's and rejects them. And
1450	the reason why this reduction function works is that Mw is in A TM, if and only if M sub w is in the complement of A TM. So M accepts w exactly when Mw's language is not empty, OK? So M accepts w if and only if the language of Mw is not empty. So you have to mull this over a bit to realize it's-- I know this can be a little tricky. But I think what we're going to do here, I think we're at the time for the break. So oh, no, there's one more slide. I apologize. So let's talk about this and then we're going to have our coffee break. So these properties are really going to be getting at what makes mapping reducibility fit with our understanding of what a reducibility should be. So if A is mapping reducible to B, and B is decidable, then so is A. So that fits with what we want. Because if A is reducible to B, and B is easy, then A is easy.
1451	And here is the proof. Let's take a Turing machine that decides B and construct a Turing machine that decides A as claimed, S operates like this. It takes its input, computes f of that input, tests whether f of w is in B using the R machine that we were assuming. We have R deciding B. And if R halts then output the same result. So if R accepts, we're going to accept. If R halts and rejects, we'll reject. And of course we're going to be similarly running R. So if R is not going to be halting, we are not going to end up halting either.
1452	So the corollary is, and this is the way we're going to be using it, if A is reducible to B and A is undecidable, then so is B. So this is as I mentioned, the focus for us is going to be on undecidability. And you may want to think about A is like the A TM problem which we know is undecidable. We're going to show the A TM is mapping reducible to some other problem to show that other problem is undecidable. And the important thing about mapping reducibility is that it also applies to recognizes. So if A is mapping reducible to B, and B is Turing recognizable, then so is A. So if you're reducing A to a recognizable problem, then A is also recognizable, same proof. Because you can just map your w to f of w and feed it into the recognizer. That's going to give you a recognizer for the original language. And the corollary is that if A is mapping reducible to B, and A is unrecognizable, then so is B.
1453	So this is again that inverted logic. So now I think we're-- oops, I meant to put this picture up earlier. OK, so here's a check in. It will be more of a check in for me to see how well you're following me. So these are some properties-- so I'll give you a minute here to think
1454	Suppose A is mapping reducible to B, what can we conclude? Does that mean that we can flip it around? If A is mapping reducible to B, does that mean that B is mapping reducible to A? What about this one? If A is mapping reducible to B, is the complement of A mapping reducible to the complement of B, or maybe neither? So you can check all that apply, multiple choice, 5 seconds. Sorry to pressure you, but we have to move on here. Pick anything. If you don't know, OK, 1, 2, 3, the end, OK. Well, the majority is correct. In fact, it's only B. Now, A really is not in the spirit of reducibility. Because as suggested even by the inequality sign there, A being reducible to B is really a rather different thing than B being reducible to A. So that's something. We're not going to prove that right here. But that's something that you could think about. But part B, I think, if you just look here at the definition of mapping reducibility, it
1455	maps strings in to in and out to out. Well, that's just going to be if you exchange in and out as you do when you're flipping compliments on both sides, it's still by the same f going to still work as a mapping reduction, OK? So now we're at our coffee break. So we're going to take five minutes here, and I'll be happy to take questions here. Don't forget the TAs. They're here to. OK. OK, so this is a fair question here. You know, so we had this notion of a general reduction and a mapping reduction. They are not the same. So any time you have a mapping reduction, it's going to be an example of a general reduction, but not the other way around. So if you go back and look at the reduction that we offered for HALT TM where we showed A TM is reducible to HALT TM where we started, it's actually not a mapping reduction because we're doing something more complicated than translating an A TM problem to a HALT TM.
1456	We're kind of using the HALT TM decider in a more complicated way. And there are cases where that's actually necessary. So we're not going to discuss that here. But it's actually kind of an interesting homework problem perhaps, or some kind of a problem to think about. So Turing machines for f's, it's not really a decider, but it has to be-- well, I guess it does have to be a decider in a way. It's always halts. The Turing machines for f has to always halt. It always has to have an output. So f for the computing the function always has to halt. So someone is asking me, can I explain the statement that if error halts, then output the same result? I just mean that in that previous slide, or two slides back, if R accepts, halts and accepts, then we're going to halt and accept. And if R halts and rejects, then we halt and reject. So I don't know if this is a good idea, but we can just pull that back here. So
1457	that was the statement here. If our halts and output the same result, I just mean that S is going to do the same. You know, we're translating an A problem to a B problem, and then answering the B problem. And we're going to give the same value, the same answer there. So whatever R says, we're going to say too, if that's helpful, all right. Boy, this is a good question here. If A is reducible to B, why can't we just get B reducible to A by inverting the function? That's a great question. I like that question. The reason is because the function that's mapping onto B doesn't have to be onto, subjective I guess. So if it was onto, so if it covered all of B, then I think then you would get an invertible function. And you would get the reduction going the other way as well. But though, I'm not sure what happens when you have. It doesn't matter if you have collisions. It turns out that's not going to matter. But anyway,
1458	let's not get it too complicated here. But the problem with inverting it is that it's not necessarily onto the whole range of B. So we're kind of out of time here. Is A reducible to A compliment? Let me just handle that. No, not necessarily. It's reducible. A is reducible to A complement, but not mapping reducible to A compliment. But A is general reducible to A compliment. So actually we'll talk. I have a slide on that. So let us move on, OK?
1459	versus general reducibility. So we're going to contrast it to a bit. So mapping reducibility, which is what we've just been talking about has this picture, which is, I think, a very useful picture to remember. And because I like to think of a mapping reduction as a problem translator. Your problem is sort of in the A domain. And the mapping reduction allows you to translate that problem into the B domain. OK, and then if you have a way of solving it in the B domain, combining that with the reduction, you get a solution to the problem in the A domain. So that's why if A is mapping reducible to B, and B is solvable, then A is also solvable. So mapping reduction is a special kind of reducibility, as opposed to the general notion in general reducibility where we started. And it's particularly useful to prove Turing unrecognizability. So when you want to prove Turing unrecognizability, as we'll see, general reducibility is not fine enough in a way, it doesn't sort of differentiate things as well
1460	as mapping reducibility does. And for that reason, it's not always going to be useful to prove Turing unrecognizability. It's better for proving undecidability.
1461	or general reducibility is where we just use a solvent for B to solve A in sort of a most general possible way. So I'm writing that as a picture here. If you want to solve A, you're going to use the B solver as a subroutine to solve A. That's the way we did the HALT TM reduction at the beginning. But we didn't necessarily translate an A TM problem to a HALT TM problem. It's slightly different. So you can go back and look at that. So I find that people struggle more with the mapping reducibility concept. And that the general reducibility is what people naturally gravitate towards. And so in some sense, it's conceptually simpler. And it's useful to proving undecidability. But you really have to be comfortable with both. And especially in the complexity part, we're going to be focusing on mapping reducibility. So one noteworthy difference here as sort of foreshadowed by the person who made this question, which is a good question, is that A is reducible using a general reduction to A
1462	compliment, which kind of makes sense. I mean, if I can test whether things are in A compliment, well, I can test whether things are in A. You just invert the answer. But A may not be mapping reducible to A compliment because there is a very special kind of reduction. And you have to just translate things in the language to things in the language, and things out of the language to things out of the language. And they don't necessarily allow you to do that inversion. So for example, A TM complement is not mapping reducible to A TM. Because as we pointed out, anything that's reducible to a recognizable language is going to be recognizable. Anything mapping reducible to a recognizable language is going to be recognizable. But we know that A TM complement is not recognizable. We showed that before. So it couldn't be mapping reducible to A TM. It's coming a little fast I realize. You're going to have to digest it. So here's the last check in for today. OK, we showed that if
1463	A is mapping reducible to B, and B is Turing recognizable, then so is A. And so let's just say that again carefully. If A is mapping reducible to B, and B is Turing recognizable, then so is A. And here are the emphasis on Turing recognizable as opposed to decidable. Is the same true if we use general reducibility instead of mapping reducibility? So you got it? So we're saying A is mapping reducible to B using this picture over here. And we're going to assume that B is Turing recognizable, so that we have a machine which halts an accepts when you're inside B, and you know, is going to reject possibly a looping when you're not inside B. Now, that allows you to get a recognizer for A if you have a mapping reduction. Does it always work to give you a recognizer if you have just a general reduction? If you just have now, assuming you have a B solver, and you're going to build an A solver out of that. OK, so mull that over
1464	while I'm setting this thing up. Well, the right answer is winning, but not by much. I suppose I shouldn't be laughing about it. But I knew that this is going to be challenging. So I think it's the kind of thing you're going to have to work at. So let's see we're almost done here, 5 seconds to go. Better answer that, I can see a few of you, either you've left the room, or you're-- OK, 2 seconds, 1, 2, 3. Somebody hasn't answered it. There we go. So the correct answer is B. It's not the same. The reason is that in general, I mean, the picture is right here. Let's see, how do I explain this? So we know that a language is going to be-- OK, if we're using general disability and A is just reducible to B, we know that a language is always reducible to its complement in using general reducibility. So if this were true, then we would have here so if this were true, when a language is reducible to its
1465	complement, if the complement were recognizable, the language would also be recognizable. That clearly is not going to be the case because you know, A TM complement is reducible to A TM using general reducibility. But A TM complement is not recognizable even though A TM is recognizable. So we kind of have a proof that this has to be no. But as you can see, I'm even getting myself confused. So you have to stare at it. So let me see, we can try to take a couple of questions see if I can clear up people's confusion. So why again, is A reducible to its complement in the general sense? So I'm saying, if you have a solver, if you have a decider for A compliment, it gives you a solver for A. You just ask the solver, is the string in the language or not? And now you just give the opposite answer if you want to solve the complimentary problem. So the A complement is general reducible to A. You just invert the answer for whatever
1466	the solver is doing for A. But you can't just do that inversion when you have a mapping reduction. It's a much more kind of specific translation that's allowed. I mean, the fundamental difference between general reducibility and mapping reducibility, I'm trying to bring it out here. It's just a difference in the nature of the way things are used. Mapping reducibility is a special kind of general reducibility. So to answer the question about what's the fundamental difference, one is using the problem as a subroutine and the one is using it as a transformation. Anyway, I think we're going to have to move on here. And I am going to have couple of examples which may help. And then, there are office hours too after the lecture. OK, oh, yeah, so I wanted to again to help you. I'm putting these down as sort of templates for how do you use reducibility. I'm not saying you should just apply things blindly. But I think it's sometimes good just to see the pattern and then to understand how the
1467	pattern works. So once you just start to understand the pattern of how things are used. So to show a language is undecidable, to prove a language B is undecidable, show undecidable languages reducible to B. Using just a general reduction is going to be good enough. And the template for that is, assume we have R deciding B, which you then can use as a subroutine when you make a Turing machine S deciding A. And that's going to be your contradiction. If A was originally shown to be known to be undecidable. But now to prove something unrecognizable, this kind of reduction it's not as restrictive enough because this kind of reduction allows for complementation which is not going to be satisfactory when you're trying to prove Turing unrecognizable. So you're going to have to prohibit the complementation. And that's really one of the effects of the mapping reducibility if that sort of is getting at the essence of it. So you're going to show an unTuring of a recognizable A is mapping reducible to B. Often you
1468	start out with the complement of A TM, which is a language we know is Turing unrecognizable as we showed before, OK, here the template is you give the reduction function f, that computable function, OK. So here are going to be two examples, one showing that E TM is Turing unrecognizable. We showed it was undecidable before. Now we're going to show it's even in a sense worse. It's not even recognizable. And the way we'll do that is to reduce a known unrecognizable language to E TM in the emptiness language. So here is the picture that we have when we're doing mapping reductions. We're going to map strings that are in the complement of A TM, so strings that are outside of A TM if you wish to strings where the language is empty to machines where the language is empty. And here are strings describing machines which are where the language is empty. And here we're going to take A TM problems and map them to machines where the language is not empty. And the thing
1469	that's going to do the trick is going to be that same reduction function that we saw earlier. We're going to take that machine w from before, the machine that filters out all the non-w's. And we're going to take Mw, which is an A TM compliment problem. So if M rejects w that it's in the complement of A TM, and that's supposed to map to a string, a machine which is where the language is empty, OK. So if Mw is in the complement of A TM, so M rejects w, then Mw's language is going to be empty, which is what you want to have happen. Let me move on to my last. I mean, this example is in a way kind of similar to the one we did before. And I really want to get to the last example here. OK, so we'll have to just talk through this rather than having it build. Let's take EQ TM. That's the equivalence problem for Turing machines. Do they recognize the same language? So this is a language
1470	of a new kind for us. This is a language where neither it nor its complement are going to be recognizable, Turing recognizable. So the way we get that is, the way we show problems are not recognizable is mapping reduce a non-recognizable language to typically the complement of A TM. So we're going to mapping reduce the complement of A TM to both EQ TM and to the complement of EQ TM to show that both of those are not recognizable. And here we're going to introduce a new machine that we're going to be building inside the reduction function. And that's going to be a machine I'm going to call Tw. And Tw is a machine that always behaves the way M behaves on w for every input. So if M accepts w, T is going to accept everything. If M rejects w, T is going to reject everything. So it copies the behavior of M on w onto all inputs. And the way I describe that machine Tw is it ignores its input. Whatever the input is,
1471	it just simulates M on w. You could easily give an M and w, you can build the machine Tw. It just always runs M on w, no matter what input it gets. And so now we're going to give a function which maps A TM problems which have the form Mw. So it's an A TM compliment problem. So this want to test if M accepts w or not. So that's an A TM compliment-type problem. And I want to map that to an EQ TM problem with the form-- you know, EQ TM problems repairs the machine now, and where going to be testing equivalence.
1472	of the reduction function f. And specifically, what it's going to look like is when we have f is processing on Mw, it's going to produce two machines. One of them is going to be Tw which always behaves the way M behaves on w but expanded to all inputs, and then a machine I'm going to call T reject, which just is designed to reject everything. Now, just walk through the logic with me. If M rejects w, Tw rejects everything. And so we'll be equivalent to the machine T reject. That's what we want. If M rejects w, so we're in the language A TM compliment, then these two machines that I produce for you are going to be in the EQ TM line. That's what I want to have happen for a reduction from A TM compliment to EQ TM. Similarly, to do part 2, I'm going to make here a different f, maybe I should call it f prime, all right, f1 and f2 for the two different parts. So these are two different f's. I'm
1473	going to make f here. Instead of generating Tw and T reject, I'm going to have Tw and T accept which is a Turing machine that always accepts its input. Now, if M rejects w, it's in A TM compliment, then Tw is going to reject everything. And it's going to be different from its companion here, T accept. And so it won't be in EQ TM compliment. But if M accepts w, then Tw is going to accept everything. And it's going to be equivalent to T accept. And you will be equivalent. So the here is where we're taking A TM compliment and mapping it to the compliment, the EQ TM. Too many compliments here I realize. Compliments are confusing. But anyway, why don't you mull this over. And just to summarize, OK, we're out of time here. But why do we use reducing when we talk about reductions? It's because when we reduce A to B, we kind of bring A's difficulty down to B's difficulty, that's where the reducing comes from. Or we bring B's difficulty
1474	up to A's difficulty, because it's really A's difficulty relative to B that we're talking about when we're reducing A to B. So that's why the term reducing seems a little out of place when we're proving things undecidable, or unrecognizable. But that's where it's coming from. Anyway, quick review, we introduced the reducibility method. We defined mapping reducibility as a special kind of reducibility. We showed E TM as undecidable and unrecognizable. And that EQ TM is both, it and it's complement are unrecognizable. So we're out of time. I will shut this down. But I'll take a few questions here actually. I'll stick around for a few questions. And then I'll move to the other chat room for office hours, OK?
1475	So I will do that. So that's in this slide here. OK, so this is proof part 2 for the person who asked me to go over it. But I think it's helpful for those of you who might be a little bit shaky on this. I want to mapping reduce the complement of A TM to the complement of EQ TM. By the way, I don't know if this is going to be helpful. But as we pointed out in the check in a while back, that's completely equivalent to having a mapping reduction from A TM to EQ TM. You can complement both sides, and you get an equivalent statement. Maybe let's stick with the compliments here though. I hope that doesn't make it too confusing, OK. We're trying to show the complement of A TM is mapping reducible to the complement of EQ TM. What does that mean? So that means when M rejects w, so you're in the compliment, we want the two Turing machines to be inequivalent. No, yeah, so we're in the compliment of
1476	EQ TM. So in other words, when we're in the complement of A TM, we want the result of the f to be in the complement of EQ TM. So in other words, when M rejects w, the two machines should be inequivalent. Right? When M accepts w, the two machines should be equivalent. Because when we're not in this language, so we're in A TM, we want to be not in that language. So we should be in EQ TM. So when M accepts w, we should be equivalent. When M rejects w, we should be inequivalent. That's what we want. Let's go down here. So if M accepts w, we want them to-- so when M accepts w, we want them to be equivalent. So if M accepts w, Tw accepts everything. And it's equivalent to T accept. When M rejects w, Tw rejects everything. And so it's not equivalent to the machine that accepts everything. So just go through the logic yourself. You'll see why it's working. All right, so, bye, bye, everyone.
1477	okay why don't we begin hi everybody see how many we got here uh most of you um i'm sure the others will show up hopefully uh soon enough so welcome back um we have today's lecture four and um let's just remember what we've been doing um in the last few lectures we were exploring uh the regular languages as described by finite automata and regular expressions we showed how to convert them back and forth those two models to one another and we also showed how to prove certain languages are not regular now remember finite automata are a very um weak model of computation they only have a limited memory a finite memory um and uh they still aren't able to do certain things with their finite memory but um they are you know um if you compare them with a general-purpose computer at least the way we think about it is their uh you know their capabilities are just extremely limited and so we're going to over the next uh few lectures explore uh some more
1478	powerful models we started doing that last time uh the context-free grammars and as we'll see there are certain things that you can do i think we saw that last time as well those are some things you can do with context-free grammars that you cannot do with finite automata and uh but they still have their limitations as we'll see um so um today what we're going to do we're going to continue that discussion uh by looking at the definition of context-free grammars in a more formal way uh one of the uh things that we do in this course is develop practice with formalism and um so that that's going to be in the spirit of that we also are going to look at their associated languages called the context free languages so they're going to be the counterpart for context-free grammars of what the regular languages are for the finite automata of regular expressions and then we're going to look at a an automaton based model which is the counterpart to the grammars called the push
1479	down automata and we'll see that those are equivalent in power and finally um well and as part of that we will show how to convert the context free grammars to the push-down automata
1480	to move on then and uh return to uh our topic of context-free grammars that we began last time and just to refresh your memory um so here was that example of a context free grammar that we gave last time and it has the way we're going to be writing context-free grammars is using a bit of a shorthand uh which looks like this when you have multiple rules that have the same variable on this on the left hand side you can combine them into one line so these two rules over here s goes to 0 s1 and s goes to r can be written in one line as a little bit more compact way this is standard as s goes to 0 s 1 or r that's where you would read this this is really two rules but written on one line okay so uh as you recall uh from last time a context-free grammar has terminals variables and rules uh those are the parts that we speak of as well as one of the variables
1481	being designate designated as a starting variable which gets the whole thing going so i'll talk remind you about how that computation goes but um so the variables are the symbols that appear on the left-hand side of the rules the terminals are the other symbols that appear in the grammar and the we take the grammar and we use it to generate strings according to a certain system and the system is that you start out by writing down the uh starting variable and then once you've written down that variable or whatever variables you have written down you're allowed to substitute them according to the rules of the substitution rules that are in the grammar so you can keep on replacing the variables that you have with the corresponding right hand sides and then you do that over and over again until you don't have any variables left only terminal symbols remain and at that point you have generated a string that's in the language of the grammar all right so the grammar's language is going to be
1482	a language over strings whose alphabet are the terminal symbols so the terminal symbols in a certain sense play the same role as the input alphabet say for the finite automata okay the the the variables are kind of internal working um symbols for the grammar the terminals are sort of are are the symbols over which the language is is written okay we'll make that more precise in a minute where when i give the formal definition so the result is the generated string and the language of the grammar is the language of all generated strings that you can get using that grammar so um and the important thing is that we call that language a context free language okay so the that's like what we get from that that's the analogous thing to the regular languages but here we call them context-free languages uh the things that you can get from a context-free grammar again just a quick recap of that example we did last time so you start out by writing the start variable and then
1483	i'm going to give you kind of two views of that either in terms of the tree of substitutions which we call the parse tree or in terms of the resulting string as you do the substitutions so here is the uh parse tree here is the resulting strings here are the substitutions that you make um and now we have r um coming from s and we have zero zero r one one and now we have uh r in turn becomes an empty string and then uh the string that we generated is zero zero one one that's in the language of the grammar and now uh if you play with this a little bit you'll see that the language of the grammar is all strings that look like runs of zeros followed by runs of ones
1484	um i think the next uh slide is gonna have a check in and so hopefully that'll uh get us all together on the same page with this anyway um so here's our formal definition anyway uh we have a context-free grammar is a four-tuple there are four parts of context for grammar these are the parts we've already been discussing uh the variables the terminal symbols the rules um the rules are always of the form a variable uh followed by you know with an arrow to a string of variables and terminals that's the way we write just write that down so this is the form of the rule and then we have the special start variable and we all wrap that up into a package this four tuple that's what the context free grammar is um now we have here uh and now maybe a little bit overkill but let's talk about what formally speaking what the the way the grammar actually processes um and produces strings um so we're going to write uh the the standard
1485	notation for this is that if you have two strings of variables and terminals so imagine you have an intermediate string that you've generated in the grammar so far um you know which might be like 0 0 s 1 1 from the previous line so that's an intermediate string that is so far what you've generated you're going to say um maybe that's you and v might be the next line down uh so that means we're going to write u arrow v and that arrow is the the word we're going to use is yields we'll say u yields v um if it can go from u to v just with one substitution step um and then we'll write u yields v in some number of steps or actually we say u derives v if it can go to u to v with some number of substitutions instead of just one and that's used with the um the yields arrow with the star above it to mean some number of um another way of writing that is you
1486	can say u goes to v if there are a bunch of one step moves that you can make which take you from u to v and that whole sequence is called a derivation of v from u that's a sequence of steps that you go through doing these substitutions one by one to take you from u to v according to the rules of the grammar and lastly if u is a starting variable then we call that sequence just the derivation of v it could be the derivation from the start variable but that's kind of the assumed if you don't say it's a derivation from anything the derivation of v in the grammar is the derivation of v from the start variable it's just the sequence of substitutions that you make kind of the you know what you is what i think you would expect now the language of the grammar is the set of all strings that um of terminal symbols that you can get from uh starting at the starting variable of the grammar okay
1487	and that's called a context-free language as i mentioned before so it's a context of free language it's the language of of the grammar for some grammar okay so let's have a little check in here again nothing too hard nothing to get worried about anyway we're not counting correctness uh here so um let's just see um i'm gonna give you two uh things that look like grammars which of them are actually grammars and let me just pull that poll up uh here okay so which of these are valid grammars here are they both neither i mean you can kind of make an argument either you know either way for both of them but both of them are kind of a little have their own a bit of weirdness to them uh in a way if you if you if you study them for a second um okay that's pretty much converged um share the results um okay so um so in fact the correct answer is b um [Music] and uh why is only c2 first
1488	of all you know well what's wrong with c1 c1 the problem with c1 is that the rules have things besides a single variable on the left hand side so having a b1 on the left-hand side is not legal in a context-free grammar in fact there are other kinds of grammars there's a kind of grammar called a context sensitive grammar the term context free means you can replace the variable independent of its context in the intermediate string so independent of what's around it but here the this substitution is going to you can replace b but it depends on there being a one next to it um this is called a context sentence set of grammar but it's not the kind of character we're going to be using which are only context free grammar so c1 is out that's not a legit context-free grammar c2 the thing that's a little weird about c2 is if you try to generate a string in c2 you'll see that um there's no way to get rid of the variables you're
1489	always going to be stuck with the variable um now that doesn't violate the definition of a context-free grammar so this is a context-free grammar but but it's not going to be able to generate any strings of only terminals so this is a context-free grammar whose language happens to be the empty language but that's totally okay so the correct answer here is b that only c2 here is a valid context-free grammar okay um common let's just see common question does a string u derive itself yes a string u derives itself uh that's a little bit of a little bit of an esoteric question there for us right now but yes um a string u in in this definition here u arrow stars you is legit is illegal maybe it isn't uh according to the way i've written it down here but it is it is uh a legal thing it's not going to really matter
1490	let's do another somewhat interesting example of a context-free grammar um this is a grammar that is um can generate arithmetical expressions involving pluses and times so here it is it has how many rules well there are six rules here each line represents two rules so e goes to e plus t or t t goes to t times f or f and f goes to uh parenthesis e parenthesis or a um now so the variables are going to be the symbols that appear on the left hand side et and f the terminal symbols which are going to be the symbols of the language that you're going to be generating um is going to be the plus the time symbols the parentheses are just terminal symbols here so they're nothing not playing any special role besides that and then you have the a which is representing kind of the um operand on which those operators uh would be working if there was actually an expression you would use but they're just symbols from the perspective of the
1491	of the grammar and lastly the start variable is going to be as normally appears on the upper left hand side of the grammar in terms of the way you write it down so sometimes you might specify a different start variable but
1492	okay so let's just see uh some examples of uh using the grammar to generate uh a string so here is a string in the language a plus a times a and and this example will kind of reveal some other interesting features of the grammar but let's just see it in operation first so again i'll try to write it to you in both ways in terms of the parse tree and the resulting string as you're doing the substitutions so um the uh so first we start with the e then we substitute e plus t and we see the resulting string z plus t but now we as we're doing additional substitutions the resulting string that you get is going to evolve um accordingly and um so i hope it comes across that this tree here picture on the left shows you the structure of the various substitutions whereas on the right it just shows you the strings that you get as a result of those substitutions [Music] so now you can generate this particular string which
1493	is now in the language of this grammar you could generate all sorts of other strings as well uh such as you know parenthesis a plus a parenthesis times a and so on and in fact um this might be a piece of a programming language that you're trying to describe um and one application of context-free grammars is to describe the syntax of programming languages you know what are the legal programs that you can write with in that programming language and not only that the grammar can be used to automatically generate the part of the compiler uh for that programming language which will interpret the um which would uh interpret the structure of the input you know the so-called parser which will figure out the meaning of the uh input to the compiler so that the compiler then can generate the code or if it's an interpreter it could interpret the uh the resulting um code that you've given it um but the very first step in both of those is to figure out the meaning and
1494	the meaning is um embedded within the structure of the parse tree now in the in the case of this particular tree just to give you some sense of what meaning i have in mind this parse tree due to the structure of this grammar has the precedence for times over plus so normally when we write down a plus a times a you you assume you're going to do the multiplication before you do the addition even though it appears second that's just the way we tend to write things and and this grammar has grouped it that way for you it groups the times lower down in the tree than the plus so the the times is going to be done before the plus if you imagine doing this in terms of the way the tree is guiding you so the tree as you can see has a certain amount of meaning built into it now we're not actually going to be using that in this course but i just want to you describe that as a an
1495	illustration of how this material can get applied um now so you know here is what i'm saying that the tree contains additional information now that's also relevant um if you happen to have a grammar which might allow multiple parse trees for the same string okay that can happen um this particular grammar does not allow that but you might write other grammars that as we'll see in a minute that could generate the same string in multiple ways with multiple different parse trees now that might be undesirable when you have a programming language because typically you want it to be only a single meaning for your code you don't want it to be ambiguous and have multiple meanings but um uh ambiguity is it does occur and it's not necessarily something we're always going to uh see is a bad thing um so you know i think as i mentioned last time a lot of this subject originated with linguistics um and that's where the terminology comes from grammar and um uh languages and so on the
1496	terminology for the subject really comes out of linguistics in fact one of the key players for that is an emeritus faculty member at mit noam chomsky he was instrumental in setting a lot of this stuff up um but the um uh you you can think of grammars as applying to natural human languages as well so let me give you a little example as a pop-up this is not directly uh pop-up a check-in not directly relevant uh to the material i just presented but just sort of a curiosity um if you take the english sentence the boy saw the girl with the mirror um you know does that is there only one natural uh interpretation for that sentence or are there perhaps other natural interpretations for that sentence so let me pose that to you as another uh poll here um and uh so i ask you to think about how many different meanings you might find for uh reasonable different meanings i mean you can you know if you're going to go wild you can
1497	think of zillions of meetings but i think in terms of reasonable meanings how many meetings might you get for the sentence uh people are seeing more meetings than i'm seeing but that's okay um so this is a quick why don't we just give this another uh 10 seconds here um and then um most of you are in agreement with me um uh i can see here that uh uh you are uh seeing that there were two meanings the two meanings that i see here for this sentence are um when you say the boys or the girl with the mirror is who has the mirror is it the boy seeing the girl through the mirror or is it the girl that has the mirror and the boy just happens to see her so two very different meanings for the same sentence and that's the nature of english it's just uh the the way um uh it's it's an it's it's an ambiguous um structure there and often we resolve that ambiguity in english with other information
1498	that we might have um but um typically you don't want there to be ambiguity when you have this a grammar say describing a programming like
1499	um so let's continue on that um so talking a little bit more about ambiguity i was promised you an example where you might have an ambiguous grammar um so uh if you take these two grammars g2 and g3 the g2 from the last slide and g3 is a similar grammar in fact has it's the grammar that has the very same language um that gives you the very same language so l of g2 equals l of g3 both of them are describing these arithmetical expressions um but whereas g2 has a unique parse tree for every string that you generate g3 can have multiple parse trees for the same string okay so i'm just going to illustrate that here so here is the same string that we generated last time a plus a times a in g3 the parse tree is actually even simpler here um so here i'm showing you the uh there's just the two substitutions that you uh need to make starting from e and then to to get the string a plus a
1500	times a it's a it's a it's a simpler grammar in a sense um but you there's another parse tree that'll give you the same uh result and i've written that down below here upside down um so uh the upper parse tree groups the times before the plus or more in more inside uh than the plus but the lower parse tree doesn't have that precedence built into it and can alternatively interpret the plus as being of higher precedence than times and so in that sense we have here um a grammar which is um has two interpretations for this um same string and we call that whoops we call that an an ambiguous uh derivation ambiguously derived string and the grammar itself is called an ambiguous grammar um uh okay so let us continue on from that by the way there's a question here that came in uh uh like for example a plus a is that ambiguous in g2 no uh if you if you try to uh apply it you'll see the way that g2
1501	can produce a plus a to a plus a plus a is going to group the first two and then the and then the the second one then the last one you can't you can't derive things in multiple ways um i mean addition is associative but the grammar doesn't it doesn't the grammar for the grammar um it's going to have a prescribed order for the way things get interpreted there okay um so that's ambiguity um so let's uh introduce push down automata um which is going to be our automata counterpart for context-free languages all right um so the way i'm going to introduce push-down automata uh sort of shifting gears here and now um is by first uh giving a new view of finite automata remember before when we presented a finite automaton we gave it in terms of a state diagram which i've kind of shown here in miniature form on the picture um uh we could do that for pushdown automata but the picture tends to be very complicated so i'm going to take
1502	a bit of a higher level um uh description for pushdown automata which is i'm calling a schematic view or a schematic diagram and there i'm really not going to be showing you the individual states but i'm going to be showing you the individual components of the machine at a sort of more of an abstract and from a more abstract perspective and so from that perspective um [Music] a finite automaton has here what i'm going to call the finite control so i'm going to be suppressing the details of the states in this pic in this picture i'm going to represent uh that those states as the control of the um of the dfa or the nfa they're really going to be the same
1503	going to be appear on as a string that's written down on what we're calling a tape again this is somewhat of an anachronistic terminology back in my days people actually did feed their inputs into computers on a tape sometimes we don't do that so much anymore but that terminology has stuck and it's going to be a persisting um uh later on in the course too so you might as well get used to it um so the input is going to appear on a tape or sometimes called an input tape um and the way the machine actually will read that input whoops uh is going to have a head which is going to be um starting at the left side and moving from left to right reading the symbols on the that appear on the input tape one by one okay so this is our picture of a an a finite automaton just redone from uh last time just a different way of picturing it now that's going to be setting the stage for the picture
1504	of a push down automaton because the push-on automaton is like a finite automaton but it has an extra feature has an extra device attached to it and that's called a stack
1505	and that's going to be a stack which is going to be basically a form of auxiliary storage now remember part of the limitation for a finite automaton was that we had a limited amount of memory um so we were not able to do some very simple things like counting because we had a limited memory so the push-on automaton is going to be able to use its stack as a kind of unbounded memory but a memory that's very restricted in the way it can be used so it's unlimited but still restricted as we'll see so uh the way the push down automaton uses um this extra memory on on what we're calling the stack or push down stack is that you can write symbols um instead of only reading symbols but those symbols can only be read at the very written or read at the very top of this list of symbols and every time you add a new symbol the other symbols that are already there get pushed down hence the name people also often
1506	refer to it as a stack of plates uh in a cafeteria if you've ever seen those things or you can remember back to the days when we went to cafeteria uh which getting further and further away but um uh if you have a cafeteria you had a stack of plates and you know you as you removed plates from them they were on a spring and they kept coming up or if you add more they would go down and it's the same idea imagine these symbols here are sort of on a um on a spring and the more symbols you add them the more they go down uh or if you remove them by read
1507	so a push out of tabaton operates like a finite like a non-deterministic finite diameter as we'll see push down automata for out for us are always going to be allowed to be non-deterministic so we're not going to be studying the push on automata that are restricted to be only deterministic um uh i'll say more about that in a second but like they operate like an nfa except they can write uh or read symbols from the top of the stack and when they write they're adding the symbol on pushing down that stack and when they're reading they're removing symbols from the stack and thereby lifting up the stack okay we give them special names so those of you who have seen stacks already this is you know i'm sure old hat for you uh but i'm sure now everyone has have seen stacks before so uh the special name for writing onto a stack is called a push operation so that you're pushing a new symbol down on the top of the stack and it pushes
1508	everything down whereas when you're reading a symbol and removing it from the top of the stack that's called a pop so that's reading and removing we we always think of those as going together writing and editing and reading and removing are combined i mean you might wonder why can't i just read it and leave it alone and not just have remove it you uh no you can get that effect by reading it and then uh which removes it and then putting it back if you really want it to stay there but the way we're setting it up is that reading comes with removing writing comes with adding okay and they're called pushing and popping okay so let's do an example um so we have here a push down automaton for a language we'll call d it's a we've seen that language before it's this uh it was um actually we use the same uh letter for it the strings of zeros followed by ones where the numbers are the same of the two so zero
1509	to the k one to the k we couldn't do that with a finite automaton we will be able to do that with a push down automaton um and here i uh um i thought i wrote down the input here but okay so the basic idea is i'm going to give you a uh an input now and the pushdown of the tombiton is supposed to test whether that input is in the language whether it's of this form um now it has the ability to use the stack because you know it's going to have to count how many zeros it has and so the way it's going to do it is you know i have a bunch of zeros hopefully and then a bunch of ones and you want to see that they're uh of the same number it's going to take the zeros and store them on the stack until it sees a one and then one's going to start to read the ones and it's going to remove the zeros matching them off one to
1510	one with the ones that it's seen okay so um you initially first read the zeros and push them onto the stack until you read a one and then you read the ones uh while popping zeros from the stack and you enter the accept state if the stack is empty just like with a finite automaton the except entering the accept state only counts when you're at the end of the input okay so um without me needing to say anything it's really saying you enter the accept state if the stack is empty at the end of the input string but that's kind of implicit because it only takes effect at the end of the input string if you enter an accept state alone in the middle somewhere it doesn't matter it doesn't affect anything um okay uh with that we're going to take a little break and then we'll be back uh shortly to look at push down automata again in a more uh with a more formal definition um let me put that's going to be
1511	five minutes so if i can figure out how to get my timer screen up here yes and we will uh the camera when the candle burns down to nothing we will return and continue okay our candle has burned down and has gone out i think i never actually watched to see what would happen at the end uh so um we're good to go let's continue um uh good and let me put myself back in there all righty um [Music] so we were doing push down automata and we just did that example of zero to the k1 to the k now that you have a stack we can do uh all sorts of fancy things that fina tamara could not do just with their limited memory okay so let's take a look at how we define push down automata um [Music] so now uh push down automata is actually going to be a six tuple so it's a little bit got some fancier stuff here to deal with not too much but a little bit um
1512	and uh so it has uh let's look at these a little bit more carefully since there's some novelty here we have the uh input alphabet just as we had before uh sigma but we also have gamma which is the alphabet for uh using the stack now um you might ask why don't we just use the same alphabet well it's really a matter of convenience um that we would like to be able to have other symbols that uh could include the input alphabet but could include other things as well so it just gives you more flexibility in terms of what you're going to be writing on the stack um okay the transition function more complicated uh so i think i don't know if i'm going to even say what the other things are but you know these are the accepting states this is the starting state so that's um the same as before but the transition function is is a much different animal here in a push-down automaton so let's just try to uh unpack that
1513	and understand what it's saying the transition function tells us how the machine operates how it goes from state to state how it's going to read the input how it reads from the stack and what it might write on the stack too because that's going to all happen under program control so um what this means here is that you know when the machine is in a particular state um reading a particular input symbol let's ignore the empty string uh subscript for the monument so it's in a particular state reading a particular input symbol and with a certain stack symbol appearing at the top of the stack so that's all information that's available to the controller of this pushdown automaton the transition function the current state the next input symbol and the symbol at the top of the stack and once we have that we know what new state we can go into and what new symbol we can write on the top of the stack okay so that's what the uh um right-hand side of this
1514	function specification means so this is where uh kind of the input to the function this is going to be the output of the function state entry and a new symbol to appear on the stack so this is the popping symbol this is the pushing symbol so now there are two things that bear explanation here first of all now this is this is a power set so this is going to be representing as we did before um a non-deterministic machine we may have several possibilities and we're going to represent that as a set of possibilities for the machine that it could go to at any point i will give an example of how a push down automaton uses its non-determinism in a minute the other thing is is these epsilons so we have to understand why they are there and we remember we had them for the nfas corresponding to when the nfa had an epsilon transition an empty transition so it could go along that transition without reading any input so this is going to
1515	play the same role here so if you have um instead of an input symbol from sigma appearing in this um uh part of the you know uh for the for the transition function instead you have an you have an epsilon appearing that means that the transition that that move of the machine can happen without reading any input symbol just like for the nfa's or if you have an epsilon appearing for the stack symbol that means you can make that transition without reading any stack symbol so any whatever's sitting on the top of the stack it doesn't matter the machine can make that move and it won't read anything either we're not going to pop anything it's just going to uh be proceeding without looking at the stack at all or it might have both of them which case it's going to go from one state to another state without looking at the input or at the top of the stack so um that's what the possibility of epsilon means for the um for the transition
1516	function in the in those places the epsilon appearing over here means something a little different but very similar what that means is that um [Music] we won't write anything on the top of the stack that's going to be we will go to a new state but without doing any writing so we'll leave the stack alone um so here means we're not going to read anything if it's in this position in this position means we're not going to write anything okay so all of those things are valid and legal from the perspective of you know constructing a push-down automaton and i've kind of illustrated here you know just with a little bit of an example if you have delta that applies to some state q reading an input symbol a and popping a c from the top of the stack then you might have let's say in this case two possibilities that you might end up going to you might end up going to states r1 or to states r2 and in the former case you'll
1517	end up writing a d pushing a d onto this top of the stack and in the latter case you would be pushing an e onto the top of the stack okay so this is i'm trying to help you look at this notation you can you know you know i hope this is clear to you um i'm sure for some of you it's too slow but others of you i'm trying to help along but if you're really struggling with this notation at this point you know you really have to going to have to dig in and make sure you follow it because it's only going to get harder from there i'm going to stop being uh going over these these kinds of points and if you're still struggling you can't get it this is not the right class for you i'll just i'll be honest um because we're just gonna be
1518	okay so it's a non-deterministic machine um we accept uh like we did before uh there might be several different threads of the computation you're going to end up accepting um if some of the threads or what at least one of the threads end up ends up in an accept state at the end of the input string okay that's when we machine overall accepts it's just the way we normally think of non-determinism again you can use the models that we had before in terms of guessing or parallelism whatever works for you and sometimes different things work in different different different occasions uh but that's how non-determinism works we'll do an example now okay here is a push on automaton for a different language we haven't seen before i don't think well maybe we have um which is um going to be using its non-determinism in an essential way this is a language that is going to where non-determinism is going to be critical um without it you can't uh a deterministic push on automaton which is
1519	something by the way that people study um and there's a section of my book about that section 2.4 because it has relevance to applications we're not going to address that in this course so you can just skip section 2.4 it's pretty technical uh i'll have to say um but still quite interesting and beautiful if you're if you like that stuff but it's
1520	so here is um this input string w w reverse for all possible w's over our alphabet zero one and what w reverse by the way means is writing w backwards uh so this is all strings followed by a reversal of the same string okay the string written backwards um really you can think of these as uh um you know so these are strings that um well here's an example like 0 1 1 1 1 0 the string written backwards so this is a string in the language appearing on a tape as i as i described okay so how is the machine going to um recognize this language it's kind of pretty similar somewhat similar to before but with one important difference um and if you imagine i think again i like to use this kind of and anthropomorphizing these things putting yourself in the place of the machine and thinking how you would do it um so if you imagine getting these symbols one by one zero one one you don't know what's coming next
1521	as you're getting the symbols you have to figure out how to match off the second half with the first half so you're gonna put the first half on the stack and then you're gonna remove the first half and match it off with the with the with the second half con conveniently the first half comes out backwards the stack is a first in last out kind of thing so um it comes out in reverse order so that's perfect for matching off with the second half uh but the tricky part with this language is how do you know when you're at the when you're at the middle because you don't get to see um the rest you only get to see what you've seen so far you don't know what's coming so you know uh when you read that second one at this point you read zero one one now you're reading that second one you don't know that perhaps there's just going to be a zero following that and it's going to be all so maybe
1522	you should be deciding to that this point here that i've marked um uh is the midpoint and you you put zero one on the tape and then start popping the second the the second one and matching it off with the first one um that might that would be a tempting thing to do but you just don't know um and that's where the non-determinism is going to be essential so let me let me write down more of this so what you're going to do is you're going to read and push input symbols but not deterministically guessing that you're at the middle so you're going to now deterministically either repeat that and continue to read and push symbols onto the stack or you're going to go to two deciding that or guessing that you're at the midpoint and now it's time to start reading and popping instead of reading and pushing so you're going to read input symbols and popping that popping the stack symbols comparing the the two the the symbols that you're reading with the
1523	top the symbols you're removing from the stack if they ever disagree then this thread of the non-determinism rejects because either the input is not in the language or at least you've made a wrong choice as to where the midpoint is um and then you're going to enter the accept state if the stack is empty and ignore this part for the moment of this software reference uh let's just um i'll speak to that in a second but um i just want to make sure we understand that at an intuitive level how this machine is using its non-determinism to uh recognize this language because the non-determinism is critical and it's important that you understand it um so let me just make some side comments and then we'll come back to this software remark so first of all one question that comes up a lot well um not paying attention to the chat here sorry so if you're not getting answer from me try the tas but um one of the uh one of the um questions that
1524	comes up a lot when they're thinking about non-determinism for push down automata is what happens to the stack the stack gets replicated in the non-determinism every time the machine forks just like everything else gets replicated so an entire every time there's a fork in the non-determinism and the machine branches into multiple possibilities the entire machine replicates the current state the current position of the head the what's the stack and its contents all of that gets replicated um and the two um sides of the the two branches or the two sides of the fork each go on independently in their merry way okay doing their own thing independently and then if any one of them accepts that's the only way there's sort of a kind of a communication because the one that accepts raises the flag and then uh the overall machine is set to accept okay so the non-deterministic forks replicate the stack of saying it uh just want to make sure you've got that um and then this language requires non-determinism that that i
1525	said earlier um so our pda push down time model is going to be non-deterministic i mean you might have examples which are deterministic but the model is going to always allow non-determinism okay what's this bit about the software so if you look at this formal definition here it doesn't have anywhere in it the ability to test if the stack is empty that's not part of the hardware specification at least as we are describing it for a push-down automaton you can might imagine someone somebody else describes push on the tama in some other way which gives that as a primitive but we're not going to do that why because we don't need a primitive for that you can get the effect of testing if there's an empty stack even if you don't have that as a primitive for the machine because uh what you could do is you can start the machine off when it very at the very first thing it does is it writes a special symbol to mark um the bottom you know
1526	what's going to eventually be the bottom of the stack there's going to be some special symbol maybe a dollar sign symbol that's the very first thing that the machine does and then it proceeds as before if ever sees that dollar sign symbol again it knows the stack is effectively empty okay so you can get the effect of testing for the stack being empty even if you don't have a primitive for that and we're not going to actually fuss about some details like that um so you can use when you're writing your homework sets you can just use the assumption that you can test for empty stack which is what i'm going to do myself okay um
1527	yeah so now what we're going to do we're going to prove our one so far we really haven't proved anything we've just given some definitions and some examples today was going to now we're going to come to our big theorem which actually is um important and has some meat to it um and that is how do we convert you know i claim that to put context-free grammars and push down automata are equivalent well we're going to prove that equivalence in one direction converting the grammars to push down automata okay so um let me show you how that goes in some ways um it's a nice proof not super complicated but it has some meat to it uh so if i give you a grammar here what i'm going to tell you how to do is convert that grammar into push down automaton which does the same language okay so if you're checked out for a minute please come back because we're sort of starting this topic now that you can think a bit about this
1528	good good uh re-entry point if you're sort of uh been doing something else which i can't tell good thing uh so all right so converting a given grammar to a push down automaton how is that going to work so the idea is okay actually before i tell you the idea let's just think about it together again i like to think about the push down automaton building a push on automaton the way you would do it so a grammar is a generation device it generates strings a push down automaton or thinking about it as you you're a recognizer you're given an input and you want to know is it in the language so you want to know is it possible for that grammar to generate that input you're given so how are you going how are you going to how are you going to do that um and uh are you going how are you going to um test if the input is in the language of the grammar well the thing that you would naturally
1529	do is you say well can i derive that string using the rules of the grammar let me start with the start string and try to do substitutions and see if i get the string i'm given and if i can get it then i know it's in the language right that's a natural thing to do you're just going to try try to do so you know try to do the substitutions even get to the string now the thing is there are many there might be many different substitutions that you could make and you know that seems like a really challenging uh hard thing to figure out which substitutions to use among the many possibilities that's where non-determinism is going to come in because you can think of yourself as guessing which substitutions to make and you're always going to make the right guess so the choices of which substitutions to make that's not going to be a problem for you that's going to be managed by the non-determinist so imagine you're always going to make the
1530	right substitution but now the challenge is how do you keep track of the intermediate results as you're doing those substitutions um and that's where the stack is going to come in the machine is going to write down those intermediate results on the stack but even there there's a subtlety that's an important subtlety that you have to look at so let's try pulling that together so far before i get to that subtlety uh okay so as i mentioned um uh the push down automaton is is going to start out with the starting variable and is going to guess to be guessing the substitutions to make it's going to keep the intermediate results on the stack when it's done doing all the substitutions and it has only terminal strings on the stack it can compare with the input and see if it got the right thing so if it made it all the right guesses so you think of it as guessing doing the right guesses but in the end you have to check to make sure
1531	that you've got the right the you that you did all the right thing and you accept when when things um have matched up you know you and you made all the right guesses so you have to in the end you have to check that you actually got
1532	okay so let's let's let's try to see this operating in action and then you'll see the subtlety the the delicacy the the the the the a problem that's going to arise hopefully you're following at least in part what i'm just saying so far okay so here is the input we do know that that's an input in the language of the we we've been seeing this example multiple times so here's the input appearing on the input tape a plus a times a now the push on automaton is supposed to be accepting that input because it's in the language of the ground okay so it's going to operate by first writing to start off the starting variable on the stack and then doing the substitutions as we're going along okay so um we're going to substitute we we we uh e goes to e plus t so we do that first substitution um and then we do the next substitution here the e so i'm i'm if you're looking at this tree here that means this is
1533	the right tree for that uh for that input so we we substitute e by t uh so far so good the automaton can do to make that substitution then the next substitution is going to be a little uh so we're where e plus t we did we substitute here we got t plus t and now we're going to substitute the t times f which is this t over here we want to substitute that and that appears as t times f now on the stack now if you're following me you should be suddenly getting nervous because we just cheated it's okay um doing substitution doing these replacements at the very top of the stack because the push down automaton has access to the top that's how stacks work but it does not have access deep down within the stack that is uh not house style that is not how stacks work so that's cheating but ignoring the cheating for the minute if you could replace those um do those substitutions deep down within the stack this
1534	would all work we would be good you would do the substitutions uh one after another until you ended up with no uh variables and then you have the string here and you're going to match it off and compare it with the input it's all done in the right way so that the things are in the right order so the you know the after all the substitutions you'd have a plus a times a sitting here on the stack you match you compare that with the input it's going to match up and you'll end up accepting all good so how do we deal with that problem here problem access below the stack of step top of stack is cheating what are we going to do instead so the idea is actually pretty simple well if you've understood what i've said so far the you know fixing that is actually not too bad um uh uh sort of fading out here uh put some more light on the on my image um so how do we do that
1535	uh how do we get the effect of the access below the top of the stack and the way we're going to do that is um by making the obs what we're going to do we're only going to do substitutions that we can make at the top of the stack so whenever there's a variable at the top of the stack we're going to do the substitution because we the top we can access now what happens if we have a terminal symbol sitting at the top blocking our way from accessing variable variables below well actually that's an easy case to handle because we have terminal symbols sitting on the top they're never going to change anyway so you might as well match them with the input at that time so when you have a terminal sitting at the top we'll just read another input symbol and do it and match it off there and we just keep reading the terminal symbols off until we have a variable sitting on the top then we do a substitution um
1536	and we keep substituting variables until we have a terminal then we read it then we compare it with the input and in so doing um we will end up getting the same effect that i described before without ever needing to dig down into the into the interior of the stack and doing substitutions there they're all going to rise up to the top uh and we can always do them at the top okay um so anyway uh you know i forgot to do that here so instead only substitute variables when they're at the top of the stack uh if a terminal is on the top pop it and compare with the input and reject if they're not equal so if you ever have something which is not matching the way it's supposed to do that i mean that thread is just gonna fail you know then it was not a bad uh non-deterministic choice was made or maybe the input was not in the language anyway and there are no no good choices um so here
1537	my animation broke here so let me just put the whole thing up in front of you so here is the actual construction um push the start symbol on the stack if the top of the stack uh is a variable replace it with a corresponding right-hand side doing a non-deterministic choice among the various possibilities if it's a terminal you pop it and match it with the next input symbol and if the stack is empty you accept so here is how the stack would actually look for this particular input you know it would start off the same you'd have e and then substitute with e plus t and then we're going to always substitute do the substitutions at the top so e gets substituted by f oh is that right no this slide i messed up i apologize so e gets substituted by t which gets substituted by f um and the point is that when you get to an a sitting at the top uh forgive the typos here now we have a terminal symbol and
1538	that's going to get matched off with the next input symbol and get removed and now we have just the plus and the t left and then the plus is also a terminal symbol that's going to get matched over the next thing we just have a t sitting on the top and now we can do a substitution okay so that's how uh it works okay i that's all i wanted to say i think um oh yeah there's one just remarked so this is not we're not going to prove this but i think it's uh i i do need to say this that actually you can do the conversion in the other direction too you can convert a um so a is a context-free language if and only if some push-down automaton recognizes a and um if you haven't seen if and only if it's a it's an expression i'm going to use uh uh again over and over so you should get used to it it stands for if and only if and which just means
1539	the implication goes both ways so a is an uh context-free context-free language implies that some push on time time recognizes a and vice versa um so there's really two things you need to prove whenever you have an if and only if you have to prove both directions um so uh thinking about that way splitting them in half um the the forward direction we've already proved converting a push context uh free grammar to a push down on automaton the reverse direction we're not going to prove it's in the book if you're curious and you're responsible knowing that the fact is true but you don't have to know the proof uh which is a somewhat comp a little bit complicated and you know i think it would take us too long to go through it so you're not responsible for it um so there's a last check in here that i have for you which is just a question uh uh which you can answer based on the material that we presented so far is every regular
1540	language also a context-free language just yes no or you're not sure so let me launch that as a poll here okay about to close um [Music] ending polling and sharing results this one i think you you pretty much uh most of you got some of you uh are not sure um every language is in fact a context-free language um and the way to see that is that every regular language can be done by a dfa or an nfa as we already showed and um dfa or an nfa is really just a push-on automaton that never uses its stack so you can always think of a dfa as a push down automaton and we already argued that pushdown automata are equivalent to context-free grammars and so they do the context-free languages so anything that you can do with a dfa you can also do with a push-down automaton and so is therefore uh um all the regular languages are also context-free languages okay so with that let's just uh kind of pull things together um a
1541	little quick recap as to what we've been doing so far in the class we have the regular languages and the context-free languages we had the two forms of sort of getting at them the recognizer form which is like the automata based perspective like either a dfa or an nfa in the case of the regular languages push down automaton for the context-free languages and for the generators we had the regular expression uh for the regular languages and the context-free grammars for the for the contextual languages okay um and as we just pointed out in our most in our last check-in the regular languages form a subset and in fact a proper subset of the context-free languages uh as shown in this venn diagram because we have already exhibited languages that are context-free but not regular all right so quick review we've defined the context-free grammars and their associated languages the context-free languages we define push-down automata and we showed how to convert context free grammars to push down automatic um and that's all i have for
1542	you today okay here's a question i'll answer to everybody why do we strict ourselves to a stack why don't we use random access memory we will use random access memory um for the next model called the turing machine and we're going to introduce that i think next to the next lecture so that's going to be the model that we're going to stick with throughout the term but we have not uh we were kind of using introducing weaker models uh as a kind of a prelude uh to the more general purpose uh computational model um uh really to get ourselves warmed up and also um because um for the weaker models you can fully analyze them um in a way that you cannot return machines you you will be able to as you will see you can determine properties of languages for the weaker models that you cannot for the more general models and so i think that's helpful to have that perspective that you know for some cases you can get get a full analysis
1543	and some other cases you cannot um but anyway um that's the reason why we're stricter restricted to the stack besides the fact that these models have applications um that i think are worth you people seeing um why yeah some reason we chose a stack well why did we choose a stack and not some other data structure for our uh temporary for our our extra storage and the reason for a stack for one thing the stack is what is exactly what you need to get to the correspondence with context-free grammars um if you use some other storage like the queue for example instead of a stack in fact you get a very different outcome and it's an actually interesting exercise to see what happens what do you get if you use a queue as an external storage instead of as a stack uh it's a good homework problem maybe i'll assign it um uh let's see um nfa okay uh we showed so um we we showed that non-determinism can be eliminated for finite automata so
1544	nfas and dfas are equivalent uh what about for for pushdown automata uh the answer is no they're not equivalent i think i mentioned that earlier but i don't mind repeating it there are certain languages that can be done only with non-deterministic push down automata and cannot be done with deterministic push down automata for example that language w w reverse that requires the non-determinism in order for the machine to be able to guess where the middle is so um okay i'm gonna head off uh thank you guys see you on tuesday
1545	[SQUEAKING] [RUSTLING] [CLICKING] MICHAEL SIPSER: All right, why don't we get started? It's 2:35, time to begin. So everyone, welcome back-- good to see you all. Well, at least a few of you-- glad that you're here. So let's see. Why don't I get a layout, as I usually do, where we have been, where we're going today. I'll talk a little tiny bit about the homework, because I've gotten a couple of questions on that. And then we'll jump in. So we have been talking about Turing machines, which is going to be our preferred model for the rest of the semester, since Turing machines are the model which we use to capture general purpose computing. And we looked at Turing machines in various variations on Turing machines-- multi-tapes, non-deterministic, and so on. It's a bit recapping the history of the subject, when people looked at a variety of different ways of formalizing the notion of algorithm. And they showed that all of those different formalizations were equivalent to one another, which led to the Church-Turing thesis that all
1546	of these models-- each of these models really capture our intuitive idea of what we mean by a procedure or an algorithm for-- at least for addressing things like mathematical problems and precise problems of that kind. So we talked about the Church-Turing thesis. We also talked about a notation for encodings and Turing machines. We'll review that briefly. So today we're going to give a bunch of examples of Turing machine algorithms for solving a variety of different problems. I should just say algorithms really-- nothing special about Turing machines. Turing machines are just going to be our formal counterpart. But from now on, we're going to use our Church-Turing thesis in a way to just talk about algorithms in general, because that's really our interest. Turing machines is just our way of reasoning about them mathematically, but we're really ultimately interested in understanding algorithms. In terms of the format of today's class, I'm going to try a little experiment. We're going to have little breaks along the way, as well as the big coffee break in the middle.
1547	We're going to have a little mini breaks, because I sometimes feel that there really isn't enough time for people to be writing chat-- questions in the chat, because things just are racing on. And so this way we'll have a little break after the-- pretty much after each slide. Some of them are going to be a little longer than others. In case you have questions, you can pose them to me or to the TAs, and we'll try to get back to you on those.
1548	Turing machines, as we set them up, they have-- on any input w, they have three possible outcomes. The Turing machine can halt and accept w, can halt and reject w, or it can go forever on w, which is rejecting by looping in our language. A Turing machine can recognize a language, the collection of old strings that it accepts. And if the Turing machine always halts, we say it decides the language, and it's a decider, and so therefore, that language is a decided language, a Turing decider. Often we just say decidable, because we don't really have a notion of deciding in other models, so we often talk about Turing-recognizable or just decidable. Or we'll sometimes just say recognizable, when we understand that we're talking about Turing machines. We briefly talked about encodings. When you write it inside brackets, some objects-- whatever they are-- could be strings, could be machines, could be graphs, could be polynomials-- we're representing them as strings, and maybe a collection of objects together represented as a string in order so that we
1549	can present that information as an input to a machine. And we talk about-- our languages our collections of strings. And a notation for writing a Turing machine is going to be simply that English description put inside quotation marks to represent our informal way of talking about the formal object that we could produce, if we wanted to. But we're never going to ask you to do that. OK, so now let me see. Let's just take a quick break, as I promised. If there's any quick questions here, you can ask. Let's see-- got a lot of questions here. All right, why don't we move on? And some of these things are good questions.
1550	tell if the machine is looping or if it's really just taking a very long time? You can't. That's what we're going to prove not in today's lecture, but going to prove that on Thursday. You just can't tell. So if that's in reference to problem 5, you're going to have to find some other way of doing-- solving that problem without knowing whether the machine is actually ever going to halt.
1551	if an English description is possible for a Turing machine? Well, you can always write down an English description for any machine. It's-- might be very technical looking, but if you can write it down in a formal way as states and transitions, then you can simply write down an English description, which would just be, follow those states. OK, let's move on. OK, this is going to be our first example of a algorithm that's going to answer a question about automata. And it's a very simple problem. It's a very simple problem to solve, because we want to start out easy. The name of the problem is the acceptance problem for deterministic finite automata, acceptance problem for DFAs. And I'm going to express it, as I always do, as a language.
1552	which stands for the acceptance problem for DFAs-- is the collection of pairs. B and w-- B is a DFA. w is considered to be some other string, which will be an input to B. We're going to be thinking of it as an input to B. I put the two of them in brackets to represent the pair of them as a single string. We're not going to make explicit what the form of the encoding is. The only important thing is that the encoding should be something simple, but that the Turing machine can decode back into the DFA and this input string to that DFA. So anything reasonable is going to be a satisfactory encoding from us-- for us. So this is an encoding of the two of them into a string, and where B is a DFA, and B accepts w. So now, if you want to test if something's a member of ADFA, then, first of all, you want to make sure that the string itself that you're getting really encodes a DFA and a
1553	string. So it has to be the right form. And once you know that, then you have the DFA, you have the string w, and you're then going to do the obvious thing, which would be to simulate B on w and see if it's actually accepting w. So that's what the content of this slide is. I'm just going to write it down for you. So I'm going to give a Turing machine, which I'm going to call-- the name of that Turing machine is going to be D A DFA. To help you remember the function of this machine. This is a decider for the language below, the ADFA language. This is just a name, but-- so nothing fancy going on here, but just to help us remember, because I'm going to refer to some of these Turing machines later on. So this is the decider for ADFA. And I'm going to describe that machine for you, and that machine decides the ADFA language. So what does that mean? So that machine-- I'm describing it now in English,
1554	as I promised. We're going to take an input string s, and first, it's going to check that s has the right form, as I mentioned-- has the form which is the encoding of a DFA and a w. If it's not of that form, the Turing machine should reject that input right away. Now, I'm not going to go through the details of how that Turing machine is going to work, though I'll say a little bit more this time only just to give you a sense of how it actually might carry that out. If you don't believe that you can do it with a Turing machine, believe you could do it with your favorite programming language. That's good enough, because that's going to be-- that's equivalent to a Turing machine. So first, you check that the input's of the right form. Then you're going to simulate the computation of B on w. And then, if B ends up in an accept state, then we know B is accepting the input, and we should accept, and we do.
1555	If B does not end up in an accept state at the end of w, then we should reject, because B is not accepting w. OK? That's my description of this machine. Let's just turn to a little bit of details just to make sure we're comfortable with this. So here is our Turing machine-- D, the decider for ADFA. The input to that Turing machine, as I mentioned, is going to be B and w, provided it's of the right form. So that's what this string S is supposed to be of that form. And what does that mean? It's just an encoding of the machine w and the string-- the machine B and the string w. Let me just write it down. Here is B written down in some just completely explicit way, where you're just listing the states of B, the alphabet of B, the transition function as a table, the start state, and the set of accepting states-- just writing it down explicitly, as you might do it if you would just want to describe that
1556	machine in a completely formal way, and then writing down with the string is-- whatever it is. Once DADFA has that as its input, it can then go ahead and do that computation. And just to try to make it a little bit more explicit, I'm going to capture that here by saying, let's give that Turing machine an extra tape, because we already know that the multi-tape model is equivalent to the single tape model-- make our life perhaps a little easier. And in the course of doing that simulation, what do we want to keep track of? Well, what is the current state of B, the DFA, as we're reading the symbols of w? And where in w are we at right now? So I'll call that k, which is the input head location on w. How many symbols of w have we read? OK? And that's all I'm going to say about what this Turing machine D looks like. Oh, there's one more thing I do want to say for the-- that's coming up, because pretty much
1557	all of the Turing machines that we're going to talk about today and going forward are going to often want to check that their input is of the correct form. I don't want to repeat this every time, because that's going to be assumed. So my shorthand for that is to say my input is of the form I'm looking for, and that has built into it the check that the string-- the input string is of that form, and we're going to reject if it is not. So all of our Turing machines are going to start out, on input, the string is of a certain form, and then go out and do something with it. OK? OK, so let me try to answer a few of the questions that I've gotten here, because I think this is important as a way of getting us all started. Now, somebody asked me, can we use arguments of this form? Somebody asking, can we use-- can we give our description of a procedure, if I'm understanding this correctly, as using some
1558	other programming language? Well, typically, you just want to make sure you're understood. If you want to do that on a homework, I wouldn't advocate writing your algorithm in Java, because it's going to be hard to read. But write it down in some pseudo programming language if you want, just to make sure it's clear that-- what you're doing. Probably English is going to be the easiest for you-- even though this person says-- feels it would be easier to do it in terms of a formal language. Well, whatever's easier-- as long as we can understand it. This is a good question here I got to ask. What if B-- here's our B-- gets into a loop on w? Well, that's not going to happen. B is a DFA. DFAs-- they move from state to state every time they read a symbol of w. When they get to the end of w, it's the end of the story. There's no more computation to be done. So we know in exactly how many steps B is ever going to
1559	take on-- it's going to take the same number of steps as the length of the input. That's how many moves it gets to make. B as a DFA never loops. So that would be a problem if it did loop, but it doesn't. That input never does loop. So have we verified that D is a decider? Well, I think I just did. From my standpoint, we've said enough to be sure that D is a decider. There's never any reason for D to be-- for that DADFA Turing machine to be getting into a loop. The input head location is referring to where we are on the string w? Yes. And somebody's asking me, is this the level of detail for the homework? Yes. That's all I want. It's all I'm looking for. OK? Let us move on. I'm going to have to-- otherwise we'll never get anywhere. There are a lot of questions here. They're good questions. So why don't we go on? Some of these may get resolved as we're going to look at additional examples,
1560	because that's all of today is pretty much examples. Let's talk about the similar problem, the acceptance problem, but now for NFAs. So now, actually, NFAs can loop, so we have to think about what that possibly could look at.
1561	the acceptance problems for NFAs looked very similar, except B is going to be an NFA. That's going to be a decidable language too. And now we have Turing machine A-- DANFA, the decider for ANFA that decides ANFA. OK? So now, as promised, here's our new form for writing our Turing machine. On input B, w, we're assuming that B-- based on the context, sometimes you may want to say at this point, what B and w are. But from the context, we know what they are. They're going to be an NFA and an input w for that NFA. I do want to jump into the solution. First, before we actually look at the solution of this, we-- the Turing machine could simulate the NFA on input w. And you have to be careful on that simulation that you don't end up looping, because don't forget, an NFA could have epsilon moves, and could be looping on those epsilon moves. And so that would be a problem, if you're not careful about how you do that simulation. Now,
1562	I think, if you were going to simulate an NFA, you would be-- wouldn't follow loop around loops forever. And I think you can-- without getting-- because this is not the way I'm going to solve the problem-- you could find a way to avoid getting caught and getting stuck in loops for an NFA. So even though that looks like it could be a problem, in terms of looping forever, it turns out that it won't be a problem-- it wouldn't be a problem if you're careful. But I'm not going to solve it that way anyway, because I'm going to illustrate a different method for solving this problem. And that is we have exhibited before a way of converting NFAs to DFAs. So my Turing machine is going to solve the ANFA problem by converting its input, which is an NFA, to an equivalent DFA. I'm calling the NFA B and the DFA that I got-- converting it into B prime. And what's nice about that is that, first of all, we already know how to do that
1563	conversion, because we essentially went over that in lecture a few lectures back, and it's spelled out in full detail in the textbook. So that is a conversion we know how to do-- we'll assume we know how to do. And we can implement that Turing-- that conversion on a Turing machine. Then, once we have the equivalent DFA, what do we do with that? In the previous slide, we showed how to solve the problem for DFAs. So if we can convert the NFA to a DFA, and then we already know how to solve the problem for DFAs, then we're done. So that's how I'm going to say. We're going to convert the NFA to a DFA, and then I'm going to run that DADFA problem on the new machine that I produced. So remember that the-- this machine here decides the ADFA problem. And now I'm going to accept, if that new machine-- if that previous Turing machine accepts the DADFA problem the machine accepts, and I'm going to basically do whatever it does. If it accepts,
1564	I'll accept. If it rejects, then I'll reject. So I guess the thing that this illustrates is this idea of using a conversion construction inside a Turing machine, and then a previously constructed Turing machine basically as a subroutine. All this is perfectly legal, and it's the kind of thing we're going to be doing a lot of, and that you should be used to doing that-- get ready to be doing that on your homework too. And in fact, I'll give you another a little extra hint that problem 6 can be solved in this way. OK. All right, so here, let's pause briefly. OK, got some interesting questions here coming up-- somebody asked me, do we need to be explicit about how we're going to simulate that NFA or the DFA? Because we don't know how many states it has. You do know how many states it has. Once it's presented to you on the input, you can see, oh, this is a machine that has 12 states-- because you're given the machine, and then you can do
1565	the simulation. Let's see.
1566	power of a Turing machine. That's a question that I'm going to postpone to later, because you're asking if a Turing machine can simulate itself. And we'll talk about things like that, but that's in a few weeks from now, so I'll hold off on that one. Decidable languages-- somebody's asking me a good question about closure properties of the class of decidable languages. Are they closed under intersection, union, and so on? Yes. And the decidable languages are also closed under complement. That should be something you should think about. But yes, that is true. The recognizable languages, however, are closed under union and intersection, but they are not closed under complement. So that we will prove on Thursday's lecture. So another question is, could we have just run B on w in this-- in solving this problem, instead of using reduced-- converting it to a new Turing machine-- the B prime? Well, yes, we could have just done that. OK. I think we better move on. I don't want to get too bogged down here-- got a lot
1567	of questions there, so sorry if I'm not getting to all of the questions. OK. Or you can write to the TAs too, obviously. I'm sure you are.
1568	emptiness problem for DFAs. I'm going to give you now a-- just a DFA-- B-- and no input. And I'm going to ask, is the language of that DFA the empty set, the empty language? You understand the problem, first of all? I'm just handing you in a DFA, and I want to know, does this DFA accept any strings at all, or is it just some dumb DFA-- it's just always very negative DFA, it just rejects everything-- and it has the empty language? How do you tell? Not super hard, if you think about how you would write a program to do that or how you would do it yourself-- so that's a decidable language again. So we're going to give now a Turing machine decider for that language. That decider says, well, I'm giving that DFA-- I want to know if its language is empty. And the idea is just what you would think. I'm going to see, is there a path from the start state of that DFA to the-- an accept state of the DFA?
1569	If there is such a path, then that DFA is going to have an input which goes along that path, and will be accepted. And so the language won't be empty. If there's no such path, then clearly, this DFA can never accept anything, and so this language will be empty. OK. Now, there are many different path algorithms. I think it would be a little bit sparse of me just-- some of you know algorithms. Some of you don't know path checking algorithms. I would like you to just to-- if you were giving this kind of an answer on a homework, to give me some sense of how that algorithm is going to work. Don't be too high level about it. So the one I have in mind is the breadth research, if you've heard of that. But it's very simple algorithm. What I'm going to use is kind of a marking procedure. So I'm going to start by coloring the-- here is this-- I should have indicated-- this is my DFAB. This is B over here. Should
1570	I try taking a chance of writing on this thing-- oops. This is B. Oh, great-- that didn't help. So this is B here. And the way I'm going to test if it has a path-- if it accepts an input is by seeing if there's a path from the start state to any one of the accept states. And I'm going to start it by marking the start state, and then marking all states that I can get to from previously marked states, and keep doing that until I can't get to anything new. There's going to be a series of iterations here marking more and more states until there's nothing new to mark, and then I say, did I mark any accept states? OK, so let's just see how I write that down in English. So I started marking the start state. I repeat until no new state is marked. I'm going to say, mark every state that has an incoming arrow from a previously marked state. Accept-- then, once I'm done with, that repeat loop-- accept if
1571	no accept state is marked, because that means-- don't forget, it's a little bit inverted from what you might think. I'm going to accept if there's no marked accept state, because that means there's no path to an accept state from the start state, which means the language is empty. And EDFA is the DFAs that have empty language, so I should be accepting those. If there's no way to get to an accept state, no accept state is marked. And reject if some accept state earmark, because then the language is not empty. OK, so that's all I wanted to say about that.
1572	something like breadth versus [AUDIO OUT].. The sketchier you are, the more chances that you're going to get caught by the grader, who's not going-- we have an army of people grading these problems, and just to stay on the-- be on the safe side of sketchiness and, say, don't cut too many corners, because you might miss something. Chances are it would be OK just to say breadth research, but I would prefer if-- you'd be safer if you said a little bit more than that. OK. Oh, this is a good question here. Somebody asked, can we just run the DFA on all short-- on all strings? Well, first of all, one thing-- to say something bad would be, well, just feed in all possible strings into the DFA, and if any one of them-- if it accepts any one of them, then we know its language is not empty. Well, that's not a good algorithm, because that's going to potentially run forever, because there's lots of strings. There's infinitely many strings to feed in to that DFA.
1573	And so a Turing machine, if it's trying to be a decider, had better not do any infinite operations that are potentially going to go forever. To be fair to the proposer here, the questioner here-- didn't ask that-- says, well, can we feed in all strings up to some bound, which would be the number of states of the machine in this case? And yes, that would work, but then you would have to argue that that's enough. And yes, it is enough, but it wouldn't-- would not be enough in answering the problem just to say, feed it in that number of them, and we're done. You would have to say why. OK. Lot of questions here-- I'm going to move on.
1574	Let's see. Equivalence problem for DFAs-- now we're going to take things to the next level-- ask, are there two-- I'm going to give you two DFAs. And I want to know, do they describe the same language-- do they recognize the same language? OK? So how are we going to do that? So that's a decidable language. Here's the decider. My input now is going to be two DFAs-- again, represented as a string, because that's what Turing machines deal with as their inputs. But they can unpack that string into two DFAs. And there are several different ways to do this problem, and I'm sure I'm going to get suggestions with other ways to go. One thing you could do is just to feed in strings up to a certain length. Just like before, you can't feed in all possible strings and see if the machines ever behave differently on any of them, because that's an infinite operation, and we already decided we can't do that. Now, if you want to talk about this being a recognizer, instead
1575	of a decider, then you might be able to do something like that just to make sure your-- you have to be just careful. Let me not say more on that right now. But certainly, for a decider, you can't go forever. You can't have infinite operations. So you would have to have a cut-off. So you can feed in all possible strings up to some length, say, into A and B, and see if there's any difference. Now, we actually had a problem on that in the problem set 1, which said, if two DFAs have unequal languages, then they're going to see a difference. Then there's going to be a string which acts differently on them, which is of length, at most, the product of the number of states of those two machines. So you can either reference that problem-- that would be an adequate solution-- or reprove it or whatever. That would be fine. In fact, you can do even better than that, as the optional problem showed. You only have to go up to the sum
1576	of the number of states, not up to the product. But that's actually very difficult to show. I'm not going to prove it that way. I'm going to prove it in an entirely different way, which doesn't require any analysis at all-- no proving something about balance. I'm going to take advantage of something we've already shown, which is I'm going to make a new finite automaton, a new DFAC built out of A and B, which accepts all the strings on which A and B disagree. And I'll show you how to-- that's easy to do. So first of all, let's-- in terms of a picture, let's understand what this is. So here we have-- this is the language of A, this is the language of B written as a Venn diagram. And where are those places where they disagree? Well, they're either in A, but not in B, or in B, but not in A. I'm showing it to you here in terms of the blue region. That actually has a name called the symmetric difference of these
1577	two sets. These are the-- all of the members which are in exactly one out of the two, but not both. If you can make a machine C that would accept all of the strings in the blue region, then what do we do with that machine? We test of its length language is empty, which is what we've already shown how to do-- because of the blue region is empty, that means that L of A equals L of B. So I'm going to make a machine, a DFAC where the language of C is exactly that symmetric difference. It's all the strings in A intersected with the strings that are not in B-- so in A and not in B-- or in B and not-- then not an A-- take the union of those two parts. And how do we know we can make C? Well, we have those closure constructions, which we showed several lectures back. Those closure instructions can be implemented on a Turing machine. So a Turing machine can build the DFAC, and then use
1578	that test from a few slides back, the emptiness-- the last slide-- the emptiness tester for DFAs on C to see whether its language is empty. And now, if C's language is empty, then we know we can accept, because that means the two-- that L of A equals L of B. Otherwise, we can reject. OK? So here's a note-- I'm going to ask you a check-in. You can also use that time to send me a few more questions, if you want. OK, here's my check-in. OK, now, instead of testing equivalence of finite-- of DFAs, I want to test equivalence of regular expressions. So here are R1, R2. Regular expressions are called the EQ regular expressions
1579	equivalents of regular expressions. Can we now conclude that this problem is also decidable, either immediately from stuff we've already shown; or yes, but would take some significant extra work; or no, because intersection is not a regular operation? So let's see if I can pull that out here-- launch the polling. Here we go. OK, I think we're just about done here. Five seconds more-- OK, ready, set, end. All right. Yes, the correct answer is A. We have basically already shown this fact, because-- why is that? Because we have shown that we can convert-- if you're given two regular expressions, and we want to test whether they're equivalent, they generate the same language, we can convert them both to find out automata. We can convert them to NFAs, and then the NFAs to DFAs. And then we can apply what we've just showed about testing equivalence of DFAs. So yes, it really follows immediately from stuff we've already shown-- the conversion, number one, and then the testing of equivalence for DFAs. So there's not really any work
1580	to do here. And in fact, what I'm trying to illustrate with this check-in-- that, once you've shown how to do some kind of a test for one model, it-- going to apply for all of the equivalent models that we've shown to be equivalent, because the Turing machine can do the constructions which show the equivalence. OK, so let's move on. Somebody didn't get the poll. Did most people not get the poll? Well, I think most of you have gotten it. Did you? I'm not seeing a lot of complaints. So if you didn't get the poll, something is wrong with your setup, and you're going to have to take the recorded check-ins that are going to launch right after this lecture's over. Sorry. But you should figure out what's wrong with the setup there, because I think most people are getting these. OK, and with that, we're going to take a little break, and then we'll continue on afterward. Let me know how this is-- should I be speed a little speedier about the little mini breaks
1581	that we're taking, or is this good for you? Feedback is always-- I'm trying to make this as good as I can for all of you. OK, I think there's a mixture of between people saying that these breaks are good. Someone says they're a little overlong, so I'll try to tighten them up a little. Some folks are saying what-- more people should be asking the TAs. I don't know how the TAs are doing, in terms of their-- I'll check with them afterward-- how well this is going for them, in terms of the questions. But I think some amount of break is good so that we don't-- so there's time to be asking questions. Otherwise, what's the point of having a live lecture? So we will start promptly when this timer runs down. So be ready to go in 55 seconds from now. Just to confirm, to show the decidability of the equivalence of two regular expressions, do we need to show that we can use a Turing machine to convert them to two DFAs first? If
1582	you want to test whether two regular expressions are equivalent, you can give any procedure for doing that deciding you want. I'm just offering one simple way to do it that takes advantage of stuff we've already shown. But if you want to dig down and do some analysis of those regular expressions to show that they describe the same language, they generate the same language, be my guest. I think that's-- actually would be complicated to do that that way. OK, so we're just about ready to go here, so let's continue. And let me take this timer off here. All right. Now, we are going to talk a little about context-free grammars. So we talked about decision problems for finite automata. Let's talk about some for grammars. OK, now I'm going to give us an analogous problem. I'm going to give you a-- I'm calling it the acceptance problem, but-- just for consistency with everything else, but it's really the generating problem. So I'm giving you a grammar-- context-free grammar G and a string that's in a string.
1583	And I want to know, is it in the language of G? So does G generate w? I'm calling that the ACFG problem. So that's going to be a decidable again. These are getting slightly harder as we're moving along, so I'm giving you a grammar and a string, and I want to know, does the grammar generate that string? Well, it's not totally trivial to solve that. One thing you might try doing is looking at all possible things, all possible derivations from that grammar and see if any one of them leads to w-- leads you to generate w. Well, you have to be careful, because as I've-- as we've shown in some of our examples, you actually could have-- because you're allowed to have variables that can get converted to empty string, you might have very long intermediate strings being generated from a, grammar which then ultimately give you a small string of terminals that get generated, a small string in the language that gets produced. You certainly don't want to try every possible derivation, because there's
1584	infinitely many different derivations-- most of them generating, of course, things that are irrelevant to the string w. But you have to know how to cut things off, and it's not immediately obvious how you do that-- unless you have done the homework problems that I asked you to do, which I'm sure very many of you have not done-- the zero point X problems, because they're-- that's going to come in handy right now. And so I'll help you through that. Remember-- you should remember, but you may not have looked at it-- something called Chomsky normal form, which is for context-free grammars, but only allows the rules to be of a special kind. And they have to look like this. They can be a variable that goes to two variables, on the right-hand side, or a variable that goes to a terminal. Those are the only kinds of rules that you're allowed. This is a special case for the empty string, but let's ignore that for-- the start variable can also work to the empty string, if you
1585	want to have a-- the empty string in a language. But that's a special case. Let's ignore that. These are the only two kinds of rules that you can have in a Chomsky normal form grammar. Once you have a Chomsky normal form grammar-- well, first of all, there's two things. First of all, you can always convert any context-free grammar into Chomsky normal form. So that's given in the textbook. You do the obvious thing. I'm not going to spend time on it. And you don't have to know it. It's just a little bit tedious, but it's straightforward and it's there, if you're curious. But the second lemma's the thing that's important to us, which is that, if you have a grammar which is in Chomsky normal form and a string that's generated, every derivation of that string has exactly 2 times the length of the string minus 1 steps. If you think about it, this is a lemma-- very easy to prove. I think the homework problem asks you to prove that in the 0.2 or whatever
1586	it was in problem set 1-- or problem set 2-- I don't remember. Rules of this kind allow you to make the string one longer, and rules of this kind allow you to produce a new terminal symbol. If the length w is n, you're going to have n minus 1 of these and n of. Those that's why you get 2n minus 1 steps. But the point is that I don't really care exactly how many. It's just that we have a bound. And once you have that bound, life is good from the point of view of giving a Turing machine which is going to decide this language-- because here's the Turing machine. What it's going to do-- the first thing is it's going to convert G into Chomsky normal form. That we assume we know how to do. Now, we're going to try all derivations, but only those of length 2-- twice the length of the string minus 1, because if any derivation is going to generate w, it has to be this many steps, now that
1587	we know the grammar is in Chomsky normal form. OK, so we have converted this problem of one that might be a very unboundedly lengthy problem and to one where it's going to terminate after some fixed number of steps. And so therefore, we can accept, if any of those generate w, and reject if not. OK? Before moving on, so this answers the problem-- shows that this language is decidable, the ACFG language. So that's something that-- make sure you understand. We're basically trying old derivations of up to-- of a certain length, because that's all that's needed when the grammar is in that form. Now we're going to use that to prove a corollary, which is important for understanding how everything fits together. And that corollary states that every context-free language is a decidable language. Every context-free language is decidable. Now, why does that follow from this? Well, suppose you have a context-free language. We know that language is generated by some context-free grammar G. That's what it means. So then you can take that grammar G and
1588	you can build it into a Turing machine. So there's going to be a term machine which is constructed with the knowledge of G. And that Turing machine is going to take its w and run the ACFG algorithm with w combined with a G that's already built into it. So it's just going to stick that grammar G in front of w, and now we run the ACFG decider. It's going to say, does degenerate w? Well, that's going to be yes every time w is in A. And so this machine here now is going to end up accepting every string that's in A, because it's every string that G generates. So that is, I think, what I wanted to say about this. Now, I feel that this corollary here throws a little bit of a curveball. And we can just pause for a moment here just to make sure you're understanding this. The tricky thing about this corollary is-- that I often get-- a question I often get where-- is when we start off with a context-free
1589	language, who gives-- how do we get G? Because we need G to build a Turing machine M sub G. So we know A is a context-free language, but how do we know what G is? Well, the point is that we may not know what G is, but we know G exists, because that's a definition of A being a context-free language. It must have a context-free grammar, by definition. And so because G exists, I now know my Turing machine, M sub G, exists. And that's enough to know that A is decidable, because it has a decider that exists. Now, if you're not going to tell me the grammar for G, I'm not going to tell you the Turing machine which decides A. But both of them exist. So if you tell me G, then I can tell you the Turing machine. So it's a subtle, tricky issue there. A certain little element maybe of-- sometimes people call it non-constructive, because we're just, in a sense, showing just that something is existing. It does the job for
1590	us, because it shows that A is a decidable language. OK, so not so many questions here-- maybe the TAs are getting them. So let's move on. Here's another check-in. So now, can we conclude that A-- instead of ACFG, APDA is decidable? People are getting this one pretty fast. Another 10 seconds-- three seconds-- OK, going to shut it down-- end polling, share results. Yeah. So this problem here is APDA is decidable. I was almost wondering whether or not to give this poll, because it has-- it's true for the same reason as poll number 1, because we know how to convert PDAs-- or we stated we can convert PDAs to CFGs. And that conversion has given in the book. We didn't do in lecture, but I just stated you have to know that fact, but not necessarily know how to do it. That's OK. But the fact is true. The conversion is in the book, and it could be implemented on a Turing machine. So if you want to know whether a PDA's language is empty, you
1591	convert it to a context-free grammar and then use this procedure here to test whether it's a language--
1592	The acceptance problem-- I just want to know, does the PDA accept some input? I'm saying it wrong. So I want to know, does the PDA accept some input? I convert that PDA to a grammar, and then I see if the grammar generates that input, because it's an equivalent grammar. So again, this is using the fact that grammars and PDAs are equivalent and convertible from one to another, just like regular expressions and DFAs from the previous poll. So you need to be comfortable with that, because we're going to not even talk about it anymore. We're just going to be treating those things-- going back and forth between them without sometimes even any comment. OK.
1593	Emptiness problem for CFGs-- hopefully you're getting comfortable
1594	So now the emptiness problem for context-free grammars-- I'm just going to give you a grammar, and I want to know if its language is empty. OK, so remember, we did this for finite automata by testing a path. We don't really have paths here. You might think testing paths and pushed automata. That's not going to really work, because the stack is there. So how are we going to do that test? Well, there's something sort of like testing a path, just working with the grammar itself, kind of working backwards from the terminals now. I'll illustrate that here. Here's a very simple grammar, and I want to know, does it generate any strings? Obviously, only care about strings of terminals, because those are the things that are in the language-- so does this grammar generate any strings of terminals? So way we're going to answer that is by a marking procedure, but in a sense, we're going to start from the terminals and work backwards to see if we can get to the start variable. So first, we're
1595	going to mark all the terminal symbols, and then we're going to mark anything that goes to a string of completely marked symbols, either terminals or variables-- because anything that's marked, we know, can derive a string of terminals. That's what it means. Anything that's blue can derive a string of just terminals. And so now, if you have a collection of those that are all marked, they together can generate some string of terminals together. And so then you can mark the associated variable. So T goes to a. So that may be oversimple, but we're going to mark T here everywhere in the grammar. So all these T's are going to get marked, because we know that T can generate a string of terminals. Now let's take a look at R. R is going to a string of symbols that are all marked, and that means those symbols can, in turn, generate strings of terminals. So we're going to mark R2. We can't yet mark S, because we don't know yet whether S has some unmarked thing that
1596	it goes to. So we don't know yet whether S can generate a string of terminals. But R we know right now, so we're going to mark R. But then now that gets us to mark this R, and so then we can go backwards and we can mark S. And we keep doing that until there's nothing new to mark. And here we've marked everything, so clearly there's nothing more you can mark. But you might stop before you've marked everything. And then you see whether you've marked the start variable or not. And if you have, you know the language is not empty. OK, so let's just go through this in text. Mark all occurrences of terminals in G, then repeat until no new variables are marked. We mark all occurrences of variables A, if A goes to a string of symbols, and all of those symbols were already marked, because those are the things that already have been shown to generate a string of terminals. And so now we're going to reject if the start date-- start
1597	variable's marked-- because that means that the language is not empty-- and accept if it's not. OK? I'll take a couple of quick questions here. OK, somebody asked whether-- if I understand-- are the regular languages also decidable? Well, remember, the regular languages are context-free languages, and the context-free languages are decidable, so yes, the regular languages are decidable. Some of those are going to be too long to answer, and they're trying to come up with alternative solutions. So I think we're going to move on. All right. Just like we did for the finite automata, we talked about acceptance, we talked about emptiness, we talked about equivalence. So how about the equivalence problem for context-free grammars? I'm going to give you now two context-free grammars, and I'd like to know, are those two context-free grammars generating the same language? OK, so how might you think about that? Well, one thing-- following some of the ideas that we've already had, you could try feeding strings into those grammars. You know how to test whether those individual grammars can generate
1598	those strings, so you can just try feeding strings in to G and to H, and seeing whether those grammars ever disagree or whether they generate some string. Find some string that say G generates, but H does not generate. And we can test that string by string. Unfortunately, we got a lot of strings to test. We would need to give some bound if we were going to use that procedure-- not clear what the bound is. Another idea might be to use the closure construction that we had from before. So let's mull that over-- whether that might work. But in fact, let me give away the answer here. This language is not decidable. There's no algorithm out there-- no Turing machine, but therefore no algorithm-- which can take two grammars and test whether they generate the same language or not-- seems, at first, glance kind of surprising. Such simple things as context-free grammars can nonetheless be so complicated that there's no procedure out there which can tell whether the two-- those two grammars generate the same language.
1599	We will show that next week. A related problem, which is related to your homework-- this that's due on Thursday-- is testing whether a grammar is ambiguous. So given a grammar, I'd like to know, is that grammar an ambiguous grammar or not? Does it generate some string in the language of that grammar in two possibly different ways, two or more different ways? So is there some string that can be generated with two different parts. So the problem with testing whether grammar is ambiguous-- not decidable. So I'm asking you to do something hard, when you have to produce that grammar which is unambiguous for that language. In general, testing whether a grammar is ambiguous or is not a decidable problem. Now, hopefully the grammar that you'll produce to show that-- that unambiguous grammar for that language that I'm asking you to produce is not going to require our graders to solve some decidable problem, but it'll be clear based the construction of that grammar why it's not ambiguous. So you'll have to hopefully say some explanation of
1600	your thinking there. OK. And we will prove that the problem of testing ambiguity is not decidable. That's going to be a homework problem in problem set 3. OK. Last check-in here-- something that I alluded to, but didn't quite-- didn't want to give away. Why not use the same technique that we use to show equivalence of DFAs is decidable, to show that equivalence of context-free grammars is desirable? Obviously, something goes wrong because EQCFG is not decidable. Why doesn't that same technique just work? Well, what's the answer? Got a real race here-- another 15 seconds-- this one gives you something to mull over. All right. Let's end it. OK, you're good to go. At least click something. OK, ending polling, sharing results-- OK, bunch of you have thought, well, CFGs are generators and DFAs are recognizers, and that's the issue. Well, not really, because we could test equivalence of regular expressions-- those are generators. It's nothing to do with being a generator or not, because we can convert regular expressions to DFAs and then test equivalence for
1601	the DFAs, so that-- it's not really a matter of being generated. That's not the issue. The issue is that we can't follow the same construction that we did to show EQDFA is decidable, because the context-free languages are not closed under those operations we needed to make that symmetric difference machine-- if you remember how that worked. So they're not closed under implementation and not closed under intersection. We needed both in order to build that machine C, which accepted all the strings that are in the difference. OK?
1602	Let's move now to Turing machines. This is where stuff is really going to start to get interesting-- hope it's been interesting all along, but maybe even more interesting.
1603	for Turing machines, ATM. This language is going to become an old friend, but we're just getting to know it. So this is the problem. You're given a Turing machine now, and an input, and I want to know, does M accept that input? Does that Turing machine accept its input? OK, so that's going to not be a decidable problem either. So we've shifted gears from a bunch of decidable things to a bunch of undecidable things. So this is not a decidable language. We will prove that on Thursday. That's going to be the whole point of Thursday's lecture is proving the ATM is decidable. And that's going to be really a jumping off point for showing other problems are decidable. So that's going to be our first proof of decidability. But we do know that ATM is recognizable, and that's worth understanding-- for multiple reasons, but for one thing, it's going to give us an example of a problem which we know is recognizable, but not decidable, as we'll prove undecidability. But it's also, I think, of
1604	historical importance, this algorithm for showing-- recognizable. So let's go through that algorithm. It's very simple, sort of doing the obvious thing. The following Turing machine-- I'm going to call it U, for a reason that I'll make clear in a second. That's going to be a recognizer for ATM. So it takes as input an M and a w, and it's just going to simulate M on w, pretty much the way the algorithm the decider for ADFA work. But now the machine-- instead of being a DFA, it's a Turing machine, and the Turing machine might go forever. And so the simulation may not stop. And that's the key difference, which makes it from a decider into a recognizer. So you're going to be simulating, just keeping track of the tape of M, the current state of M, where-- and proceeding to modify the tape as M modifies it. And then, if M enters an accept state, then you know M has accepted its input, so U also will enter an accept state. So the machine U enters
1605	the accept state if M observes during the simulation that M enters an accept state. Furthermore, if an M enters a reject state, then U also enters a reject state. OK? Now I'm going to say something beyond that, which I want you to pay attention to, which is the kind of thing I do see sometimes people saying. We want U to reject if M never halts. That's also-- seems like what we want, because if it never halts, then M is rejecting by looping, so you should also reject. But I don't like that. I don't like that line here, step 4 of the Turing machine, because there's no way for a Turing machine to determine-- or at least as we-- no obvious way-- and in fact, there will not be any way, but certainly, at this point, no obvious way for M to even tell-- for U you to tell whether M is halting or not. Well, certainly you can tell that it's to say it never halts. How can you make that determination? If I saw
1606	this on a solution, either on an exam or a homework, I would mark you off. This is no good. It's not illegal to Turing machine action. If M does not hold on w, then you should reject. That is correct. And you can make that reasoning external to the algorithm of U, but U is going to end up rejecting, because it never holds either. It never actually knows that M is rejecting w in that case, if M is rejecting by looping. It's just blindly going along and doing the simulation of M on w-- and will end up halting-- rejecting by looping, if M is rejecting by looping. But that's something that you can argue if you need to make a proof or make some sort of reasoning about the machine, but it's not part of the algorithm of the machine. OK. Now, what's, I think, from a historical standpoint, that's interesting about this machine U and why I'm calling it U is because this appeared-- this machine U appeared in Turing's original paper where he laid
1607	out Turing machines. He didn't call them Turing machines, by the way. He called them computing machines. People afterward called them Turing machines. But Turing called this the universal computing machine. That's his language. Actually, I just looked at the paper yesterday just to refresh my memory of it. And he gives the description of the operation of U in gory detail, with all of the transitions and the states. He nails the whole thing down-- takes pages, and pages, and pages. So he it gives it there.
1608	universal Turing machine. It's more than just an idle curiosity that this appeared in Turing's paper, because this actually turned out to be profoundly influential in computer science, because it really was the first example of a machine that operated based on a stored program. It really was a revolutionary idea. In those days, if you wanted to make a machine that did something different, you had to wire the-- rewire the machine. But here's a machine that operated based on instructions. And instructions, in a sense, are no different than the data.
1609	come to be known as the von Neumann architecture, but von Neumann himself gave credit to Turing machine for having inspired him to think of this. And some people argue that it's really-- calling it the von Neumann-- bunch of people came up with this concept around the same time, maybe other people too. There's Babbage and so on, and others who-- Ada Lovelace-- also who came up with notions of programming, but I think it's a little different than this, in concept. But anyway, this nevertheless played an important role in the history of the subject. So with that, I think we're out of time. I'm going to quickly review where we've been. So we just showed the decidability of various problems. These are all languages that we showed are decidable. We showed that ATM is Turing-recognizable, and I think that was all we had for today. So I will stop right here. I will stick around and take a few questions, and our TAs can take a few questions, if you want, by chat. And then I also
1610	have my office hours, which will start in like five minutes or so, once I get everything set up on my end. OK, somebody wanted me to review this point here, which I'm happy to do. This code here that I'm describing in English needs to be something that you can implement on a Turing machine. We're never going to go through the effort of building the transition functions, and the states, and so on, but we need to be sure that we could, if we had to. And how could you make a Turing machine do the test that M doesn't halt? That's something we don't know how to do. I can see if M halts. During the simulation, I can see that M has entered the Q reject state or the Q accept state, so I can tell while I'm simulating that it has halted. But how would the machine, or how would you know that M is now-- someone says, well, do x if M never holds. Well, how do you know M-- how can you do
1611	the test that M is not halting? There's no obvious way to do that. In fact, there is no way to do that. But as it stands right now, the proof would be on you to show how to implement that on a machine, and there's just no obvious way to do that. So I think that's why you should only put down things here which you're sure you could implement, even if it might take a long time. So you don't have to worry about how long it would take, but you have to put things down that you are sure you could at least implement in principle. OK, so someone has asked me about the equivalence problem for context-free grammars being unsolvable. Why couldn't the machine be a human level system of logic so that the computer could logically deduce whether or not it was decidable? We're taking a turn into the subject of mathematical logic, which is supposed to formalize reasoning in a way. In the end, what it really has come down to-- that there are
1612	certain grammars which are equivalent to one another, but there's not going to be any way to prove that they're equivalent in any reasonable system. Inequivalence you can always prove. You can exhibit a string that one-- you can show that this grammar's generating it, this grammar's not generating. This other one is not. So inequivalence you can always prove, but equivalence-- there are going to be certain pairs of grammars which are going to be beyond the capability of any reasonable formal system to be able to prove that they're equivalent, because you can even convert-- make those grammars into something which talk about the system itself, ultimately. You're going to end up with a Russell paradox kind of thing. That's maybe going beyond more than you want to know, and I'm happy to talk about it offline. But there's just no way to make a Turing machine which is going to implement human reasoning, and then get the right answer on all pairs of grammars-- just cannot be done. Goodbye. I'm going to shut down the meeting now.
1613	MICHAEL SIPSER: Hi, folks. Why don't we get started? Welcome back. Good to see you all here. So I am going to first-- well, we'll recap what we did last time and what we're going to do today. I'll talk a little bit about the problem set. And we'll also have a break, as requested, halfway through. So why don't we jump in? What we did last time was besides introducing the course, we introduced finite automata in regular languages, which are the languages that the finite automata can recognize. We talked about these regular operations. Those allow us to build what we call our regular expressions. These are ways of describing languages. So we have finite automata can describe languages, and regular expressions can describe languages. And one of our goals is to show that those two systems are equivalent to one another, even though they look rather different at first glance. So to move in that direction, we're going to prove closure properties for the class of regular languages over these regular operations. So we'll show that-- well,
1614	we already showed that any two regular languages have their union, also being regular. And we'll show that for the other two operations as well. So let's just look ahead to what we're going to do today. We're going to introduce an important concept which is going to be a theme throughout the course, called nondeterminism. And having that as a tool that we can use, we'll be able to show closure under concatenation and star, finishing up what we started to do last time. And then we'll use those closure constructions to show how to convert regular expressions to finite automata. And that's going to be halfway to our goal of showing that the two systems are equivalent to one another. And the following lecture, we will show how to do the conversion in the other direction.
1615	return to the material of the course. As you remember, we were looking at the closure properties for the class of regular languages. We started doing that. And if you recall, hopefully, we did closure under union. And then we tried to do closure under concatenation, which I have shown here on this slide, the proof attempt that we tried to do last time. And let's just review that quickly, because I think that's going to be helpful to see how to fix the problem that came up. So if you remember, we're given two regular languages, A1 and A2. And we're trying to show that the concatenation language A1A2 is also regular. And so the way we go about all of these things is we assume that A1 and A2 are regular. So that means we have machines, finite automata, for A1 and A2. We'll call them M1 and M2, that recognize A1 and A2, respectively. And then what we need to do in order to show the concatenation is regular is to make a finite automaton which recognizes
1616	the concatenation. And we tried to do that last time. So if you remember, that concatenation machine-- M, we're calling it-- what is it supposed to do? It's supposed to accept its input if it's in the concatenation language. And that means that the input can be split into two parts, x and y, where x is in the A language, and y is in the B lang-- y is accepted by M1-- and x is accepted by M1, and y is accepted by M2. Sorry I garbled that up. So x should be in A1, and y should be in A2. if you can split w that way, then M should accept it. So M has to figure out if there's some way to split the input so that the first machine accepts the first part, the second machine accepts the second part. And the idea that we came up with for doing that was to take these two machines, build them in to a new machine M, and then connect the accepting states for M to the start
1617	state-- connect the accepting states for M1 to the start state for M2. Because the idea would be that if M1 has accepted an initial part, well, then you want to pass control to M2 to accept the rest. But as we observed, that doesn't quite work. Because the first place to split w after you found an initial part that's accepted by M1 may not be the right place. Because the remainder may not be accepted by M2. You might have been better off waiting until you found another place that M1 accepted, later on in the string, say, over here. And then by splitting it over there, then maybe you do get successfully find that the remainder is accepted by M2. Whereas if you tried to split it in the first place, the remainder wouldn't have been accepted by M2. So all you need to do-- M has to know, is there some place to split the input so that you can get both parts accepted by the respective machines? The problem is that M might need to
1618	know the future in order to know where to make the split. And it doesn't have access to the future. So what do we do? So what we're going to do is introduce a new concept that will allow us to basically get the effect of M1-- and the-- sort of being able to see the future. And that new concept is going to be very important for us throughout the term.
1619	And so we're going to introduce a new kind of finite automaton called a nondeterministic finite automaton. And first, we'll look at that, and then we'll see how that fits in with the previous deterministic finite automaton, that we introduced last time. So here's an example. It's always good to start off with an example. Here is a picture of a nondeterministic finite automaton. It looks very similar, at first glance, to the former kind, the deterministic finite automaton. But if you look a little carefully, you see that there are some key differences. The most important difference is that in state q1, for example, whereas in the machines that we introduced last time, there had to be exactly one way to go on each possible input symbol so you knew how to follow along through the machine it's computing, here there are two ways to go. In q1, you can either stay in a1, or you can go to q2. That's the essence of nondeterminism. There could be many ways to proceed. And furthermore, on q1, if you get
1620	a b, then there's nowhere to go. So that's also possible within nondeterminism. So let's just start looking at these features. There are multiple paths forward-- multiple paths possible. You might be able to have one, as we had before, or many ways to go at each step, or maybe 0 ways to go at each step. Those are all legitimate for a nondeterministic machine, which is doing a nondeterministic computation. Another difference, if you look carefully, is that we're allowing here the empty string to appear on a transition. That's perhaps a little less essential to the spirit of nondeterminism. But it's going to turn out to be a convenience when we actually apply nondeterminism to build machines, as you'll see very shortly. Now, if there are many different ways to go-- and some of those ways to go might have different outcomes. As we remember from before, we accepted the input, if you end up in an accept state, and we rejected the input, if you end up not in an accept state, in a non-accepting state. Then
1621	you reject. But now there might be several different ways to go. And we'll do an example in a minute. But there might be several different ways to go. And they might disagree. Some of them might accept. Other ones might reject. So then what do you do? Well, in that case, acceptance always overrules rejection. That's the essence of nondeterminism the way we're setting it up. You may ask why that is. And the spirit of that will become clear in due course. But right now, just take it as a rule. When we're having a nondeterministic machine, acceptance overrules rejection. So as long as there is-- one of the possible ways to go ends up at an accept, we say the whole thing is accepted. The only way we can possibly reject-- if all of the possible ways to go end up at rejection, end up at a non-accept state. So we'll see example of-- I think we're going to do an example right now, yeah. So if we take, for example, this machine N1 now on an
1622	input ab-- and we're going to process the symbols one by one, just like we did before. But now, to follow along, there might be several different ways to go. So if we take the first symbol a, and we run the machine-- so when the machine, it starts at the star state, as before-- but now an a comes in. And there might be two-- now there are two different ways to go. So we're going to keep track of both of them. After the machine reads an a, you can think of it as being in two states now simultaneously. It can be in state q1, and it can be in state q2. So those are two different possible places it could be at this moment. OK? Now we read the next symbol, the b. And from a b, you take each of the places where the machine could be at the end of the previous symbol, and you then apply reading a b, the next symbol, from each of those states where the machine could be in
1623	from the previous symbol. So the machine could be in q1 and q2 after reading an a. Now we apply a b. Well, q1 on a b goes nowhere. So you think of that branch, if you will, of the computation as just dying off. It has nowhere to go. It just vanishes. However, the other possibility, which was state q2 on a b, does allow, does have a place. So the machine is now going to go from q2 to q3 on that branch of the computation, which reading-- on reading a b. And then it has, coming out of q3, there are two symbols. There's an a and an empty string symbol. Now, on an a, the machine would have to read an a in order to transition along that arrow. But when there's an empty symbol on the arrow, that means the machine can go along that arrow for free without even reading anything. As long as it gets to q3, it can automatically jump the q4. And so once it has read a b and gone
1624	to q3, now it can either stay in q3, or it can go along the empty transition and go to q4. So again, it is going to be a nondeterministic step at this point. The essence of having a empty transition is that there is going to be nondeterminism. That's why we didn't introduce that for deterministic automata, because you don't have to transition along an empty string transition. You can stay where you are, or you can go along the empty string transition without reading any input and go over to the next state, which, in this case, is q4. So let's just see where we are. After reading an a, we're in states q1, q2. But now after reading a b, we're in states q3 and q4 as possibilities. And now we're at the end of the input, and we look and see what we got. If any one of the states as possibilities that we are right now at the end of the string is an accept state, then we say, overall, the machine has accepted. So
1625	that corresponds to what we said over here before-- accept the input if some path leads to an accept. So if any way of proceeding through these nondeterministic choices will lead you to an accept, then you will say, we're going to accept the input. OK? So this input here is accepted. Let's do another example. Suppose we have the input aa instead of ab. So aa, after the first day, as before, we're in states q1 and q2 as possibilities. Now we read an a again. Now, the one that's on state q1, that possibility, q1 possibility, after reading an a, it again branches to q1 and q2. So we know after reading the second a, we're going to be in at least q1 and q2. Now how about the state that had been on q2 on reading an a, the one from before? After reading the first a, you were in q2. Now reading the second a, there's nowhere to go. So that one just gets removed. So after reading aa, we remain in states q1 and q2
1626	as possibilities. Neither of those are accept states. So therefore, on input aa, the machine rejects. OK? Let's just do a couple more, and then I'll ask you to do one. So we have aba as an input. Let's see what happens then. So remember, after reading ab, the machine is in the two states q3, q4 as possibilities. That's what we have from the first example. So after reading ab, we're in states q3, q4. Now we read another a. The q4 on an a has nowhere to go. In fact, it has nowhere to go in any input. So no matter what comes in after you're in state q4, that branch dies. But on q3, which is another one of the possibilities reading an a, it can follow along, just transition. Because that's one of the labels on that transition, is a. So you can follow along just in transition on reading an a, which is the last symbol in the string. And so now after aba, you are in only state q4 as a possibility. But that
1627	happens to be an accept state, so the machine accepts. OK. And now lastly, let's take our final example. What happens if we have abb? So as we remember before, after reading ab-- that was the first example-- we were in states q3, q4 as possibilities. Now we read a b. Well, neither of those states have anywhere to go on a b. So now all threads, all branches, of the computation die off. And at this point, the machine is totally dead. It has no active possibilities left. So certainly, it's going to reject this input, because none of the active states-- there are no active states or accepting states. And in fact, if you looked at anything that came later, anything that extended the string abb would also be rejected. Because once the machine had all-- all possibilities have died off, there's no way for them to come back to life on any extensions. So with that-- oh, here's an important point before I'm going to jump to a check-in on you. But I think one thing that
1628	might be on your mind about this nondeterminism is how does that correspond to reality? Well, it doesn't. We're not intending for nondeterminism as we're defining it to correspond to a physical device. But nevertheless, as you'll see, it's a very mathematically useful concept, this nondeterminism. And it's going to be playing a big role throughout the subject as we'll experience it during the rest of the term. So with that, I'm going to have a little check-in. I'm going to ask you to consider what happens on one of the inputs. So here we go. What does it do on input aab? So here's the machine. You can look at it. And suppose, hopefully, there's a poll here for me to give to you so you can give me your input. So what does the machine do on input aab? Most of you have answered. Again, you're not going to be penalized for getting the wrong answer. But hopefully, you'll get the right answer. Anyway, let's just take a look here. So time is up. Let's end the polling
1629	and share the results. So the majority of you, majority have gotten the correct answer, which is a. The machine does accept aab. Because when you have a-- so I'll show you the path that corresponds to accepting. You go a, a, b, and then empty string. And so that sequence of steps is one of the nondeterministic possibilities that the machine can follow. And that shows that the machine does accept the input aab. You can think about it, the way we did it before also. If you read an a, it's in the two possibilities q1, q2. You read a second a, again, in the possibilities q1, q2. Now you read a b. It's in the possibilities q3, q4. And that's it, aab. So now you read the b. It's in possibility q3, q4. q4 is an accepting state. That overrules the non-accepting state. And so the machine accepts. You have to understand this. So if you didn't get it right, go back and think about where you slipped up. OK? Because this is just getting-- we're just
1630	getting warmed up here. It's going to get a lot harder. OK, so stop sharing the results.
1631	So just as we did last time, we can formally define a nondeterministic finite automata. Here's the picture again. OK. So it looks a lot like the case we had before, the Deterministic Finite Automata, or DFA, as we'll call them. It's a 5 tuple. So I've written down little reminders for what those components of that 5 tuple are, that list of five components. So they're all the same as before-- states, alphabet, transition function, start state, and accepting states. So that the formal definition looks exactly the same except the structure of the transition function. So now, before, if you remember, you had a state and an input symbol, and you got back a state. Now we have something more complicated-looking. We have a state and an input symbol, but instead of just sigma, it's sigma sub epsilon. And that that's a shorthand for sigma union epsilon. And that's a way-- my way of saying that you're allowed to have on your transition arrows either an input symbol or an empty string. So the transition function has to
1632	tell you what to do when you have an empty string coming in as well. So that would be part of your table for the transition function. Now, over here, what's going on over here? Well, now, instead of just producing a single state, when you've read, for example, an a from q1, there's a whole set of possibilities. So here we have what's called a power set. That's the set of subsets of the collection Q. So here we're going to produce an entire subset of states. Instead of just one state coming out, there might be a subset of possible states that you can go to. So the power set of Q is a set of subsets of Q. So that's what this notation means. Again, this is something that I'm, hopefully, presenting to you as a bit of a reminder. You've seen this somewhere else before. But please make sure you understand the notation, going forward, because we'll be doing less hand-holding as we start moving forward. OK. So just let's take a look. In the N1
1633	example here, just to illustrate what's going on, when you're in state q1 reading an a, now you get a whole set of possibilities, which, in this case, is q1 and q2. Whereas, if you're reading a b, what would be that set? Coming out of q1, what's the set of possible successor states? Well, there are none. So it's the empty set. OK? So hopefully, you're understanding the notation here. So now here's, I think, really important. How do we understand nondeterminism, intuitively speaking? And there are multiple different ways, which each has their value under different circumstances. So one way is thinking about nondeterminism as a kind of parallelism. So every time the machine has a nondeterministic choice to make, where there's more than one outcome, you think of the machine as a branching, forking, new threads of the parallel computation at that stage, where it makes an entire copy of itself when there's a choice of possibilities. And then each of those independently proceeds to read the rest of the input as separate threads of the computation.
1634	So if you're familiar with parallel computing, this should be reasonably familiar to you. The only key thing to remember is that as this thing forks a number of possibilities, the acceptance rule is, that if any one of those possibilities gets to an accept at the end of the input, it raises a flag and says, accept. And that overrules everybody else. So acceptance dominates. So another way of looking at it is the mathematical view, where you can imagine-- and we're going to use all these. So you really need to understand them all. The mathematical view is you can think of the computation as kind of a tree of possibilities. So you start off at the very beginning at the root of the computation, which is when it really begins. But every time there's a nondeterministic branching that occurs, that node of the tree has multiple children coming out of that node. And so the different threads of the computation correspond to different branches of that tree. And now you're going to accept if any one of
1635	those branches leads to an accepting state-- OK, obviously, somewhat similar to what we had before. But I think it's a little bit of a different perspective on how to think about nondeterminism. And the last one is going to sound a little weird. But actually, I think for people who are in the business, it's the one they use the most. And that's the magical way of thinking about nondeterminism. And that is, when the machine has nondeterministic choices to make, you think of the machine as magically guessing the correct one at every stage, and the correct one being the one that will eventually lead it to accept. OK? So you can think of the machine as guessing which is the right way to go. And if there is some way right way to go, it always guesses right. Of course, if the machine ends up rejecting, because there is no right way to go, then it doesn't matter. There is no good guess. But if there is some good guess, we'll think of the machine as taking
1636	that good guess and going that way. OK. So now here is a very important thing. We introduced this new model, the Nondeterministic Finite Automaton, NFA. It turns out, even though it looks more powerful, because it has this nondeterminism, it isn't any more powerful. It can do exactly the same class of languages, the regular languages. And we'll show that with this theorem here, that if an NFA recognizes a, then a is regular. So we'll prove that by showing how to convert an NFA to an equivalent DFA, which does the same language. So we can take an NFA that has the nondeterminism and find another DFA which doesn't have nondeterminism, but does the same language. It accepts exactly the same strength, even though it lacks that nondeterministic capability. This is going to be extremely useful, by the way, and for example, in showing that closure under concatenation. OK, so in this presentation here, I'm going to ignore the epsilon transitions. Because once you get the idea for how to do this, you could figure out how to
1637	incorporate them. They just make things a little more complicated. So let's just focus on the key aspect of nondeterminism, which is that the machine could have several ways to go at any point in time. There could be several next states on an input. OK? Now the idea for the construction-- so we're going to start with a nondeterministic machine M, and we're going to build a deterministic machine M prime, which does exactly the same thing. And the way M prime works is it's going to do what you would do if you were simulating M. What would you do? This is what we were doing as I was explaining it to you. If you were simulating M, every time you get an input symbol, you just keep track of what is the set of possible states at that point in time. That's what the DFA is going to do. it's going to have to keep track of which possible set of states the NFA could be in at the point on that input where we are right
1638	now. And then as you get to the next symbol, the DFA is going to have to update things to keep track of the next set of states the NFA could be in at this point, just like you would do. OK? And so here's a kind of a picture. And how do we implement that? So here's the NFA that we're starting with, M, and we're going to make here the DFA. But in order to remember which set of states that DFA could be in at a given point-- so maybe it's in the set of states that M could be in. Did I say it wrong? Which set of states the NFA could be in a given time-- so maybe M, the NFA, could be in, at some point, state q3 and q7. The way the DFA keeps track of that, it's going to have a state for every possible subset of states of the NFA. That's how it remembers which subset of states the NFA is in. That's the way DFAs work. They have a separate
1639	state for each possibility that they need to keep track of. And the possibilities here are the different subsets of states that the NFA could be in at a given point. OK? So corresponding to this subset, to these two possibilities q3, q7, the DFA is going to have a state with the subset q3, q7. And it's going to, for every possible subset here, there's going to be a different state of M prime. So M prime is going to be bigger. OK. So quickly, the construction of M, the states of M prime now, q prime, are going to be the power set, the set of subsets of states from the original machine M. And now we have to look at how the transition function of the DFA, when you made the primed machines of the DFAs, the DFA machine. So these are the deterministic components. So delta prime, when it has a subset, something like this, has one of its states, which corresponds to a subset of states of M, and it reads an input symbol, you
1640	just have to do the updating the way you would naturally do. You're going to look at every state in R, look at where that can go under a-- so there's a bunch of sets there. And look at all the possible states that could be in one of those subsets, and that's the set of states that you could be. That's going to be the new set of states, and that's going to be in the new state of M prime. OK? So it's going to be the subset corresponding to all of the states that could be in, when you apply the transition function of the nondeterministic machine, to one of the states in the subset of states that the nondeterministic machine could be in. OK? It's a little bit of a mouthful. I suggest you look at this, if you didn't quite get it, after the fact. Good to understand. The starting stage for the NFA-- for the DFA-- I'm sorry-- is going to be which subset now we're going to start off with. It's going to
1641	be the subset corresponding to just the start state of M. And the accepting states are going to be-- of the deterministic machine are going to be all of the subsets that have at least one accepting state from the NFA. OK? So I hope you got that. Because I'm going to give you another little check-in here. Which is I'm going to ask you, how big is M prime? How many states does M prime have? I told you what those states are. So just go think about that. So check-in two-- if M has n states, how many states does M prime have by this construction? OK, so let's launch the next poll. OK, five seconds-- and I think we're almost done here. good. All right, share results-- I don't know if sharing results is a good thing. I'm not trying to make you, if you didn't get the right answer-- because most of the people did get the right answer-- but if you didn't get the right answer, trying to make you feel bad. But it's a
1642	little bit of suggestion that you need to review some basic concepts. So the basic concept here is if you have a collection-- you have a set of states, how many subsets are there? And the number of subsets is going to be exponential. So if you have a collection of n elements, the number of subsets of those n elements is 2 to the n. That's the fact we're using here. And that's why M prime has 2 to the n states, if M had n states. And you should make sure you understand why that is. All right, so with that, as requested, we're going to have a little break. And that break is going to last us exactly five minutes. So we will return in five minutes. I'm going to be prompt. So I gave you a little timer here. So please, I'm going to begin it right when this is over. OK, almost ready.
1643	I hope you're all refreshed and ready for the second half. So now that we have nondeterminism, we're going to use that as a tool to prove the closure properties that we were aiming for, starting from last lecture. OK. So remember, let's look at closure under a union. Now, we already did that, but I'm going to do it again, but this time, using nondeterminism. And you'll see how powerful nondeterminism is. Because it's going to allow us to do it almost with no effort. We'll start off the way we did before. I'm going to start off with two DFAs. But actually, these could be NFAs even. But let's say we started with the two DFAs for the two languages A1 and A2. And now we're going to construct an NFA, recognizing the union. And that's good enough, because we already know that we can convert NFAs to DFAs. And therefore, they do regular languages, too. OK. So now here are the two DFAs that do the languages A1 and A2. And what I'm going to do is
1644	I'm going to put them together into a bag of states, which is going to be M, the NFA that's going to do the union language. So remember-- what does M supposed to do? M is supposed to accept its input, if either M1 or M2 accept. So how is it going to do that? What it's going to do, we're going to add a new state to M, which is going to branch under epsilon transitions. And now you can start to see how useful these epsilon transitions are going to be for us. Going to branch under epsilon transitions to the two original start states of M1 and M2. And we're done. Why? Well, now, nondeterministically, as we get an input, w coming in to M-- and at the very beginning, even just right after it gets going, the very first thing that happens is it's going to branch to M1 and also branch to M2 nondeterministically as two possibilities. And then inside M1 and M2, it's going to actually start reading the input. And each one is
1645	going to be now following along as it would have originally the states corresponding to reading those input symbols. And M, as a combination of M1 and M2, is going to have a possibility for one state in M1 and one state in M2. And so M is going to have those combined into one package. And now at the end of the input, if either of these end up at an accepting state, then M is going to accept as a nondeterministic finite automaton. Because that's how nondeterminism works. You accept if either-- if any one of the branches ended up accepting-- which is just what you need for union. So when we're doing union, you want either one of these to be accepting. And the nondeterminism just is built conveniently to allow us to do the union almost for free. So you can again, thinking about nondeterminism as terms of parallelism, you could think of the nondeterministic machine as running in parallel M1 and M2 on the input. And if either one of them ends up accepting, M
1646	will accept. Or you can think about it in terms of that guessing that I referred to before, which means that as M is getting-- when it's just about to read the first symbols of its input, it guesses whether that's going to be an input accepted by M1 or an input accepted by M2. And the magic of nondeterminism is that it always guesses right. So that input happens to be an input that's going to be accepted by M2. M is going to guess that M2 is the right way to follow. And it's going to go in the M2 direction. Because nondeterminism, the magic is you always guess right. I wish that was true in real life. It would make exams a lot easier.
1647	under concatenation. OK, so now we're going to actually have a picture of very similar to the one we had originally. But now using nondeterminism, we can make it work. So here we have the two machines doing the two languages, A1 and A2. And we're going to combine them into one bigger machine M, as shown. Remember, what M is supposed to do is accept its input, if there's some way of splitting that input, such that the first half is accepted by the M1, and the second part is accepted by M2. The way we're going to get that effect is by putting in a transit empty-- empty transitions, epsilon transitions, going from the accept states of M1 to the start state of M2, just as I've shown in this diagram. So these were the original accepting states of M1. And now they're going to be declassified as accepting states. But they're going to have new transitions, empty transitions, attached to them, which allow them to branch to M2 without reading any input. And so intuitively speaking, this
1648	is going to do the right thing. Because once M1 has accepted some part of w, then you can nondeterministically branch to M2. And you're going to be start processing inside M2. And the point is-- I jumped ahead of myself-- is that the reason why it fixes the problem we had before is that the epsilon transitions don't-- the machine does not have to take that. It can stay where it is as one nondeterministic option, or it can move along the epsilon transition, without reading any input, as another nondeterministic option. So it's using this nondeterminism now to both stay in M1 to continue reading more of the input and to jump into M2 to start processing what might be the second half or the second part of the input which M2 accepts. And you can think of it in terms of the guessing as that the machine is guessing where to make that split. Once it found an initial part that's accepted by M1, it guesses that this is the right split point. And that passes to
1649	M2. But there might be other guesses that it could make corresponding to other possibilities. And so with nondeterminism, it always guesses right. If there is some way to split the string into two parts accepted by M1 and M2, the machine will make that good guess. And then M1 will accept the first part, and M2 will accept with the second part. And we'll get M accepting that whole string altogether. And so that is the solution to our puzzle for how do we do closure under concatenation. OK, I hope that came through. Because we're just getting going with nondeterminism. We're going to be using nondeterminism a lot, and you're going to need to get very comfortable with it.
1650	Now let's do closure under star. And closure under star works very similarly, but now we're just going to have a single language. If A is regular, so is A star. So they're not a pair of languages, because a star is a unary operation applying to just a single language. So if we have a DFA recognizing A, in order to show that A star is regular, we have to construct a machine that recognizes A star. And the machine we're going to construct is as before and then an NFA. OK? So here is M, the DFA for A. And we're going to build an NFA M prime that recognizes A star. And let's think now, what does it mean to recognize A star? So if I'm going to give you an input, when is it in the star language? What does M prime have to do? So remember what star is. Star means you can take as many copies of you lot as you like of strings in the original language, and that's in the star language.
1651	So to determine if something is in the star language, you have to see, can I break it up into pieces which are all in the original language? So you want to see, can I take my input w and cut it up into a bunch of pieces-- four, in this case-- where each of those pieces are members of A, the members of the original language? So that's what M prime's job is. It has its input and wants to know, can I cut that input up into pieces, each of which are accepted by the original machine M? That's what M prime does. And if you think about it a little bit, really what's happening is that as soon as M-- so M prime is going to be simulating M. That's the way I like to think about this, as having M inside. So if you were going to be doing this yourself, you're going to take w. You're going to run it for a while. You'll see, oh, M is accepted. Now I have to start him
1652	over again to see if it accepts the next segment. So every time M accepts, you're going to restart M to see if it accepts another segment. And so by doing that, you're going to be cutting w up into different segments, each of which is accepted by M. Of course, it's never totally clear whether you should, for any given segment, you should cut it there or you should wait a little longer and find another, a later place to cut. But that's exactly the same problem that we had before with concatenation. And we solved it using nondeterminism, and we're going to solve it again using nondeterminism. So the way we're going to get that effect of starting the machine over again, once it's accepted, is by adding in epsilon transitions that go from the start states back to-- from the accept state back to the start state. So now every time M has accepted, it has an option-- not a requirement, but has an option. It can either stay continuing to process, or it could restart, making
1653	a cut at that point and trying to see if there's yet a second, another segment of the input that it's going to accept. And this is basically the whole thing, with one little problem that we need to deal with. And that is we need to make sure that M prime accepts the empty string. Because remember, the empty string is always a member of the star language. And as it's written right now, we're going to be requiring there to be at least one copy of at least one segment. We're not taking into account the possibility of no segments, which is the empty string. And the way we're going to get that is-- well, I mean, one thing, one way to get to add-- so we're missing the empty string right now. So how do we fix it? Basically, we're just going to take the construction we have on the screen, and we're going to adjust it to add in the empty string. Because it's possibly missing. One way to do that, which is tempting, but wrong,
1654	is to make the start state of M an accepting state for M prime. So we could have made this an accepting state, too. And now M prime is also going to accept the empty string. That's the good news. The problem is that the start date might be playing some other role in M besides just being the start. There might be times when M comes back to the start state later on. And if we make the start state the an accept state, it's going to suddenly start accepting a bunch of other things too, which might not be intended. So it's a bad idea to make the start state an accept state. Instead, we'll take the simple solution alternative of adding a new start state, which will never be returned to under any circumstances, and make that a new start-- an accept state as well. So here, we'll have to make this additional modification. So as I'm saying, this is what we need to do. And the way we'll do that is by adding a new start
1655	state, which is also an accept state, to make sure it accepts the empty string. And then that also can branch to start off M as before, if the string that's input is not the empty string. And so then M prime is actually going to have to do some work to see if it can be cut off, as it was doing before. So that's the proof of closure under star. I'm not going to do it anything beyond what I've just described. These proofs by picture are convincing enough, I hope. And if not, they are explained in somewhat more detail, somewhat more formally, in the textbook. But for the lecture, this is where I'm going to stop, with these two arguments. And so now-- oh, we have one quick check-in on this. So if M has n states, how many states does M prime have by this construction? So I'm not intending these to be very hard, more just to keep you awake. So how many states does M prime have? OK, maybe a little too easy
1656	even for a check-in. Yeah, everybody is getting this one. Because all you did was-- we added one new state. So the answer is as you have-- I think pretty much everybody is observing that it's number b. So I'm going to end the polling, and I'm going to share the results. And everybody got that one. And so let's continue on. And so the very last thing we're going to do today is show you how to convert regular expressions to NFAs, thereby showing that every language that you can describe with a regular expression is a regular language. On Tuesday, we'll show how to do the conversion in the other direction and so thereby showing that these two methods of describing languages are equivalent to one another. So here's our theorem. If R is a regular expression, and A is the language-- a set of strings that that regular expression describes, then A is regular. OK? So we're going to show how to convert. The strategy is to convert R to an equivalent NFA M. And so we
1657	have to think about, remember, these regular expressions that we introduced last time. These are these expressions that look like ab union b star, something like that-- so built up out of the regular operations from the primitive regular expressions that don't have any operations, that we're calling atomic. So if R is an atomic regular expression, it just looks like either just a single symbol or an empty string symbol or an empty language symbol. Or R can be a composite regular expression-- whoops. We're having a little-- yeah, so we have two possibilities here. R is either atomic or composite. And so let's look at what the equivalent expression is in each case. So if R is just the single letter regular expression-- that's a totally legitimate regular expression, just a regular expression 1. So that just describes the language of the string 1. So we have to make an NFA which accepts-- which recognizes just that language, accepts only the string 1. So it's a very simple NFA. It just starts in the start state. And on
1658	that single symbol, it branches to an accept state. And there were no other transitions allowed. So if you get anything else coming in besides that one, that string, which is just that one symbol, the NFA is going to reject it. If it's too long, if it gets aa coming in, well, there's nowhere to go from this accepting state on an A. So the machine is just going to die. It has to be in an accept state at the end of the input. Now, I want you think for yourself for a minute, how do we make an NFA which accepts only the empty string and no other strings? You can do that with just one state with an NFA, just this one here. The machine is going to start off in the start state, which is also immediately an accept state. So it accepts the empty string. But if anything else comes in, there's nowhere to go when the machine dies. So this machine accepts just the empty string. Or its language is the language with
1659	one element, the empty string. How about the empty language? Well, here's an NFA which has no accepting state, so it can't be accepting anything. Now, if we have a composite regular expression, we're already finished. Because we showed how to build up-- we showed constructions which give us closure under union, concatenation, and star. And those constructions are going to enable us to build up the NFAs that do the language of these more complex regular expressions built up out of the NFAs that do the individual parts. So if we already have NFAs that do R1 and R2, then the closure under union construction gives us an NFA that does R1 union R2 as a language. So I hope that's clear, but I'm going to do an example which will hopefully illustrate it. And it's going to show you-- basically, what I'm giving you is an automatic procedure for converting a regular expression into an equivalent NFA. So let's just see that procedure in action, which is really just following this recipe that I described for you. So
1660	here is a regular expression a union ab star. So this is a regular expression. It's some language. Whatever it is, I don't care. But I want to make an NFA which recognizes that same language. And the way I'm going to do that is first build
1661	of this regular expression, and then combine them, using our closure instructions, to be NFAs for larger and larger subexpressions, until I get the NFA that's the equivalent of the entire expression. So let's just see how that goes. So the very most primitive parts, the smallest subexpressions here, are just the expressions for a and for b. So here's the one just for a. So this is the NFA which recognizes the language, which is just the one string a. Here is the NFA whose language is just the one string b. And now I want an NFA which accepts only the string ab. Now, of course, you could just do that by hand yourself. It's simple enough. But what I'm arguing is that we can do this automatically, using the closure construction for concatenation. Because really there's a hidden concatenation symbol. This is a concatenate b. So now for ab, I'm going to take the thing from a and the part from b-- so these two things that I had from before, and use the concatenation construction to
1662	combine them. You see that? So now I have automatically an NFA which does the language whose string is just ab, just the ab string. And it's not the simplest NFA. You can make a simpler one, but the virtue of this one is that I got it automatically just by following the closure construction. So now I'm going to do a more complex one, just the inside here, a union ab. So the way I'm going to build that is from the two parts, the a part and the ab part, the a part and the ab part. So here is the a part. Here's the ab part. I've already got those from before. It's really kind of a proof by induction here. But I think it's simple enough, we don't have to use that language. So we have the a part, the ab part. And now we are going to apply the closure under union construction to combine those into one machine. And remember how that worked. We had a new symbol here, which branches under empty string
1663	to the previous-- we're adding a new start state, which branches to the original start states under empty transition. And now this is an NFA for this language, a union ab. And lastly, now we're one step away from getting the star of this. And how are we going to do that? We're going to take this thing here and apply the construction for the star closure. And that's going to be an NFA which does a union ab star, which is what we wanted in the first place. So first, we're going to bring that one down. Because we've already built that one. And now remember how we built the closure under star. We made the accepting states return back to the start state, and we added a new start state to make sure we got the empty string in there that transitioned to the original start state under epsilon. OK? So that's all I wanted to say for today's lecture. Let's do a quick review. Very important concept, nondeterminism and nondeterministic finite automata-- we proved they were equivalent
1664	"in power, showed the class of regular languages closed under concatenation in star. We showed how to do conversion of regular expressions to NFAs. So I think that is it for today's lecture. And thank you, all, for being here. I'll try to answer a few of these. ""Why does concatenation have order?"" Well, because it's an ordered construction. Is there a simple way to prove closure under concatenation without using nondeterminism? No. ""Why are the empty strings at the accept state? Can't they be at any state? Doesn't star make copies of any part of the input?"" No, it's only-- you have to think about what's going on. You have to branch back to the beginning only on an accept. Because that means you found a piece that's in the original language. ""Is there an automaton that can add some or subtract memory automata?"" Well, depends on what you mean by all that. But certainly, there are more powerful machines that we're going to study than finite automata. But yes, there is. And even finite automata can add and"
1665	subtract, if you present the input in the right way. I would refer you to the first problem on the homework. So I think I'm going to check out then. Take care, everybody. Bye-bye.
1666	[SQUEAKING] [RUSTLING] [CLICKING] MICHAEL SIPSER: Hi, everybody. Can you hear me? Yes. Good. Welcome back to the course. And so we are now at lecture 10, and let's see. What have we been doing? We've been talking about undecidability. So we introduced, last time, reducibilities and mapping reducibilities for proving various problems are undecidable. And this time, we're going to-- and today, we're going to introduce a more sophisticated method for proving undesirability using reducibilities. And that's called the computation history method. And that's pretty much what's used in all of the more serious cases where people have proved problems undecidable. It's pretty much a widespread method. Especially it's not an active area of research these days, but at times when people were proving problems undecidable, this was frequently a method that was used. So we'll go over that today, and we'll prove a few examples of problems undecidable using that method. All right.
1667	So first of all, most importantly, you should remember how we prove problems are undecidable in the first place. And that is by showing some other undecidable problem that we already know is undecidable is reducible to the problem of interest. So typically, you might be reducing ATM, which is a problem that we started with and showed to be undecidable by the diagonalization method. Or it might be some other problem that we've subsequently shown to be undecidable, and you take that problem, and you reduce it to the problem you're trying to show undecidable. OK? Whoops. Let me fix that. OK. So this is the thing to keep in mind. To prove a language is undecidable, show that ATM or some other known undecidable language is reducible to the problem B that you have at hand that you're trying to show undecidable. All right. So we are now going to--
1668	first, I'm going to start off by remembering Hilbert's tenth problem, which we discussed briefly a few lectures back, as you may remember. So that's a problem where you were given, say, some polynomial over several variables, like 3x squared y minus 15z plus 2xz equals 5. And you want to solve that problem. You want to find a solution that solves that equation, but you require that the solution involves only integers. So those are so-called diophantine problems because the requirement is that the solution be in integers. And Hilbert's problem was to ask for an algorithm. Not the language that he used, but doesn't matter. Essentially, he asked for an algorithm to test whether a polynomial has a solution in integers, whether the polynomial equation has a solution in integers. And as we now know, that problem was posed back in 1900, it took 71 years to find the solution, but the answer is no. There is no-- there is no such algorithm. We talked about this when we were discussing the Church-Turing thesis. And the method showing
1669	that there is no algorithm is by a reduction from ATM to that problem. So one can use exactly the method that we're using today to prove that problem is undecidable about polynomials. The only thing is is that the reduction, that single reduction, would take the entire semester. And I know that's in fact correct because when I was a graduate student, there was a woman in the math department at Berkeley, where I studied, and the whole course was to go through the proof of Hilbert's tenth problem, of the solution to Hilbert's tenth problem, the proof of the undecidability of the solution, of the undecidability of testing whether a polynomial has an integral solution. So the thing is is that involves some fairly hairy number theory in order to come up with the right polynomials to basically simulate the Turing machine. So that's kind of getting ahead of ourselves. That's what we're going to be doing today. But we're going to-- instead of looking at that problem because we don't have a whole semester to spend on
1670	it, we're going to look at a toy problem instead where there's no number theory, but it still has the same basic underlying idea that was employed in the solution to Hilbert's tenth problem. So that toy problem is called the post correspondence problem. And it's going to have some other utility for us. Well, the main reason we're studying it is just to illustrate the method. So and the method is going to be, as I have been saying, is this computation history method. OK, so why don't we-- we'll first talk about this post correspondence problem because that's very easy to understand, and then we'll spend a little time introducing that method. All right. So the post correspondence problem is as follows. You're given a bunch of pairs of strings. So here is one pair, t1 and b1. And I'm writing them as dominoes. I'm calling them dominoes because I'm writing one of the strings on top of the other string. In fact, I'm using t and b for top and bottom here. So this is t1 is
1671	the top string, b1 is the bottom string in the first domino. And then in the second domino, we have two other strings, a top and a bottom and so on. So we have these here, this collection of dominoes, as sort of the legal dominoes. And what the goal is, to find a sequence of those dominoes. So you want to pick from these dominoes here. You're allowed to repeat dominoes. So you want to pick a sequence of those dominoes, line them up next to each other, and so that the string that you get by reading along the top, all of the ts together, is going to be exactly the same as the string you get by reading along all the bottoms. I'll give you an example. So here, to write it down a little bit more formally, so what I'm calling a match is a sequence of these dominoes, so it's ti1, ti2. Well, it's i1 is the first domino, i2 is the second domino and so on. And then what you're going to have is
1672	all the top strings concatenated together is exactly the same as what you get by concatenating together all the bottom strings. So here's an example, and I think it'll become clear if you didn't understand it so far, but it'll be completely clear from the example, I hope. So here is a bunch of dominoes, four. And what I want to know is, is there some selection of these dominoes-- again, you can repeat dominoes. Otherwise, it would be not an interesting problem. So you can repeat these as many times as you like. And I want to pick these dominoes and line them up so that what you get by reading along the top is the same as what you get by reading along the bottom. So first of all, if you just stare at this and you're trying to make a match, you'll see that there's only one possible way to start this. For example, if you started with the third domino here, ba over aa, it would fail immediately because the b and the a are different.
1673	And if you use the second domino as your starting point, that would fail to match as well because aa would have to be-- the top string would start with aa, the bottom string would start with ab, and they could never be equal. So by looking at this, you can see that the only possible choice that you have is to start with the first domino. So I'm going to start to build a domino for you just so you can see it. So here's the match so you can see the process. So the match starts with the very first domino. And the way I'm going to write it is I'm going to take the dominoes and kind of skew them so that you can see how the top and bottom strings are lining up. But they're the same dominoes, they've just been-- I changed the shape. So this is the first domino, ab over aba. Now, the second domino in my match, it's got to start with an a as the leftmost symbol on the top string.
1674	So that would rule out this one, for example. But there might be several choices, and so it's not exactly obvious which one you should take. What I'm going to suggest is we take this one here. So we take aa over aba. You see it. aa over aba. It's just written-- I'm just skewing it so that I can line up the a over a, the b over b, the a over a and so on. So I'm starting to build this concatenation of the top being equal to the concatenation of the bottom. Following me so far, I hope? So now, what's next? So I need to have something where the top string is going to start with a ba. Fact, there's only one choice for that, so it's clearly going to have to be this domino is going to be next. So it's going to put a ba up here, but then it's going to force an aa down below because that's what this domino does. So this ba matches with that. Now we have the aa
1675	to deal with. So we're going to reuse this domino because that's the only one that starts with an aa. So we're going to reuse that one. Now we have aa and aba. Now we need something that starts with aba. I see two choices. Could be this one because this is consistent with-- at least it captures the ab. We could try putting this one over here, but a better choice would be to use this one because if we use this one, we finish the match. And therefore, we have found what we're looking for. And this collection of dominoes here has a match. Now, it's not always obvious. Some collections of dominoes may not have a match. And so the computational problem is, is there a match? And the theorem that we're going to prove today is that this problem is undecidable. Simple as it is, simple little combinatorial problem of trying to put together different tiles like that to form a match, there is no algorithm for solving that problem. And I think this is kind
1676	of interesting because it's the first example of a problem that we have where the underlying question does not really seem to have anything to do with computation. You might argue that ATM being undecidable is perhaps a little unsurprising after the fact because it's a problem about Turing machines, so you can imagine Turing machines are going to have a tough time answering. But here's a problem just about strings. And we're going to show it's undecidable. So just to formulate this as a language, I'm going to call the PCP language, is the collection of these PCP problems, PCP instances, which are just themselves, each one is a collection of dominoes. So it's the language of all collections of these dominoes where there is a match. So it's all of the PCP problems where you can solve them with a match. And we're going to prove that it's undecidable by showing that ATM is reducible to that PCP language. Now, before we do that, I'm going to have to-- I'm going to explain to you what the computation
1677	history method is in the first pla-- that we're going to be using. So before we do that, here's our first check-in for the day.
1678	Just to make sure you're following me about what this PCP problem is, I am going to give you a question to test, is there a match with these three dominoes? So I want you to think about that. I mean, the main thing I want to make sure you understand is what a match is in the first place. This is not a super hard problem to tell whether or not there's a match. OK. Five seconds. All ready? OK. Closing it out. OK. So for those of you who said there is a match, I want you to exhibit the match because in fact, there is no such-- there is no match. And I mean, you could get-- by fiddling around with it, I think if you try to find a match, you'll pretty quickly see that you're going to get-- I think what happens is you kind of get into-- if you try to build a match with this particular setup, you're just going to get stuck sort of repeating yourself. And one point here that you
1679	may have missed is that a match has to be a finite sequence. So if you were thinking about-- there is a kind of an infinite match that you can build with this set of dominoes, but that's not allowed. We're only allowing finite matches. And so that means that you might change your answer as a result, but too late. So and one way to see that you can't have a match in this problem is that you're going to have to start-- neither of these two are possible starting points, so this one is going to be clearly the only chance that you're going to have as a match, the first domino here. But then once you put this one down, the bottom one, the bottom string, the bottom bs that you're going to get, the bottom string is going to be longer than the top string. And then the other two are going to have the same length. So you're never going to have the top be the same length as the bottom. The bottom is always
1680	going to be longer no matter how many more dominoes you lay out.
1681	OK. So now we're going to work our way up to introducing this computation history method. And first, let me define something for a Turing machine that I'm going to call a configuration. Configuration is just a snapshot of the Turing machine in the middle of its computation. So if you're running the Turing machine and you just stop it at some moment, it's going to be in a certain state, the head is going to be on a certain position, and the tape is going to have a certain contents. And with that information, you can then continue the computation of the Turing machine. That's a full set of the information that you need about the Turing machine that tells you everything about its computation at that moment in time. The state, head position, and tape contents. And so that, we're calling that information together, state, head position, tape contents, we're calling that a configuration. Fairly basic notion. I mean, if your program-- if you have something-- if you have the states of all the variables and where the
1682	current execution of the program is at a moment in time, same idea. OK. So in terms of a picture here, here is the Turing machine. Imagine it's in state q3. The head position is in the sixth position on the tape, so p would be 6 because it's in the sixth position, and the tape contents is going to be this bunch of as followed by this bunch of bs. So I would write it down like this. State's in q3, head position number 6, this is the contents of the tape. Now, what we're going to often do for convenience in using this notion in proofs is that we're going to want to represent a configuration as a string in a particular way that's going to be-- that's going to-- this concept is going to come up kind of again and again during the course. And so it's going to be handy to have a particular way of writing down configurations for doing proofs about them. And so the way we're going to write them down is-- I
1683	think it's just maybe-- I can just put it right up here like this. We're going to write down the symbols of the tape. But what we're going to do is stick in the middle of those symbols the state of the machine immediately to the left of the position that the machine is currently reading. So you can imagine the head here, which is coming. Imagine the state is kind of where the head is. It's pointing at the symbol immediately to its right. So this is just another way of writing down a configuration. Here's the tape contents, which I'm sort of writing formally here. I'm breaking the tape contents into two parts, which I'm calling t1 and t2. This is the t1 part, the t2 part. And I'm putting the state in between t1 and t2 where I have in mind that the machine's head position is right at the beginning of t2. But maybe this picture just says it all and it's clear enough. So just keep in mind that when we're going to be writing
1684	down configurations of machines, we're typically going to write it down this way. OK, so I think this is a good moment to take a-- to take a moment for questions. Oh. I see there's a lot of questions already. So one question is, how does the encoding differentiate between the string and the state? If I'm understanding you correctly, I'm going to be assuming that the symbols that represent states and the symbols that appear on the tape are distinct from one another. So you can always tell just like usually the way we write things down when you have a state symbol or whether you have a tape symbol. And so in a configuration, you're going to have a bunch of tape symbols and a single state symbol represent in the position where the head is. Somebody says-- 6 here is just this is 1, 2, 3, 4, 5, 6. We're in head p-- the head is in position six. That's all I had in mind for 6, and that's why that 6 is appearing over there because
1685	that's the position of the head. Good. All right. So why don't we continue.
1686	Now, we're all ready to start defining computation histories, which themselves are not very difficult concept. Computation history for a Turing machine M on an input w is just the sequence of configurations you go through. When you start the machine at the beginning with M on the tape-- with w on the tape, I'm sorry, and the head at the beginning in position one and the state in 20 or whatever the start state is of the machine. So that's going to be the starting configuration here. And these are the sequence of configuration that machines go through-- that the machine goes through step by step. Every step of the machine is getting represented here until it ends up at an accept. That's what we mean by a computation history, or sometimes we're going to emphasize that by calling it an accepting computation history. Represent meaning that the machine has accepted its input, and these are the sequence of configurations that the machine goes through. That's what I mean by a computation history. You know, I'm sure in-- I
1687	mean, I think the terminology changes over the years, but there's a notion similar to that for any kind of-- if you're running a program and you just want to keep track of how the variables are changing as you're in this particular run of the machine, and you're writing them all down, it's like a log of the history of the settings of the internal states of the machine and variables and so on. So this is just all of the configurations the machine goes through on the way to accepting its input. If the machine does not accept its input, there is no computation history. OK? So there is no accepting computation history, at least, to emphasize that point. Because that can only occur obviously if the machine has accepted its input. OK. So just as we had with configurations, we're going to want to be able to write down computation histories as strings. And it'll be convenient to have a particular format for doing that as well. And it's kind of the obvious thing. We're just going
1688	to take the sequence of configurations in the computation history and write them down as a string where each configuration is going to be the string for that configuration. I'll show you kind of a little example in a second. But just to focus on the concept here, we're just going to write down the string for this configuration, the starting configuration and then the next configuration and so on until you get to the accepting configuration and separate each of those strings by some pound signed letter. OK? So here is a computation history for M on w where w is the string w1, w2, dot, dot, wn. So here is the-- here is the first configuration. So this part here is the computation history encoded as a string. I'm giving you this extra side information just to make it clearer what's going on there. So this is the first configuration, this is the second configuration, and so on. And I'm trying to even give you a little bit more detail of how it might look by kind of
1689	making the example a little bit more concrete. So let's say that the Turing machine, when it's in the starting state q0, looking at the very first symbol of the input tape in this particular input, say w1, it goes from q0 to q7 and writes an a on the tape and moves its head to the right. So that's why the second configuration reflects that. See here, it went from q0 to q7. Now the head is in the second position, so that's why that state symbol is moved over one. And the very first position now has become an a because the machine has changed whatever was on that input tape there in the first position to an a. And then the next step, it goes from q7 reading a w2, which is where the head is now, looking at the w2, and goes to q8, writing a c, and again moves right. OK? So that's why I drew these in the way I did. And so you go through a sequence of those, you get to q
1690	accept, and that's the encoded form of the computation history. All right? I think that's-- is that all I wanted to say? Yeah. So you can feel free to ask another question if you want. I'm just going to relaunch this. Yeah. Good. So if we're all together on configurations, computation histories, and how we're going to be writing them down as strings, that's what we've done so far.
1691	All right. So let me define a new automaton that we're going to mainly use as just to provide an example for us today. I'm going to call this a linearly bounded automaton. And all it is is a Turing machine where the Turing machine is going to be restricted in where it can-- the tape is not going to be infinite anymore. The tape is just going to be big enough to hold the input. So the machine no longer has the ability to move into the portion of the tape to the right of the input because there is no tape out there. It just has the tape sitting here that contains the input, which the tape itself can vary in size. However big the input is, that's how big the tape is. So the tape adjusts to the length of the input. But once you've started the machine with some particular input, that's as big as the tape is. There's no more. The reason why it's called linearly bounded is because the amount of memory is a
1692	linear function of the size of the input because you can effectively get somewhat more memory by enlarging the tape alphabet, but that's going to be fixed for any given machine, so that's where the linearly comes from, if that's helpful. But if you don't get that, it's sort of a side remark. But what's important to me is that you understand what I mean by a Linearly Bounded Automaton, or an LBA. It's just like a Turing machine, but that portion of the tape that originally had blanks is just not there. As the machine tries to move its head off the right end of the input, it just sticks there just as if it tried to move its head off the left end of the input. Doesn't go anywhere. So now, we're going to ask the same kinds of questions about LBAs that we ask for other automa. So the acceptance problem. If I give you an input and some particular LBA and I want to know, does the LBA accept that input? Well, and now the question
1693	is, is that the decidable or not? So at first glance, you might think, well, an LBA is like a Turing machine, and the ATM problem is undecidable, so that might be a good first guess. And also, if you try to simulate them, if you try to figure out how you would go about simulating the machine, if given b and w, if you actually tried to simulate the machine to get the answer, so you run b on w, well, of course, if you run it for a while, and it eventually halts, either accepting or rejecting, then you know the answer and you're finished. But this machine might get into a loop. You know, nothing to prevent the machine from looping on that finite amount of-- on that limited amount of tape that it has. And then you might be in trouble. But in fact, that's not the case because when you start out with a limited amount of tape, if you run the machine for a long time and it's not halting, it's going and going
1694	and going, inevitably, it's going to have to repeat, get into exactly the same configuration that it did before because there's only a limited number of configurations that the machine has. And once it repeats a configuration, it's going to be repeating that configuration forever, and it's going to be in a loop. So this problem, in fact, is decidable because the idea is if b on w runs for a very long time and an amount that you can calculate, then you know it's got to be cycling. More than just looping. It's got to be repeating itself. And so therefore, once it starts repeating itself, it's going to be going forever. So and here is the actual calculation, which is something I'm sure you could do on your own, but just to spell it out. So if you have an input of length n that you're providing to b, so if w is of length n, the LBA can only go for this number of different-- it can only have this number of different configurations. The number of
1695	states times the number of head positions, which is n, the number of head positions on the tape, times the number of different tape contents. If the tape was only one long, this is the-- this is the size of the tape alphabet. So if the tape were two long, the tape had two cells on it, the number of possible tape contents would be the square of the alphabet. And if the tape is going to be n symbols long, it's going to be the tape alphabet size to the nth power. So therefore, if a Turing machine runs for longer, it's got to repeat some configuration, and it'll never hold. So the decider is going to be hopefully clear at this point. You're given b and w, so this is the decider for a LBA. It's going to run b on w for this number of steps. If it's accepted by then, then you accept, and if it hasn't, if it's rejected or it's still running, then you can reject. And you know, if it's still running at
1696	this point, it's never going to accept. All right. Any questions on this? OK, let's move on.
1697	All right. So now, but what's different now, or what's perhaps interesting now is that even though the acceptance problem for LBAs is decidable, the emptiness problem is undecidable. And that's where the computation history method is going to come in. So this is where we're going to be starting to do something new in terms of a proof technique. So we're going to reduce ATM to ELBA, the emptiness problem for LBAs. So given an LBA, does it accept anything or not? And this is going to use the computation history method. So this will be a chance to illustrate that method for the first time. So the setup initially is just like before. We're going to assume we have a Turing machine that decides this ELBA problem that of interest. And we're going to use that to construct Turing machine-deciding ATM for our contradiction. OK, so here is S, supposedly deciding ATM, and what is it going to do-- and this is going to be the tricky part. S is going to use M and w to design
1698	an LBA. That LBA is going to be built with the knowledge of M and w. In fact, it's going to have M and w built into it. So that's why I'm calling that LBA B of Mw because it depends on Mw, as I'll describe. And what that LBA does, it takes its input, let's call it the x, the input to the LBA, and examines that input to see if that input is an accepting computation history for M on w. That'll be just looking for computation histories for M on w. And that's the only thing it's going to ever accept. If you feed it something which is not a computation history, that sequence of configurations for M on w leading to an accept, if you feed it something else, the LBA is just going to reject it. It only accepts the accepting computation history for M on w. And now, if you can build such a thing, then you can use that machine in your emptiness tester to see if it accepts any strings at all.
1699	Because the only thing it could possibly be accepting is an accepting computation history. You don't even know if there exists one because you don't know if M accepts w. So you're going to build this LBA, which is looking for accepting computation histories, and then see if its language is empty or not. If its language is not empty, the only thing it could be accepting is this computation history, so you know M accepts w. Whereas if the language is empty, you know that there is no computation history for M on w, and so M does not accept w. So that's the whole idea. The trick is, how do you build this LBA? So first, you're going to make this LBA which tests its input to see if it's an accepting computation history for M on w. And you have to build this LBA without even knowing whether there is a computation history. It's not like you can take that string and just build a string into the LBA because you don't even know if that string
1700	exists. But what you can do is you can make the LBA follow the rules of M. It knows w, and it knows M, so it can take its input, and using w and the rules of M, see if that input is a computation history for M on w. And that's what it's going to do. So here is this machine I'm going to construct. I'll give it to you written down and with a little bit more details of its procedure. But just to kind of illustrate it, so here is a proposed input to B of Mw. This would be the x here. This would be an x that would be accepted. But anything else that would be provided would not be accepted. So this is the sequence of configurations written down as a string. That would be the x that I'm providing to the B of Mw. And it's supposed to be checking this to make sure it's legit. So on input x, the way it's going to-- the way it's going to proceed, it's going
1701	to first check to see whether x begins in the right way because this LBA, it knows M and it knows w. So the very first thing is it takes a look at the first part of the string up to the pound sign. If there's no pound sign, if you're going to just feed junk in, it's going to be easily identifiable as junk. So if you're going to feed something-- so it's going to-- the LBA is going to take everything up to the first pound sign and just confirm that that thing is the first configuration, the starting configuration of M on w, which means it has to start with the start state, then here is w. So just kind of check that. Then it's going to check that each one of these guys follows legally from the previous one according to the rules of M. It's going to first check that this one is correct, and then this one leads to that one, according to the rules of M, then this one leads to that one,
1702	according to the rules of M. All of that-- the knowledge of M and w is built in so it can do that. And then it just follows along, checking this computation. It's easy to check that a computation is correct. That's all that's really going on here. It's going to check that the computation is correct until it gets to the end and then makes sure that the last configuration that it's been given as input is an accepting configuration, that there's an accept state in it. And if everything that passes it accepts, otherwise, it rejects. OK? And the point is that this is an LBA. You don't-- oh, wait. Just kind of jumped ahead of myself. You don't need any additional information. So how does it actually do this? So how do you actually do this on the tape? So I claimed that the LBA doesn't need any extra space to do this-- to do this check. It's just going to be zigzagging back and forth here on the input, checking that the corresponding symbols match up
1703	except around the head position where it gets updated correctly. And it may need to mark-- it will need to mark on the tape, it's allowed to write on the tape, just to make sure it keeps track of where it is. But this is a very simple-- I mean, I'm not trying to-- if you're not following it, I'm not trying to alarm you, but I'm just trying to help you understand that this is not a complicated procedure here to do this check that the actual computation that's written down of the Turing machine is valid. But we can deal with the question here. Oh, good. Now we got some questions. Oops. You can be thinking about-- while I'm thinking about this, you can think about that check-in over there. So here's a good question. Going from each configuration to the next configuration, is it a unique next step? Well, I'm assuming that the Turing machine we're starting with is deterministic, so there should be only one way to go. So the answer to that question is yes.
1704	This is going to be a unique string here. There's really going to be only one computation history. Not that it really matters in a sense, the answer to that question, as long as that accepting computation history corresponds to the machine actually accepting. Oh boy, we're all over-- we're all over the place here. OK, are you ready to end this poll? All right. Well, this is where we are. Everybody who said they'd rather be in 6.046, I know who you are. You're all going to be expelled. No, I'm joking. I don't know who you are. So yeah. Good. So we are here at the break, and I made this poll on purpose at this moment so we can spend a little time. Let me just start our clock going, and I can try to help you, those of you who answered C, that you're baffled. I can try to help you understand what's going on. Ah. So this is a good-- this is a good question here. OK, well, OK. Several good questions here. So somebody
1705	asks, why don't we just test all possible strings for B? Remember, if we're trying to test emptiness for B's language, that's the ELBA problem. Now, why don't we just try all possible strings? And that would work if we had enough time, but there's infinitely many strings, and so that's not going to be good if we're trying to be a decider. So that's why we don't just try all strings. But here's this other question here. This is a-- OK. So the question is, how do we find the input x? So this is an important question because we don't find the input x. There's no-- the input x, at least the accepted input x, would be the accepting computation history for M on w. We're never going to find an-- we're never going to find an x. We're building this LBA. We're never going to run that LBA. We're designing that LBA not for the purposes of running it. We're building that LBA only for the purpose of using the LBA language emptiness tester. We're going to
1706	build that LBA and feed it into the Turing machine R, which is going to tell us whether that LBA's language is empty. We, ourselves, is never going to run that machine. We're never going to come up with an x. We're just having-- we are designing a computation checker. And then the emptiness tester for that that we assume to exist for ELBA is going to say, yes, there is some computation which this machine accepts, or no, there is no computation which this machine accepts, and that's going to be a computation for M on w. And so that's going to tell us whether or not M accepts w. So we're never going to actually be finding an x. We're never going to be running that LBA. We're just feeding, using that LBA as an input to R. Does the computation history method always use LBAs? No, as you will see right after the break. Because the LBAs is just kind of an easy place to get started, but we're going to use the computation history method and
1707	computation histories next on the post correspondence problem. Yes. The computation histories and the input x are always going to be finite. So that was an answer to a question about whether these histories or the inputs are going to be finite or not. So those strings are always going to be finite, and the computation history is going to be finite. So we are at the end of our five minutes. Let me just see if there was another question I wanted to answer. Let's move on. OK, now coming back to the undecidability of this post correspondence problem. So remember the post correspon-- this problem, you're given those dominoes. You want to know if there's a match. Here is a little mini version of the diagram, if that helps you remember it. And we're going to prove that this language is undecidable. And so it's undecidable to test whether you have a match, given a set of dominoes, whether a match is possible. And we're going to use-- we're going to reduce ATM to this language using the
1708	computation history method. So how in the world are we going to do that? First of all, there's a little detail here I want to mention. Just don't focus on this, but I'm going to assume the matches always start with the very first domino on the list, the very first domino in the collection. So there's going to be, like, a starting domino. Just going to make my proof a little simpler to do it that way, and then you can fix that assumption later. And if we have time at the end, I'll do that or maybe after the lecture is over. If there are questions, I can show you how to fix that assumption. But for now, to simplify the proof, we're going to assume that there was a starting domino, that the matches always have to start with that particular domino. If you didn't follow that point, don't worry. You can just ignore it. You'll see where it comes up later. So now we're going to reduce ATM to the PCP. So assuming we have a
1709	machine that decides the PCP, we're going to use that to make a machine that decides the ATM as before. So here is the Turing machine S, which is going to decide ATM. And the way we're going to do it is like this. We're given M and w. We want to know, as always, does M accept w? What we're going to do is we're going to build an instance of the PCP problem. So we're going to build a collection of dominoes which are going to-- and that collection is going to be built knowing M and w. So that's going to affect the dominoes we're going to create. So this collection of dominoes is going to be called P of Mw. Depends on an M and w. And finding a match for this set of ws is going to force you to simulate M on w because the match is going to correspond to a computation history for M on w. So we're going to use-- once we do that, once we build the set of dominoes
1710	where a match corresponds to a computation history, we're going to use R to determine whether or not there is a match. Or in other words, whether or not there is a computation history, which is whether or not M accepts w. So if there is a match, we're going to accept because we know M accepts w. And if there is no match, we're going to reject because we know M does not accept w. OK. This is the plan. I haven't told you how to do this yet. I mean, I'm worried about the significant number of you who are feeling confused by the method. I mean, you guys should be texting me and the TAs to try to at least get a sense of how this is working. I mean, we're going to be going-- we're going to be doing the method again. It's just going to be a little more complicated because we have to also deal with these dominoes and all that stuff, and that's why I presented it to you the first time in
1711	the setting of the LBAs, which were, in a sense, the method comes out perhaps more simply. So a match is going to correspond to an accepting computation history. Sometimes if I don't use the word accepting, I'm just being a little sloppy. Computation history and accepting computation history, for us right now, they're the same. I mean, later on, we may actually talk about rejecting computation histories, but let's not get ourselves confused. Computation histories always have to end with the machine accepting. OK. Somebody's asking, what does it mean for match to correspond to a computation history? You'll see. That's going to be on my next slide. Oh. So this is a good question. Is my step two trying to use R to determine whether M accepts w? Well, yes, but I'm doing that by testing whether these dominoes have a match. Because R decides PCP. I can only use R to test whether things have a match. Someone asks, should step two be to use R to determine whether M accepts w? Well, in effect, that's what
1712	it's doing, but it's doing indirectly through testing whether this PCP-- whether these dominoes have a match. Because those dominoes are going to force you to simulate M on w. OK, I think I'm repeating myself here, so let's avoid getting into a loop on the lecture and see how we actually build P of Mw. So now you understand what-- you have to have the plan in your mind. We are given M and w. We're trying to make a set of dominoes where a match is going to be a computation history for M on w. So the string you're going to get in that match, the top string and the bottom string, which are going to be-- have to match, they're going to be computation histories-- they're going to be a computation history of M on w. So I want to figure out how to make my dominoes force that. OK. So my starting domino, as I told you, there's going to be a special starting domino in my collection, which is going to require the match
1713	to start with that domino. It's going to be this one here. It's going to have these two strings in it. And you can see already, it's starting to look like a computation history. The dominoes are going to have that feature. So it's the pair of strings, and I've written it kind of to help you see what's kind of going on. It's a pound sign on the top and the starting configuration for M on w on the bottom. And what I'm going to do for you here is at the bottom of the slide, I'm going to take the dominoes I've written down so far and try to be building a match, and you'll see how that match is forcing a simulation of the machine. So let's take this as an illustration. Let's assume the input to M, so I'm running M on w now. I'm trying to see, does M accept w? w is a string 223. So the start configuration for M on w is q0, that's the starting state for M, and then w
1714	following it is 223. That's what is going to appear on the tape of the Turing machine to start off. So this is the start configuration for M on w, assuming that I had this particular input string to w. And so given the dominoes that I've given you so far, just one, this is how the match is going to start. Now, there's going to be more dominoes coming. So for every possible tape symbol and state, don't get confused by the language here, this is the important thing. If in the Turing machine-- and I'll just read this in English to you. If the Turing machine, when it's in state q, and the head is reading an a, it moves to state R, writes a b at that point, and its head moves to the right. I'm focusing on rightward moving Turing machine steps right now. But for every possible state and tape symbol and looking at what happens, I'm going to have a domino that's going to capture this information, and it's going to be this domino
1715	here. q a on top, b r on the bottom. So just a string. q a on the top, b r on the bottom. So let's see why? Well, that's sort of arcane-looking. Why is that a good thing to-- why is that a useful domino to put in here? Well, if you take a look, let's assume my Turing machine, when it's in state q0, which is the starting state, and the head is reading a 2, which it will happen to be reading because the string w starts with a 2, if it goes into state q7 and writes a 4 and then moves right, I'm going to have-- in this domino, I'm going to have q02 on top and 4q7 on the bottom because 4 is what I-- right here, that's the b, and the new state that I'm going into is q7. So that's going to be the domino that I'm going to get. And here it is. Here's that domino appearing in the match. So it's going to match up with q02, which don't get
1716	the-- the top string has to equal the bottom string. So and this is going to be the only choice that I have for extending the match. So q02 is going to be on the top when I put that there, but that's going to force 4Q7 to appear at the bottom because that's what's going to be the bottom string corresponding to the q02 on the top. OK? So if you're looking down here, this is the beginning of the second configuration of the machine. That's what I want to be happening. I want to be-- that match should look like a computation history. So this is going to be-- all possible right moves are going to be handled in this way, and it's going to be a similar process for the left moves, but let me not-- I'll leave that to your imagination. Now, how do I continue on from there? What does the rest of this configuration look like? Well, that should just be a copying over of the remaining symbols that were on the tape because
1717	they don't change. Things only change around the head. The rest of those symbols, which is the 2 and the 3, those should just get copied over here. So I'm going to have two additional-- I'm going to have additional symbols in my-- dominoes in my collection. So for every tape symbol, I'm going to have aa be a domino. So for every tape symbol a, I'm going to have aa be a domino in my collection. And so that says I can have-- so there's going to be a 2 2 domino. So I can match up this 2 over here, but that forces me to put a 2 down over there. There's also going to be a 3 3 domino, which is going to match up with that 3, but it's going to force me to put a 3 down over there. That's the only way I can extend this match that I built so far. I have no choice. Those are the only dominoes that I'm going to be given. And so doing, I'm forcing you to
1718	basically simulate the machine. Now, what I want to have happen next is a pound sign to appear here, and that will conclude my second configuration. So there's going to be a pound sign pound sign domino as well because there's a pound sign here. It's going to get matched with the pound sign up top. Forces a pound sign to come down on the bottom. And if you look at the way we are right now, we're exactly like where we were at the beginning when we had just this first domino appearing. But now we're one configuration later. So if you understood that, and I admit that it's-- there's just one idea here. And once you get the idea, it's all trivial. It's all very simple. But there's just you have to get that idea. I'm trying to figure out how to get that idea into your head. Once you get the idea, you can write all this stuff yourself. So following this description of how the transition function of the machine works and copying over the symbols
1719	from the tape to the next configuration, I'm going to be able to get configuration after configuration going until I get to a point when there's an accept. And now, from the machine's perspective, we're done. The machine has accepted its input. This is our computation history. But is it a match? Well, up until-- this bottom thing is the computation history, but it's not a match because the top doesn't equal the bottom. There's still extra stuff at the bottom, which the top, it doesn't have. So what I'm going to need to do now is add some additional kind of pseudo steps of the machine where I'm going to allow the top to catch up to the bottom. And the way I'm going to be thinking about that, and this is not real for a Turing machine as much as the Turing machine is real anyway, but you're going to imagine I'm going to add a new kind of move to the machine which is going to allow the head to eat the symbols off the tape like
1720	Pac-Man. OK? And the way I'm going to get that effect, on the top, if I have any tape symbol next to a qaccept on either side on the top, what I'm going to get you to write on the bottom is just qaccept with that tas-- with that tape symbol gone. And by repeating that move after move, the actual tape is going to be shrinking. The symbols on the tape are going to be going down one by one, move by move, until there's nothing left except just the qaccept all by itself. OK? So I have this sort of Pac-Man idea. I'll be eating the symbols on the tape. And then finally, I get to a point when there's just the qaccept alone on the tape. There's no symbols left to consume. And then I'm going to add one last domino here, which is qaccept pound pound matching with just pound, which just conveniently finishes off the match. And so the match is completed. This is actually a little detailed here. I hesitate even to bring it
1721	up because I think it's the kind of thing where if you understand everything up to this point, you could fill it in yourself. But just for completeness' sake, you have to deal with the situation when the head of the Turing machine might move into the blank portion of the tape, which is not taken into account here. And the way we get that effect is by having another domino here, which allows me to add blank symbols at the bottom as needed. That's just a detail. I'm more worried that you understand the underlying concept. So here is going to be a check-in. I'm trying to remember-- OK. But so OK. So what else can we conclude from this information? So we know-- at this point, we know that PCP is undecidable. That's what we just finished proving. What else do we know, if anything? Or do we even know that? Let's see. My picture is a little bit covering the check-in, but it's still readable. So I mean, this is not an easy concept to get the
1722	idea. But once you get it, you'll see it's not that bad. OK. Another 15 seconds. So this portion-- this question is not really relying so much on the computation history method. It's just relying on the fact about PCP being undecidable. OK. Everybody almost done? Five seconds. All right. So I can see that there is some level of confusion. So the reason why B is correct is that we know PCP is undecidable, but we also know that it's recognizable because you could try all possible ways of combining dominoes and one after the next, except if you ever find a match. So that might go forever. But if there is a match of a possible, you'll find it eventually. So PCP is a recognizable language. Undecidable. And so therefore, we know its complement has to be unrecognizable because that's something we've shown before. If a language and its complement are both recognizable, then it's decidable, but we know PCP is not decidable, so both sides can't be recognizable. OK. So let me prove to you one last
1723	theorem that's going to be useful for your homework involving the computation history method. So you'll have one last chance to get the way we're going to use this, though this one is going to be a little bit more similar in spirit to the LBA version than to the PCP version, which has this extra kind of complication about coding the computations of the machine into dominoes. Here, we're going to operate with another automaton which where it's going to be more straightforward. But anyway, OK. Getting ahead of myself. So if you remember, for context-free grammars, we had the ECFG problem, the emptiness problem. We showed that was decidable. So testing whether a context-free grammar's language is empty is decidable. However, testing whether a context-free grammar's language is everything, whether it's equal to sigma star, that turns out to be-- that turns out to be undecidable. OK? So emptiness testing for context-free grammars, decidable. Sigma star testing, undecidable. OK. So we'll show that ATM is reducible to old PDA via the computation history method. And so assume we
1724	have same patterns. Assume we have a decider for all PDA and make a decider for old t-- decider for ATM. Here's the ATM decider. And now, similar to what we did for the LBA case, but with a twist. We're going to make a pushdown automaton that's going to check its input to see whether it's an accepting computation history of M on w. Just like the LBA did, if you think back to how that worked. Remember, the LBA tested its input to see whether it's an accepted computation history. Accepted if it did, and then we test the LBA's language for emptiness to see if there are any computation histories. So we're doing the same kind of thing, except now, the PDA is going to test its input to see whether it's an accepting computation history, and if it is, it's going to reject. It's going to do the reverse of what the LBA did. And that's going to turn out to be necessary. But for the moment, let's just go with it, and maybe we'll see
1725	it in the proof, why the proof needs it to be this way. So this pushdown automaton is going to accept its input if it's not in accepting computation history for M on w. Otherwise, it will accept. So you can think of this PDA as accepting all junk. It just doesn't accept the good stuff, the accepting computation history. OK? It's accepting all the things which fail to be an accepting computation history. OK? And then once we have that, we test whether R's language is everything, whether BMw's language is everything using R. Because if that PDA's language is everything, then we know there could not be an accepting computation history because that's the one thing that gets not accepted. That's the one thing that gets rejected. So if it's accepting everything, there is not going to be an accepting computation history. So if there is no-- if this is equal to sigma star, then there couldn't be an accepting computation history, and so we're going to accept. OK. So how is this going to work? So what's
1726	different now about this case from the LBA case is remember, the LBA got the computation history on its input, and it used its ability to write on the tape to check that each configuration followed the next one. We don't have the ability to write on the tape in a pushdown automaton. And by the way, I hope you're all comfortable with my using PDAs instead of grammars because we can interchange one to the other. Should have mentioned that when I did it. But so the PDA is going to be using its stack to compare each configuration with the next one, OK? So the way that's going to happen is it's going to non-deterministically take one of these-- so the very first thing it does is, as before, it checks to make sure that the beginning of the input is the start configuration. But then once that's-- that's the easy part. But once we get going with that, we push each configuration-- well, first of all, we non-deterministically choose which configuration might be the one that fails
1727	where one fails to go to the next one. Because those are the ones we're trying to accept, when there's a failure. So we're now determined to simply look for the place that there's a failure. We push that onto the stack, and then we pop it off the stack and compare it with the next configuration. So that's how we're using the stack instead of being able to mark on the input. Now there's a-- so I'm kind of going to illustrate that here. So as we're going to read this thing here, I'm going to put it onto the stack. So this thing moves over to here, and this input here got put onto the stack. q0, w1, w1, it's q0, w1, w2. You see that. That first configuration is now sitting on the stack. Now, as we're going to pop it off, we're going to match it with the second configuration. Now, if you're following me, you'll realize that there's a difficulty here because it's coming out in reverse. It comes out in the reverse order that
1728	we put it in, and that's not what we needed to do. So what we're going to do here, and here's a little sort of a twist, we're going to change the way we're writing down computation histories by making them-- by writing them-- reversing the even-numbered ones. So this one here is going to be written down in reverse. And that's perfectly OK. We can write down computation histories in any way we want to meet our needs. So we're going to reverse-- we're going to reverse the alternate ones. And now, when we push one, it's going to come off in the right order to compare with the next one. And so that's how the procedure works. OK? We're running a little short on time. You need to be able-- let's see. So let me just go to a quick recap. The computation history method is useful for showing the undecidability of problems when you're testing for the existence of an object. Each of those four cases that we showed today involved in testing whether something exists. So
1729	is there an integer solution to the polynomial? Is there some string in the language? Is there string that's not in the language? Or is there a match? So that's a typical case when this computation history method comes up. And so as a quick review, these are the things we showed today. OK, so why don't we-- we're just out of time. And so I'm going to let you go, but I will stick around for another 5 minutes or 10 minutes. Happy to answer any questions if you have them, but that's officially the end of the lecture. OK. So let me try to get to-- there's a lot of questions in the chat. Don't forget, write to the TAs too. So if M does not accept w, what will happen to the computation history? So if M does not accept w, then there is no computation-- there is no accepting computation history. That's the only kind of competition histories we're considering. So if M does not accept w, there is no accepting computation history. There's no computation
1730	history. So I don't know what it means, what will happen to it. It just doesn't exist. So I hope that's helpful. Don't we need to be able to add states to the end of the tape? Hm. I don't know what that means. Add states to the end of the tape. I don't under-- you'll have to repeat that one, sorry, or explain that better. Ah. So this is a go-- this is a very good question here. Where does the previous proof fail when trying to reduce ATM to ECFG? It's got to fail because ECFG is decidable. So that's a very good question. Maybe we can just go back to that last slide here. Because I was running a little short on time, I didn't really focus on why we have to accept the non-computation history strings. Why are we accepting all the junk strings and only rejecting the strings which are the computation histories? So we're looking for strings that fail. A string could fail because it starts wrong. It doesn't have the start configuration. Or
1731	it maybe doesn't end with the accepting configuration. Or maybe one configuration doesn't lead properly to the next one. Any of those cases are a failure, and are going to be a reason to accept. The reason why we can do that is because we're taking advantage of the pushdowns non-determinism. We don't know where the failure might occur, so we're going to non-deterministically guess where that failure occurs. If we were going to flip this around and say let's accept only the good ones and reject everything else, we would have to test that each configuration led to the next one. So we'd have to check them all. So if something fails, it only has to fail in one place, and then we can accept. If it's a good computation history, we have to-- it has to be good everywhere. And so the pushdown automaton, really, if you're going to get down to the nitty gritty, the pushdown automaton can check that this configuration leads to that configuration pushing on the stack and then popping it. But now, by
1732	the time you get to here, you want to check that this second configuration leads to the third one. You would need to push the second configuration onto the stack, but at this point, you're already after the second configuration, so we cannot back up and push the second one on the stack. So the pushdown automaton is not able to check in the positive sense that you have a computation history. It's only able to-- and accept them. It's only to check in the negative sense that you don't have a computation history and accept all the ones that fail. And that's just because it only has to fail in one place. I hope that helps. So that's why we couldn't flip this around and make this proof work for the emptiness problem and only have to work for the everything problem, the all problem. All right. OK, so bye-bye everybody, and I will see you on Tuesday.
1733	hi everybody um glad to have you all back for our next to last installment of theory of computation today um we are going to embark on the very last big topic for the semester and that is in some ways going to be following on what we started a couple of lectures back when we looked at probabilistic turing machines and probabilistic computation and its associated class bpp now what we're going to discuss is in some sense a probabilistic version of np and that's going to be a complexity class called ip which stands for interactive proof systems um and so we're going to present that model and look at a couple of examples uh i would just like to say at the beginning that the this model is a very important one it's really uh has been the starting point for a great deal of research in complexity theory so we're just really going to be touching on it but there's a lot more that people have pursued with this model and it's also a connection in
1734	to the cryptography field which also makes use of the interactive proof system model in fact some of the genesis of that model comes out of cryptography where you're having uh multiple parties either communicating or in some ways interacting uh to achieve certain uh goals of communication or signing or passwords or or or what have you so uh this is a both a an applied area and also one that has a lot of very interesting theory uh um associated to it so with that one we we're going to jump in um and uh start out by uh making myself smaller and just do a an introduction i'm going to introduce the model or the the concept of an interactive proof with an example and that example involves the graph isomorphism problem that's the problem of testing whether two graphs are isomorphic what we mean by two graphs being isomorphic is that they're really just the same graph with one of them perhaps being re-labeled or permuted so that they may look superficially different they may appear
1735	with a different sequence of labels or the nodes are appearing in a different order but except for that it's really just the same graph so i'm kind of illustrating that here if you can see those two graphs here which look different from each other both on eight notes they are in fact the same graph as i can illustrate by a little animation which will convert this one into that one so uh the um [Music] so the two graphs um these graphs being the same um they're we call that isomorphic so these are graphs g and h and they're really the same graph so we we um call them isomorphic graphs and we are have an associated computational problem called iso which is given a pair of graphs we'd like to know are they isomorphic or not so the iso is the collection of pairs of graphs which are isomorphic and it's easy to see that this problem is an np problem because all you need to do in order to see or to give a
1736	certificate that the two graphs are isomorphic to each other is tell you it's just to say which nodes in the one graph correspond to which other nodes in the other graph um and then you all you need to check is that the edge relationships are consistent with that mapping or that isomorphism as it's called um so it's easy to see that the iso problem is an np and if you're not getting that make sure you uh understand because this is the whole first part of the lecture will be lost if you don't understand this iso problem now the question of whether you can test two graphs being isomorphic in polynomial time is not clear and in fact that's an unsolved problem to this day uh and it's a problem that has generated an enormous literature uh there are hundreds of papers on the graph isomorphism problem as it's called um to try to uh resolve um you know uh to try to see if one can find a polynomial time algorithm and in fact it
1737	was a very big result just in the last 10 years where there was a sub-exponential algorithm given so that was more than faster than the brute force search approach but didn't get it all the way down to polynomial now why is there so much attention just to this one particular np problem it's because it's not known whether the graph isomorphism problem is np-complete iso is not known to be an np-complete problem and that puts it into a very very small class of problems in np which are no not known to be either in p or np-complete it's kind of a curiosity that for np problems almost all of them have ended up being in one side or the other and in fact um it's a uh um in fact the the um i i think it's the only problem that just involves graphs that's not known to be either in p or an np um so so i got a question here what would be in between exponential and polynomial for example i don't remember
1738	what the the bound is but it's it's something in the uh in the range of n to the log n uh time complexity for the graphite some more i might be getting that wrong um i don't remember exactly what the bound is but um that's significantly better than two to the n or some some exponential amount of time but it it's more than enter any constant so it's more than any polynomial time so um another question uh of the same sort is whether the complementary problem is in np or whether whether iso is in co-np or let's let's talk about it in terms of the complement whether the complement of iso which i'll refer to as the non-iso problem whether that's known to be in np so that's also not known um in other words if i give you two graphs and i ask you to show that they're not isomorphic suppose they aren't isomorphic and you go through the effort of you know determining that by a brute force search and now you want
1739	to prove that they're not isomorphic well that's not it's not known to be an np either so there's no known short certificate certificate of two graphs not being isomorphic we don't know how to do that either but there's something that's very interesting nevertheless um and it has to do with the ability to for one party to prove to another that graphs are either isomorphic or not isomorphic so if you're just having like a prover we haven't really been necessarily formulating that this way so much in this class but this is a completely equivalent way of formulating the notion of np whether you have a polynomial time verifier an approver who can produce certificates say it's a powerful prover so um if you have a problem that's in np approver can convince a polynomial time verifier that uh strings are in the language if in fact they are so in the case of the iso problem a prover can convince a polynomial time verifier the graphs are isomorphic just by exhibiting the isomorphism now for the
1740	non-isomorphism case we don't know that that problem's in np but it's still possible for approver to convince a verifier that graphs are not isomorphic if you change the rules of the game slightly um so even though the non-iso problem is not known to be an np approver can still convince a polynomial time verifier that graphs are not isomorphic assuming they they are in fact not isomorphic um provided that um the prover and the verifier can interact with one another so the verifier can ask questions of the prover and the verifier gets to be probabilistic so that's in this in that's in sense in which i mean that this notion is a kind of a probabilistic version of np okay so um let me show you how that's done so before we jump in to the uh to the method for approver to um show a verifier that graphs are not isomorphic um let me let let's try to get a little clearer on the model so i'm going to
1741	okay so in in interactive proofs there are two parties um and i'm going to think about them as one of them is going to be the professor okay so the professor is going to play the role of the verifier in a sense but it's like that the one who checks um and uh the professor being kind of old and tired he's been teaching too long maybe can only operate in probabilistic polynomial time so the professor if wants to tell whether two graphs are isomorphic or not probabilistic polynomial time doesn't seem to be enough to tell whether two graphs are isomorphic or not because it seems to be a more than polynomial problem however the professor has um help it has an army of graduate students and the graduate students they're not limited uh in the same way the professor is the graduate students are young they are energetic they can stay up all night they know how to code so the graduate students have unlimited computational ability so that we're going to think of the
1742	graduate students playing the role of the approver because they're not they're not limited in their capabilities we'll assume the professor on the other hand is limited so the professor wants to know if the two graphs are isomorphic let's say whatever they are um can't do it by himself so he's going to ask his students to figure out the answer and report back now there's only one problem the professor knows that students uh well in the old days they'd like to party i guess these days they like to play on uh play computer games a lot and so they're not really that eager to spend all their time figuring out whether graphs are isomorphic so he's worried that the the students will just come up with some answer and figure that he won't be able to tell the difference so the professor does not trust the students it's not enough to he for the professor to give the problem to the students and just take any answer that they're going to give the professor wants wants
1743	to be convinced okay so um now how could the students convince the professor of the answer that they've really done the work and figured out whether the graphs are isomorphic or not well if the graphs are isomorphic if it turns out that the graphs were isomorphic and the students figure that out then life is good because what are they going to do to convince the professor they're going to hand over the isomorphism and show yeah i mean they are you know those graphs really are isomorphic and here's how the correspondence works professor can check oh yeah i i now not now i'm convinced but suppose the graphs were not isomorphic what are we going to do then um the students have figured out where after night else the professor wants wants to be convinced oh no what are we going to do well in fact we're going to engage the the professor and the students are going to engage in the following protocol dialogue what's going to happen is now you have to make sure
1744	you're you're this is critical to follow to understand this little part of the story here because it's really going to set the pattern for everything in today's and tomorrow and to today's lecture and the and the next lecture okay so we're going to engage in a following interaction between the students and the professor which is going to enable the students to convince the professor that the two graphs really are not isomorphic so how is that going to work this is a beautiful little uh thing by the way so the professor is going to take the two graphs and pick one of them at random because the two graphs g and h um let's say they're not they really are not isomorphic the professor doesn't know that for sure that's what the students claim the professor really wants to not be convinced that the students are right um so the professor's gonna pick one of the two at random randomly permute that uh that choice the one that he picked and hand it over to the
1745	students say okay here is one of those two graphs randomly scrambled then i'm going to ask the students which one did i pick okay now if the graphs were really not isomorphic the students can check whether that randomly scrambled graph is isomorphic to either g or to h it's going to be isomorphic to one or the other and then they students can figure it out and they say oh you picked g or no you picked h as the case may be the students can figure that out but if the graphs were isomorphic then that scrambled version of g or h could equally well have come from either of them and the students would have no way of knowing which one the professor picked so that there's nothing they could do which would be better than guessing so if we do that a bunch of times the professor picks at random sometimes secretly of course the picks the grip picks either g or picks h and the students get it right every time either the students
1746	are really doing the work and the graphs are really not isomorphic or the students are just incredibly lucky they're managing to guess right let's say a hundred times so how the the the professor randomly and secretly picks grh uses this uses its probabilism flips a coin just a two-sided coin and says okay sometimes if we're going to do g sometimes they're going to do h just completely at random picks one or the other and then with some more randomness gets finds a random permutation of the one that he picked and then sends that over to the students and say which one did it come from um i'm not sure okay so let's pause here let's let's make sure we all understand this because this is really important um so i'm getting a question here how do we i'm not sure what your question is um okay so let me just say yeah the professor's going to play the role the verifier the graduate students play they're all approver that's coming but i really want to
1747	understand this protocol here okay so how is the professor picking the graph skin if you're okay i don't you know picking the graphs at random you have just two graphs they're in part of the input uh the both the students and the professor can see the graphs and the professors are just picking one of them at random using a coin so i'm not sure i understand the question there could p and v engage in a protocol where the secretary is on the prover side instead the question of revealing the isomorphism i there is no why so i'm not sure i understand this question either um maybe we'll make this clear you know if for for this little illustration the professor doesn't know the graphs could be isomorphic or they could be not isomorphic and so uh the professor wants to be convinced either way whatever the students whatever answer the students come up with we're going to shift this into a problem about a um deciding a language next but right now i'm just trying
1748	to give a sense of the how the model works i want to move from this informal model and now i'm going to formalize that in terms of model which will be deciding a language okay so so the interactive proof system model we have two interacting parties a verifier which is probabilistic polynomial time playing played by the professor in the previous slide and the prover which is unlimited computational power played by the students in the previous slide both of them get to see the input which in the previous case well it could be for example the pair of graphs they exchange a polynomial number of polynomial size messages so the whole exchange including the verifier's own computation is going to be polynomial the only thing that's not not not included within the computational cost is the prover's work which is unlimited um after that the verifier after the interaction the verifier will accept or reject and we're going to define the probability that the verifier together with a particular approver ends up accepting as you look
1749	over the different possible coin tosses of the verifier which could lead to different behavior on the part of the verifier and therefore different behavior on the part of the approver so over all the different possibility possibilities for the verifiers computation we're going to look at the probability that the verifier with this particular approver ends up accepting and i've written it this way this is the probability of the verifier interacting with the prover accepts the input is just simply that um and so we're going to work through an example we're going to work through the previous example more precisely in a second the class ip for interactive proofs stands for it's the class of languages such that for some verifier and approver um for strings in the language the prover makes the verifier accept with high probability and here's the interesting part for strings not in the language the prover makes it except with low probability but every there's no prover which can make it except with high probability so there's no way to cheat if
1750	you think about it in the case of the graphic non-isomorphism there's nothing you know if if the graphs were really isomorphic and the students were trying to in a devious way prove through that protocol that they're not isomorphic they would fail because there's nothing they can do if the graphs were isomorphic then um when the verifier the the professor picks one or the other at random um and scrambles it the students would have no way of telling which one the professor did so no matter what kind of scheme they try to come up with they're going to be out of luck so it's no mat for any strategy for strings that are not in the language for any s any prover calling that p with a tilde to stand for a devious or crooked prover for any uh possibly crooked prover even that with working with the verifier is still going to end up accepting with low probability so strings in the language there's going to be an honest prover who just follows the protocol
1751	in the correct way which makes the verifier accept with high probability for strings not in the language every prover is going to fail to make it accept with high probability um okay so that i mean the way i like to think about it is that p tilde is a possibly crooked proverb which is trying to make the verifier accept when it shouldn't because the string is not in the language it's like you know it's like even you can think of this in the case of um satisfiability um you know you a crooked prover might try to convince of the verifier that the formula is satisfiable when it isn't by by somehow trying to produce a satisfying assignment but that's going to be impossible there's nothing any strategy can possibly work when the formula is not satisfiable if that's what the verifier is going to check it's going to be looking for that satisfying assignment okay and by the way this is we're not going to prove this but it's really going to be proved in
1752	the same way you can make that one third error that could that occurs here something very tiny by the same kind of repetition argument okay so let's see um so why can't the prover in the first case be crooked um the prover in the first case would could be crooked but that's not going to serve the purposes um you know what what we want to show um you think about it like we think about np for strings in the language there exists a certificate there is a proof that you're in the language so if somebody is going to not produce the proof that's irrelevant the question is if you look at the best possible case the best possible prover um you know who's going to be able we're asking does there exist a way to convince the verifier that the um string is in the language so it doesn't matter that there might be some other uh silly way that doesn't work we're just looking at the best possible way so the best possible way
1753	when you're in the language is going to end up with a verifier having high probability when you're not in the language the best possible way is still going to end up with low probability when when i talk about best possible i'm trying to maximize the probability that the verifier is going to end up accepting let's continue um not sure as clear as i would like but um maybe again we're going to we're going to stick with that example because this is a very uh helpful example and to try to understand the setup and uh so we're gonna i'm gonna revisit that previous example about non-isomorphism but now in the context of this thinking about as a language so we're going to take this non-isomorphism um uh yeah we're going to take the non-isomorphism problem and show that it's an ip so there's going to be a verifier together with approver which are going to make the verifier accept with high probability for strings in the language namely graphs not ice being isomorphic and nothing there's
1754	going to be no way to make the verifier except with high probability for strings out of the language therefore that's when the graphs are isomorphic okay um so the protocol is just gonna we're gonna repeat the following thing twice you know i said in the previous case do it a hundred times just to help us think about it but actually
1755	so the verifier is going to operate like this in terms of this is the verifiers in first communicating sending messages to the approver it's going to randomly choose grh just like what the professor did last time randomly permute the result to get a new graph k which was going to be which was which is isomorphic either to grh depending upon the choice the verifier made and then send that graph k now the provers turn is going to respond by the proof is going to compare k with the two one of the both of the original graphs it's got to be isomorphic to one or the other and it's going to report back which one just going to say well you pick g no or you picked h because the prover with its unlimited capabilities can determine that um and then v accepts if the approval was right both times um and if the approval was ever not right the verify says oh something's fishy here because we know that the prover has unlimited capability so
1756	could get it right if you know um if there was if this was an honest approver um and so um if uh if it's not getting it right then the verify is going to reject so if the graphs are not isomorphic the proofer can tell which one it picked randomly so therefore if the graphs are not isomorphic the verifier with that that honest prover will accept with probability one because that honest proof is always going to get the right answer which is at least two-thirds is what the bound we need uh we don't care about the space used in answer to a question um if we were not in the language so g and i h are not isomorphic then there's nothing any crooked pervert could possibly do because it gets a graph can't tell there's no way to tell whether it came from g or came from h um so that crooked proofer would have all it could the best thing you could do is guess sort of a 50 chance advancing correctly each
1757	time and only a 25 chance for doing it twice and that's why i did it twice in order to get that error um uh to be small so there's only a 25 chance of the approver getting lucky so that would be an error case if the proof of just by chance picked the right answer twice even though the graphs were isomorphic so therefore for the isomorphic case the verifier interacting with any prover is going to accept that input with at most one quarter 25 of the time which is less than a third so those are that's just to achieve that bound okay so let's let's answer some questions first and then i'll try to um uh i'll ask you you understand this so this it's i think it's worth trying to understand this model um of this interactive proof system it's a little little slippery i i realize but um if you just hold your hold on to your intuition of the prover trying to convince you know of uh you know a powerful prover
1758	trying to convince a limited verifier um of some string being in a language uh you want the proven to be able to succeed when the string is in the language but fail when the string is not in the language yes we are going to somebody's asking if the prover is identifying grh by brute force yes the prover is going to use its unlimited capabilities to determine given k whether it came from g or h the um the computational cost of the approver is irrelevant for this it's just like when we think about a certificate um you know for satisfiability we don't talk about the cost of finding that certificate uh for np for ip again we don't talk about the cost of the prover running so somebody's asking does the crooked per prover answer just randomly or does uh can the cr quick approver has have a strategy the crooked perimeter can have a strategy now we're not we're assuming the crooked approver is devious but it's still going to fail okay um let's do
1759	the check-in suppose we change the model so that the prover can watch the verifier picking its random choices so uh the verifier cannot act in secret anymore but the the prover can watch the verifier now let's suppose we had the same protocol that i just described what language do we end up with is it the same language different language and what is that language okay so i want to hopefully um let's let's it'll give me some sense of how well you're following me by how well this uh this goes yeah someone's asking about how this connects up for example with np so we're going to look at that also in a second okay so this is reassuring that most of you i think are on the right track at least for this check-in uh do we assume p uses this access to guess right what access p is not really guessing the p is tr is actually i don't think a p is non-deterministic or anything like that p is actually trying to get the
1760	right answer and using its computational ability to do that if it's possible may not be possible then there's nothing you can do okay so let's uh end this are you all in two seconds left please vote vote now or never okay ending um yeah so c is the correct answer here if the prover can watch what the verify is doing the prover can see what graph the verifier picked right from the beginning and so the prover without having to do any work can say you know it proves looks over the verifier's shoulder and says oh you picked g and now you're randomly permitting it but i don't care about that i just i know you pick g uh so uh the proof is going to respond back uh g even if the graphs were isomorphic the proof is going to be able to get the right answer kind of interestingly um uh you can make a you can change the protocol somewhat um to make it uh that even if the prover has access to
1761	the verifier's randomness you can still achieve this but not with the same protocol um so that's uh that's a separate question
1762	okay here's another check-in um uh okay so you have to tell me which of the following statements are true as far as you know now you have to think about a little bit how this these uh relate to um how np and ip or bpp and ip relate to one another okay how are we doing on this okay so we're gonna have to close this pretty soon too do the best you can interesting okay closing up shop last last vote okay one two three there's one more person out there who hasn't voted who voted last time oh well uh all right in fact they're all true um let's see why is np contained with ip contained in ip uh well many of you have seen this already so let's just quickly go through it um [Music] if we just had a deterministic v um you know the uh you can uh maybe it's just that that can be enough of deterministic v i think it's just going to be equivalent but actually just to be
1763	doubly sure the deterministic v and the approver just sends a message to the verifier and then checks it that's the way we normally think about a certificate for np uh i don't think it's going to change anything but should double check that if the verifier can still ask questions but i think as long as the verifier is deterministic you're going to get exactly np here um and um now how about bpp well there you don't even need approver because the verifier is already probabilistic so verifier can ignore the approver and this one is a little tricky uh i p containing p space because we haven't covered that so there's no way for you to know that unless you happen to read ahead in the book but it's in fact true um in some ways it's a little bit like the proof that uh np is contained in p space ip is sort of an enhanced version of np and you and there's just a basically a uh a piece based brute force algorithm that goes
1764	through the entire tree of possibilities um of the verifier exchange verifier with exchanges with approver and can uh determine that um the verifier is either going to accept for some approver or is going to end up projecting for every approver um so we're not going to prove this statement but something good for you to know anyway they're just a fact uh but we're going to do what the surprising thing in reference to part c is that the containment also goes the other way this is the amazing um uh was is an amazing result that everything in p space you can do with in ip so this is ip is actually turns out to be incredibly powerful gives you everything up in p space you get i p equals p space so that says that any problem that you can solve in p space like any of the a game for example um if you can imagine you know formulating you know checkers or chess as a piece based problem which you know depending upon some
1765	details of the rules you can do because you know you have to generalize it to an end by end board but okay let's not quibble um uh then uh um [Music] we don't know which side has a forced win in chess um and even if somebody goes through the effort of going through the game tree um and determines that let's say white has a forced win uh there's no way for them to there's no short certificate we don't know that that problem is not an np but by going through an interactive proof an all-powerful prover could still convince somebody that white had a force you know convince somebody in polynomial time that a white has a forced wind let's say in um in chess again little uh stretching things because this is you know you really need to talk about this as an n by n not an eight by eight but i think in this the spirit is is uh fair so um okay uh so let's continue so wha when we're not going
1766	to quite prove that that p base is contained in ip we're going to prove a somewhat weaker statement but very similar um is that uh and historically came first that co-np is contained in ip so not only is np contained in ip but we're going to prove that co np is contained in ip and this actually has most of the i most of the idea for the p space being contained in ip and itself it's just an amazing proof a little easier um okay and th this was done if i'm remembering somebody's asking me when how old is this it's something in the 19 i think late 90s but i'm not i don't remember but maybe early 90s i think it's late 90s when this was shown so it's been a while now um okay so um yeah so in terms of the relationship with cryptography there were two parallel threads um that both independently came up with the notion of an interactive purge system uh i was a little bit personally involved with this
1767	in in a way as well but but mainly that the the there was one group in cryptography um working on this and there was another group who was actually coming out of the graph isomorphism world working on it and they they came up with two separate models one involving the private randomness and one involving the public randomness um and it was turned out that was that they're actually equivalent um and uh
1768	uh so why don't we move on and i'm gonna start showing you how the proof that co-np is contained in ip goes and what we're going to do is work with a problem that's almost like co p complete but um going to be uh well it's going to be this number sat problem we'll see the connection with co-np in a second uh so cohen p so it's supposed to be exactly k satisfying assignments fee comma k is the set of pairs where the formula fee has exactly k satisfying assignments so really that's a problem of counting how many satisfying assignments you have in a formula um so you know for np you have at least one um but i'm i want to know exactly how many uh so the numbers that problem is the pairs formula and the count so um and uh so if we define the count number fee is the number of satisfying assignments of a fee then another way of writing this uh number stat problem is uh the pairs phi
1769	k where k is the number of satisfying assignments of fee so we're going to be using this notation number fee a lot so just make sure you get you got that notation this is the number of satisfying assignments of that formula okay and here's a definition i probably should have given you earlier in the term but better late than never um uh so the notion that a language is np hard it's like np complete except without being necessarily being in np so this is just the reduction part a language is np-hard or co-np-hard or p-space hard or any of those other classes that we looked at if every problem in the class is reducible to that language but you don't know whether this that that language is in the class so we just call it np hard instead of mp complete so you could say the language is np complete if it's hard and it's in np okay and so we're going to show that this number set problem is co np hard so everything
1770	in cohen p is polynomial time reducible to number set that's easy because what we're going to do is take a co np complete problem which is the unsatisfiability problem the complement of satisfiability and sure that reduces to the numbers that problem and that's easy because a formula is unsatisfiable exactly when it has zero satisfying assignments so if you can tell how many satisfying assignments something has exactly or you can answer the question you know does a formula have exactly a thousand satisfying assignments if you can do that in general then you can solve co and p uh you can solve the unsatisfiability problem by asking with zero satisfying assignments and that allows you to solve anything in cohen p okay so we're gonna just work with this one problem the number set problem and show that that problem's in ip okay let's take a quick break um okay feel free to send me let me see if i can catch up with some of the questions that have been cropping up here so if the
1771	approver knows the random choices of the verifier can it can flip the answer to make the verifier reject not sure what that you mean in the context just of the graph isomorphism problem or um something in general i'm not sure you'll have to explain sorry i'll respond with a question mark what else can i answer for you guys so i got a question might if i p equals p space does that mean that iso or the or non-iso might be um in might be p space complete but no that's not known so we're about out of time okay
1772	okay so this this is where we're kind of getting going to start to get into the meat of things um [Music] and if you didn't quite understand everything up till now maybe just try to keep your intuition about how do i you know how does a powerful party convince a um a polynomial probabilistic polynomial time party of the number of satisfying assignments exact number not not at least but you won't know exactly the number um of satisfying assignments um so it could be zero for example how do you convince that how do you convince someone that there were zero assignments and and and you know you can have an interaction which does that and that's not obvious at all how you're gonna do that um uh all right so um okay so we're gonna have to introduce some notation which i don't hope this doesn't cause heartburn here uh so let's say again here is the the computational the language we're working with number set and we have a fee where that has m variables
1773	x1 to xm now here's our notation i'm going to if i write phi with this free phi of 0 that just means the formula that i get by plugging in 0 for x one and leaving all the rest of the variables uh alone okay so i substitute zero for x one where zero means false and one means true as usual and but that's it's going it's still going to be some other formula but just with that substitution if i write fee 0 1 that means i preset the first two variables to 0 and 1. um if i write fee with a bunch of preset values i'm just setting the first i variables x1 to xi to some values and leaving the other variables as unset so i'm calling the ones that i'm nailing in there as i'm already saying these are the presets okay so this is just converting some formulas into other formulas that have somewhat fewer variables all right now let's recall that number notation the number sign notation number fee is the
1774	number of satisfying assignments now if i say number fee of 0 that's the number of satisfying assignments when i've preset x1 to 0. similarly if i preset the first i variables to some values and then i take i want to think how many how many satisfying assignments subject to those prefix presets i write it this way so i'm going to use this notation a lot you have to understand this notation ask if you don't none if you don't get it so another way of writing it i don't know if this is helpful but another way of writing number fee of a1 to a i remember we have m variables all together that means i take the variables which i have not yet preset um and i allow them to range over all possible zeros and ones and i add up the the formulas values for all of those so there's a one every time i satisfy and a zero every time i don't satisfy so i'm adding up all the satisfying assignments subject to these
1775	i presets okay so here are two critical facts about this number sign notation first of all if i preset the first i values to something now i can in addition set the next variable either to zero or to one and i get this relationship which is just simply a generalization of the fact that the total number of satisfying assignments of the formula is equal to the number of satisfying assignments when x1 is 0 plus the number of satisfying assignments when x1 is 1. right they together have to add up to the total number because x1 is going to be the either zero or one so that's fact number one fact number two is that if i preset everything all of the variables so there are no variables left then the number of satisfying assignments subject to that preset of everything is just whether or not i've satisfied the formula which is the value of the formula on that those presets okay both two simple facts but it's going to be critical in the protocol i'm
1776	about to describe questions on this i think actually i do have a question for you so let's just see what do you think just to check your understanding okay got about 80 getting this um i'm not sure that's good but uh all right almost done closing okay okay so uh yes a is the correct answer you know if if there are nine satisfying assignments all together and there are six satisfying assignments where the first variable is set to zero then there's only three satisfying assignments with the first variable set to one because nine has got to be equal to six plus three that's actually this fact number one it's not going to be 15 this is not true either so it's just a
1777	okay so let's try to with with that knowledge let's try to see how we can put number sat in ip so this is not going to quite work but it's really going to set us up to do this to finish this next time um so you might immediately see where this is going wrong but you'll you'll have to put up with it because um the setup is what's important um okay so understand now here's the here's the the setup we have um the input is a formula and a number where that number is supposed to be the number of satisfying assignments you know it could be wrong and in which case we're not in the language um but if it's right you're in the language so the approver is supposed to convince the verifier that it's correct if it is correct and it's not gonna it's gonna fail no matter what it tries to do if it's uh not correct so this is the approver is going to send first of all um so so
1778	the proof is going to send a claim about the number of satisfying assignments going to send when i say this value here this is what the prover if it's honest is going to send the right value of course the verifier does not know if the approver is honest but i'm describing how the honest approver is going to operate and we'll have to understand what happens if the prover tries to cheat so the proof is going to send the honest proof is going to send the number of satisfying assignments all together and the prover verifier just makes sure that that matches up with the input if it doesn't match up with the input uh the verifier is just gonna you know you know the the verifier is gonna not be convinced that the input is um in the language so it's gonna just uh reject at that point um okay uh then now the verifier says okay that was very good that you sent me this how do i know that's right so what the verif
1779	prover is going to do to try to convince the verifier that this value was correct is uh unravel that by one level by say well you know there were nine satisfying assignments all together uh six of them were when the when x one is zero and three of them were when x one is one to verify what does the verify have to check that these add up correctly when i preset x1 to zero and to one it had better add up to the total number of satisfying assignments if that works out the verifier is happy is still being it's still consistent with being convinced that this k was the right value um so um the next step is well the verifier says well how do i know those two values are correct the prover says okay well i'm going to prove send un unravel them one level further then here's a number of satisfying assignments when the next variable is set to both possibilities for each of the possibilities of the first variable now if
1780	you're understanding me about what the prover is sending you should start to be getting a little nervous because something is i mean this is going to be correct but it's going to start it looks like it's starting to blow up in terms of the number of amount of work that's involved and that's actually a problem but let's bear with that for the moment let's just worry about correctness not about complexity for the moment so the proof is going to now send the number of satisfying assignments for each of those four possible ways of presetting the first two variables and the verifier is going to check that that was consistent with the information the prover sent in the previous round right by again checking this identity here so then the proof is going to continue on doing that until it's got it's done that through m rounds where m is the number of variables so at this point the proof is going to send all possible ways of presetting all of the variables so that now
1781	there's two to the m possibilities here again this is hopelessly not allowed but okay ignoring that the proofer's got to use this at the nth round to check what happens at the at the previous round so that's when they were m minus one values sent because each one has one more uh uh you're extending the presets by one so which using this to check that the previous round was the values were correct so it's looking for um you know the m minus one presets have to add up correctly um you know in terms of the m the presets of m uh values uh for each of those ways of uh doing those uh m minus one presets and so now the provers send all of those two to the m counts which are by the way ones and zeros because at this point we have preset all of the values of the variables and so there's only one possible assignment at most that there can be and now the verifier the approver is done the
1782	verifier is going to check by itself that these values make sense that these values are correct so it's going to do that by looking back at the formula so far up at this point the verifier has not been looking at the formula it's just been checking the internal consistency of the provers messages with each other but now at the end the verifier is going to take the messages these these values that the approver sent for each of the two to the m presets and see if it matches up with what the formula would do remember that was the other sort of the base case of the the end the fact number two um from the uh slider to ago make sure that these agree okay and now the verifier says well okay if everything has checked out and all of these are are in agreement then the verifier is going to be convinced that um that uh fee had k satisfying assignments but if anywhere along the way one of these checks fails the approver
1783	is not the verifier is not going to be convinced and is going to reject okay so in a sense this is kind of dopey you know you know we've just i'm just kind of giving you a complicated way of just counting up one by one each of the satisfying assignments of the formula and seeing if that matches k but nevertheless this way of looking at it is gonna be uh help us to understand um the way to fix this so so bear with me for another minute on this one so another way of looking at this which i think is is particularly useful is to think of what happens well okay we'll get there in a second i want to look at what happens if k was wrong but before i do that let's look at the i'm going to give a kind of a graphic a graphical view of um the information that the prover sends and the and the verifiers actions in this protocol so the the values that the prover sending are
1784	going to be in yellow so the and the information that the verifier has or checks is going to be in white so the the verifier has the k the the input value which is supposed to be the number of satisfying assignments and the prover sends some value and the verifier checks that this value which is supposed to be the number of satisfying assignments corresponds with k so that's one of the checks it does then the approver is going to send kind of take to justify this value it um sends the number of satisfying assignments when you have x1 set to zero or set to one the verify adds those up to give you and it's supposed to equal the total number of satisfying assignments and so this is if you understood this protocol this is just i'm writing it out in a sort of a simplified way perhaps okay and so um keeps checking that these things add up correctly until you get down to setting all m values in all two to the impossible
1785	ways and now the verifier is going to then check to make sure that that equals the what the formula would say um okay okay so now let's what happens if k was the wrong value it did not agree with the number of satisfying assignments um and what does what happens now um could the prover what happens if the approver tries to make the verifier accept anyway so um so the only thing the prover can do at the very first step would be to lie um about you know if the approver sends the if k is wrong and the proof approver sends the correct value for the the the total count the verifier is going to reject so i'm trying to see is it could the approver try to make the verifier accept what what happens so the prover has to lie here and i'm going to indicate that by saying the approver is sending in the wrong value for um uh the the total count well if the proof is going to lie here um
1786	then just like you know if you you know you have a child who um tells a lie and then you start you know as the parent you start asking questions to try to see if the story is consistent one lie is going to lead to another lie um and that's what happens here if the uh in order to justify this lie um the proof is going to have to a lie in one or perhaps both but at least one of these two values because you can't have the two correct values adding up to the incorrect value because you have to think about what's going on here so if this is a lie that's going to force a lie at one of one side of the other one level down which is then going to force a lie to propagate down and so there's a lie at every stage is going to force a lie at least in one one place or another to propagate all the way down to the bottom and then at the
1787	bottom the verifier will see that the check doesn't work as when it turns when it tries to connect it up with the formula itself and the form verifier will reject okay so just a way of looking at this um if the form if the value if the input was not in the language um so uh but the problem is that as i said that this is exponential so how are we going to fix that so just looking ahead to what we're going to do on tuesday okay let's see if there's any questions here first of all uh okay yes i got a question should this be uh should this be a minus i i purposely made this bracket only go not include the very last zero yeah there's a total of m zeroes here all together but the i left out the last zero that's why i said n minus one maybe it would have been better to say m okay so and you got another interesting question here why can't we reject right away
1788	if k is wrong um uh well the verifier is probabilistic polynomial time how does the verifier know if k is wrong um so it means or or or right so what we're trying to do is something like you know like np where we have a certificate but now we have this kind of interactive certificate in the form of disprover maybe that's another way to look at it um where if you're in the language there should be some way for the prover to convince to get make you accept but if you're not not in the language there should be no way for the proverb to make you accept um uh so the verifier just can't reject right away because there's no way to tell how does the verifier know it's going to start rejecting things when it shouldn't if it's just going to be rejecting willy-nilly here um okay how does the verifier need to determine if the prover is internally consistent instead of just asking so why does the verifier need to determine if the
1789	approver is internally consistent instead of just asking the questions in step n plus one yeah so maybe that's because it looks like all of the work is happening at the very end um but i'm really presenting this to you as a preparation for what we're going to do on tuesday um so it's important to think about the connection from each step to the next each step is going to be justified by what happens at the next step until we get to the very end so you have to just understand it for what it is don't try to make it more efficient yeah i realize this is kind of dumb um good point we're not using the probabilism here um and moreover we're not really even using the interaction here the prover is doing all the sending the verifier is just accepting at the end yeah this is we're not using the power and we're getting a weaker result so let's move on before we run out of time here so how do we gonna fix
1790	this so the problem is is blowing up each to justify each stage where each value we're um needing to present two values which add up to it um and that's uh good leading to a blow up now it would be nice if we can do something where each value was supported by just a single value at the next level so we know here's an idea well you know in order to understand to see that uh that that this total count is correct why don't we just pick at random either zero or one and only follow that one down well the problem with doing that is because the the the sequence of lies is could be just a single path through this uh tree and the chances you're going to find that path down to a contradiction at the bottom is very low if you're just doing it at random um so just randomly picking zeros and ones as as the as the one you're going to justify used to justify the previous value is not
1791	going to be good enough so what but this is what we're going to do however the values that we're going to pick for um for these random um inputs are not going to be boolean values we're going to pick non-boolean assignments to the variables which again just as with the branching program case didn't make any sense on the surface of it we're going to have to make it make sense and we'll have to see how to do that on tues in tuesday's lecture okay so that's kind of the setup okay um yeah so in a similar question why is this any different from just non-deterministically guessing the assignments it's because of this we're really setting the stage okay so what we did today was we introduced them the the model and defined the complexity class we can we did show this one in its full glory we showed that non-iso is an ip really worth understanding this uh protocol here making sure you you're comfortable with that and and also the the model itself and
1792	so for tuesday's lecture we're going to finish this up uh well we started showing that number set as an ip which is what we need to to do to prove co-np is an ip and we'll finish that next time which will be our last time okay so that's it for today i'll stick around for questions so a good question here why can't um v just reject if some of the checks are incorrect yes v could as soon as there's a check that fails we can just reject at that stage i'm just trying to argue that at some point along the way if the input is not in the language there's going to be a check that fails so i mean i said reject at the end but yeah i mean you could have rejected at any point along the way um okay um someone's asking for what what role did i play uh so i did my my own personal role in this i were to which was twofold first of all i i came
1793	up with the idea uh of well not the idea i came up with the name interactive proof uh i remember when sylvia mccauley was explaining this to me in my apartment many many years ago he had a kind of a little bit complicated and i don't even remember what the protocol was for it was not for something simple was something involving uh prime numbers and i said oh that's a kind of an interactive proof and it's and it it stuck from that point on so um that was one thing but the other thing in terms of more mathematically i my role was so uh shafi goldwater and i approved the equivalence of the two models the public coin and the private coin version um so that that was uh my uh my role in this back and when this was all first coming out approved it approved it on an airplane on the way to a conference somewhere so i think we're going to notice any other questions i think we'll head out take care
1794	everybody see one see you on tuesday bye bye
1795	[SQUEAKING] [RUSTLING] [CLICKING] MICHAEL SIPSER: Why don't we get started. So as I like to do, let's just review where we have been recently, which
1796	We talked about the context-free grammars and the pushdown automata as a way of describing the context-free languages. As you remember, the context-free languages are a larger class of languages than the regular languages, which is where we started, the languages of the finite automata. So when you add a stack, you get more power. You get more languages that you can do. And we're very rapidly going to be moving on today to our main model for the semester, which is called the Turing machine. So let's just take a look at what we're going to be covering today. And that is, first, we're going to show that a technique analogous to the one we use for proving that languages are not regular, but this time for proving languages are not context-free. So the pushdown automata and the grammar still have their limitations in terms of what we normally think a computer can do. And with that, we're going to use that as a kind of a lead-in to our general-purpose model, which is the Turing machine. And so
1797	we're going to talk about Turing machines and aspects of that. I would want to comment-- so I have posted the solutions for the first problem set. I know you're starting to think about the second problem set now, which I have posted as well. If you want to get a sense of what I'm looking for in terms of the level of detail, you can look at the solutions to problem set one, because I consider those to be model solutions. That's part of the reason why I post them, just to give you a sense of the level of detail that I'm looking for, which is not a whole lot. But I do want to make sure you're capturing the main ideas of what's involved in solving the problem. So have a look at those. And for problem set two, which I'll talk about in a second-- so I'll just say a few words. If you want to pull that up, you can do that. But just to get you started on a few of the problems if
1798	you're finding some challenges there-- I don't want you to get stuck really before you even understand what the problem is saying. So for problem number one, if you looked at that, so that's a problem where you're asked to prove a certain language is not context free. And by the way, all of the problems in this problem set except perhaps for the last, for number six, you'll be able to solve. We'll have enough material at the end of today's lecture to solve all of them. I believe that's right. Yeah, so number six, you should have enough as of Thursday's lecture to solve that.
1799	is not context free. So we're going to introduce a method for doing that. That method is going to come in handy. For parts B and C, if you look at the problem set, it has this strange-looking thing, sigma sigma sigma in parenthesis star. It's really just a regular expression that's very simple. You should just make sure you understand that that's a way of representing all strings whose length is a multiple of 3. And if I stick a sigma in front of that, it's all strings whose length is 1 plus a multiple of 3. So once you understand that, and if you think about what kinds of strings are in the language C2, it'll help you to understand what happens when you take those unions. And parts B and C are not intended to be very hard, but you just have to understand what's going on.
1800	I touched on that briefly in lecture. It's enough to solve the problem. The book has a little bit more detail about ambiguous languages, ambiguous grammars-- ambiguous grammars, I should say. And so this is a grammar that's supposed to represent a fragment of a programming language with if thens and if then elses. I'm sure you're all familiar with those kinds of constructs
1801	And there is a natural ambiguity that comes up in a programming language. If you have if some condition then statement one, else statement two, I presume you understand what the semantics of that is, what that means. And the tricky thing is that if you have-- those statements can themselves be if statements. And so if you have the situation where you have if then and if then else is what follows that, the question is, where does the else attach? Is it to the second if or to the first if? So that's kind of a big hint on this problem, but that's OK. You need to take that and figure out how to get an actual member of the language which is ambiguously generated, and then show that it has-- show that it is by showing two parse trees or two leftmost derivations. If you read the book, you'll see that's an alternative way of representing a parse tree. So and then what you're supposed to do is give a grammar for the same language which is
1802	"unambiguous. You don't have to prove that it's unambiguous, because that's a bit of a chore. But as long as you understand what's going on, you should be able to come up with an unambiguous grammar which resolves that ambiguity. And I don't have in mind changing the language by introducing new programming language constructs like a ""begin end."" That's not in the spirit of this problem, because that's a different-- it's grammar for a different language. So you need to be generating the same language without any other extraneous things going on that are going to resolve the ambiguity. The ambiguity needs to be resolved within the structure of the grammar itself. So keep that in mind. For problem number three about the queue automata, you know, that came up actually as a suggestion last lecture, I believe, or two lectures back. What happens if you take a pushdown automaton, but instead of a pushdown-- instead of a stack, you add a queue. What happens then? Well actually, it turns out that the model you get is very powerful."
1803	And it turns out to be equivalent in power to a Turing machine. So you'll see arguments of that kind today, how you show that other models are equivalent-- no, not today. So I apologize. This is going to be something that you'll-- I'm confusing myself here. Problem number three actually needs Thursday's lecture as well to really at least see examples of how you do that kind of thing. Yeah, so I'll try to send out a note clarifying this. By the end of Thursday, you'll be able to do everything, except for problem six. And for problem six, you'll need Tuesday's lecture, a week from today's lecture, to do. So problem number four, that one you'll be able to do at the end of today. That's also going to-- the problem is I'm working on preparing Thursday's lecture too. So I'm getting a little-- I'm confusing myself. Problem number four, you'll be able to do after Thursday's lecture. Maybe we should talk about that next lecture. Problem number five, you can do today, but maybe I'm not going
1804	to say anything about that. And problem number six, I won't say anything about either. OK, so why don't we just jump in then and look at today's material. What about seven? Oh, seven is an optional problem. Oh, I should have mentioned that. Seven is always going to be an option. I indicate that with a star I should have made that clear on the actual description here, but seven is optional. It's just like we had for problem set one. OK, let's move let's move on, then, to what we're going to talk about today. And just a little bit of review-- so we talked about the equivalence of context-free grammars and pushdown automata, as you remember. Oops, let me get myself out of the picture here. As we mentioned last time, we actually proved one direction, but the other direction of that, you just have to know it's true, but you don't have to know the proof. The proof is a little bit lengthy, I would say. It's a nice proof, but it's pretty long. And there
1805	are two important corollaries to that. If you know what a corollary is, it's just a simple consequence which doesn't need much of a proof, sort of a very straightforward consequence. First of all, I think we pointed out last time, one conclusion, one corollary you get is that every regular language is a context-free language, because a finite automaton is a pushdown automaton that just happens not to use its stack. So immediately, you get that every language is context free. And second of all, you also immediately get that whenever you have a context-free language and a regular language and you take their intersection, you get back a context-free language. So context free intersect regular is context free. That's actually mentioned in your homework as well as one of the 0.x problems which I give to try to get you-- you don't have to turn those in, but I suggest you look at them. I don't know how many of you are looking at them. But this is a useful fact. And some of those other facts in
1806	0.x problems are useful. So I encourage you to look at them. But anyway, intersection of context free and regular is context free. You might ask, what about intersection of context free and context free? Do we have closure under intersection? The answer is, no, we do not have close to closure under intersection.
1807	So here is the proof sketch for--
1808	free and regular, why do we know that's still context free? Because the pushdown automaton for A can be simulating the finite automaton for B inside its finite control, inside its finite memory. The problem is, if you have two context-free languages, you have two pushdown automata, you can't simulate that with one pushdown automaton, because it has only a single stack. So if you're trying to take the intersection of two context-free languages with only a single stack, you're going to be in trouble, because it's hard to-- anyway, that's not a proof, but at least it shows you what goes wrong if you try to do the obvious thing. OK, so if-- and just, here is an important point that was trying to make before. If A and B are both context free and you're taking the intersection, the result may not necessarily be a context-free language. So the class of context-free languages is not closed under its intersection. We'll comment on that in a bit. The context-free languages are closed under the regular operations, however, union, intersection--
1809	union, concatenation, and star. So you should feel comfortable that you know how to prove that. Again, it's one of the-- I think it's problem 0.2. And I think the solution is even given in the book for it. So you just should know how to prove that. It's pretty straightforward. OK, so let's move on then to basically conclude our work on context-free languages, to understand the limitations of context-free grammars, and what kinds of languages may not be context free. And how do you prove that? So how do you prove that, for some language, there is no grammar? Again, you know, it's not enough just to, say, give an informal comment that, I couldn't think of a grammar, or some-- things of that kind. That's not going to be good enough. We need to have a proof. So if we take the language here, 0 to the k, 1 to the k, 2 to the k, so those are strings which are runs of 0's followed by an equal number of 1's followed by an equal number
1810	of 2's, so just 0's, then 1's, then 2's, all the same length. That's a language which is not going to be a context-free language. And we'll give a method for proving that. If you had a stack, you can match the 1's with the 0's, but then once you're done with that, the stack is empty. And how do you now make sure that the number of 2's corresponds to the number of 1's that you had? So again, that's an informal argument that's not good enough to be a proof, but it sort of gives an intuition. So we're going to give a method for proving non-context-free-- languages are not context free using, again, a pumping lemma. But this is going to be a pumping lemma that applies to context-free language, not to regular languages. It looks very similar, but it has some extra wrinkles thrown in, because the other older pumping lemma was specific to the regular languages. And this is going to be something that applies to the context-free languages. OK, so now let's just read
1811	it. And then we'll try to interpret it again. It's very similar in spirit. Basically, it says that, whenever you have a context-free language, all long strings in the language can be pumped in some kind of way. So it's going to be a little different kind of pumping than we had before. And you stay in the language. OK, so before, we broke the string into three pieces where we could repeat that centerpiece as many times as you like. And you stay in the language. Here, we're going to end up breaking the string into five pieces. So s is going to be broken up into uvxyz. And the way it's going to work here-- so here is a picture. So all long strings-- again, there is going to be a threshold. So whenever you have a language, there is going to be some cut-off length. So all the longer strings in that language can be pumped. And you stay in the language. But the shorter strings, there is no guarantee. So if you have a long string
1812	in the language of length at least this pumping length p, then you can break it up into five pieces. But now it's that second and fourth string that are going to play that special pumping role, which means that, what you can do is you can repeat those and you stay in the language. And it's important that you repeat them both, that v and that y, the same number of times. So you're going to have a picture that looks something like this. And that is going to you repeat. If you repeat the v and you repeat the y, you get uvvxyyz. Or if you look at over here, it would be uv squared xy squared z. And that's going to still be in the language. And then we have-- so that's one condition. We'll have to look at all of these conditions when we do the proof, but we just want to understand what the statement is right now. So the second condition is that v and y together cannot be empty. And really, that's another
1813	way of saying, they can't both be the empty string, because if they were both the empty string, then repeating them wouldn't change s. And then of course it would stay in the language. So it would be kind of meaningless if they were allowed to be empty. And the last thing is, again, going to be there as a matter of convenience for proving languages are not context free, because you have to make sure there is no possible way of cutting up the string. When you're trying to prove a language is not context free, you have to show the pumping fails. It's going to be helpful sometimes to limit the ways in which the string can be cut up, because then you have-- it's an easier job for you to work with it. So here, it's a little different than before, but sort of similar, that vxy combine as a substring. So I show that over here. vxy together is not too long. So the vxy-- maybe it's better seen up here-- is going to be, at
1814	most, p. We'll do an example in a minute of using this. OK, so again, here is our pumping lemma. I've just restated it. So we have it in front of us. And we're going to do a proof. I'm just going to give you the idea of the proof first. And then we'll go through some of the details.
1815	We give it-- call it a proof by picture. Again, remember what we're trying to do. We're trying to show that we have this context-free language A. And now all long strings in A have this pumping quality, that you can break them up into five pieces so that the second and the fourth piece can be repeated. And you stay in the language.
1816	Let's take a look at the proof here. And why is that going to be true? So first of all, I'd like to do it qualitatively rather than quantitatively. So let's just imagine, instead of thinking-- we'll calculate what p is later. But just imagine that s is some really, really long string. That's the way I like to think about it. So s is just really long. What is that going to tell us? It's going to tell us something important about the way the grammar produces s, which is going to be useful in getting a way of pumping it. So if s is really long, we're going to look at the parse tree for s. And we're going to conclude that the parse tree has to be really tall, because it's impossible for a very shallow parse tree to generate a very long string. And again, we'll quantify that in a second. But intuitively, I think that's not too hard to see why that ought to be true. So if you have a long s, the parse
1817	tree has to be really tall, because the parse tree can't generate very many-- it can't expand by very much at each level. So we'll look at how much it can expand. But it depends on the grammar, how much expansion have at each level. And it's going to be-- you can't have just in three levels some small grammar generating a string of length 1 million. You'll see that that's just impossible. So once you know that the parse tree is really tall here, then you're actually almost done, because what does it mean to be really tall? It means that there is some path starting at the start variable E, I'm calling it in this parse tree, which goes down to some terminal symbol in s, which goes through many steps. That's what it means for the tree to be very tall. And each one of those steps is a variable until you get down to the very end. OK, so that's the way parse trees look. You keep expanding variables until you get to a terminal. So
1818	here, you get some path that's really a long path. And once you have a long path that has many, many variables appearing on here, well, the grammar itself has only some fixed number of variables in it, so you're going to have to have a repetition coming among the variables that occur on that long path. Got that? So a long string forces a tall parse tree, forces a repetition on some path coming out of the start variable of some other variable that comes out. Now that's going to tell us how to cut up s, because if you look at the subtrees of s that those two R variables are generating, shown like this, I'm going to use that-- so you have to follow what I'm saying here. So R here is generating this portion of s. And the lower R is generating a smaller portion of s, just looking at the subtree that you get here. And that's going to tell us that we can cut up s accordingly. So u was that very first part
1819	out here generated by E, but not by the first R. R is generated-- v is generated by the first R, but not by the second R. The second R generates exactly x. And then we have y and z, similarly. So that all follows from having a tall parse tree. And now we're finished. Now we know how to cut up s. How do we know we can repeat v and y and still be in the language? Well, I'll actually show you that you're in the language by exhibiting a parse tree for the string uvvxyyz. Here it is. I'm going to get that parse tree by, when I expand this lower R, instead of expanding it to get x, I'm going to follow the same substitutions that I had when I expanded the upper R. So it's as if I took this larger subtree here and I substituted it in for the smaller subtree under the second R. And so I get a picture that looks like this. So here I'm substituting under the second R the
1820	same subtree that I had originally coming out of the upper R, the first R. And so now this parse tree is generating the string uvvxyyz, which is what I'm looking for. And of course, you can do that again and again. And you're going to keep getting higher and higher exponents of v and y. And in fact, you can even get the 0 exponent, which means that v and y both disappear altogether. And for that, you do something slightly different, which is that you replace the larger subtree by the smaller subtree. OK so here, which was originally that larger tree generating vxy, I stick instead the smaller subtree. I do the substitutions from the smaller subtree. And I just get x there. And so now the string I generated is uxz, which is the same as uv to the 0 xy to the 0 z. And that is the idea of the proof. Now, I think you could work out the quantities that you need in order to drive this proof. I'm going to do that
1821	for you. I actually hate writing down lots of inequalities, and equations, and so on, on the board, because I think they're just almost incomprehensible to follow. Or at least they would be for me. But I'm going to put them up there just for completeness sake. So here we're going to give the details of this proof on the next slide here.
1822	I'm going to call this the cutting and pasting argument, because I'm cutting apart pieces of this parse tree and I'm pasting them in to other places within the parse tree to get new strings being generated. So this is a cutting and pasting argument. So OK, let's take a look at the details here, just, well, we have to understand, well, how big does p actually need to be in order for this thing to kick in? Well, first of all, we have to understand how fast that parse tree can be growing as we go level to level. And that's going to be dependent on how big the right-hand sides of rules are. I mean, that really tells you how many-- what's the fan out you know of each node? What's the maximum fan out? And that's going to be the maximum length of a right-hand side of any rule. So for example, in that other grammar we had seen last time for arithmetic expressions, we had this E goes to E plus T, this rule here. And
1823	in terms of the parse tree, that would look like a little element like that. And that's actually the longest right-hand side that you can get. And so the parse tree can be growing by a factor of 3 each time. Now, that's going to tell us how big the string needs to be that's being generated, what is the value of p in order to get a high enough parse tree so that you're going to get a repeated variable. Let's call the height of the parse tree for S h. So now if you-- this is just repeating what I just said. If you have a tree of height h and the maximum branching is b, then you get, at most, b to the h leaves, because each level, you get another factor of b coming up, because that's how much branching you have. So each node at one level can become b nodes at the next level down. So you're multiplying by b each time. And if you have h levels, you're going to have b to
1824	the h leaves. So the length of s, which are really the leaves here, is at most b to the h. The reason why it's at most and not exactly is you might be doing some substitutions which are shorter right-hand sides. OK, so to try to show this as a picture here, pulling that same picture we had before, we want h, the height, to be bigger than the number of variables to force a repetition. So the number of variables is going to be written this way. V is the variables. V with bars around it is going to be the number of variables. And we want that height to be greater than the number of variables. So once you know how high you want that tree to be in order to force a repetition, then it tells you how big s has to be. So V has to be bigger than b to the V, b to the size of V, because then the height that you're going to get is going to be greater than the
1825	size of V, which is-- so that's what you want. You want h to be greater than the size of V. So you're going to set p to be one more than b to the V. And so if s is at least that length, this whole thing is going to kick in. And you're going to get that repeated variable. So we'll let p to be that value where V is the number of variables in the grammar. And so if s is at least p, which is greater than b to the V, then the length of s is going to be greater than b to the V. So h is going to be what you want to make this thing work. If you don't follow that, those inequalities, I sympathize with you. I would never follow that either in a lecture. So but I hope you get the idea. But we're not quite finished yet, because I want to now circle back, and look at these three conditions, and make sure that we've captured them all, because
1826	actually, it's not totally obvious in each of those cases that we've got them. So there is a few extra things we need to do. OK, so this is concluding the argument. There are going to be at least V plus 1 variables in the longest path. So there is going to be a repetition. So now let's go back here and see, now that we have this picture with a repeated variable, how do we know we can get condition one? Well, that's just the cutting and pasting argument from the previous slide. How do we know that v and y are not both empty? Well actually, that's not totally obvious, because it's possible that, when you generated v here and you generated y, maybe going from this R to that R, you got nothing new. You know, it could have been that R got replaced by T, another variable with nothing new coming out, and then T got replaced by R. You substituted T for R and then R for T. And you've got nothing new coming out.
1827	And in that case, v and y would both be the empty string. And that would violate what we want. The way you get around-- that and these are details here. If you're not totally following these points, don't worry. They're easy to describe. So I figure, let me present the whole thing in full detail. So if going from this R to that R doesn't generate anything new, you're getting exactly the same things coming out-- v and y are just the empty string-- how do we avoid that from happening? There is a simple way to address that, which is to say, if you have this string s, when you take a parse tree, make sure you take a small-as-possible parse tree. You're not allowed to start off with an inefficient parse tree that can be shortened and still generate s. I want the smallest possible parse tree. And that smallest possible parse tree can't have an R going to another R which is generating nothing new, because then you could always have eliminated that step. And you
1828	would still have a parse tree for s, but it would be a smaller parse tree. So that would be-- I want you to start off with the smallest possible parse tree. And then you're going to be guaranteed that v or y is going to be something not empty. So that takes care of condition two. Condition three-- you know, how do we know that vxy together is not very long? And basically, it's the same argument all over again. You just want to make sure that, when you're picking the repetition R, the two R's here, you pick the lowest possible repetitions that occur, if you have many choices. And those lowest two, those lowest repetitions, there is not going to be any lower repetition here. And then by the same argument, since once you have that very first R, there is no more repetitions occurring below, the vxy can't be very long, because that would, again, force another repetition to occur. So anyway, those are the three conditions. And that's the proof of the pumping lemma for
1829	h free languages. Let's see how we use that. OK, so let's do an example of proving a language not context free using the pumping lemma. How are you going to go about doing that? Because that's the kind of thing, at the very least, you need to know how to do this in order to do the homework. I'd like to motivate you that the stuff is so interesting and fun, but it doesn't work for everybody. So for you practical people out there, pay attention so you can do the homework. OK, let's go back to that language we had a couple of slides back, 0 to the k, 1 to the k, 2 to the k. It's not a context-free language. We're going to show that now using the pumping lemma for context-free languages. So it's going to do, similar to the proofs using for non-regular languages, proof by contradiction. So you, first you assume the language is context-free. And then we're going to apply the pumping lemma. And then we're going to get a contradiction. So
1830	the pumping lemma gives that pumping length, as we described above. And now we just want to pick a longer string in the language and show that that longer string, which is supposed to be pumpable and stay in the language, in fact is not pumpable. So the pumping lemma says that you can divide it into five pieces satisfying the three conditions. Condition three implies that-- so now I'm going to I'm going to work through. I'm going to show you get a contradiction. So condition three implies that you cannot contain both 0's and-- let's pull up a picture here. So here is s, 0's, 1's, and then 2's, all of the same length. Condition three-- so if you break it up, condition three says, vxy together cannot be too long. Well, if vxy together is not too long, how could it be that, when you're repeating v and y, you stay in the language? For one thing, you can't have 0's, 1's, and 2's all occurring within v, x, and y. Some symbol is going to get
1831	"left out. So then when you pump up, you're going to have unequal numbers of symbols. And so you're going to be out of the language. OK, so no matter how you try to cut it up following condition three, which is one of the things that restricts the ways to cut it up, you're going to end up, when you pump up, going out of the language. And so therefore, it's not in-- D? D is wrong. B, should say ""B."" I'm supposed to be able to write on this thing. I guess not. I didn't test that. Oh well, that's supposed to be a B. So B is a context-free language, which includes-- so that's the assumption, that B is a context-free language. That's false. And we conclude that it's not a context-free language. Let's do-- oh yeah, I have a check in here. So let's see what I'm going to ask you to think about. OK, my head is blocking part of the text? Oh, that was a while ago. Yes, so just one question by the"
1832	way, in terms of applying the pumping lemma-- either v or y can be empty, but not both. But anyway, let's get to this check in here. So let's look at these two languages, A1 and A2, which look very similar to B, but a little different. So it's A1 is 0 to the k, 1 to the k, 2 to the l, where k and l could be any numbers, any positive, non-negative numbers. So basically what this is saying is that the number of 0's and 1's are going to be equal, but the number of 2's can be anything, whereas A2, similar, but here, we're requiring the number of 1's and 2's to be equal. And the number of 0's can be anything. Now, you can easily make, I hope-- you should make sure you can-- pushdown automata that can recognize A1 and A2, because let's just take A1. The pushdown automaton can push the 0's as it's reading them, pop them as it's reading the 1's to match them off and make sure that they're the
1833	same number of them. And then the 2's, it doesn't care how many there are. It just has to make sure that there are no strings, there are no letters coming out of order. But any number of 2's is fine. So you can easily make a pushdown automaton recognizing A1, similarly for A2. So what can we conclude from that? Here are the three possibilities. Let me-- so look at that, the class of context-free languages is not closed under intersection. You can read it. So I want to pull up the poll and launch that. Please fill that out. 10 seconds. Again, just, if you don't know the answer, just give any answers so that-- because we're not counting correctness. There is still a few dribbling in. OK, five seconds. OK, end polling. Most of you got that right. I don't know. Is it OK to share these things? I don't want to make people who didn't get the right feel bad. You know, but you should understand, I think if you're missing something, you should understand what
1834	you're missing. The pumping lemma shows that A1 union A2 is not a context-free language? No. As I mentioned at the beginning, the context-free languages are closed under union. So the pumping lemma had better not show that these-- we already know that these two languages are context free, because we get them from pushdown automaton. And we said at the beginning that context-free language is closed under union. So we know that these two are context free. So the pumping lemma better not show that they're not context free. Something would be terribly-- have gone terribly wrong if that were true. And also we know also from a little bit of further reasoning that the context-free languages is not closed under complement by what we've already discussed, because they are closed under union. And as I pointed out, they're not closed under intersection. And so if they were closed under complement, De Morgan's Laws would say that closure under union and closure under complement would give you closure under intersection. But we don't have closure under intersection. So in
1835	fact, they're not closed under complement. OK, so in fact, this does show us that the class of context-free language is not closed under intersection, because the intersection of A1 and A2, two context-free languages, is B. And B is not context free. So it shows that this is-- the closure under intersection does not hold. So let us continue, then. We have one more example. Then we'll take a break. So the pumping lemma for context-free languages, again, here is the second example. Here is the language F. We have actually seen this before. ww, two copies of a string, two copies of any string-- and we're going to show that's not a context-free language. Assume that it is context free, the pumping lemma gives pumping length.
1836	Often, the challenge in applying the pumping lemma in either case that we've seen involves choosing that string that you need to pump, that you're going to pump. So you have to choose s in F, which is longer than p, which s to go with. So you might try this one, first glance. Here is a string that's in the language, because it's two copies of the string 0 to the p1 0 to-- and then 0 to the p1. So that's in the language, but it's a bad choice. Before I get ahead of myself, let's draw a picture of s, which I think is always helpful to see. So here is runs of 0's and then a 1, runs of 0's and then a 1. Why is this a bad choice? Because you can pump that string and you remain in the language. There is a way to cut that string up and you'll stay in the language. And the way to cut it up is to let the x be just that substring which is just
1837	the 1. And the v and y can be a couple of 0's or a single 0 on either side of that 1. And now that's going to be a small vxy. But if you repeat v and y, you're going to stay in the language, because you'll just be adding 0's here. You'll be adding same number of 0's there. And then you're going to have a string which still looks like ww. And you'll still be in the language. So that means that cutting it up doesn't get you out of the language under pumping. And the fact is that that's a bad choice for s, because there is that way of cutting it up. So you have to show there's no way-- you don't get to pick the way to cut it up. You have to show that there is no way to cut it up in order to violate the pumping lemma. So if instead you use the string 0 to the p, 1 to the p, 0 to the p, 1 to the p-- so
1838	this is 0's followed by 1's followed by 0's followed by 1's, all the same number of them-- that can't be pumped satisfying the three conditions. And just going through that-- now if you try to break it up, you're going to lose. Or the lemma is going to lose. You're going to be happy, but the lemma is not going to be happy, because it's not going-- it's going to violate the condition. Condition three says vxy is not-- doesn't span too much, and in fact, can't span two runs of 0's or two runs of 1's. It's just not big enough, because they're more than p things-- they're p things apart. And this one string, this string vxy is only p long. And so therefore, if you repeat v and y, you're going to have two runs of 0's or two 1's that have unequal length. And now that's not going to be the form ww. You're going to be out of the language. So I hope that's-- you've got a little practice with that. I think we're
1839	at our break. And I will see you back here in five minutes, if I can get my timer launched here. OK, so see you soon. This is a good time, by the way, to message me or the TAs. And I'll try to be looking for if you have any questions. In the pumping lemma, can x-- yeah, x can be epsilon in the pumping lemma. x can be epsilon. y can be epsilon, but x and y cannot both be epsilon, because then, when you pump, you'll get nothing new. Technically, v and y can include both 0's and 1's. Yeah, v and y can include both 0's and 1's. So let me try to put that back, if that's will-- so v and y can have both 0's and 1's, but they can't have 0's from two different blocks. And you can't have 1's from two different blocks. So what's going to happen is either you're going to get things out of order when you repeat-- like, a v has both 0's and 1's in it. When
1840	you repeat v, you're going to have 0's and 1's, and 0's and 1's, and 0's and 1's. That's clearly out of the language, so that's no good. Your only hope is to have v to be sticking only inside the 0's and y to be sticking only inside 0's or only inside 1's. But now, if you repeat that and just look at what you're going to get, you're going to have a string which is going to be-- if you try to cut that string in half, it's not going to be of the right form. It's not going to be two copies of the same string, because it's going to have a run of 0's followed by a longer or shorter run of 0's, or a run of 1's followed by another run of 1's of unequal length. So there is no way this can be two strings, two copies of the same string, because that's what you required. F has to be two copies of the same string to be in the language. OK, let me
1841	just see where-- we're running out of time here. Let me just put my timer here. We've only got 30 seconds. And I'm sorry I'm not getting to answer all the questions here. OK, we are done with our break. It's going to come back. And now we're shifting gears in a major way, because in a sense, everything we've
1842	These limited computational models really are kind of helping us to set our understanding of automata and the definitions and the notation. And they're also going to be helpful in providing examples later on in the term. But really, in terms of a model of computation, they don't cut it, because they cannot do very simple things that we normally think of a computer as being able to do.
1843	called the Turing machine. And that's really going to be the model of what we're going to stick with for the rest of the semester, because that's going to be our model of a general-purpose computer, the way you normally think about it. So let's-- we'll spend a little time introducing it. And then we we'll continue that discussion next time.
1844	the Turing machine model is pretty simple. It's going to have states and all that stuff. So there is going to be a finite control here, which is going to include states and a transition function, as we'll describe in a minute. The point is that it's going to have the input appearing on a tape. The key difference now is that the machine is going to be able to change the symbols on the tape. And so we think of the machine as being able to write as well as read the tape. So that's really the key feature of a Turing machine, is the ability to write on the tape. Everything else, in a sense, follows from that, and a few other differences. But so the fact that the head can read and write so that we can use the tape as storage much as we use the stack of storage, but it's not limited in the way we can access it the way a stack is-- so we kind of have very flexible access of the information
1845	on the tape. Now, being able to write on the tape doesn't do any good if you can't go back and read what you've written later on. So we're going to make the head to be able to be two way. So the head can move left to right as before, but it can also move back left. And that's going to be under control of the transition function, so under program control, essentially. The tape is going to be-- oops, sorry. The tape is infinite to the right. And so we're not going to limit how much storage the machine can have. So the tape is going to-- we'll think of as having, instead of just having the input on it, it's going to have the input. But then the rest, it's going to have infinitely many blanks, blank symbols following the input. So the tape is infinite in the right-hand direction. And so there is infinitely many blanks. I'm going to use that symbol for the blank to follow the input. You can accept or reject. Oh yeah,
1846	so that's another thing that's important. Normally, we think of-- in the previous machines, finite automata, pushdown automata, when you got to the end of the input, that's when the acceptance or rejection was decided. If you were going to accept it at the end of the input, then you accepted. But you have to be in that location at the end of the input in order for that to take effect. That doesn't make any sense anymore, because the machine might go off beyond that, and still be computing, and come back and read the tape later on. So it only really makes sense to let the machine accept or reject upon entering the accept or reject state. So we're going to have a special accept state and a special reject state, which is also a little different than before. And when the machine enters those states, then the machine-- then the action takes effect. The machine halts and then accepts or halts and then rejects. So we'll make that absolutely clear in the formal definition in a second,
1847	but just to get the spirit of it. So I'm going to give you an example of the thing running. Sorry, me too-- again, my PowerPoint is having issues. OK, so here is a Turing machine recognizing that language b. Actually, I switched gears on you. Instead of 0's, 1's, and 2's, I made them a's, b's, and c's, but the same idea. So I'm going to show you how the Turing machine operates. And then we'll give a formal definition. I hope that's on here. I think it is. In a second, but let's-- this is an informal discussion of how the machine is going to operate to do this language, a to the k, b to the k, c to the k, using its ability to write on the tape as well as read and move its head in both directions. OK, so let me just first describe in English how this machine operates. And then we will see it in action on this little picture I have over here. So the way the machine is going to
1848	operate is the very first thing is the head is going to start here. And the head is going to scan off to the right, making sure that the symbols appear in the correct order. So it's seeing that there are a's and b's and then c's, without checking the quantities, just that the order is correct. For that, you don't need to write. A finite automaton can check that the input is of the form a star, b star, c star. So writing is not necessary. The machine, if it detects symbols out of order, it immediately rejects by going into a special reject state. Otherwise, it's going to return its head back to the left end. And let me just show that here. So here is-- oh no. Before I illustrate it over here, let's go through the whole algorithm. So the next thing that happens is you're going to scan right. And now you want to do the counting. So you're going to scan right again, but this time, you're going to make a bunch of passes
1849	over the input, a bunch of scans. And each time you make a scan, you're going to cross off one symbol of each type. So you're going to cross off an a. You'll cross off a b. You'll cross off a c on a single scan. And then you repeat that, crossing off the next a, the next b, the next c. And you want to make sure that you've crossed off all of the symbols on the same run and not crossing off some symbols before other symbols, while other symbols will remain, because that would mean that the counts were not equal. If you cross them off and they're all run out on the same scan, same pass, then we know that the numbers had to start off being equal. So I mean, this is a sort of baby stuff here, but I hope you get the idea. And we'll kind of illustrate it in a second. If you have the last one of each symbol-- so what I mean by that is you just crossed off the
1850	last a, the last b, and the last c-- then that you originally had an equal number. And so you accept, because you're crossing off one of each on each scan. So if you cross off, on the last scan, each one of them gets crossed off, then you accept. But if it was the last of some symbol but not of other symbols, so you crossed off the last a, but there were several b's remaining, then you started off with an unequal number of a's, b's, and c's. Then you can reject. Or if all symbols still remain after you have crossed them, one on each off, then you haven't done enough passes. And you're going to repeat from stage three and do that again another scan. OK, so here is a little animation which shows this happening on this diagram. So here is the very first stage where you're scanning across, making sure things are in the right order. I didn't have to write on the tape. And now you're going to reset the head back to
1851	the beginning. This is, by the way, not the most efficient procedure for doing this. Now we're going to do a scan crossing off a single a, a single b, and a single c. So here, I'm going to show that here, a single a, a single b, single c. And now as soon as you have crossed out that last c, we can return back to the beginning. So scan right across-- so if all symbols remain, so there are still symbols remaining of each type, we're going to return to the left and repeat. Now we're getting another pass, single a, single b, single c get crossed off. Have we crossed them all off yet? No, there is-- of each type, there still are remaining ones. So again, we return back to the beginning. Now we have a last pass, cross off the last a, the last b, the last c. The last one of each type was crossed off. So now we know we can accept, because the original string was in the language. OK, so that's
1852	to give you at least some idea how the Turing machine can operate, more like the way you would think of a computer operating. Maybe it's very primitive. You could imagine counting also. And a Turing machine can count as well. But this is the simplest procedure that I can just describe for you without making it too complicated. OK, so let's do a little checking on that. OK, so the way I'm describing this, how do you think? And in a sense, you don't quite know enough yet. But how do you think we're going to get this effect of crossing off with the Turing machine? Are we going to get that by changing the model and adding that ability to cross off to the model? Are we going to use a tape alphabet that includes those crossed-off symbols among them? Or we'll just assume that all Turing machines come with an eraser and they can always cross off stuff. So what do you think is the nice way, sort of mathematically, to describe this ability to cross things
1853	off? Yeah, again, most of you, again, I think are getting this. So there are, like, 10 laggards here. So please wrap it up so we can close the poll. Five seconds to go. OK, polling ending, get your last-- last call. All right, share the results. So most of you got that right. All Turing machines come with the eraser-- I don't know. That was thrown in there as a joke, but it came in second. So don't feel bad if you got it, but that's not what I had in mind. The way the Turing machine is going to be writing on the tape is to write a crossed-off symbol instead of the symbol that was originally there. So we're going to add these new crossed-off symbols. And that's going to be a common thing for us to do when we design Turing machines. We're not going to get down to the implementation level for very long. We're going to very quickly shift to a higher level of discussion about the machines. But anyway, that's how you would
1854	do it if you were going to actually build a machine. So let us then look at the formal definition. And personally, maybe I should have done that check in after the formal definition. That might have been clearer, but oh well. OK, Turing-- here is the formal definition. This time, a Turing machine is a 7-tuple. And there is-- now here, we have sigma, which is the input alphabet. Gamma is the tape alphabet. So now you're a little bit analogous to the stack from before where gamma was the stack alphabet. But these are the symbols that you're allowed to write on the tape-- that are allowed to be on the tape. So obviously, all of the input symbols are among the tape symbols, because they can appear on the tape. So you have sigma is a subset of gamma. One thing I didn't mention here is that the input alphabet, we don't allow the blank symbol to be in the input alphabet, so that you can actually use the blank symbol as a delimiter for the end
1855	of the input, a marker for the end of the input. So in fact, and the blank symbol is always going to be in the tape alphabet. This is actually always going to be a proper subset because of the blank symbol. But we're just allowing-- it doesn't really matter. We're allowing the tape alphabet to have other symbols for convenience, so for example,
1856	Now let's look at what the transition function, how that operates. So the transition function, remember, tells how the machine is actually doing its computation. And it says that, if you're in a certain state and the head is looking at a certain tape symbol, then you can go to a new state. You write a new symbol at that location on the tape. And you can move the head either left or right. So that's how we get the effect of the head being able to be bi-directional. And here is the writing on the tape. It comes up right here. So just an example here which says that, if we're in state two and the head is looking at an a currently on the tape, then we can move the state r. We change that a to a b. And we move the head right 1 square. Now, this is important. When you give a certain input here to the Turing machine, it may compute around for a while, moving its head back and forth, as we were
1857	showing. And it may eventually halt by either entering the q accept state or the q reject state, which I didn't bring out here, but that's important. These are the accepting, rejecting, special states of the machine. Or the machine may never enter one of those. It may just go on, and on, and on and never halt. We call that looping, a little bit of a misnomer, because looping implies some sort of a repetition. For us, looping just means not halting. And so therefore, M has three possible outcomes for each input, this w. It might accept w by entering the accept state. It could reject w by entering the reject state, which means it's going to reject it by halting. Or we also say we can reject by looping. You can reject the string by running forever. That's just the terminology that's common in the subject. So you either accept it by halting and accepting or rejecting it by either halting and rejecting or by just going forever. That's also considered to be rejecting, sort of rejecting
1858	in a sense by default. If you never actually have accepted it, then it's going to be rejected. OK, check in three here-- all right, so now our last check in for the day, we say, this Turing machine model is deterministic. I'm just saying that. But if you look at the way we set it up, if you've been following the formal definition so far, you would understand why it's deterministic. So let's just, as a way of checking that, how would we change this definition? Because we will look at the next lecture at non-deterministic Turing machines. So a little bit of a lead in to that, how would we change this definition to make it a non-deterministic Turing machine? Which of those three options would we use? So here, I'll launch that poll. I've got about 10 people left. Let's give them another 10 seconds. OK, I think that's everybody who has answered it from before. So here, I think you pretty much almost all of you got the right idea. It is B, in fact, because
1859	when we have the power set symbol here, that means there might be several-- there is a subset of possibilities. So that indicates several different ways to go. And that's the essence of non-determinism. OK, so I think we're-- whoops. All right, so look, this is also kind of setting us up for next lecture and where we're going to be going with this. So these are basically two in a-- well, two or three important definitions here. One is-- we talked about the regular languages from finite automata. We talked about the context-free languages from the grammars and the pushdown automata. What are the languages that the Turing machines can do? Those are called, in this course, anyway, Turing-recognizable languages, or T recognizable. Those are the languages that the Turing machine can recognize. And so just to make sure we were on the same page on this, the language of the machine is the collection of strings that the machine accepts. So the things that are not in the language are the things that are rejected either by looping
1860	or by halting and rejecting. So only the ones that are accepted is the language. Every machine has just a single language. It's the language of all strings that that machine accepts. And we'll say that and recognize that language, if that language is the collection of such strings that are accepted. And we will call that language a Turing-recognizable language, if there is some Turing machine that can recognize it. Now, this feature of being able to reject by running forever is a little bit weird, perhaps. And from the standpoint of practicality, it's more convenient if the machine always makes a decision to accept or reject in finite time and doesn't just reject by going forever. And so we're going to bring out a special class of Turing machines that have that feature, that they always halt. The halting states, by the way-- maybe it didn't say this explicitly-- are the q accept and the q reject states. The accept and reject states are the halting states. So if the machine halts, that means it ends up in
1861	one of those two. So it has made a decision of accepting or rejecting at the point at which it has halted. So we'll say a machine is a decider if it always halts on every input. So for every w fed in, the machine is eventually going to come to a q accept or a q reject. We call such a machine a decider. And now we're going to say, a language is-- so we'll say that the machine decides a language if it's the language of the machine, so the collection of accepted strings, and the machine is the decider. We'll say that, instead of just recognizing the language, we'll say that it decides the language. And the Turing-decidable language is a language that the machine-- of all strings the machine accepts for some Turing machine which is a decider, which is a Turing machine that always halts. So if a Turing machine may sometimes reject by looping, then it's only recognizing its language. If the Turing machine is always halting, so it's always rejecting by explicitly coming
1862	to a reject state and halting, then we'll say it's actually deciding the language. So then, in a sense, that's better. And we're going to distinguish between those two, because they're not the same. There are some languages which can be recognized, but not decided. And so in fact, we're going to get the following picture here, that the Turing-recognizable languages are a proper subset. They include all of-- everything that's decidable, certainly is going to be recognizable, because being a decider is an additional restriction to impose, an additional requirement. So everything that's decidable is going to be automatically recognizable. But there are things which are recognizable which are not decidable, as we'll see. I'll actually give an example of that, but not prove it next lecture. And just for, just to complete out this picture, I'm going to also point out-- we haven't proven this yet, but we will prove it-- that the decidable languages also include all the context-free languages, which, in turn, include the regular languages, as was already seen. So we haven't shown this inclusion
1863	yet. But actually, this is the picture that we get. So there is actually a hierarchy of containments here. Regular languages are a subset of the context-free languages, which are, in turn, a subset of the decidable languages, which in turn, are a subset of the Turing-recognizable languages.
1864	to move to our little bit of a review of what we've done today. So we proved that pumping lemma as a tool for showing that languages are not context-free languages. We defined Turing machines, which is going to be our model that we're going to be focusing on for the rest of the term, not forgetting the other models, because they're going to be useful examples for us. And we defined Turing deciders, Turing machine deciders that halt on all inputs. OK, so I think, with that, we have come to the end of today's lecture. I will stick around a little bit and answer questions in the chat. I will try to share them with everybody as I'm answering them so I'm not just talking to one person. How is the concept applied in-- so I'm getting one question about the practicality of all this. Bunches of questions are coming in. So look, is this stuff all practical? I would say, yes and no. I don't know which concept you have in mind. We're going to introduce lots
1865	of concepts in this course. And the concept of the finite automata, and the pushdown automata, and context-free languages, definitely used in other subjects, in other fields in computer science and elsewhere-- these are very basic and fundamental notions. And so yes, and Turing machines-- well, I mean that's a model of a general computer. If you want to understand computation, you're going to need to understand some model. And a Turing machine is a particularly simple model. And that's why we use it. As it turns out, it doesn't really matter what model you use, but we'll talk about that next time. But yeah, I would say there is a lot of applied material in this course, as time has shown, whether it's led to things like public key cryptography, which is used on the internet, or understanding various algorithms. I mean, that's not the reason I study it. I study it because I'm more coming at it from more of a mathematical perspective. I just find the material very beautiful, and interesting, and challenging, but it does have
1866	applications. Any other questions here? I think I'm going to sign off, then, to get myself set up for my office hours, which is on a different Zoom link. OK, so thank you, everybody. And see you on Thursday. Bye bye.
1867	[SQUEAKING][RUSTLING][CLICKING] MICHAEL SIPSER: So we are-- welcome back, everybody. And we are going to continue our discussion of computability theory, Turing machines, and how to prove things undecidable, which is what we've been doing. So we talked about this more advanced method of proving things undecidable last lecture, called the computation history method, which comes up in all sorts of proofs of undecidability, usually more complex ones. Such as, for example, the proof of Hilbert's 10th problem that I mentioned, whether you want to-- if you want to test whether a polynomial has a solution in integers. It's a reduction from ATM, just like we've been doing all along. All of those proofs are pretty much reductional from something undecidable. This reduction from ATM is as good a starting point as any. And it uses the computation history method. So what they end up doing is, given a Turing machine and an input, you construct a polynomial that has several variables. And where in order to get an integer root, an integer solution of that polynomial, one of the variables
1868	is going to have to be assigned to some kind of encoding of a computation history of the Turing machine of M on w. One of those variables is going to be a computation history-- an integer which represents the computation history for m on W. And the other variables are there to help you kind of decode that so that the polynomial can actually check and make a solution. It becomes a solution if that actually is a legitimate computation history of m on W. So it really uses the very same method that we've been using all along, but it's pretty hairy to construct that polynomial and do the check in the way that you need to do. So for the Post Correspondence problem which we introduced last time, doing the check is relatively simple. You know that the match is the computation history, and following the rules of the match, it's fairly simple to construct that Post Correspondence problem instance. We talked about linearly bounded automata. Of course, we defined configurations and computation histories along the way
1869	and proved certain problem-- other problems are undecidable as well using the same method. OK, so today, we're going to shift gears. We're going to-- in our last lecture on the computability section of the course, we're going to talk about something called the recursion theorem, which basically gives Turing machines the ability to refer to themselves. Turing machines in any program, to do self-reference so that you can actually get at the code of the Turing machine or the code of the program that you're writing. Even if that's not a built-in primitive of the programming language or the operating system that you're working with, it still gives you that access. And also, we're going to-- if we have time at the end, I'm going to talk a little bit about mathematical logic, which is sort of a nice application of the recursion theorem. And it's a beautiful subject on its own.
1870	OK, so today's topic is about self-reference, self-reproducing machines, and the broader topic called the recursion theorem. So let me introduce it with what I would call the self-reproduction paradox. And that is, suppose you have a factory, like a Tesla effect or a car manufacturing factory. See, there's a picture of the factory, and it's producing cars. All right? So we have a factory that makes cars. And what can we say about the relative complexity of the cars compared with the factory, in some informal sense? So I would argue that you would be reasonable to say that the complexity of the factory is going to have to be greater than the complexity of the cars that it makes. Because not only does the factory have to know how to make the cars, so it has to have all the instructions and whatever things that go into a car, it has to be included in at least some kind of-- it has to be, in some sense, represented in the factory. But the factory also has to have
1871	other stuff-- the robots, and the other manufacturing items, tools, and so on-- for making the cars. So the factory has to have all the complexity of a car incorporated plus other things as well. And for that reason, one could imagine that the factory's complexity is more than the car's complexity. But now, suppose you want to have a factory that makes factories-- so imagine here's the picture-- or in general, a machine that makes copies of itself. Well, that seems, at first glance, to be impossible. Because not only does the factory obviously have to have all of the instructions for what a factory is like, but it needs to have all of the extra things that it would need to do the manufacturing. And so for that reason, it seems like it's not possible to have a machine make copies of itself. I mean, you would run into the very same problem if I asked you to produce a program in your favorite language that prints out itself-- an exact copy of the same code. You can
1872	always write a program which is going to print out some string, like Hello, world. That's easy because you just put Hello, world into some kind of a variable or some sort of a table into the program and say print that table. But if you want the program to print out a copy of itself, you can't take the whole program and stick that into a table because the program is going to have to be bigger than the table. And so, you're going to end up with something impossible happening. Because the program-- an entire copy of the program can't fit inside the program. You just get the program inside itself, inside itself, inside itself, forever. And so, you end up with an infinite program that way. So if you just kind of naively approach the problem for how to make a program which is going to print out a copy of itself, it's not so easy to do. But hopefully, after today's lecture, you will see that it is possible and in fact, how to do it.
1873	And not only that is an idle bit of curiosity, but there are actually applications for why you might want to do that, mainly within mathematics and in computer science theory. But there's even a kind of a real-world application, if you will, in a way too. So we'll get to that at the end. So it seems, as I'm saying, impossible to have a self-reproducing machine. But we know that in the world, there are things that make copies of themselves-- living things. So it seems like a paradox. Cells can make copies exactly of themselves. All living things can make copies of themselves. So how do they manage to get around this paradox? Well, in fact, it is no paradox because it is possible to make a machine that self-reproduces, that makes copies of itself. And this has been known for many years. Probably, it goes back to Von Neumann who wrote a famous paper on self-reproducing machines. OK, so self-reproducing machines are, in fact, possible.
1874	So let me give you an example of how you would make a self-reproducing Turing machine. What do we mean by that? I mean a machine-- I'm going to call it SELF-- which ignores its input. So on any input, you turn it on, the machine grinds around for a while, and halts with a description of itself on the tape-- with the description of SELF, its own code, sitting on the tape. So very much like producing a program which would print out its own code, that's really what we're doing. So for that, we're going to first need a little lemma, which is a very simple lemma, but it looks worse than it is. So let me just read it out to you, and then I'll explain what its saying. Because what it's saying is extremely simple. So there's a computable function, I'm going to call it q, that maps strings to strings, which will take any string, w, and produce from w a Turing machine which will print w. OK? That's all it does. So as you
1875	know, if I give you a string, w, you could produce a Turing machine which would have w represented in the states and transitions of the machine. So that if you turn the machine on, the machine will output w. If I want you to give me a Turing machine that prints the string 1, 1, 0, 1 on the tape, you could do that-- I hope. And no matter what that string was, instead of 1, 1, 0, 0, or whatever, it's 20 0's and then five 1's, you could do that too. And in fact, there's a simple procedure that takes a string and maps that onto a Turing machine which prints out that string. So that's a computable function, which basically takes a string and converts it to something that evaluates to that string. And I'm calling it q. I don't know if this is helpful to you or not. It's kind of like it converts the string w to w in quotes. So q stands for quotes, in a way. So if that's helpful, then good.
1876	But anyway, Pw is a Turing machine. When you turn it on, it just prints out w and halts. And I can find Pw from w-- straightforward proof. So now, I'm going to tell you, assuming that we have that computable function, q, I'm going to tell you how to make this machine SELF. And it's not complicated. The Turing machine SELF is going to have
1877	a schematic for the machine. So here's SELF. It's in two parts A and B. And what I mean by A and B, it's like two separate teams. SELF is going to start out running A, and when A is finished, it's going to pass control to B. And then B is going to finish the job. And when it's done, you're going to have the description SELF sitting here on the tape. All right? So what's left is to give you the code for A and for B. So A is going to be something super simple. A is going to be that machine which prints out B-- prints out a description of B. The one that I described up here. So remember, Pw is the machine which prints out w. And P sub the description of B is simply going to machine that has this string, PB, stored in its states and transitions. You turn on that machine, and it prints out B, and then it's done. So this is a very simple-- A is very simple. So
1878	here, PB is a part of A. And when it's done, B appears on the tape. So that's at the point when A has finished its work. Now it's going to pass control to B. So we're not obviously done yet, because what we want is A and B both to be on the tape, not just B. Because SELF is a combination of A and B together. So I have to tell you how B works to finish the job. So you might think, as a first, given what we did for getting B on the tape, that we'll get A on the tape in the same way, by putting a copy of A inside B. So a copy of B is inside A, and a copy of A is inside B. And at some conceptual level, that seems like that might do the job. But it's really not-- that is not a solution. Because the fact that I can put B inside A kind of forbids me from also putting A inside P, because that's going to be
1879	the same kind of circular reasoning of just putting a machine inside itself. You just can't do that because you're going to end up with an infinitely big machine that way. In fact, if I'm putting B inside A-- a copy of B in terms of its description inside A, A is really going to be much bigger than B. Because it has all of B with inside it, plus other stuff-- all the states and transitions for printing that B out. So I can't have the A be much bigger than B and then B also much bigger than A. So this is no good. We're going to have to do something else. So how is B now going to get ahold of A? And the trick for doing that, without having a copy of A inside B-- which doesn't work. That's not going to be a good solution. Instead, the way that B is going to get A, it's going to figure out what A is. It's going to figure out what A is. And how is it
1880	going to figure out what A is? Because if you remember, B can now look can look at the tape. It sees some string there which happens to be a description of itself, but it doesn't care. It sees some string on the tape. A is the machine that prints out that string. A is q of this string. So B is simply going to compute q of whatever it sees on the tape. That is A. OK? So I don't know if you can read. That's kind of small here. It's going to compute A from B sitting on the tape. So here is the instructions for B. It's going to compute q of the tape contents, which happens to be the description of B. But that's irrelevant to B. B just sees some string on the tape. It computes q of that, and that is A. Because A is the machine which prints out that string. Then it's going to combine A with B, doing whatever slight interfacing that needs to happen-- I'm not going to get into
1881	those details-- to convert those two pieces into one machine, which is the machine SELF. And then it's going to print out with SELF on the tape, as I'm going to indicate over here. OK? So that's how a Turing machine can print out a copy of its own description and leave it on the tape. And what's nice about this is nothing specific about Turing machines. This is a general procedure that allows any programming language to print out a copy of its own code. You can even carry this out in English, as I'm going to do in the next slide. OK, so here's a good question. There are many possible Turing machines that can print out B. That's right. How do I know how to get the particular one? What I have in mind, that's a little bit of a subtle question, but it's a good question. I have in mind the particular Turing machine that prints out B, which is the one that q produces. Remember, so we have to refer back to this lemma. This
1882	lemma produces a particular machine that prints out B from B. And that's the one that I'm going to use for A, and that's the one that B is going to be able to obtain by running the q algorithm to figure out what A is. So you have to make sure you're being consistent then. That's a little bit of a detail, but it's a good question. And why doesn't this create a circular argument too? Well, so that was another question I'm seeing here on the tape. Well, there's no longer anything-- see, B does not have to have A stored within it. It figures out A. So in a sense, you're going to write the code for B first. B is just a simple program. Here it is. There's nothing circular about it. It says B is a simple-- the code for B is, take a look at the tape, compute q of that, combine the result with whatever was sitting on the tape from before, and print it out. I mean, that's a piece of code
1883	which you can just write. This will become more clear, hopefully, in our next slide where we talk about the English implementation. But just, I don't want to rush to that. So you could figure out B without even knowing what A is. B stands alone. But then, because B is just a piece of code that runs q based on what it sees on the tape. A, now you need to know what B is in order to obtain A. Because A has the code for B embedded within A as a string. So first you produce B, then you can figure out-- then you can obtain A. There's nothing circular in this argument. I don't know if that's helpful to you, but you may need to mull it over. Or maybe it'll be helpful from the next slide. So let's go there now. So as I'm saying, you can implement this in any language.
1884	"So let's just shift gears. Let's talk about writing down English instructions. And then I'll show what happens if you carry out those instructions. So let's start simple. How about the sentence, Write ""Hello World."" So an obedient person reading those instructions would then write ""Hello World"" on their paper or wherever. OK, fine, hopefully you get the idea. So now, what I'd like-- here's another sentence, another instruction. Write this sentence. And the obedient reader would then, OK, Write this sentence. This is the kind of thing I'm looking for. Here is a sentence which instructs the reader to make an exact copy. But I don't like this one, even though it does, in a sense, what I'm looking for. Because it kind of cheats. When it has this, this refers to the entire sentence itself. It's using kind of implicitly here a construct which a Turing machine does not have. The Turing machine does not have a way of accessing its own code. And in fact, really what the point of this whole theorem that we're going to"
1885	"present is, is that you don't need to have this self-reference as a primitive. You can get that effectively using the procedure that I'm describing, which will give you the same effect. So you don't need it as a primitive. You can design some software basically, which will give you the same effect. So let me show you how to do that in English. So let's look at a slightly more-- whoops, cheating, so Turing machines don't have this self-reference primitive. So let's look at another sentence here. Write the following twice, the second time in quotes, and then, ""Hello World."" So what do we get if we follow that instruction? Well, you get ""Hello World"" and then ""Hello World"" again, now in quotes. OK? Hopefully not too bad. But now, I'm one step away for doing the implementation of the self-reproducing algorithm in English. Write the following twice, the second time in quotes, and then in quotes, the same text. Now following those instructions, you get, well, ""Write the following twice, the second time in quotes,"" so that comes"
1886	"out here. And the second time, you put it in quotes, just like you did with the ""Hello World."" But that's exactly here, the output is exactly what the input was. And even though there is a part of the sentence here which refers to a different part, so here the first part is referring to the second part, never do I have to have the sentence referring to its entirety. There's no part of the sentence here that's pointing at the entire sentence. And so, this here manages to get the effect that I'm looking for, where the output is equal to the code, but avoids having the self-reference. One thing is referring to something else, but not referring back to itself. So let me just see here. So here, I'm going to have a check-in on this in a minute. So I'm going to try to contrast what's happening here with what's happening in that Turing machine SELF that I had from the previous slide. So why don't you mull this over, and I'm going to give you"
1887	a check-in to see-- this is a little bit of a challenging check-in. But let's see if you can figure your way through it.
1888	And basically it says, so really what we're doing here is called the recursion theorem, as you'll see. We'll actually present the recursion theorem formally on the next slide. But here, in both of these cases, we kind of have a template part and an action part. In both cases, there are two parts to the instructions, the template and the action. OK? So I'm going to leave it to you to try to imagine which of those is which, in each of these two examples. And then, I'm going to ask you to pick. In the Turing machine, which is the action and which is the template, and in the sentence, which is the action and which is the template. The action is the part where there's some interesting sort of instructional stuff happening that you have to carry out. The template is really basically just text or just a string. So let me pull up that poll. See what you think. Because I'm asking you now to indicate where is the action part in both of those cases.
1889	What is the upper phrase and lower phrase? I mean, of this sentence here. So write the following twice. This is the upper phrase. And the part in quotations is the lower phrase-- sorry. OK, almost done here? 5 seconds-- a few of you have not answered yet. Answer it. One second to go. OK, here we go, ending polling. So the majority here is correct. I would say, in the English sentence here, the action part is the first part. That's where you actually have been directed to do something. The second half of the sentence, the lower part of the sentence, is just a template written. This is just some string here. There's no action really being directed. It happens to be the same as the top, but this could have been just Hello World. This could have been anything. And then the upper part acts on that. So the upper part is the action part. So it's the upper phrase that's the relevant part. Now, in the Turing machine, in a sense, it's the other way around.
1890	The first part is really just the template. The second part, B, is where you're doing some actual work on the template. You're taking that, basically text, which could be anything. A could be anything. And you're looking at that template and reconstructing what A was from that string that appears on the tape. So B is actually the one that's doing the work. So it's B and the upper phrase with part c is correct. So let us continue then. Oh, I want to mention here problem 6 on the Pset. So your job really is to implement this in-- if you have a programming language that you like-- it could be Python or whatever your favorite Java, whatever you like-- you can implement this. If you don't know any programming languages, then just make up some sort of pseudo programming language and implement it there. Let me point out that getting the quoting right is a bit of a pain because you have to kind of escape the quotes and so on. I'm not going to be fussy
1891	about that. So you can still get full credit even if you don't get the quoting part quite correct. Do your best. I think it's an interesting problem to try to solve. And if you struggle with it for a while, it's slippery. It's the kind of thing you can easily spend a couple of hours on this problem. Because it's a bit tricky to manage to make a program which prints itself out, which is what the task of problem is on the Pset. But don't fuss about too much on the quoting if that's the only thing that's hanging you up. Try to get the main structure of it, which is fairly simple, actually. And if you can't get the quoting part to work, I'll ask the graders not to penalize you for that part.
1892	Let's look at the sort of the more formal version of what we've just done and really kind of also taking it to the next level. Because being able to print out a copy of yourself is kind of a curiosity in a way. But the recursion theorem says, not only can you make a machine which prints out a copy of itself, but you can actually make a machine which can obtain a copy of itself and then do some computation on that copy of itself, on its own description, which actually turns out to be a useful thing to do. Once you have access to your own description, as you'll see from some examples, then you can do perhaps some interesting things with that. So basically, what the recursion theorem is, is a kind of a compiler. It allows you to have a new primitive when you're writing Turing machines, which is, compute your own description. And the recursion theorem will implement that for you. OK? So the technical form of the recursion theorem is going to look
1893	a little bit counterintuitive, perhaps. Let me put it out there. If you struggle a little bit with the slide, don't sweat it. The main thing to remember, and we'll see from examples, is that you can compute your own description in a Turing machine. And that's going to be allowed as code. So the way we're going to do this is, what the recursion theorem does for you is, it says you can write a piece of code here. Let's call it a piece of Turing machine code-- algorithmic code-- called T. And T is going to get transformed into a new machine, R. And R is going to get provided a copy of the program itself, which is just a description of R, for free. But otherwise, it's going to act exactly like T. So R is going to act exactly like T, except R is going to have provided a copy of R. And that's what the theorem shows you how to implement. So let me just see. So for any machine, T, there is a machine
1894	R which, for any w, which is going to be the input for R. R, on w, operates the same as R on the input with w where it's given R. So R is going to be getting access to R without-- it's going to be obtaining R by calculating it. Maybe it'll be clear from the proof. I always struggled with how to explain this clearly. So now, the proof of this is going to be very much like the proof from two slides back, except it's going to be three parts. This is the part, T, that you're going to provide. And the T is going to be the Turing machine code that says, get your own description. And you don't have to worry about how that happens. The compiler is going to add on the A and B parts, which is going to get the whole description of the whole thing, which is R, and feed it into T as if T had it as an input. So T is going to be allowed to get its
1895	own description now and operate on-- now does its thing on the input w. So the way it's going to work, so T is given. A is going to be, as before, the description of B now with T. So when A is done, it's going to produce BT sitting on the tape next to the w. B is going to now figure out what A was from the BT sitting on the tape. And then, it's going to combine that to get ABT, which is R. And after that, it passes control to T with w and now R sitting on the tape. And now, T is going to have its own description. But don't forget, now T has been modified to be R. So it's not that T is going to get T on the tape. For this to make sense, this is going to be now the new machine R. And R appears on the tape. And now, the code that you provided, T, is now going to get to operate on that. OK? If you didn't
1896	get that, I'm not so worried. The main thing is that you can use compute your own description when you're describing Turing machines. That's what this thing is telling you. I think it'll be-- oh, there's a check-in here. Yeah, so I don't know. Let's do this one kind of quickly here. Can we use the recursion theorem to design a machine T which, instead of producing its own description, accepts only its own description as an input? So the language of this machine is going to be simply the one string, the description of T. So can we make a machine, T, which does this? Now I'm looking at this check-in. This T here is confusing with that T. It's not the same T. That's bad. I should call it M. Design a machine, M, where L of M is the description of M. And can we use the recursion theorem to do that? What I would ask you to do is think about it in this context. You can use compute your own description when you're writing the
1897	code for this machine. If you could do that, could you make a machine which just accepts strings which happen to be their own description? This is supposed to be easy. But I think it ended up being a little bit more complicated than I wanted. Launch polling, make your best guess. I think you all kind of see-- I was kind of leading you, leading you along the path here. Yes so, I think you're pretty much all are getting it. Maybe a few of you are unsure. But anyway, let's just wrap this one up quickly so that we can move on. I think you're pretty much-- so, 5 seconds, I'm going to end it. So the correct answer is Yes, as I was hinting at. So I think maybe this example would have been better after the next example. And then we're going to have a break. So here is a new proof that ATM is undecidable but now using the recursion theorem. And this is going to give you a nice example of how we use
1898	the recursion theorem in action. So remember, we spent half a lecture or more with a proof by diagonalization. As our first example of an undecidable problem ATM, we subsequently showed other things undecidable by reduction. But for the very first example, we used that diagonalization. Now I'm going to give you a new proof. So proof by contradiction, assume we have a Turing machine, H, that decides ATM. It starts the same way that the diagonalization proof went. But now I'm going to make a new machine called R. So this is going to be different from the earlier proof. R says, on input w, I get my own description. Use the recursion theorem. That's the way these things always start. Now, I'm going to use H. Now that I know my own description, I'm going to feed-- I can ask H. I can feed R, w-- w was the input here. I can feed R, w into H to determine whether R accepts w. That's what H does. Solving ATM, H will tell this machine whether R accepts
1899	w. R is the machine we're writing, however. That is the machine that's currently running. So R now uses H, and it knows what it's supposed to do. H is going to say, well, you're going to accept w or you're not going to accept w. That's what H is assumed to be able to do. But then what is R going to do after that? R is going to do the opposite of what H says it's going to do. So if H says, R accepts w, then R is going to reject w. If H says R doesn't accept w-- it rejects it by looping or halting, doesn't matter-- H just says it rejects, then it's just going to accept. So whatever H says, R is going to show that H is wrong. So that's a contradiction. It says that H cannot be deciding ATM. So if you step back and think about what this is here, that's that whole diagonalization proof in one line. Basically, we've done that proof in a different way, though there is some
1900	similarity here. I don't want to say that we've totally reinvented things and done that totally differently. But it's kind of, in some ways, sort of gets at the essence of the diagonalization in a certain sense. But anyway, it gives you kind of a new, very short proof that ATM is undecidable. I think that's kind of a cool thing.
1901	"and you can feel free to ask questions during the break. I will start my timer going. And we'll be back continuing lecture in five minutes. OK, so questions-- so we're getting some questions on when I said, we don't have to worry about the quotes when we're solving problem 6 on the Pset. Somebody says, can we just say print A, B, C, instead of print quote, ""A, B, C,"" and it will print A, B, C. Yes, you can-- don't worry about the quotes. I think it's kind of-- you'll see a challenge if you want to try to get the quotes to work. But it's also kind of a pain. So yeah, you can just kind of ignore the quotes, and I'll ask the graders to give that full marks there. So any reasonable interpretation will-- as long as you get the rest of the concept right-- will be fine. Let's see, somebody is asking, In the recursion theorem, why doesn't T get the description of T instead of the description of R? Because the machine that's"
1902	running is R, back in the previous slide, two slides ago. So if R got T, it would not be getting its own description. It would be getting the description of some other machine. So you need to think about what we actually need to have happen here in the proof of the recursion theorem. But it needs to have R, not T. Let's just see if I can-- why does R do the opposite of what H says? Why does R do the opposite of what H says? Well, first of all, I'm the one who gets to design R. So here is the code arc. We're assuming we have H. I'm going to design R to do anything I want to satisfy the proof. And R here is designed to do the opposite of H. So I'm asking R-- I'm programming R to find out what H predicts it will do and then do the opposite. Maybe the situation is sort of like this. Suppose somebody says, I have a crystal ball, which is going to be like
1903	the role of H. And you say, oh, really? That's kind of cool. I don't believe you, but it still sounds interesting. And the person says, yeah, I can see the future. I know what you're going to do in five minutes. And in fact, I can see that in five minutes, you're going to say, Hello. And you can say, well, you can think to yourself, well, this person is nuts. I'm not going to do that. I'm just not going to say Hello. And then the genie there with the crystal ball waits five minutes and you don't say Hello. And then you've proven that the crystal ball doesn't work. It's very similar. I'm not going to explain how we can do the combining in SELF. I just want to explain at a high level. That's just going to be messy. Because I said, we were somehow going to combine in SELF. Let me leave that as a conceptual level. OK, how does this idea work for Turing machines? I don't really understand that question. How does this
1904	idea work for Turing machines are decidable? You'll have to resend that because I don't understand the question. Can I explain, use your own description? So when you write code that says, get your own description, after that code executes, the Turing machine appears on the tape, like magic, the description of its own code. Say, sitting next to the input to the machine, because the machine may have an separate input from that. So the machine just magically gets its own code. And the proof of the recursion theorem implements that, so it's not magic after all. But I still don't understand the question. So for problem 6, is it enough to attach code? If you're going to attach code for problem 6, and that's good enough. Or if you can explain, it's also good, like usual. Do we worry about tabs and new lines? No. OK, we're going to have to defer the rest of the questions. Don't forget we have a zillion questions here which I didn't get to. OK, last one here-- why does programming R
1905	do the opposite of H? Is that a contradiction? Well, H is predicting that R accepts, but R doesn't accept, so H is wrong. We're a little short on time. Let me skip this one. You can look at this on your own. I mean, this is proving sort of the cool fact that-- I'll just say it at a high level. If you have a program transformation, so if I have some method of transforming one program to another program, but it's done by algorithm. So an algorithmic way that transforms one program to another program. There's always going to be some program whose behavior is unchanged by the transformation. That's called the fixed point theorem. So there some program whose behavior doesn't change no matter how you try two transform programs-- easy proof using the recursion theorem. You can look at the slide offline separately if you like to see how that goes. It's pretty simple. Here's another exercise of the recursion theorem. So if I have a-- let's say a Turing machine is minimal if its description
1906	is the shortest among all Turing machines which behave the way it does, which are equivalent to it. When I was an undergraduate, I took a programming class. And some of us sort of enjoyed writing short programs to carry out the exercises. Probably these days, that's forbidden because it just encourages bad programming style. But anyway, so you kind of won if you found the shortest solution for a given programming exercise. It was Heap Sort, I remember, was one of the ones that we had to do. So this is sort of similar. You might imagine if people try to find the shortest possible universal Turing machine. So short is, in our sense is, in terms of whatever encoding method we have in mind, a machine is minimal if there is no shorter program which is equivalent using our encoding system, whatever it is. So M is minimal if anything that has a shorter description has a different language. OK, so let's look at the collection of all descriptions of minimal Turing machines. And I want to prove
1907	that that language is unrecognizable. I'm going to do it using the recursion theorem. And it's kind of a cool exercise. And you can actually use it to prove something more powerful. But let's focus on this theorem for now. So assume we have-- and it's also in the little nice exercise about enumerators. I don't know how comfortable you ever got with enumerators. But I'm trying to prove this language here is not recognizable. And so remember, enumerators, you can enumerate exactly all the recognizable languages. So I'm going to assume I have an enumerator for this language, which just prints out all of the minimal Turing machines. So I have some enumerator. It's a program that prints out the descriptions of all of the minimal-- the shortest possible Turing machines. And now I'm going to get a contradiction. So we're going to build this Turing machine, R, which gets its own description. And then, it's going to start the enumerator until-- so looking at the strings that the enumerator produces. So this enumerator is producing these minimal Turing
1908	machines, one after the next-- chunk, chunk, chunk, chunk, chunk. All these minimal Turing machines are coming out. And you keep looking at those until you find one of them which is bigger than yourself. And how do you know how big you are yourself? From the description you're given by the recursion theorem. So you keep on printing out these Turing machines until you find one that's bigger than yourself. And then, what do you do with that? You simulate that. So now, so what? Well, the point is that you're going to be smaller than that machine that you're simulating. Because you waited to find a machine that the enumerator produced which is bigger than you. So you're going to be simulating that machine that's bigger than you. And so, you're going to be doing exactly what that machine does on every input, because you're always going to be simulating that same machine on every input. And so, you're going to be equivalent to that bigger machine. But that bigger machine is supposed to be minimal because E
1909	is producing it. But here, you are exhibiting a machine that's smaller than that-- that allegedly minimal machine couldn't be minimal. That's the contradiction. So the language of R, this machine I just produced, equals the language of B. Because R ends up simulating B. But R is smaller than B because R waited until it found a bigger machine that's bigger than it. So B couldn't be minimal, but B was one of the machines that the enumerator produced. That's a contradiction. So let me do a check-in on this. I expect this is going to cause some of you heartburn, but let's do the best you can. Suppose I have this collection of minimal Turing machines and I take some infinite subset of that. So now I'm not demanding that I have all of the minimal Turing machines. I just have infinitely many minimal Turing machines. Is it possible that subset-- whatever it is-- could be Turing-recognizable? Now, think about that. Now, you can have languages which are not Turing-recognizable, that have infinite Turing-recognizable subsets. Could that be
1910	for this language? And maybe I'll give you a-- it will be helpful to you to understand and perhaps apply the methodology that I gave you in this proof here. And that might be helpful to you. But I can see this is not-- this one is a bit of a struggle. OK, let's end it. Two seconds, just pick something. So the majority has the correct answer here. So in fact, this proof would still work if the enumerator was enumerating an infinite subset of minimal Turing machines. Because all you need is to wait until one that's bigger than you appears. And all that R needs to do is wait until one that's bigger than R appears, which will certainly happen eventually if the subset is infinite. And then R simulates that bigger machine and acts the same way, thereby proving it could not be minimal. So it's exactly the same proof shows that the answer here is No. And it's a kind of a curiosity. It's not necessarily that easy to construct languages which not only are
1911	they not recognizable, but they have no recognizable subsets-- infinite subsets. Obviously, a finite subset is going to be recognizable because it would be decidable as well. So anyway, let's move on. Some other applications-- so first, a real-world application-- somebody is asking for an example of a language of a recognizable subset of a non-recognizable language. So starting out with something which is not recognizable, and can we come up with a quick-- So here is, I don't know if this will help you. So the question is, can I give an example of a non-recognizable language that has a recognizable subset? So I didn't prepare this, but let me see if this helps you. So let's take ATM complement. We already showed that ATM complement is not recognizable. So these are the sets of pairs, M and w, where M does not accept w. So if I focus only on those M's, which are finite automata, which are a subclass of Turing machines, then I can get the answer for those M's. So for the infinitely many cases
1912	where the Turing machine never writes on its tape, it even becomes decidable. So I don't know if that's helpful, but you can definitely find cases where there are undecidable languages that have decidable subsets, unrecognizable languages that have recognizable infinite subsets. But there's one example where it's not true, in the previous slide. OK, a lot of questions are coming up here. Yes, I'm seeing some other proposals here. If you take ATM complement and you union with just any old strings of 1's, just one star, assuming that one star-- just strings of 1's are never going to code for a Turing machine-- that's still going to be unrecognizable. But then you can just throw away all of those just strings of 1's, and you're going to get an infinite subset. Oh, wait a minute. It's still unrecognizable. That's no good. Oh, no, yeah, I threw away the wrong stuff. You throw away the descriptions of the Turing machines, and you just have the one-star strings left. And so, that becomes decidable, even regular. Anyway, I'm not sure
1913	I'm helping you. Let's move on to other applications. So this is kind of a curious application that actually is in the real world, where a machine might want to get a copy of itself and then do something perhaps even nefarious with a copy of its own code. And that would be a computer virus. Computer viruses make copies of themselves and then propagate them through the internet, or whatever media you have, to infect other computers. And I'm sure we all know computer viruses. Well, they need to get copies of themselves in order to do the infection. How do they do that? Many of them operate in a way where in either in a language or in a system, where they can make reference to their own code, either by looking at the machine code, or whatever direct access to their own code. There are languages and systems which allow for that. But I'm not an expert on computer viruses. I would be shocked if they're not some other viruses that get access to their own code
1914	by using something in the same-- using basically the method of the recursion theorem. I haven't done a systematic study. But I'm sure, if you can't access to your own code directly using some operating system mechanism, some primitive, the only other way is basically doing the method that we just described. OK, so another application is in a branch of mathematics called mathematical logic. Where, I imagine that many of you have heard of the work of Godel from the earlier part of the 20th century, where they show that you can come up-- it's possible to demonstrate that there are true mathematical statements but which cannot be proven to be true. So proof-- there might be something like maybe even questions of interest to us, like P versus NP question, which we will, at some point, look at in a few weeks-- actually, yeah, maybe two or three weeks from now. There are many unsolved mathematical problems. And people wonder, maybe there's just no way to prove them one way or the other. So in the 1930s, when
1915	Godel did his work, he shocked the mathematical community by showing that proof does not work for everything. There may be things that are true that you cannot prove. In Hilbert, in particular, from Hilbert's 10th problem, he was dismayed by this result. Because he had earlier believed that anything that was true you could prove. So anyway, let's just see how-- I'm going to sketch how we actually go about doing that. Because we now have a kind of enough technique to at least give you an idea of how do you demonstrate that there are true but unprovable statements and actually even exhibit one. OK, mathematical logic is the mathematical study of mathematics itself. Godel's first incompleteness theorem, as we described, is that in any reasonable formal system of mathematical provability, there are going to be some true statements that are not provable. And in order to sort of get the sketch of the proof-- I shouldn't say proof here. We're going to proof sketch. We're going to basically use two properties of formal proof systems. One is
1916	that kind of obvious property that you would expect all probability systems to have, is that you can only prove true things. So if something is being proven, it's going to be true. You can't prove anything false. If you can prove false things, your system of provability is bad. And the other thing is that proofs are checkable by machine. So if you write down-- do your system in a formal way and you have this formal notion of proofs, which underlies all mathematical reasoning, by the way. This is completely well accepted. Both of these properties are accepted by mathematicians. Then in principle, you can convert any mathematical proof into a form that you can check it by computer. It might become much longer. But in principle, you can put the proof into a form where a computer could check the proof. And the way we're going to frame that in the way we've been talking about things is that the language of all pairs of proof, comma statement being proved-- so where pi is a proof of
1917	the statement phi-- that's a decidable thing. So you can check, by machine, whether pi is a valid proof of phi. So your proof checker can say, Yes, it's valid, No, not valid. And that's something you can do by algorithm. So those are the two assumptions that we're going to make about our system of proofs. And that's all we're going to need. Now, the first conclusion, which is, I think, a good sort of a little bit of exercise on the kind of thinking we've been doing in this course. Number 2, checkability implies that the set of provable statements is recognizable. Why? Suppose I give you a statement that has a proof-- a provable statement. I'm not saying it's a true statement, necessarily. That's going to be perhaps a larger class of statements. But the statement that do have proofs, that's a recognizable language. Because, if I give you a statement, your recognizer is going to take that statement and start looking through all possible proofs. It's going to look at string after string as a candidate
1918	proof, one after the next. Some strings, of course-- most strings are going to be junk. But every once in a while, a proof is going to come out. It's going to be a string which is a valid proof of something. And then you're going to check, oh, let me just see if that's a valid proof. And if it does prove the statement that I have in mind, and if it is, then I accept that statement. And it goes through statement by-- the input is a mathematical statement. And that's going to be accepted if the machine, by looking through all possible proofs, finds one and then it accepts that statement. So the collection of all statements that have a proof, that's recognizable. So similarly, if you take statements of the form M and w is in the complement of ATM. So M doesn't accept w. If you take all statements of that form where M doesn't accept w, or M, w is in the complement of ATM, some of those statements may have proofs in your
1919	system. Some of them may not have proofs. If all of them had proofs, if you can prove every statement of this form when it happens to be true-- obviously, you can't prove the ones that are not true. But if you can prove all the true statements of this kind, then ATM complement would be Turing-recognizable. Because you can go through, just for the same reason as above. But we know that that's false. So there must be some statement of this kind which is true but does not have a proof. Because otherwise, the ATM complement would be recognizable. So we've actually done the first half of Godel's incompleteness theorem. The second half, which we're going to unfortunately not have time to finish, but let me just give you the outline, is that we can use the recursion theorem to give it specific-- see, what we showed here is that there is some statement of this form which is true but unprovable. It doesn't exhibit a particular one. Now the recursion theorem allows you to give a particular
1920	"one. And the one, it basically implements Godel's so-called Godel statement or Godel sense that says, ""This statement is unprovable."" And you can formalize that precisely. And then that statement becomes true but unprovable. Let's just say why that is. Because if the statement were false, suppose the statement were false, then, well, then it would be provable. Because the truth says it's not provable. But if the statement were provable, then it had to be true, which would mean it would be unprovable. So the only viable outcome here is that the statement is unprovable. And which is, it's therefore that it's true that it's unprovable. So that this is a true statement, but then it has no proof. And let me not go through it because again, we're unfortunately running short on time. But you can implement this using the recursion theorem to make a particular machine, R, where you cannot prove that R does not accept, say, some string 0. So you can find a particular R using the recursion theorem, where it's impossible to prove that"
1921	R doesn't accept 0. Even though, by construction, R does not accept 0. So it's a little bit slippery there because you have to understand what we mean by proof within the formal system versus our external form of reasoning, but taking us a little bit far afield. So for those of you who care, I hope this little digression was interesting. As I mentioned at the beginning, for those of you who don't care, you don't have to worry about it. It's not going to be on the midterm or on the final exam. You're not going to be responsible for this last five minutes or so of the lecture. But I thought it's kind of an interesting application of the recursion theorem to a problem outside of computer science in mathematical logic. OK, so here is the entire reasoning here again. I invite you to look at that on the slide that I posted if you're curious. So anyway, a quick review of today is, we went through self-reference and the recursion theorem. We gave a few applications.
1922	And we did a sketch of Godel's first incompleteness theorem in mathematical logic. OK, so that's all I'm going to have for you today. We're out of time. And I will take any questions. So getting back to the MIN Turing machine example, somebody is asking, how do I know there's a Turing machine that's longer than the machine, R, that I'm building? Well, there are infinitely many machines in MIN TM or in the infinite subset of MIN TM. So eventually, one of them is going to have to be longer than the machine that I'm constructing. Because that's a machine of some very specific size, and so eventually there's going to have to be one that's bigger that shows up. So this may be a similar question. Now, another similar question is about, how big is R? And does the size of R in that previous thing here-- I don't know if we want to go through this. But, OK, let's quickly look at it. This machine, R, has a fixed, predetermined size. Its size does not depend
1923	on B. It depends on E because it's going to be simulating E. But E might be producing very, very long strings. Eventually, it will. So E is fixed. And then, R's size is fixed. So eventually, R will find a machine that's bigger than it is. But let's look at-- right, so this is a good question. I was wondering if I would get questions of this kind. This is getting back to the question in logic here at the end. Yes, because I said this statement here is unprovable. But in a sense, I proved it. Because how do I know it's true? And I gave you an argument for it. And so, you have to differentiate between the reasoning that we're providing and the formal system that we're reasoning about. And the formal system that we're reasoning about is not capable of proving this. But we're outside that formal system so that we can reason about the formal system. I know it's a little bit perverse seeming. And mathematical logic is a little tricky because it has
1924	to deal with those kinds of issues. But this is arguing within any particular formal system of probability, this is going to be true. But that's kind of an approximation to our own thought process. So it's slippery, I agree. So, a good question here, would Godel's theorem still hold informal systems where we don't require that proofs of statements are decidable? So I'm not saying that the proofs are decidable. That you can-- proofs are checkable. So you can test whether a proof is a proof. If you can't test whether a proof is a proof, I don't know of any people who have studied that situation. So that's a little bit of a trickier case. I'm not sure what to say about that. Can I give an example of two equivalent Turing machines where one has a shorter description than the other? How do we define the length of the description? Well, we never really precisely defined our encoding system. But whatever encoding system you want to use, is going to represent Turing machines as strings. And those
1925	strings are going to have a length. And so, it doesn't really matter which encoding system you're going to use because the statement isn't going to be true in any of them. We could go through the exercise of defining a particular encoding system. It's going to be pretty tedious to do that. But you can just imagine writing down the states, the transition function, et cetera, et cetera, as this big long string. And that's going to be our encoding system. And then there are going to be some long machines. Some machines will have long representations and other machines that have short representations. And there's going to be some machine where you can introduce a bunch of useless states that are never accessed. So you can expand-- you can kind of add junk to the description of the machine, which is not going to do anything. But it's just going to make the description of the machine unnecessarily long compared to what with some other description, which is going to compute the same thing but will be much
1926	shorter. So you can certainly find examples of pairs of machines that do the same thing where one is much longer than the other. So I will then close the session here. And I will be very shortly on the office hours link and see some of you there.
1927	[SQEAKING] [RUSTLING] [CLICKING] MICHAEL SIPSER: Welcome, everyone, back to theory of computation. So we are now at lecture number 15. And this is an important lecture. Well, all of our lectures are important, but this is going to introduce one of the major topics that we're going to see going on in various forms through the rest of the semester, which is the notion of a complete problem. In this case, it's going to be an NP complete problem. And I think some of you have probably heard of that concept already. Maybe you've seen it in some courses or other, but we're going to do that in a rather careful and formal way over the next couple of lectures. So we are following up on our previous discussions about complexity, time complexity. We defined the time and not deterministic time complexity classes, as you may remember, the classes P and NP, talked about the P versus NP problem, looked at some interesting algorithms for showing problems in P called dynamic programming. And we started to move toward our discussion
1928	of NP completeness with the introduction of polynomial time reducibility, which is related to some of the earlier reducibility notions that we discussed in the computability section.
1929	Quick review-- what it means for one problem to be polynomial time reducible to another-- this follows our pattern of reducibility concepts, where if a problem is reducible to another problem, and that other problem is solvable, then the first problem is solvable. So if a problem is reducible to an easy problem, that problem becomes [INAUDIBLE].. And the kind of reduction that we're going to be looking at here are the mapping reductions, but now where the reductions are computable in polynomial time. And so we had this result we mentioned last time, that, if A is polynomial time reducible to B, and B is in P, then A is also in P. So that's going to be critically important for the whole of discussion that's coming. Our intuition about P and NP, repeating that here-- the NP problems are the ones where you can verify membership easily, as opposed to being able to test membership easily. Those are the problems that are in P. The verification typically requires some kind of a certificate that establishes a proof that
1930	the input is a member of that language. And the big question of the field, which remains an unsolved problem, is whether P equals NP. It's called the P versus NP question. And we don't know the answer-- so whether there are problems that are in NP solvable in non-deterministic polynomial time-- typically these are problems that involve searching-- whether they can be solved in polynomial time, typically without the searching. And if P were equal to NP, then you could always eliminate searching. And if P were different from NP, then there were cases where you need to search. And we don't know the answer to that. So in the direction of exploring this question and its ramifications, we introduced this problem called SAT. These are the Boolean formulas, which have an assignment that makes them evaluate to true. So we call those satisfiable formulas. And we mentioned, but have not yet proven-- and we will not prove until the next lecture on Tuesday-- that there is this theorem, a very remarkable theorem that says that, if you have--
1931	take the satisfiability problem, and if it is solvable quickly, then all of the NP problems are solvable quickly. So if SAT is in P, then P equals NP. So in a sense, SAT is kind of no the-- it's sort of the super NP problem, in the sense that all of the difficulty of any NP problem is embedded within SAT. So if SAT becomes easy, then all of the other NP problems become easy. And we'll eventually prove that, but right now we're setting up the terminology to allow us to do that. So anyway, we'll get there. So the key ingredient for proving this Cook-Levin theorem is polynomial time reducibility. What we're going to show is that every problem in NP can be polynomial time reduced to SAT. So every NP problem can be converted into a SAT problem. And so working toward that-- because when you think about it, there are infinitely many primes in NP, and being able to show that all of them are reducible to SAT is, in a sense, kind of-- you
1932	have to prove a higher level theorem. It's not just a single reduction. We're exhibiting a schema of reductions, which shows that all of these problems can be reduced to SAT. And developing our intuition toward that direction, we're going to look at some specific polynomial time reductions today. And we'll start out with a reduction between two problems we have not yet seen-- one of them called 3SAT and the other one called clique.
1933	So remembering, again, about Boolean formulas, we're going to consider a special class of Boolean formulas, restricted form of Boolean form formulas called conjunctive normal form. And so this formula here in particular is in that conjunctive normal form. So just remember-- I was explaining some of this to someone else earlier this morning, showing some of these slides, and it was pointed out that not all of you may be familiar with these the Boolean operations of and and or. So this is the or symbol here. This is the and symbol here. Hopefully you've seen just the concept of Booelan and and or. Or is, in a sense, a little bit like a union. And it's like an intersection. And the symbols here are a little bit similar to the union and the intersection-- union and intersection symbols themselves. The V shape is a little bit like a pointy union symbol an the upside down V shape is a little like a pointy intersection symbol. If you haven't seen those-- seen that connection before, maybe it's interesting to
1934	observe that. But anyway, what makes this formula be in conjunctive normal form? Well, conjunctive normal formulas are organized in a certain way. They have these groups called clauses within the parentheses that are anded together, that are connected by these and operations. And within those groups, which are called clauses, the elements are ORed together. Those elements are going to be either variables
1935	So just to repeat that, these-- well, just to state, those variables or negated variables are going to be called literals, and the ORs of a bunch of literals are going to be called clauses. This is just the standard terminology in the field. OK? So a literal is a variable or a negated variable and a clause is an or of literals-- just a definition. All right, so we have a bunch of these clauses here. Each of the clauses has an or of literals in it. Now, a Chomsky-- Chomsky-- conjunctive normal form formula-- I guess they're both CNFs-- but conjunctive normal form formula is one that's written as an and of these clauses. So we take these clauses, which themselves are ORs-- we and them together, we get a formula that's conjunctive normal form. Conjunctive stands for and, I think. Conjunction is an and. And then a 3CNF is a CNF where each clause has exactly three literals. So for example, this particular formula is a CNF, but it's not a 3CNF, because it has at least
1936	two clauses which violate the condition of three literals per clause. This one is OK, obviously-- this first clause. And a 3SAT problem-- so this is the first of the two problems we're going to be talking about-- the 3SAT problem is the satisfiability problem restricted to these 3CNF formulas. So this is the collection of-- set of 3CNF formulas which are satisfiable. So you can think of it as kind of a special case of the SAT problem, where we only care about formulas of the special kind. This being a special case, you might imagine that this might be an easier problem to solve, but in general, it turns out not to be, as we will see. Solving this special case is just as hard as hard as solving the general case for satisfiability. Now let's turn to the second of these two languages up in the headline, the clique problem. So for that we-- going to turn to graph theory. So we're going to consider graphs, points and lines-- connecting them. And we will say that a
1937	clique in a graph is a collection of nodes-- collection of the points that are all pairwise connected by lines. And a k-clique is one where you have k such nodes. So here we have a three clique, four clique, and a five clique. And then the clique problem is to try to find cliques of a certain specified size embedded within a given graph. You're going to be given a graph, and it targets clique sized k, and you want to know, is there a subset of the nodes in the graph of size k that are all connected to one another? That's the clique problem. So obviously, the clique problem, just as with the satisfiability problem, is a decidable problem. You can just try every possible subset of k nodes and see whether it constitutes a clique. But that's, in general, going to be an exponential algorithm. If you have-- k is a large value-- it might be half the size of the graph-- you might be looking for a very large clique. Then you have to try
1938	many, many subsets in order to see whether any one of them is a clique. It's also going to be and-- I hope you get this intuition-- this is a problem that's in NP. The clique problem is an NP problem, because you can easily verify that a graph has a k-clique just by exhibiting the clique. OK. Now, so the language here is you've given a graph and a k, and you want to know, does the graph contain a k-clique? And what we're going to show is that these two problems are connected, that the 3SAT problem on the clique problem are related, in that you can reduce in polynomial time 3SAT to clique. Just standing back at it-- back for a minute, it seems kind of surprising. There's no real reason-- no obvious reason why there should be a connection between three 3SAT and clique. They look very different from one another. But we do give that-- we will give that reduction. That implies that, if you can find a way of solving the clique problem quickly,
1939	that'll give you a way of solving the 3SAT problem quickly. And that's going to be the whole point of this. So we're going to show this over the next slide or two, this polynomial time reduction. I'm going to walk through it slowly, but this is one where it's really important to try to get a sense of how it's working, because this is the kind of thing that we're going to be doing a lot of, and you're going to be asked to do it also on the homework and possibly on the final exam. I hate to use that as the motivating force here, but at least it might be one motivation for some of you, that you have to understand how to do this kind of a reduction. I think, at a high level, what's going on is we're showing how to recode a Boolean formula satisfiability problem into the problem of testing whether a graph has a clique. Oh, let's see if we have any questions here that are coming up in the chat. OK,
1940	so this is an interesting question here. Can we always convert a Boolean formula into conjunctive normal form, first of all? Yes. The answer is you can always convert a Boolean formula into an equivalent one in CNF. But in general, that might make the formula exponentially larger. So just the mere fact that you can convert formulas into conjunctive normal form doesn't mean that solving conjunctive normal form formulas for testing satisfiability of the CNF formulas is going to be as hard as testing the general case, because just the conversion might be exponential. There's something more-- little bit more complicated going on than that. Let me just see here. If phi is a satisfiable with formula which is not in CNF, can be-- so a similar question-- so the questions that I'm getting are about converting formulas to CNF. So yeah, you can do it, but not in polynomial time, in general, because the resulting formula you get might be much larger-- if you're looking for an equivalent formula. If you're not looking for an equivalent formula, then--
1941	of course, then, depending upon what you're looking for, you might be able to find something smaller. This is, I guess, a good basic question. Why is clique in NP? Doesn't verifying that you have a clique require going through all the possible cliques? You have to understand what verifying means. Verifying means you can verify something if you're given a certificate. In the case of a clique-- the clique problem-- the certificate is the clique. So once you have the certificate, you can do the verification in polynomial time. Finding the certificate, of course, might be difficult. So you only think of NP in the context of having that certificate. So in a case for compositeness, the certificate might be the factor. There are problems sometimes where what the certificate is is not necessarily obvious. But there can be a certificate for showing that the input is in the language. In the ones that we've done so far, maybe you can argue that the certificate is sort of an obvious thing, but it's not always an obvious thing. OK.
1942	Why don't we move on then? So let's see, how do we do this polynomial time reduction
1943	OK, here we go. So I'm just going to give a reduction. That's what the definition means. I'm going to give a way of converting formulas to pairs, a G and a k, where the formula's going to be satisfiability if and only if the graph has a k-clique. OK, so let's a little bit do it by example. And in order to do that-- so here's going to be a formula now. It's in 3CNF. That's what I need in order to be doing this reduction. I'm converting 3CNF formulas into clique problems. We to have a little bit understand what it means when we say-- we talk about the satisfiability of a formula like this, because it's going to be helpful in doing the reduction. Obviously, satisfiability means that the-- you can find an assignment to the variables. So you're going to set each of these variables-- A, B, and C, and so on-- to true or false, and you want to make the whole formula evaluate the true. But what does that actually mean? It means that,
1944	because of the structure of the formula, that making this formula true corresponds to making each clause true-- because the clauses are all anded together, so the only way for the formula to be true is to make each clause true. And to make a clause true, you have to make at least one of the literals true. So it's another way of thinking about satisfying this formula. Satisfying these [INAUDIBLE] satisfying assignment makes at least one true literal in every clause. It's really important to think about it that way, because that's what's going to be the basis for doing this reduction and all of the reductions. It's what makes 3SAT easy to think about, in terms of its satisfiability. If you had a general satisfiability problem and you had a satisfiability both formula, there's no obvious way of seeing what the satisfying assignment looks like, but here we understand what it looks like. It has that very special form, making one true literal in every clause-- at least one true literal in every clause. So now we're going
1945	to do the reduction. So I'm going to take from this formula-- I know, for some of you, you're going to be chafing. Why am I going slowly? But I want to make sure that we're all together and understanding what the rules of the game are and what we're trying to do. We're trying to convert this formula into a graph and a number. So right now my job is, to do this reduction, is to exhibit that graph. So I'm going to do that and two steps. First, I'm going to tell you what the nodes of the graph are. Then I'll tell you what the edges of that graph [AUDIO OUT] Finally, I'll tell you what the number k is. That's the way this polynomial time reduction is going to work. And we have to also observe at the very end that the reduction that I'm given-- giving you, this procedure for building this graph can be done in polynomial time, but that, I think-- you'll see, once I'm done, that that's pretty obvious. OK, so first,
1946	as I promised, the nodes-- so the nodes of this graph are going to correspond to the literals of the formula. Every literal is going to become a node in the graph, and it's going to be labeled with the name of that literal. Every node is going to be labeled an a, a b, or c bar, and so on. So here it goes.
1947	So those are the nodes of the graph G, one for each literal in the formula, labeled as promised. Now I have to tell you what the edges look like. I'm going to tell you what the edges are by first telling you what they are not. I'm going to first explain to you what the forbidden edges are, what edges I'm going to promise not to include. And then the ones that I will include are going to be all the others. So what are going to be the forbidden edges? First of all, the forbidden edges are going to be of two types. One is the edges between nodes that come from literals in the same clause. So I would just call that no edges within a clause. So for example, these three nodes will not be connected to one another. And I'm going to indicate that by writing red dashed lines, which means there's not an edge there. Those are forbidden from having an edge. So these three have no edge, and the same thing for every
1948	other triple of three nodes that come from clauses. Those are no edges there. And there's one other category of edge that I'm forbidding, and that are edges that can-- that go between inconsistent labels, and the nodes with inconsistent labels. So for example, between a and a bar-- those are inconsistent. Nothing's wrong with a going a to d. Those are not inconsistent. Those are just different labels. Or going from a to a-- that's OK. But from a to a bar-- that's not allowed. So that's going to be another forbidden edge-- or for example, a to a bar here, a bar to a, or for example, from this c bar to c-- forbidden. OK? So you imagine, you're going to write down all of those forbidden edges. Those are all of the forbidden edges, and then, after taking those away, you're going to be putting in all the other edges possible. So for example-- let me just gray those out so they don't interfere with the picture-- from a to d, there's going to be an edge,
1949	because those are not forbidden. a to a-- not forbidden, because they-- they're in different clauses and they're not inconsistent. They're consistent with one another. So here are a whole bunch of others. I'm not showing them all. It becomes very messy. But here are all of the other edges between nodes which are-- where they're not forbidden. OK? And that's the graph. That's G. G is all those nodes and those edges which are not forbidden. And I just have to tell you what k is. k is going to be the number of clauses. That's going to be the size of the clique I'm looking for in this graph G that I just spelled out for you. And I'm going to claim that this graph here that I just described will have a k-clique. k is the number of clauses exactly when phi was satisfied. It's kind of cool. If phi is satisfiability, then there will be a k-clique here. And if phi was not satisfiability-- no k-clique. We're going to prove that as a claim on the
1950	next slide. OK, so k is the number of clauses. All right? Any questions on that construction? So I've done with the construction. What's left is to argue why the construction works. So far, so good-- let's move on. OK. So here is that very same construction. I eliminated the red forbidden edges. These are the ones that were remaining, plus anything else that was not forbidden. That was the same formula that I had from the previous slide. Now I want to claim that that formula is satisfiability exactly when G has a k-clique. Now, why in the world is that? So this is an if and only if. It's proved in both directions. And this is going to be the typical kind of thing that you're going to want to do when you're exhibiting a-- one of these reductions, which is you're going to have an opportunity to do that. And we'll do that too in our examples.
1951	that, if phi is satisfiable-- so let's prove the forward direction-- if phi is satisfiable, then G has a k-clique. OK, so first of all, if phi is satisfiable, that means it has a satisfying assignment. Now, here's a common confusion. I'm not sure whether it's helpful to sprinkle the confusions alone with the discussion, but in case you're worried, you might ask, well, how do I find that satisfying assignment? I thought that was exponentially hard to do. This is a proof. This is not an algorithm. We're just trying to argue the correctness of this construction. So there's no longer any concern about how to find an assignment. I'm just saying, if there is an assignment-- if there is a satisfying assignment, then something will happen something. Then something will happen-- in particular, then we will show that G has a k-clique. So let's say phi is satisfiable, so it has some assignment. Let's take that satisfying assignment. And remember that, in any satisfying assignment to a formula in CNF, that makes at least one literal true in
1952	every clause. So let's just pick one of those. There might be several clauses which have multiple true literals. In that case, just pick one of them arbitrarily. I don't have this indicated on this diagram here, but imagine maybe, in the very first clause, a was true; in the second clause, b was true; in the third clause, e complement-- e bar was true, not e-- e bar was true, which means e itself was false, but e bar was true. And that's the way each of those clauses, in turn, got to be true in this particular satisfying assignment-- because you're going to pick one true literal every clause. And now, from that choice of literals-- one per clause-- I'm going to look at the corresponding nodes in G, and I'm going to claim that those nodes taken together form a k-clique. OK, so first of all, do they have the right number of nodes? Well, sure, because I'm picking one node per clique. I already said k is the number of cliques, so I'm getting exactly k
1953	nodes. So I have at least the right number of nodes. But how do I know they're all connected to one another, those nodes that I just picked? Well, they're all connected to each other because I'm going to say-- well, because there were no forbidden edges among them. And remember that we put in all possible edges except for the forbidden ones. So how do I know there are no forbidden edges? Well, what were the rules for being forbidden? It means they-- two nodes in the same clique-- in the same clause. Well, I'm picking one node per clause, so I can never be having two nodes from the same clause. So I'm never going to run into trouble with the first condition of being forbidden. So what's the second possibility for being forbidden, is that I'm picking two nodes which are inconsistent-- well, how do I know that I didn't end up with two nodes with inconsistent labels? That would be bad, because then they would have a forbidden edge, and what-- my result would not be
1954	a clique. How do I know I didn't end up picking-- in this group I pick a, and in this group I pick a bar? Well, because they all came from the same assignment. They were all true liberals in clauses. It's not possible that a was true in this clause and a bar is true in that clause, because if a is true here, a bar's got to be false. It can't be the true literal in this clause. So I cannot have any inconsistent nodes appearing among the nodes of my clique. And so they're not in the same clause. They're not inconsistent, so the edge has to be there. And that's going to be true for every pair of nodes in that clique-- in that group of nodes, and that's why it's a clique. So that proves one direction. Now we still have to prove the other direction, because we have to say, well, if G has a k-clique, how do we know that phi is satisfied? So that's the reverse. So let's just take any k-clique
1955	that's in G. And how do I know I can get from that, a satisfying assignment to the formula? Good-- getting some good questions here in the chat. But let me just move on. So proving the reverse-- the reverse direction, assuming we have a k-clique-- take any such k-clique. Now, first of all, you observe that it's got to have one node in every clause. It can't have two nodes in the same clause or zero nodes in a clause. First of all, it can't have two nodes in the same clause. Why? Well, because those nodes are never connected to one another. So they cannot be both in the same clique, because all the nodes in the inner clique are connected to one another. By the way we constructed G, nodes from the same clause are not connected, so they cannot appear in a clique together. So there's going to be at most one node from every clause appearing in this clique, but-- appearing in this clique. But we also have-- we know we have k nodes, so
1956	that means, if there is at most one per clause, and we only have k clauses, that means every clause has got to have one. If some clause is missing a node, then there's got to be some other clause that has two. So we know that every-- that this clique that G has exactly one node in every clause. So how do we get from that satisfying assignment? So what we're going to do is take the corresponding literals that correspond to that one node in that was in the clique, take those liberals and set those literals to be true, which means setting the variable to be true or setting-- if the literal was a bar, then setting a to be false, because you want a bar to be true. You want to set the literals to be true. Well, now we're setting-- there's one node in each clause-- we're setting one literal-- the corresponding literal-- true, so that's going to set one true literal in every clause. So that means it's going to be satisfying. There's one
1957	thing that one has to really be careful here to double check-- to make sure that we're doing this consistently, that we're not being asked to set a true and also a bar true, because then that would not be possible. But a and a bar are not connected, so it's-- we're never going to be trying to set both a and a bar true. If we're going to be trying to set a true, we're never going to try to set a bar true, because those are not-- a and a bar cannot be in the same clique. They're not connected to each other. OK? So that is the argument. And lastly, I claim-- we're not going to look at this in detail-- that it's kind of obvious that this reduction can be done in polynomial time. Namely, if I give you that formula, you can write out that graph in-- pretty easily. There's no hard work to be done in writing out that graph or counting up the number of clauses. So that's the proof that I can
1958	reduce 3SAT to clique. And it tells you also that, if I could solve clique quickly, then I can solve 3SAT quickly. And this is the whole point, because I can convert now clique problems to 3SAT problems. No. I'm sorry. I got it backwards-- convert 3SAT problems to clique problems. So if I can solve clique easily, then I can solve 3SAT easily. I just showed a way of converting these formulas to graphs. So that says, if I can solve the graphs easily, then I can solve the formulas easily. OK, why don't we turn to some-- oh, question, check-in. But we can now also-- I'll launch a check-in, but we'll-- let's just see. I'm seeing many, many questions here, which are actually what my check-in is about. I'll turn it back to you guys. OK, so where did we use the fact that we have three literals per clause? Does this thing just work even if we had any number of literals per clause? What do you think? We got a tight race here. Truth is losing
1959	out, unfortunately. All right. Oh, it's really close, but still-- OK. One more-- OK, it's neck and neck. OK, almost done-- 10 seconds-- are we done here? OK, that's it-- ending polling. Yes, truth has won out. Thank God. Yeah, it works for any size clause. We didn't use the fact that it's a 3CNF. It could have been any number here. Well, we've got a-- I guess it's a plurality here, though, not a majority. Where did we use 3 in any of these argument? I didn't mention it. Maybe you were imagining that it's going to be part of it, but 3 does not come into this discussion at all. If you think about how it's-- why it's working, even if we had-- one of these clauses had 10 literals in it, as long as k is the number of clauses, and we don't connect any variable-- any literals internal to a clause, this whole argument is going to still work. So please check that make. Sure you understand what's going on, because I can see that a
1960	good chunk of you have not got this right. So I got a good question here. What if it's only just one big clause-- so it's like the whole formula's just one big OR. So what does happen in that case? Good question-- so in that case-- suppose there's one big clause with 100 literals. That's the whole formula. It's just a big OR. So we know the formula's going to be satisfiable, by the way, obviously. So if you look at the corresponding G, it's going to have 100 nodes, because there's one for every literal. None of them are going to be connected to each other, because they're all in the same clause. So it looks like we're going to be in tough shape trying to find a clique there, because there's no edges at all. Everything's forbidden. But what is k? k is going to be 1 in that case, because there's only one clause. And kind of a degenerate case, but a clique with just one-- just a single node is-- counts as a one clique,
1961	because it's just one node. There's no need for any edges at all. It still counts as a clique. So it'll still work out. Let's see. What else here? That was kind of a fun question that you asked me. Thank you. There are a lot of questions. I think we're actually pretty near the break also. We'll just see. Yeah. Oh, many, many questions here-- so I think I'm going to start the clock going down for our, coffee break and I will take some of these questions. I'll try to answer some of these questions-- oops--
1962	All right. Good-- all right. So I got a question about making sure why nodes don't have inconsistent labels, if I understand the question correctly. So I never put edges between nodes with inconsistent labels. That's the rule. That's my construction. I get to say how the construction works. So those two nodes with inconsistent labels can never be in the same clique, because there's no edge between them. So I'm not sure that answered the question there, but that was-- let's see. So we're getting another question here. Since any Boolean formula can be converted to CNF, does that mean-- is SAT polynomial time reducible to clique as w-- [INAUDIBLE] time reducible to clique, but not for the reason that any Boolean formula can be converted to CNF, because that conversion is going to be an exponential conversion in general-- the conversion to CNF. So you have to be careful about what we mean by converting a formula to CNF. So also getting question-- what happens in the case of 1SAT? Well, we didn't really talk about 1SAT. So
1963	the question is, suppose there's only a single literal per clause. That's an interesting-- another sort of edge case here. What happens under those circumstances? So there's only a single literal per clause. So you have to work out what happens. But in that case, all the clauses just have one literal in them, and now they have-- when you have a 1CNF, so there's only one literally per clause, the only way that can be satisfiable is you have to make each literal true, because there's no ORing anymore. So every literal has to be true in the assignment. So that means you can never have any consistent literals. And that's the only case when you would not have an edge, because you're not-- the forbidden condition won't happen because you don't have more than one node per clause. Every clause is going to have just a single node in it. So it really comes down to whether or not you have an inconsistently labeled-- inconsistent clauses. I didn't explain that super well, but it's-- the argument still works,
1964	though. You should check it for yourself. So this is a basic question. How do we see that F is polynomial time? I'm not sure I want to spend a lot of discussion on that. The conversion from the formula to the graph is kind of a one-to-one-- every literal becomes a node. The rule for when edges are present-- it's a very simple rule. I'm not sure what more to say. It seems pretty clear that the conversion-- that reduction is polynomial time computable. If you wrote a program to do that, it would operate very quickly. Is it possible for G to have a k plus n clique, where n is greater than 0? Does that matter? If you think about it, the biggest possible clique that this graph G could have is k. It could never have more than a bigger clique, because two nodes in the same clause are never connected. You only have k clauses. So the answer is no, you cannot have a-- bigger than a k-clique-- just not going to happen. Does each
1965	clause need to have the same number of literals? I don't see why. So question is, why are we worrying about 3SAT, since it didn't seem to matter here? There are other examples where it does matter. I'm actually not sure if we'll see one or not, but there are cases where it does matter. Let me just see if there's any quick questions here. Somebody's saying, does-- do we have to worry about there being a polynomial number of literals? So you have to think about what that question means. The size of the input, which includes all of the literals, is n. So there's going to be, at most, n literals, because that's the size of the input, at most, in literals appearing. So you don't have to worry about that being polynomial, because-- by the way, we're defining the size of the input is going to be, at most, n literals. I hope that's clear. OK. OK, so this is a good question. When we talk about polynomial time, it's polynomial in the representation of the input,
1966	which is-- if you want to think about it in terms of bits, that's fine-- or whatever. It's not going to matter if you use some larger alphabet. But the number of symbols you need in your fixed size alphabet, the number of symbols you need to write down that input in whatever your reasonable encoding is is going to be n. And it's going to be polynomial in n, polynomial in that length of the input. So another question is, does SAT reduce the 3SAT? Yes. That we will see. SAT actually does polynomial time reduce to 3SAT. Not by converting to an equivalent formula, but by some more-- somewhat more involved argument than that. OK, why don't we move on? Some of these are going to come out anyway in the lecture.
1967	OK, so now let's talk about NP completeness, because we've kind of set things up. We're not going to prove that the basic theorem, the Cook-Levin theorem about NP completeness, but at least we'll be able to make the definition. OK, here is our definition of what it means for a problem to be NP complete. So a language B is called the NP complete if it has two properties. Number one is that it has to be a member of NP, and number two-- every language in NP has the polynomial time reduce to that language-- to that NP complete language in order for it to be NP complete. So simple picture-- has to be in NP and everything an NP reduces to it. And so that's kind of the magical property that we claim that SAT has. sat, for one thing, is obviously in NP. And as we-- the Cook-Levin theorem shows-- or will show-- everything in NP is reducible to SAT, so SAT's going to be our first example of an NP complete problem. And we're going
1968	to get what we claimed also for SAT-- that, if SAT or any other NP complete problem turns out to be solvable in polynomial time, then every NP problem is solvable in polynomial time. And that's immediate, because everything is reducible in polynomial time to the NP complete problem. So if you can do it easily, you can do everything easily just by going through the reduction. OK. So the Cook-Levin theorem, as I mentioned, is that SAT is NP complete. And we're going to actually prove it next lecture, but let's assume for the remainder of this lecture that we know it to be true. So I'll use the terminology of problems being NP complete, assuming that we know-- that we have SAT as NP complete. OK? So we're going to be using some of the things that we're proving next lecture just in the terminology that we're going to be talking today. OK, so here's the picture. Here's the class NP. And everything in NP is polynomial time reducible to SAT. SAT itself is a member of NP,
1969	but I didn't want to show it that way because it makes the picture kind of hard to display. So just from the perspective of the reduction, everything in NP is polynomial time reducible to SAT. We'll show that next lecture. Another thing that we'll show next lecture is that SAT, in turn, is polynomial time reducible to 3SAT. So 3SAT, as you remember, are just those problems that are in conjunct-- are in 3CNF. And then what we show today is that 3SAT is polynomial time reducible to clique. So now, taking the assumption that SAT is NP complete-- so everything is polynomial time reduce both the SAT, which is, in turn, polynomial time reducible to 3SAT, and in turn, reducible to clique. These reductions, as we've seen before, composed. You can just apply one reduction function after the next. If each one individually is polynomial, the whole thing as a combination is going to be polynomial. So now we know that 3SAT is going to be also NP complete, because we can reduce anything in NP to SAT,
1970	and then to 3SAT, and then we get a reduction directly to 3SAT by composing those two reductions-- and then, furthermore, at the clique. So now we're-- have several NP complete problems. And moving beyond that, we have the HAMPATH problem, which we are going to talk about next. And we'll show another reduction in addition to the one we just showed to clique, now one going from 3SAT to HAMPATH. OK. So in general, I think the takeaway message is that, to show some language is NP complete, you want to show that 3SAT is polynomial time reducible to it. OK, some good questions coming in-- I'll try to answer those. So you're going to take 3SAT and reduce to C. That's the most typical case. There's going to be other examples too, we might start with another problem that you've already shown to be in NP complete, and reduce it to your language. So it doesn't have to start with 3SAT, though often, it does.
1971	Why is this concept important? So I would say there are two reasons. And this is going to get a little bit at some of the chat questions. First of all, if you're faced with some new computational problem-- you've got some robotics problem that you want to solve in your thesis, and you need some algorithm about whether the robot arm can do such-- move in a certain such a way, and involves searching-- possibly searching through a space of different kinds of motions, and you want to know-- I'd like to find a polynomial algorithm to solve that problem. I'm using this as an example because this actually did happen to one of the former students from this class, who was working in robotics, and they actually end up proving that the problem that they were trying to solve is NP complete. So that's useful information, because even though knowing a problem is NP complete doesn't guarantee that it's not in P-- because conceivably, P equals NP-- what it does tell you-- if you have a problem that's
1972	NP complete and it does turn out to be in P, then P equals NP. So there would be tremendous surprising consequences of your problem, if it was known to be NP complete, ending up in P. So generally, people take a proof of NP completeness as powerful evidence that the problem is not in P. Even though it's not quite a proof, it's powerful evidence that it's not in P. And so you might as well give up working on trying to find a polynomial algorithm for it, because if you do, you don't have to worry about robotics anymore. You're going to become famous as a So I wouldn't worry about-- so if you throw problem's NP complete, you can pretty much assume-- almost certainly not in P. Now, there's another reason related to-- for the theorists to be-- care about NP completeness, and that is, if you're trying to prove P is different from NP-- or P equals NP, as one of the chat questions is raising-- order to prove P different from NP, the most likely
1973	approach is you pick some [? pre ?] problem in NP and show it's not in P. That's what it would mean for them to be different. You're going to pick some NP problem and show it's not a P problem. Well, one thing would be terrible is possibly, P is different from NP, and you pick the wrong problem. Suppose I'd spent all my time trying to show-- back 20 years ago, I'm working really hard trying to show composites is not in P, which is-- would have been perfectly reasonable to do, because composites is an NP, and it was not known to be in P 20 years ago. And then I invested tons of effort to try to prove-- because I like number theory or God knows what-- to prove that composites is not in P. And then, turns out, composites was in P. It was the wrong problem to pick, even though P might be different from NP. But what NP complete is guarantees is that, if you work on a problem, which is NP complete,
1974	you can't pick the wrong problem, because if any problem is in NP, and not in P, an NP complete problem is going to be an example of that-- because if the NP complete problems in P, everything in NP is in P. So if NP is different from P, you know the complete problems are not in P, so you might as well work on one of those. So those are two ways in which NP completeness has turned out to be-- is an important concept. OK, so here's a check-in. You guys are getting-- maybe you're getting-- starting to think the way I think. You're getting-- some-- at least one of you asked this question in the chat. Which language are we've probably seen is most analogous to SAT-- ATM, ETM, or 0 to the k, 1 to the k? Obviously, this is maybe subjective. You may have your own interpretation of what that means. There's, in a sense, perhaps no right answer, but what do you think? OK, that's it. I don't know how in the world
1975	that you could see this problem as analogous to 0 to the k, 1 to the k, but OK. I'm sure you have your reason. Yes, this is a lot like ATM. Why? well, because for one thing, we showed in a homework problem that all Turing recognizable languages are reducible to ATM-- mapping reducible to ATM. So that's a little bit like the notion of completeness that we have for satisfiability, because all NP problems are going to be reducible to the SAT. And the other thing too is that, once we start-- we want to show other problems are undecidable, we reduced ATM to them. And that's also very similar. We're going to be reducing SAT or 3SAT-- so it's indirectly from SAT-- to other problems in order to show that there shouldn't NP complete, so that they're hard-- that they're hard, in a sense. And so in both those ways, ATM and SAT are kind of playing similar roles. One key difference, however, between ATM and SAT is in that for ATM, we can prove that it's
1976	undecidable, but for SAT, we don't know how to prove it's outside of P. Those would be the analogous situations. And so the story for SAT, which is easily solved by a diagonalization argument for ATM-- there's reasons to believe-- that we will see later-- that the diagonalization is not going to work to prove SAT outside of P. And besides that, we don't really have any good methods. So anyway, let's move on. Why is ETM less analogous? Because the ATM was the first problem we showed undecidable, and SAT is the first problem that we're going to be showing NP complete. I guess that would be my answer. OK, let's continue. So let's show now that HAMPATH is NP complete, assuming that we know SAT or 3SAT is NP complete. So we're going to give a reduction from 3SAT to HAMPATH. That's what this is about. It's just like what we did for clique, but now for HAMPATH. And this is going to be very typical. In these reductions, typically what happens is that you're trying to simulate
1977	a formula-- Boolean formula for satisfiability-- from the satisfiability perspective. You're trying to simulate that formula with some sort of structures inside the target language, which would be HAMPATH. The lingo that people use is that you're going to build gadgets to simulate the structures in the formula-- namely, the variables, the literals, and the clauses. OK, these are going to be substructures of the graph, in this case, that you're building. We'll see what that means. So let's take a formula here and let's, again, try to imagine how we would reduce that to the HAMPATH problem. So the reduction would produce a graph-- no, it would produce an HAMPATH instance-- so a G, s, and t. Want to know, is there a Hamiltonian path from s to t in the graph? And this is going to be not the whole graph, but this is going to be a substructure in that graph. The next slide is going to have the global structure of the graph. But here, this is going to be a key element, and we're going
1978	to call that the variable gadget. OK, what does it look like? I don't know if you can see it on your-- clearly enough, but these edges-- so there are four outside nodes here. The edges connecting them are all kind of pointed downward. And then there were these horizontal nodes here, and there are edges connecting them both left to right and to left. There's a row of these horizontal nodes. OK, so you get the picture of what this looks like? You have to look carefully to see the arrowheads. I maybe should have made those a little bigger. Whoops-- so now, if we're trying to get from this node to that node-- imagine now you're trying to build a Hamiltonian path, because this is going to be a part of that graph G that I'm constructing. Now, remember, for them-- for there to be a Hamiltonian graph, that means you have to go through every node in the graph. So if I want to get from s to t, the only way I'm going to be able
1979	to go-- to hit these horizontal nodes here is by picking them up as I go from s to t. So the only possibility is-- if you think about it, is-- would be for the sequence to go like this, if you can-- if that comes through for you. So the path would go from s to this node, and then through these hops of-- along these horizontal nodes, and then down to the bottom node here. So that's one way that you can get from here down to there and pick up all the other nodes along the way, which is-- they're not going to have any other possibility-- possible ways of getting to them. So I'm going to call that a zig-zag. OK? But there's another way to get from s to the bottom node, which is going to be by doing sort of the dual-- going to the right, then going out to the left, and then down to the bottom. I'm going to call that a zig-zig-- and with a little diagram here just to summarize
1980	what it means. And this is the classic thing for a variable gadget, because it's a structure that when you're trying to think about how the object that you're asking whether it exists or not-- the Hamiltonian path-- how it relates to that object, it's going to have two possibilities, which are going to correspond to the variable being set true or false in the formula. So we're showing how to set the-- simulate the variable in this HAMPATH instance. So setting the variable is going to correspond to constructing the path. OK? Now, we also have to make sure not only that the variable gets set to true or false, but that it gets a set of true and false in a way that makes this a satisfying assignment-- namely, that we get one true literal in every clause. So I'm going to add another gadget here called a clause gadget, which is just a single node. And visiting that node here is going to correspond to satisfying that clause, to having a true literal in that clause. I'm
1981	going to have [? enabled ?] a detour from these horizontal nodes out to this clause gadget. So here it is. Here's that detour. As I'm going from left to right, I can-- instead of doing a single jump here, I could branch out and visit that clause node, and then come back, and pick up my left to right path, as I was doing before. I hope you're seeing the big picture, because this has to be a Hamiltonian path. It has to hit every node. That's one of the requirements. This is going to be one of the nodes in my graph. The path has got to hit that node. The only way it's going to be able to hit that node is by taking a detour off of this horizontal path here. But notice-- and this is the key-- if I'm doing a zig-zag, then I can make the detour and visit that clause gadget-- that clause node. But if I'm doing a zag-zig, the way this detour is structured does not allow me to visit that
1982	node, because if I'm going from to right left here, by the time I get to this outgoing edge-- now I want to come back-- that note has already been taken. It only works if I'm going zag-zig, if I'm going from right to left-- left to right. If I'm going from left to right, then I can do it, but if I'm going right to left, no. If you think of left-- the left to right direction as true, that's going to correspond to that variable appearing in the positive way in that clause, but not in the negative way. The negative way-- I would reverse in and out of the detour, flip that around so now I could only do the detour when I'm going right to left, instead of left to right. I hope you get the picture. This is how the structure is working. Now what's only left for me to do is put it all together. But this slide contains the guts of what's happening. Is there any question that I can answer for you
1983	on this? Let's move on to the next slide, and then, as questions come up, you can be typing them in, and we can maybe answer it there. OK, so here is the big picture. So imagine we have that formula that we're start-- we're reducing that formula. And let's say it has m variables and k clauses. I'm going to call them clause c1, c2, up to ck-- here, the m variables appearing either positively or negated in that formula. And this is the way the global structure of G is going to look like. Now, I'm getting a question here. What do those horizontal nodes-- what role do they play? Those nodes are there to allow me to visit those clause nodes, the nodes which represent the clause gadgets, which I'm going to place over here. This is almost a whole of G. I'm just missing a few edges, but these are all the nodes of G. So remember, I'm trying to find out, is there a Hamiltonian path from s to t? Now, if I didn't have
1984	to worry about these nodes, the answer would be just yes. In fact, there would be many Hamiltonian paths from s to t, because I can do a zig-zag or a zig-zag through each of these variable gadgets, and that would take me from s to t, and I'd be good. It's just the c nodes, these nodes-- these ci nodes-- I have to hit them too. So they're going to be-- visiting them is going to be enabled by detours from here. So let me just try to show you what that looks like. So I'm going to magnify little pieces here from these gadgets here and show you how these guys are connected up. So here is the x1 gadget. So x1 appears positively in c1. Here's x1 and c1. And so that means, when I'm going left to right, I'm going to be a possibility of visiting c1. But now, let's look what happens with-- which was the next one I had here? OK. Right. So the next one is-- oh, yeah. So x1 appears positively in
1985	c1. That's why I have the connection like this. Now, x1 appears negated in c2, so I only want to do-- enable the detour to visit c2 when I'm going to left, as opposed to left to right. So this set of horizontal nodes is only going to allow me to take a detour either out to c1 or out to c2, but not to both, because the Hamiltonian path is either going to go left or right or to left. It can't do both, when it's going through the x1 gadget. You need to-- [INAUDIBLE] I'll try to help you through it, but you have to try to think about why it's working. Let's think together. So x2 also appears in c1, but now it appears negated. So I'm going to have edges from this x2 gadget-- oops-- the x2 gadget, but now look at the-- look at how I've arranged that detour. I can leave on the left leftward side and return on the right side, which means I can only do that detour when I'm going to
1986	left. And that's because x2 is negated in c1. Maybe it's a lot here, if you're not quite getting it, but the point is, let's say, try to quickly prove-- so that's the whole construction. You just do that for every single appearance of the literal in a clause. You're going to add these detours, which allow you possibly to go visit the clause. So the forward direction is-- why is this true? So you take any satisfying assignment, as I suggested, make the corresponding zig-zags or zag-zigs through the variable gadgets from s to t, and then take the detours to visit the clause nodes. The reverse direction actually is slightly trickier. We're not going to have time to go through the subtlety of it, but what you want to make sure here is that you don't have a weird path occurring, because I'm going to start with a Hamiltonian path now and build an assignment. And we want to make sure that the path that I'm constructing doesn't go from one-- from this horizontal nodes to a closed
1987	node, and then back to somebody else's horizontal nodes, and is kind of a hodgepodge of things which don't make any sense in trying to reconstruct a satisfying assignment. What you really want to have happen is the Hamiltonian path should have clear zig-zags and zags-zigs that allow you to decide how to set the variables. And so that's the role of these little nodes here. These are spacers that separate the detours from one another, and that force a visit to the clause node to come back to the same place from which it left. Otherwise, you would never be able to visit those spacer nodes. You have to look in the book for that, but there is a little bit of a detail that you have to go through. You have to show it must be zig-zags and zag-zigs, and then you get the corresponding truth assignment, and it must satisfy phi for all paths. OK. Again, the reduction is polynomial time computable. I'm not going to say more about that. We're a little bit low on time.
1988	Last check-in-- would this construction still work if G was undirected? Suppose I just eliminated all the directions from the edges, made them lines, instead of arrows. Would that now show that the undirected Hamiltonian path problem is NP complete? Let me see. OK, what do the c nodes represent here? There's one c node for every clause. So there are k clauses named c1 to ck, and there are k c nodes. These are the so-called clause gadgets, which are going to force there to be one true literal in every clause for the satisfying assignment. You have to look at it, or maybe we can spend a little bit more time explaining it, but that's what the purpose is. Does that mean we need only two inside nodes? So the horizontal nodes-- do we only need two of them? You won't be able to reuse these nodes for multiple detours. For one thing, once you've gone to a detour, you come back to the node next over, and so you better not overlay multiple detours. And also, you
1989	need to keep them separated from each other. Don't forget, this node x1 can appear in many, many different clauses, so you would need to have possibly many of these horizontal nodes. So someone now says 2k inside nodes would suffice. Probably 2k-- I would say 3k, just to be safe for the spacer nodes. You need to look carefully at the argument, which is laid out in the textbook. You may not actually need the spacer nodes, but then it makes the argument just more ugly. So the way the construction is done is you have 3k inside nodes. OK. Again, several questions like that-- the graph would start looking messy if x9 was in c1. Yeah, if x9 down here was in c1? Yeah, it would be messy. It's OK. Messy is allowed. All right, I think we're-- let's end the polling. Are you all in? All right-- share results. Yes. The answer's no. The construction depends on this being directed. You can see that all over the place, but for one thing, the whole point of these
1990	detours is the directions of the edges. And so without that, this construction is going to be just a bunch of-- is not going to mean anything. It's not going to prove anything. It's probably always going to be-- have a Hamiltonian path without the directions. So I think we're out of time. A quick review-- these are the topics we've covered. I think we're out of time, so I should let you go. But I'll stick around for a few minutes, in case any of you have any questions. But I need to run off at 4:00 myself for another meeting, so I don't have much that much time. Clarify my comment about picking the wrong problem to tackle P versus NP, when I used composites as an example-- if I worked hard to prove that composites is not in P as a way of proving that there is some NP language which is not in P, that would have been a mistake, because composites is in P. I would have been working hard to prove something which we
1991	now know was false. So we don't want to spend time working on the wrong language. But the nice thing about NP complete languages is that we have a guarantee that, if P's different from NP, that that language is not in P. Are there problems that are not in P that are in NP, but are not NP complete? Oh, that's a good question. Are there problems in between P and NP complete? So NP complete is sort of like the hardest problems in NP, and the P problems are obviously the easy problems that are in NP. Is everything either NP complete or in P? So for one thing, there are problems that are not known to be in either category. So we'll discuss some of those in due course, but one of them is the graph isomorphism problem, testing two graphs-- if they're really just permutations of one another. It's clearly a problem in NP, but not known to be in P. So there are problems that are not known to be either NP complete or in
1992	P, so there are problems that might be in between. But then there was another theorem out there, which says that, if you assume that P is differ from NP, then you can construct problems which are in between, which are neither NP complete nor in P. They're NP, problems but they're not NP complete, not in P. So those problems themselves are perhaps somewhat artificial, but they at least prove the point that it is possible to have these intermediate problems. Oh, so somebody's asking, isn't factorization one. Not [? known-- ?] for the case of factorization-- or you have to make a language out of that, by the way. But it's a because factorization's a function, so we won't really want to be talking about languages. As the homework suggests, NP and P are classes of languages, but OK, that's a separate note there. Factorization is not known. Factorization could be in P and it could be NP complete. Both of those are not ruled out. So I think most people would probably venture to guess that it's
1993	"a problem that's in the in-between state, that's neither P nor NP complete, but not known. Who first thought of this reduction from 3SAT to HAMPATH? It's so clever. Well, it wasn't me. I think that is due to Dick Karp, who was one of my professors at Berkeley, where I was a graduate student. That was done before I got there. It was around 1971 when-- so there were two famous papers. There's the Cook paper. There's also the Levin paper. That was in Russian. That took a while for people to discover out here in the West. But the Cook paper was 1971, and very quickly followed after-- he just showed SAT is NP complete, but after that, Karp was-- he had a paper called ""Reducibility Among Combinatorial Problems,"" and he had a list of about 20 problems that he showed were NP complete-- by reduction from SAT-- include clique, include HAMPATH, and a bunch of other things. And that was also a very famous paper. Both of those are-- people often talk about Cook-Karp as, together, they"
1994	really show the importance of NP completeness and the whole notion of NP completeness. Yeah, 21 problems, so-- yeah, so Karp proved 21 when problems were NP complete in 1972. So that was shortly after Cook showed that SAT was NP complete. Incidentally, I think the terminology NP complete wasn't around until a little later. And that might have been-- might be due to Knuth. I'm not sure. I remember he did a big poll of people about what should be the right language to use for that term, and I think he came up with it. All right, I'm going to head off, guys. Nice seeing you all-- so until Thursday-- oh, until Tuesday. Bye bye.
1995	[SQUEAKING] [RUSTLING] [CLICKING] MICHAEL SIPSER: Hi, folks. Welcome back. So we will continue our discussion that we had-- that we've been doing for the past few lectures. We first talked about time complexity. And then we shifted gears to talk about space complexity. So we had a couple of lectures on PSPACE, kind of culminating in proving that there were languages which are PSPACE complete, namely this TQBF language, which is where we started. And then we also proved that there are problems involving games, such as the generalized geography game, where determining which side has a winning strategy is PSPACE complete. At the end of the lecture last time, we moved to a different regime of space, namely from polynomial space down to log space. And we introduced the classes L and NL. And so I'm going to begin today's lecture by reviewing some of the material on N and NL, which I think came a little too quickly last time. And then we have two important theorems we're going to cover today. One is about proving that there
1996	are complete languages for NL that has a bearing on the L versus NL question-- log space, deterministic log space, versus nondeterministic log space. That's yet another unsolved problem in our field. And so there is a notion of a complete problem for NL. And then we're going to prove a theorem that was, in its day, very surprising to people. I remember when it came out in the 1980s, that NL, in fact, is closed under complementation, that the NL class and coNL class both collapse to 1, that they're equal, which is not the way we believe the situation to be for NP. But until someone has a proof that they're different, strange things can happen. OK.
1997	And let's do our review. So we are-- in order to talk about space complexity classes that are smaller than n, we had to introduce a new model, which was the two-tape model, where there was a read-only tape that had the input on it, which you normally would think of something very large-- the whole internet, or something so big that you can't read it into your local memory. And then you have a work tape, which is your local memory. And the way we're going to think about it in the context of log space is that that work tape is logarithmic in the size of the input. And that is enough to have small counters or pointers into the input, because a reference location of the input is just-- you only need log n bits to do that. So we gave a couple of examples of the L and NL-- of L and NL languages, so this language of ww reverse, as you may remember. So here is an input in ww reverse. It's a string follow--
1998	it's a palindromic string, which is of even length. And so you can make a machine in log space here that can test whether its input is of that form. And the work tape is only-- all it needs is a pointer into the-- or a couple of pointers that refer to the corresponding places of the input that you're looking at at the moment. So you maybe start out looking at the two outside a's and then the b symbols that are next to that. And you can write down on your tape where you're looking currently. And so that's going to be enough for you to-- you may have to zigzag, of course, back and forth a lot in order to do that test. But that's completely fine, using the model. We're not going to be measuring time. We're only going to be focusing on how much space we're using. Another example that we gave is the PATH language, where you're given a graph, and a start node, and a target node. And you want to know, is
1999	there a path in this directed graph that goes from s to t? And that's the language that's also-- that language is in NL-- in fact, not known to be in L. So the way that would look, shifting to an input in the PATH language, you would have a graph represented, say, by a sequence of edges, and a start, and a target. And the work tape would keep track of the current node. So the nondeterministic machine would guess a path that takes you from s to t, node by node. And the work tape would keep track of the current node. OK, so I hope you have this-- develop a little bit of an intuition for these classes, L and NL. We're going to be spending the entire lecture today talking about that. OK. So as I mentioned, the L and NL problem is an unsolved problem. And it's very much analogous to the P versus NP problem, except, as I mentioned, as we'll show, that NL and its complement end up being the same, which is
2000	not something that seems to be the case for NP, though we don't know. Can we think of this as a multi-head Turing machine? I'm getting a question about that, which is, I think, you can. In fact, that's an alternative way that people look at it. You can think of it as having multiple-- you know, a head basically needs log space to store the location-- to store the location of where that head would be. So if you imagine having several different heads on the input tape, you can think of a log space machine as being sort of a Turing machine that has multiple heads on the input table. It's equivalent. Good question.
2001	OK. So one of the things we proved last time was that anything that you can do in L, you can also do in polynomial time. And I'll answer some of these chat questions in a minute. But the-- so the class L is a subset of P. This is easy to prove. But I think it's nevertheless important to see why it's true, because it sort of sets some definitions of things that we're going to use later. So in particular, we really need to know the notion of a configuration of a log space machine on an input. So because the input does not change, we don't really consider the input to be part of the configuration. The only thing that's-- the thing that's relevant in the configuration is the dynamic part of the machine-- the state, the head locations, and the work tape contents. So we're defining that the configuration for the machine on a particular input, w, is those four things-- state, the two head locations, and the tape contents. And the important thing to keep
2002	in mind for this theorem is that we have only a polynomial number of different configurations if you just do the calculation. The main part is the number of different tape contents as you can have, which is exponential in the log n. And that's a polynomial. And so therefore, any machine that runs in log space, provided it always holds, and we always assume our machines always hold, they can only run for a polynomial number of steps, because that's as many different configurations as they have. If they ran for, say, an exponential number of steps, they would have to be repeating configurations. And then they would be looping. OK, so there we go. OK, so let me just get back-- so somebody asked me a question. Which is harder? P versus NP or L versus NL? Completely no idea. It's a-- I guess there was a common line of thinking that if you're going to-- that it's good to try to think about-- if you're trying to separate classes, you might as well take classes that are
2003	as far apart as one another. Like, if you're trying to prove-- if you're comparing P different from NP and P different from PSPACE, maybe P different from PSPACE might be easier, because P and PSPACE seem to be even further apart than P and NP. Nobody knows. And I suspect that there's something fundamental about computation that we just don't understand. And then once somebody makes a breakthrough and solves one of those problems, a lot of them are going to get solved in short order. But again, it's purely speculation. OK, d. What is d here? d would be the size of the tape alphabet. OK, so this is the number of different tape contents we have. Good. All right.
2004	Another thing we mentioned kind of quickly in passing, but still an important fact, is that Savitch's theorem works down to the level of log space-- same exact proof. So that means that nondeterministic log space is contained in deterministic log squared space, because that's what Savitch's theorem does for you. It converts nondeterministic machines to deterministic machines at the cost of a squaring in the amount of space you need. And so I'm not going to go through this in detail. But the same picture that I copied off an earlier slide with a simple modification is that instead of-- that I'm right down-- the size of the configuration is going to be now log n, because that's how big the configurations are when you have a nondeterministic log space machine. And so simulating that-- so this would be what the tableau would look like for an NL machine. And then you can simulate that in the same way by trying all possible intermediates and then splitting it, doing the top half and then the bottom half. We're using
2005	the space, of course, recursively. The amount of space you're going to need is going to be enough to store, for one level of the recursion, one configuration. And that's order log space. And then the number of levels of recursion is going to be another factor of log n, because that's log to the running time, which is going to be exponential in log n, which is polynomial. So the total amount of space that you would need would be log squared space. Again, this is sort of saying the proof of Savitch's theorem, just over again. So if it's coming too fast for you, just review the proof of Savitch's theorem and observe that it works, even if the amount of space that the machine-- that the nondeterministic machine starts off with is log space. All right.
2006	of a review is our theorem that not only is all of L within P-- and that's kind of trivial, kind of immediate. You don't even have to change the machine. If you have a log space machine for some language, the very same machine is a polynomial time machine for that language, because it can only be running for a polynomial amount of time. But now, we have a nondeterministic machine for some language. We're going to have to change it to become a deterministic machine that runs in polynomial time. And so we're going to give a deterministic polynomial time simulation of a nondeterministic log space machine. And we kind of did this last time, but a little quickly. So now, if we have some nondeterministic log space machine, so an M, which decides the language A in log space, we're going to show how to simulate that machine with a deterministic polynomial time machine. And the key idea, which is going to come up in a later theorem, so good to understand it not only here, but
2007	to understand it for the next theorem that's coming, is the notion of a configuration graph. I was sort of thinking about calling it a computation graph. But now, on further reflection, I think configuration graph maybe is the more suggestive term. So let's stick with that. So a configuration graph for a machine on an input is just a set of all configurations that the machine has, all the possible different configurations the machine can have, with edges connecting configurations that correspond to legal moves of the machine. So here is some configuration. This is a snapshot of the machine at a moment in time. Here is some other configuration, another snapshot of the machine at a moment n time. And you're going to draw an edge between ci and cj if cj could follow in one step from ci. And you could tell by just looking at the configurations whether that could be possible. Obviously, the head has to be one place over in cj from where it was in ci. And it has to be updated according
2008	to the rules of the machine. So you can tell whether-- so you could fill out this graph. You could write down all the possible configurations. And you can put the edges down. Now, the point is that when we have a log space machine, we don't have too many possible configurations. There's only a polynomial number. So the size of this whole graph is polynomial. So our polynomial time simulation is going to write down that entire configuration graph of the log space machine on its input. There [INAUDIBLE] many configurations. There can be only polynomially many. So you can write down all those configurations as the nodes and then go look at each pair of nodes, whether this configuration could lead to that configuration. According to-- it's a nondeterministic machine. So a configuration could go to several different locations-- there could be several different ways to go. But those are just several different outgoing edges from a particular node in this graph representing the configuration, which might have several different legal successors in the nondeterministic computation. OK. Now,
2009	the important thing here is that M accepts its input, w, exactly when there is a path [INAUDIBLE] configuration graph that takes you from the start configuration to the accept configuration. And as I mentioned, let's assume, as we've been doing, that the machine-- I should have put it here, but I didn't. But the machine, when it is about to accept, it erases its work tape and moves both of its heads to the home position at the left end of the tape. So there's just one accepting configuration you have to worry about. It just makes life simpler. So there's going to be a start configuration, a single accept configuration in this configuration graph. And now there's going to be a path, indicated here, that connects the start configuration to the accept configuration if and only if M accepts w, because that path is the sequence of configurations that the machine would go through if you launched it on w. It would start at the start. And there might be several different ways to go. But if there
2010	is one of them that leads you to an accept, that's going to correspond to a branch of the computation that it's accepting. OK, so that tells us what the polynomial time algorithm is. On input w, you construct that configuration graph for M on w, G sub Mw. And you test whether there's a path from c start to c accept using any polynomial time depth-first search or breadth-first search algorithm for testing whether there's a connection path in a graph. And if there is such a path, you accept, because that means the machine M accepted. And if there was no path, you reject, because then M must have not accepted. And therefore, you have a polynomial time simulation of your nondeterministic log space machine M, OK? How are we doing? OK, so that tells us that NL is contained within P. And also, L is contained within NL, as before. So we have kind of this hierarchy of classes. Now, you can even talk about, not only is L different from NL, even is L different from
2011	P? Is it possible that anything that you can do in polynomial time, you can do [INAUDIBLE] space? Don't know. Open question. OK, getting a very good question here just now. Why is this construction taking log space? It doesn't. This construction takes polynomial time. This algorithm here is not a polynomial-- this is not a log space algorithm that I'm giving you. I'm giving you a polynomial time algorithm for simulating a nondeterministic log space machine. Now, later on-- I don't want to confuse the issue right now. For this particular slide, all I need to do is construct that graph in polynomial time. It's a polynomial size graph. I can't store that whole graph in a log space memory. OK, so question here-- we can see that listing out the nodes and edges would be polynomial time. But how do we actually provide structure to this graph representation? I don't even know what that means. So if you can clarify that for me, then maybe I can try to answer it. But a graph is just a list
2012	of nodes and a list of edges. After that, we know what the graph is. I mean, you may like a picture. But the machine doesn't need a picture. Our definition of-- we just represent these things as strings, in the end. So please clarify if you want me to-- I'll answer it the next at the next pause. I'm grateful for all the questions, because I'm sure, any question that any of you have, another 20 of you also have. So questions are good. Don't be bashful. And also ask the TAs if I become overloaded. OK, now we're going to shift gears into some new material. All right. We're going to talk about the notion that-- sort of thinking about, analogous to the P versus NP problem, where there were these NP-complete problems, now we have the L versus NL problem. There are going to be an NL-complete problems that kind of capture the essence of NL the way NP-complete problems capture the essence of NP, in a sense, in that all of the problems in NP are
2013	reducible to them. So they're kind of like the hardest NP problems. Here, we're going to have exactly analogous situations for NL, where we're going to show problems where all other NL problems are reducible to them. So if you can kind of solve one of them, like solve one of these NL-complete problems in log space deterministically, then you solve all of NL problems in log space deterministically. So it's a very similar-looking definition to what we had before. It's NL complete if it's in NL. And then all other languages in NL should be reducible. But now, we have a new notion here, with an L instead of a P. Now, before, when we talked about NP completeness, we had polynomial time reducibility. That's not going to work anymore, because if you remember, NL is a subset of P. So all NL languages are polynomial-- are languages in P. And if we're talking about-- if we use polynomial time reducibility, all languages in P are reducible to each other. We need to have a notion of reducibility which
2014	is kind of weaker than the class. And so polynomial time reducibility just would not work here, because everything would become NL complete, because everything is reducible to each other. So we need to have a weaker notion. We're going to use log space reducibility, which we have to define. So here, for that, we're going to have to talk about the notion of a function that you can compute in log space. And it's a little tricky here. Just like when we talked about language recognition in log space, where we had the work tape had to be smaller than the input tape, because the inputs can be large. The work area is small. Now the output also could be large relative to the work area. So we're going to have a three-tape model, where there's the input is going to be a read-only, the output is a write-only-- it's like a printer. It's something you can only write on, but you can't read back, because otherwise, you could cheat by using the output as a kind of storage.
2015	And then you have your storage area, which is your read-write work tape. OK, so this-- we'll call this-- the traditional name of this is a log space transducer. So it converts inputs to outputs, but uses only log space for its working memory. OK, so the input tape stores n bit-- n symbols. The work tape stores log n symbols, order log n symbols. And then we have the output tape. You may want to think about how big-- there's going to be a check-in coming to kind of ask you, how big could the output be? But we'll save that for the end if you--
2016	OK. So we think of a log space transducer as computing a function, which is just a mapping from the input to the output that the transducer provides for you. A transducer is a deterministic machine, by the way. So you take the transducer. You give it w. And you turn it on. And then it halts with f of w on its output tape. That's what it means to be computing the function f, OK? And we'll say that A is log space reducible to B, using the l subscript symbol on the less than or equal to sign, if it's mapping reducible to B, but by a reduction function that's computable in log space, just the same way we define polynomial time reducibility. But there, we insisted that the reduction function was computable in polynomial time. OK. Just quickly, I got a question again. Why log space here? Because polynomial time would be too powerful for doing reductions internal to P. Every language in P is reducible to every other language in P. And so everything in NL
2017	would be reducible to everything else in L with a polynomial time reducibility. And so that would not be an interesting notion. We have to use a weaker notion than that, a weaker kind of reduction, using a weaker model, so that you don't get-- otherwise, the reduction function would be able to answer whether-- would be able to solve the problem A itself if we had a polynomial time reduction, and we're mapping things from NL to other problems in NL. The reduction would solve the problem. And that's not what you want. The reduction should be constrained only to be able to do simple transformations on the problem, not to solve the problem. Anyway, you have to look at that. This is an issue that's come up before when we talked about, what's the right notion of reduction to use for PSPACE completeness? Same exact discussion.
2018	Now, there is an issue here, though, that we have to be careful of. When we have A being log space reducible to B, and B in L, then what you want-- if A is log space reducible to B and B in L, then you want A to be in L. That's the same pattern we've always had for reductions. If A is reducible to B, and B is easy, then A is easy. So here, the notion of easy is being an L. Now, if you remember the proof of that we had from before, which I'll just put out for you, is that to show a log space solver for A, you take an input, w. And now, if A is reducible to B, you compute the reduction. And then you run the decider for B. So if we're assuming A is reducible to B, and B is in L, so B has a log space decider, you take your w, which you want to know, is it in A? You map it over to a B
2019	problem using the reduction function. And then you solve it using the decider for B. And you give the same answer. Now, this actually doesn't work anymore, or it doesn't work in an obvious way, because, if you're following me-- I hope most of you are-- there is a problem here, which-- because we're trying to give a log space algorithm for A. And that algorithm is going to be computing this reduction function, mapping w to f of w. f of w might itself be very large, as this picture suggests here. You may not be able to store f of w in the log space memory for the machine that's deciding A. So this is an obstacle that we need to solve in order to prove this theorem, which we need, because that's the whole justification for doing these reducibilities-- should be a familiar-looking kind of line to what we've seen before. So we don't have space to store f of w. What do we do? And I'll also mention that this is going to be relevant to
2020	one of your homework problems.
2021	So what do we do? We don't have space to store the intermediate result that we need in order to solve the problem. We started with w. Now we'd need to test if f of w is in B. That can run in log space. But just simply getting your hands on f of w-- what do you do about that? So what we're going to do is the following, is the decider-- the decider for B, which needs f of w, because it's deciding if f of w is in B-- it doesn't need all of f of w sitting there in front of it all at once. If you think about how the Turing machine operates on its input, it only looks at one symbol at a time. It starts out reading the leftmost symbol of f of w, then maybe it moves its head right and moves to the second symbol of f of w, then the third symbol of f of w. Maybe it gets up to the 10th symbol of f of w. Maybe it
2022	moves his head back and goes to the ninth symbol and the eighth symbol. But the Turing machine's head, which is deciding B, only looks at one symbol of f of w at a time. So instead of writing down all of f of w, the idea is that we are going to compute the individual symbols of f of w that we need only at the moment we need them. So if the decider for B is reading the 10th symbol of f of w, we fire up the transducer on w. And as it's writing out its output, which we don't have space to store anymore, we throw away all of the output values until we get to the 10th one. And then we say, ah, the 10th one is whatever, is a c, whatever the value is. Now we feed that into the decider for B. We can now simulate that decider for one more step. Now the decider says, all right, now I need the 11th symbol of f of w. OK, now we can run
2023	that machine for one more place. But if it needs-- but we don't even have to do it. I think the better way to think about it is, every time that decider for B needs another symbol, we start the transducer over again and just keep-- throw away everything except for that one symbol output that we need. So every time we do another step of simulating B, we're going to have to rerun the transducer from the beginning, just to recompute that, or compute maybe for the first time, or recompute it if we need it subsequently. This is going to be slow, but we don't care, to recompute that symbol that the simulator-- that the decider for B requires, OK? So I'm saying that over here. Recompute the symbols of f of w as needed. OK, so let me-- let's take a couple of questions. And then we're going to move to a check-in. So somebody's asking, why did we have to introduce transducer for log space reducibility when we didn't do it for polynomial time reducibility? We
2024	could have for polynomial time reducibility. But we didn't need to, because we could just all do it on the same tape. The problem is, for log space, the tape is-- the work tape is too small to hold the input on the output. So we can't-- since we're only working-- we have a log n bound that we have to work within. We need to separate those functions from the work functions, the input function and the output function. So if we have more than the amount of resource we have, either time or space was at least n, then we could just lump them all together and have that one tape do multiple functions. And somebody's asked me here, yeah, this is mapping reducibility, this m. This is from the notion we saw before. OK. Does f of w lie on the input tape of B? Well, yes. So we are-- good question. So f of w-- you know, because what are we doing? We're trying to find a decider for A here, using the decider for B
2025	and the mapping from A to B, the reduction from A to B. So the decider for B expects to find its input on an input tape. That input is going to be f of w. But we have to get the effect of that without actually writing down that input tape, because we don't have enough room to write down the input tape for the decider-- for the B decider, because that could be very large. And we only have-- we have no place to put the f of w. So think about what's going on here. We're making a log space machine whose input is w, has to compute f of w as an intermediate value, to feed it into the B decider. That is not going to be possible to hold onto that whole f of w at one-- altogether, because it's too big. But that doesn't matter. We don't need it. We only needed one symbol at a time, which we can recompute. OK, so let's see. So somebody says, can we just ensure that the
2026	output tape is order n so we don't need to use more tape than the input? Order n is still going to be too big. Where are you going to put that output? Even if it's just order n-- first of all, the answer is no, we can't, because there are going to be reductions which are bigger than that. But the other question is, can we just ensure that the output is order n? You can't put the output on the input tape. The input tape is read-only. The output tape is write-only. So there's no place to-- even if the output is just as big as the input, it doesn't help you. If the output is only log n, OK, then we could do it. But that's not going to be interesting for us. You're going to need, for these large space reductions, big outputs, as we'll see in a minute. What's the running time for this log space reduction? It's all going to be polynomial. It's all going to be a log space algorithm. So it's all
2027	going to be polynomial. Is there any NP completeness reduction which can be done in log space? All of the NP-- all typical NP completeness reductions, those polynomial time reductions, they all can be done in log space, because they are-- reductions tend to be very simple transformations. And log space is going to be enough to do all of them. OK. I can't answer the second part of that. That's too complicated. And I think we should move on. So let's look at the first check-in here. So if we have a long space transducer that computes f, and if you feed it inputs of length n, how big can the outputs be, actually? So why don't you think about that and give me an answer? I'll give you a minute to answer this question. Oh, this is a tough one. Let me just say up front, there are-- I struggle with this lecture, because some-- especially the stuff in the second half, it's kind of hard. I wouldn't say it's technical. But conceptually, I think some of the
2028	material is a little harder, maybe in part because people are not used to thinking about memory complexity or space complexity, even though I don't see why-- I mean, I think it's an important resource to be considering. But I think it's less common. And I think there's some discomfort with that. OK, so we're just about done here. Five more seconds, please. All right, about to wrap. Wrap the check-in. 1, 2, 3. All right. So yes, the correct answer is c. As I mentioned, we're going to want to have outputs that are larger than log n. And there's no reason why they wouldn't be able to be larger than log n, according to the definition that I gave you. There's no bound on the output. We're only measuring the running space of this algorithm in terms of its work tape. The input and output tapes don't count. So they can be more than log n. They can be more than n. Polynomial is the right answer. Why? Because a log space transducer, if you just ignore the
2029	output, is just an ordinary log space machine. And it can only run for a polynomial number of steps without it end up going into a loop. The same argument that we gave for that before applies here as well. So if it's going to exceed a polynomial number of steps, it's never going to hold. And so that's going to be-- not allow it-- it's got to halt with the output on the output tape. And so it'll be disqualified as a log space transducer if it doesn't halt. So it can't be anything longer than polynomial. It's a good thing to think about, to understand. OK, so let's continue. So we're going to show that the PATH problem is NL complete. Now, we defined NL completeness. And we've seen the PATH problem before. And we're now going to show that PATH occupies a very special position for NL, namely that it's an NL-complete problem. So if you can solve the PATH problem deterministically in log space, you have gotten a big result. No one knows how to do
2030	that. And it would collapse all of NL down to log space if you could do PATH in log space deterministically. OK, so let's see why that is. So first of all, the two components of being complete are being in the language and the reduction part. So in the language, we've shown already. Now, we want to show that for any other language in NL, it's going to be log space reducible to PATH. In a certain sense, this may not feel so surprising, thinking back to our proof that NL is a subset of P, because we managed to convert any NL machine, the running of any NL machine, to a PATH problem that the polynomial time machine then solved. And so it's really the same idea that says that PATH really captures any NL machine. The computation of any NL machine really can be seen as a PATH problem, where
2031	So let's just see how-- let me just try to go through that if that wasn't super clear, which I'm not sure it was. So suppose we have a machine decided by-- a language decided by a nondeterministic-- an NL machine, a nondeterministic machine in log space. Again, I should have put this before. But we're going to modify M to erase its work tape and move its head to the left end on accepting. So it has a unique accepting configuration. Now I'm going to give it the log space reduction that maps our language A, which is in NL, to the PATH language. So thinking about what that means, I'm going to take an input, w, which may or may not be in A, and produce for you a graph with a start and target node, start and target notes, where w is going to be in the language if and only if G has a path from s to t. And what do you think that graph is going to be? That's going to be the configuration
2032	graph for the machine that decides A, OK? So that is how it's going to look. So maybe here's a picture. Right. So f of w, where w, again, is your problem about membership in A, is going to become a problem about membership in PATH. And it's just going to be the configuration graph for M on w. Now, what's left is to show that we can do this conversion with a log space transducer. So it's a log space computable reduction. So let's just try to go through that quickly-- conceptually, not super hard. So here's our transducer. Let's just think about what it needs to do. It needs to take an input, w, and convert that f of w to this thing here-- computation graph of M on w-- the configuration graph M on w, the start and accept configuration. So that's going to look like this down here. That's what we want to eventually appear on the output tape. So the way we're going to achieve that-- we only have a small log space, order log
2033	space work tape. And the way we're going to be able to produce this output is-- the configuration graph is just a series of edges, which are-- say, you can go from this configuration to that configuration in one step. So what we're going to do is, on our work tape, we're going to go through all possible pairs of configurations, again, just in some like odometer order, just by looking at all possible strings, really, of length order log n that are big enough to represent two configurations. Every once in a while, it's going to be actually a pair of configurations. At that point, we look at those two configurations, look at M, and see, can this configuration go to that configuration? If yes, you print it out on the output tape. If no, you just move on to the next pair of configurations. And then, at the end, you write down on the start and accept configurations. So I've indicated that here. Here is the transducer. It says, on input w, for all pairs of configurations, that--
2034	now, this is getting written down on the work tape-- you output those pairs which are legal moves for M. And then finally, you output the start and the accept. That's it. So let's just see. Let me take any questions here. Why do we need special accept state for M? Well, we want to have-- I think you mean accepting configuration. I just want to have a-- I don't want to have a multiplicity of different possible accepting configurations, because then it's not really a PATH problem. Then it becomes a question of, can I get from the start to one of those nodes representing accepting configurations? That's a little messy. I could fix it. But the simplest fix is just to make there be a single accepting configuration. Well, why do I output start and accept at the end of the output tape? That's the way I write down my PATH problem. It's a graph, followed by a start node and a target node. So I have to follow that form. I'm not sure what you're asking. You
2035	want me to put that first? I'm not sure what the-- or why at all? Because it has to be a-- here it is. Here's the output I'm looking for. OK. Do the three-- do the read-write work tape here store pointers to configuration or some sort of counter? No, they store the actual configuration. The configuration for M is-- just think about what it is. It's a log space size object. It's a tape for M. It's a location of its heads and its state. So you could kind of write down that stuff right over here, on the left side of this-- this left slot. And on the right slot, you're going to write another configuration for M on w. And you're going to just put the edges in accordingly. OK, so somebody-- did that help? Somebody, again, is asking, why is the configuration only log space? It's just a tape. It's a log space tape. That's the main thing in the configuration of the tape. On the read-write work tape, do we only write two configurations at
2036	once? Yeah. We're just writing down a candidate edge that we're going to output onto the output tape. So that's why we have two configurations. I want to know, can I get from this configuration to that configuration? If yes, I print it out, print out that pair. That's an edge in my configuration graph, which is what I'm supposed to be outputting here. Can there be multiple-- OK, why don't we move on? Again, direct questions to our TAs, who would be more than happy to help you. And we will-- let me just quickly give-- we're running a little tight here time-wise. But let's just see. Here's an example of showing some other problem is NL complete. You have a homework problem on that. So I thought I wanted to give you an example. Maybe we can just defer this to the recitation. So maybe we'll try to do this a little quickly to save us on time. But the 2SAT problem, which is just like the 3SAT problem, except with two literals per clause-- curiously, the complement
2037	of that problem, so the unsatisfiable formulas, that form an NL-complete language. And so first of all, you have to show it's in NL. We're not going to do that. It's a nice exercise. It's not totally trivial to do. But you might want to try that. We're going to show that PATH is reducible to the complement of 2SAT. We've got to give a reduction that converts graphs to formulas, where there is a PATH, now, when the formula is unsatisfied. And what's going to happen is the PATH is going to correspond to a sequence of implications in the formula, which yields a contradiction and forces it to be unsatisfied. Again, this is going to come a little fast. And then maybe we can discuss it over the break, which is next. So every node in G is going to have associated variable in the formula. So there's a variable for every one of the nodes. For every edge, there's going to be a clause of implication connecting those two associated nodes. So if there's an edge from
2038	u to v, then there's going to be an implication in the formula that says, if xu is true, then xv is true. And note that that's equivalent to the more conventional way [INAUDIBLE] xu complement or xv. These are logically equivalent. So I'm not cheating you here in terms of being a 2SAT problem. They really just look like this. And lastly, I'm going to put two additional clauses. It's [INAUDIBLE] x for the start variable-- from the start node, s-- here, s. I want to force that one to be true. So it's x-- since I want to have exactly two per clause, that's xs or xs. So that forces x-- that variable true. And lastly, if t is true, that's going to force the-- if xt is true, that's going to force xs to be false. So now, if there's actually a path in the graph that goes from s to t, there's going to be a sequence of implications, starting now with s being true, forcing other things being true, including forcing t to be true,
2039	which then forces s to be false. And that's our contradiction, which shows that the formula cannot be satisfied. So now, you have to prove that this works. As I said, for the forward direction, if there is a path, you follow the implications to get a contradiction. For the reverse-- let me not spend time here. I'll leave this to you to think about offline. But if there is no path, there is a way of assigning the variables to true and false to make a satisfying assignment to the formula. So that gives the other direction, OK? And you can show it's computable in log space. That's very simple, because a very simple transformation there, OK?
2040	And I'm happy to take questions at this point about this. Does the configuration, going back, include the input? No. The configuration does not-- as I said, the configuration for M on w is the state, the head positions, and the work tape contents, not the input tape, because then you would be-- it's not there for a reason. The input is huge. But you don't need the input there, because the input is going to be constant for everybody. Everybody can look at that input, which is a fixed, sort of external thing. Somebody's asking me, are there NP-complete problems in-- there are definitely NP-complete [INAUDIBLE].. I don't know-- there are some problems in number theory where it's-- like factoring, where we don't know the status, somewhere between P and NP, formulated as a language, of course. But there are problems in solving certain kinds of equations, low-degree equations, that I don't remember now if [INAUDIBLE] actually known to be NP complete. Now, you asked about NL complete [INAUDIBLE].. I don't know if there are NL-complete number theory problems.
2041	Oh, good question. Somebody's asking me, does NL also have an alternative definition using certificates or witnesses? Yeah. Yes, sort of. For NL, you can make a certificate, which is, again, polynomial size certificate. But it has to be-- you're only allowed to read it with a one-way head. So it's like a one-way certificate. So it has to be-- you can only process it in a certain way. That's a nice exercise, actually, itself. But anyway, let us-- we are now done. And we're going to move back. We're going to continue. So everybody return. This is what's next on the agenda, proving that NL equals coNL. This is a hard proof. I'm going to try to break it down as much as I can. And let's hope you get-- I hope you get it. I'll try to be as helpful as I can. OK. But if you're finding it tough, you won't be alone. So first of all, we're going to show-- the way we're going to solve this is by showing that the complement of PATH is
2042	solvable in NL, because the complement of PATH is-- just as PATH is complete for NL, the complement is complete for coNL. And so by doing that problem in NL, we're going to reduce all of-- all of coNL will be reducible to problems in NL. And so therefore, we'll be in NL. coNL will be then inside NL. And then NL is going to be equal to coNL. If that sequence of logical connections, is not clear. Don't worry. The point is that we want [INAUDIBLE] go back and figure out why that's enough later. But what this means is we want to give a nondeterministic machine, which will accept when there is no path from s to t. OK? And please don't say, why don't we just take the machine for PATH and flip the answer? You can't do that with a nondeterministic machine. So you better-- if you're thinking that that's allowed, go back and review nondeterminism. So you want to make a nondeterministic machine, which is going to accept when there's no path. So some branch
2043	is going to make a sequence of guesses. And it has to be sure that there's no path. And then it's going to be-- and then it can accept when there's no path. Now, if you can find a way of like making a separator, something that cuts the graph in half and separates s from t, then you would be good. The only problem is there's no obvious way of doing that, because those kind of separators, even if they were [INAUDIBLE] probably too big to write down in log space. So I'm going to give you a completely different way of doing it. And I'm going to make-- this is a little different presentation than what's in the book. I think hopefully, this is a little longer, and therefore, a little clearer. We'll see. So first of all, I'm going to define a notion of a nondeterministic machine computing a function. And that's a simple idea. What you want is, on the different branches-- so you have some function, f, which has, for every w, there's an output,
2044	f of w. And the nondeterministic machine can operate that on all of its branches, it's allowed to either give f of w or say reject, meaning punt, or say, I don't know. So every branch has to give the right answer. So all the branches that give an answer have to agree, because there's only one right answer. All the branches that give an answer have to give the right answer, or they can say, I don't know. The only thing is you have to also say that at least one of the branches actually gives an answer. So somebody cannot reject. Somebody cannot say, I don't know. So at least one of the branches gives an answer and-- gives the answer. And all the other branches can either give the answer, or they can say-- they can just reject. But there's no notion of accepting. There's just a notion of this nondeterministic machine, on some branches, giving the output value, and other branches just punting and saying reject. Maybe reject is the wrong word. I could just say
2045	punt. All right. So we're going to be talking about functions that you can compute with nondeterministic machines, with NL machines in particular. All right? So we're going to look at this path function now. Now, this is not exactly the same as the PATH language. This is a function here, written with lowercase. So given a graph, s and t, I'm going to say yes if there is a path and no if there's no path. And this is a function now, which is going to output yes or no, not a language. This is a function. It's very closely related. I understand. So if you can solve the function, you can do the language. But what we're going to give is a NL machine, a nondeterministic machine, which is going to compute this function. And therefore, you can use that to do the PATH language. Two important things for us is, if G is some graph, well, here's the starting node, s. R is all of the nodes that you can reach from s. This is some collection
2046	of nodes. And c, which stands for count, is the number of reachable nodes. So I've written that down here more-- if you like it more formally. R is the number-- is the collection of nodes for which there's a path from s to the node. And c is the size of R. So you have to understand these two, because we're going to be playing with this for the next three slides. OK. Now, first of all, this is kind of a little bit of an exercise theorem. But it's still going to be a useful fact that we're going to end up needing later. But it's also a little bit of just to test your understanding. Suppose there's some NL machine which computes this path function. So on the different branches of the nondeterminism, given a graph, G, s, and t, there are going to be some branches which may output yes, or some branches that may output no. And other branches might say, I don't know. But the machine always has to give the right answer if
2047	it's going to give any answer. So all branches either have to say yes, or all branches-- all branches have to say yes or punt, or all branches have to say no or punt, because one of those answers is going to be the right answer. So suppose I have a way of computing path by an NL machine. Then can I also compute the-- can I make some other NL machine which computes the count, the number of nodes reachable? So if I can test if a node is reachable, can I figure out how many nodes are reachable? This is supposed to be easy. This is kind of a little bit of a practice. So if I can figure out if nodes are reachable, yes or no, then I can say, figure out how many nodes are reachable. You just go through them one by one, testing if they're reachable, and count the ones that are. That's all I have in mind. So start with a counter that's set to 0 initially. And go through each of the
2048	nodes of G one by one. And I use my NL machine that computes path. That's what I mean by this part. So I test it. If the NL machine says yes, there is a path, then I increase the counter. And if it says there's no path, then I just continue without increasing the counter. Now, when I'm running my NL machine to compute this function, that NL machine might punt, might reject sometimes on some branches. That's OK. I'm also allowed. I'm also an NL machine. I'm computing a value. And I also might punt on some branches. So at the end, I'm going to output that count, OK? So what I'm going to prove next is the converse of this. And that's-- and that's the magical hard part, that if I can compute the count, then I can do the test of whether individual nodes are connected, have a path from s. OK, so let's just see. Somebody is asking if nondeterministic machines-- so like M is not allowed to loop? No. If a machine, if any
2049	one of these machines, like an NL machine, loops, it's going to be going forever. That's not allowed. So no looping. I'm not sure why that's relevant, but no looping. But what I'm more worried is that you understand this theorem here. I think we have a check-in coming. Let's see. OK. This might be helpful. So consider the statement that PATH complement is NL. That's what we're trying to prove, and also that some NL machine can compute the path function. These are going to be related facts. Which one can we prove from the other easily? I mean, they're both going to be true. So in some sense, it's trivial. But I want to know, which one can we prove kind of immediately without doing much work? That I can solve this PATH problem in NL, the complement of the PATH problem in NL, or that I can compute the path function in NL? So what do you think? OK, almost done here? Yeah. Ending. You guys didn't do well. That's OK. Actually, the right answer is c.
2050	Most of you got that if I can solve the path function, so the yes-no value, I can use that now to solve both PATH and PATH complement. That seems more clear cut. But suppose I can solve the PATH complement problem in NL. And I also know I can solve the PATH problem in NL. That, we've already shown. So knowing both of those, if I'm given a G, s, and t, what I can do is nondeterministically pick which of those two directions. You know, I pick-- I'm going to guess, well, it's in PATH, or it's in the complement of PATH. So there are two different nondeterministic ways to go. One of those is going to always end up rejecting. And so that's going to end up punting. The other direction is going to sometimes end up accepting and sometimes punting. And based upon whether which side ends up-- one or the other is going to have some accept-- is going to be accepting. And so the one that's accepting is going to tell me whether to
2051	answer yes or no. So actually, both directions, both implications follow pretty easily. OK. Anyway, let's try to show-- this is the hard part. And we have five minutes. Let's see how far we can get. So this theorem works by magic. So it kind of blew everybody's mind when it first came out. So let's just see. It's really not that hard. But it's sort of-- it's kind of twisted. So suppose some machine can compute c, the count, the number reachable from s. I'm going to use that to solve path, the path function, to test, yes, I can output yes if there is a path or no, there is no path, for each node t. So if I know how many nodes are reachable, then I can solve now for individual nodes, which is strange that you can do that. Now, I'm not telling you how to compute c. That's for later, which I probably won't get to. But just pretend we can somehow figure out what the count is of the number of reachable nodes, OK?
2052	So here is my nondeterministic algorithm for computing path. First, I'm going to compute c, or let's say c is given. And now, maybe the best thing to do is to try to give you the idea up front. What we're going to do, since we're a little short on time, what we're going to do is, suppose I tell you, there are, in this graph, 100 nodes reachable from s. So c is 100. There's 100 reachable nodes. Now I want to know-- I say, well, I don't really-- that's all very nice. But I'd like to know this particular node, t. Is that reachable from s? Now, I'm a nondeterministic machine. Now, if t was reachable, then I'd be fine, because nondeterministically, I don't even care about the 100. I take, nondeterministically, on some branch, starting from s, I'm going to hit t. And that branch is going to say yes. The other branches, maybe they'll punt. But some branch is going to get the right answer. The problem is, suppose t is not reachable. Then you want
2053	some branch to say no. And how could that branch ever say no, unless it's sure that t is not reachable? And how can one branch be sure? The idea is this. Suppose I know that there are 100 reachable nodes. What I'm going to do nondeterministically is I'm going to guess those 100 nodes, one by one. You can't store them all, because it could be-- 100 could be a big number. I'm going to guess them one by one. I'm going to guess them. And every time I guess a node, I'm going to prove it's reachable by guessing the path that shows it's reachable. So I'm going to guess 100 nodes, prove that they're reachable, and then see, was t of those reachable nodes? If it was, well, then I would have found it, and I would know to say yes. But if t was not one of the 100 reachable nodes, and I know there's only 100-- so if t is not one of those nodes-- in other words, if I found them all, and t
2054	wasn't one of them, then I know it's not reachable. And that's how, using the count, I can be sure that certain nodes are not reachable, because I just find all the ones that are, prove that they are, check that the count agrees with what I was given, and then say no, t is not reachable, if it's not one of those nodes that I've found to be reachable, which adds up to my given count. That's the whole idea. Of course, how do you get the count? Oddly enough, it's kind of the same idea repeated over and over again. But I guess we'll have to do that next time. So let's just write this down. And we'll kind of use it as the beginning of Thursday's lecture. So we're going to go through each node u, one by one. Now we're going to guess, for each node, whether there's a path to it or not. So I'm going to call it either p or n. Again, this is now-- think about my 100 nodes. I'm going to
2055	be guessing all 100 nodes. I'm going to nondeterministically pick a path from that node that I guess is reachable. So if I guess a node, there is a path. I'm going to confirm there's a path by nondeterministically picking it. If I don't find that path, I just reject punt on that branch. If that path that I found actually led me to t, so u, that node that I'm working on, is currently t, then I know to accept. But otherwise, I'm just going to count the number of nodes that I find are reachable. If I've guessed that u is not reachable, I'm just going to skip it. At the end, I see whether the number of nodes that I have determined are reachable agrees with my original count, c. So does k equal c or not? If it doesn't equal, they're not equal, then I didn't find all the reachable nodes. I didn't guess right. And so I punt. I say, well, bad branch of the nondeterminism. I just give up. But some branch of the
2056	nondeterminism is going to guess all of the correct nodes which are reachable. And then, if t hadn't been found already to be one of them, at this point, I know t is not reachable. And so I can output no. OK? So that's the whole thing. What is m? m is the-- yeah, good question. m is the number of nodes of the graph. I should have said that. So you don't want to go-- you don't want to get into a loop. So you better cut off your picking of a path to some cutoff value. So you're going to cut it off at m, which is the number of nodes, which is going to be long enough. Actually, we're going to play with that in a bit later, but-- OK, let's just see. How do I know I did not visit the same node twice when counting? Because I'm just going to go through all of the nodes in some order. Pick any order. The nodes appear in some order in the representation of the graph on
2057	the input. So any old order-- I'm just going to go through the nodes in order. Therefore, I'm never going to see the same node twice. What does step 4 mean? So step 4 is-- step 4 means, for each node, I'm guessing that that node either has a path to it from s or does not have a path to it from s. So kind of thinking about it, the original-- we're out of time. So why don't I-- I'm happy to discuss this in the office hours. I'm just going to skip over the rest of the slides here and review. We have a missing check-in. Let's just-- I want to make sure everybody's got all their check-ins here. So why don't we just-- if we know NL is equal to coNL, we also-- we showed 2SAT complement is NL complete. It also then follows that 2SAT itself is NL complete, because NL equals coNL. So I'm going to give you the answer to this just, because I want you all to finish this poll. Still, some of
2058	you are getting it wrong. OK. So please answer it quick. And then we're going to end. Are we all done? Get your participation points here. Three seconds. OK, ending. OK, doesn't matter. So here, we ran over. Sorry about that. Quick review. This is what we didn't quite finish. This is part 5. But we'll finish that next time. OK, when showing PATH is NL complete, we also need to list the nodes for constructing the graph. The slides only mention-- yeah, I kind of skipped that. But yeah, you can just write down all the nodes. Again, but that's also going to just take log space, as you observed. Yeah, technically, when you're writing down a graph, you write down a list of the nodes, and you write down a list of the edges. I kind of skipped writing down the nodes. But yeah, it's the same-- doesn't matter. So I'm going to say goodbye to you all. Thank you.
2059	[SQUEAKING] [RUSTLING] [CLICKING] MICHAEL SIPSER: Welcome, everyone. Welcome back to theory of computation. And just to recap where we are, we have been looking at time complexity and space complexity. And we just finished proving what are called the hierarchy theorems, which, in a nutshell, basically say that, if you allow the computational model to have a little bit more resource, a little bit more time, a little bit more space, then you can do more things with certain conditions. So we proved that last time. It was a proof, basically, by a diagonalization. I don't know if you recognized the diagonalization there, but when you're encoding a machine by an input and then basically running all possible different machines, that's essentially a diagonalization. So today, we're going to build on that work to give an example of what we call a natural intractable problem. We'll say a bit more about what that means. And then, we're going to talk about something which is a different topic, but nevertheless related, having to do with oracles and methods which may or
2060	may not work to solve the P versus NP problem, which, of course, is
2061	OK. So the time and space hierarchy theorems-- because we're going to be using those today-- they say that if you give a little bit more space here-- so for space constructible functions, functions that you can actually compute within the amount of space that they specify, you can show that the things that you can do in that much space is probably larger than what you can do in less space. And you can prove a similar slightly weaker fact about the time complexity classes. So what that means is that these classes form a hierarchy. So as you add more time, or let's say, in this case, space, from n squared, to n cubed, to n to the 4th, you get larger and larger classes, which I'm kind illustrating here by putting a dot there, which shows that there's something that we know that's new in those classes as you go up these different bounds. And this is going to be true for space complexity and it's also going to be true for time complexity. And one of
2062	the corollaries that we pointed out last time is that, PSPACE is a-- properly includes non-deterministic log space, NL. So NL is a proper subset of PSPACE. So there's stuff in PSPACE that is not in NL. And remember this notation here, this means proper subset. One of the things that-- a follow-on corollary that we didn't mention last time, but that's something that you should know, is that the TQBF problem, our PSPACE based complete problem, is an example of a problem that's in PSPACE, obviously, but we know it's also not in NL. And in order to get that conclusion, you have to look, again, at the proof that TQBF is PSPACE complete, and observe that the reductions that we gave in that proof can be carried out not only in polynomial time, but they can be carried out in log space. And therefore, if TQBF turned out to go down to NL, then because everything in PSPACE is log space reducible to TQBF, that would bring all of PSPACE down to NL. But that we just proved
2063	is not the case. So therefore, TQBF could not be in NL. OK, and we're going to be using that kind of reasoning again in this lecture. So just a quick check-in. These are a few, more or less easy, maybe more or less tricky, follow-ons that you can conclude from the time and space hierarchy theorems plus some of the other things we've proven along the way. And so just as a check of your understanding, maybe these a little bit on the tricky side, so you have to read them carefully. Which of these are known to be true based on the material that we've presented? And this is also just material that's the facts that we know to be true in complexity theory. So let me launch that poll. And just check off the ones that we can prove. Hmm. OK. I'm going to close it down. So please answer quickly if you're going to. OK, 1, 2, 3, end. OK. Well, the two leading candidates are correct. And the two that are the laggards here are,
2064	in fact, the ones that are not true. So A and D are not true, based on what we know. And B and C are true. So let's understand, first of all, A, we know it's false because 2 to the n plus 1 is just 2 times 2 to the n. And so these two bounds differ only by a constant factor. And so in fact, they're the same complexity class. And so you don't get proper containment for A. So that one we absolutely know is false. D, well, if we could prove that, then we would have solved the famous problem, because we don't know whether even P equals PSPACE. So if P equals PSPACE, then certainly PSPACE would equal NP, which is in between the two. And so we don't know how to prove PSPACE is different from NP, that's based on the current state of knowledge of the field. So this would not be something that we know to be true based on what things that we've said. Now, B follows directly from the time
2065	hierarchy theorem, because 2 to the 2n is the square of 2 to the n. And that is, asymptotically, a significantly larger bound. And so you can prove that time 2 the n is properly contains time 2 the n. C is a little trickier because you need to remember Savitch's theorem. Savitch's theorem applies to space. But you also need to remember that what you can do in time, in non-deterministic time n squared, you can also do in non-deterministic space n squared, which, then, in turn, you can do in deterministic space n to the 4th, which is properly contained within space n to the 5th. So you can prove that PSPACE properly contains non-deterministic time n squared. OK, just a bunch of containments there. A and C are perhaps, in a sense, it may be the most tricky of this group.
2066	So let's move on. So we're going to introduce, today, two new classes. And actually, I want to go back to here. What are we going to be trying to accomplish in today's lecture? So we're going to be looking at provable intractability. So a problem being intractable for us means it's outside of P. So we can't solve it in polynomial time. For our perspective, we're going to call that an intractable problem. Now, this problem over here, that's sitting in time 2 the n, but not in smaller classes, so this is an intractable problem. That's outside of P. But this example of a language, if you remember how the time hierarchy theorem or the space hierarchy theorem was proved, basically, this language itself is not an interesting language for other than the purpose that it serves, to be in that class and not in a lower class. But it's not a language that anyone would care about. And it's not even a language that is easy to describe. It's just the language that some Turing machine decides,
2067	where that Turing machine is especially designed to have the property that its language is at a particular complexity level. But otherwise, there's no nice description of that language. It's not like a to the n, b to the n, or some equivalence of 2 dfa's or something like that. So I would say that that language is, in a sense, it serves its purpose, but it's not a natural language that you really care about. So one one of the goals of today's lecture is to give an example of a natural language, a naturally-occurring language, in a sense, that's easy to describe, where you can prove that that language is intractable, is actually outside of P.
2068	So along the way, we're going to introduce these exponential complexity classes, exponential time and exponential space, which are exponentially bigger than polynomial time and polynomial space classes. So it's 2 to the n to the k in both cases. 2 to a polynomial. And the first five of these classes, L through PSPACE we've already seen, and exponential time and exponential space extend the containments that we've already seen. So you have to double check that you understand why PSPACE is a subset of exponential time. But that's because that, as we showed, going from space to time, you can do that with an exponential increase. That's the cost of the simulation. And going from time to space, you don't need any increase at all. Anything that you can do in a certain amount of time, you can do in that much space. So anything you can do in a certain amount of space, you can also do in exponentially more amount of time. OK, so those were simple theorems that we proved right at the very beginning. Now,
2069	the hierarchy theorems allow us to conclude some separations among these classes. So we already looked at this one, NL versus PSPACE. And we saw that because NL is, by Savitch's theorem, in deterministic log squared space, which is properly contained in polynomial space, you get a separation between those two classes, provably. And for similar reasons, polynomial space to exponential space, you're going to get a separation from the space hierarchy theorem. And polynomial time to exponential time, you get a provable separation by virtue of the hierarchy theorem. Now we're going to define complete problems for these two classes, exponential time and exponential space. So we have exponential time complete. It's going to be analogous to what we showed before, which is that it's a member of exponential time. And every problem in exponential time is reducible to it, let's say, in polynomial time, though it's not going to really turn out to be matter. It could be in log space. Some simple method of doing the reduction is going to be good enough. Let's say polynomial time
2070	is the typical definition. And the same thing for exponential space complete. We'll say it's exponential space complete, if it's an exponential space. And anything else in exponential space is polynomial time reducible to it. OK. But the important thing is that if something is exponential time complete, you know it's outside of P, for the same reasons we've now seen several times. Namely, that if an exponential time complete problem ended up being in P, then because everything else in exponential time is reducible to the complete problem, they would also be in P. And so exponential time and P would be equal. But we just said they're not equal because of the hierarchy theorem. So the logic is the hierarchy theorem separates the class, and then the complete problem inherits the difficulty of the larger class. So the complete problem cannot be any lower than the other problems in the class, because they're all reducible to it. So the same thing is going to be true for an exponential space complete problem. Can't be even in PSPACE because
2071	exponential space and PSPACE are different. And if it's not in PSPACE, it's not going to be in P. And so in both cases, if you have a problem that's complete for exponential space or exponential time, we know that those problems are intractable. And our strategy, then, for giving a natural intractable problem is to show it's complete for one of these classes. And it's actually going to turn out to be an exponential space complete problem that we're going to give as our example. OK, so that is the plan. I think it's a good time to-- let's just take a few questions here to make sure we're all on the same page as what we're doing. So let me just read. I got a couple of questions already in here. So this is a little bit of a side comment that somebody-- that's an interesting question. Basically, is it possible that we may not be able to prove, solve the P versus NP problem, that it's not a problem that one can answer from the basic axioms
2072	of mathematics, if I'm interpreting the question correctly. There are certain problems in mathematics-- and I think I, perhaps, I mentioned earlier in the term, the problem of whether there is a set whose size is in between the integers and the real numbers. We know the real numbers are larger in size than the integers. That was our first example of a diagonalization. And is there a problem of size strictly in between the two? Bigger than the integers, smaller than the real numbers. So that's a problem that was posed a long time ago. It was one of Hilbert's problems. And was eventually shown to be unanswerable using the basic axioms of mathematics. So the question is, maybe P versus NP is in the same category. Could be. That could be true of any unsolved problems in mathematics. But at least our experience has shown that the kinds of problems that, at least, have been shown to be unsolvable from mathematical axioms tend to involve infinities and very large things, things that are very far from our intuitions.
2073	And something as down to earth as P versus NP, at least, it would be very surprising to me if that turned out to be unanswerable using our mathematical axioms. But, who knows? Oh, this is another good question. Do the time and space hierarchy theorems have non-deterministic variants? Yes, they do. They're much harder to prove, however, and we're not going to cover that. But you can also prove that non-deterministic time, n cubed properly includes non-deterministic time n squared. You're not going to be responsible for that. Don't worry. If you try to actually prove that, you'll see the diagonalization doesn't directly work. And so you have to do something fancier. People are asking about which reduction method to use. Again, the kinds of reductions that we encounter are always very simple. So we're just going to be working with very weak notions of reductions. Not interesting yet, generally, to consider powerful kinds of reductions like polynomial exponential time reductions or things like that. So it's just not something that people really think about much. I mean, I
2074	can talk about it at length offline. But let's just assume that our reduction strength is something very low. Log space is going to be good enough to do all of the reductions in this class.
2075	OK, so let's move on, then. So here is the problem that we're going to spend the next 20 minutes or so proving to be exponential space complete. I have got to do a little introduction first. So this is not the problem, but this is related to the problem. So the problem of testing if two regular expressions are equivalent. Write down to regular expressions, do they generate the same language? So that problem actually turns out to be in PSPACE. So it's not going to be exponential space complete. It's actually in PSPACE. I don't think we're going to have-- I thought about presenting it in the lecture. It's not that hard to show. But it just took too much time and doesn't really introduce new methods. It's a good exercise, actually, using Savitch's theorem. But maybe we'll do it in recitation, or if the lecture miraculously ends earlier, I'll do it at the end. But I don't think we'll have time. But that's a setup for the intractable problem that we're going to talk about, which is
2076	very related. Now, OK, before we get to that, so if I have a regular expression, I'm going to enhance our regular expression in one simple way, by allowing exponents or exponentiation. And that means if I have a regular expression R, I can write R to the k to mean R concatenated with itself k times. We've been sort of informally using that all the way along anyway, like when we talk about 0 to the k, 1 to the k. So if we're going to formally allow that when we write down regular expressions, in some cases, that might allow the regular expression to be much smaller, especially if we're writing down k in binary. Because I can write R to the million with just a few symbols if I have exponentiation. But if I don't have exponentiation, then I have to write R concatenated with R out a million times, and I get a much, much longer, an exponentially longer expression if I don't have that exponent as a way of describing regular expressions. And that's going
2077	to make a big difference. So now, the equivalence problem for regular expressions with exponentiation-- that's what that little up arrow means, what it signifies-- now I'm giving you two regular expressions. But they're allowed to have the exponentiation operation in addition to the standard regular operations. So now, testing whether two of these regular expressions that have exponentiation, that problem turns out to be exponential space complete. So here's the equivalence problem for regular expressions with exponentiation. That's an exponential space complete problem. And as we pointed out, that means this problem is provably intractable. So there's just no way, in general, to solve that problem in polynomial time. That's proven, that's known. So we're going to go through the reduction. I think it's going to be our last reduction of the term, of proving problems complete for some class. But each one of those has their own kind of thing that makes it special. So first of all, we have to show that it's in exponential space. That's really going to rely on this other fact that we
2078	didn't prove. So I'm going to go over that very quickly. But the interesting part is doing the reduction. So if I have something in exponential space that I can show that I can reduce it to the equivalence problem for regular expressions with exponentiation. OK, so quickly arguing part one that we're in exponential space, basically, what you do is you take your two regular expressions that you want to test to see if they're equivalent, but now they have exponentiation. And as a first step, you get rid of the exponentiation. You just expand things out by repeating the parts that have the exponents. And of course, as I said, that's going to make the expression themselves exponentially bigger. But now, you run the PSPACE algorithm on those two exponentially larger expressions. So the input that the PSPACE algorithm is now exponential in the original input size, but it's PSPACE in that enlarged input. So that's going to give you an exponential space algorithm in the original input size, because you expanded it to become exponentially bigger, and
2079	then you run the PSPACE algorithm on that expanded problem. So that gives you an exponential space algorithm for this problem. But now, what we're going to do-- the interesting part is the reduction. So given some language and exponential space, say, decided by some Turing machine in that amount of space, 2 to the n to the k, we're going to give a reduction that maps a to this equivalence problem. Got it? That is the plan. So let's make sure we're all together on the plan before we go ahead and carry out that plan. We just sort of set things up here, in a sense, for what we're going to be doing. So feel free to ask a question on just the plan. It's going to get technical. Because, as doing these reductions always is, there's a simulation involved, and you have to kind of describe that simulation in its own way. So now, we're going to be simulating, in a certain sense, M on w, the decider for this exponential space, problem A, we're going to
2080	take M on w and we're going to somehow have to express the fact that M accepts w using this equivalence problem for regular expressions with exponentiation. So no questions? Why don't we move on? I have three slides on this, but they're kind of dense, I'm sorry to say. So here is the plan as usual. We're going to map A with a polynomial time reduction to the equivalence problem for regular expressions with exponentiation. So that means we're going to have to take an input, which may or may not be in A, and produce two regular expressions with exponentiation, which are going to be equivalent when w is in A. Or when M accepts w. So it's going to be, as these things always are, these are going to be in terms of the computation history for M under w. But in this case, it's going to turn out to be convenient to work with the rejecting computation history for M on w. So remember, now we have a Turing machine M. It's a decider, so that
2081	means it always holds-- for the strings in the language, it ends up at a Q accept state, for things not in the language, it ends up at a Q reject state. So a rejecting computation history is the sequence of configurations the machine goes through from the start configuration until it ends up at a configuration with a reject state, a rejecting configuration. And we're going to make a regular expression that describes all strings except for that one. It's going to avoid describing a rejecting computation history for M on w. Otherwise, it's going to describe all possible strings. Now, if M does not reject w, so there is no rejecting computation history-- namely, M accepts w, by the way. So if M accepts w, does not reject w, it does not have a rejecting computation history, what is R1 describing? Well, it's describing, in that case, everything, because there is no rejecting computation history. So it's describing every other string besides. So that means it's describing all strings, if there is no rejecting computation history in the
2082	case that M accepts w. So what does that suggest we should use for R2? R2 is going to be the regular expression that just generates all strings. So we'll be testing whether R1 generates all strings or not, which is the same as saying does M accept w or not. So R2 is going to be-- I would like to say sigma star, but sigma is really the input to M, and gamma is the tape alphabet for M. So we have a lot of Greek letters to play with, so we're going to use delta for the alphabet that we write the computation histories in. If you want to get reminded what that delta is, a computation history can have a tape alphabet symbol for M, it can have a state symbol for M, or it can have a delimiter pound-- hashtag. So it's either a capital delta alphabet is a tape alphabet symbol, or state, something representing a state symbol, or a hashtag. That's just delta. So don't get-- I always feel bad if somebody gets confused
2083	by something that's supposed to be very simple. Don't get confused by delta star. This is just all possible strings over the alphabet delta. OK, so what does R1-- so my job is to do R1. R2, I already told you. R1 now has to describe all those strings except for the rejecting computation history. So everything that fails to be a rejecting computation history-- so it fails either because it started wrong, or it ended wrong, or it's wrong somewhere in the middle. And by wrong I mean, it fails to correctly describe the way the machine operates if it's ending up rejecting w. All right. So I'm going to describe all those possible strings by breaking it down into those three categories. Starts wrong, ends wrong, or somewhere computes wrong along the way. OK. So rejecting computation history looks something like this. Here's the start configuration as we usually envision it. It's a start state looking at the first symbol of the input, and there's the rest of the input. So let me just write this out. This
2084	is a rejecting computation history now. So the first configuration, the second one, and so on and so on, until we end up at a rejecting computation-- rejecting configuration. Now, for convenience, I'm going to insist that all of these configurations are the same length. It's going to make my life easier in doing the proof. But why can I do that? Well, I'm just going to take them-- you know, because usually you think of the configurations, they start small because they're just basically of length n, but this is using exponential space, they're getting longer and longer. Let's just pair them all out with blanks so that they're all the same size. So as I've indicated over here, we're adding in a bunch of blanks. It's going to be a lot of blanks here, to make sure they all have length 2 to the n to the k, which is the maximum size of a configuration when you have that much space. I'm going to construct-- so basically, that's my job. I'm going to construct R1 so that
2085	it generates all those strings. I wrote a little box around that thing I'm trying to--
2086	It's going to help me in the coming slides because they're a little bit dense. When I'm going to draw this sort of reddish, pinkish box around something, that means that I'm going to try to describe all strings except for that one. I want to avoid describing that one, because that's the rejecting computation history, but I want to describe everything else. That's my wish. So here's a check in before we move forward. But we can also-- maybe we should just take some questions, even before we launch the check in. How are we doing here? So, is our one describing-- well, R1 is a regular expression. Over here, we're talking about a-- this is just an ordinary computation history, but it ends with a reject. That's all. A rejecting computation history is just one that's a little different at the end. The machine just ended up rejecting instead of accepting. Otherwise everything has to be spelled out in accordance with the rules of the machine and the start configuration. Yeah, we were assuming one rejecting state. Yeah,
2087	that's the way we actually define Turing machines in the first place. But, who's arguing. Yeah, there's one reject state. We're all deterministic, correct. Why do we need the padding? Because I want to make these all the same size, all of these configurations. That's going to help me later in terms of describing the invalid configurations, the ones that are not legal configurations, legal rejecting configurations. So just simply a matter of convenience, but just accept it for now. I just want all of those configurations to be the same length in my rejecting computation history. Otherwise I'm not going to-- I'm just coding that rejecting computation history in this particular way. So people are asking about the details of bad start. That's yet to come. I have two more slides on this. So I'll tell you about how we're going to do those. So R bad-start-- that's a good question-- is R bad-start all-- these are all the strings that don't start this way. We'll see it in a second. But R bad-start are all the things that
2088	don't start with the-- they start bad. They're not starting with the start configuration. They're starting with some other junk. Do we need only one rejecting computation history? What about the other ones? This is a deterministic machine, so there's only going to be-- if I prescribe the lengths as I've done, there's going to be only one rejecting computation history. Because it's deterministic, everything is going to be forced from the beginning. Should R1 be the not of those three? No. R1 is describing all of the strings except, except this one string. So I'm capturing all the different possible ways a string could fail to be the string. It could start wrong. Could be wrong along the middle somewhere. So I have to union them together. Because I'm describing-- as I always believe, negations are the most confusing thing to everybody, including me. So we're describing all the things that are not this string. We're trying to stay away from that one. We want to describe everything else. All right, I think I'd better move on here. We've
2089	got a lot of questions. Talk to the TAs. All right, check in. How big is this rejecting computation history anyway? Interesting. There's a lesson here. I got a big burst of answers right at the very beginning. All wrong. But then the bright-- the people who took a little bit more time to think started getting the right answer, which is-- let's look. We've got a close election here folks, so now I have to report. Hope we don't have to do a recount. OK, come on guys. Answer up. 10 seconds. This is not super hard. Stop the count. Yeah, I think we'd better stop at this, we're on the edge. OK, 3 seconds. End polling. Share results. The correct answer is, in fact, c. Why is that? Because each configuration is 2 to the n to the k. So that's how much space the machine has, exponential space. But the amount of time, which is each one-- the number of configurations is going to be the amount of time that's used. It's going to be exponentially more
2090	even than that. So it's going to be 2 to the 2 to the n of the k, is how many steps the machine can run. And that's going to be how long the computation history could be. So it's a very long thing. And when you think about it, the regular expression we are generating, how big is that? The regular expression-- again, a lot of people playing off my comments here. Were the votes legal or not? OK. Let's focus here. So this is doubly exponentially large. How big is the regular expression that we're generating? Well that has to be produced in polynomial time, so it's only polynomially big. So we have this little teensy weensy, relatively speaking, regular expression, which is only n to the k. It's having to describe all strings except for this particular string, which is 2 to the 2 to the n to the k. So in a sense, this string that is related to that regular expression is doubly exponentially larger than that. And that kind of presents some of the
2091	challenge in doing the reduction, in constructing that regular expression.
2092	this is the hard stuff. Here is the bad start, which is challenging enough. Even this little piece is going to be a little bit challenging to describe. Just rewriting from the previous slide. So we're trying to make R1, which is generating all the strings except the rejecting computation history for M on w. It's in those three parts. Right now I'm describing the bad start piece. So that's going to describe all strings that don't start with this C1. So let me write that out here. This is going to generate all strings that don't start with C start or C1, which is as specified. Looks like this. So any string that doesn't start with these symbols, doesn't start exactly like this, should be described by bad start, that regular expression. So that, in itself, is going to be further subdivided. And the reason for that is not that hard to understand. I'm going to-- bad start is going to accomplish its goal by saying, well, anything that doesn't start this way either doesn't start with a q0,
2093	or doesn't or doesn't have a w1 in the next place, or doesn't have a w2 in the next place. Or somewhere along the way, it has a wrong symbol. Each one of these guys is going to be about one of those symbols being wrong in some particular place. So I'm going to show you what those look like. So right now, I'm going to focus my attention on describing all strings except for this one. All strings that start with something except for this one. So just remember, delta is the alphabet for the competition histories. And some notation here, delta sub epsilon, we've seen this before, is you're going to add in epsilon as an allowed thing for delta. So it's all the symbols, or epsilon, now thought of as a set here. And furthermore, it's going to be convenient to talk about all of the symbols in delta, except for some symbol. So like at the very beginning, q0. I want to talk about all of the symbols except for q0 symbol. Because that's what I'm
2094	going to be using to start off R bad-start. It's going to be anything except for q0. So let's just see how that looks. So here is S0, the very first part of our bad start. It's going to say-- I'm trying to color the active ingredient here in the pink color. So delta, with q0 removed, followed by anything. So this little regular expression here describes all strings that don't start with a q0, as I'm indicating over here. All strings that don't start with a q0 is what as S0 describes. You have to understand that, because it's just going to build up from there. So what do we want to say for S1? What's going to be all strings that don't have w1 in the second place? So I'm going to write that over here. S1 is anything in the first place-- I mean, if the first place was wrong, S0 took care of it. So I'm just going to keep my life simple. All I want to do is describe all of the places where the
2095	second symbol is wrong. Namely, it's not w1. So anything in the first place, something besides w1 in the next place, and then anything at all afterward. Those are all strings that don't have-- [AUDIO CUTS] So I'll write it over here like that. Now S2 similarly is going to d since I have exponentiation, let's use that for convenience. Delta delta, or just delta squared. So anything in the first two places, then not w2, and then the next place, and then anything. So that's going to capture this part. So this is what these S's do, and you can sort of get the idea. So dot, dot, dot. This Sn is going to describe everything except for wn in that location, which is going to be the n plus first location, actually. And now I have to continue on doing that for the blanks. So now, if you think with me, let's just take a look how that could go. The next symbol, which is skipping over the n plus 1 that I've already taken care of, I
2096	want to say it's not a blank symbol in this very first location after the input. So again, I'm describing these non-- these strings which are not the start configuration. It could fail because there's not a blank where there's supposed to be a blank. Suppose I do that for each one of these guys. That would work. But. But what? Think. This is actually not going to be a good solution for us. Because there are exponentially many blanks over here. This is a hugely long configuration. And so there's exponentially many blanks. If I do it this way, I'm going to end up with an exponentially large regular expression. And that's not doable in polynomial time. So I have a more complicated way of getting the same effect. Which is-- I don't really expect you to fully parse through this right now, in real time in lecture, but let me try to help you. What I'm going to do is skip over these first initial n plus 1 places, and then a variable number of places, which is
2097	indicated by the next piece here. And the way that works is-- these are all strings of length n plus 1 through the end of the configuration. And to understand that, it's almost a little too technical to even try, but let's see. If I put delta to the 7, that's all strings of length 7. But if I put delta sub epsilon to the 7, if you think about what that means, that's all strings of length between 0 and 7. Because I can either have it as epsilon as my variable or a symbol from delta. And so that's what I'm doing over here. I'm getting a variable length space, spacer of deltas, that are going to then end up at a certain location-- I'm going to say at that place. Then I have a non-blank. Because all I need to do is describe the strings that fail to have a blank somewhere in this range. So we've got to sort have a variable spacer out to that spot, where that missing blank might be. So that's what
2098	this describes. If you didn't get that, don't worry. That is a technical point and you can try to think about it offline. And then at the very end, I'm going to describe what happens. Describe the strings that fail to have a hashtag in that location. It's how I describe all strings that don't start right. That's a lot of work, just to do that little piece. Fortunately, the next two pieces are easier, surprisingly.
2099	You can jump in with a question, but maybe I should move, push on. So now I'm going to describe the bad move and bad reject pieces. And bad reject generates all strings that don't contain the q reject symbol. So that's going to certainly describe all of the strings that don't end correctly. And that's just simply the delta with the q reject symbol removed, and then any string of those. That's all strings that don't have q reject. So that's going to describe all strings that don't end with a q reject, plus some other junk strings along the way. But that's all that's never a problem, to put in other strings that you might be capturing in some other part of the regular expression that you know are bad strings. You just want to make sure you don't put in that one uniquely good string, which is the rejecting computation history, good string. And lastly, we're going to use the notion of the neighborhoods. You might think this is the hardest part, but in fact not that
2100	hard. So these are all of the strings that have somewhere along the way a violation according to M's rules. You want to describe all of those as well. I'm going to do that in terms of the neighborhoods. But the neighborhoods are going to be stretched out. We don't have a tableau anymore, so they're not so easily visualizable, but it's the same idea, the neighborhood. So this is abc and def. But now it's an illegal neighborhood. def does not follow from abc. If all the neighborhoods are legal, then the whole computation is a legitimate computation, provided it starts and ends correctly. So if it's not a legitimate computation, there's got to be an illegal neighborhood somewhere. And I'm going to just describe all strings that have an illegal neighborhood. And the interesting part is that you have to describe-- you have to place that separator between abc and def. So this is another place where we're going to critically use the exponentiation, and the fact that all of the configurations are the same length. That's what
2101	we're using there. We know exactly how far apart the bottom of the 2 by 3 neighborhood is from the top of the 2 by 3 neighborhood. So we're going to take a union over all illegal 2 by 3 neighborhoods. Neighborhood settings, I should say. And there's only a fixed number of those, for the same reason that we had in the Cook-Levin theorem. There's a fixed number of those, depending upon the machine. And now we're going to have, say, we're going to start with anything. Here's the top of the neighborhood. Here is the separator that separates the top from the bottom in the two consecutive configurations, here's Ci going C i plus 1 inside my computation history. And then after that separator, I put in the second part of the neighborhood, which is the def. You have to really be comfortable with the way we've been presenting these other reductions up till now, to really get this. Anyway, I think we're at the break. So we can just take questions during the break, if you have
2102	"any. And I will, otherwise, see you in five minutes. In my description back here-- let me just take this off. For bad reject, it looks like I'm doing kind of overkill, and maybe doing something wrong here. I'm describing all strings that don't have a reject anywhere. But as long as I don't describe the legitimate rejecting computation history, I do describe all strings that don't end correctly, I'm good. I could go through more effort to make sure that I'm only describing the very last configuration here as not having the reject. But that would just be more work, and I don't need to do that work. So maybe it would be good just to understand why this is sufficient, what I've described here, and it's not going to cause me any problems. I'm getting a note from one of my TAs, Thomas, saying that the notion ""bad"" perhaps is confusing, because bad sounds like rejecting. Yes. I mean bad in the sense of not describing a legal computation history. If you can think of another name, I'm"
2103	happy to switch that for future years. Too late for now. But, yeah. I don't mean that rejecting, I mean that it's-- well, I don't know what the right term is. Illegal? Or-- I'm not sure what a good-- How are the neighborhoods defined here? What is the tableau here? I think you do need to think about it after lecture. But the tableau, you can think of the tableau now here just written out linearly. There are all of the rows now, instead of nicely organized into a table. They just appear consecutively, because I'm just trying to describe-- I need to do it to describe a string, whether my regular expression doesn't really make sense to think about. I mean you can fold it up into a tableau, if you like. And then abc and def will line up. But here, if you think about them written consecutively, this is exactly how far apart they end up being. Are there only polynomially many illegal neighborhoods? That's why I kind of corrected myself. It's not illegal neighborhoods that we're
2104	talking-- because the number of neighborhoods in this picture is vast. But the number of neighborhood settings, the way to set these values to abc, def. I mean these are symbols that can appear in a configuration of the machine. There's only a fixed number of symbols that can appear here, that depend upon the definition of the machine. So it's not only polynomial. There's a constant number of these things, that only depends on the machine. So you have to think about what's going on. There's a lot-- this is a lot on the slide. Bad history for reject. It's a bad history for rejecting, somebody's suggesting. Yeah, it's a bad history. Fake news. Maybe we should be fake. Fake would be a good term. No, that's not so good. I don't know. Yeah, 2 by 3. The reason 2 by 3, is the right-- Somebody's asking why 2 by 3. 2 by 3 is exactly the size you need to say that, if all the 2 by 3 neighborhoods are correct everywhere in the computation history, then the
2105	whole history is going to be consistent with the rules of M. It's going to be a legal representation of a computation of M. So if the string, which is allegedly a computation history, has a bad neighborhood somewhere, bad 2 by 3 neighborhood somewhere, then-- well if it's not a legal computation history, it's got to have a bad neighborhood, 2 by 3 neighborhood somewhere. OK, let's move on. Because I think we're out of time here. Our timer is up. We're going to shift gears now anyway. So if you got a little lost in the previous proof, we're going to talk about something different. And in some ways, a little bit, I think a little lighter, a little less technical. And that's about oracles.
2106	What are oracles? Oracles are a simple thing. But they are a useful concept for a number of reasons. Especially because they're going to tell us something interesting about methods, which may or may not be useful for proving the P versus NP question, when someday somebody hopefully does that. What is an oracle? An oracle is free information you're going to give to a Turing machine, which might affect the difficulty of solving problems. And the way we're going to represent that free information is, we're going to allow the Turing machine to test membership in some specified language, without charging for the work involved. I'm going to allow you have any language at all, some language A. And say a Turing machine with an oracle for A is written this way, M with a superscript A. It's a machine that has a black box that can answer questions. Is some string, which the machine can choose, in A or not? And it gets that answer in one step, effectively for free. So you can imagine, depending upon the
2107	"language that you're providing to the machine, that may or may not be useful. For example, suppose I give you an oracle for the SAT language. That can be very useful. It could be very useful for deciding SAT, for example. Because now you don't have to go through a brute force search to solve SAT. You just ask the oracle. And the oracle is going to say, yes it's satisfiable, or no it's not satisfiable. But you can use that to solve other languages too, quickly. Because anything that you can do in NP, you can reduce to SAT. So you can convert it to a SAT question, which you can then ship up to the oracle, and the oracle is going to tell you the answer. The word ""oracle"" already sort of conveys something magical. We're not really going to be concerned with the operation of the oracle, so don't ask me how does the oracle work, or what does it correspond to in reality. It doesn't. It's just a mathematical device which provides this free information to"
2108	the Turing machine, which enables it to compute certain things. It turns out to be a useful concept. It's used in cryptography, where you might imagine the oracle could provide the factors to some number, or the password to some system or something. Free information. And then what can you do with that? So this is a notion that comes up in other places. If we have an oracle, we can think of all of the things that you can compute in polynomial time relative to that oracle. So that's what we-- the terminology that people usually use is sometimes called relativism, or computation relative to having this extra information. So P with an A oracle is all of the language that you can decide in polynomial time if you have an oracle for A. Let's see. Yeah. Somebody's asking me, is it really free or does it cost one unit? Even just setting up the oracle and writing down the question to the oracle is going to take you some number of steps. So you're not going to be
2109	able do an infinite number of oracle calls in zero time. So charging one step or zero steps, not going to make a difference. Because you still have to formulate the question. As I pointed out, P with a SAT oracle-- so all the things you do in polynomial time with a SAT oracle includes NP. Does it perhaps include other stuff? Or does it equal NP? Would have been a good check-in question, but I'm not going to ask that. In fact, it seems like it contains other things too. Because co-NP is also contained within P, given a SAT oracle. Because the SAT oracle answer is both yes or no, depending upon the answer. So if the formula is unsatisfiable, the oracle is going to say no, it's not in the language. And now you can do the complement of the SAT problem as well. The unsatisfiability problem. So you can do all of co-NP in the same way. You can also define NP relative to some oracle. So all the things you can do with a non-deterministic
2110	Turing machine, where all of the branches have separately access. And they can ask multiple questions, by the way, of the oracle. Independently. Let's do another, a little bit of a more challenging example. The MIN-FORMULA language, which I hope you remember from your homework. So those are all of the formulas that do not have a shorter equivalent formula. They are minimal. You cannot make a smaller formula that's equivalent that gives you the same Boolean function. So you showed, for example, that that language is in P space, as I recall. And there was some other-- you had another two problems about that language. The complement of the MIN-FORMULA problem is in NP with a SAT oracle. So mull that over for a second and then we'll see why. Here's an algorithm, in NP with a SAT oracle algorithm. So in other words, now I want to kind of implement that strategy, which I argued in the homework problem was not legal. But now that I have the SAT oracle, it's going to make it possible where before
2111	it was not possible. So let's just understand what I mean by that. If I'm trying to do the non minimal formulas, namely the formulas that do have a shorter equivalent formula. I'm going to guess that shorter formula, called psi. The challenge before was testing whether that shorter formula was actually equivalent to phi. Because that's not obviously doable in polynomial time. But the equivalence problem for formulas is a co-NP problem. Or if you like to think about it the other way, any formula in equivalence is an NP problem, because you just have to-- the witness is the assignment on which they disagree. So two formulas are equivalent if they never disagree. And so that's a co-NP problem. A SAT oracle can solve a co-NP problem. Namely, the equivalence of the two formulas, the input formula and the one that you now deterministically guessed. And if it turns out that they are equivalent, a smaller formula is equivalent to the input formula, you know the input formula is not minimal. And so you can accept. And if
2112	it gets the wrong formula, it turns out not to be equivalent, then you reject on that branch of the non-determinism, just like we did before. And if the formula really was minimal, none of the branches is going to find a shorter equivalent formula. So that's why this problem here is in NP with a SAT oracle. So now we're going to try to investigate this on my-- we're getting near the end of the lecture. We're going to look at problems like, well, suppose I compare P with a SAT oracle and NP with a SAT oracle. Could those be the same? Well, there's reasons to believe those are not the same. But could there be any A where P with A oracle is the same as NP with an A oracle? It seems like no, but actually that's wrong. There is a language, there are languages for which NP with that oracle and P with that oracle are exactly the same. And that actually is an interest-- it's not just a curiosity, it actually has relevance to
2113	strategies for solving P versus NP. Hopefully I'll be able to have time to get to. Can we think of an oracle like a hash table? I think hashing is somehow different in spirit. I understand there's some similarity there, but I don't see the-- hashing is a way of finding sort of a short name for objects, which has a variety of different purposes why you might want to do that. So I don't really think it's the same. Let's see, an oracle question, OK, let's see. How do we use SAT oracle to solve whether two formulas are equivalent? OK, this is getting back to this point. How can we use a SAT oracle to solve whether two formulas are equivalent? Well, we can use a SAT oracle to solve any NP problem, because it's reducible to SAT. In other words-- P with a SAT oracle contains all of NP, so you have to make sure you understand that part. If you have the clique problem, you can reduce. If I give you a clique problem, which is
2114	an NP problem, and I want to use the oracle to test if the formula-- if the graph has a clique, I reduce that problem to a SAT problem using the Cook-Levin theorem. And knowing that a clique of a certain size is going to correspond to having a formula which is satisfiable, now I can ask the oracle. And if I can do NP problems, I can do co-NP problems, because P is a deterministic class. Even though it has an oracle, it's still deterministic. It can invert the answer. Something that non-deterministic machines cannot necessarily do. So I don't know, maybe that's-- let's move on. So there's an oracle where P to the A equals NP to the A, which kind of seems kind of amazing at some level. Because here's an oracle where the non-determinism-- if I give you that oracle, non-determinism doesn't help. And it's actually a language we've seen. It's TQBF. Why is that? Well, here's the whole proof. If I have NP with a TQBF oracle. Let's just check each of these steps. I
2115	claim I can do that with a non-deterministic polynomial space machine, which no longer has an oracle. The reason is that, if I have polynomial space, I can answer questions about TQBF without needing an oracle. I have enough space just to answer the question directly myself. And I use my non-determinism here to simulate the non-determinism of the NP machine. So every time the NP machine branches non-deterministically, so do I. Every time one of those branches asks the oracle a TQBF question, I just do my polynomial space algorithm to solve that question myself. But now NPSPACE equals PSPACE by Savitch's theorem. And because TQBF is PSPACE complete, for the very same reason that a SAT oracle allows me to do every NP problem, a TQBF problem allows me to do every PSPACE problem. And so I get NP contained within P for a TQBF oracle. And of course, you get the containment the other way immediately. So they're equal. What does that have to do with-- somebody said-- well, I'll just-- I don't want to run out
2116	of time. So I'll take any questions at the end. What does this got to do with the P versus NP problem? OK, so this is a very interesting connection. Remember, we just showed through a combination of today's lecture and yesterday's lecture, and I guess Thursday's lecture, that this problem, this equivalence problem, is not in PSPACE, and therefore it's not in P, and therefore it's intractable. That's what we just did. We showed it's complete for a class, which is provably outside of P, provably bigger than P. That's the kind of thing we would like to be able to do to separate P and NP. We would like to show that some other problem is not in P. Some other problem is intractable. Namely, SAT. If we could do SAT, then we're good. We've solved P and NP. So we already have an example of being able to do that. Could we use the same method? Which is something people did try to do many years ago, to show that SAT is not in P. So what
2117	is that method really? The guts of that method really comes from the hierarchy there. That's where you were actually proving problems that are hard. You're getting this problem with through the hierarchy construction that's provably outside of PSPACE. And outside of P. That's a diagonalization. And if you look carefully at what's going on there-- so we're going to say, no, we're not going to be able to solve SAT, show SAT's outside of P in the same way. And the reason is, suppose we could. Well the hierarchy theorems are proved by diagonalization. What I mean by that is that in the hierarchy theorem, there's a machine D, which is simulating some other machine, M. To remember what's going on there, remember that we made a machine which is going to make its language different from the language of every machine that's running with less space or with less time. That's how D was defined. It wants to make sure its language cannot be done in less space. So it makes sure that its language is different. It
2118	simulates the machines that use less space, and does something different from what they do. Well, that simulation-- if we had an oracle, if we're trying to show that if we provide both a simulator and the machine being simulated with the same oracle, the simulation still works. Every time the machine you're simulating asks a question, the simulator has the same oracle so it can also ask the same question, and can still do the simulation. So in other words, if you could prove P different from NP using basically a simulation, which is what a diagonalization is, then you would be able to prove that P is different from NP for every oracle. So if you can prove P different from NP by a diagonalization, that would also immediately prove that P is different from NP for every oracle. Because the argument is transparent to the oracle. If you just put the oracle down, everything still works. But-- here is the big but, it can't be that-- we know that P A is-- we know this is false.
2119	We just exhibit an oracle for which they're equal. It's not the case that P is different from NP for every oracle. Sometimes they're equal, for some oracles. So something that's just basically a very straightforward diagonalization, something that's at its core is a diagonalization, is not going to be enough to solve P and NP. Because otherwise it would prove that they're different for every oracle. And sometimes they're not different, for some oracles. That's an important insight for what kind of a method will not be adequate to prove P different from NP. And this comes up all the time. People who propose hypothetical solutions that they're trying to show P different from NP. One of the very first things people ask is, well, would that argument still work if you put an oracle there. Often it does, which points out there was a flaw. Anyway, last check in. So this is just a little test of your knowledge about oracles. Why don't we-- in our remaining minute here. Let's say 30 seconds. And then we'll do a
2120	wrap on this, and I'll point out which ones are right. Oh boy, we're all over the place on this one. You're liking them all. Well, I guess the ones that are false are lagging slightly. OK, let's conclude. Did I give you enough time there? Share results. So, in fact-- Yeah, so having an oracle for the complement is the same as having an oracle. So this is certainly true. NP SAT equal coNP SAT, we have no reason to believe that would be true, and we don't know it to be true. So B is not a good choice and that's the laggard here. MIN-FORMULA, well, is in PSPACE, and anything in PSPACE is reducible to TQBF, so this is certainly true. And same thing for NP with TQBF and coNP with TQBF. Once you have TQBF, you're going to get all of PSPACE. And as we pointed out, this is going to be equal as well. So why don't we end here. And I think that's my last slide. Oh no, there's my summary here. This is
2121	what we've done. And I will send you all off on your way. How does the interaction between the Turing machine and the oracle look? Yeah, I didn't define exactly how the machine interacts with an oracle. You can imagine having a separate tape where it writes the oracle question and then goes into a special query state. You can formalize it however you like. They're all going to be-- any reasonable way of formalizing it is going to come up with the same notion in the end. It does show that P with a TQBF oracle equals PSPACE. Yes, that is correct. Good point. Why do we need the oracle to be TQBF? Wouldn't SAT also work because it could solve any NP problem? So you're asking, does P with a SAT oracle equal NP with a SAT oracle? Not known. And believed not to be true, but we don't have a compelling reason for that. No one has any idea how to do that. Because, for example, we showed the complement of MIN-FORMULA is in NP with a
2122	SAT oracle. But no one knows how to do-- because there's sort of two levels of non-determinism there. There's guessing the smaller formula, and then guessing again to check the equivalence. And they really can't be combined, because one of them is sort of an exist type guessing, the other one is kind of a for all type guessing. No one knows how to do that in polynomial time with a SAT oracle. Generally believed that they're not the same. In the check-in, why was B false? B is the same question. Does NP with a SAT oracle equal coNP with a SAT oracle? I'm not saying it's false, it's just not known to be true. It doesn't follow from anything that we've shown so far. And I think that would be something that-- well, I guess it doesn't immediately imply any famous open problem. I wouldn't necessarily expect you to know that it's an unsolved problem, but it is. Could we have oracles for undecidable language? Absolutely. Would it be helpful? Well, if you're trying to solve an undecidable
2123	problem, it would be helpful. But people do study that. In fact, the original concept of oracles was presented, was derived in the computability theory. And a side note, you can talk about reducibility. No, I don't want to even go there. Too complicated. What is not known to be true? What is not known to be true is that NP with a SAT oracle equals coNP with a SAT oracle, or equals P with a SAT oracle. Nothing is known except the obvious relations among those. Those are all unknown, and just not known to be true or false. Is NP with a SAT oracle equal to NP? Probably not. NP with a SAT oracle, for one thing, contains coNP. Because it's even more powerful. We pointed out that P with a SAT oracle contains coNP. And so NP with a SAT oracle is going to be at least as good. And so it's going to contain coNP. And so, probably not going to be equal to NP unless shockingly unexpected things happen in our complexity world.
2124	[CLICKING] [RUSTLING] [SQUEAKING] [CLICKING] MICHAEL SIPSER: OK. Hi, everybody. Let's get started. So, it's been a while since we came together in a lecture. Last week, we had the holiday. We had the midterm. So with that, what have we been doing? We finished the first half of the course about two weeks ago, where we talked about-- we were talking about computability theory. We have shifted into the second half, talking about complexity theory. So get your mind back to that. We discussed the various different models and ways of measuring complexity on different models-- at least in terms of the amount of time that's used. And in the end, we settled on the one-tape Turing machine, which is the same model we had been working with in the first half of the course, and argued that though the measures of complexity are going to differ somewhat from model to model, they're not going to differ by more than a polynomial amount. And so, since the kinds of questions we're going to be asking are going to be, basically,
2125	whether problems are polynomial or not, it's not going to really matter which model we pick among reasonable deterministic models. And so, the one-tape Turing machine is a reasonable choice. Given that, we defined time complexity classes, the TIME[T(n)] classes. We defined the class P, which was invariant among all of those different deterministic models in the sense that it didn't matter which model we choose, we were going to end up with the same class P. So that argues for its naturalness. And we gave an example of this path problem being in P. And we kind of ended that lecture before the midterm with the discussion of this Hamiltonian path problem. So we're going to come back to that today. So today, we're going to look at non-non-deterministic complexity; define the classes' non-deterministic time or NTIME; talk about the class NP, the P versus NP problem-- which one of the very famous unsolved problems in our field; and look at dynamic programming, one of the most basic algorithm - polynomial-time algorithms and polynomial-time reproducibility - moving toward our
2126	discussion of NP completeness, which we will begin next lecture. So with that, let's move into today's content, which is, well, just a quick review. As I mentioned, we defined the time complexity class. The time complexity class is a collection
2127	solve in a certain time bound, within a certain amount of time. So the time n-squared, for example, is all of the languages or all of the problems that you can solve in n-squared time. We're identifying problems with languages here. And the class P is the collection of all problems that you can solve or all languages that you can solve in polynomial time. So it's the union over all time n to the k-- so n-squared, n-cubed, n to the fifth power, and so on. Union out of all of those bounds. The associated languages, that's the class P. And we gave an example, this path problem. We gave an algorithm for path.
2128	So if you remember? Instead of just asking given a graph, whether you can get from s to t, now we want to know can I get from s to t, but visit every other node along the way. So find a path that goes through everything else and gets from s to t. And I should say also it's a simple path, so you're only allowed to go through every node just once. And now, the question for this problem is can we solve that problem in polynomial time. Can we somehow modify the algorithm for path to give us an algorithm that solves Hamiltonian path in polynomial time? Of course, we could solve Hamiltonian path with an exponential algorithm by trying all possible paths. And that will give a correct algorithm, but there are exponentially many different paths and trying them all will not give a polynomial time algorithm. So the interesting problem is can we solve that without doing that brute force searching through all possible paths. And that's a problem that no one knows the answer
2129	to. Despite lots of effort, people have not succeeded in finding an algorithm for that. But on the other hand, we don't have any idea how do you prove there is no such algorithm. I mean, it's conceivable that one could prove such a thing, but we just don't know how to do it. And so, that problem is an unsolved problem and I just-- this isn't really a note to myself. What's kind of amazing, and this is what we're going to be showing over the next few lectures, that there would be very surprising consequences if you could find a way to solve Hamiltonian path in polynomial time. Because what that would immediately yield is the polynomial time way of, say, factoring large numbers or solving a large number of other problems that we don't know how to solve in polynomial time. So as we mentioned, factoring is a problem that we only know at present how to solve with an exponential algorithm. And it doesn't seem to have anything to do with the Hamiltonian path problem. Seem
2130	very different. But, yet, if you can solve Hamiltonian path in polynomial time, then you can factor numbers in polynomial time. And so, we'll see how to make that connection. That's what we're building toward with the next few lectures. OK. So happy to take any comments and questions on that, or we'll just move on, if you have any questions on our little review. Well, send questions along and we can stop at the end of various slides to try to answer them. And, of course, write to the TAs,
2131	OK. So to start this off, we're going to have to talk about non-deterministic complexity as a variation of deterministic complexity. So first of all, all of the machines in this part of the course and the languages, everything is going to be decidable and all the machines are going to be deciders. So what do we mean when we have a non-deterministic machine which is a decider? And that just simply means that all of the branches-- it's not just the machine halts on every input, but all of the branches halt on every input. So the non-deterministic machine is non-deterministic, it has lots of possible branches. They all have to halt-- all of them-- on every input. That's what makes a non-deterministic machine a decider. And you're going to convert a non-deterministic decider into a deterministic decider. But the question is, how much time would that introduce? How much extra time is that going to cost? And the only way that people know at the present time for that conversion would be to do an exponential increase. Basically,
2132	to try all possible branches.
2133	So first, let's understand what we mean by the time used by a non-deterministic machine. And what we mean by the time used is, we're looking at each individual branch individually, separately. So a non-deterministic machine, we'll say, runs in a certain amount of time if all of the branches halt within that amount of time. So what we do not mean that the total amount of usage, the total amount of effort by adding up all the branches is at most T of n. It's just that each branch individually uses at most T of n. That's just going to be our definition. And it's going to turn out to be the right way to look at this to get something useful. So now we're going to define the analogous complexity class associated to non-deterministic computation, which we'll call non-deterministic time. So non-deterministic time T of n is the set of all languages that you can do with a non-deterministic machine that runs in order T of n time. Just think back to the definition we had for deterministic
2134	complexity, the time class-- or sometimes people call it dtime to emphasize the difference. But let's just say we're calling it in this course time versus ntime. So TIME[T(n)] is all of the language that you can do with the one-tape Turing machine that's deterministic. But this here is a non-deterministic Turing machine for non-deterministic time. So the picture that is good to have in your head here would be if you think of non-determinism in terms of a computation tree thinking of all the different branches of the non-determinism. All of those branches have to halt and they have to halt within the time bound. So imagine, here, this is T of n time. All of the branches have to halt within T of n steps for this, a non-deterministic Turing machine to be running in T of n time and to be doing a language in the NTIME[T(n)] class. And by analogy with what we did before, the class NP is the collection of all languages that you can do non-deterministically in polynomial time. So it's the union
2135	over all of the ntime classes where the bound is polynomial. OK, so a lot of this should look very familiar, but we've just added a bunch of non-deterministic and a bunch of Ns in place. But the definitions are very similar. And one of the motivations we had for looking at the class P was that it did not depend on the choice of model, as long as the model was deterministic and reasonable. And the class NP is also going to not depend on the choice of model, as long as it's a reasonable non-deterministic model. So it's again a very natural class to look at from a mathematical standpoint. And it also captures something interesting, kind of, from a practical standpoint - which we're going to talk about over the next couple of slides - which is that it captures the problems where you can easily verify when you're a member of the language. OK, so we'll talk about that. But if you take, for example, the Hamiltonian path problem. When you find a member of the
2136	language, so that is a graph that does have a Hamiltonian path from s to t, you can easily verify that's true by simply exhibiting the path. Not all problems can be verified in that way. But the problems that are in NP have that special feature-- that when you have a member of the language, there's a way to verify that you're a member. So we're going to talk about that, because that's really the key to understanding NP-- this notion of verification. OK, so let me go-- there was a good question here. Let me just see if I want to answer that. Yeah, I mean, this is a little bit of a longer question than I want to fully respond to but-- well, let's turn to my next slide, which maybe sort bringing that out anyway.
2137	But I'll get to that point. So let's look at Hamiltonian, the hampath problem. And what I'm going to show is the Hamiltonian path problem is in NP. And I'm going to walk you through this one kind of slowly. So the Hamiltonian path problem, remember, we don't know if it's in P. But it is in NP. So it's in one of these. You can solve Hamiltonian path in polynomial time if you're a non-deterministic machine. Why is that? Well, it's because of the parallelism of non-determinism, which allows you to kind of check all of the paths on different branches. So let me first describe how I would write down the algorithm. And then, we'll kind of try to unpack that and understand how that actually looks in terms of the Turing machine's computation. So first of all, taking the Hamiltonian path problem, you are given an input now, which is a graph and the nodes s and t where I'm trying to figure out is that Hamiltonian path-- again, which visits all the nodes, which takes you
2138	from s to t. And we're trying to make now a non-deterministic machine, which is going to accept all such inputs which have a path. So the way this non-deterministic machine is going to work is it's basically going to use its non-determinism to try all possible paths on the different branches. And the way I'll specify that is to say, non-deterministically, we're going to write down a candidate path which is just going to be a sequence of m nodes, where we will say that's the total number of nodes of the graph. Remember, a Hamiltonian path, because it visits every node, is going to be a path with exactly m nodes in it. So I'm going to write down a sequence of nodes as a candidate path. And I'm non-deterministically going to choose every possible sequence in this way. If you'd like to think of the guessing metaphor for non-determinism, you can think of the non-deterministic machine as guessing the right path, which is going to be the Hamiltonian path from s to t. But I think for
2139	this discussion, it might be more helpful to think about all of the different branches of the non-determinism. Because that's perhaps more useful when we're thinking about it in terms of the time. I think you'll get used to thinking about it. You should be used to thinking about it in many of the different ways. but maybe the computation tree of all branches might be the more helpful one here. So now after we write down a candidate path sequence of nodes, now I have to check that this really is a path. And the way I'm going to do that is to say, well, now if I have just a sequence of nodes written down, what does it mean for it to be a Hamiltonian path from s to t? Well, it better start with s and end with t, first of all. And we have to make sure that every step of the way is actually an edge. So each pair vi to vi plus 1 has to be an edge in the graph. Otherwise, that sequence
2140	of nodes is not going to be a legitimate Hamiltonian path from s to t. And it has to be a simple path. You can't be repeating nodes. These four conditions together will guarantee that we have a Hamiltonian path. And once we have written down a candidate sequence, we can just check that the sequence actually works. At this second stage of the algorithm, non-determinism isn't necessary. This is going to be a deterministic phase. But stage one of the algorithm is going to be a non-deterministic phase where it's writing down all possible paths. Now, I'm going to try to unpack that for you so you can actually visualize how the machine is doing this. And then, of course, you know on each branch of the non-determinism, you're going to check to see whether the conditions have been satisfied. And on that branch, if the conditions were not satisfied, that branch is going to reject. Of course, one of the other branches might yet accept, so that's how non-determinism works. OK? So I'd like to visualize this as
2141	the tree of the different branches of the computation of m on its input. So here is our non-deterministic Turing machine. Which? This one. And you provide it with the input G, s, and t. And how is the machine actually working? So when I say non-deterministically write down a sequence of m nodes-- look, this is getting into a little bit more detail than I would normally think about it, because we try to tend to think about things at a higher level. But just to get us started, I think it's good to think about this with a bit more detail. So let's think of the m nodes as being numbered, having labels numbered 1 through m. And I'm going to think about them being labeled by their binary sequences. We're going to write down those nodes. That's how the machine is going to have to operate on those numbers for the nodes. We'll think about them as being written in binary. And now, as the machine is going to be writing down, let's say, the node v1.
2142	So it's non-deterministically picking the first node of the sequence. What does that actually mean in terms of the step-by-step processing of the Turing machine m? Well, it's going to be guessing via a sequence of non-deterministic moves, the bits that represent the number of the node for v1. For example, v1 might be the node number 5 in the graph. Of course, non-deterministically, the machine is on different branches, picking all different possible choices for v1. Those are going to be the different branches here. But one of the branches might be-- and what I'm really representing here, these are-- I probably could have written this down on the slide here in tiny font. But these are like the 0, 1 choices. That's why it's sort of a binary tree here for writing down the bits of v1. So here maybe this could be 101, representing the number 5, which might be the very first node that I'm writing down in my sequence. Some other branch is going to write down node number 6. Some other branch is going
2143	to write down node number 2. Because non-deterministically, we're making all possible choices for v1. That's what I'm trying to show in this little part of the computation of m on this input. So then, after it's finished writing down the description of the node for its choice for v1, it goes down to choose what v2 is. Again, non-deterministically, so there's going to be more branches for each possible choice of v2. And so on, node after node. Then, it's going to finally get to the last node, vm. It's going to write down lots of choices for vm. And at this point here, we have completed the first stage of the algorithm. Now, there's some huge tree of all of the possible choices for the V's that have shown up at this point. OK? And now, we're going to move into the second phase. So following this, there's going to be, here, a bunch of deterministic steps of the machine. So no more branching is needed because here, we've written down-- at this point, we've reached a point
2144	in each of those locations, where we've chosen one of the candidates, one of the possible branches-- one of the possible paths through the graph, I'm sorry. So here, we're guessing potential paths in the graph. And now, we're going to check that we actually have picked a path that's a Hamiltonian path from s to t. OK? So each one of these branches is now going to end up accepting or rejecting. And the whole overall computation is going to accept if at least one of them ended up accepting, which means you actually found a Hamiltonian path. OK? I don't know if that's helpful to you or not, but that is-- if there's any questions on this, let's see. Question on is there something-- trying to draw a connection here between this and computation histories. I mean, there is a pattern here that does come up often where you want to check that something starts right, ends right, and that all of the intermediates are right. So I think there is some deeper connection here. Probably too hard
2145	to explain but that has something to do with this Hamiltonian path problem. Why are we using binary representation? Well, we're going to talk about-- the algorithm would have worked equally well if we used base three or base five or base 20 as a way of writing down our labels for the nodes. But in a sense, it doesn't matter. The alphabet has to be finite though, so that's true. I mean, that's why it's not just in a single step of the Turing machine that you would pick the node the choice for v1. You really have to go to a sequence of steps. Because each of the branches of the machine only has a fixed number of choices. So you can't, in a single step of the Turing machine, pick all the different possibilities for v1. That has to go through a sequence. OK. Now, let me do a second example, the problem of composites. So the language of all composites are all of the non-primes, written as binary numbers again. So we'll talk about the base
2146	and the representation in a second. But just imagine these are all of the numbers that are not prime. And that language is easily seen to be a member of NP. Here is, again, the algorithm for that. Given x, we want to accept x, if it's not a prime number. So it has some non-trivial factor. So first, the way the non-deterministic machine is going to work is it's going to guess that factor. So non-deterministically, it's going to try every possible factor. Y is going to be a number between 1 and x. But not including 1. You have to be an interesting factor, so not including one in the number itself. So something strictly in between. And we're going to then-- after we've non-deterministically chosen y, then we're going to test to see if y is really a factor. So we'll see if y divides evenly into x with a remainder of 0. If that branch successfully picked the right y, it's going to accept. And some other branch where it might have picked the wrong y,
2147	will not. And if x is really a composite number, some branch will find the factor. Now, the base doesn't matter. Could have used base 10, because you can convert from one base to another. So this is really in terms of our representation of the number. But I do want to make one point here, that changing-- we don't want to write the number in unary-- writing the number of k as a sequence of k1s. That's not really a base. That's just an exponential representation for the number and that changes the game. Because if you make the input exponentially larger, then it's going to change whether the algorithm relative to that exponentially larger input is polynomial or not. So an algorithm that might have been exponential originally when the number's written in binary might become polynomial if the numbers are written in unary. And I do want to mention as a side note, that the composites language-- or primes, for that matter-- both are NP. But we won't cover that. So whereas the Hamiltonian path problem is
2148	not known whether it's NP, the primes and composites problem are NP. So that was known. That was actually a very big result in the field. Solved by folks at one of the Indian Institute of Technology back about almost 20 years ago now.
2149	So let's turn here, to trying to get an intuitive feeling for P and NP. And we'll return now to this notion of NP corresponding to easy verifiability. NP are the languages where you can easily verify membership quickly. I'll try to explain what that means. In contrast, P are the languages where you can test membership quickly. By quickly, I'm using polynomial time. That's going to be, for us, that's what quickly means in this course. In the case of the Hamiltonian path problem, the way you verify the membership is you give the path. In the case of the composites, the way you verify the membership is you give the factor. In those two cases, and in general, when we have a problem that's in NP, we think of this verification as having-- we give it a special name, called a certificate, or sometimes a short certificate, to emphasize the polynomiality of the certificate. It's like a way of proving that you're a member of the language. In the case of COMPOSITES, the proof is the factor. In
2150	the case of HAMPATH, the proof is the path, the Hamiltonian path. Contrast that, for example, if you had a prime number. Proving a number is composite is easy because you just exhibit the factor. How would you prove that a number is prime? What's the short certificate of proving that some number has no factor? That's not so obvious. In fact, there are ways of doing it, which I'm not going to get into in the case of testing of numbers prime. And now it's even known to be in P, so that's even better. But there's no obvious way of proving that a number is prime with a short certificate. This concept of being able to verify when you are a member of the language, that's key to understanding NP. That's the intuition you need to develop and hopefully take away from today's lecture, or at least
2151	If you compare these two classes, P and NP. P, first of all, is going to be a subset of NP, both in terms of the way we defined it because, deterministic machines are a special case of non-deterministic machines. But also if you want to think about testing membership, if you can test membership easily then you can certainly verify it in terms of the certificate. You don't even need it. The certificate is irrelevant at that point. Because whatever the certificate is, you can still test yourself whether the input is in the language or not. The big question, as I mentioned, is whether these two classes are the same. So does being able to verify membership quickly, say with one of these certificates, allow you to dispense with the certificate? Not even need a certificate and just test it for yourself whether you're in the language. And do that in polynomial time. That's the question. For a problem like Hamiltonian path, do you need to search for the answer if you're doing it deterministically? Or can you
2152	somehow avoid that and just come up with the answer directly with a polynomial time solution? Nobody knows the answer to that. And it goes back, at this point, quite a long time. It's almost 60 years now. That problem has been around 60 years. No, that would be 50 years. No, 50 years, almost 50 years. Most people believe that P is different from NP. In other words, that there are problems in P-- in NP which are not in P. A candidate would be the Hamiltonian path problem. But it seems to be very hard to prove that. And part of the reason is, how do you prove that a problem like Hamiltonian path does not have a polynomial time algorithm. It's very tricky to do that, because the class of polynomial time algorithms is a very rich class. Polynomial time algorithms are very powerful. And to try to prove-- there's no clever way of solving the Hamiltonian path problem. It just seems to be beyond our present day mathematics. I believe someday somebody's going to solve it.
2153	But so far, no one has succeeded. So what I thought we would do is-- I think I have a check-in here.
2154	And then we'll stop for a break. Let's look at the complementary problem, HAMPATH complement. You're in the language now if you don't have a path. So is that complementary problem in NP? For that to be the case, we would need to have short certificates of when a graph does not have a Hamiltonian path. I leave it to you. There are three choices. OK? Going to stop here, so make sure you get your participation credit here. I'm going to end the polling now. Interesting. [LAUGHS] So the majority is wrong. Well, not wrong, we don't know. I think the only fair answer to this question is C. Because we don't know whether or not we can give short certificates for a graph not to have a Hamiltonian path. If P equaled NP, then you can test in polynomial time whether a graph has a Hamiltonian path. And then the computation itself would be a certificate, whether it has a path or whether it doesn't have a path. Because it would be something that you can check easily.
2155	Since we don't know for sure that P is different from NP, P could be equal to NP, then it's possible that we could give a short certificate. Namely, the computation of the polynomial algorithm. So the only really reasonable answer to this question is that we don't know. Just ponder that. Those of you who answered yes, however, need to go back. And I put this here explicitly because I know this is a confusion for, well I can see, for quite a few of you. When we have non-deterministic computation and you have a non-deterministic machine, you can't simply invert the answer and get back a non-deterministic machine. Non-determinism does not work that way. If you remember, the complement of a pushdown automaton is not a pushdown automaton. If you have a non-deterministic machine and you invert all of the responses on each of the branches, it's not going to be recognizing or deciding the complementary language. I think that this is something you-- if you answered yes, you need to go back and make sure you understand
2156	why yes is not a reasonable answer to this question. Because that's not how non-determinism works. So you have a not complete understanding of non-determinism. And that's going to be really important for us going forward. I really urge you to figure out and understand why yes is not a good answer to this check-in.
2157	we can talk about that more over the break. And so we'll return here in five minutes. Somebody's asking about-- can infinite sequences be generated by the machine. When we're talking about, especially in the complexity section of the course, all of the computations are going to be bounded in time. So we're not going to be thinking about infinite runs of the machine. That's not going to be relevant for us. So let's not think about that. How does a Turing machine perform division? How does a Turing machine perform division? Well, how do you perform division? [LAUGHS] Long division is an operation that can run in-- the long division procedure that you learn in grade school, you can implement that on a Turing machine. Yes, a Turing machine can definitely perform-- do long division, or division of one integer by another in polynomial time. Another question. Can we generally say, try dividing y by x? Or do we have to enumerate a string of length y and cross off every-- no. I think that's the same question. I
2158	mean, if you have numbers written in binary, how would you do the division? You're not going to use long division. Anything such as the thing that's proposed here by the questioner is going to be an exponential algorithm. So don't do it that way. Why does primes in P-- composites in P not imply primes in P? It does imply. If composites are in P, then primes is in P as well. When you have a deterministic machine, you can flip the answer. When you have a non-deterministic machine, you may not be able to flip the answer. So deterministic machine just having a single branch, you can make another deterministic machine that runs in the same amount of time that does the complementary language. Because for deterministic machines, just like for deciders in the computability section, you can just invert the answer. There is an analogy here between P and decidability, and NP and recognizability. It's not an airtight analogy here, but there is some relationship there. Somebody's asking me, what are the implications of P equal to
2159	NP? Lots of implications. Too long to enumerate now. But, for example, you would be able to break basically all cryptosystems that I'm aware of, if P equal to NP. So we would have a lot of consequences. Somebody's asking, so composites-- primality and compositeness testing is solvable in polynomial time. But factoring, interestingly enough, is not known to be solvable in polynomial time. We may talk about this a little bit toward the end of the term if we have time. The algorithms for testing whether a number is prime or composite in polynomial time do not operate by looking for factors. They operate in an entirely different way, basically by showing that a number is prime or composite by looking at certain properties of that number. But without testing whether it has-- testing, but without finding a factor. Another question here about asking when we talk about encodings, do we have to say how we encode numbers, values? No, we don't have to. We usually don't have to get into spelling out encodings, as long as they're reasonable
2160	encodings. So you don't have to usually. We're going to be talking about things at a high enough level that the specific encodings are not going to matter. Let's return to the rest of our lecture.
2161	"And how do you show that a problem might not be solvable in P, like the Hamiltonian path problem? Many people who are not practitioners in the field, know about the P versus NP problems-- over the years, I've gotten many, many emails and physical letters from people about that. Since I've spent some time thinking-- I'm known as having spent some time thinking about it. People claim to solve the problem, solve P is NP, the P versus NP problem, by basically saying, problems like Hamiltonian path or other similar problems, basically there's clearly no way to solve them without searching through a lot of possibilities. And then they go through a big, long analysis showing that there are exponentially many possibilities. A lot of the proofs that claim to solve P versus NP, they all look like that. You only have to look-- somewhere in that paper, there's going to be a statement along the lines, ""to solve this problem, clearly you have to do it this way."" And that's the flaw in the reasoning. Because just like"
2162	for the factoring problem-- just like for the compositeness testing problem, you don't necessarily have to solve it by searching for factors. There might be some other way to do it. You might be able to solve the Hamiltonian path problem without searching for Hamiltonian paths. There might be some other process that you can use, which would give you the answer. The class of polynomial time algorithms is very rich, can do many, many things. And I wanted to present to you one of the most important polynomial time algorithms. In a sense, you can make a certain argument that this is the most fundamental polynomial time algorithm. Some people might argue with me on that. And that's a process called dynamic programming, which I'm sure some of you have seen already in your algorithms classes, and some of you may not have. Since you have a homework problem on it, I want to spend a little time describing it to you. And that's useful for solving this A CFG problem, which you may remember from the first half
2163	of the course, involving testing if a grammar generates a string. So you remember this A CFG problem? You're giving a grammar, context-free grammar, and a string. And I want to know, is it in the language of the grammar. So that's going to turn out to be solvable in polynomial time, but only with kind of a clever algorithm. Remember, it's decidable. We decided it by making sure that you are converting the grammar in Chomsky normal form. Then all the derivations have a certain length. You just try all the possible derivations of that length, and you accept if any of those derivations generate w. You may remember that from the first half of the course. That immediately gives an NP type algorithm for this language. Because basically, you non-deterministically-- instead of trying the most sequentially, all of these derivations, you try them in parallel non-deterministically. So non-deterministically, you pick some derivation of that length. And you accept it if it generates the input. This classically fits our model of NP. You can think of it as guessing
2164	the derivation and checking that it works. Or, in parallel, writing down all possible derivations. But this A CFG problem is classically an NP problem, a problem in NP. And if you just imagine-- then what's going to be the certificate? If you found an input that's in the language, that's generated by the grammar, the certificate is the derivation. So if you look at it that way, you might think, well, that's the best you can do. This is going to be an NP problem, in NP, and is not going to be a way of avoiding searching for the derivation. But that's not true. There is a way of avoiding searching for the derivation. You can build up the derivation using dynamic programming. And so that's what I wanted to describe for you, how that works. Also partly because it's a homework problem. And I think dynamic programming is a very important algorithm. Before we describe what dynamic programming is, which is very simple, by the way, let's try to work up to it by making an attempt
2165	to solve this problem just using ordinary recursion. How would we solve the A CFG problem? So you're given grammar, you're given an input. Let's assume the grammar is in Chomsky normal form. That's going to be useful. So it's a Chomsky normal form grammar. And we want to see how to test if you can generate w. And it's going to be recursive algorithm. The recursive algorithm is going to actually solve something slightly more general. I'm going to give you the grammar. I'm going to give you the string. And I'm also going to allow you to start at some other variable besides the start variable. I'm going to give you some variable, R, and I know I want to know, can I generate w starting at R? So that's my slightly more general problem, which is going to be useful in the recursion. So the input now to this algorithm is the grammar, the input, and the starting variable. And now how is the algorithm going to work? It's going to try to test, can I get
2166	to-- is there some derivation, pictured here as the parse tree, for w starting at R? That's what the algorithm is trying to answer. Can I get w from R? The way it's going to do that is it's going to try to divide w into the two strings in all possible ways. Which sounds like it might be exponential, but it isn't. There's only a polynomial number of ways to divide the string into two substrings. Just of order n, just depending where you make that cut. So that's not too bad. There's a polynomial, there's only n ways of making that division. And also I'm going to try every possible rule that comes from R that generates two variables. So these are what's allowed in Chomsky normal form, R goes to ST. For each possible way of cutting w into x, y, and for each possible rule, R goes to ST, I'm going to see, recursively, can I get from S to x, and from T to y. So I'm going to use my recursion now. Now that
2167	I have smaller strings instead of w, I can apply recursion and try to answer it that way. And this algorithm will work. If I found a way to cut w into x, y, and I found a rule, R goes to ST such that S generates x and T generates y, then I'm good. I know I can generate w from R. And if there's no way of cutting w up to satisfy that, or if I can't find any way to divide w into x, y, and a rule R goes to ST which makes this work, if all possible ways fail then you can't get from R to w. And then you can decide the original A CFG problem now, by starting from the start variable, instead of just any old R. You plug in the start variable for R. So this algorithm works, and it can be used to solve A CFG. But the question is, is it polynomial? And it's not. Because every time you're doing the recursion, you're essentially adding another factor of n.
2168	Because here, as we pointed out, this is a factor of n. But that's happening every time you're doing a recursive level. And you can imagine, I'm just doing a very crude analysis here, depending upon how you divide w up. But roughly speaking, it's going to get divided in half each time, so there's going to be log n levels. So that means you're going to be multiplying n by itself log n times, or give you an n to the log n algorithm. That's not polynomial, because polynomials end with a constant, for some fixed constant. n to the log n is not going to be polynomial. This is not a polynomial algorithm. Instead, you're going to have to do something just a little bit more clever. It's going to be the same basic idea, but relying on one little observation. And the little observation is that when-- this non-polynomial implementation that I've just described is actually pretty dumb. Because it's doing a lot of recomputation of things that it's already solved. Why is that? Because if you
2169	look at the number of possible different subproblems here, once I give you G and I give you w, how many different subproblems of G, S, and T are there? The number of strings here, all of those strings are going to be substrings of w. There's only roughly n squared substrings of w. I'm always going to be generating, in a subproblem here, some substring of w from some starting variable in the grammar. So because there aren't that many different substrings, and not that many different starting variables, the total number of possible problems that this algorithm is going to be called on to solve is going to be, in total, a polynomial number of different subproblems. There aren't very many of them. It's only something like order of n squared. So if the algorithm is running for exponentially long time, it's solving the same subproblem over and over again. That's dumb. Why don't you just remember when you solve the subproblem, so you don't solve it again? Doing that enhanced recursion where you remember the problems you've
2170	already solved, it's called dynamic programming. I don't know why it has such a confusing name like that. Actually it's called by several different things. But anyway, that's known as dynamic programming. It's recursion plus the memory. And here is just repeating myself. There are not very many different substrings, so every time in your recursion somewhere, you're going to be working with a substring. So there's not that many different subproblems that you can possibly solve. And just remember when you solve the subproblem, and not solve it again. Let me just show you that algorithm again here, with the little modification. So first of all, let me give you-- this is the same algorithm from the previous slide. I'm just repeating it here without all the other stuff so we can look at it directly. Dividing it into x and y for each possible rule. And then recurse. I'm going to add a little step 0 beforehand, which says, if I have G, w, and R, let me just check first if I've already solved that one before.
2171	So I have to keep track of the ones I've already solved. That's not too bad, because there's only order n squared possible different ones that I could be called on to solve. So I'm just going to have a little table where I'm going to remember those. And then every time I get a new one, I get one to solve, I'll check. Is it on that table? And what's the answer? So I won't have to rerun those. I'm going to be basically pruning that tree so that it has only a polynomial number of leaves. And so the total size of that tree now is going to be polynomial. And so that's going to yield a polynomial running time. This, by the way, I only learned this myself, I'm sure you guys all know this who have taken this in the algorithms course, has a special name called memoization. Not memorization. Came from the same root, I think, but memoization, which is somehow remembering the results of a computation so you don't have to repeat it. The
2172	total number of calls is going to be, at most, n squared, to this algorithm, because you're never going to be redoing work that you've done already. And when you actually have to go through it, the running time-- the total amount of time that you're going to need is going to be polynomial altogether.
2173	Oh yeah. This is somehow related. And feel free to ask questions too, while you're thinking about this check-in. But the check-in says here, we've solved the A CFG problem in polynomial time. Does that tell us that every context-free language itself is also solvable in polynomial time? Just mull that over, and please give me an answer to it. I hope you do better on this check-in than you did on the last one. But anyway, why don't you go ahead and think about that. I can take some questions in the meantime. Somebody is asking here-- actually, I'm getting several questions on this. Why isn't it order n cubed or something greater than order n squared because of the variables? The variables don't depend on n. When you're given-- well, actually that's not true. No. You are right. Because the grammar is part of the input. So you might have as many as n different variables in the given grammar. So you are right. There is potentially-- the grammar might be half the size of the input, and
2174	the input to the grammar w might be half the size of the input. So I didn't think about that, but you're correct. There are potentially different numbers of variables in different grammars, so you have to add an extra factor, which would be at most the size of the input, because that's as many variables as you could possibly have. So it really should be, I think, order n cubed to take that into account as well. Plus all of the work that needs to happen in terms of dividing things up. On a one-tape Turing machine, there's going to be some extra work just to carry out some of these individual steps, because with a single tape things are sometimes a little awkward. I think the total running time is going to end up being something like n to the 4th or into the 5th on a one-tape Turing machine. But that's a good point. Somebody's saying, how can we be storing n squared strings in finite time? I'm not saying finite time. We have polynomial time. Every
2175	stage of this algorithm is allowed to run for polynomially many steps. As long as it's clearly polynomial, we can just write that down as a single stage. Part two should say-- oh. There's a typo here. So use D. Thank you. That is a typo. I'm afraid if I change it on my original slide here, things will break in some horrible way. Let's just see. Did I completely wreck my slide? No, that's good. Yeah, thank you. Good point. Oops. OK, how's our check-in doing? I think you're just about all done. Spent a lot of time on this. End polling. As you may remember from the first half of the course-- so the answer is A, indeed. Remember that we showed A CFG is decidable, and therefore each context-free language itself is decidable, just because you can plug in a specific grammar into the A CFG problem. The very same reasoning works here. If you have a context-free language, it has a grammar. You can plug that grammar into the A CFG problem. And then, that's polynomial
2176	time, you're going to get a polynomial time algorithm for that language. Good to review that. It's the same thing, same argument we used before. I don't want to spend a lot of time on this. There's another way of looking at dynamic programming. We'll talk about this again maybe in a lecture, probably next lecture, just because I you have a homework problem on it. If you've seen dynamic programming before, this is going to be easy. If you haven't seen it before, it's going to be, I think, probably a little challenging. Another way of looking at dynamic programming is the so-called bottom-up version of dynamic programming. And what that would mean is, you solve all of the subproblems first. You solve all the smaller subproblems before you solve the larger subproblems. It's here on the slide. I'm not sure I want to talk it through. But basically, you solve the subproblems here where, start with strings of length 1, and then from that you build up to subproblems with the substrings are of length 2, and then
2177	3, and so on. And each of those only relies on the smaller previously solved subproblems. So you can, kind of in a systematic way, solve all the larger and larger subproblems for larger and larger substrings. That gives kind of a different perspective on dynamic programming. And for different problems, sometimes it's better to think about either this sort of top-down recursion based process, or the bottom-up process that I'm describing here. They're really completely equivalent. The version that's described for this particular algorithm, which appears in the textbook, is actually the bottom-up algorithm. So you shouldn't be confused if you see something there which looks somewhat different. You basically solve all possible subproblems, basically filling out a table. Let me not say anything more about that here, since we're running a little short on time. There are really two perspectives on dynamic programming. So moving on from there, let's shift gears. Leave context-free languages and dynamic programming behind. And so I'm moving toward understanding P and NP. And for that, we will introduce a new problem called the
2178	satisfiability problem. And that's one we're going to spend a lot of time on. If you tuned out a little bit during the dynamic programming discussion, time to get back on board. The satisfiability problem is going to be a computational problem that we're going to be working on. And it has to do with Boolean formula. So these are expressions, like arithmetical formula, like x plus y times z, but instead of using numerical variables, we're going to be using Boolean variables that take on Boolean values, true, false. Or sometimes represented by 1 and 0. The operators that we're going to be using are going to be the and, or, and negation operations. And, or, not. I'm going to say such a formula, such a Boolean formula, we're going to call it satisfiable-- we'll do an example in a second-- if that formula value evaluates to true if you make some assignment of values to its variables. So just like arithmetical formula will have some value if you plug in values for the variables, Boolean formula is going
2179	to have some value if you plug in Boolean values for its variables. And I want to know, is there some way to plug in values which makes the whole thing evaluate to true. The formula itself is going to evaluate to either true or false, and I wanted to evaluate to true. Here is our example. Let's take the formula, phi, which is x or y, and x complement-- or, not x or not y. So the notation x with a bar over it, x complement, is just x bar, not x. It's just the way if you're familiar with the other notation, the not operation, which just inverts 1s and 0s. We're going to write it with a bar instead of the negation symbol. I'm assuming that you've all seen Boolean algebra, Boolean arithmetic before, where the and operation is only true if both inputs are true. These are going to be binary and operations and binary or operations. Or is going to be true if either input is true. And not is true if its single input
2180	is false. Oops, just looked at the answer. Here I want to know, for this Boolean formula, here is it satisfiable. Is there some way to assign values to the variables to make this formula evaluate to true? So for example, let's just try things. Let's make x and y both true. So x is true and y is true. So x or y, well that's good, that's true. But now we have to do an and, so we need both sides to be true. So now we have x complement-- well we said we said x is true, so x complement is false, y complement is false. False or false is false. So now we have a true and false. That's going to be false. We did not find a satisfying assignment. But maybe there's another one. And in fact, there is. If you make x true and y false, then both of these parts will evaluate to true, and then you'll have true and true. So we found a satisfying assignment to this formula. It is, in fact,
2181	satisfiable. So if you say x is 1 and y is 0, yes. This is satisfiable. Now the problem of testing for a Boolean formula, if it is satisfiable, is going to be the SAT language. It's a set. It's a collection of satisfiable Boolean formula. And testing whether you're in SAT or not is going to be an important computational problem. There was an amazing theorem which really got this whole subject going, discovered independently by Steve Cook in North America and Leonid Levin in the former Soviet Union, almost exactly at the same time, which made a connection between this one problem and all of the problems in NP. By solving this one satisfiability problem in polynomial time, it allows you to solve all of the problems in NP in polynomial time. So if you could solve this problem set in P, then Hamiltonian path is also solvable in P. If you step back and think about that, it's kind of amazing. And the method that we're going to introduce is called polynomial time reducibility. Let's do a
2182	quick check-in on this. This should be an easy one. Why don't you just think about, is SAT, the SAT problem that we just described here, is that in NP? Three seconds. You all there? OK. Ending polling. Hopefully you're getting the intuition for NP that these are the problems-- to be in NP means that when you're a member of the language, there's a short proof or a short certificate of membership. And in this case, the short certificate that the formula is satisfiable is the assignment, which makes it true, also called the satisfying assignment. So yes, this is an NP language, language that's in NP. There are a lot of things that we don't know in the subject, but this isn't one of them. We do know that SAT is in NP. So let's talk about our method for showing this remarkable fact that, if you can solve SAT in polynomial time, then all of NP is solvable in polynomial time. And it uses this notion of polynomial time reducibility, which is just like mapping reducibility that
2183	I hope you've all grown to know and love in the first half of the course. But now, the reduction has to operate in polynomial time. So it's the same picture that we had before, mapping A to B, transforming A questions to B questions. But now the transformation has to operate quickly. And we get that if A is polynomial time reducible to B, and B is polynomial time, then A is also polynomial time. Same pattern as before. If A is reducible to B and B is easy, then A is easy. Here is kind of the essence of the idea, or at least the outline of the idea of this Cook and Levin theorem. That if satisfiable is in P, then everything in NP can be done in P. Which is because, we will show that all problems in NP are polynomial time reducible to SAT. That's the amazing fact. So therefore, if you can bring SAT down into P by using this reduction, it brings everything else along with it, everything is reducible to SAT. So
2184	we just have to show how to do that. There is an analogy that we had in the first half of the course, in one of our homework problems, if you may remember. We showed that A TM has the very special property that all Turing recognizable languages are mapping reducible to it. I think that was problem 2, or 2a, either in problem set 3 or problem set 2. I think problem set 3. That every Turing recognizable language is polynomial time reducible to A TM. And so, very similar picture. And there's a lot of analogies here that you can draw between the computability section and the complexity section. With that, I know we're just about out of time. So let's just quick review of what we've done here. I will stick around for questions for a while. Is there a-- OK, that's a good question. Is there a regular reduction analogy version to mapping reducibility? We had the general reduction for the computability section. And we had the mapping reduction for the computability section. Here, we're only
2185	going to be focusing now on the mapping reduction. So polynomial time reduction is, by assumption, going to be a mapping reduction. Yes, there is a general polynomial time reduction notion as well. This is not required, but if you are curious about the general reduction and how to precisely formulate that, it actually appears in chapter 6 under Turing reducibility. That's the general notion of reducibility spelled out in a formal way. And there's polynomial time Turing reducibility as well. We're not going to talk about it in this course. Other questions? Does NP correspond exactly to verification in polynomial time? For me to answer that as a precise question, we have to have a precise definition of verification. But with the right definition, the answer is yes. So you can define a verifier as a polynomial time algorithm that gives a certificate, that takes a certificate and an input to the language, and will accept if that certificate is a valid certificate for that input. This is actually discussed in chapter, I think, 9 of the text. Now
2186	I'm forgetting already, what's where in the book. But yeah, you can think of NP in terms of verification as the definition. Is proving P equal NP the same as proving that a polynom-- actually, I can even make the-- if you want, you can post public comments too. I should have done that in other cases. Is proving P equal NP the same as proving that a polynomial time non-deterministic Turing machine N has a polynomial time deterministic? Yeah. Suppose we prove that P equals NP, which is the minority view, I would say, the small minority view. There are some people who believe that that is entirely possible, and might even be the case. But that's a very small group. But yeah, if you prove P equal NP, that's the same as saying that every non-deterministic polynomial time Turing machine is going to have a companion deterministic polynomial time Turing machine which does the same language. That's exactly what it means. Bye bye, everybody.
2187	[SQUEAKING] [RUSTLING] [CLICKING] MICHAEL SIPSER: Let's get back to space complexity. So just to review what we've been doing from last lecture, which feels like a long time ago but it was only two days ago, we were looking at those three theorems, which all had basically the same proof. One was about the ladder problem, where you're trying to see if you can get from one string to another string changing one symbol at a time. And all of the strings were in the language of some finite automaton, or you had some reasonable rule for saying which are the valid strings, which are not. And then we built on that idea. We showed Savitch's theorem, that going from any nondeterministic machine to a deterministic machine only squares the amount of space. And then we finally proved that TQBF, this problem about quantified Boolean formulas, testing whether they are true, that that problem is complete for PSPACE. So we're going to build off of that last theorem today, and talk about one other complete problem, and also show a
2188	connection between PSPACE and testing which side can win in certain kinds of games. And then at the end of the lecture, the second half of the lecture, we'll talk about diving deeper into space complexity. We're going to talk about a different part of the parameter space where instead of looking at polynomial space, we're going to talk about what happens if you have logarithmic space, which is another natural point to look at for space complexity. But we'll get to that after the break. Talk about game complexity and games-- so when I was little, we used to play, me and my sisters, would play a game called Geography. I don't know how many of you have heard it or maybe it goes under a different name. But it was a game basically about words and places. And it has a very simple set of rules. Let's say there were two people. You take turns picking names of places. And then each person has to pick a place which starts with the letter that the previous person's place
2189	"ended with. So for example, you have two people playing. Perhaps you agree on some starting place like a major city nearby, like Boston. So one player, the first player, picks Boston. And then after that, the next player has to pick a place that starts with N, because Boston ends with N. And so maybe Nebraska would be a possible response to Boston. And then the first player would have to respond to that with a place that starts with an A, because Nebraska ends with an A, maybe Alaska, which also starts with A, ends with A. So then Arkansas, maybe, would be a reasonable response to that. And then that ends with S, so San Francisco, and then so on, and so on. And of course, you want to forbid people from reusing names because then you'll just get into a loop. Saying, ""Alaska,"" ""Alaska,"" ""Alaska,"" won't make the game very interesting, so you have to forbid that possibility. Names cannot be reused. They can be used at most once. And then, eventually, one side or the"
2190	other is going to run out of names and not have-- either because of the lack of their geographical knowledge or maybe you've just exhausted all the possibilities-- and will not have a good response. And that person will be stuck. And that person is the loser. The other person has won the game. So the objective is to try to avoid getting stuck. So let's just take a look. I'm going to think about that game in a slightly more abstracted, formalized way. So you write down all of the legitimate places. They become nodes of a graph such as I've shown here. And then you draw an edge from one node to another if that corresponds to a legal move in the game, a legal step of the game. So Boston connects to places that start with N, like New York and Nebraska. So the first person might pick Boston. The second person might pick either of these two, and then back to the first person. If they picked Nebraska, they could pick Arkansas. They can pick Alaska,
2191	"and so on, just as I described. Believe it or not, we actually played this game. I can remember playing this game when I was a kid. That was, of course, before we had ""League of Legends"" and other fun stuff, but this is what kids used to do. So anyway, just to get it down on the slide, the rules are-- assuming we have two players, we'll call them Player I and Player II. Player I goes first. And they take turns picking places that start with the letter which ended the previous place, no repeats allowed. And the first player stuck loses, the person who doesn't have a move to make. So what we're going to look at today is a generalized version of that, where we're just going to take away the names, but just leave the underlying graph."
2192	"So here, that can be played on any directed graph. You take away the names of the nodes. Now you just have some arbitrary graph. You're going to designate a particular node as the starting node. And then the players take turns following those edges. And because you're going to forbid having any loops reusing any nodes, what you end up doing is, working together, you're going to be constructing a simple path in that graph. Simple path just follows those edges and never intersects itself. And the first player to be stuck is the loser. So the other one is the winner. So we're going to call that ""generalized geography."" And we're going to look at the computational complexity of deciding, for a given graph and starting point, which side would win if both players played optimally, the best possible. And we'll name that problem GG, or look at its associated language. So here is a graph and the starting node. And you want to say that pair is in the language GG if the first player, Player I,"
2193	who must play at that node A to start off with has a forced win in that generalized geography game on that graph starting at A. Again, what I mean by a forced win-- I'm not going to define this formally, though we could do that-- it's not hard to do.
2194	"That just means that if both sides play optimally, they play the best possible-- not of their capability, I mean absolutely the best possible play-- then that Player I would still win. There's nothing that Player II can do to prevent Player I from winning if Player I has a winning strategy or a forced win. You may have seen, for example-- there are examples of this that-- I mean, I don't even know if they still exist, but it used to be in the newspaper. There used to be examples of chess boards and they would start from a certain position. And they would say, ""White to win in three."" And so that means white has a forced win. No matter what black does, white is going to end up winning. But you have to think of what the strategy is. It may not be so obvious to think through what are the right moves that white makes. But the point is that no matter what black would do, white would end up winning. And what you can show--"
2195	we're not going to do that-- but for a class of games that includes this generalized geography, either one side or the other is going to be guaranteed to have a forced win. That's not necessarily true for all possible games, obviously, but for a large class of games, one side or the other is guaranteed to have a winning strategy or a forced win. So let's just review that, because this is going to be essential for the first half of the lecture-- to understand what we mean by a game and what we mean by one side or the other to have a forced win. And what we're going to show is that GG is PSPACE complete, that the problem of given one of these graphs and a starting point, figuring out does Player I have a forced win or is it Player II that has a forced win? Which side is guaranteed to win under optimal play? That's a PSPACE complete problem. And so let's do a little checking on that. And so I'm going to give
2196	you a very small example of a generalized geography game. You have to figure out whether it's Player I or Player II that has the forced win, the winning strategy, or maybe neither, or both. Those are the four options. And you understand Player I has to play here, because that's the starting place of this generalized geography game. So then it's up to Player II to continue on. All right, so let's launch that poll. You'll have to think about it a little bit, and let me know what you think. Which side has a forced win? Which player makes the first move? It's Player I makes the first move, and Player I plays, as I showed you here, this is Player I playing at A. So Player I picks A, and then Player II has to pick one of these two. All right, I think we're the end of the poll. Everybody's in? Pick something. You guys did not do well on this poll. At least not too many of you picked D. That's a little reassuring because
2197	you can't have both players having a forced win. I did say that in games of this kind, one side or the other is going to have a forced win, so C is not a very good choice, either. So maybe you should spend less time reading your email and more time listening to the lecture. The actual correct answer is B. Player II, which obviously is a minority position here-- Player II has the forced win. Let's understand why. So Player I plays here. As I said, that's the first move. Player II can either take the upper node or the lower node. Player II takes the upper node, then Player I has no choice but to take the right-most node, and now there's no more move for Player II. So Player II will lose if Player II takes the upper node, the upper choice there. Because Player II will go here, Player I will go there, and it'll be game over. And Player I will have won because Player II was stuck. However, Player II had another choice.
2198	"Player II could have also gone down here. So Player II, if it played down here, things are looking a lot better for Player II. If Player II goes here, Player I's move is forced, goes here. But now, there's another move left that Player II could make. So Player II goes here, I goes there, Player II goes up there. And now Player I is stuck. So it's Player II's choice, Player II can make a move which will end up causing Player I to get stuck, because that's the nature of what we mean by having a winning strategy. There is some way to guarantee if you're playing optimally, and you're certainly playing optimally, means you'll take that lower move. Then you will take that. So under optimal play, Player II will win this game, and so Player II has a winning strategy. It has a forced win. So I see. So I'm not going to define ""playing optimally."" There's some questions here about that. I'm going to-- I'm going to leave it somewhat informal, but we could"
2199	make that all precise. I don't think it would be clarifying to go through a precise definition of that. We don't even have to think about it in terms of optimal play. You can say that a player has a forced win if they have moves that they could make in response to every possible move the opponent could make that will guarantee that they will end up winning. So you don't even have to talk about optimality here. Just talk about every possible opponent. Every possible opponent is going to lose to somebody who has a winning strategy and follows that strategy. I can see there was some confusion about who was going first and so on. I'm glad. That was part of the reason I gave this check, just to hopefully to clear up some of those points. So Player I plays here then Player II goes. And I got some comments that some people were confused about what does it mean where does the first person move. Hopefully, that's clearer. All right, so let's move on because
2200	"we're going to be spending a while proving something about generalized geography in these graphs. So let's continue. So in order to make the connection between games and complexity, we're going to need to talk about a problem, one related to one that we've already seen, where we can reformulate that problem as a game. And that's going to be a problem on quantified Boolean formulas called the ""Formula Game."" So this is a different game now, not one that you're likely to end up playing. But in a sense in which you'll see, this is still a reasonable game where two players can play against one another. And one of them is going to end up winning and one of them is going to end up having-- one or the other will have a winning strategy. So let's understand what the game is. The game is played on a formula. So you write down a quantified Boolean formula. Remember, we talked about that for several lectures now. It's a bunch of quanti-- variables with quantifiers. And then there's a"
2201	part that has no quantifiers, which you can always put into conjunctive normal form if you want. But for the purposes of this discussion so far, it doesn't matter. Later on, we'll actually want it to be in CNF. But for now, we just have some formula. And associated to that formula there is a game, in a very natural sense. So first of all, there are going to be two players. But now the names of those players are going to be Player Exist and Player For All. And this is how the game goes-- both players are going to be picking values for variables. They're going to say variable x1 is true, variable x2 is false, variable x3 is false, variable x4 is true. And that's how the moves of the game go. They're just assigning values to variables so that in the end, all of the variables have been assigned a Boolean value. And so we end up with an assignment. But before we get to that stage, which players get to pick which variables? And the
2202	way it works is the Exist player is going to assign values to the Exist variables. So Exist will pick x1 and x3 and assign them values. The For All player is going to assign values to the variables that have a For All quantifier attached. So in this case, the For All player will pick the value for the x2 variable. Fading out here.
2203	And the order of play is according to the order of the appearance of the qualifiers in the formula. So the way I have it written out in this particular formula, it's Exist x1-- so Exist will pick the value for x1. Then For All's turn. For All will pick the value of x2. Then it's going to be Exist picking the value for x3, and so on, until they get to the end, and all of the variables have been assigned to value by one side or the other. And now the game is over. So what's left is to understand who has won at that point. And the way we say who has won is Exist wins if in the end, this part psi, which is the part without quantifiers, ended up being satisfied by that assignment that the two players together ended up picking. And then For All will win if that part of the formula is not satisfied. So let me just write that down here. After the variables have been assigned values, we determine the
2204	winner. Exist wins if the assignment that built cooperatively together satisfied psi, and otherwise For All, if it doesn't satisfy psi. So think about it this way-- Exist is picking the values of those variables. He's trying to make this part of the formula satisfied, trying to satisfy this part of the formula. For All is picking values, but she's trying to make this part of the formula unsatisfied. So they're in opposition to one another. And in the end, one of them is going to have succeeded and the other one will have failed. And now, thinking about it as a game, depending upon the formula, one side or the other is going to have the ability to dominate the other one and always win. And so the question is, which side has that ability to always win? Which side has the winning strategy? Of course, it'll depend upon the formula. Some formulas, it'll be the Exist player who has the winning strategy. And other formulas, it will be the For All player who has the winning strategy. And
2205	computationally, we'd like to make that determination. Which side is going to win for a given formula? And there's a very, very nice, and actually very easy and simple way to understand that because we've already run into that problem before. The problem of determining which side has a forced win is exactly the same thing as determining whether this quantified Boolean formula is true because the Exist player has a forced win when that formula-- let me say it again-- the Exist player has a forced win when that formula is true. So if this quantified Boolean formula were a true quantified Boolean formula, then Exist is guaranteed to be able to win that game if it plays its hand right. If this is a false formula, the For All player will always be able to win if it plays its hand right. So why is that? It really follows kind of almost without doing any work at all. This proof, even though it looks superficially like it might be not so easy to prove, it follows for a
2206	very simple reason because the meaning of what it means for Exist to have a winning strategy is exactly captured by the semantics of the quantifiers. Let's see what that means. What does it mean that Exist has a forced win, let's say up here? That means that Exist has a move that it could make, that Exist can pick some value for x1-- so there was some way to assign x1 so that no matter what the opponent does, no matter what For All does, there's going to be a response that Exist can make, some assignment to x3, so that no matter what For All does, there's going to be an assignment to the next variable, and so on and so on, so that this thing ends up being true. So let me just say that again somehow. I didn't feel it came out very clear. So Exist has a winning strategy exactly when there is some assignment to x1 that Exist can make such that no matter what assignment that For All makes to x2, there is
2207	"some assignment x3 such that no matter what assignment that For All makes to x4 and so on, makes this thing true. That's what it means for Exist to have a winning strategy. That's exactly what the quantifiers are saying in the first place. So even really without doing anything, you can see that ""Exist has a winning strategy"" means exactly the same thing as the quantified Boolean formula being true. So making the test of which side has a winning strategy is the same as testing whether the formula is true. So let me try to turn to the chat before we move on to anything else. Here we go."
2208	and about the alternation of the quantifiers here. So the way I'm showing it is that the quantifiers always alternate-- Exist, For All, Exist, For All. That doesn't really matter. You can have several Exists in a row, and that would correspond to Exist making several moves in a row before turning it over to For All. But alternatively, we could just add extra variables which don't play any role in psi. And they're just kind of dummy variables that serve as spacers so if you have two Exists in a row and you don't like that, you can just add a For All of some variables that you never see again in between. So you can always get it to be alternating if you want. OK, also question-- the difference between phi and psi. So psi is the part here that does not have any quantifiers. So the way we always write down our QBFs is they're leading quantifiers with the variables, and all variables have to be within the scope of one of the quantified variables. So there
2209	are no free variables that are unquantified in our QBFs. And so all of these QBFs have a run of quantifiers and then a part without quantifiers, so the Boolean logic part. Psi here is the Boolean logic part. And phi is the whole thing together with the quantifiers. So I'm not sure I understand some of these-- why not have the For All player have a forced win? The For All player might have a forced win. One side or the other is guaranteed to have a forced win. So if Exist does not have a forced win, then For All will have a forced win. I'm not going to prove that. That's a fairly simple proof by induction, which I'm not going to go through. Just take it as a fact. Somebody is asking, why does For All want to not satisfy this expression, the psi part? Well, that's the way we set up the game. In order to make this correspond to TQBF, just the truth of this expression, we want to make Exist try to satisfy
2210	this part and For All try to make it not satisfied because that's what works. I'm not sure what else, what other why I can answer there.
2211	Somebody is asking, how do we know how many variables to use? So the variables are the variables of the formula. So somebody is going to hand you a formula. That's going to have x1 to x10, whatever that formula has, some number of variables. And so that game is going to have 10 moves. If the quantifiers alternate, then the moves will alternate, but whatever the pattern of the quantifiers is going to be the pattern of the moves. So Exist is going to follow the places where the Exist quantifier occurs, and For All is going to follow the places where the For All quantifier occurs. So if you have Exist, For All, Exist, For All, Exist will move first, then For All will move, then Exist will move, then For All will move. Together, they're picking values to their respective variables with their opposing goals. Exist is trying to make the psi part satisfied. For All is trying to avoid making it satisfied, to make the assignment not satisfy that part. And if you think about what
2212	that means, just in terms of the meaning of that, it's going to mean exactly the same thing, that the formula is true. So anyway, if you don't-- let's see. I don't know if there's any more questions that I can try to answer here. It's still about the numbers of variables. Each formula is going to define a different game. You see the formula. So the formula, however big-- it may have 50 variables, it may have two variables. Well, we'll do an example. Maybe that'll help. The next check in, which is coming up pretty soon-- might actually be now-- we'll give you an example. So we'll see who is understanding and who is not. So let's continue here. So therefore, the problem of determining does Exist have a forced win is exactly the TQBF problem, because Exist has a forced win exactly when the formula is true. And what we're going to show is that TQBF is a polynomial time reducible to generalized geography, but conceptually, we're going to think about TQBF now as a game because
2213	that's how generalized geography is set up. So given a formula like this, we're going to construct an instance of generalized geography. We're going to construct a graph where play on that graph is going to mimic play in the formula game. So making the moves in that graph are going to correspond to setting variables true and false because the graph is going to be specially designed to force that behavior. So I think we have a check-in coming in. Yeah, so let's just see how-- I suggest you pay attention to this check-in, really try to think about it and solve it, because I think that'll help you make the connection between the truth of the formula and Exist having a winning strategy. So if you take this formula here-- this is some particular formula, Exist x for all y, blah, blah, blah. There's going to be associated to that formula, a formula game where first Exist moves, assigns a value for x, and depending upon that value, For All is going to move and is going to
2214	assign a value for y. And after that's done, this part here is either going to be true or false, is either going to be satisfied or unsatisfied. And I want to know, can Exist always find a way to guarantee that this part is going to be satisfied, or can For All always find a way to guarantee that this part is not satisfied? So you have to look at this formula to understand which side is going to end up succeeding. So if you're not clear on the rules, look back here. Exist is trying to make this part satisfied. For All is trying to make this part unsatisfied. But they neither of them has the totally upper hand, because Exist is picking one of the variables, For All is picking the other variable. But they're doing it in a certain order. First Exist is going to pick, then For All is going to pick. So that's the way the game works-- Exist picks a value, then For All picks a value, and then you see who wins.
2215	So who wins? Who's guaranteed to win? Can we make sure that Exists always wins or can we make sure that For All always wins for this particular formula? So there's just two variables here. You can think about this in either of two ways-- strictly speaking, purely as a game, or you can look at, understand whether that formula is true or not. They're equivalent ways of looking at the problem. In fact, in a certain sense, it's the same. That's what I'm trying to get across. Thinking about this as a game or thinking about it in terms of quantifiers-- it doesn't make any difference. Almost done here. So all right, last call. Closing the poll. I think this one you got. You did pretty well on. So the correct answer is the For All player has a winning strategy, has a forced win. And also, similarly, the expression, phi is false. Because if you try to find some x such that no matter what y you pick, this is going to be true, this is going to
2216	be satisfied, you're out of luck. Because if you make x true, well, then-- now I'm confused. What is going on. If you make x true, then x bar is false, so y bar has to be true. Now I'm completely confused. Oh, no. If you make x true, you have to work For All y. So this thing is clearly false. If you make x true, then this x bar is going to be false, and it's not the case that for every y, setting for y-- because y is forced here. y is going to have to be true. y bar is going to have to be true, so y is going to have to be false. So if you try again to make x false-- maybe that's one to think about first-- if you make x false, you're going to be stuck on the first clause because it has to work for both settings of y. But maybe thinking about it as a game is better. No matter what x does, y is going to have a
2217	way of making one of those two clauses unsatisfied. So if x is true, we can set y to make the second clause unsatisfied, and if x is false, y can be assigned to make the first clause unsatisfied. So anyway, the right answer is the For All player has the winning strategy here. And at the end of the day, it's not critical that you understand this correspondence, but you have to then, if you don't quite understand that, you're going to have to take on faith that the formula game is the same as TQBF because that's what we're going to use. And by the way, I would like to also mention here that this correspondence between games and quantifiers is something that mathematicians use all the time. Because if you have some expression which comes up often in mathematics, where there are a whole run of quantifiers in front of some statement, it's really kind of hard for anybody to really get a feeling for what that means. If you have six alternating quantifiers, which happens often
2218	in mathematics-- you're going to have statements that have a lot of alternations with quantifiers-- very hard to get a feeling for what that means. But if you think about it as a game, it's much more intuitive. And it's completely equivalent to think about quantifiers. Go back and forth between quantifiers and games. Anyway, let's look at the reduction, the construction that shows generalized geography is complete. A little longer than I thought-- I just want to make sure everybody is with me on this. So why don't we call the break now, and then we'll come back and we'll look at the construction after that. Because the construction itself is going to take about 10 minutes to work through to, figure out how to reduce TQBF and build a graph that simulates the formula. So I'm going to move right on to the-- and we'll come back. So feel free to ask some questions and get ready for us diving in to a construction for the reduction of TQBF to generalized geography. So it is an interesting question
2219	"about what's the relationship between a formula and when you swap the order of the quantifiers. The questioner is asking, does that somehow relate to negating the quantifier-free part, the part without the quantifiers? And I don't think that that's the right correspondence. There actually is some relationship. When you say ""there exists for all,"" it's actually a stronger statement than saying that ""for all there exists."" And in general, that actually implies-- exist x for a y implies for a y there exists an x, because what you're saying is that if there exists an x for a y, there is one x that works for every one of the y's. If you're saying for a y there exists an x, the choice of that x can depend on the y. So there is a connection, but you have to think through what it means in order to understand that connection. You won't need to know that in order to process what we're going to be doing, but maybe it just helps you think about it. Other questions here."
2220	I think we're out of time here. So let's return to our lecture. So I'm going to go back. Hopefully that won't crash everything. There we go. So now we're going to be reducing TQBF to generalized geography. Are we all together now? OK. So I'm going to illustrate this construction, which is a very nice construction, by the way. I'm going to illustrate this construction just by doing an example, or a partial example, but I think it'll give you the idea. So you understand what I'm trying to do here, is I'm starting off with a quantified Boolean formula. So here it is. I'm going to assume it's in conjunctive normal form, which I can always convert it into that form, maybe by adding some additional variables, but without doing anything too drastic to it. And so now, starting from that formula, I'm going to now build a graph, where playing the geography game on that graph-- which is, remember, taking turns, picking nodes which form a path-- is going to correspond to playing the formula game, which
2221	is picking the variables of that formula. And then you want-- if the Exist player wins in the formula, then Player I is supposed to win in the geography game. So here is how the graph is going to look. So try to follow this. So there's going to be kind of two parts, one that's going to correspond to the variables, and the other part that's going to correspond to the clauses. And so for each variable, I'm going to have a diamond structure here. So there's a little starting thing that's going to be unique to the first variable. But then every variable is going to have a little diamond structure here. And they're going to be attached one to the next. And we'll understand what this means when we play geography on this piece of the graph, but let's just understand the structure first. So this is the start node. And now, here Player I is going to play the role of Exist. Player II is going to play the role of For All. And in fact,
2222	I'm going to identify that. So I'm going to call-- because it's going to be helpful just to think about Player I as being the Exist player. So the Exist player is going to be playing on this graph. The Exist and the For All players are going to be playing on the graph. It's really just Players I and II. So the Exist player, Player I, by the rules, has to pick the start node. And now it's Player II's move, the For All player's move. Now, if you're with me on this graph, the For All player's move is now not very interesting because it's forced. It has to go to here, because again, they're just picking the nodes of a simple path in this graph. So the For All, Player II, the For All player, has to go here if Exist started over there. Now it's the Exist player's turn. And now something interesting happens. The Exist player has a choice-- it can either go left or right. There are two possibilities. And then after that, the
2223	For All player's turn, who is, again, just forced. So far, For All has not had much interesting stuff to do in this, has not had to think hard. So no matter whether Exist went left or right, the For All player's move is forced and ends up over here. And now it's this player's turn. And again, this is kind of an easy one. Oh, before I do that, let's just look at how that play could go. So the first two moves, as kind of I was suggesting, Exist goes here and then For All goes there. I'm going to illustrate possible plays through this graph by tracing them out in green. So now Exist goes here, For All goes there. Those were forced. But now, the Exist player goes, could either go this way or could go that way. So those are two possible different ways of playing the game that we're building. And now, whose turn is it here? This was the For All player picked this one, so the next turn is the Exist player,
2224	and that's forced. But now notice-- now for the first time, the For All player has to think, because the For All player can either go left or right, so could either go left, or it could go right. And so then there's going to be a sequence of these diamond structures, where they're constructed so that alternately either the Exist has a choice or the For All player has a choice, until you get all the way down to the bottom. That is the graph we've built so far. Now, if we stopped here, then whoever ended up at this point, whether it was Exist or For All, would be the winner because there's nowhere for the opponent to go. Of course, that wouldn't be very interesting. So there's going to be more stuff we're going to add on, which are going to correspond to the clauses. Now, how to think about what's happened so far? Maybe some of you might be guessing that when the Exist player over here has a choice, could have either gone left or
2225	right, that's going to correspond-- because this is supposed to be mimicking the formula game-- that's going to correspond to the Exist player in the formula picking the variable either true or false. So to the left or right is going to correspond to true or false. And so let's just arbitrarily say left is going to correspond to picking it true and right is going to correspond to picking false. So the way I've set it so far is Exist ended up picking the first variable false, then For All picked the second variable false. And the nth variable also got set false. Everything got set false so far. Who knows what happened over here, of course-- so just to understand what we've done so far. Now I'm going to show you how to build the rest of the graph. So let's take away the green part. And now we're just back to the construction. The green part is actually how you use that construction. So back to the construction here-- now, what do we want to achieve? By
2226	the time the players on the graph have got down to here, they've effectively made an assignment to the variables by going either left or right at each one of these diamonds. So the assignment is done. From the perspective of the formula game, the game is over, and now one side or the other has won. Here, we want to build some extra structure here as a kind of an endgame, to make sure that the For All player gets stuck if the Exist player has made an assignment which satisfies this part of the formula. And the Exist player should get stuck if the For All player, if the assignment that they made does not satisfy the formula. So let's see how we're going to achieve that with some additional structure. So there's going to be some extra node over here. Let me just tell you what the structure is, and then we'll argue why it works. So going from this bottom node, we're going to start the second part of the graph. There's going to be a
2227	node which fans out to a node for each one of the clauses. And each one of those clauses, in turn, fans out to a node for each one of its literals. So you see we have clause c1, and it has the literals x1, x2 bar, x3, x1, x2 bar, x3. So there's a node for each of the literals in clause c1, same for clause c2, and so on. Now we're almost done. Now I'm going to tell you how to connect up these literal nodes. So x1, each node is going to correspond back to its own diamond. So now we're going to tie it back to the first part, where we made the assignment part of the graph. x1 is going to connect back to the true part of the x1 diamond. And x2 because, it's negated, is going to tie back to the false part of the x2 diamond because it's an x2 variable. Similarly, x1 bar-- because x1 bar-- here's x1 bar in clause 2-- x1 bar is going to connect up now to
2228	the false side of the x1 diamond. And x2 bar is going to connect up to the false side of the x2 diamond, and so on. I don't have the other diamonds here, but the x4 would connect up to the true side of the x4 diamond, for example. That's the whole construction. Let's understand why it works. So the endgame here is we want Exist to win if the assignment satisfied all the clauses. And For All should win if there was some unsatisfied clauses. So why does this happen? So let's put back an assignment here that was made. So the one I'm putting back, the assignment that they cooperatively built had x1 being true, x2 being false, and some other stuff. Now, why does this work? So what we want to have happen now-- so now, the move proceeds over to here, and you need to arrange it so that Exist is the one who picks that node. If this would have been For All, just add an extra node to switch whose turn it is. But
2229	"you want Exist to be up here. And what you want is for For All to be picking the clause node. Now, here is the part to understand what's going on-- we want For All to win if this is not satisfied. So For All is going to make a claim. If it is not satisfied, there is some clause which is not satisfied. There's some clause which ended up being false in the assignment. So the For All player going to say, ""I think I won. And I won because clause number 1 is unsatisfied."" So it's going to pick clause number one. So here's the For All player's [INAUDIBLE].. Here's Exist player. And so the For All player picks the clause claimed unsatisfied. So over here, For All player says, clause c1 is unsatisfied. I'm going to move here. Exist player says, ""Uh-uh, I don't agree with you. The assignment, your line-- the assignment actually makes one of the literals true in clause c1. Let's say you made x1 was true, as in fact, it is here-- x1,"
2230	in fact, is true. So Exist is now going to pick the literal that was true in the assignment in that clause, that the For All player is claiming is unsatisfied. One of them is lying at this point. This is either now true in here, which means the For All player did not pick an unsatisfied clause, or the Exist player picked the false literal, which is the Exist player picked the false literal so the Exist player is lying.
2231	if Exist picked here, now it's the For All player's turn. It's connected back to the true side of the diamond. So that node was already used. That's the only place that For All could possibly go. For All is stuck, and Exist has won the game, which is what you want because For All's claims are false and the Exist was correct in saying that x1 satisfied clause c1. So x1 is true, so there's nowhere for For All to go. But compare that with the situation if the assignment, on this part of the graph, had gone through the false, had assigned x1 to be false, so the path had gone through the For All side of the diamond. Now this node would still be unoccupied, would still be available. So now the For All play-- so if Exist was claiming that x1 was true and it really was false, the For All player would be able to move onto that node. And now it's the Exist player's turn, and the Exist would be stuck because this node
2232	down here is guaranteed to have been used. So that is the idea. It's really very beautiful, and actually not that complicated. You have to stare at it a bit. So let's just see what happens, for example, if I had one other case-- maybe it's not necessary at this point, but if the For All player claimed it's the second clause which is unsatisfied in the mutually selected assignment, then-- so this is sort of the case where the For All player is correct, in that if the Exist player now says, well, I think x1 bar satisfied that second clause, but this assignment made x1 true, so x1 bar is false. And so the Exist player's lying this time. And so now the For All player can take this last edge and go here, and has one last move to make. And then the Exist player's stuck. So the For All will win in that case. So let's turn now, shifting gears entirely to a different part of space complexity. Instead of looking at polynomial space, which is
2233	very powerful, we're going to look at log space, which is comparatively speaking much, much weaker. So log space are the things that you can do when you only have enough space to write down, essentially, a pointer or some fixed number of pointers into the input. That's what you get when you have logarithmic space, because log space is enough to write down an index of something. So this is what you can do with a bunch of pointers. And in order to make sense of this, we have to change the model of computation. Because if we use the ordinary one-tape Turing machine, just scanning across the input, just reading the input the way we've defined it, would cost space n. And so you can't even read the input if you have less than n space available, like log space. So we're going to introduce a different model just to allow us to define this. And that's a model where it's going to have two tapes, where the part that contains the input doesn't count. And in order
2234	to make sure it's not being cheated, the input tape is going to be read only, but it doesn't count toward the space used. Only the work tape, which now can be written or read, is going to count toward the space bound. So now what we're going to define is,
2235	we'll define SPACE log n, the things that you can do if you have only a log amount of space here, on the work tape. So the length of the input is n. The length of the work tape is order log n. So we have the deterministic and nondeterministic associated classes-- SPACE log n and NSPACE log n. We're calling it L and NL-- log space and nondeterministic log space. And as I said, that's just enough space to write down some pointers into the input. And let's do some quick examples. So if you take the language of palindromes, essentially, or ww reverse, that's in log space. So here is a string. Here's a string that's in ww reverse. And the ordinary way you might use to test whether a string is of this form in ww reverse might be to cross off corresponding locations here. But you can't do that. It's a read-only input tape. So you have to somehow avoid writing on the input tape, but still testing whether you're in this language. It's not hard
2236	to do. You can use the work tape just to keep track of where your pointers would be. And in so doing, you can just make sure you're matching off corresponding locations with each other in the input. So log space, because of its ability to store some fixed number of pointers, gives you enough to test membership in this language.
2237	The path problem, which we've seen before-- you're given a graph, and a start node, and an ending node, or a start and a target. You're given a graph of an s and t-- it's a directed a graph-- and can I know, can I get from s to t? So that problem is solvable in nondeterministic log space because the way we would do that, not writing this down in any detail, but what you would do in your nondeterministic log space machine-- you have your input graph written here in the input, and you're just going to guess the sequence of nodes one by one, which takes you from the start node to the target node. You're not going to write down that whole sequence in advance because that cost you way too much space to write down. The only space that you're going to use is to remember the current location where you're sitting. So you start out, you write down on the work tape the start node. Then you're going to nondeterministically pick one of the
2238	outgoing edges from the start node and look at its associated node, and replace that on your work tape, and keep repeating that. If you ever get to the node t, then you can accept. And you also have to be a little careful-- I don't have this on the slide. You also have to make sure that if the graph has a loop in it, because that's not allowed in space complexity, so you're going to need also a counter to make sure that if you count up to-- you've gone through a number of nodes which exceeds the total number of nodes in the graph, then you can shut down that branch of the nondeterministic, because it's just going in a loop. If there's any path that connects s to t, there's certainly going to be a path that has the most of the number of nodes of the graph in it. So path is in NL. This language here is in L. What's the relationship between L and NL? Well, certainly the deterministic class is contained in
2239	the nondeterministic class. That's all that's known. Whether these two collapse down to be the same is unsolved. And so we're going to spend a little time next lecture exploring this. But let's first look at some of the basic facts about log space, sort of setting ourselves up for next lecture. So first of all, anything that you can do in log space you can do in polynomial time-- in a sense kind of trivially, and in a sense we almost kind of really proved this already. Because if you remember, we said that anything that you can do in a certain amount of space you can do in time that's exponential in the amount of space, in the corresponding amount of space. So going from space to time blows you up exponentially. And the exponential of order log n is polynomial. So the way we're going to prove this-- and again, we kind of proved this already but let's just go through it again, specific to log space. We'll say-- and this is going to be a useful
2240	definition for us anyway-- a configuration for M on w. So we also already talked about the configuration of the Turing machine M, which is just a snapshot, which is the tape, the state, and the head position. When we have an input, which is sort of a read-only input, which is not being counted toward the space, we don't include that in the configuration. We just say it's a configuration of M on that particular input, but we're going to be counting configurations. And I don't want to count all the different inputs as well. I'm going to fix the input and count all of the configurations relative to that input. And so the number of such configurations is just simply going to be the number of states times the number of head positions for the two heads now, times the number of possible tape contents, which is, as I mentioned, here is a number of different possible tape contents. It's d, which is the tape alphabet, to the order log n. And that's just going to be n
2241	to the k for some k. So it's going to be polynomial. So that tells us that because the total number of configurations for M on w is polynomial, this machine can only be running for a polynomial number of steps. Otherwise, it'll be looping. It'll be repeating a configuration. And so therefore, that machine has to run itself in polynomial time. So you don't really, in a sense, have to do any work. If a machine is deterministically deciding a language in log space, it's also deterministically deciding the language in polynomial time because that's all the time you can use when you have log space, unless you're looping, which is not allowed. So therefore, the same machine shows that you're also in P. I'll get to that in a second. One thing I forgot to mention on the previous slide when I'm talking about the model is by the way, this model is not so unreasonable, where you have kind of-- imagine having a very large, read-only input and your local storage is much smaller. It's much too
2242	small to pull in the entire input. The way I used to explain this years ago was your input as a CD-ROM, which you guys probably barely even know what it is anymore, but you used to distribute software that way. So the ROM was on a DVD or a CD, which contained whatever you're trying to-- like your software you're trying to distribute. It was some large thing, relatively, and so you imagine having a smaller amount of memory relative to that. So you didn't want to necessarily copy that whole thing into your storage. Maybe even a better example now is you think of the input as being the entire internet. Obviously, unless you're Google, you can't download the whole internet into your own local memory, but you can have references, pointers into the input into different places. That's perhaps more analogous to this sort of read-only input Turing machine model that I'm describing. And there's another fact that I want to mention, is that anything that you can do in nondeterministic log space you can do in
2243	deterministic space, but now with the squaring. And that's using the same proof. That's using Savitch's theorem, which you have to check also works down to log space-- same proof. So anything that you do nondeterministically in log n space you can use deterministically in log squared n space. So let me just see if there's a couple of questions I want to answer here. The relationship between L and NL is not known to be strict. Nobody knows of an example. No one knows whether they're equal. And have people looked at sublinear time classes? Yes, generally when you have nondeterministic or probabilistic-- which we haven't defined yet, but we will-- people have looked at those sublinear time classes as well. Deterministically, it doesn't make so much sense because then you can't even talk about the whole input. OK, let me move on. This is my last slide. Let me see if we can do this before we break. Not only is L contained within P, but the much stronger statement is that NL is contained within P. And
2244	for that you'll have to do some work because converting your nondeterministic log space machine to a deterministic machine-- obviously, you're going to have to change the machine. And so we'll introduce a new method here. Maybe we'll quickly go over this at the beginning of the next lecture. I don't like rushing through things at the end. But for this, if I'm given a nondeterministic machine that runs in log space, I want to make a new machine that runs in polynomial time deterministically for the same language.
2245	"called the ""configuration graph"" for M on an input w. And that's just you take M and w, its input, and you look at all of the configurations for M on w-- actually, configuration-- actually, that should be called the ""computation graph."" That's what it's called in the book, but it's a typo. Yeah, I'll fix that next time. It doesn't matter. Computation graph, configuration graph, all the same. Basically, you're going to take all of the configurations of M on w, of which we already observed are only polynomial in number. And they become the nodes of a graph. And the edges connect two configurations if one follows another according to the rules of the machine. So here's a picture. This is some graph. The nodes of this graph are the configurations of M on w. So each node here corresponds to a snapshot of the machine, a tape contents, head position, and state. So writing down all those different configurations, I connect one to the other, if I can get to C j from C i in one"
2246	step legally on the machine. And then, the nondeterministic machine M accepts w exactly when there's a path from the start configuration to an accept configuration. Let's assume we have just a single accept configuration, as we argued we can do one or two lectures back, if we clean up the tapes. So testing whether you can get from the start to the accept is the same as testing whether the machine accepts its input. And so because we can test whether there's a path in a graph connecting two nodes in polynomial time, we can solve this problem on this computation/configuration graph in polynomial time. And so we can figure out whether the nondeterministic machine accepts its input. Sorry, that came a little faster than I like to do,
2247	So here's the polynomial time algorithm. You construct the graph, you accept if there's a path from the start to the accept, and you reject if there is not. And so that tells us that not only is L contained within NL, but NL itself is also contained within P. So here's a kind of a nice hierarchy of languages. Not only do we not know whether L equals NL, we don't know whether L equals P. It's possible that anything you can do in polynomial time, you can do deterministically in log space, shocking as that might be, because this is a pretty weak class. But we don't know how to prove that there's anything different, anything in P that's not in here. Last check in. So we showed that PATH is in NL. What's the best thing we can do about the deterministic space complexity of PATH? So deterministic. So this is nondeterministic log space. What can we say deterministically about PATH? Hint-- this should not be hard if you think back to what we've shown very recently.
2248	"Get your check in points. Closing up. Closing shop here. All set, 1, 2, 3. Yeah, so the correct answer is log squared space, because this is just Savitch's theorem. We can do it in log space nondeterministically, so you can do it in log squared space deterministically. So this is what we did today. And as I mentioned, I will do this again on Tuesday's lecture, just to recap that. All right, so I'll stick around a little bit for questions. And someone's asking me about the nomenclature. Why is it L and not L space? Because people don't usually talk about L time. So L is sort of-- everybody knows the only reasonable option is space, so people just say L and NL. I mean, some of these names have a little bit evolved over time. And even now, some people talk about-- I call ""time classes,"" some people call ""detime classes."" You can make different choices there. Let's see. Good."
2249	Why does Savitch's theorem work for log n? You have to look back and see what you needed. And all you needed to be able to do was to write down the configurations. And if you look back at how Savitch's film works, you're just needing to write down the configuration. So the deterministic machine can write down the configurations for the nondeterministic machine. They take exactly the same size. And then you look at the recursion. And the depth of the recursion is going to be exponential in the size of the configurations. And so you're going to end up with a squaring again. You have to go back and just rethink that proof. And you'll see nowhere did it need a linear amount of space. It works down to-- it actually does not work for less than log n. Log n is sort of the lower threshold there. And the reason for that is because you also need to store the input location, and that already takes log space. The tape heads-- the tape heads already kind have
2250	kind of a log space aspect to them. And so if you're going to use less than log space, then funky things happen with storing the tape heads. And so less than log space usually turns out not to be interesting, very specific to Turing machines and not general models. Yeah, so somebody's asking, suppose in the reduction to generalized geography from TQBF, if the formula had two Exists in a row, then you would do kind of the natural thing in the graph. Instead of having that spacer edge between the two diamonds, you could just have one diamond connecting directly to the other diamond without a spacer edge. And that would give you the effect of not switching whose turn it is. Somebody is asking me just a general question, are people thinking about these open problems? I don't know. People don't say. There was a lot of work on problems related, that seemed to be related to those many open questions, like P versus NP, L versus NL or L versus P and so on, P versus
2251	PSPACE. We'll talk a little bit more about some of that. There's some very interesting things that have been developed. I think there's a sense within the community that people are stuck, and you're going to need some sort of major new idea in order to push the thing forward. So I don't know how many people are still thinking about them. I hope people are because I would like to see the answer at some point, or get the answer. I think about them sometimes myself, but one has to acknowledge chances of success are not high. So we're a little after past the end of the hour here. Unless there's any other questions, if I didn't answer your question, I may have missed it, so you can ask again. But otherwise, I'm going to close this, close the session here. OK, bye-bye all. Have a good weekend. See you next week. Take care.
2252	[SQUEAKING] [RUSTLING] [CLICKING] MICHAEL SIPSER: OK, everybody. Let's begin. Welcome back. Good to see you all here on Zoom. So we're going to pick up with what we had been discussing last week, which was an introduction to NP-completeness. So we're following on our description of time complexity. We started talking about the time complexity classes, the class P, the nondeterministic classes, the class NP, P versus NP problem, and then leading to this discussion of NP-completeness. And today we're going to prove the big theorem in the field, which really kind of got things going back in the early 1970s by Cook and Levin that there was actually an NP-complete problem, that SAT in particular is an NP-complete problem. And then we'll also talk about 3SAT, which is a useful tool. Just to remember, we had this notion of NP-completeness. A language is NP-complete if it's in NP. And everything else in NP is polynomial time reducible to it. And if an NP-complete problem turns out to have a polynomial time solution, then every NP-problem has a polynomial time
2253	solution. And that's part of the importance of NP-completeness, because since we consider it unlikely that P equals NP, and that there probably are some problems that are an NP, but are not solvable in polynomial time. That would imply that an NP-complete problem would have that property. And so proving a problem being NP-complete is evidence, very strong evidence, that it doesn't have a polynomial time solution. And so therefore it's called intractable. It's a very difficult problem. So the way we are going to typically show problems NP-complete is by reducing a known-- a previously known NP-complete problem to that problem. Often it's 3SAT, as we've seen in several examples already, or it could be some other example. So let's just survey briefly the things that we've already-- languages that we've already seen, which are NP-complete.
2254	has a direct reduction from every NP problem. And so we're going to show that today, that every NP language is polynomial time reducible to SAT, which is, in turn, reducible to 3SAT. And we showed previously that 3SAT is reducible to CLIQUE and HAMPATH. And in recitation, if you went to that, they showed that the SUBSET-SUM problem and the undirected HAMPATH problems are also reducible from previously shown-- well, either from 3SAT, or in the case of the undirected HAMPATH problem, it's reducible from the HAMPATH problem. And the conclusion, once we have these two blue reducibilities shown, then we know that all of these problems are NP-complete. So the class NP basically breaks down into the NP-complete problems, P problems, problems that are in P, and then there might be problems in between as well. So there are some problems that are not known to be in either category. And in fact, there's an old theorem which shows that if P is different from NP, then there are actually problems that are in the intermediate state. And
2255	of course, it's possible that P equals NP, and then everything collapses down to be the same with the tiny exception of the sigma star and empty set languages, which can never be complete. OK. So that's our quick review. Here is a check-in that I'm going to use to get us ready for the big proof that we're going to be spending most of the lecture on about showing SAT is NP-complete, but just to define a little notation, which you might have-- maybe you've seen already. But I'm going to do it in the form of a check-in. So I'm sure you've all seen the big sum notation using a big sigma to represent a sum over some set of possibilities. Just as there is the big sigma notation, we have-- you can have other operations that apply to a set of elements. So in this case, we're going to be seeing the big end AND and the big OR operation-- it's going to-- notation, which is going to allow us to talk about taking the AND of
2256	many things or the OR of many things, because we're going to be building these Boolean formulas. And so ANDs and ORs are going to be the operations that we're going to be focusing on. And so just as an example just to make sure we're all understanding this notation, if you have two strings x and y written out in terms of their individual symbols. So they're both of length n. So x is x1 to xn. Y is y1 to yn. And now I write the following expression. The big AND for i ranging between 1 and n of xi equal to yi. If that big AND is true, what does it tell us about x and y? And I'm just going to offer you two possibilities, that either x and y agree on some symbol or are equal, namely that they agree on every symbol. And so let's just pull that up as a quick poll to get us going here. I just want to make sure you understand the notation because we're going to be using
2257	that a lot in describing the polynomial time reduction from languages in NP to the SAT language. OK. I think most of you have got the idea. So let's finish this up quick. So another 15 seconds, please, just to give you a chance to participate. OK. We're going to close this poll. Last chance, last call. All right. So yes, the big AND-- as most of you can see, the big AND says that x1 equals y1, and x2 equals y2, and x3 equals y3 so they're all-- every symbol in x is equal to the corresponding symbol in y. If we had a big OR instead of a big AND, then A would be the correct answer, because then just there would be some place where they agree instead of every place where they agree.
2258	The proof itself is a mass of details with one underlying idea. And in fact, it's an idea we've seen before. But let's-- before we get ahead of ourselves, let's just understand what we're trying to do. So we want to show that this language SAT is NP-complete. We remember what SAT is. It's Boolean formulas that are satisfiable. So we already showed that the SAT prob-- so being NP-complete means it has these two features. It's in NP, and everything in NP is reducible to it. So first of all, SAT is in NP, as we've already seen. The witness that shows the formula is satisfiable is simply the satisfying assignment that evaluates to true. So now we're going to pick some language in NP, A, and show that A is polynomial time reducible to SAT. So this is going to apply to any language A in NP. So let A be some language in NP. It's decided by some nondeterministic Turing machine M in time n to the k. That's what it means to be an NP. I'm
2259	going to be ignoring the constant factors when we could carry that throughout the proof. It just would make the description a little more cumbersome and wouldn't change any of the ideas. So let's just say it's M runs in time n to the k, and recognizes or decides this language in A. So it's a nondeterministic machine. So we've got to give a polynomial time reduction from A to SAT. That's what I have to demonstrate to you. So what does that reduction look like? It's going to map strings, which may or may not be in A, to formulas, which may or may not be satisfied. That's what the reduction has got to do. So saying that out more formally is it's going to take some string w and map it to a formula we'll call phi sub M, w, where M is the machine that decides A and w is the input. So f is going to map w to this formula, where the string is in the language exactly when the formula is satisfied. And the
2260	formula is going to depend upon M and w. That's why it just has-- it's written in this way. So we've seen that kind of thing before. So basically, my job-- we have this language A that's in NP. And now we have some string w, which might be in A, or maybe not is in A. And I have to quickly in polynomial time now produce a formula which is going to be satisfiable exactly when the string w is in A. So how is that formula going to work? How can I produce such a formula? Which I mean, of course, I don't know whether w is in A or not, because I'm just the polynomial time reduction. And A is an NP language. So polynomial time probably is not enough to solve whether w is in A. So I've got to do that mapping without knowing the answer. And the idea is that-- and this is where we've seen things like this before-- the formula we're going to construct simulates the machine on w. So in some
2261	way it's going to do that simulation. The trick is figuring out how to-- what that means. But the interpretation of that formula is that in a sense describes, says, in my informal language, that M accepts w. Very much like-- there's a lot of parallel here between this construction and, for example, the construction, the PCP construction, where we made an instant-- given a machine and an input, we made a set of those dominoes, where finding a match forced you to simulate the machine. Here finding a satisfying assignment is going to force you to simulate the machine. So the satisfying assignment is going to be a computation history for M on w. And I'm just going to write that computation history in a particular way. So it's going to have a somewhat different encoding, which is going to help us to visualize what's going on better. So that's the approach. That's the basic idea of what we're trying to-- what we're going to do. So I'm happy to take a minute if you have any questions about
2262	this part. But otherwise, I'll just move on to start doing the actual construction of what the formula looks like. How is it going to do that? How is that formula going to work? OK. So no questions.
2263	So first of all, let me describe what my computation history is going to look like. And the situation is a little bit different than what we had before because when we were talking about the Post correspondence problem we had a deterministic machine. And now our machine is nondeterministic. So we're going to call the object-- instead of an accepting computation or a computation history, we're just going to-- we're going to call it a tableau, or sometimes an accepting tableau if you want to emphasize the accepting nature of it. But generally, we're just going to call it a tableau. So a tableau is really an accepting computation history for the machine on an accepting branch of its nondeterministic computation. So if M accepts w, it's got to have some accepting branch, and the tableau is going to be the sequence of configurations that the machine goes through on that accepting branch. If there are several accepting branches, there may be several tableaus. There will be several tableaus. So there's going to be one tableau for each accepting
2264	branch of the machine's computation on w. If the machine does not accept w, there won't be any tableaus. And so the whole point is that we're going to make our formula represent the statement that there is a tableau. And satisfying that formula is going to correspond to filling out the symbols in the tableau to make it a tableau. So here is a tableau. So a tableau is just, again, an accepting computation history on some branch, some accepting branch of the machine's computation. The rows are the-- instead of writing the computation history out linearly, we're going to represent it in a table form where each configuration is going to be on a separate row. Now, the dimensions of that table are going to be n to the k by n to the k, because the machine runs for n to the k steps. So there's going to-- if there's an accepting branch, it's going to accept within that number of steps. And we'll have enough rows here to write down all of the configurations that the
2265	machine goes through one after the next, row by row, each one having a configuration in it. And then at the bottom, there'll be an accept. Minor detail, if the machine accepts earlier, we'll just say the machine stays in the-- once it enters an accept, the machine does not change from that point on. So the rule of the machine is nothing changes. And it just remains in the same configuration from that point on.
2266	So important to understand what we're-- if you're not following what I mean by a tableau, you're doomed for this lecture. So it makes sense for you to ask a question to understand what we mean by tableau. So just a few more elements here. So this is going to be the start configuration for M on w. This would be an accepting configuration here down at the very last row. And you might imagine-- I think I've filled out some hypothetical first step of the machine after the start where maybe the machine was-- when it's in-- remember how we encoded our configurations. So this is the machine is in state q0, looking at the w, the first symbol of the input, w1. And maybe when it's in q0 looking at that first symbol, it moves to state q7, and goes right, and then changes that w1 to an A. And so now here is the head shown moved one position to the right in the new state q7. I mean, of course, that depends on what the machine
2267	is designed to do, what the transition function is. But this possibly is what happens. So does the-- OK, so good. Does the tableau trace all steps of all branches? No. The tableau corresponds to one accepting branch. Each different accepting branch is going to have its own tableau. So there might be several different ways of filling out that second row even. Of course, the first row is going to be-- in any tableau, it's got to be the same. Once I know w-- here I've written down-- maybe I should unpack this for you. It's in the start state here, then here are the first-- here are n symbols of w, w's of length n. So there's w1, w2, up to wn. And then I'm padding out the rest with blanks. So I should have said that, too. But OK. So I want to make my table n to the k by n to the k because that's going to be enough to represent the entire-- all of these configurations of M running for most n to the
2268	k steps, because the machine, even if it sends its head moving to the right as fast as it possibly can, it's never going to have-- it's never going to go outside this box if it only runs for n to the k steps. So this is going to be big enough to represent the entire computation of M. So it means running for n to the k time. And the input w is of length n. All right. What is k? So k is the running time of the machine. So we assumed from the previous slide that M runs in time n to the k. OK. So a good question here. How can the tableau be a square table if we have a low number of computation histories, but a lot of tape? Well, the low number computation history, that's a problem. You're not saying that well. You know, each computation history is in a different table. So this, I'm representing a single computation history here. There may be-- there are going to be many configurations. So I
2269	can't have a small number of configurations using a lot of tape, because I can only use one more cell, one additional tape cell each time I-- each additional step of the machine. Yeah. So there's really no difference between this. If you want to think of this as a computation history, that's fine. This is really just the standard terminology that's used when you're proving this particular theorem. Typically people talk about it as a tableau, but it's really just a computation history. The q state-- I mean, the question about what are these states' q, this is the way we represent configurations. So this means the machine is in a state. They're not all going down the diagonal. The states are going to zigzag here through this picture here, depending upon how the head of the machine moves. So you have to go back and review how we represent the configurations of the machine. Remember the configuration is a snapshot of the machine at a given point. How do we know that M runs in polynomial time? We're
2270	assuming M runs in polynomial. We started off with a language that's in NP. So it's a nondeterministic polynomial time machine, and we're picking one branch that accepts and writing down all the sequence of configurations the machine goes through. Let's move on. And maybe ask more questions as they come to you, and I'll pick out some to answer if that's going to be helpful to others. So we're going to now construct this formula to say that M accepts w. Again, that was what we-- that's our goal. And it says that a tableau for M on w exists. And basically what that means is we want to say that it starts right, it ends right, and everything in between is right, and then we're going to need some other stuff to talk about how we're going to be encoding those symbols using Boolean variables. So those are going to be the four parts. Here's the start. It starts right. Here it ends right. Here it moves right. And here it talks about the encoding of the symbols
2271	into Boolean variables. So those are the four parts of this formula that I'm going to describe. I hope you got your question answered as to why the total number of columns is n to the k, because it's just big enough to fit the entire-- all configurations that the machine is running for at most n to the k steps, which is what we're assuming.
2272	So now just getting back to that, I'm going to describe these different components now on separate slides. Let me start out with this component phi cell, which is sort of the most fundamental one because it talks about how we're going to be encoding those symbols of the tableau into the Boolean variables.
2273	So again, here's kind of the picture to have in mind of this tableau, this n to the k by n to the k table, representing some accepting branch of the machine's computation if there is one. And so now let me draw one of the cells here. I'm going to magnify it. So this is the i, j cell here. And I'm going to-- there are going to be a collection of Boolean variables associated with each one of the cells. So each one of the cells is going to have a bunch of variables all to itself. And those are going to be basically indicator variables. They're going to indicate which symbol that cell gets to have in it. So again, picture here-- in this tableau, we don't know how it's going to get filled out. But however it gets filled out, each one of these cells gets some symbol. And that symbol could either be a tape alphabet symbol, or a symbol representing a state. That's the way we do our configurations. So it could be a
2274	tape alphabet symbol here showing the magnification. Maybe it's the tape alphabet symbol, which represents the blank symbol. Or maybe it's represents some state. Now, how am I going to encode that with variables? So this-- let me-- this is the collection of variables that's going to apply to the entire formula phi sub M, w. Each cell is-- so each cell i, j is going to have a set of variables, one for each possible symbol sigma that's in the configuration alphabet, namely a tape symbol or a state symbol. So I'm going to have-- well, maybe this will become clear as I'm writing it. So if I turn the variable x i, j, sigma equal to true, that's just a way of saying that cell i, j contains a sigma. So if I have x i, j, a, that means the symbol contains an a. So I'm going to illustrate that now for you. So imagine you have lights representing all the different x i, j's for the different sigmas. Didn't say that well. So we're in cell
2275	i, j. So these are all x i, j variables. They're all x i, j sigma variables for the different sigmas that can go in this cell. So all different possible sigmas. So this is gamma union Q. So now if I have an A here in that cell, so then the variable x i, j, a is true. And just helping you visualize that, that's going to correspond to turning the light on. There's going to be a light associated with each one of these variables. And it's going to be turned on when that variable is true. Similarly, if I have the blank symbol is the thing that goes in that cell, then that variable gets turned on. I hope you can see it. Maybe it's a little bit small on your screen. The x i, j blank, a variable is true. And similarly, if it's q7 here, the x i, j q7 variable is true. So that's the way we're going to be encoding the contents of these cells using these indicator variables. And now we have
2276	to start making some Boolean logic to make sure that those variables reasonably represent the cell con-- the contents of these cells. So for example, what would be the first thing that comes to your mind? Well, we better not have two lights going on in any one of the cells, because then we have two symbols in that cell. And that's not allowed. Each cell is going-- we want each cell to have exactly one symbol. And that corresponds to each cell having exactly one of its lights turned on, or equivalently, each cell should have exactly one of the variables be true. That's the very first part of the formula is just going to say that. So let me show you what that looks like.
2277	So here we're talking about this phi cell. It says that there's exactly one light on per cell, or in other words, exactly one of the x i, j sigmas is true for each i, j. So this is how I'm going to actually express that using my Boolean formula. I'm sort of color coding the different parts of the formula, which I'm writing out to you here in English. So first, I want to say this. So in every cell, there's at least one light that's on, and there's at most one light that's on. So here's the green part. This is going to say at least one light is on. So I'm going to say that by taking all of the var-- all of the symbols that can appear in that cell, and taking an OR over all of those different associated variables. So it's either got the first symbol on, or the second symbol is there, or dot dot dot, or the last symbol is there. One of those has got to be there. I'm going to
2278	write this using my big OR notation. So for sigma appearing in this set of possibilities, one of those variables has got to be on at least. That's what this big OR tells you. Now we want to make sure that there's at most one that's on. So that there are not-- there's at least one on, but there are not two that are on. So I'm going to have an additional part of the formula here, which says-- and I hope you can read this. It's a little small. If I have two different symbols, sigma and tau, that are configuration-- possible configuration symbols, where sigma and tau are not equal. So that's I'm reading it out to you if it's too small for your screen. Then I'm going to say it's not possible. So I have the negation of x i, j sigma, and x i, j tau. So saying it another way, it's not the case that that cell contains both sigma and tau for any two symbols sigma and tau as long as they're different. And
2279	we want to take these two formulas and add them together. And this tells me in the cell i, j, there's exactly one of the variables is true. Exactly one of the lights is on. And that's going to represent which symbol goes into that cell. And then I want to take the AND over all possible cells to make sure that I'm going to now apply that everywhere. And so now I do an AND for i and j ranging between 1 and n to the k to apply this logic throughout the picture. Yeah. Sigma unions-- asking sigma union Q contains the input, output, yes. This is not a sigma. This is a gamma. Gamma is the tape alphabet. This is any symbol, including an input symbol, from sigma is going to be in gamma. So this is any symbol can appear on the tape. And this expression here, that is the expression phi sub cell. So here's a little check-in for you. But maybe before we jump into the check-in, let's just make sure-- it may be
2280	better to take some questions, and then we can ask the check-in for you. Do you understand? I mean, if you're not getting this, you should try to figure out how to get it, because this is really just the foundation. It only gets more-- it is not a very complicated proof once you sort of get the idea of what's going on, but if you're not getting this part, you won't be able to get the rest. OK. I have no idea what the-- what that means, but I'll read it out to you guys. This looks like a one-hot tensor encoding, same from common-- same form commonly used in ML. OK. It's just an indicate-- I would just call them indicator variables. Why is it sigma union Q for the big AND here? Sigma union Q? You mean gamma union Q? [GASPING] This is wrong. OK. Now I understand why everybody is upset. This should be a gamma, not a sigma. There's a boo-boo. Sorry about that. I don't know if I can fix that without breaking the
2281	whole slide, so I'm not going to even try. This symbol here should be gamma, not sigma. It's a typo. Thanks for catching that. Yes. So the question is-- OK. So phi sub cell is just trying to make sure that the encoding represents setting a bunch of symbols into the tableau. Not-- so each cell is going to have one symbol exactly, not two, not zero. So that's what phi sub-- if you've satisfied, if you've set the variables to satisfy phi sub cell, then there's going to be one symbol on in each-- one symbol in each of those cells. Now, another question, this is not a CNF. No, this is not a CNF. That's the second half of-- that's going to be-- I hope we don't run out of time. But I have a way of converting general SAT formulas to CNFs and preserving satisfiability. So we're going to do that reduction afterward. Here's a little check to see if you understand at some level what's going on. How many variables does this formula actually have? Is
2282	order n? Order n square? n to the k? Remember, k is the running time of the machine. Or n to the 2k? What do you think? So I mean, for how many variables. I mean that in all of phi sub M. How many variables do we have all together in this formula if that's what the question is. And here are the variables. So describing them here-- x i, j, sigma. OK. I'm going to close this. So pick something. All right. Ending polling, 1, 2, 3. OK. Yeah. OK. That's a good question. So first of all, the correct answer is, in fact, D. It's order n to the 2k. Now, I'm getting some questions about, what about the size of gamma and Q? Well, those are going to be fixed. They depend only on the machine, but they don't depend on n. So thinking about it functionally in terms of n, that's going to be a constant multiplier. And so it's going to be absorbed within the big O. So that's why we have-- these are
2283	constant relative to n. These are fixed. There are not n to the k possible symbols. There's a fixed number of symbols. It depends only on the machine. So we're looking at a particular machine, and what happens when you look at large inputs. So why is D and not C? Well, don't forget-- how big is this table? This is n to the k by n to the k. So there are n to the 2k cells, n to the k quantity squared, or n to the 2k cells here. And so there's a collection of variables for each cell, some fixed number of variables for each cell. So that's why its order n to the 2k. Good. So let's move on. I think we're actually-- hold on. So we have one more slide, and I think then we have a break after. So now let's next talk about constructing two more pieces of the phi sub M, w formula. So we already got phi sub cell done. Let's look at phi sub start and phi sub accept. And
2284	phi start is going to tell us that the start configuration has exactly these symbols. And phi accept tells us that the bottom configuration contains an accepting state somewhere. So how are we going to write that down? Well, first of all, I'm going to write these down just cell by cell. So first of all, phi start is going to say the cell 1, 1 contains a q0. I mean, I know what the start configuration should be, because thinking of me, or think of us as the reduction, the reduction is given M. It's given w. So it knows what the start state is. It knows what the symbols of w are. So it knows what that start configuration is. It's just q0 followed by the n symbols of w followed by blanks. So it wants the very first cell in the left-hand corner here to be a q0, the start state of the machine, which it knows. So it's going to say x sub 1, 1, q0, that has to be turned on. So it's going to
2285	be AND of a bunch of variables here. And in order to satisfy phi sub start, all of those variables have to be set to true. So that means we have to have a q0 in that cell. So now we're going to do the next cell here. The 1, 2, the next cell of the start configuration. So phi start is going to have x 1, 2. So that's the next place. It contains w1. And so on. x 1, 3 contains w2, all the way up to wn, and then there's going to be a bunch of additional parts which say that we have blanks in the rest, just spelling out exactly all of the symbols in that top row. Because that's what the phi start formula, or sub formula of the overall formula we're making looks like. Now let's take a look at phi accept. Phi accept, because I'm just looking for q accept to appear somewhere in that bottom row, I'm going to do that in terms of an OR. So here is-- the variables now,
2286	notice, have n to the k because it's the last row in the table. So row n to the k here. And then I'm going to vary j from 1 to n to the k. So j, the column number, is going to range from 1 to n to the k. And I'm looking for that to accept. So x n to the k j, where j's vary, and q accept. One of those has to be true. One of those has to be turned on. And so that's why it's a big OR.
2287	And now we'll take a little break. And feel free to ask me some more questions. Let me just start our clock. Go grab yourself some coffee, or ask me some questions. I'm happy to answer them. Why don't we check that q accept only appears once? Is it possible for q accept to appear twice? That's a great question. So that would definitely be a broken configuration if that happened, because a configuration can have-- must have exactly one state symbol appearing. The way we're going to enforce that is with the phi move part of the formula, which we haven't seen yet. So phi move is going to guarantee that the machine is acting correctly, so that all of the rows of the tableau are all legal configurations, and they all legally follow from the previous. So really, in a sense, the hard-- heavy lifting is coming in phi move, but it's really not that bad. Somebody says, out of curiosity, how close is this intuition proof to the actual proof? This is the actual proof. There's no--
2288	I'm not hiding anything. I mean, we're being a little loose here, but you can turn this-- we're not cutting any corners here. This is exactly how the proof goes. And so not-- you're getting the real deal here. Somebody wanted to see the previous slide, so here we are. Whoops. Is there something you want to ask? So phi cell says there's exactly one symbol per cell. And the variables are set in a way in terms of thinking of them as indicator variables. There's exactly one variable set to true in each cell. So there's exactly one symbol per cell. That's what phi cell tells you. If you don't have that, then you have a mess. So you've got to start with that. And then with the-- other things are going to be additional conditions, which when satisfied are going to enforce the rest of the properties that we want. Why would the proof fail if we replace n to the k with 2 to the n to the k? So OK. I presume where does-- we'll just
2289	use the polynomial running time of the machine of M, the nondeterministic machine. I mean, if you had an enormous tab-- we have to show ultimately that this reduction is a polynomial time reduction. And that's going to depend on how big the tableau is, because that's going to tell us how big the formula we're producing is, phi sub M, w. If phi sub M, w is exponentially big, we don't have a prayer of being able to output that formula in polynomial time. If there were less than n to the k steps, do we repeat the last configuration? Yeah, that's what I said. If the machine ends early, the last configuration just stays there. So we're going to modify the definition of the machine slightly so it just stays. Yeah. OK. Yeah. Let me not take the other-- there's a bunch of other questions, some of them a little on the technical side. Let me-- maybe I'll try to address them as they come along if it turns out to work to do that. So the break
2290	is over. Why don't we-- is it possible that the encoding configuration will not fit in n to the k? So the question is, is there a possibility that the encoding of the configuration won't fit in n to the k? If the machine runs for n to the k steps, the configuration has to fit within n to the k, because it can't use anything more within n to the k steps. So think about it. But no. The answer is the configurations-- if the machine runs in time n to the k, that whole tableau is big enough to write down the entire computation history. All right, so let's continue. Phi sub move, this is, in a sense, the part which is going to tell us that we started right, we ended right. Phi cell says every cell contains one symbol. And now we have to say that the whole interior is correct. How are we going to do that? So these are the parts we've already done. And the way I'm going to describe that is in
2291	terms of these kind of little windows I'm calling neighborhoods. So imagine here we have a 2 by 3 rectangle, which I'm going to call a 2 by 3 neighborhood. And what I'm going to argue, but I'm not going to prove here. I'm just going to really state it, but it's really just a sort of more or less obvious fact. But the proof-- the book has the formal proof, that if any-- every one of these here is legitimate, is legal according to the rules of the machine, if every single-- imagine you have these-- oops. Let me put myself back on here so you can see me. If you have here every 2 by 3 window, you can take this as a window, and you slide that over the entire picture of the tableau. And everything here looks OK as far as the running of the machine. So I'll say what that means in a second. But if everything looks locally fine everywhere, then the whole tableau has to be a valid tableau in terms of the
2292	rules of M. Maybe it's easier if I describe what I mean by these being legal. So these neighborhoods, these 2 by 3 neighborhoods are legal if they're consistent with M's transition function. So I'm going to describe rather than-- I mean, to do this formally, I would have to go through a process that we went-- like what we did when we went through the construction for the Post correspondence problem, and say if the machine moves left, this thing happens. If it moves right, that's-- I think that it's not really necessary. You can kind of get the idea very clearly by doing it at a little bit of a higher level.
2293	So let's look at what I mean by a legal neighborhood. So a legal neighborhood is a setting of the values, the six values of this 2 by 3 neighborhood, in a way which doesn't violate M's rules. So for example, if M, when it's in state q7 reading of b, goes into state q3 and moves left, then this would be a legal neighborhood, because it shows the head moving left, the b becoming a c. So reading a b, I should also say that it converts that b to a c. And we just head left into state q3. So this would be a legal neighborhood if that's the way-- so being legal depends upon the transition function of the machine. So given the transition function, that's going to tell you which are the legal neighborhoods. So another legal neighborhood-- this would always be a legal neighborhood-- is that if nothing changes. So that means the head of the machine was somewhere else. And so whatever was on the tape in this step is going to be the
2294	same stuff in those places one step later. Here's another possible legal neighborhood. If the head suddenly appears on one of the cells either in the left or the right, that would correspond to the machine moving its head from somewhere off the neighborhood into the neighborhood in that step. So this could be a legal neighborhood, provided the machine actually does move its head left into a state q5
2295	And here is another kind of a weird legal neighborhood. If you have a, b, c, and then the a changes to a d, that could also be a legal neighborhood if the machine transition function allows an a to get converted to a d when there is some machine-- when there is some state reading that a, and that state also moves its head left. So it doesn't move into this picture. So those are examples of legal neighborhoods. Let me show you some illegal neighborhoods. Just I'm doing this-- this is kind of a proof by example now. This is perhaps the most intuitive part. But I claim that this is easy to turn this into something airtight and formal. So this would be clearly illegal. If you have a piece of the tape in the previous step where it's a, b, c, and then suddenly the b changes to a d. The symbol on the tape changes out of nowhere without having a head nearby to a different-- to something else. That could never happen. So that
2296	would be illegal. Another thing that would be illegal is if a state appears from nowhere. That could never happen. Or if it just disappears. That could never happen. And here's another-- here's an interesting one. If a state becomes two states. Don't forget the machine is nondeterministic. So the machine in principle could move its head left on one branch and move its head right on a different branch, but those would have to be in different tableaus. They can't be in the same tableau, because that doesn't correspond to any of the threads of the computation, those with multiple threads. And I say this because if you think about my claim, which is going to put down over here, that if every 2 by 3 neighborhood is legal, then the tableau overall corresponds to a computation history. This illustrates why it's not enough to have a 2 by 2 neighborhood, where you really need the 2 by 3. Because if this was a 2 by 2 neighborhood, if you just look at these four-- this leftmost 2 by
2297	2, that could be a legal neighborhood if it was a 2 by 2, if the rules of the machine allowed for that. And the right four box-- right four cells could also be a legal neighborhood. So you could have something that looks OK from the perspective of 2 by 2 neighborhoods, but globally, in terms of the overall tableau, it's completely nonsensical because it has multiple hits. But if you have a 2 by 3 neighborhood, it's big enough to prevent this situation from occurring. And then you can check the details. And I think it's very plausible that it guarantees that the overall tableau is legitimate if all of the 2 by 3 neighborhoods are legal. And so that's what we're going to turn into a Boolean expression. We're going to say for each cell that the set-- for each neighborhood-- so here's a neighborhood at the i, j location. I'm calling this position here sort of the home location for that neighborhood. For each neighborhood, it has to be set to one of the legal possibilities.
2298	And there's, again, only a fixed number of those because there's a fixed number of possible symbols that can appear in those cells. So this is that fixed number to the sixth power at most. And I'm going to say that the cell in the upper left, which would be this one, is in r. And this one here is an s. And this one is a t. And this one is a v, if you just trace down what the indices are telling you. It says that that piece of the tape, that piece of the tableau here is set according to one of the possible legal settings. And we're just going to OR over all of those possible fixed number of legal settings. And then I take an AND over all possible tape cells, over all possible neighborhoods. And so that's going to be my phi move. And that's it. OK. Let's see. Can I explain again the third example of illegal? So this one over here, I presume, I'm being asked about. Well, if the machine is
2299	in a state q7 reading a c, the head has to move either left or right. So at the next configuration, there's got to be a state symbol appearing either in this cell or in this cell. And here the tape-- the head has basically just vanished with nowhere to-- it's gone. That could not happen according to the rules of the machine the way we talk about Turing machines. So that's not possible. So this would be an illegal neighborhood. You want to prevent any of the bad stuff from happening anywhere in here. So only good stuff can be happening locally. And that guarantees the overall picture is OK. Do we have to check that the head doesn't leave the tableau from the left most to right right? Yeah, there are some little details here like that. So the question is, do I have to make sure that the-- yeah, you probably need to mark. I think the book probably does this correctly. You may have to mark the left and right ends to make sure that-- I
2300	mean, the right end is not a problem, because the machine can never go off the right end. And if you design the machine so that it never moves its head off the left end either, which you can do, then you wouldn't have to worry about that possibility. But otherwise, you would have to put some sort of delimiter here to enforce the head not moving off the left end. So there are some details like that, too. There will be two heads in the same row. No, this can-- I don't know what you-- somebody says, there will be two heads in the same row. Please elaborate, because this is designed not to allow two heads in the same row. Could I go over the OR for legal again? OK. The OR, the big OR here, what I have in mind is I take-- there's going to be-- first of all, I look at the machine and I look at the transition function. And based on that, I write down the list of all the legal 2 by
2301	3 neighborhoods. So all the settings which correspond to legal 2 by 3 neighborhoods. There's going to be some fixed number of those. 100. There's 100 possible legal neighborhoods of which I've written down here four. But maybe there's some number, say 100. So now there's going to be an OR over those 100 different possibilities. It's either going to be this legal neighborhood, or some other legal neighborhood, or some other legal neighborhood. And for each one of those legal neighborhoods, I'm going to say, well, the variables are set according to that legal neighborhood, or the variables are set according to the next legal neighborhood, or the variables are set according to the next legal neighborhood, and do that 100 times. One of those has got to end up-- I mean it's an OR, so one of them has to work. Otherwise, the formula fails. And it will be false, because you're going to AND that over all of the neighborhoods in the picture. Is it possible to have a head on the far left of the configuration
2302	and one on the far right? You mean a head over here and a head over there? I mean, how'd the head get there? It can't happen. You know, the head has to come from a head above it. If you're going to be worrying about the details of the boundaries here, all that's fixable. So let's not lose sight of the main idea. I mean, if you understand the main idea, you can fix the little details. So I want to make sure you understand the main idea of what's happening. So let's finish up this proof. So in summary, we gave a reduction from 8 to SAT. This is what we needed. It was in those four pieces. And you really just need to argue that that formula we're building is not too big. And it's going to be basically the size of the tableau if you look at what we constructed. The number of variables is roughly the size of the tableau. And the amount of logic that we're putting into the formula is also going to
2303	be a fixed amount of logic independent of n for each of the variables in that tableau. And somebody asked me about the size-- how big the indices are. The indices for the x i value, the i and j values, technically, they're going to be numbers between 1 and n to the k. So you're going to have to write those down. And so that's going to be a slight additional logarithmic cost to write those things down. It's not really that interesting a point. And so the overall f is going to be computable in polynomial time because the output is not very big. And it's also not complicated to write the output down. So that's the end of the proof. I can take a couple of questions. Why can't we just check that the whole-- this is a good question. Why can't we just check that the whole row is legal? You can check that a row actually is a configuration. But to check that the row follows from the previous row, ultimately, the operation of a
2304	Turing machine is a local thing. I mean, the way it moves from one configuration to the next depends locally on how where the head is. And so really, that's just another way of-- the way I'm saying it is just really checking the whole configuration, but just doing it locally. I don't know if that's satisfying to you. Why don't I move on because I just want to make sure we have enough time to get to the very last part, which is a little bit-- I'm afraid, a little technical. So we're going to kind of shift gears now and talk about reducing SAT to 3SAT. And let's see how it goes. I don't always have the most success with presenting this little piece, because it's slightly a technical argument. But if you don't get it, don't worry. Just you have to accept that it's true. But I'd like to show it to you just to make the whole presentation complete in that sense. So I'm going to give a reduction that maps general formulas to 3CNF formulas.
2305	So that's how we map SAT to 3SAT. If you remember 3SAT is satisfiability but for three CNFs. So a conjunctive normal form in the form of those clauses, which are ANDed together. And each clause is an OR of a bunch of literals, which are variables or negated variables. So I want to convert phi to phi prime, which is 3CNF formula, but preserve the satisfiability. And phi prime is not going to be logically equivalent to phi, because I could do that, too. I can convert any formula to a logically equivalent CNF formula. Maybe not even a 3CNF, but yeah, you won't be able to get a 3CNF, but you can get a CNF. But it might be exponentially larger. And that's not good enough. I have to do the reduction in polynomial time. So I can't generate a much larger formula that's exponentially larger. And so I'm going to do that by adding additional variables. So it won't be logically equivalent because the new formula is going to have additional variables in it. I'm going to
2306	kind of do it by example. And we'll see how that goes. So here's phi, which is not in 3CNF. It's not even in CNF, because it's got ORs of ANDs appearing, which is not allowed to happen in a CNF. So how are we going to convert that into a 3CNF formula preserving the satisfiability? And just working it through with this example, I hope to at least give you some idea of how you do the conversion in general. So first of all, I'm going to represent this formula as a tree using its natural tree structure. So you understand. So a AND B becomes a AND b written as a tree. And then I OR that with c. So I get the tree structure here in sort of the natural way. And I'm going to label all of these intermediate nodes, which are associated now with operations. And I'm assuming also that the formula is fully parenthesized so that each operation I'm only thinking about is applying just the two-- it's a binary operation. And let's ignore
2307	negations for the minute, because negations, you can always push those through down to the leaves. But it's just going to make it too complicated. So negations turn out not to be a problem. So there's only going to be negations at the level of the inputs, not at the negation operations in the middle. So we have this tree structure here. And now I'm going to use these two logical facts. And I don't know if-- you've probably all seen ANDs and ORs, I hope. Otherwise, it's going to be really tough. But there's also other logical operators, such as the implication operator, where you have A implies B sort of as a logical operation. And so this requires that if A is true, then B is true. However, if A is false, B can be anything. And similarly if B is true, A can be anything. The only thing that's prohibited is that if A is true and B is false. That's the only thing that would be invalid. And so if you think about it, that's going
2308	to be equivalent to saying that either A is false or B is true. One of those has to be. And that's going to be logically equivalent to saying that A implies B. Another logical equivalence may be more familiar to you. It's just simply De Morgan's law, which says that if you have the not of A AND B, that's equivalent to saying the not of A or the not of B. I'm going to make use of both of these. Now, here, I want to-- I ran out of room on this slide. So I'm going to take myself out of the picture here for a minute. I had no place else to put this. So here we have-- if you're going to think of the AND in terms of its truth table, so here's a and b in terms of a and b. So 1 and 1 is 1, but all other settings of a and b yield 0 for the AND. And I'm going to represent those-- if you imagine a and b is going to
2309	be called c. I'm going to represent this information with four small formulas, which taken together, you AND them together, are going to force c to have the correct behavior associated with a AND b. So if a AND b are both 1, then c is 1. If a is 0 and b is 1, then it forces c to be 0. And similarly, every other setting besides a AND b being true, for C to be false, which is what you want when you have AND. So I'm going to write this expression here down with z1 being in the place of c by just taking those four expressions and ANDing them together. So this is exactly those same four expressions written out linearly. Now I want to do the same thing for z2, but now that's written in terms of an OR. So there's a slightly different truth table here up in this corner. So now if either one is 1, we get a 1 result. And so now if a AND b are true, you get c
2310	is true. However, if a is true and b is false, that still implies c is true. So I'm going to write down those rules for specifying how z2 must be set. And each one of these things is going to get converted into clauses, three clauses with three literals, using these rules over here. So I'm going to do that for each zi. And lastly, to make sure the whole thing is satisfied, which means there's an output of one here, I'm going to have one clause associated, which says that z4, the output, is 1. Now, I can convert all of those when I have a AND b implies c. That's logically equivalent to not a OR not b OR c. And the way you can see that is really by repeated application of these rules here. We're running a little low on time. So maybe you'll just have to check this offline. But quickly, a AND b implies c using the first equivalence is the not of this part, OR C. And then I can use De
2311	Morgan to convert that not of an AND to an OR of the nots. And then I can remove the parentheses because OR is associative. And so I get a clause, which is what I need. So each one of these guys is really equivalent to a clause. And so I just get a bunch of clauses. And actually, technically, this needs to be three, a copy of three things here. It should be z4 OR z4 OR z4, which is a lot. So check-in-- [INAUDIBLE] I realize my check-in is broken, because I only realized that last point just now as I was talking. So the actual value that you get in terms of-- oh, no, the number of clauses is correct. No, I take it back. This is fine. So if you understood what I was saying, hopefully, you can see how big the formula phi prime is in terms of the number of operations in phi. So let's see how many people get that. I acknowledge this may be a little on the technical side. OK. I'm
2312	going to close it, close it down. Please enter your value. OK. Yeah, the correct answer is 4k plus 1, because each one of these operations is going to end up being a row in this picture. Each operation is going to have a variable associated to it. It's going to become a row in this picture. And so then each row is going to have four clauses, which define what you need-- set what you need in order to force that variable to have the right value corresponding to that operation. And so then you need-- and you need one extra clause here for saying that this whole thing evaluates to true. So that's all I wanted to do today. We proved those two main theorems. And now we know that there are NP-complete problems. And all of the other problems that we can get from-- by reductions from these problems are also going to be NP-complete as long as they're in NP. So that's it. Feel free to put some questions into the chat, or move on to
2313	whatever else you're going to be doing next. So a good question here is, why is phi prime not logically equivalent with this construction? It can't be logically equivalent. Logically equivalent means that it gives you exactly the same function. If you set the variables in the same way, you get the same result coming out. Well, phi prime has more variables than phi does. So it wouldn't even make sense to talk about logical equivalence because they're two functions on different numbers of variables. So in that sense, it doesn't really make sense. What you could say is that for every setting of the overlapping variables, so the variables that appear in both phi and phi prime-- so those are the original variables of phi-- there's going to exist some setting of new variables, which is going to make the-- there's going to be-- there will exist some setting of the new variables which will make the two formulas agree, but that's not the definition of logical equivalence. So why-- going back to the proof, the satisfiability proof and
2314	the legal neighborhoods, could I go over why the number of legal neighborhoods is polynomial. The number of legal neighborhoods is not only polynomial. It's constant. It depends only on the machine. It does not depend on M. Because each cell can have at most some fixed number of-- can have the number of tape symbols plus the number of state symbols. That depends on the machine only. So now we have six tape cells for the six cells in a 2 by 3 neighborhood. So you're going to have that number to the sixth power. But still, it's a constant to the sixth power. It's still a constant. It doesn't depend on M. So it's not a question of even being polynomial. It's a constant value. It's a constant multiplier if you want to think about it in terms of the size of the formula that's going to result. Don't forget we're trying to make a formula which is-- the reduction has to be polynomial. It's a polynomial time reduction. So that means that as n increases, the time
2315	to calculate the reduction increases as a polynomial. But we're fixing M. So M does not change. So therefore anything that depends on M only is just going to be a constant impact on the formula. It's not going to be-- it doesn't depend on M. OK, everybody. Bye bye. See you.
2316	okay welcome everybody so we are um here today lecture number 21 uh coming into the home stretch of the course uh i'd say probably um this last quarter of the class of the course is a bit more technical uh perhaps so a little bit more abstract some of the theorems are going to be more difficult um so i'll i'll try to work through them slowly and answer your questions but uh um you know it's i think you can expect them to find the material a bit more challenging as we started uh um [Music] uh as we started um um you know with uh this theorem last time uh uh uh non-deterministic log space being closed under complement so nl equals colonel we kind of only got about part maybe a third of the way through that so i'm going to start over with that and spend kind of the first half of the lecture today talking about that and then we're going to talk about the hierarchy theorems which are very important um uh aspect
2317	of the complexity landscape basically they tell you that if you allow you know your favorite model let's say turing machines to have more resources then they can do more things um but we'll get to that in due course okay so let us uh go back to oops reminder to myself um go back to the immerman celeb cheney uh which is that nl is equal to co nl um so as i mentioned these are going to be the same slides as last time uh and i'll just try to walk through them slowly um i hope hope i hope you i hope you uh get it but if you don't you know uh ask me at the ta's questions so we're gonna first i mean the the the the i the thing we're gonna show is that the complement of path is solvable in non-deterministic log space we already know that path is solvable in nl that's easy to do you basically just start at the start node and you guess the sequence of nodes storing only
2318	the current node in your log space working memory on the on your in your logs based work tape you guess the sequence of nodes on the different branches of the non-determinism and if you ever get to the target node t then you can accept um but how can a non-deterministic log space machine know or accept the complement of path so it would have to accept when there's no path um and that uh is a lot harder but it's a big surprise to the complexity community that it is it is true um so as we uh discussed last time we're going to talk about computing functions with a non-deterministic machine and that turns out to be a convenient way of looking at this so we're going to have non-deterministic machines that have different branches of their non-determinism you know on some input and they're supposed to compute some function value you know remaining on the tape but because of the non-determinism you can't imagine that different branches might have different function outputs well that's not allowed
2319	all branches must either report the value of the function um that we're trying to compute or they can punt basically they can reject and say well you know uh i i you know it's a basically i i don't know so all branches can must either report the correct answer or they can say i don't know and some branch must at least one branch must report an answer must report the answer um for and that's what it means to be computing a function with a non-deterministic machine and we're going to show that certain functions can be computed with non-deterministic log space machines um in particular this path function which sort of incorporates both the positive and negative of the pair both when there is a path and when there is an is not a path into into the function because the function has to answer yes when there is a path from s to t and no when there is no path from s to t okay so if you could do this you're done because
2320	um you can make a non-deterministic you could make an nl machine so if you could compute the path function you could make an nl machine which would accept whenever the function says no um and the other cases you know and if the um machine that's computing the function uh rejects you can then you'll reject as well but you accept if the function says no and so therefore you're going to be making a an nl machine which does the complement of the path problem so it's uh you know if you can compute the path function that would be great so that's what we would like to be able to do so as i mentioned we're going to have two other values that that are going to be relevant to computing the path function which is what we're ultimately going to do and that's going to be the number of nodes that you can reach from the start uh from the the start node in your graph and the and then for r is is the collection
2321	of nodes and c is the number of reachable nodes um so shown on this picture and here i'm if it's helpful to you to see it in a more form is you can think of r as a function of the graph and the start node of course but sometimes we'll just call it r you know when it's clear which graph and start node we're talking about r is the set of reachable nodes so it's the collection u such that the answer is yes and c is the size of r okay so the way we're going to start is kind of an easy theorem though this is still going to be relevant kind of at the end um but for now it's really more a practice with the concept that we have come up you know this function concept that we've just introduced so i want to say that the path function with an nl machine then i can compute the count
2322	okay so understand what computing the path function means that you have your nl machine and um every branch has to either say i don't know which is reject or it has to have the answer which in it's going to be yes if there is a path and know if there is no path and if i can do be able to count the number of nodes that do have a path the number of notes for which the answer is yes and this i think if you're comfortable with the definition this is [Music] more or less obvious because what you would do is you would go through the nodes of g one by one and test uh using your path function uh what the answer is yes or no and every time it's a yes you add one to the count until you've gone through all of the nodes and then um you have your answer which is nodes that's c now if the machine that's trying to compute the path function on the non-determinism rejects that
2323	that's okay you'll computing c that branch will reject also but when you're um some branch has to get the right answer on the on uh you know for it has to get the right answer um and so then you get the you know you know what's happening with that node and so you then um can either increment the count or you move on to the next node i think i'm uh trying to say i'm not sure if i'm making any clear by kind of repeating myself but okay here so you're going to start out with the you're given the the graph and the start node we're trying to compute this value c which is the number rechargeable from the start node you start out with you you have a counter which you're going to set initially to zero and you go through every node of the graph and if uh the path function computation says yes you can reach you then you add one to the count it says no you cannot reach you then
2324	you just continue um and uh maybe i should add another line here if if the you know if the if the the thing that's computing uh rejects then you also reject um and then at the end you output um so what we're going to prove is the other direction if i give you the count then i can answer the question for each node whether it's reachable or not and this is the thing because what it's saying that is i can give you the count i'm done if we can get that count that's going to be enough um okay so maybe even before the check-in maybe we should just answer any questions because you know if if you're stuck here then you then you're doomed um so i think it's you it makes sense to try to understand what's going on at this at this um because i think the real the real guts of this proof is coming on the next slide um they're kind of the main idea so i'm happy to take if
2325	there's any questions about this i'll just wait for a second to see if you're typing away there well why don't we go to the check-in maybe that'll help um not a very difficult check-in um it'll come up okay just a little practice with the concept so i'm getting going to give you some graph it has nine nodes um and i want to know the value of the count um so we'll we'll assume that s the start node here is reachable from itself and now what's the value of c okay are we good gonna shut this down give you another two seconds please get your answer in okay uh ready set end yeah the right answer is in fact uh e which is six there are six reachable nodes in this graph and that's what the value c is supposed to tell you is how many nodes can i get to from s okay and what i'm saying is that if i can calculate that in this sort of non-deterministic function sense so if it's so
2326	some branches can get that answer um then i can use that to test for each node whether it's reachable or not which is kind of a little bit of a miracle right that's kind of surprising just knowing how many nodes are reachable will allow me to test whether each individual node is reachable um because that's there's no obvious reason why that would be so there's uh going to be a procedure for doing that which is on the next slide and here it is um okay so this is the key idea that we're going to repeat um uh later but so it's good to understand um this is this is the slide you really need to understand uh okay so i'm given the graph let's assume the graph has m nodes um now as i said okay so let's just say what what are we doing here given that count we can compute path so we'll get the answer for every node in the graph if i just know how many you know so i'll know
2327	i can get the answer for which whether a node is reachable or not if i just have if i just know how many reachable nodes there are um so what i'm going to do is get get that count of how many are reachable now i'm going to go through um i'm going to because let's see what's the idea here uh before we even jump into the algorithm the idea is let's say i know how many nodes are reachable like 100 nodes are reachable now what i'm going to do what the algorithm is going to do is find all hundred reachable nodes it's got one by one but it doesn't matter sort of conceptually it's going to find all reachable all reachable nodes and non-deterministically guessing them so it's not sure in advance which ones they are but it's going to guess basically a hundred no it's going to guess some of the nodes as being reachable confirm that the ones that guest are reachable are reachable and then check to see that that number equals
2328	100. on some branch of the non-determinism you will guess right and you'll end up with exactly the right set of 100 reachable nodes and then you'll see is t one of those reachable ones um in which case you say yes or is t not one what is not one of those hundred nodes and then um you know the answer is no because if you've guessed a hundred nodes and you know they're all reachable and you know there are exactly 100 reachable nodes then every other node is not reachable so that's kind of that's the spirit of this and that's i'm just going to write that down here on in the algorithm can you guys hear me still somebody said my audio is like blipping out i am getting a sign or two of unstable internet so you know uh if if you need me to repeat anything just just send me a note good thank you okay um all right so well uh oh maybe i should speak slowly if it's not coming through too
2329	well okay um so so what we're going to do is go through eat all the nodes of the graph one by one and guess whether it's a reachable node or not a reachable node if we guess it is reachable i'm going to also guess the path which shows that it's reachable and then i'm gonna and i'm gonna keep a count of how many reachable nodes i found if that count agrees with the value c um i started with then i know i found them all and if t is not one of them then i know t is not reachable that's the idea okay so here's my this is going to be a count of the number of nodes that i have found which are reachable um that's k now here i'm going i'm going to non-deterministically choose is it a reachable node or not i've just called it two branches of the algorithm the p branch or the n branch p means there's a path and n means there's no path so if i guessed
2330	p at this point for this node u so i'm going through each of the nodes one by one each and u is the current node if i've guessed that it's it is it does have a path from s then i'm going to uh guess that path to make sure that it really is a reachable note um if i fail to find a path then this is one of the branches of the non-determinism that is going to fail it's going to punt it's going to say i don't know under this branch um because either you guessed wrong and this node was not reachable or if it was reachable you guessed you you failed to find a path which shows you that it's reachable there was some path but you didn't guess the right one um either way you made a bad choice you're gonna you're just gonna punt now if you have determined that t is uh um that node that you've just shown is reachable because at this stage you did not fail so you
2331	succeeded in showing a path to um then um uh and u equals t then you know t is reachable that so there is a path from s to t and you're finished that you know you've got the answer you're looking for and so now you can say yes otherwise if t is some if you is some other node then you can just increase your count of the number of reachable nodes that you found okay so you've found a reachable node if it's t you're great you're done if it's not you just include that as your in your account of reachable nodes um now if you've guessed that the node is not reachable okay then you just proceed you know you you're not gonna you're just gonna move on to the next note because you're looking for a collection of reachable notes um okay uh i'm getting some questions here but let me let me wait till the end here um now after i finished going through all of the nodes so i'm finished with this
2332	uh um this loop here of going through all the nodes um now i see did i find c reachable nodes because k is the count of the nodes that i've found to be reachable if that agrees with c then i know i found them all if it differs from c then something has gone wrong because i am told there are c reachable nodes and i did not find c reachable nodes so i made some bad guess along the way i guess some node which really is reachable i guess it was not reachable so i didn't find them all i'm gonna punt um but if i found them all and so and and i didn't end up accepting it it didn't say yes at this stage so t was not one of the ones i found a reachable then i then i uh i'm convinced that t is not one of those that are reachable that was not one of those c nodes that i found which are reachable and now i can say no okay
2333	so let me let me take questions here uh because i think we're yeah that's the end of this slide this is this is the kind of an important uh piece to understand we can spend a couple of minutes trying to work through this uh so somebody's asking how does non-deterministically pick a path fail it if you fail um what i mean is pick a path from s to u so you have to go from s to whatever your current node u is so you're going to pick some path to u you guessed u is reachable now you have to demonstrate it's reachable by picking a path from s to you if you don't end up at u um and the pair you don't want to go forever on any branch so you're going to limit it to m steps your path has to be of length m at most so after m steps if you have not reached you by that point you've picked a bad path and you're going to reject um okay uh
2334	okay so what's the difference between know and reject that's a good question um reject in this case is an i don't know the algorithm uh could not make a determination based on the guesses that it's made in this non-deterministic branch of the algorithm it made bad choices which doesn't allow it to reach a conclusion one way or the other okay remember this algorithm here is computing a function now it's not a now it cannot deterministic algorithm in the language recognition sense this is a function computer and so it has to get the answer to the path function which is a yes or no or i don't know on some branches or some branches that's allowed to do that too so no and reject are totally different um okay okay this is the same thing we talked about last time why do we need two branches for p and n um if we're only going to have proposal just to have the p branch well but some nodes are not reachable if you're gonna look for
2335	if you're gonna you know if you have a an unreachable node so it's not an r you can't get to that node from s you have to skip over that note because you're trying to find a subset of the reachable nodes so you're trying to pick that subset here um one note at a time so if you're only going to allow things you're going to require everything in this subset there are going to be some nodes which are not reachable and you're not going to find a path because they're not reachable and you're going to end up projecting all the time you know on that node so you're going to be this the algorithm will will it will not will not work um okay so i'm not sure i understand this question here but somebody says if t is reachable we output yes on that branch but don't we also output no on some other branch let's that's that's a good cool let's see what happens if it's if t is actually reachable um how
2336	can we up so if t is reachable there's some branch that's going to output yes we all agree with that at least if you're following we agree but how could some other branch output no if t actually is reachable because that's a great question um and no that's not going to happen uh if t is actually reachable how could a branch output no um [Music] that must mean that it does not guess t as one of the reachable nodes because it's going through all of the nodes here um you know it's going to all the nodes and it's picking them as reachable or not if it pick t is one of the reachable ones then it's going to output yes because it will find you know it'll either output yes or if it doesn't find the right doesn't guess the right path it'll end up rejecting on that uh on that path but some path will will end up saying yes so if t is reachable and uh if you guess if you know t
2337	is reachable and you guess t you know you guess u is reachable one at the point when u equals t you will end up outputting s the only way you could not not output yes is if you guess that node is unreachable but then your count is not going to add up right because you you wouldn't you did not find all the reachable nodes if t is one of the reachable nodes and you know there are 100 reachable nodes and you skipped over t as one of the ones that you say is unreachable you at best can only find 99 reachable nodes and and you're not going to end up saying no you're going to end up projecting so it's a very good question but you have to think through what's going to happen here that's this c here is kind of a check it's almost like you know um uh well in it's like a checksum if you know what it is it's so it makes sure that everything that you if you got
2338	to see if you got the if if k equals c at this point that means you actually found all the reachable nodes so c is kind of a check that you found all the reachable nodes um right so if k equals c at this point you have found every reachable node and if t was one of the ones that are reachable you found t uh okay let's see um is the reason we do this with c essentially so that we know and we can stop guessing and correctly identify if it's impossible to reach t well it's not a matter of it it's not a matter of stopping guessing it's it's it's a it's a check that we found everything because we're going to go through and do all the guessing for every node no matter what so we're not going to stop anything early unless we find that t is reachable then then we can stop early but if to show that t is not reachable we have to go through the whole process um
2339	how can we intuitively see that we don't have contradictory branches that's sort of i was trying to say that just now i don't know i i hope that got through you can't have contradictory branches because if you got to this stage here you have found all the reachable nodes so you've at this stage if you got to six you have made all correct guesses you have found all the reachable nodes you have convinced yourself that they're all reachable um by guessing the pairs to them and you've checked that you have the right number of reachable nodes because it equals c so you must have found them all so you cannot have a contradictory answer because either t was one of the ones you found in which case you would have already said yes or otherwise you found them all and t was not one of them and so you're going to say no you can't have both both things cannot happen okay let's move on so the next thing we're going to do is the
2340	next slide is exactly the same as this slide except instead of saying is um is t reachable i want to know is it reachable within d but within distance d okay so um which is going to mean exactly the same procedure can i get uh instead of asking can i get um um uh from s to t with a path of any length of course it's going to be most length m now i want to know can i get to it from s to t by a path of most length d these are number of edges in the path say um and uh that's the same procedure because instead of i'm just going to cut things off at a d but if i if i if i know in advance how many nodes are reachable within d um i'm going to find all the nodes that are reachable within d and c was t one of the ones reachable within d it's the same exact idea so here here is the next slide which kind
2341	of shows that uh so here here's the definitions path sub d means reachable by a path of length of most d okay so um r sub d is all of the ones that are reachable by a path of that length and c sub d is the count it's a number that are reachable uh within d um so if you understood the last slide hopefully this slide will seem kind of obvious to you i'm gonna just highlight all the changes so if i can now calculate c sub d which is the number reachable by a path at most of length d then i can test whether or not nodes are reachable by a path without length first i calculate c sub d i go i pick every node as being reachable within d or not now i just have to check that my path that i'm guessing has a length of most d instead of length at most m which is what i had before keep a count of the ones that i found if that
2342	count equals c sub d then i know i found them all if it's not equal to c sub d then uh i've made some bad choice along the way and i can just punt and say i don't know um and if t was not one of the ones that i've shown to be reachable within d then i know it's not reachable within d and so um uh i can say no okay so i don't know if this merits any additional questions um but this is really the same it's just a repeat of the previous slide what's kind of amazing is now the last slide is going to be again a repeat uh let me just let me just force out of where we're going but feel free to ask a question on this or on the first slide if you didn't on the previous slide if you didn't get that um also we can try to help you out with that um the next slide what i'm going to do is show how to compute
2343	all these c values and i should mention um the value c which is the total number reachable is going to be the same as c sub m reachable with an m the number of nodes of the graph so if i can get up to c sub m i'm done um and what i'm gonna show you is that uh knowing c sub i i can compute c sub i plus one or c sub d i can compute c sub d plus one since i'm using d as my index here basically so c sub zero we know is just s well r you know it's just one because you can read just start with s that's the only thing reachable with zero and then once i know that i can fi figure out c sub 1 c sub 2 c sub 3 and so on and then i get the c sub n and then i have the count of the total number reachable and then i can test the path function um okay so the trick
2344	now is being able to count uh given c sub d i would like to figure out what is c sub d plus one now how am i going to do that what i'm going to do is that's my goal what i'm going to do is something in between i'm going to do a theorem just like this but instead of given c sub d instead of computing paths of d i'm going to compute paths of d plus 1. so knowing how many are reachable from d i'm going to give a test for whether things are reachable within d plus one and the fact is that's easy because this thing already tells me how to compute whether i'm reachable within d and being able to be reachable from within d plus one means i have an edge from something that's reachable within d so if i can figure out which are reachable within d well and i just want to say do i have an edge you know uh do i have an edge from from one
2345	of the nodes that are reachable within d then i'm reachable within d plus one then if i can test whether individual nodes are reachable within d plus one i can count how many nodes are reachable within d plus one that was that very first easy theorem that i showed so i know there's a lot of pieces here that you have to put together but in the end each p each individual piece is not that bad um okay i don't know how many of you have followed me oh no this is not supposed to be here uh there we go so here is the last part which again is just a simple modification of what what the previous slide had so i'm going to show how to compute the path d plus 1 function so testing if there's a path of length d plus 1 from s to some node t but only knowing how many nodes are reachable within d so i'm going to find all nodes that are reachable within d just like i
2346	did before but see if any one of those nodes has an edge to t not necessarily that one is equal to t because that says that t is reachable within d but i want to know does it have an edge to t that means t is reachable within d plus one so if i find all the nodes that are reachable within d and t turns out to be reachable from one of those with it by an edge then t is reachable within d uh d plus one and if d is not reachable from any of those nodes with an edge then t is not reachable when d plus one i hope you're following me i'm not sure you are uh so anyway that's the that's the algorithm here and uh uh the corollary is that you can compute c sub d plus one from c sub d because if you can count the path you if you can test for each node if it's reachable as i mentioned before you go through all the nodes
2347	see whether the reachable and d plus d plus one and then count them up now i have c sub d plus one and now i'm done because uh uh i'm gonna compute each d plus one from the from the value d that i previously computed i'm going to do that from for all these should say zero here actually um and except uh if the path says if this if the path function now says there's no that the answer is no because i'm trying to do you know the complement of the path language and reject of the path uh thing for m says yes and that's my non-deterministic algorithm for the path complement uh problem anyway maybe you need to look at a little bit offline um it's presented in a little bit different way in the book uh i don't know if that will be more or less clear to you but i kind of i think this has been a little bit more unpacked for the purposes of the lecture um so let's just
2348	see do we i'm not getting any questions which probably means uh uh i've lost a huge chunk of you um but uh the good news is we're gonna move on to a different topic so um but feel free to ask a question on this if you want
2349	which is going to be the second half of the lecture also not so easy i have to say probably a little less technical than this one is but it's also this are going to be um spending time on just mainly just one theorem but anyway so looking ahead to what where we're going and then we'll have a break um we uh well what we've shown so far these are the major complexity classes i'm not not including let's say the the complementary classes the co-np uh type classes um these are the major complex classes we've seen so far and as we've seen they form a hierarchy of containments some of those containments trivial and some slightly less trivial but we have not shown whether any of these classes are different you know we've pointed out that there are some unsolved problems here but do we know any of these classes differ from each other or could it all collapse down to l and the answer to that is we do know that p space and l
2350	are actually different that we can prove and it's a um it relies on the theorem that says if you give a turing machine more space then you can do more things so because p space is much is a bigger bound than log space we know we can do more things in fact because n l is contained within log squared space deterministically and p space is bigger than that we actually can separate p space and nm so we're going to prove that today um so the basically the idea of the theorem says that if you give a turing machine a bit more time or a bit more space then it can do more though you have there are some conditions on that that we have to uh we'll get into one of the conclusions that we'll show is that um time n squared if you compare with time it's you know the time com the things you can do in n squared time uh versus the things you can do in cube time there are more
2351	things you can do in n-cube time then you can what you can do with n-square time i mean that's what you would expect um but it's not the case that everything we expect in uh complexity theory we can prove this is one of the things we can prove so as you add more time you can do more things so this is a proper subset here so there's there are some things in time n cubed that are not in time n squared and ditto for space okay um
2352	coffee break and so feel free to shoot me any questions about what we've done so far or anything else and otherwise we will um launch our timer and i'll see you in five minutes okay so i get getting some good questions here could we also make a solution this is getting back to that um um uh um the logs the nl equals coin l somebody's saying could we just um make another selection just by non-deterministically choosing c vertices and then not and then checking that they're all reachable that's effectively what we're doing but be careful that we because we cannot store c vertices so that's why we're doing them one at a time we can't guess all c vertices up front because where you're going to store all that we only have log space okay another so maybe somebody's asking how much working space do we need for storing the intermediate steps i'm not sure what intermediate steps you mean but if it's all the ci values you know see going from c0 to c1
2353	to c2 to c3 we don't store those we all you need you need c sub d to calculate c sub d plus one and then you forget c sub d you couldn't store all the c values but you don't need them all you only need the most recent one to go to the next one okay somebody's asking can i go over why the complement of path in nl implies nl equal coin l because the complement of path is uh essentially it's co n l complete i mean l it is um so everything in nl is reducible to path the everything in cohen l is reducible to the complement of path by the same reduction um and so if you can do the complement of path in any uh class you can do all of the complements of nl languages in any class and so you can do the complement of path in nl you can do all the connell problems in out in nl and so then nl equals comma now you have to you
2354	have to just think through the logic of it this is not that that part is not hard um why it's enough to solve the path complement problem in nl that does everything else because it's a good so the same completeness phenomenon that we've been seeing okay somebody's asking about the the two sat problem that we talked about last time um and is it um and you know i i pointed out that that's in nl the you know the the two side problem well the complement of the two set problem uh you know the unsatisfiable two set formulas that that's an nl language because you can basically look for a contradiction uh non-deterministically in log space um that's i think i probably won't be able to explain that in a minute but maybe we'll have our recitation instructors cover that in recitation um it's a nice proof not very hard but it's it's an it's a nice proof it's it's it's it's it's you know it's not it's something you have to do you have to
2355	think about you you have to argue but it's still it's not super hard um understanding the two sad problem and you know the complement of two set we showed is in nl and because nl equals coin l also the two sat problem itself without complementation is in nl and in fact is nl complete okay um i think we're going to have to move on uh i'll stick around after lecture in cases any questions that i can answer quickly at that point sorry if i couldn't get to your question just now all right continuing on here
2356	shifting gears the space hierarchy theorem so um so as i mentioned i think um
2357	we're going to do the time and space hierarchy theorems which show that if you can do a little bit more if you give a little bit more time or a little bit more space you can do more things we're going to do the space case first because that actually tends to be slightly for certain technical reasons slightly easier
2358	space hierarchy theorem so here is the statement of the theorem and it says for any bound think of s is going to be some you know space bound and again f has to satisfy some technical condition in yellow remember that it's yellow because that's going to be relevant later um uh so there's going to be some technical condition um for no matter what function you you have whatever space bound you have as long as it satisfies this condition which is a mild condition but you need it uh whatever space bound you have um you can find a language a which requires exactly that much space so if f is like n cubed we're going to find a language a that requires n cubed space if it's n to the hundredth we can find the language that requires into the 100th space and cannot be done within 1999 space whatever it is you can find a language that requires exactly that much space and if you like it a little bit more formally so that means
2359	that it can be decided in that much space but it cannot be decided in less space okay framing it in a slightly different way in terms of our space classes um i'm going to define a notion which is you know kind of it's not it's not said this way in the book but maybe it's a helpful way to write it down it's space little o of f of n so those are all the things that you can do by a function that's little o of f of n in space so space little o of f n is properly contained within space f of n in other words there's something here which is not in there okay picture pictorially i'm going to exhibit some language some explicit language a which i can do in this much space but not in any less now you know you can sort of think of this as a little bit like the situation for context-free languages and regular languages where we exhibited a particular language that differentiated that was it
2360	context-free but not regular and we're going to kind of do the same thing now but the one key difference is that in the case of separating the context free and the regular we could give a nice language like 0 to the k1 to the k here the language is not going to be so nice to describe it's going to be the language that some turing machine we're going to give decides but you're not going to be able to get a nice simple understanding of a it's going to be whatever that turing machine does and so in that sense it's not a very natural language um that's easy to sort of get your mind around um so the i outline and really you don't have to worry about this but maybe it helps it's really going to be a kind of a diagonalization proof um the way this machine d um is going to operate so d is going to give you my language a um so d is going to be designed and i'm going
2361	to show you d on the next slide uh d is going to run within my target space bound f of n and here's the key here's the kicker d is going to be designed to make sure that its language cannot be done in less space and the way it does that is it makes sure that its language is different from any language that that is um decidable by a turing machine in in less space and it's going to be different in at least one place so any d is going to guarantee that its language cannot be done in little o of f of n space because it's going to be different from every language that's doable in little o of f of n space somewhere okay that's the point and then the language a is going to be the language of this uh turing machine d okay so it looks like a tall order the d has to make sure that each you know that that for every machine its language differs uh from that
2362	machine's language if that machine is running in little of f event space but it's basically going to be a diagonalization so for all of the different possible inputs to d that input is going to actually code up a machine uh on which we're going to make sure that we're different from that machine if it's a small space machine okay let's see so i can take a couple of questions here does f have to be computable so that's going to be one of the conditions um that we're going to have to guarantee where f satisfies the technical condition yeah it's going to end up being half it's going to be computable but that's not enough um good question though uh okay so let's let's let's move on from there okay now so here is now what's what my job is to give you this turing machine d so d these language is going to be my my language a which i can which requires f of n space cannot be done unless okay oops i need
2363	to i need the full slide here so i have to take myself out um [Music] all right uh now this is my goal i want to exhibit this language a which i can do in this much space but not in any less and so i'm going to give this machine d as i mentioned where a is d's language d runs in order f event space and that sort of that achieves this part and d it makes sure that its language cannot be done in any less space so that achieves this part so it's different from the language of any machine that runs in little o event f of n space okay um [Music] so uh this is how d is gonna work okay i'm gonna try to give you a little picture uh to help help see the to accompany the description uh so d gets its input w which is of length n the very first thing d does is it marks off f of n's space because it's only allowed to use we're
2364	only going to allow d to use f of n space because otherwise we're in danger of d not of a not being in in space f of n so d is going to guarantee that by making sure it's going to mark off f of n space and if it ever tries to use more than that it just rejects and but by virtue of that we're sure that these language is in space f of n because d is an f of n space turing machine and it's going to be the side okay so this part so far is not too hard okay now we're going to start getting into the meat here so if w um now what we want to think of w as a description of a machine that we're going to feed that's that's going to run on w so this is going to a little bit you know back to an earlier when we talked about diagonalization so don't get thrown off by this um we if we're going to think of
2365	w not only as the input to d but it's also going to be the description of a machine and if it turns out that w is doesn't describe anything it's just a jump w then we're not not interested we're gonna we're just gonna reject on that w we're only interested in the w's that do describe some machine m okay so if m if w uh describes some machine m then we're gonna run m on w and we're going to do the do the opposite of what uh what m does that's the whole idea we're just going to uh make sure that what we're doing is not the same as what emma's doing so at a high level the the basic idea for this is is not hard um so we're going to simulate m on w if m x rejects then we'll accept and if m accepts then we'll reject we're just going to do the opposite um and i think that is so we have to be careful when we do the simulation this
2366	is a little bit of a detail but you know this is a proof where you need to pay attention to some details um the cost of simulating m on d is only a constant factor um because if m uses a certain amount of space when d is simulating m you know m may have a larger tape alphabet than d does but these can then encode um m's tape by using several cells for each of m's cells but it's only going to be a constant factor and that's important here because um we have to make sure that you know if this was a big blow up um d would not be able to run m um i i think i'm sort of arguing the details without making sure we understand the fundamental concept um so let me back up the point is that d is doing something the opposite of m now uh d can't be different from every m because d itself is a turing machine of course but but the thing is is that
2367	d is only running within f of n tape cells so it has to be able to do that simulation of m within that amount of tape if m is using a lot of tape then d is going to use a lot of tape and it's just going to reject so this is only going to really come into play getting being able to simulate m if m is using a small amount of using a small amount of space so that d can do the simulation okay so let's just see maybe uh so they're going to be some issues here but before i get to that let's just see what uh what your questions are how can a turing machine know if w is encoding some other turing machine no that's simple you know what what is a coding of a turing machine it's just you know the standard we have a standard coding um it's just you know coding the rules of the machine so it has to have states transition function blah blah blah so
2368	it just has to be some you know whatever our encoding for the turing machine is we can always test whether a string is a legitimate encoding of a turing machine so that that shouldn't be bad um somebody says why do we reject if we use more than f n cells isn't it okay to use order f of n yes it could be but we have to cut it off somewhere you know it might be it's okay we could use two f of n we could use 10 f of n but we have to have some constant for d and let's just kind of simply constant one so d has to run within f of n cells um and that's going to guaran that's going to be good enough for us okay do we have to make sure that m runs a little of f of n so we can't really tell whether m is running in little o of f of n or we can tell us whether we can finish the simulation so that's
2369	actually going to be maybe you can just hold off on that question because there is a point that we have to follow up on in that which is um uh just because you know we may or may not be able to finish simulating m on this w doesn't necessarily tell us what the asymptotic behavior of m is but we'll have to look at that in a bit okay so somebody's saying what happens if m loops on w that's going to be one of our issues we have to deal with that's a good question there step two alone can use them more than f of n cells yeah step two alone can use more than f of n cells if it does we're just going to end up projecting okay so we're getting good questions here some of them we're going to which i'm going to address anyway so why don't we just move on um okay so here is sort of a question i think this is one of the questions that that related to
2370	one of the ones that got asked what happens if it runs in little of f of n space so we we remember what we're trying to do is be different from every small space you know little o of f of n space machine so what if m runs a little o of f of n space but has a big constant so what i mean by that concretely is suppose d is an n cubed space so suppose we're trying to get a in in cubed space but show what's not in n squared space d is going to run an n cubed and what and we have to make sure that any machine that's running in n squared space cannot do the same language um so we're going to be different from that but the problem is that uh in uh the machine m might be running in n squared space but with a huge constant so it might be running in a million n squared so that's still a machine that's running in a little o
2371	of n cubed and we have to be different from it but for the particular w we're working on we might not have enough space to run m because of the huge constant it that con the asymptotic behavior is only going to be relevant well for large w for smaller b we may not see that we may not have enough space to run m so um what are we going to do to fix that we're going to run that m on infinitely many different w so it's going to be infinitely many different w's that are all going to encode the same m and the way i'm going to do that is by uh thinking of w as representing m but having an unbounded number of trailing zeros after that so i'm going to strip off the very first thing i'm going to do with w is i'm going to strip off the trailing zeros up into the final one i'm going to remove those and then take the rest and as the description of the machine
2372	so now i'm going to have potentially w's that have an enormous number of zeros at the end big enough so that i can see the asymptotic behavior of m and that if m is really running in little o of f of n space i'll have enough space to run m to completion on w and so then i'll be able to be different from it okay um so i'm kind of showing that over here so here's a very large w i'm going to strip off the trailing zeros the rest of it is just going to be m and i'm going to run this m on the whole w the entire w without the zero stripped off so now m is going to be running on a very large input um big enough so that d uh d which has asymptotically more space than m does will have enough space to run empty completion um now another question that got asked what happens if m loops that's going to be a problem because d always has to
2373	hold and if it just blindly simulates m then d might be looping on m none of m is going to use a lot of space by the way because then d is going to catch it in step one but if m uses his loops on a small amount of space then uh d might end up looping as presently constructed so what i'm going to do is i'm going to put a counter which makes it stop if it runs for 2 to the f of n space so basically because that's how long d could possibly run without looping anyway m could be running without looping anyway and so we're going to run it for this amount of this number of steps and uh i'm going to reject if it hasn't yet halted as well as uh that because it has to be looping at that point anyway um and so it's not interesting for us it doesn't matter what we're going to do
2374	and the last thing is how to compute f um so i'll try to address some questions here in in our remaining time uh how to compute f so to mark off f of n cells we also have to compute f i didn't think anybody any of you guys asked that question except maybe sort of the very beginning about f being a computable function certainly f is going to have to be computable but not only does it have to be computable it has to be computable within the space bound and that's just going to be a condition we're going to impose on f it's so called space constructable namely that you can compute it within its own space bound and all nice functions that we care about are going to be space constructable so it's not doesn't turn out to be an obstacle to applying uh the hierarchy theorem but it is a condition that we need it actually is not true without that condition um okay let's let's just oh this i have a check
2375	in here maybe we can take a couple of questions first some of you are anticipating my check-in actually which is good um so let me hold off on those sorry a bit confused about what is m can we say d as input m and simulate m on yeah so uh somebody's saying can we say that d has input m and simulates m on itself yes that's exactly what's happening the reason why we're doing that is because we have to cover all possible m's so as we get all possible inputs w they're going to range over all possible ends and so every possible m is going to get addressed to see if we can run it um within the space bound and be different from it d's job is to be different from each of those ends but it's not you know again there were some details here that got raised in these issues um but in a sense this is just kind of more technical i would focus on understanding what i originally wrote down
2376	because that's the main idea the rest of it is just kind of
2377	can i give an example of a non-space constructable function yes log log log n space you cannot compute log log log n space within log log log n space and in fact it's known that there's nothing new between constant space which is just regular and log log log n space anything you can do in log log log n space is a regular language so the the hierarchy theorem doesn't doesn't won't apply there because well it applies but that's not a it doesn't well you know it's not it's not space constructible to find higher level um you know large um non-space constructable functions you can do it but they're you know you you they're not easy to describe okay let's do our check in here what happens when we run dion itself i got a couple of people asking me about that so that's a this is just a good lead into our check-in and this a little you really have to understand what's going on to see what does d do when if you feed
2378	in itself maybe with some trailing zeros because remember the algorithm strips off trailing zero so what is what does it do in that case um so here are my options there you can get to pick which ones which one you uh you think is the answer so i'll give you another 30 seconds on this because this requires a little bit of thinking if you want to invest in it all right i'm wrapping this up guys five seconds to go okay i'm gonna end it so get your participation points in a bunch of you have not uh said anything come on um i can see the count here and it's there's a three or four of you are not not answered well you're going to lose out closing all right so the right answer is in fact c it does reject let's just understand what happened is definitely we don't get a contradiction i mean this is an algorithm i just described it's going to do something um uh i'm assuming the people who picked e
2379	are having fun as i did when i came up with the check-in but um uh not a question answer a doesn't is not going to be good either because d has to be a decider so it can't loop on anything so the only sort of reasonable answers are accept or reject when you run d on itself uh what's it going to try to do it's going to the very first thing it's going to you know mark off f of n tape cells and then it's going to get its input which is itself tries to simulate itself on the same input that uh simulated d is also going to try to mark off f of n tape cells but um due to some simulation you know there's going to be some cost to doing the stimulation when the simulated d is going to try to mark off f of n tape cells it's going to blow the original d space bound and exceed the bound and so d is going to reject up right in step
2380	one when it tries to get an input of its of itself so that's um it's very clear what's gonna happen in this it's just gonna reject because of the for this reject this reject in particular and notice this would you know yeah you know okay let me not try to confuse it um okay so that's that's that's all i want
2381	hierarchy theorem which is very has the same proof um but some of the technical details are slightly different okay um so now if i give you a time bound again we you have gonna have a face with the same notion that you have to be able to compute f within f's amount of time so it has to be a time constructable i'm not gonna define that um so there's a language a which requires that much time um so it has to be decidable within that much time but there's a slight difference here and there's and this is an artifact of the proof of the theorem not because it's an absolute truth as far as we know uh it's not that it's not decidable little o of f n you actually you can only prove something slightly weaker when you have one tape turing machines that it's little decidable little o over there's there's a slight um uh gap in what you can prove so it's not only that you can't prove you it requires little
2382	o but little o of little of f of n over log f of n is uh what you can prove that the you get from this uh time hierarchy theorem but let's not get caught up on that for now um
2383	so the proof outline is the same outline as we had before um uh we're going to give a d that runs in order f of n time so it's ensures that the language is in that uh time complexity class time f of n and it makes sure it's different from every machine that runs faster by some significant love by a log factor faster okay and so um why don't i uh show how that goes um the proof is in some ways almost exactly the same um i'm going to give a d which runs this much time and it shows it's different from every m that runs in a lot less time here is the algorithm for d now it computes f n but it does something a little different with f of n remember in the space hierarchy theorem we marked off f of n space now this f event is going to be used for a different purpose it's going to be a clock and you have to shut m down if it runs
2384	for more than f of n steps not if it uses more than f of n space because we're only interested in m's that use significantly less than f of n time so we're going to run an m you know for f for some number of steps whatever m says we're going to do the opposite and only if we can actually finish that simulation we'll be be able to be sure that we're different from what m is doing um so this is the whole algorithm here we don't have to do any further modifications and where's that login factor coming from it's actually coming from a funny place um and and you know you have to get into the little bit of the guts of this when you're simulating m on w remember that m itself was described by w so you're going to have to write down a copy of m which is you know just as described by w and then so you're gonna and then you're gonna have the tape that am is working
2385	on which is starting out with w on it um and uh you have to be now you have to be a little careful how you manage that because if your description of m is just sitting at the beginning of the tape as you're simulating m every time you do one step and modifying the tape you don't want to have to go back to the beginning of the tape to look up the next step of m so you actually have to carry m along with you as you're doing the simulation and you can do that by expanding the tape alphabet of the tape so that you can effectively have two symbols on one cell one is going to be for describing m and the other one is going to be for just the for m's for the simulation tape and you'll be carrying m along with you uh wherever your head is so you don't have to go very far to look up m and so that's all possible because that's going to add only a
2386	constant factor because m is fixed in size doesn't depend on you know you know for large inputs to m m is fixed but the tricky thing here is the counter to make sure we're not using too much time um [Music] the counter has size log f of n because that's how big it has to count up to so you should you can shut it down if it's going to exceed the f of n steps um and because you know you have to run for a certain amount of time and carrying the keeping the counter nearby has the counter now could be pretty big and so that's going to cost you a log factor of um of simulation cost to move that counter around all the time and so that's why you have to run for only a log factor less so that you can actually finish within f of n time as you're as you're required to do okay i realize that that's a mouthful there and you may not have all understood that it
2387	doesn't matter it's not that critical i think what i'm really more concerned is you understand the the main idea of the um the hierarchy theorem some of these implementation details you know you if you don't get them i wouldn't worry about it i i feel i have to include them for completeness sake and to be honest with you about the proof but if you didn't follow everything that's okay i do want to understand the main idea though of the algorithm making sure that what it's doing is different from what every machine is doing if that machine runs in little o of f of n space or or a small amount of time you know little o of f n over log f of n time okay so and i think we're gonna uh we're gonna end here so come pretty much out of time uh i'm gonna stick around for a little bit um in case there's any questions here oh wait there's one let's check in though um let's let's look at this this
2388	is kind of an interesting sort of follow-on to the hierarchy theorem um if you look at the two questions does l equal p and does p equal p space these are both unsolved problems does the what if anything does the hierarchy theorem tell us about those questions and it's kind of interesting that there actually does well i'll leave it to you to uh tell me if you can see what what it might actually be telling you closing get your answer in okay one two three i feel like i'm running an auction house here i should have a gavel okay yes in fact we know that you know these are separated so it's not even though we don't know if l equals p or p equals p space they can't both be equal because then um l would equal p space and we know that's false um so at least one of these has the answer no okay so with that let's wrap up today's lecture you know we prove these hierarchy theorems and why don't
2389	we just uh um i'm going to uh shut us down here but but before well we're over so you can feel free to go um but i'll stick around in case anybody's any questions for a few minutes anyway um and then uh we'll call it a day since we just showed space and is a proper subset of space n to the k for any k why can't we also say space n is a proper subset of p space yes space n is a proper subset of p space yeah so somebody just asked we just showed that space n is a proper subset of space n to the k does that also say that space n is a proper subset of p space definitely any um space n to the k is a proper subset of space n to the k plus one which is a subset of p space so any fixed polynomial is going to be a subset of p space because p space includes all the polynomials which of the two unsolved problems
2390	uh whoops do i think is more likely likely to be true well i think most i mean i would bet that both of these are not equal so both of these have answered no um uh it would be weird you know i mean you think l equals p that anything you can do in polynomial time you end with log space log space is incredibly weak and and p space is incredibly strong um i would be shocked if either of these were equal so we just the problem is that we don't have a method for proving um problems are are actually have high complexity of of any sort we don't know how to show things outside of l don't know how to show things outside of p except by using the hierarchy theorem diagonalization is the only method that we have for showing things or outside of classes and there's reason to believe that as we'll this will get to i think next lecture in fact there's kind of reasons to believe that the hierarchy theorem
2391	type argument which is diagonalization is not going to answer those kinds of questions um so we need a different method and diagonalization is all we got good question though if i didn't get to answer your question you have a question for me ask it again because it's got buried so it means we are very far from disproving p versus np is that right it could happen tomorrow you know how do you how do you how can you tell it doesn't you know it it seems clear that the present state of mathematics as of right now is you know we don't have a clue how to answer those kinds of questions and it's not obvious that we've even made any progress um but you know that's the nature of the game that's the nature of the beast you know somebody gets a good idea and all of a sudden lots of things uh can change and that can happen and then in any point maybe one of you guys when were these results first this is
2392	the the stuff okay the hierarchy theorem is old that goes back to the very when time when time classes were first defined i think is one of the first results to show the hierarchy and that's late 60s the nl equal coen l i think i mentioned was like mid 1980s much later i mean from your points of view it was a bit it was back in the cave cave age uh either way but uh yeah but but the the hierarchy team that that's actually pre predates uh my coming into the field but but the but the nl equal conel that was something that i was i personally experienced how surprised people were okay i think i'm gonna send you off all off on your way good good having you here and i have a good weekend everybody and um i will see you on tuesday bye
2393	[SQUEAKING] [RUSTLING] [CLICKING] MICHAEL SIPSER: So welcome, everybody. Welcome back. Let's get started with today's lecture. Where were we? On Tuesday, we covered, the main topic was the recursion theorem, which allows programs to self-reference. And we saw some applications of that, too. So we gave a new proof that ATM is undecidable. We looked at this language of minimal Turing machine descriptions. And we had a short digression into mathematical logic, where we looked at how one shows that there are true, but unprovable, statements in any reasonable formal system. So today, we're going to shift gears entirely. And we're moving into the second half of the course, where we are beginning a study of computational complexity theory. And we'll say a little bit about that during the course of the lecture, of course. But the main things that we are going to cover in terms of content that you will need is defining the complexity classes and the class P. And we'll prove a few theorems along the way. But that's the main objective of today's lecture. Computability
2394	theory, which was the subject of the first half of the course, and which is what the midterm exam is going to cover, was a subject that was an active area of mathematical study in the first part of the 20th century. It really got-- it really dates back into the late 19th century, in fact, when people were trying to figure out how to formalize mathematical reasoning. But it really got going in the 1930s with the work of Godel, and Church, and Turing, who really formalized for the first time what we mean by algorithm. And that allowed the study of algorithms to really get started. And it had its impact, as I mentioned, on the actual design, building, and thinking about real computers. The main question, if you kind of boil the subject down to a single question, is some language decidable or not. In complexity theory, which got started kind of when computability theory more or less wrapped up as a subject, largely because they answered many of the questions that they-- they answered pretty much
2395	all of the questions that they were asking. So there really aren't interesting unsolved questions left in that field. And you really need mathematical questions to keep a subject alive, unsolved questions. So complexity theory got its start in the 1960s. And it continues on as an active area of research to the present day. And I guess if you could boil it down, it would be is a language decidable with some restriction on the resources, such as the amount of time, or memory, or some other-- or some other kinds of resources that you might provide, randomness, and so on? All of those are within the area of computational complexity
2396	So let's get ourselves started with an example. Here is the language that we've looked at in the past, a to the k, b to the k. And let's look at it now from the perspective of complexity. All of the languages that we're going to be studying in complexity are all going to be decidable languages. So the question of undecidability in complexity theory is not really of interest. It's all decidable languages, but the question is how decidable. What sort of resources do you need to do the deciding? So for this language A, how many steps are needed? Well, we're going to spend a little time just kind of setting up the definitions of the subject and kind of motivating them. So for this language A, when I ask how many steps are needed, well, it's going to depend upon which input you have in mind. Some inputs might require more steps than others. So the way we're going to set the subject up, which is the standard way that people in this field look at it,
2397	and I think that applies to lots of examples outside as well, is that we're going to kind of group all of the inputs of the same length together. And look at the maximum cost, the maximum number of steps you need, to solve any one of those inputs of a given length. And we'll do that for each length. And the way we're going to frame it is in terms of giving a maximum, or what's called an upper bound, on the amount of time that you need to solve all of those inputs of length n. That's what's sometimes called worst-case complexity. I'm sure many of you seen this already. But just to make sure we're all together on this, you might contrast that, for example, with what's called average case complexity. Where instead of looking at the most difficult case among all inputs of length n, you take the average of all inputs of length n. And then you have to-- then it's a little bit more complicated, because then you need to have a probability distribution
2398	on those inputs and so on. We're not going to look at it, in this course, from that perspective. We're only going to be looking at what's called worst-case complexity.
2399	So let's begin, then, by looking at this in more detail and taking as our starting point the theorem that says that on a one tape Turing machine, which is deciding this language A, a to the k, b to the k, you can do this on a one tape Turing machine, M, we're calling it. In at most some constant times n squared steps, for any input of length n, where the constant is going to be fixed independent of it. So this is going to be-- having a constant in-- factor in the complexity is going to come up often. And so instead of saying this over and over again, we're going to use a notation that m uses order n squared steps. I'm sure many of you seen that terminology as well. But just for the purposes of making sure we're all together on that, there is this big O and little o notation. I'm expecting you to be familiar with that. Big O is when you apply to functions, as it's done. You say f is
2400	big O of g, as for two functions f and g. It's basically if f is less than or equal to g, if you're ignoring constant factors. And you say f is little o of g if f is strictly less than g if you're ignoring constant factors. That's kind of one sort of informal way of looking at it. The precise definition is given up there on the slide. And if you haven't seen it before, make sure you look at it in the book, where it's all carefully described and defined. So that you're comfortable with these notions. Because it's really-- we're going to be using this without any further discussion from here on.
2401	So let's get to the proof, then, of this theorem that you can do the language A in order n squared steps. Not super hard. I think if I asked you to come up with an algorithm to solve A, this would be the algorithm that you would find basically. First, you would start off by scanning the input w to make sure it's of the right form. So a run of a's followed by a run of b's of some lengths. And if it's not of that form, then you're going to reject right away. The next thing you'll do is then go to a repeat loop in the Turing machine. And if you imagine, here is your machine, here is the input w, you're going to go through that repeating repeatedly. Of course, you can do this in a number of different ways. But here's the way I have in mind for you, on this slide, anyway. We're going to scan the entire tape, crossing off a single a and a single b on a scan. And then
2402	you're going to keep doing that until you've crossed off everything. Unless you run out of a's or you run out of b's. In that case, you're going to reject. If you run out of a's or b's before you run out of the other type, then you know that you started out with an unequal number. And so the machine is going to reject. If you've managed to cross them all off without running out of one before the other, then you'll accept. I know this is kind of obvious. But I think it's important to get us all together on this at the beginning. So here's a little animation of the Turing machine doing that. I'm not showing the motion of the head. But you imagine the head scanning back and forth, crossing off these a's and b's, one a and one b on each pass, until they're all crossed off. And then it accepts. Unless of course, it runs out of a's or b's before the other type, then it rejects. OK, now let's do a very
2403	quick, informal analysis of how much time this has taken. So the very first stage, I'm calling each of these things stages of the Turing machine to distinguish them from the steps of the Turing machine, which are the individual transition function moves. So this is the entire stage of the machine. The very first stage takes order n steps, because you have to make a scan across the input. And then I'm not giving all the full detail. Of course, you're going to scan and then you're going to return the head back to its starting position. I'm not-- that's just going to be an extra factor of n, an extra n. And so that's where we're talking about being order n steps for the very first stage. And then as you go through the repeat loop, each time you go through the repeat loop, you're going to cross off one a and one b. So that's going to mean you're going to have to do this roughly order-- you're going have to do this order n times in
2404	order to cross off all the a's and b's. So there's going to be order n iterations of this repeat loop. Each one of them is going to, again, require a scan. So that's order n steps for each one of the iterations. So adding that all up, the very top row gives us the order n and then we have the order n iterations times order n steps is order n squared steps. And so the sum of these two is order n squared steps due to the nature of arithmetic when you have the big O notation. The dominant term overrides all of the others. So that's, in a nutshell, how we-- well, this is our very first example of analyzing the Turing machine algorithm for a language. So let me ask you now whether there is some other Turing machine, some other one tape Turing machine which can do better than this Turing machine does in terms of how much time it takes. So one idea that you might have, instead of crossing off a single a
2405	or a single b, maybe you can cross off two a's and two b's, or 10 a's and 10 b's. Well, that'll cut down the running time by a factor of 10. But from the standpoint of this theorem, it's still going to be an order n squared algorithm. And so that really doesn't change the amount of time used from the perspective of-- from our perspective, where we're going to be ignoring the constant factors on the running time. So I ask you here, can you do better than just improving things by a constant factor? There we go. OK, so here's a check-in on this problem, on the problem A, deciding A on a one tape Turing machine. Can we do better than order n squared, as I just described in that theorem in that algorithm for that theorem? Or can you get it down to n log n? Or maybe you can get it down to order n? What do you think? Obviously, we're just getting started. But just make your best guess. And let me just
2406	post that for you as a poll. What's most important to me is that you understand the terminology that we're using and the way we're discussing-- the way we're talking about it. Because that's going to be setting us up for the definitions that we're going to come a little bit later in the lecture. So I'm going to close the poll. We're kind of all over the place on it. But that's good. Since we haven't really covered this material yet. In fact, B is the correct answer. We can improve this algorithm down to order n log n, but not all the way down to order n. So let me give-- let me show you how you do it in order n log n on the next slide. And so here is a one tape Turing machine that can decide A by using only order n log n steps instead of order n squared steps. So this is a significant improvement. So I'll describe the Turing machine. Here, again, is the picture of the machine on an input.
2407	And the very first thing I need to say is that we're going to scan to make sure the input is of the right form. And now, we're going to-- again, it's going to be making repeated passes over the input. But we're going to do it a little differently now. Instead of crossing off a single a and a single b, or some fixed number of a's and a fixed number of b's, we're going to cross off every other a and every other b. And that way, we're going to essentially cut the number of a and b in half. And that's why the number of iterations is only going to be a log, instead of linear. So we're going to cross off every other a and every other b. And at the same time, we're going to keep track of the parity, the even/odd parity of the number of a's that we've seen and the parity of the number of b's that we've seen that have not yet been crossed off. And we're going to compare those
2408	parities to make sure that they agree. If they ever disagree, we know we started off with different numbers of a's and b's. And I'll illustrate this in a second, just to make sure we understand this algorithm. So I'm going to write down as a little table of the parities that we've seen. And I'm going to illustrate the algorithm with a little animation. So again, we're now going to scan across, crossing off every other a, and then every other b. But before we get to the b's, we observe, as we cross these off, that we had six a's. Now, I'm not saying we count them. We just keep track of the even/odd parity. That can be done in the finite control of the machine. Counting them would be more complicated. But just keeping track of the parity is something that the finite automaton could do. So the parity in this case, because they were six, is going to be even. Now, we cross off the b's. Same, even parity, now we're going to return the head
2409	back to the beginning, I'm obviously not showing the head moving here. We return the head back to the beginning. And now, we scan across, again, crossing off every other remaining a and counting the parities of the remaining a's. So here now, it's going to be this one and this one are going to get crossed off. And there were three a's, so that was odd parity. And the same for the b's, three b's, odd parity. And now we return our head back to the beginning, cross again, off every other a and every other b. So that was odd parity, there was just one. Crossing off the b, odd parity because just one. They all agree. So the machine is going to accept. Because everything is now crossed off. And the parities agreed along the way. Let me just say for a second, obviously, if you ever get disagreement on the parities, then that the number of a's and the number of b's had to disagree. But how do we know that if the parities always agree
2410	that we actually did start out with the same number of a's as b's? And that, you could see that in a number of different ways, but perhaps a cute way to see it is there is actually-- if you look at these parities , here the sequence of parities, actually in reverse. So if you say odd, odd, even, and you look at the binary representation of the number of a's, which is six, so the binary representation would be 110. The fact that you get odd, odd, even and 110 is not a coincidence. In fact, the sequence of parities in reverse that you get is exactly the same as the binary representation. You'd have to confirm that with a little proof. It's not hard. But that, once you have confirmed that, you can see that if the sequence of parities agree, then the numbers have to be the same, because the binary representations agreed. OK, so now getting to the analysis here, again, order n steps to do the check. Log n iterations. Each scan takes order
2411	n steps. So the total running time here is going to be order n log n. It's going to be the log n times n. That's where the n log n comes from. Now, question you might ask, could I do even better than that? Can I beat n log n by more than any constant factor? So can I do little o of n log n? And the answer is no. This is the best possible one tape Turing machine for this language. So a one tape Turing machine cannot decide A by using little o of n log n steps. We're not going to prove that. I'm not going to ask you to be responsible for the proof. But in fact, what you can show is that any language that you can do on a one tape Turing machine in the little o of n log n steps turns out to be regular. So you can prove a rather strong theme here. Not super difficult to prove. But I don't want to spend a lot of time on
2412	proving grounds for Turing machines. Because really the whole purpose of setting this up using Turing machines is to talk about algorithms in general, algorithms in general, I'm not going to be focusing on the nitty gritty of Turing machines. OK so what is my-- yeah, so I wanted to just stop and make sure that we are together here. So a brief pause. And feel free to send me any questions. OK, this is a good question. If we can keep track of parities, why can't we just keep track of the number of a's or b's? Well, you could keep track of the parity in the finite memory. And so you can do that with effectively no work. But the finite memory cannot is not enough for doing a count up to some arbitrarily large number. Now, you could store the count on the tape. But that's going to cost you time to maintain that counter. And so that's not going to be so simple as keeping track of the parity in the finite memory. Somebody is asking
2413	if a star b star is regular. Yes, a star b star is regular. So what? But a to the k, b to the k, which is our language, is not regular. That's the language we're looking at. So getting questions about what happens with multiple tapes. We'll talk about that in a second. Yes, we could do an order n steps on a regular computer, sure. But for this slide, anyway, we're looking at one tape Turing machines. Getting questions about big O and little o. For something to be little o means it's less than any constant factor times the function. So you have to look at the definition in the book. I think enough people in the class probably know this and have seen this already, I don't want to spend everybody's time on it. But please review it in the book. Somebody is asking if you need to store the parity on the tape. No, you can just store it in the finite memory. I mean, storing in the finite memory seems to me the simplest
2414	thing. Why don't we move on? Please feel free to ask questions to the TAs as well. We have two TAs at least here attending with me. So good, all right, all right, so we cannot do better than a one tape Turing machine-- on a one tape Turing machine than order n log n. And that's something we can prove, though we're not going to do it here. However, if you change the model, for example, you use a two tape Turing machine, then yes, as a lot of you are suggesting in the chat, you can do better than that. So if we now have a two tape Turing machine, or a multi-tape Turing machine, you can do it in order n steps. And that's actually the point I'm really trying to make here. So if you have here your two tape Turing machine, then two tapes, same language. Now, what we're going to do is copy the a's to the second tape. That we can do on a single pass. And then once the a's have been
2415	copied to the second tape, we can continue on reading the b's and match them off with the a's that appear on the second tape. So in order n steps, you can do the comparison, instead of order n log n steps. And of course, if they match, you're going to accept, otherwise reject. So let's just see, here's a little animation demonstrating that. Of course, it's very simple. So here is-- here are the-- if you could see that, it came maybe a little too fast. Here, let's just show it again. Here is the heads moving across and the a's coming down to the bottom. And now, the head, the upper head is going to continue on reading the b's. The lower head is going to go back to the beginning on the a's and matching off the b's with the a's. And that's how we can verify or check that they are the same number. So now in this case, they were the same number. So the machine would accept. If they were a different number, the
2416	machine would not accept. And the analysis is very simple. Each stage here is going to take a linear number of steps, order n steps, because it just consists of a single scan. There are no-- there are no loops in this machine, no repeat loops. So question on this? All right, why don't we move on then? Now, observe-- and the point I'm really trying to make is that on a one tape Turing machine, you can do it in n log n, but not any better. But on a two tape Turing machine, you can do it in order n. So there's a difference in how much time you need to spend, how many steps you need to spend, depending upon the model. And that's significant for us. So the number of steps depends on the model. One tape Turing machine was order n log n, multi-tape was order n. We call that model dependence. If you contrast that with the situation in the complexity--
2417	we had model independence. The choice of the model didn't matter. And that was nice for us. Because the theory of the decidability didn't depend upon whether you had a one tape Turing machine, or a multi-tape Turing machine, it was all the same set of decidable and recognizable languages. So we didn't have to worry about which model we're actually going to work with. We could work with any model, even just an informal model of algorithm would be good enough. Because we're going to end up with the same notion in the end. Now that goes away in complexity theory. Now, we have a difference, depending upon the model. And from a mathematical standpoint, that's a little less nice. Because which model do you work with? If you want to understand the complexity of some problem that you have at hand, now you have to make a choice. You're going to work with a Turing machine, or how many tapes, or you're going to look at some other model, and you're going to get different results. So it's
2418	somewhat less natural from a mathematical standpoint just to talk about the complexity of some problem. But we're going to kind of bring back something close enough to model independence by observing that even though we don't have model independence, as we did in computability theory, we can limit how much dependence there is. So the amount of dependence is going to be low, as we will see, provided you stick with a reasonable class of deterministic models. So the dependence, though it does exist, is not going to be that much. It's going to be polynomial dependence. And we'll say exactly what that means in a second. And from our standpoint, that's going to be a small difference, a negligible difference that we're going to ignore. So we're going to focus on questions that do not depend on the model choice among these reasonable deterministic models. Now, you may say, well, that's not interesting from a practical standpoint, because polynomial differences, say the difference between n squared and n cubed certainly make a difference in practice. But it really
2419	depends on what kinds of questions you're focusing on. So if you want to look at something that's a very precise distinction, say between n squared and n cubed, then you might want to focus in on which model you want to be working with. And that's going to be more the domain of an algorithms class. But from our standpoint, we're going to be looking at other, still important, questions. But they are questions that don't depend upon exactly which polynomial you're going to have. We're going to be looking more at distinctions between polynomial and exponential. And still, there are important practical questions that arise in that somewhat different setting. So with that in mind, we're going to continue to use the one tape Turing machine as our basic model of complexity. Since the model among the reasonable deterministic models in the end is not going to matter from the perspective of the kinds of questions we're going to be asking. So with that, so we are going to continue, then, it's important to remember that from going
2420	forward, we're going to stick with the one tape Turing machine model. Maybe that's something you would have expected us to do anyway. But I'm trying to justify that through this little discussion
2421	So now, we're going to start defining things with the one tape model in mind. So first of all, if you have a Turing machine, we're going to say it runs in a certain amount of time. So if t is some sort of time bound function, like n squared, or n log n, we'll say the machine runs in that amount of time, like n squared or n log n. if that machine M always halts within that number of steps on all inputs of length n. So it always halts within t of n steps on inputs of length n. Then we'll say that the machine runs in t of n time. So in other words, if the machine runs in n squared time, then the machine, when you give it an input of length 10, it's got to be guaranteed to halt within 100 steps, 10 squared, 100 steps, on every input of length 10. That's what it means for the machine to be running in that much time.
2422	And width that, we're going to come to the following definition, which is highlighted in color, because it's going to be-- we're going to be using this definition throughout the semester. So it's important to understand it. This is the definition of what's called the time complexity classes. And what I'm going to do is take some bound, t of n, and again, think of t of n like a bound like n squared. So if you have time t of n or like time n squared, that's going to be the collection of all languages that you can decide within time n squared or within time t of n. So in other words, it's a collection of all languages B such that there's some one tape Turing machine, here we're focusing again on the one tape Turing machine, there is some deterministic one tape Turing machine that decides B. And that machine runs in that amount of time. So this is a collection of languages. The time complexity class is a set of languages. I'm going to draw it
2423	now as a diagram. So if you take the language, again, that we've been using as our standard example, a to the k, b to the k, that's n time n log n, as we observed two slides to slides back, or three slides back. So on a one tape Turing machine, you can do this language A in time n log n. So it's in the time complexity class n log n. This region here captures all of the languages that you can do in order n log n time. For example, that also includes all of the regular languages. Why is that? Well, any regular language can be done on a one tape Turing machine in time order n, because the Turing machine only just needs to scan across. Doesn't even need to write, just need to scan across from left to right on the tape. And in n steps, it has the answer. So all of the regular languages are actually in time n, certainly a subset of time n log n. And these all form a
2424	kind of a hierarchy. So if you increase the bound, you can imagine that the class of languages grows as you allow the machine to have more and more steps to do its computing. So these are all the languages that you can do in n squared,
2425	n cubed time on a one tape Turing machine, and so on, 2 exponential time, 2 to the n time on a one tape Turing machine. These are all collections of languages getting larger and larger as we increase the bound. So someone is asking kind of-- let's see, let me get to some of these questions here. I'll try to get to them in order. So somebody says if you have-- a good question, if you have a regular computer, so an ordinary sort of random access computer, which we'll talk about that in a second, can do it in order n, can you do it on a multi-tape Turing machine also in order n time? Actually, I don't know the answer to that offhand. I suspect the answer is no. That ordinary computers have a random access capability that Turing machines do not. And so that there are going to be some examples of problems that you can do with a random-- with a regular computer that you cannot do with the multi-tape Turing machine in order n
2426	time. I'd have to double check that, though, so we can-- it's also a question what we believe is true and what we can prove to be true. As we'll see, there are a lot of things that we believe to be true in this subject that we don't know how to prove. Somebody is asking kind of an interesting sort of more advanced question. Is there some function f, some function t where it's so big that so that time t of n gives you all of the decidable problems? It would be a very big t. But the answer actually to that question is yes. But that's a little bit exotic. So let's not spend a lot of time on that right here. But happy to talk about that offline. It's a good question here. Somebody's asking me does it mean that there are no languages between order n and order n log n, because I pointed out that anything below n log n is going to be regular. And so, as soon as you get below n
2427	log n, you can do it in order n. And yes, there is what's called a gap between order n and order n log n on a one tape Turing machine. You don't get anything new from order n until you jump up. So from order n to order n log log n, nothing new shows up. So we'll talk about those kinds of things a little bit down the road, when we look at actually the relationship among these various classes, and what we call a hierarchy theorem, which shows-- how much bigger do you have to make the bound in order to be sure you'll get something new? All right, somebody's asking is there a model which has the same time complexity as a normal computer? Well, I mean, there's the random access model, which is supposed to capture a normal computer. So let me-- these are all great questions, kind of more riffing off of this into more advanced directions. Let's move on. Here's another check-in. Suppose we take-- this is a little bit of a check
2428	to see how well-- how comfortable you are with the notions we've just presented and whether you can think about some of the arguments that we've made and apply them to a new language. So take the language ww reverse, strings followed by their-- followed by themselves backwards. This language B are the even length palindromes, if you will. What's the smallest bound that you need to be able to solve that language B? And I'll pose it as a-- pose that as a question for you. So which time complexity class is that language B in? Is it time order n, order n log n, n squared, so on? What do you think? So we're about to come to the coffee break. So why don't we-- I'll answer any questions that come up. I think we're got everybody answered. So I'm going to end the polling. OK, make sure you're in if you want to be in. So the correct answer is, in fact, order n squared. It would be hard-- reasonable guess here would be order n log
2429	n. I mean, you can come up with the same procedure as the one we showed at the beginning, the order n squared procedure for a to the k, b to the k works for ww reverse as well. You can just cross off, sweep back and forth, crossing off a symbol from w, and going across to the other side, crossing off a symbol from w reverse. And that procedure will give you an n squared and order n squared algorithm. You might imagine you can improve it to order n log n. But you cannot. You can prove that order n squared is the best possible. I'm a little unhappy that a lot of you came up with order n, frankly. Because I already told you that order n is-- these are just regular languages. Anything that you can do in less than-- a little o of n log n is going to be regular. And we know this language is not regular. So this was not a good answer. So please pay attention. And OK, so let
2430	us stop sharing.
2431	And I'm happy to try to take questions along the way as we're waiting for the time to end. So let's see, let me put this up here. Let me try to take some of your questions. So someone is asking me about quantum computers as reasonable models of-- you may say a quantum computer is a reasonable model of computation. And that's fine. I would not say it's a reasonable model of deterministic computation, at least from our standpoint. Let's not quibble about the words. I'm not including quantum computers in the collection of machines that I have in mind right now when I'm talking about the reasonable models of deterministic computation that we're going to be discussing. Let's see. Oh, because a bunch of people apparently are asking the TAs why all regular languages can be done in order n. So if you think about a DFA, which processes an input of length n with n steps, and a DFA is I'm going to be a type of Turing machine that never writes on its tape, so if
2432	a DFA can do it in n steps, the Turing machine can do it in n steps. And so therefore, every regular language can be done in order n steps on a Turing machine. Not sure where the confusion is. So please message me if you're still not getting it. OK, somebody saying why are we using one tape Turing machines instead of random access? Wouldn't it be better to use the random access machines? If you were using-- if you're trying to do algorithms, yes. That's a more reasonable model. We're trying to prove things about the computation. And from that standpoint, we want to use as simple a model as possible. Trying to prove things using random access computers is possible. It'd be very messy. So that's why we don't use random access machines to prove the kinds of things we're going to be proving about computation that are really the meat and potatoes of this course. So I mean, there's compelling reasons why you would want to use a simple model like a Turing machine, but not
2433	a powerful model like a random access computer. So somebody's asking me, does the class time order n log log n have any elements? Yes, it has all the regular languages, but nothing else. Order n log log is it's only the regular languages. You have to go all the way up to n log n before you get something non-regular. Someone's asking me are we going to talk about how the random access model works? No. That's beyond the scope of this course, outside of what we're going to be doing. We're going to talk about Turing machines. Not because we care so much about Turing machines. But I'm trying to prove things about computation. And the Turing machines are a convenient vehicle for doing that. Our candle has burned out. Why don't we return, then, to the next slide. So everybody come back. So this answers one of the questions I got on the chat. What actually is the dependency between multi-tape Turing machines and one tape Turing machines? Can we bound that in general? Yes, we can.
2434	We're going to show that converting a multi-tape Turing machine to a one tape Turing machine can, at most, blow up the amount of time that's necessary by squaring. No, I acknowledge it's a lot. But it still allows you-- but it's still small compared with an exponential increase. And we're going to be focusing, in this course, on things like the difference between polynomial and exponential, not between the different-- not between the difference of-- not the difference between n squared and n cubed. That's going to be less of a factor, less of an issue for us. So the way I'm showing this theorem is that if you have a multi-tape Turing machine that can do a language in a certain amount of time, then it's in the time complexity class of that time bound squared. And the way I'm just saying that is because this is the bound that's utilizing the one tape model. So another way of saying that is converting multi-tape to one tape squares the amount of time you need at most. So the
2435	way we're going to prove that is simply by going back and remembering the conversion that we already presented from multi-tape to one tape. And observe that if we analyze that conversion, it just ends up squaring the amount of time that the multi-tape used. So why is that? So if you remember, let's just make sure we're all together on this, the way the single tape machine S simulates the multi tape Turing machine M is that it takes the contents of each of M's tapes, up to the place where there's infinitely many blanks. Obviously you don't store the infinite part. But the active portion of each of M's tapes, you're going to store them consecutively in separate blocks on S's tape, on S's only tape. And now every time M makes one move, S has to scan its entire tape to see what's under each of the heads and to do all the updating. So to simulate one step of M's computation, S is going to use order of t of n steps, where t of n
2436	is the total running time that M is going to use. So why is t of m steps coming up here? Well, that's because you have to measure how-- S is going to make a scan across its tape. How big can its tape be? Well M, if it's trying to use as much tape as possible, can use, at most, t of n tape on each of-- t of n cells on each of its tapes. So altogether, they're just going to be some constant number of times t of n cells on S's tape. Do you see that? So each one of these is going to be, at most, t of n long. So this all together is going to be order t of n long. Because what can M do? It could send its head out, say the head on this tape here, moving as fast as possible to the right, using as much tape as it can. But you can only use t of n cells in t of n time. So this is going to
2437	be order t of n. So one step of computation is going to be t of n steps on S's computation. But M itself has t of n steps. So it's going to be t of n times t of n for the total number of steps that S is going to end up using. And that's where the squaring comes from. Similar results, I'm not going to do lots of simulations of one model by another. I think that you'll get the idea. And you can, if you're interested, you can study those on your own. But you can convert multidimensional Turing machines to one tape Turing machines, one tape ordinary linear-- one tape, one dimensional machines.
2438	of the reasonable models, they're all what are called polynomially related if each can simulate the other with, at most, a polynomial overhead. So if one of the machines can use this t of n time, the other machine that's simulating it would use t to the k of n time for some k. That's what it means for the two machines to be polynomially related. And all reasonable deterministic models are polynomially related. So as we've already seen, one tape and multi-tape Turing machines are polynomially related, because converting multi-tape to one tape blows you up by, at most, squaring. So k equals 2 in this case. Multidimensional Turing machines, again, polynomially related, the random access machine, which I'm not going to define, but it's the machine that you might imagine-- you would, I'm sure they must define in some form in the algorithms classes, polynomially related. Cellular automata, which are just arrays of finite automata that can communicate with each other, similarly. All the reasonable deterministic models, again, classical models, I'm not talking about quantum computing, are polynomially
2439	related. So we are-- that kind of justifies our choice in picking one of them, as long as we're going to ask questions which don't depend upon the polynomial.
2440	Let's then talk about the class P. So the class P, this is an important definition for us. This is the collection of all languages that you can do in time n to the k for some k on a one tape Turing machine. Or as I've written it over here, I don't know if this notation is unfamiliar to you, but this is like just a big sum. But here, it's a big union symbol. It's union over all values of k of the time class n to the k. So this is time n, union time n squared, union time n cubed, union time n to the 4th, and so on. We call these the polynomial time decidable languages. So we're going to be spending a certain amount of effort exploring this class P and other similar classes. Somebody's asking me why is it a union. I'm not sure how else you would write it. So if somebody-- if you have a proposal for a different way to write it, that's fine. But this is k, this is
2441	for all k. I don't know-- if you only had a limited finite number of k's, you could just take the biggest one. But since it's for all k, you need to write it as a union. Now, I want to argue that the class P is an important class. And why has it had so much impact on the subject and in terms of applications as well? So one thing is that the class P is invariant for all reasonable deterministic models. What do I mean by that? So we have defined the class P in terms of these time classes here, which, in turn, are defined in terms of the one tape model. So we have defined P by using one tape Turing machines. Now if we had defined P in terms of multi-tape Turing machines, we get exactly the same class, because one tape and multi-tape Turing machines are polynomially related to one another. And since we're taking the union over all polynomials, that polynomial difference is going to wash out. Similarly, we could define P using
2442	any of the other reasonable deterministic models. And we get exactly the same class. So in a sense, we get back what we-- the situation that we had in computability theory, when the class of decidable languages didn't depend on the choice of model. Here, the class P does not matter depending upon the choice of reasonable deterministic model. And we also kind of, even in the case of computability theory, we have to stick with kind of reasonable models that cannot do an infinite amount of work in one step. I'm not going to define what it means to be reasonable. That's, in a sense, an informal notion. But among all of those reasonable models, you're going to get the same class P. The other thing that makes P important is that P roughly corresponds to the problems that you can solve in some reasonable practical sense. Now, not exactly, problems that require n to the hundredth time, you could argue cannot be solved in any reasonable sense. But if you think about it, for example, from the perspective
2443	of cryptography, cryptographic codes that people come up with are typically designed to require, or the hope is that they would require an exponential amount of effort to crack. If someone found even an n to the hundredth algorithm to crack, that would crack a code, people would feel that the code is not secure, even though n to the hundredth is still large. So it's a rough kind of test. But it's still used as a kind of litmus test for practical solvability if you can solve it in polynomial time. You basically figured out how to avoid large searches if you can solve problems in polynomial time. We'll say more about that later. But what I want to bring out here is that we have combined, here in the class P, something that's mathematically nice, mathematically elegant with something that's practically relevant. And when you have a combination of the two, then you know you have a winner. Then you know how you have a concept that's going to make a difference. And that's been true for the
2444	class P. This has been very influential within and without the theory of computation. So let's look at an example. Let's define a new language we haven't seen before, though it's similar to procedures that we've looked at before. The PATH language, which is where I'm going to give you a graph G, two nodes in the graph, s and t, where I'm thinking of G as a directed graph. So directed means that the connections between the nodes in G are going to be directed. And that they have arrows on them. They're not just lines, but they have an orientation with an arrow. So G is a directed graph that has a path from s to t that respects the directions. So such a-- I think I might even have a picture here, yeah. So imagine here, here is your graph. If you can see it, there are little arrows connecting the nodes. And I want to know is there a path from the node s to the node t. So that is a picture of a problem,
2445	an instance of a graph of a PATH problem. And I want to find an algorithm for that. And I can show that there is an algorithm that operates in polynomial time for this PATH problem. And the algorithm, any of the standard searching algorithms would work here. But let's just, for completeness sake, include the breadth-first search algorithm that we have explored previously when we talk about finite automata. So we'll mark s. And they'll keep repeating until nothing new is marked. And we'll mark all of the nodes that were reachable by a single arrow from a previously marked node. And then CFT is marked, After you have marked everything you can get to. So you're going to mark-- let's see, pictorially, here I think I have this indicated. Yeah you're going to mark all of the things that are reachable from the start-- from the node s. And then see, after you can't mark anything new, whether the node G is marked. And if it is, you'll accept. If it is not, you reject. Now, we can
2446	analyze this, too. And I'm not going to be spending a lot of time analyzing algorithms here. But let's just do it kind of this one time. We're doing a bunch of iterations here. So we're going to be repeating until nothing new is marked. So each time we mark something new, we can only do that, at most, n times. At which point, we've marked everything. So the number of iterations here is going to be, at most, n. And now for each time we mark something, we have to look at all of the previously marked nodes and see which things they point at to mark them too. So this is going to be an inner loop, which again, has, at most, n iterations, because it's going through all of the previously marked nodes. And then once we have that, we can scan G to see-- to mark all of the new-- all of the nodes which we have not yet marked, whether they're connected with a previously marked node by an edge. And I'm being generous here,
2447	because I don't really care. This can be done in, at most, n squared steps on a one tape Turing machine. I'm not going to describe the implementation. But I'll leave it to you as an exercise. But this is straightforward. So the total number of steps here would be n iterations times n iterations times n squared. So you're going to be, at most, n to the 4th steps needed. So this is a polynomial algorithm. And whether I ended up with to the 4th, or n to the 5th, or n cubed, I don't really care. Because I'm just trying to illustrate that the total is polynomial. And that's all I'm going to be typically asking you to do. So to show polynomial time, what I'll be asking you to do is to show that each stage, each stage of this algorithm, should be clearly polynomial. And that the total number of stages, I'm sorry, this should say stages here, should be polynomial. So each stage is polynomial. And after you're doing all the iterations, the total number
2448	of stages that are executed is polynomial. And so therefore, all together, the total running time, the total number of steps, is going to be polynomial. So that's the way we would write up polynomial algorithms in this class. So let's see if there's any questions here. I don't want to get too far ahead of people. Let's see. Yes, in this theorem, I'm talking about one tape Turing machines, because we're defining everything in terms of one tape Turing machines. But now, at this point, when we're talking about polynomial time, my analysis is based on one tape Turing machines. But in general, you could use any reasonable deterministic model on which to carry out your analysis, because they're all polynomially equivalent. So from the perspective of coming up with showing that a problem is in polynomial time, is in P, you can use any of the models that you wish that for convenient. Oh, that's a good question. What is n, thank you for asking that question. n is always going to be reserved to indicate the length
2449	of the input. So here, n is going to be when we encode G, s, and t. And here, also, I haven't said this, but I'm assuming that the encoding that you're using is also somehow reasonable. I think we'll talk a little bit more about that in the next lecture, which is going to be after the midterm. But you can cause problems if you intentionally tried to come up with nasty encodings, which will represent things with unnecessarily many characters. But if you try to be reasonable, then just use any one of those encodings, and you'll be fine. So yeah, so n is the length of the representation of the input. Let's see. Someone's trying to dig into the actual how this is running here. Scan G to mark all y where xy is an edge. I'm saying that you can do it in n squared steps. If you have x, you can mark it in a certain place on the tape. And then as you're going to every other node, every other edge, you can go
2450	back and compare x with the x of the edge and then see-- and then find the y. I mean, it's just going to be too messy to talk about here. I mean, I'll leave it as an exercise to you. I'm not going to try to fumble my way through explaining why you can do this in n squared steps. But it's not hard. You guys are all really hardcore algorithms folks. You want to know the algorithms for this, I'm not going to do that, sorry. High level picture here. If you want-- if you want to look at detailed analyses, this is not the right course for you. Can k equal n? What is k? No, if you're talking about this k here, k cannot equal n. We're not looking at n to the n. These are all fixed k, it's like n squared, n cubed, but not n to the n is it going to be an exponential bound. And so that's not going to be included within this union. So we're near the end of
2451	the hour. I'm going to introduce one last language here, called HAMPATH. And the HAMPATH problem is-- I'm going to ask now, again, for a path from s to t, but now a different kind of path, one that goes through every node of G along the way. So I'm looking for a path that goes, that hits every node of G, not just the shortest, most direct path. But in a sense, the most indirect path, the longest path that goes through from s to t that visits everything else along the way. A path of that kind, that hits every node of the graph is called a Hamiltonian path. Because the mathematician Hamilton studied those and made some definitions about that. I'm not going to-- I don't actually know the history there. But I just know they're called Hamiltonian paths. So here's a picture. I want to get from s to t. But I want to sort of pick up everything else along the way. So as you remember, the PATH problem itself can be solved in P.
2452	And what I'd like to know, can this simple modification, where I'm asking you to visit everything else along the way, is that problem also in P? And I'm going to pose this as a check-in for you. But actually, before I get to that, let me give you an algorithm for HAMPATH that doesn't work to show it's in P, because it's exponential. So here's an algorithm for HAMPATH, where let's m the number of nodes in G. And what I'm going to do is I'm going to try every possible path in G and see if it's actually works as a Hamiltonian path, and accept if it is. And then if all paths fail, then I'll reject. So I'm going to try every possible routing through G. If you want to think about it, think of m as every possible permutation of the nodes of G. And then you're going to see whether that's actually constitutes a path in G that takes you from s to t and goes through all of the nodes. So this algorithm would
2453	work. This would give you a correct algorithm for the HAMPATH problem. The problem is, the difficulty is that there are so many possible paths that it's going to take you an exponential number of steps to execute this algorithm. It's not a polynomial time algorithm, because there are many possible paths that you could go through. If you're looking at it with a very crude bound, but you really can't improve that significantly, there would be m factorial, which is going to be much greater than 2 to the m paths of length m. So the algorithm is going to run for exponential time, and not polynomial time. So my question for you is, I'm going to pose it as a check-in problem, is whether you could actually do this problem in polynomial time. So why don't you think about that as I'm setting up the question? So take the HAMPATH problem, just like the PATH problem, which I described with that marking algorithm, but now you want to hit every node along the way, can you show that
2454	problem as solvable in P? And there's a whole range of possibilities here where either the answer is yes, you can see what the polynomial time algorithm is to definitely no, where you can prove there is no such polynomial time algorithm. And I'll put this is the check-in for you and see-- I'm curious to see what you come up with. Most people are getting it wrong. Well, wrong, I don't you know-- I'm not clear what wrong is here. OK, are we done? Please check something. I see a few of you have not answered. But the poll is running out. OK, time is up. So in fact, as I think many of you know, but not all of you, this is an unsolved problem. This is a very famous unsolved problem, which is equivalent to the P versus NP problem that we're going to be talking about very soon, which, among other things, would be worth a million dollars if you solve it. So for those of you who have answered a or e, please talk to
2455	me after lecture. And maybe we can work on it together. No, so yeah, I think most people would believe that the answer is no. But no one knows how to prove it at this time. So I'm interested in the folks who have come up with what they think are solutions. And I should say that there are some folks who believe that there might be other outcomes besides just a simple no. Which might be proven eventually. So we're going to talk more about this. But this is the answer to the question, just for your-- just to make sure you understand is that it's an unsolved problem right now. So we don't know. Definitely yes and definitely no, at least according to the state of knowledge of which I'm aware, are not correct answers. But any of the others, well, who knows? So I think that's the end of what I had to say for today. We covered complexity theory as an introduction, looked at different possible models, focused on the one tape model, introduced, based on
2456	the one tape model, these complexity classes, the class P. And we showed an example of this PATH problem being in P. Talked also about this HAMPATH problem, which we'll talk about more after the midterm. OK, so I'll stick around for a few minutes if you have any further questions. Otherwise, so let me just take questions here. Somebody is asking me about my personal opinion on P versus NP. My personal opinion on P versus NP is that P is not equal to NP and that we will prove it someday. When I was a graduate student back in the mid '70s, I thought it would be solved by now. And in fact, I made a bet with Len Adleman, who I subsequently ended up becoming the A of the RSA code, that we would solve it by the year 2000. And I bet what was then a lot of money for me, which was an ounce of gold, which I didn't end up-- which I did end up paying off to Len in the year 2000. So
2457	I'm not making any more bets. But I still believe that it will be solved. Hopefully I'll get a chance to see the solution. I spend a lot of time thinking about it myself. Obviously, I haven't solved it, otherwise we would know. But hopefully somebody will. I'm gettings asked a question here that's kind of an interesting question, but I don't really know I'm sure I understand it. What's the largest possible runtime of a decidable problem? What is the largest decidable runtime? So anything that I can describe can be-- there are going to be algorithms that run for longer. You can define an algorithm. You can define a runtime, which would, in a sense, beats all other runtimes. So that any runtime is going to be dominated by that extremely slow runtime. But it's not something that one can describe. I can describe it to you by mathematical procedure. But it's not going to be something like 2 to the 2 to the n. Somebody's here proposing a solution to the HAMPATH problem by presuming polynomial time.
2458	Why is the following flawed? If s goes through all nodes and ends up at t, Well, s we're not-- you mean, I presume you mean starting at s, if we end up going through all nodes and end at t, the proposal is a little complicated here. Basically, if I can try to rephrase it, you want to try to-- from every possible node, you want to try to calculate a path to t and also a path from s to that node. And you can do that for all possible nodes. But there's no way to really combine them into a single path that visits all. Solving for each node separately is not going to do the trick, because you have to somehow combine all that information into a single path, just one path that goes from s to t and visits all the other nodes along the way. And that that is not-- I don't see what your proposal, how that's going to actually work. AUDIENCE: Professor Sipser. A question on the-- we were kind of talking
2459	about earlier, what we talked about today was defined for the one tape Turing machines, correct? MICHAEL SIPSER: Yep AUDIENCE: So and you said we could apply for the multi-tape ones, but are-- I don't know if we talked about earlier, if something is accepted by the one tape machine, can it be applied to the multi-tape Turing machine and vice versa? Are they interchangeable like that? MICHAEL SIPSER: Well they're interchangeable only in the sense that the amount of time that you would need-- it's a different machine. If you have a multi-tape Turing machine for some language, you can convert it to a one tape Turing machine using the procedure that we described earlier in the term. And you'll get a different machine. It's going to run for a different amount of time by using that procedure. The point is that the amount of time that the one tape Turing machine is going to run for is not that much worse than the multi-tape Turing machine's time. So if the multi-tape Turing machine's time was n cubed, the
2460	one tape Turing machine's is going to be the square of that. So it's going to be n to the 6th. But it's not going to be-- going from multi-tape to one tape is not going to convert you from polynomial to exponential. That's the only point I'm trying to make. It's going to convert from one polynomial to a somewhat bigger polynomial. But it's still going to leave you polynomial. I don't-- you don't seem-- I can't see your face. AUDIENCE: No, I guess my opinion is just, especially when we were talking about earlier, when you were bringing it up, it just seemed like you could just turn anything to a multi tape Turing machine and completely cut the time out. If I had like something in n log n, if I did it in the multi-tape Turing machine, I have it in big O of n, you know what I mean? It just seemed like the multi-tape was so much more powerful. But then I guess not, with the explanations and the models we were talking about
2461	today. MICHAEL SIPSER: Yeah, I would not say-- the multi-tape Turing machines are still pretty limited in their capabilities. And don't forget, when you have a multi-tape Turing machine, you have only a fixed number of tapes. I mean, you can also define variations of multi-tape Turing machines that have an increasing number of tapes as the input, either under program control, it can launch new tapes. Or it could just have more tapes depending upon the size of the input, that would also be a possibility. That's not the model that we have defined. But you could define a model like that. But as long as the total amount of work being done by the machine at any step s going to be a polynomial amount of work, then you can convert it to a one tape Turing machine with only a polynomial increase in the bound. You want to be careful of machines-- one thing I meant to say but didn't say, so here would be an unreasonable model, which you might think of as a plausible model.
2462	But it's not going to be a reasonable model from our standpoint. And that would be a model, for example, that can do full precision, say, integer arithmetic with a unit cost per operation. So each operation counts as costs 1. But I'm going to allow you to do, for example, addition and multiplication. The thing that's bad about that, in terms of being unreasonable, is that after k step, each time you do a step, you could double the size of the integer by squaring it. After k steps, you can have an integer, which is 2 to the k long. And now, doing operations there is going to involve an exponential amount of work, even in any reasonable sense. In a theoretical sense, and also in a practical sense. A model that operates like that is not going to be able to convert to a one tape Turing machine with only a polynomial increase, because it's doing an exponential amount of work potentially within a polynomial number of steps. So that's within a linear number of steps, within
2463	n steps. So that's an example of an unreasonable deterministic model. AUDIENCE: Yeah, thank you. MICHAEL SIPSER: Sure. AUDIENCE: So I'm just curious, some idea just occurred to me. I guess if you have an Oracle Turing machine, basically just so that you could look at a Turing machine description and decide whether it's a decider or not, then it'd be a little bit interesting to think about what happens if you look at all-- if you have a description of a pair of the Turing machine and an input string, then you can look at for all size n descriptions of a pair, what's the most steps that it takes for such a machine to convert it. So then you'd have combined Turing machine and input string descriptions, where you could look at what's the longest it takes to convert. I don't know. It's just a random thought that occurred. MICHAEL SIPSER: Yeah, so we actually-- we're going to-- we will talk about Oracle Turing machines later on in the term. These are machines that have access to sort
2464	of free information. And that actually turns out to be-- there's some interesting things you can say about what happens when you're providing a machine with, in a sense, information for free. That you might otherwise want to charge it for actually computing that information. But let's just say we're going to allow it to get that information without being charged. And then how does that affect the complexity of other problems, for example? And so we will talk about that later. But too much of, I think, of a digression at this moment to try to define all that. But happy to chat with you about it on Piazza if you want to raise a question there. AUDIENCE: Thank you. MICHAEL SIPSER: Sure, no problem. Somebody's asking me about strategies for solving the P versus NP problem. We will talk also talk about that a little later in the term as well. But clearly, it seems beyond the reach of our present techniques to be able to prove that some problems really take a long time. Like that Hamiltonian
2465	path problem, it seems like there's nothing really you can do with that significantly better than trying all possibilities as I described in that exponential algorithm on the last slide. But how do you prove that? Nobody knows. So lots of people have tried, including yours truly. I mean, I've spent a lot of time thinking about it. Haven't succeeded with it. But there is somebody, I think, someday, somebody will come up with the new idea that's needed to solve it. But it's going to clearly take some sort of a breakthrough, some sort of a new idea. It's not just going to be a combination of existing ideas, existing methods. I think we're about 10 minutes past. A few of you are still here. I'm going to say goodbye to you folks. And shortly, I'm going to join my TAs for our weekly TA meeting. So see you guys. Thanks for being here.
2466	[SQUEAKING] [RUSTLING] [CLICKING]
2467	PROFESSOR: OK, why don't I get started? So OK, what have we been doing? So last time, we considered a bunch of procedures for testing properties of various automata and grammars, the acceptance problem for DFAs, for NFAs, the acceptance problem, which is really degeneration problem for context-free grammars, and emptiness problems for DFAs and context-free grammars. And also, we showed that A,TM is Turing-recognizable. There's a question here in the chat already about that. Yes, we did show that. That was the universal Turing machine that we presented at the end. That's what shows that A,TM is Turing-recognizable. We mentioned that A,TM is not decidable, which we promised we will prove today. And we will do so. OK, so that is the plan-- proving A,TM is undecidable. And we'll introduce the method for doing that called the diagonalization method. I will also show the complement of A,TM is Turing-unrecognizable. Even though A,TM itself is recognizable, the complement is not. And then we will introduce another method called the reducibility method for showing other problems are not decidable and give
2468	one example of another problem, which is not decidable, assuming we have time to get to it.
2469	All right, acceptance problem for Turing Machines. So just as I mentioned, we showed that A,TM, which is the language of Turing machines and inputs where the machine accepts the input. We showed that was recognizable. We claimed it was decidable. Today, we're going to prove it's not decidable. All right, now the method that we're going to use, which is really the only method out there for proving a problem as undecidable is called the diagonalization method. I mean, ultimately, we're going to show the reducibility method as well. But it really depends on having already shown some other problem undecidable via the diagonalization method. So ultimately, everything hinges on the diagonalization method, which is really what we have.
2470	I'm going to make a bit of a digression into a branch of mathematics called set theory or it's a part of mathematical logic, where the method of diagonalization was first conceived of back in the late 19th century by a mathematician called Georg Cantor. And Cantor was considering the problem of, how do you compare the relative sizes of infinite sets? For finite sets, the problem of comparing-- somebody said that Cantor went crazy. That is true. And maybe I don't know why he went crazy. But he did go-- he had some mental problems, unfortunately. And so how do we compare the sizes of sets in general? If they're finite sets, we can just count them up. We can say, whoa, this set has 11 elements, and the other set has 10 elements. So the one with 11 is bigger. Or if they both have 11, they're the same size. Well, that's not going to work for infinite sets because you can't count them up. And so he had-- Cantor had the following idea for comparing the sizes
2471	of infinite sets. And that was, basically, to see whether you can have a function that would map from one set to the other set with certain properties. And those properties are called, traditionally, well, I mean, in the past, have been called the one-to-one and onto properties for the function. I'll tell you what that means. But the concept is very simple. So a one-to-one function is a function that's mapping from A to B. Those are the two sets whose sizes we're trying to compare. And the function being one-to-one just means that there are no collisions. If you have two different elements of A, they're never going to map onto the same element of B. So two different elements of A always map onto two different elements of B. So that's the one-to-one property. It's also called injective. And the other property is called onto or surjective, which is that the range of f has to be all of B. So you're not allowed to miss any elements, but you have to hit everything. And when you
2472	have both of those properties, the function is called a one-to-one correspondence or a bijection also, OK? Now another way of looking at it-- I don't want to make this more complicated than it needs to be. It just simply means that two sets are considered to be the same size if we can match up the elements with one set with elements of the other set. You just pair them up. For example, well, if you have finite sets, that idea, that informal idea just works exactly as you would expect. For example, if we have two sets-- here's a set of puppies. Here's a set of kittens. Now we want to show that those two sets have the same size. We could count them up, as I mentioned, and see that there are six elements in both. But counting up does not work for infinite sets. So we can just match up the elements of the puppies with the kittens, and then we know we have the same number of puppies as kittens. OK, now that has the
2473	advantage of it making sense when you have infinite sets. So we're just going to extend that idea and apply it to infinite sets too. And then we'll have a notion of what it means for two infinite sets to have the same size. And you might wonder, what do you get? Are all infinite sets of the same size when you use this notion or not? What happens? Well, some strange things do happen. But there actually are quite some interesting structure there that emerges. So anyway, I don't want to rush on. Questions on any of this? If you want to-- quick question. This, hopefully, was not too hard, but I want to make sure everybody's together with me on it, so we can pop in-- I'll give a few seconds for a chat if you have any questions. The range of the set is all of the elements that you hit as you look at the different possible elements of A. So all of the things that f hits, the standard notion of a range of a
2474	function. So the range of f has to be equal to B. You have to hit everything. All right, can you think of a one-to-one correspondence as a relabeling? Yeah, I'm not sure that's helpful. But, yes, you can think of as a relabeling of the elements in a sense, but yeah. I just think of it as a matching up.
2475	So coming out of this notion of sets being of the same size with this notion of countable sets, as we'll see in a minute, so let's do an example. Let's take the set of natural numbers-- 1, 2, 3, 4, dot, dot, dot, dot, and the set of integers, which includes the natural numbers but also the negative numbers and zero. So the natural numbers are typically referred to as N. The integers are typically referred to as Z. And what do we think of the relative sizes of N and Z? Well, N is a subset of Z. It's a proper subset of Z. So you might, at first glance, think that Z is larger, and they're not really going to be of the same size. But actually, it turns out that there's a very simple way-- the arithmetic and the properties of infinite sets can be a little bit surprising. And there is a way of matching up all of the elements of Z with their own elements of N. And so you can show that following
2476	that definition, that these two sets are, in fact, of the same size. So let's just quickly go make sure you see that. So here is N. Here is Z I'm going to write down a table which shows how they match up. Here is the function f of n that I'm going to be describing. That's the one-to-one correspondence. And so here are the natural numbers-- dot, dot, dot, 1 through 7, dot, dot, dot. And here are the elements of Z that I'm going to be matching up. This is how the function is working. So one, I'm going to-- f of 1 is going to be 0. F of 2 is going to be minus 1. F of 3 is going to be 1. And I'm just giving you a way to match up each of the natural numbers with integers so that every single integer has its own natural number and vice versa. So 4 goes to minus 2. 5 goes to 2. 6 goes to minus 3. 7 goes to 3, and then minus 4,
2477	and then 4, and minus 5, and then 5, and so on. You're clearly going to cover all of the integers in this way. And each of the natural numbers is going to have its own integer. And there's never going to be any collisions. There's never going to be two natural numbers assigned to the same integer. So this meets the conditions of a one-to-one correspondence and shows that the natural numbers and the integers have the same size following this definition. OK, let's do one that's slightly more complicated and, perhaps, slightly more surprising, which is that if you consider all of the rational numbers, and then they have the same-- that is a collection. Even though the rational numbers seem to be much richer and more numerous than the integers, from this perspective, they have the same size. And for the simplicity of my presentation, I'm going to consider only the positive rational numbers, which I'm going to write as Q+. So those are all of the positive rational numbers that can be expressed as a ratio
2478	of two natural numbers. And I'm going to show that there is a one-to-one correspondence between these positive rational numbers and the natural numbers. OK, so here, I'm going to, again, make a table, just as I did up above-- so comparing the natural numbers and the positive rational numbers. And to do that, I'm going to write down over here on the side, just to help you see how I'm getting this table, a separate table that has all of the positive rational numbers appearing in a nicely organized way. Here are all of the rational numbers here that have 1 as a numerator, that have 2 as a numerator, and so on, and going through across the columns, the different denominators. So the numbers inside here represent all of the different rational numbers. And so whatever rational number you have, m over n, that's going to appear down the nth row in the nth column. That number is going to appear. So they're all going to show up. And I'm going to use this table here to fill
2479	out this function. So here are all the natural numbers. And the way I'm going to assign the rational numbers to appear over here is I'm just going to work my way in from the corner. And I'm going to do that by doing layers. So first, I'll take the 1 in this number here in this corner. Then, I'll do these three that surrounded it, and then these guys that surround that, and these guys sort of in shells going around the previous ones that I've already covered. OK, so let me illustrate that. So here's 1 over 1, my first rational number that I'm going to enter into the table, appearing right over there. So next, I'm going to go 2 over 1. That's going to appear in the table over there. Now, we have 2 over 2. Now that's actually a little bit problematic because 2 over 2 has already been done. And if we put that in-- because 2 over 2 equals 1 over 1. They're both the equal to the rational number 1. So if
2480	we put 2 over 2 in this table over here, then we would no longer have the one-to-one property because both 1 and 3 would be mapping to the same point. So we're just going to simply skip over 2 over 2. I'll show that as kind of graying it out. So we're not going to add that one on to the table onto my function. But so we'll skip over that. We'll go to 1 over 2, which has not been seen before. And then we're just going to continue doing the same thing, now going to this next shell out here. 3 over 1, 3 over 2, 3 over 3-- same thing, we're going to skip over that one-- 2 over 3, 1 over 3. I hope you're getting the idea. So I'm not going to fill this table. I ran out of room to fill out this table some more. But just to look at how the process is going to continue here, we get 4 over 1. Now 4 over 2, again, is a number we
2481	previously seen because that's the rational number 2. We saw that up here when we had 2 over 1, so we're going to have to skip that one. 4 over 3, 4 over 4-- that was going to skip. 3 over 4, and so on. OK? So by following this procedure, I'm going to be able to define this function. Now this function is not particularly nice in terms of having an elegant, closed form. But it is a totally legitimate function in the sense of being a mapping from natural numbers to the positive rational numbers. And it has the one-to-one correspondence property. So it pairs up each of the natural numbers with each of the positive rational numbers. They each get their own mate, in a sense. And so that shows that the rational numbers, despite the fact that they're dense, and they have all sorts of very more much bigger seeming, they really, from this perspective of the sizes of the sets, they have the same size as the natural numbers do. And so with that, it
2482	suggests that the following definition that a set is countable if it has the same size as the natural numbers or it's finite. From this perspective, we're going to be focusing on infinite sets. But yeah, countable or countably infinite, sometimes people say, if it has the same size as the natural numbers. Or otherwise, you have to include the finite sets as well. And countable means you can just go through the elements of the set as a list. So you can count them-- the first one, the second one, the third one, the fourth one, dot, dot, dot. And once you can do that, and that counting is going to hit everything, then you know can match them-- you can pair them up with the natural numbers. And so therefore, you have a countable set. OK. So as we've shown, both Z, the integers, and the positive rational numbers are countable sets. OK? Now you might think that, well, since we're allowing ourselves to do something as arbitrary, in a way, as this kind of a function to
2483	match up the natural numbers with whatever set you're trying to measure, that every set is going to be countable, if you think about it that way because it seems like you're allowing too many possibilities. And then all the infinite sets are going to end up being the same size as the natural numbers. Well, that is, in fact, is not true. And I don't know. Cantor, is the one who discovered that. I don't know if that was surprising or not. But it is interesting, I think, that there are different sizes of infinities. And so we're going to now take a look and see that. But I want to, again, I want to stop and make sure we're all together. Can we always find a closed formula for f, somebody's asking me. I don't know. For this particular f, you probably could, but it would probably be very messy. But in general, that's not a requirement, having a closed form for the mapping function. Any function is allowed as long as a one-to-one correspondence. Are we all
2484	together on this? Are we comfortable with the notion of some infinite sets having the same size as the natural numbers, and therefore, we're going to call them countable sets? And we're going to show some other sets are going to have more elements. They're going to be uncountable. They're going to be beyond-- strictly speaking, strictly larger sets in the sense that we won't be able to put them into a one-to-one correspondence with the integers. So is N the smallest infinity? Yes, N is the smallest one. So any infinity is going to have-- you're going to always-- I don't think you even need it-- you need a special-- whenever you have an infinite collection, you can always find a subset which is going to be a countable subset and is going to be the smallest of the infinities, but there are bigger ones. All right, why don't we move on?
2485	OK, so the example of a set that we will show is not countable-- an uncountable set, as we call it-- is a set of real numbers, which we all know what these are, I hope. These are all of the numbers that you can express by possibly infinite decimal representations like pi, or E squared of 2, or any of the other familiar ones. Rational numbers are also members of or also count as real numbers and integers too. And so but there are these additional numbers that you can get by the decimal expansions which may not be rational. And that collection, even though, in some ways, it looks somewhat similar to the rational numbers, the real numbers-- I hope I said that right. The real numbers, which is the set I'm considering here, the ones with the infinite decimal expansions, they actually are much larger. So the theorem is-- and this was discovered by Cantor-- that R is an uncountable set. And the reason why I'm introducing this is, besides that I think it's interesting and has
2486	some relation to the kinds of things we're doing, but it's really for the purposes right now, is to introduce this method called diagonalization. OK, that's what we're going to use later on again. But this is the first time it appeared. So we're going to use a proof by contradiction in order to show that R, the collection of real numbers, is uncountable. And we'll assume, for contradiction, that R countable. OK? So if we assume that R is countable, it means we have, by definition, a one-to-one correspondence from the natural numbers to the real numbers. OK, so we can match up all of the natural numbers with the real numbers in a one-to-one and onto fashion. So we can pair up the natural numbers with the real numbers. And we will cover all of the real numbers by doing that. And we can make a table, just like I did before. Here it is. And you can fill this out with all of the real numbers. And that was what the assumption means. And I'm going to
2487	show you that that's impossible. Something is going to go terribly wrong if you do that. Now you might disagree. You might be surprised. You might think, well, Professor Sipser is wrong, that I'm going to work on this overnight and forget the rest of my classes, and I'm going to come up with a list of all the real numbers. I'm going to fill them out here and show that that's impossible. So let's say, hypothetically, just for my example's sake, here is the list that you came up with. So you have to match up something with the 1. Let's say, E. That was a special case, so you're going to stick that with 1. And then pi came out to be the number that you connected up with 2. You understand what I'm doing here? I'm making a list. I'm trying to make my correspondence-- my matching up between the natural numbers and my real numbers that I'm hypothesizing to exist for a contradiction. So 3, I don't know, 3 is gets connected to 0. I'm making
2488	this up, obviously-- not on the spot. I wrote the slide, you know, yesterday. But here is the square root of 2 showing up for whatever reason. Here is 1/7. Here is some other number, which, I'll be interested if you recognize that one. That's a subtle one. This is 1.234-- yeah, some familiar looking sequence here. And whatever it is-- whatever it is, this is what you came up with. You claim that this is going to work as-- very good. Somebody got it. It's i to the ith power. But let's not get hung up on that, please. I to the ith power, oddly enough, can be seen as a real number under-- if you define the imaginary exponentiation, which is weird. But anyway, let's not get too distracted. So here's my list of numbers, my real numbers that I've matched up in my table here with the natural numbers. Now I claim something goes wrong. What goes wrong? I'm going to show you that you actually did not do as you claimed, that there's actually at least
2489	one number that's missing from this list. And I'll exhibit that number. I'm going to show you what that number is. I'm going to explicitly come up with a number and show you that there's that number it's missing from the list. So here, it's going to be a number x. X is the one that's missing. So how am I going to get x? So x, well, I'm going to start it off with 0 point, and then I'm going to fill out the rest of the places. And how am I going to get those places? I'm going to look at the table here. So I want to look at-- to get my first digit after the decimal point of x, I'm going to look at the first digit after the decimal point of the very first number. So I take the first number, look at the first digit after the decimal point, which happens to be a 7. And the number I'm going to put in for x It's not going to be 7. It's going to
2490	be anything except 7. Let say, 8. For my next digit of x, I'm going to look at-- so my second digit of x, I'm going to-- everything's going to be up to the decimal point now, so I'm not going to keep saying that. I'm going to look at the second digit of the second number, which is a 4 after the decimal point. There it is. And for the second digit of x, I'm going to use something which is anything besides 4-- 5. I have some flexibility here. So I could have used 6. I could have used 7. For those of you who have seen this before, who are going to nitpick on me, I'm going to stay away from 9 and 0 just because there is some little edge cases that arise there, which I don't want to get into because I don't think it's interesting for this argument. But since I have some flexibility, I'm going to avoid zeros and nines-- probably just nines is all I really need. And then the argument is
2491	just going to work fine, OK? So the next digit is a 0. The third digit, or the third number is a 0. The third digit of x is going to be anything except for 0. It could be a 1. Then I have a 2 here. Anything except a 2, 6. Then a 5-- anything except a 5, a 1. A 9-- anything except a 9, an 8, and so on. There's an 8. There's a 2, and dot, dot, dot. I'm just going to keep doing that. And I'm going to say you missed that number, whatever it is. But that number, that's a number. After I'm all done, it's going to be the decimal representation of something. And that number, I claim, is absent from the table. And you might say, well, it's really there. It's just on the 23rd row. You just didn't get to it and your slide. But it's there. Well, I'm going to say I know it's not in the 23rd row because it differs from the number in the 23rd row at
2492	the 23rd digit because I constructed it that way. This number is designed explicitly to be different from each of the numbers that's on the list. So it can't be on the list because it's been constructed to be different from each of them in at least one place. So I think this is a beautiful argument, and it shows that no matter how you try to come up with a one-to-one correspondence, you're going to fail. You might say, oh, like, just one number? I did so much hard work. I'm missing just one number. Can't I get partial credit and put this one on the list now I fixed it? No. Obviously, there are many, many numbers that are missing. If you put this one on the list, I was going to construct another number that was missing. So there's just not no possibility of fixing this. And in fact, the real numbers are uncountable-- cannot be matched up with the natural numbers. And there's nothing. It doesn't even come close. So here, a summary of what I
2493	just said. F is not a one-to-one correspondence no matter what you try to do. You can't come up with a one-to-one correspondence. That's the contradiction. So that proves that R is uncountable. And that's why, by the way, we call this a diagonalization because we're going down this diagonal here that's where the term-- that's where the name is come from. OK, so I'm happy to-- [CHUCKLES] OK, that's a-- somebody's asking me-- [CHUCKLES] I'm actually-- I have a-- is it here? I can't remember if it's here. I have a check-in coming about this. And somebody is anticipating that by asking the actually rather famous question about there being a possible infinity in between the natural numbers and the real numbers. We know the real numbers now are bigger than the natural numbers. But is there something that's an in between? I mean, this is a very, very famous problem, which I'll talk about when we get to our check-in, which is coming up. Somebody is objecting just the way I've defined x using this procedure that really
2494	can't, in a sense, state, you know-- but x is a number. X is the result of what this procedure is. Following this procedure, we're converging on some particular value. And so that is a value. If you want, we can make a more precise way of determining. We don't have the flexibility of choosing the way I did in my example. We can make a precise procedure for coming up with these digits. But I don't think there's anybody thinks there's anything that's-- there's any shortcoming in this argument in terms of the way we're defining x. I think it's worth understanding this because it's really going to set the groundwork for our proof that A,TM is undecidable, which is a little, I think, perhaps, slightly more abstract in a way in the way it sort of comes across. I'm going to try to connect the two. But I think it's helpful to understand at least this argument because this argument is diagonalization in its most raw form. All right, I think we're good.
2495	So there are a number of corollaries that follow from the statement that the real numbers is uncountable. First of all, if you let script L be the collection of all languages, if you want to consider it over some particular alphabet, that's fine. But that's not going to be really important for this point that I'm going to make. So script L is the collection of all languages. So every subset of sigma star-- every subset of sigma star is a language. So look at all those possible subsets. So that includes 0 to the k, 1 to the k, plus every other language you can ever think of and more-- all possible languages. So the collection of all languages is uncountable. There's uncountably many different languages out there. I don't want to belabor this point. You can just take this if you don't quite follow the quick argument I'm going to make here. But you can make a one-to-one correspondence from all languages to the reals so that each language gets its own real number. And the way
2496	I'm going to think about that-- let's put the real numbers into binary form. And if you imagine here being sigma star, all of the possible strings of sigma star written out in their standard order. And now if you have a language here, A, it's just some arbitrary language. So that's going to have some of the strings of sigma star appearing. Like 0 is appearing, but 1 is not appearing. 00 is appearing and 01, but not these three. And I'm going to associate to A, my language, some real number in binary by putting in a 0 in the decimal representation-- well, the binary representation, I should say-- for that string if it's not there and a 1 if it is there. And so a real number-- because there's infinitely many yes/no choices in the binary representation can represent a language because of each of the yes/no choices of a string being present or not. I'm going to put a 1 for when the string is present, a 0 when it's not present. So each language has
2497	its own real number, and each real number is going to be associated to its own language. Here, I'm restricting myself to real numbers between 0 and 1. That's not going to be an essential point. So let's not get hung up on that. So the fact that the languages can be putting it into a one-to-one correspondence with the real numbers shows that the collection of all languages is also uncountable. Now another observation here-- another point worth noting is that if you look at sigma star itself, the strings, all possible strings, that's a countable set. The collection of all possible languages is uncountable. But the collection of all possible finite strings is countable because I can just list them. Here's my list of all possible strings, which you can put into a table if you like to think of it matching up with the natural numbers in that way. Now I'm trying to make a point here, which is that if you take M, which is all possible Turing machines-- script M is all possible Turing machines--
2498	the collection of all possible Turing machines is countable. There are only countably many different Turing machines. And you can argue that in all sorts of messy different ways. But I think the most simple way to see that is to think about each Turing machine as having a description, which is a string. So the collection of all descriptions of Turing machines is just a subset of sigma star, which we already know is countable. And the subset of any countable set is going to be countable. So anyway, I think it's worth remembering that the collection of old Turing machines is countable. Whereas the collection of all languages is uncountable. And that tells you right there that some language is not decided because there are more languages than Turing machines. We've unaccountably many language, only countably many Turing machines, so that's fewer Turing machines than languages. There's no way to map all the languages onto Turing machines. So there's going to always be some languages that got unmapped. And so, in particular, there are going to be some
2499	languages which are undecidable. There are going to be some languages which are not Turing-recognizable. And anything based on some automata kind of a definition process is going to be some languages that they're not going to be defined. OK, now what this corollary shows you that there is some language out there, which is not decidable. What we're going to show next is that there is a specific language-- A,TM-- which is not decidable. And but first, I think we have a check-in coming up. And let me give you a little bit of background here because this is relevant to this question that I got about intermediate size sets. So the question of whether there is a set of size between the natural numbers and the real numbers strictly in between-- so bigger than the natural numbers, not the same size as the natural numbers, but not the same size as the real numbers either, but in between in size. That was Hilbert's question number 1 out of his list of 23 that I talked about a few
2500	lectures back. It's interesting that he put it as number 1 in that very privileged special place because I know Hilbert was very-- he felt that the understanding infinity was a really central issue in mathematics. And that if we can't answer a question like this, we don't really understand infinity. You want to understand what kind of sizes of infinities are there. We know there's the real number is bigger than the natural numbers. Is there something in between? So fundamental, really. But it was shown during the course of the 20th century, really, in two separate steps-- one in the 1930s by Godel, one in the early 1970s by Cohen-- that we can't answer this question by using the standard axioms of mathematics. The answer can go either way. And both of them are consistent with the axes mathematics. So you're never going to be able to prove that there is a set whose size is in between or that there is no such set. It's just impossible to prove either way using the standard axiom of mathematics,
2501	which, actually, is kind of remarkable. And so my question for you is-- and this is really a philosophical question, not one that is directly you need to know about material in the course. I think it's just a matter of your own interest. I hope you find it interesting. If you don't, you can just answer it randomly. But what's going on here that we can't answer that question about whether there is a set of intermediate size? Is it because our axioms for mathematics are inadequate? Or maybe there is no such thing as a mathematical reality. You can talk about what's real here? What's the reality? Either there is a set in between or not. If you can imagine, all of these things have their own reality to them, well, then, there's going to be an answer. And then you would expect, well, maybe we can find better axioms, which will actually give us that answer. Or you can say, well, there is no reality. And infinite sets are kind of human constructs anyway, so we can
2502	make them kind of play out any way we like. Mathematicians argue about that to this day. And it is, as I say, really, it's a philosophical question. But just out of curiosity, let's see how you guys end up deciding on that one. So here is the poll. 5 seconds to go. Please vote. And we're going to end the polling, 1, 2, 3, now. All right, here we go. So there's no right answer. I think if most mathematicians were to, I think, the instinct of most logicians, especially, I'm not sure if general mathematicians really even care about this question, but logicians would probably have an instinct that, probably, there are sets in between. There's no reason that there shouldn't be. It seems kind of strange that there should be this sort of jump from the natural numbers to the real numbers and why nothing in between? But I don't think that question is really settled. All right, let's continue on.
2503	OK, so we're going to-- our coffee break is coming, in case you're wondering. So this is my last slide before then. But this is an important slide, so please hold out. So here is our promised theorem of the day. I'm going to show that A,TM is not decidable, the acceptance problem for Turing machines. And it's all going to be contained on this one slide. We're going to give a proof by contradiction using diagonalization. And we're going to assume some Turing machine, H, decides A,TM. And we're going to get a contradiction. So let's, first of all, make sure we understand what H is doing. So H gets an input-- a Turing machine and an input. And H is going to be a decider, so it always halts with an accept or a reject. It's supposed to accept if M accepts w and reject if it doesn't. So in other words, it's going to reject if M rejects w either by halting or by looping. That's the job of H. And we're assuming we can do that.
2504	But we will see a contradiction occur. So the way we're going to do that is really kind of just one step here in a way. And we're going to use H to construct another Turing machine D. H is going to be a subroutine to D. We've already seen us doing that in the past. D is going to do something a little strange, just to warn you. D's input is just a Turing machine-- no w. And what D is going to do using its subroutine H is going to simulate H on input M, comma, the description of M. Now what is that? Well, the description of M is just some string. So what H is trying-- what it's asking H to tell, to answer is, does M accept the string representing M's own description? It's as if we're feeding M into itself, which seems like a totally twisted thing to do, you might say. Why would you ever feed a program into itself? Somebody has written cannibalism here-- yeah, kind of. I'd say it's worse [LAUGHS]
2505	because it's not eating somebody else. It's eating yourself. OK, but I claim that there are actual cases in practice where we do this. We feed programs into themselves. And the example that I know of where this is done is when you're making a compiler. You might want to make a compiler and then written in the same language that it's compiling. And then you feed the compiler into itself. You may say, why even bother because it's already, obviously, if it, once it's running, you don't need to compile it again. But actually, an example where this was really used was when there was an optimizing compiler, I think, for C written on early Unix machines. And the optimizing compiler for C was written in C. So you would feed the optimizing compiler into the regular compiler, first of all. Now, you had the compiler running, but it was an optimized. So but now that it's the optimizing compiler is running, you can feed the optimizing compiler into that, which is itself. Now you have an optimized optimizing
2506	compiler. So it really makes some-- there is at least one case where this has actually been done in practice. Not that we really care. This is a theory class-- but just for fun to observe that. So here, H is trying to say, well, does in a M end up accepting when it's fed the description of itself? You know, at least, mathematically speaking, that's a reasonable thing to ask. And then what D is going to do when it gets the answer back from H-- H is a decider, don't forget-- is D's going to do the opposite of whatever H does. It's going to accept if H rejects and reject if H accepts. So let's, in summary, let's pull this together, so it's easy to understand, in the end, what is D doing? D is going to accept. D is also going to be decider, by the way. So D is always going to either accept or reject-- Just. The opposite of what H tells it to do. So D is going to accept M exactly when
2507	M doesn't accept M because when M doesn't accept M, H is going to reject, and so then D is going to accept. So D accepts M if and only if M doesn't accept M. That's exactly the condition in which D accepts M. I think it's important to just step back and make sure you understand this line because we have only one line left to get our contradiction. Right? Are we together? D accepts M if and only if M doesn't accept M. That's just by the way we've defined setup D. Now what we're going to do is feed in, instead of M to D, and not some arbitrary feed, we're going to use feed in D into D. And that is going to be our contradiction because D is now going to accept D if and only if D doesn't accept D, and that's certainly impossible. That's our contradiction which proves that H cannot exist. And therefore, A,TM is undecidable. OK, so we're done, except for the one point, which is that why is this a
2508	diagonalization? And I think you can get that from the following picture. If you imagine here writing down all possible times-- I'm going to make a table here. Here is the list of all Turing machines, including D, which is a machine which I built under the assumption that H exists. So D appears here somewhere. But here are all the other Turing machines. And here are all of these descriptions of the Turing machines along the labeling all of the columns. OK, so these are the rows labeled. These are the column labels. And inside, I'm going to tell you the answer for whether a given machine accepts a given input. So for example, M1 accepts its own description but rejects the description of M2, but accepts the description of M3. I don't you know. I'm obviously I'm making this up. I don't know what M1 is. But just hypothetically, that's what the machine M1 does. So I'm just filling out this table. H could get the answer to any of the elements in this table because it can
2509	test whether M4 accepts the description of M3. So H could fill out this table. So maybe M2 is a machine that always rejects. It's a very unfriendly, rejecting machine. M3 is a very friendly machine. It accepts all inputs. M4 rejects some and accepts others, dot, dot, dot. Now, I want to look and see, what does D do? Now based on the information that I've already given you, we can understand what D does. So for example, what does D do when I feed it the description of M1? What does D do? Well, we can look here. D accepts M if and only if M doesn't accept M. So D is going to accept M1 if and only if M1 does not accept M1. Well, M1 does accept M1. So D does the opposite. D rejects. So OK, I'm highlighting here. D rejects because D is going to do the opposite of what the machine does on its own it on input. So D on M2, you have to look what M2 does on M2. It rejects,
2510	so D does the opposite of that. It accepts. And similarly, each one of these things-- D's answer is going to be the opposite of what the machine does on its own description, just by virtue of the definition of D. OK, and so on-- so far, so good. But the problem is, what happens when D is fed itself? Because, as you can see, we're heading for trouble because this is a diagonal down here. D is just one of the rows. That diagonal is going to intersect that row at this point. And D is defined to be going to be doing the opposite of what that element is, but it can't be the opposite of itself. And so that's the contradiction. So I think we're-- I'm going to call us, give us a little break here. And then you can also text me in the meantime. I'll be happy to answer some questions during that. A little over 4 minutes to go-- so let's see. Let me see if I can answer your questions. OK, what's so
2511	special about A,TM that enables us to do this? Why can't we do this on ADFA, for example? That's a good question. And the answer is that, in a sense, we can do this on DFA. I mean, I think this is, perhaps, a bit of a stretch. But DFAs could not answer ADFA. I mean, we could prove that in other ways as well by just-- we could use things like the pumping lemma, and it's not clear, even how you'd formulate ADFA. But what's important here is that it's really the model talking about itself that really is where the problem comes up. So if you try to push this argument through to show that ADFA is not decidable by Turing machines, you're going to fail because we're starting off with a Turing machine. And I think I'm going to confuse myself if I try to just repeat it. But you won't get a contradiction because the Turing machine is not a finite automaton. OK. Will this argument get into self-loops? I don't see why it would-- there
2512	is some self-reference, perhaps. We're going to talk about that a little later. So we're going to come back and revisit this argument in a week or so when we talk about the recursion theorem which talks about machines that can refer to themselves. But this is a little bit of a head-- getting ahead of ourselves. So somebody's commenting on this reminding them of the barber paradox, if you remember that, which has some similarity. There is a town in which there was a barber which shaves every man who doesn't shave themselves. It seems he's a very good barber. So there are some people who shave themselves. And all the rest, the barber shaves. The question is, does the barber shave himself? Because he shaves only those men who don't shave themselves. So you've got a same kind of a contradiction. There is a relationship there. So someone wants to know, where did we use the decidability? So we used the decidability to come up with H. Once we know that A,TM is decidable, then we have that
2513	H function, and then we can build D. So that's the chain of reason. So you assume A,TM is decidable. Then you have the decider called H, and then you can build D. Somebody wants to see the previous slide. What part of the slide do you want? So I'll leave that up there. Why can we apply the proof that all Turing machines are accountable to all languages? Well, because Turing machines have descriptions. General languages don't have descriptions. And so that's why. OK, the candle has burnt to the bottom, and it's time to move on. So now, let's look at the acceptance problem for queue automata. I'll give you a queue automaton on input, and I want to know, does it accept the input? Is that going to be decidable? And you have your choices. It's either yes, it is decidable because these are similar to pushdown automata and APDA is decidable, or no because yes contradicts results that we know at this point, or we don't have enough information to answer the question. OK, let's put
2514	that up. One second-- [LAUGHS] all right, that's it. Ready, going, gone. So yes, the answer is, well, no. [LAUGHS] The answer is, indeed, the answer is B. True, that queue automata are similar to pushdown automata, but all these automata are similar to each other, and that's not going to be good enough. What the homework has asked you to do is to show that you can simulate Turing machines with queue automata. So if you can answer the question about whether the queue automata will accept their input, that would allow you to be able to answer questions about whether Turing machines accept their input. And we just proved that's not possible. So it would be a contradiction if we could answer-- if we could decide A, queue, A. Now, we have an example of an undecidable language. Let's look at an example of an unrecognizable language. Now A,TM is not going to serve that purpose because A,TM is Turing-recognizable, as we pointed out by the universal Turing machine. So A,TM is undecidable, however. How about an unrecognizable
2515	language? For that, we will see that the complement of A,TM will serve. So the complement of A,TM is neither decidable nor even recognizable. Now it's not Turing-recognizable. And that's going to follow from a pretty basic theorem that connects recognizability and decidability that I've put up here on the screen, which is that if you have a language where it and its complement are both recognizable, then the language turnout turns out to be decidable. In fact, a language and its complement are decidable. But being decidable is closed under complement, so that's something you should be aware. But being-- OK. We'll get to that in a minute. But if-- so anyway, so if you have a language and it's complement both recognizable, how do we know the language is decidable? So first of all, let's take the two Turing machines, M1 and M2 that recognizes A and A-complement. And we're going to put those together to get a decider for A. And that's going to work like this. It's going to be called T. So T says, on
2516	input w, what it's going to do, it's going to feed w into M1 and M2 both. A is the language, by the way, yes. A is-- when I say it's Turing-recognizable, you know, Turing-recognizable only applies to languages. So yes, A is often this symbol I'm going to use for languages, sometimes for an automaton. But A is typically going to be a language. So now, I'm trying to make T be a decider for A from the recognizers for A and A-complement. So I'm going to take an input to T and feed it into both recognizers, M1 and M2. OK, I'm going to run them in parallel. What's nice is that because M2 recognizes the complement of what M1 recognizes, every string is going to be accepted either by M1 or by M2 because every string is either an A or an A-complement. So if I run M1 and M2 on w until one of the halts or one of them accepts, I know I'm not going to run forever because, eventually, one or the other one
2517	have to accept. So and then I got my answer because if M1 accepts, then I know I'm in the language. But if M2 accepts, I know I'm in the complement of the language, so I'm out of the language. So if M1 accepts, then T should accept. But if M2 accepts, then T should reject. , So that proves that nice little theorem written at the top in blue. So I got my decider for A built out of the recognizers for A and A-complement. Now immediately, it follows that the complement of A,TM is not Turing-recognizable because we know that A,TM itself is recognizable, but it's undecidable. If the complement was also recognizable, then A,TM would be decidable, but it isn't. So when something is decidable, either it or its complement have to be unrecognizable. And in the case for A,TM, it has to be the complement because we already showed that it is itself is recognizable. So that's the proof of that. So here is a little picture of the way the world looks right now if
2518	you have here, in the middle are the decidable languages-- so these are all languages, this Venn diagram of languages. We showed earlier, the regular, the context-free, decidable, recognizable. Here, I've got the recognizable and what I'm calling the co-Turing recognizable. This is the collection of all complements of recognizable languages. So A,TM bar, A,TM complement is the complement of a recognizable language. This region here are all the complements of the recognizable languages or the so-called co-Turing recognizable languages-- complement of. So A,TM is on this side. A,TM-complement is on that side. But if something's in both, by virtue of this theorem here, then it's decidable. OK, last check-in for the day. From what we learned so far, which closure properties can we prove for the class of deterring recognizable languages? Choose all that apply. Well, as I say, you don't have to get it right. Let's not spend too much more time on this because we'll talk a little bit about it. Almost all-- its closed under almost all of them, but not all of them. Because-- are
2519	we done here? I think we're done-- 5 seconds. OK, here we go, ending polling. I'm not sure what the meaning of [LAUGHS] deleting your answer is here. Everybody likes union, I guess. They're closed under all of these operations except complement. But we just proved it's not closed under complement, so I'm a little puzzled by why we have so many votes for closure under complement. We have here, A,TM is Turing-recognizable, but A,TM-complement is not Turing-recognizable. it's right here on the slide. I'm not trying to make you feel bad, but I'm trying to just point out that you think, please. So now closure under union and intersection, I mean, you could kind of get those answers just by running things in parallel the way we did the proof here. You just run both machines. And if they both give-- I mean, it's a little tricky, I suppose. If either one of them accept, then you can accept. Or if they both accept, you just wait until they both have accepted. Otherwise, you just keep running. So the
2520	first two are pretty straightforward. Closure under concatenation-- this is also going to be similar. You just try every possible way of cutting the string up into two pieces and run in parallel on. And if you ever find a way of cutting it up, and you run those two, and put those two sides in parallel, and if they both accept, then you can accept. And star is, again, very similar. So these are not too bad. But I admit, you know, it's not a whole lot of time to have to contend with something that you're just getting used to. So let's talk about the very last topic of the day, which is really going to be setting ourselves up for Tuesday's lecture next week. And that's how we are going to be showing other languages are undecidable, which is something that I'm going to be expecting you guys to be able to do. This is the standard procedure for showing languages are undecidable using what's called the reducibility method. And what that does is it takes, as
2521	a starting point, a language that we already know is undecidable-- typically, A,TM-- or it could be another one that you've previously shown to be undecidable-- and leverages that information to show other languages are undecidable. And it's using what's called reducibility. We're going to go into this more carefully next time. But basically, reducibility is a way of using one problem to solve another problem. And so we are going to show, for example, let's take a look at the problem called the halting problem, which is like the famous problem for Turing machines. You just want to know whether it halts, not necessarily whether it accepts. So it's very similar, but not exactly the same. And we're going to show that this halting problem is similarly undecidable. Now we could go back and do the whole diagonalization, but that seems like-- well, that's more work than necessary now that we already know A,TM is undecidable because we're going to show that we can reduce the A,TM problem to the halting problem. And we'll explain what that means again
2522	later. But the idea is-- and as we'll show in an illustration shortly-- that by proving by contradiction if the if HALT,TM were decidable, then A,TM would be decided. And we know A,TM is not decidable. And so that's our contradiction. Now the way we're going to show that if HALT,TM is decidable, then A,TM is decidable is use a decider for HALT,TM to decide A,TM with a suitable modification. So basically, we want to turn a HALT,TM decider into an A,TM decider. And that's how we're going to reduce the problem of solving A,TM to the problem of solving HALT,TM. Let's just do an example. If you've seen it before, obviously, this is not going to be hard. But for the many of you who have not seen it before, I'm partly doing it this time just so we can do it again next time. And maybe it'll sink in by virtue of repetition. So again, so as I just said, we're going to assume the HALT,TM problem is decidable and use that to show that A,TM is decidable,
2523	which we know is false. We showed it just earlier that it's not. So assume we have a decider for HALT,TM. We'll call it R. And we're going to construct from R a decider for A,TM we'll call S. OK? So we're, again, typical proof by contradiction. We're assuming the opposite of what we're trying to prove. And then we're going to get something crazy. OK, so here, my job now, is I'm assuming I have R, which is a HALT,TM decider. So now, I'm assuming I know how to decide if a Turing machine and an input eventually halts-- Not. Necessarily would it accept, just whether it halts. It's conceivable. You have to bear with me here. It's conceivable that you could find a way to test whether Turing machines halt on their input, even though we now know that testing whether they accept their input is not decidable. So you have to be open-minded to the possibility that the HALT problem is decidable, and we're going to show that that's can't be. So we're going to show that
2524	if we could decide the halting problem, then we can use that to decide the acceptance problem. OK, so how are we going to do that? So imagine how we can solve the halting problem. So to solve the A,TM, which is what my job is to do, so S is supposed to solve A,TM. I'm constructing a Turing machine as decide A,TM. I'm going to use first-- I'm giving it M and w. I'm going to feed it into R since that's really all I got. See if R tells me what happens. Does M on w at least halt? Well, if R says, no, it doesn't halt, well then I'm actually done because if M doesn't even halt on w, then it couldn't be accepting w. So at that point, I know that M doesn't accept w, and I can reject right off. So R, you can see how it could potentially be helpful. But it's going to be helpful in either way because if R says M does hold, well, then, I'm also good because I don't
2525	know the answer yet, but what I do know is I can now simulate M on w until it halts because R has told me it halts. So I don't have to worry about getting into a loop. So S can be confident in being a decider for whatever it's doing because I'm running now M on w with a guarantee that it halts. And now, that's going to tell me-- now eventually, the simulation of M on w is going to end up at an accept or reject. And that's going to be the answer I need. So if M is accepted, then accept. And if M is rejected, then reject. And that's how S solves A,TM using R, which solves HALT,TM. But S can't exist. And so therefore, R can't exist. And therefore, HALT,TM can't be decidable. OK? So that quickly-- OK, I'm not sure which diagram you wanted me to show. But anyway, maybe we can do that. We're basically at the end of the hour or end of the 90 minutes. So let's do a quick
2526	review. And if you stick around, I'm happy to go back and look at any of the other slides that you might have missed something on. OK, so just to recap, we showed that the natural numbers and the real numbers are not the same size using that definition of one-to-one correspondence to introduce the diagonalization method. We used the diagonalization method to show that A,TM is undecidable. We also showed that little theorem that if the language and its complement are recognizable, then the language is decidable. And from that, we concluded that A,TM complement is not recognizable. And then we showed, at least by virtue of an introduction to the method, the reducibility method to show that HALT,TM is undecidable. And that was today's lecture. And we're and we're at the end of the hour. So why don't I-- we are finished. You can log out. And if you want, I will stick around. OK, OK, this is kind of a good question here. So I'm getting a question about the A,TM-complement, which is-- since we have a
2527	recognizer for A,TM, if I'm doing justice to this question, we have a recogniser for A,TM, so why can't we just invert the answer? Flip the answer around, and now, we have a recognizer for the complement of A,TM, A,TM-complement. So why doesn't that work? Well, the reason that doesn't work is because the recognizer for A,TM might be rejecting some things by looping. And now, if you just flip the accepting and rejecting, when it hits one of those halting states, it's going to give the reverse answer. But when it rejects by looping, it'll continue to reject by looping. So you won't get the complementary language coming out. So if it would be helpful, I can go back to that slide here, which proves that A,TM-complement is unrecognizable because maybe we should start with the bottom. We know that A,TM is recognizable and undecidable, right? We already proved those two facts. A,TM is recognizable from the universal Turing machine, and it's undecidable by the diagonalization argument. Those two things together tell us that the complement has to be
2528	unrecognizable because if a language and its complement are both recognizable-- and we already know the language itself is recognizable. So now, if the complement is also recognizable, the language is going to be decidable by the upper theorem. So it must be the case had either the language itself is unrecognizable, or its complement is unrecognizable. We know the language is recognizable. That's what the universal Turing machine told us. So the only thing left is for the complement to be unrecognizable. You should review that if you didn't get it because this is the kind of reasoning we're going to be building on things like that. So I think it's good to make sure you understand. OK. OK, the diagram on the right-- so this is just a Venn diagram here. I threw this in at the last minute here. I was worried about it being confusing. That part is-- I'm trying to show that the three classes that we've already talked about-- the languages which are decidable, the languages which are Turing-recognizable, and the languages whose complements
2529	are Turing-recognizable. Those are three separate classes of languages. And those come up here in those three regions. These are the decidable ones. Here are the recognizable ones. And here are the ones whose complements are recognizable. Now if a language is in both the recognizable, and its complement is recognizable-- so it's in both of these bigger regions here-- then this theorem tells you it's decidable. So that's why the intersection of these two regions is marked as being decidable because that means you're in both. OK? But we know that A,TM is sitting out here as recognizable but not decidable. So A,TM is in the recognizable side, but it's not on the complement of recognizable, A,TM itself. The complement of A,TM is the complement of a recognizable but itself is not recognizable and not decidable. So you got this side of nice, you know-- I hope you think it's nice, but it's sort of a try to summarize things in this little Venn diagram. So I think I'm going to then sign off. And I'll see you all
2530	on Tuesday. And have a good weekend. Bye bye.
2531	[SQUEAKING] [RUSTLING] [CLICKING] MICHAEL SIPSER: Hi, everybody. I hope you can hear me. Give me a thumbs up if you can. Good. I see them coming through. So we're going to get started. So getting back to what we've been doing. We've been talking about space complexity. Measures how much memory the algorithm requires or various problems require. And we defined the space complexity classes, space f of n and non-deterministic space f of n, the polynomial space and non-deterministic space classes, and gave some examples and so on. And today we're going to pick up where we left off last time. One of the examples, which is going to be an important one for us, concerns this latter DFA problem. So I'm going to go over that again, give a little bit more emphasis to the space analysis, which I got some questions about last time. And then we are going to move on from there and prove Savitch's theorem and then talk about a complete problems for PSPACE and show that this problem TQBF, which we introduced last
2532	time, is actually a PSPACE complete problem. But all in due course. A little bit of review. So we defined what we mean by a Turing machine to run in a certain amount of space. That means it uses at most f of n. If it's running in space f of n, uses at most f of n cells, tape cells, on every input of length n. And similarly, a non-deterministic Turing machine does the same. But in addition to that, the non-deterministic machine has to halt on every branch of its computation. And each branch of its computation has to use at most that bounded amount of tape cells. So we're going to be talking about non-deterministic space computation today as well. It's going to be relevant to us. So we defined the classes, as I mentioned, and the polynomial and the PSPACE and non-deterministic PSPACE classes. And this is how we believe they relate to one another. The classes coNP and NP as well. And of course, as I mentioned last time, there are some very major unsolved
2533	problems in this area. So everything could conceivably collapse down to P, which would, of course, be very surprising. But we don't know how to prove otherwise. And the big theorem that we're going to prove today is that polynomial space and non-deterministic polynomial space actually do collapse down to each other. And being the same class. So in contrast with the situation that we believe to be the case for time complexity where we believe converting non-deterministic to deterministic gives an exponential increase for space complexity, it only gives a squaring increase, as we'll see. So any questions on any of this? We will just march into a little review of this latter problem. So reviewing some of the notation. And let me emphasize that. So the big theorem we're going to be proving today is that PSPACE and NPSPACE are equal. And also we're going to be talking about PSPACE completeness. But both of those involve proving theorems. In the first case, Savitch's theorem that converting non-deterministic to deterministic spaces is squaring. And in the second case, proving
2534	that TQBF is PSPACE complete. Both of those theorems can be thought of as generalizations of this theorem here that the latter DFA problem can be done in the deterministic polynomial space or n squared space. So it really pays to try to understand how the proof of this theorem works. Because in a sense, this theorem is a more concrete version of what we're going to be seeing in those other two theorems in a somewhat more abstract form. So I like understanding things in a more concrete way first. So that's why this is a good example to start out with. But really in the end of the day, it's the same proof just repeated for those three theorems. So this is really three for the price of one. Three theorems, one proof here. So you're going to be seeing the same proof repeated three times but in different levels of abstraction. So let's review again. I know some of you got it, but maybe some of you didn't. And let's just try to be clear on the
2535	algorithm to solve the ladder DFA problem. So if you remember, first of all, let me just jump on ahead. The ladder problem is-- a ladder, first of all, is a sequence of strings that change one symbol at a time that perhaps connect, go from one string to another. So you're going to go from work to play, changing one symbol at a time. So we gave an example of this or you can easily come up with an example of doing this. But the computational problem is can you do it? Can you get from this string to that string and stay within a certain language? So it might be the language of English words or it might be the language of all strings that some specific DFA recognizes. So it might be all of the string. These might all be strings that some DFA accepts or might be English words or some other rule. And so that's what we mean by trying to test if there's a ladder. And so the ladder problem is, well, I don't
2536	think I
2537	But the bounded ladder problem is basically the same idea. You're given the DFA. You're given the strings u and v. And now this is the bounded version of the problem where I'm going to give you a limit on the number of steps you can take. So I'm illustrating that here. So you're going to be given a b. And you want to say, can I get from this string to that string within b steps? And we had a notation for writing that. Going from u to v, if there's a ladder that connects u to v within at most b steps. And so the bounded ladder problem, which I'm introducing because I'm going to be aiming toward a recursive algorithm to solve this problem is can I get from u to v by a ladder, changing one symbol at a time, where each string along the way is accepted by b, and I'm only allowed b steps. Little b steps. So that is the computational problem that I'm going to be solving with the algorithm that I'm
2538	going to describe. So the algorithm I'm going to call BL for bounded ladder problem. And here is the input. And the algorithm is, first of all, going to look to see if b equals 1. If I'm just trying to get from u to v in a single step. In that case, it's a very simple problem, because you want to test, obviously, that u and v are accepted by the automaton. And they just have to differ in one place. And then you have a very simple one step ladder that takes u to v. So for the case b equals 1, it's very simple. For larger values of b, we're going to solve the problem recursively in terms of smaller values of b. So for b greater than 1, we're going to recursively test. If you're trying to solve the problem can I get from u to v, instead we're going to try each possible halfway through. We don't know that it's halfway through. So we're just going to try each possible string. And we're going to
2539	test can we get from u, the initial string, to that new string, that w, in half the number of steps. And can I get to the final string v in half the number of steps? If I can do that, then I can get from u to v the total number of steps b. So I'm just going to try to do this one w at a time for every possible w. This is going to be very expensive in terms of time, but we're not worried about time right now. We're trying to cut down on the amount of space that we're using. And this is going to be a big savings in space. Let's not worry about the division, b over 2 here. All of the divisions, we're going to be seeing this several times going forward in the lecture, we'll think of them rounding up. But I'm not going to make the notation look cumbersome by writing that every time. OK. So here we go. Here is some candidate w string, which is halfway through. Recursively
2540	test. Can I get from the starting string to that w and from w to that ending string? If I can, if I find such a w, then I accept. And if I try all possible w and I never manage to find a way to make both the top and the bottom work, then I know I cannot get from the starting string to the ending string within b steps. And so I reject. And now I'm going to solve the original unbounded ladder problem by simply putting the biggest possible bound into the bounded ladder problem. And that's this value t, which gives the very trivial bound of the total number of possible strings that I can write down within my length m that I'm working with. So this if sigma is the alphabet of these strings, it's just sigma to the m. That's all possible strings. Of course, that's going to be a maximum size on the ladder. So now how much space does this take? And I think this is where people got a little bit
2541	lost in the lecture last time. So I'm going to try to animate this. I don't know if that's going to help or not. But in the end of the day, you're just going to have to think through how do you account for the cost of this recursion. But the main thing, to start off, you have to make sure you understand the algorithm. And if you get from here to there, we're going to try all possible midpoints and then solve the upper part and the lower part recursively, reusing the space. That's the way we're going to get a saving. By solving this problem, reusing the space that we use to solve this problem. So I'm going to try to show this to you on actually how the space gets used on the Turing machine. You can kind of think of here's the input and then after that is going to be the stack for the recursion. If you're not that familiar with how to implement recursion, it doesn't really matter. But you can just think about
2542	what the algorithm needs to keep track of. And so as it's trying every possible w, so just in order like an odometer, just trying every possible string, eventually maybe it finds a string that's in the language that hears an English word, one of the first English words of length 4 that you might run into. And so now it makes sense, actually, to do the recursion. So that's all. Every time you're going to have to have a register or a location on the tape where you're going to be writing down those different w's. So let's say it's over here. And we're just going to go through. I hope that's not too small for you to see. That's really where that action is happening. And finally, maybe you got to the string w. Now you're going to try to do the recursion. So here as you're doing the recursion on the top half again, you're going to be cutting-- you're going to be finding a new w for the intermediate point just solving this upper problem where
2543	we're testing if I can get from work to able. Later I'm going to have to deal with getting from able to play. Good. So here, again, we're going to be fixing able, fixing the first w. We're going to try every possible way of getting from the start string to that middle string. So we're going to try every possible thing here. Eventually maybe we find some other string in the language. We get down to the string book. And that's all going to get stored. You can't forget the string able. But now we're going to use some more space to store those candidates. So that's a second version of w deeper in the recursion. So here we're going to be triangle to possible strings here. Again, eventually we get to some string book. And if that succeeds in getting us from work to able via book, now we're going to jump down to do the bottom half, to see if I can get from able to play as a separate problem, which gets solved in the same
2544	space. So now here we're going to try all these possibilities getting from able to play. Maybe call is the right intermediate string there. And so now we're going to erase the book and now we're going to solve the lower sub problem in the same location. I hope this is helpful. This was a lot of work making these animations. So the point of all this is every time we go down the level of the recursion, there's another register whose size is big enough to hold one of the strings, is needed. And that register gets reused times throughout as we're going through this recursion. So anyway, I hope that's helpful. Anyway. So each level of the recursion adds another order in to record the w. And so you have to do-- how many levels do we get. Well, the depth of the recursion is going to be how many times we end up having to divide this picture in half until we get down to 1. And so the height of this when we start off is
2545	going to be basically an exponential in m. m is roughly the size of n. So when you take the log of that, you're going to get-- you're going to pull down the exponential. So it's going to be order m or, which is, again, roughly the same size as the input. m is like half the input because the whole input is u and v. m is just the size of u. And so each level requires order n, and the depth is going to be order n deep. The log of the initial height of this ladder. And so the total space used is going to be order n squared. So why don't we just take a minute? I'm happy to spend a little time going through this, either the algorithm's correctness, understanding recursion, or understanding the space analysis. If there's any question that you feel you can ask that would be clarifying for you, jump in. I'll set aside a few minutes just to answer questions here. So I've got a question here. In step five, why
2546	do we reject if all fail instead of just one fails? Well, here, so remember what we're trying to do. We're trying to say can I get from u to v in b steps? The way I'm going to be doing that is trying every possible intermediate string w. If I find some w which does not work, that doesn't mean that there's not some other w which might work. All I need is one w for which I can get from u to w in half the number of steps and w to v in half the number of steps. So I'm going to try every possible w. If any one of them is good, then I can accept. If any one of them succeeds where I can get from u to w in half the steps and to w to v in half the steps, then I know I can get from u to v in the full number of steps. So I only need to find one. If one particular one doesn't work, I'll just go on
2547	to the next one. OK. This is a good question. Do we have to save the word book? So once we succeed in getting from work to able, let's say via book, do we need to save that word book anywhere? No. All we need to remember is that we've succeeded in getting from work to able. We don't need to remember book anymore. We just remember that we've succeeded. And that is by virtue of where we are in the algorithm. If we have succeeded, then we move on to the second recursion, second call, recursive call. So we found some way to do it. So we found some intermediate point which succeeds for this one. So we move on to that one. We don't have to keep any of that work anymore. All you have to do is remember, yes, I can get from work to able in half the number of steps. Now all that's left is to get from able to play in half the number of steps. It doesn't matter how I got to able
2548	in the first place. So we don't have to remember that. That was a good question though. So I think I understand this. Before we replace the value for book with call with the work involved to find call, yeah, we have to check that we can get from work to book and book to able. So we keep onto book while we're working on the upper half. And only when we've finally succeeded in getting from work to able, let's say via book, then you can throw a book away. But while you're working on the upper half, you try book, you try different strings of length four until one of them works. I'm not sure.
2549	for search. I'm not sure I see it. I'm not sure that's going to be a helpful way of thinking about this. So I'm not going to answer that right now. But you can ask that offline later if you want. Why is the recursion depth log t instead of log m? Well, how high is this thing? Initially it's t high. But every time we're doing a level, we're calling the recursion, we're cutting t in half. I'm solving this in general for b, but we starting off with b equal to t. t is the maximum size. So initially this is going to be t, and then it's going to be t over 2, then t over 4. So it's going to be log t levels before we get down to 1. Yeah. So somebody is asking, can we think of this as a memory stack? Yes, this is like-- that's the way your typical implementation of recursion is kind of with a stack, where you push when you make a call and you pop when you return
2550	from the call. Is it possible that v can appear during BL procedure on t? Is it possible that v can appear? I'm not sure what that means. It can reappear. So I'm starting with u to v. Is it possible that v might be one of these intermediate strings? Yeah. You're going to try every possible intermediate stream blindly. Including v is one of them. If you can reach v more quickly, well, great. I guess I have not dealt with the issue of what happens if you get to a-- technically it's going to work out because I'm allowing the difference to be in at most one place. So even if you get there early, you're allowed to not change anything, and that still is a legal step in the ladder. Yeah. I don't see how to do this from a bottom up perspective. Somebody's is asking is there a bottom up version of this. I don't think so. No, I don't think so. All right. Why don't we move on? So now we're going to see this
2551	proof again. But this time we're going to be proving that you can convert any NFA to a DFA with only a squaring increase. So really, well, let me just put that up there. So this is going to be Savitch's theorem, that among other things proves that PSPACE equals NPSPACE. So it says that you can convert a non-deterministic machine to a deterministic machine only squaring the amount of space. So you're comfortable with this notation here. Anything that you can do in f of n space non-deterministically you can do in f squared of n based deterministically. And we're going to accomplish that by converting an NTM to a deterministic TM but only squaring the space used. So n is going to convert it to an m. And now this proof is going to look very similar to the proof in the previous slide. It's the same proof. And the fact from the previous slide about ladder really is implied by this, because we had an easy algorithm to show that the latter problem is
2552	So ladder problem was easily shown to be in here. If you remember, you just basically guess the steps of the ladder. So non-deterministically, you can easily check, can I get from the start to the end? But Savitch's theorem tells us that anything you can do non-deterministically in polynomial space you can do deterministically in polynomial space. So what we showed in the previous slide follows from this slide, but this slide is really just a generalization of the same proof. Maybe I've said it too many times now. So we're going to introduce a notation very similar to the notation we had last time. But now we're going to be talking about simulating this non-deterministic machine with a deterministic machine. And we're going to take two configurations of this non-deterministic machine, ci and cj, and say can I get from ci to cj in at most b steps? I'm going to have a notation. Very similar to the notation for the ladder where I can get from this word to that word in at most b steps by
2553	a ladder. Here can I get from this word to that-- can I get from this configuration to that configuration with at most b steps of the Turing machine's operation? So these are two configurations now of n. So can n go from this configuration ci to that other configuration cj but only taking b steps along the way? That's now the computational problem that I'm going to solve for you with an algorithm. And it's going to be a recursion exactly like the previous one. So n gets its input the two configurations ci and cj and the bound b and want to check can I get from i to j within b? So now the picture is a little different but very similar. So instead of a ladder appearing here, it's really something that's basically a tableau for the machine n where I have an initial configuration and an ending configuration. This would happen to be the starting point for the whole procedure if you're testing whether n accepts w. But we would be solving this in general
2554	for any-- so that case, so I have the start configuration of n on w and the accepting configuration or an accepting configuration. But in general, what I will be solving is starting with any configuration ci and going to any configuration cj. So I want to test can I get from ci to cj within at most b steps. So first of all, if b is 1, you can just check that directly. And now, again, we're operating deterministically to simulate the non-deterministic machine. So this is the deterministic machine m. So m can easily, if it's given two configurations of n and says, can I get from the first one to the second one in one step? Well, that's an easy check. You just lay out those two configurations, look at the n's transition function, and say is this a legal move for n? Yes or no? And you accept or reject accordingly. Now, if b is larger than 1, you're going to try all possible intermediate configurations, calling them c mid. This was like the w from
2555	the previous theorem. This is all possible strings c-- all possible configurations c mid. And a configuration is just going to be a-- so far so-- OK. This is all possible. Looked like my PowerPoint crashed, but it seems OK. This is all possible configurations, which is just a string with a string of tape symbols with a state symbol appearing somewhere. That's all it is. Going to try all possible configurations as candidate middle configurations. And say can I get from the upper one to this candidate middle one and from that middle one to the lower one within half the number of steps each time. And solving that problem recursively. So I got a question here about the possibility of looping forever. First of all, if n is going to be looping, I don't have to worry about it, because I'm starting off, I only need to simulate machines that are deciders. Because I'm trying to show that any language in here has to be accepted, has to be decided by some non-deterministic machine. So I'm not going
2556	to worry about machines that are looping. If they're looping, m may misbehave in some way, but that's not going to be a problem for me. So let's keep life simple. Think about the deciders only. So we're going to recursively test here. So that means I'm going to try every possible middle, see if I can get from the start to the middle and the middle to the end. If both of them work after I test them recursively, then I'm going to accept. If not, I'm going to continue. And I reject if I try them all and none of them have worked. Then I know there's no way for n to get from this configuration to that configuration in b steps. And the overall picture, I test whether n accepts w, as I mentioned, by starting with ci is the start configuration and cj is the accept configuration. And now how big is t? Because I need to calculate a bound on how deep the recursions are going to be. So t here is going to be
2557	the total number of possible configurations. If this is the whole thing, it never repeats a configuration. So this is going to be a bound on how many steps then can be taken. And that's simply we calculated this before. It's the number of states times the number of head positions times the number of tape contents. And this is really going to be the dominant consideration anyway. And so now each recursive level, and maybe I should have emphasized this at the beginning, how wide is this picture? It's big enough to store a configuration. A configuration is essentially a tape contents. So that's going to be f of n wide. So each recursive level stores one configuration. Now the w costs f of n space to write down. And the number of levels is going to be the log of the initial height, which is this. So this is going to be the dominating part of it. So the log of this is going to be, again, order f of n. So each one takes f of n
2558	space to write down. The depth of the recursion is going to be order f of n. So the total is going to be order f squared of n, and that's how much space this uses. And that's the proof of Savitch's theorem.
2559	Somebody asks can there be multiple accepting configurations. I should have made the-- I forgot to say this and I was just realizing it as I was explaining it. One of the things I should have-- you can enforce that there is just a single accepting configuration. This is kind of a detail, so don't worry about it if you don't want to. But you can make sure that there's a single accepting configuration by telling the machine when it accepts, it should erase its tape and move its head into the left most cell in the accept configuration. So there's just going to be a single accepting configuration to worry about instead of having to try multiple possibilities, which you could do in this algorithm, but it would just be annoying to have to write that down that way. So we often assume there's just going to be a single accepting configuration for these machines. How do you know f of n? So that's actually a little bit of a delicate issue. I mean, if you could compute f
2560	of n, the bound, which is, for example, if it's going to be a polynomial bound, you can just compute f of n. It's very easy to compute n squared or n cubed. And so you can just compute that and then use that as the size of the registers you're going to be writing down. If you want to prove this in general for f of n, it's a little bit technical to have to deal with it. And I'm going to have to refer you to the book on that one. The book tells you how solve this for a general f of n. You basically have to try every possible value from one until it works. And I'm afraid that's going to derail us trying to decipher that. So let's not worry about that aspect of it. But you can handle general f of n here. You don't need to put any conditions on f of n. Can we go over this term here? So we've seen this term once before when we talked about LBAs and
2561	seeing that LBAs always-- we can solve the ALBA problem. This is simply the number of different configurations the machine can have. Because the configuration is a state. It's a head position and a contents of the tape. And this is the number of each of those that you can possibly have. Number of states. A head position, the size of the tape of f of n is f of n. So this is that many different head positions. And this is the number-- if d is the size of the tape alphabet, this is the number of tape contents that you can have. How is seeing if n accepts w with this algorithm convert a non-deterministic Turing machine to some deterministic Turing machine? Well, n is the non-deterministic Turing. So n is we're converting non-deterministic Turing machine n to deterministic Turing machine m. So m is a deterministic simulator of n. That's what this whole m is. So if we can do this for any n, then we've proved our theorem. Why don't we defer. I think I got
2562	through most of the questions here. If there's other things, we can save them for the coffee break, which is coming soon. I think we have one more slide before that. So I'm going to define PSPACE completeness I think. Yeah. And then I think after that we have the break. So PSPACE completeness is defined and very much inspired similarly to NP completeness. So a problem is PSPACE complete if it's in NPSPACE and every other member of PSPACE is reducible to it in polynomial time. And we'll say a bit about why we choose polynomial time reducibility here. So here's kind of a picture of how PSPACE-- how complete problems relate to their complexity classes. So you kind of think of a complete problem for a class. It's kind of the hardest problem in that class because you can convert. You can reduce any other problem in that class
2563	So here are the NP complete problems. Sort of the hardest for NP. You have the PSPACE complete problems, kind of the hardest for PSPACE. If an NP complete problem goes into P, that pulls down all of NP to P. If any PSPACE complete problem goes into P, it pulls down all the PSPACE into P by following the chain of reductions, because any PSPACE problem is reducible to the complete problem. Which in turn if it's in P, then everything goes into P. So if you have a PSPACE complete problem which is in P, then all the PSPACE goes into P. So why do we use polynomial time reducibility instead of, say, polynomial space reducibility when we define this notion? It's kind of a very reasonable question. But if you think about it, using polynomial space reducibility would be a terrible idea. And we've seen this phenomenon happen before. Every two problems in PSPACE are going to be PSPACE reducible to one another. We haven't even defined that notion yet, but you can imagine what it would
2564	be. Because a PSPACE reduction can solve the problem for a problem in PSPACE. And then it can direct its answer anywhere that it likes. So in general, when we think about reductions, the reduction should be not capable of solving the problems in the class. Because if they could, then every two problems in the class would be reducible to one another. And then all problems in the class would be complete, because everything in the class would be reducible to any one of the other problems. So it would not be an interesting notion. What you want to have happen is that the reductions should be weaker than the power of the class. And if you look at the reductions that we've defined so far, they're actually very simple. The only thing is they have to make sure that they can make the output big enough. But actually constructing the output, they're very simple transformations. In fact, even polynomial time is more than you typically need. There's even much more limited classes that are capable of doing the
2565	reductions, as we'll see. So having powerful reductions is really not in the spirit of what reductions are all about. You want very, very simple transformations to be the reductions. Anyway, I hope that's helpful. So what we're going to be aiming for in the second part of the lecture is showing that TQBF is PSPACE complete. And let me-- here is the check in. So this is our first check in, coming a little late in the lecture. Suppose we have proven that, as we will, that TQBF is PSPACE complete. What can we conclude if TQBF is actually not necessarily in P, only goes to NP? And this is relevant to a question that's coming in from the chat, but I'll answer that later. So suppose TQBF ends up being an NP and not in P. What can we conclude? Remember, if TQBF is in P, then PSPACE equals P. Suppose it goes to NP. What happens then? There may be several correct answers here. Check all that apply. All right, so we're near the end of the
2566	poll. So let me give you another 10 seconds and then we're going to shut it down. OK, are we all in? Closing it down. Here are the results. So yes, so first of all, the most reasonable solution, most reasonable answer is b, which I think most of you have gotten. That if a PSPACE complete problem goes down to NP, well, NP is capable of simulating the polynomial time reduction. And so any other problem in PSPACE would then also be in NP. And PSPACE would equal NP. But note if PSPACE equals NP, they're also NP equals coNP, because PSPACE itself is closed under complementation. So that was kind of a little bit extra fact that you could conclude from this as well. So let's move on then to our coffee break, and we'll pick up the proof that TQBF is PSPACE complete after that. So was d true or not? D was P equal NP. No, we cannot conclude that P equals NP from PSPACE equal to NP. So if TQBF is in NP, it doesn't
2567	tell us anything. For all we know, P equals NP. But from the stuff that we know so far, we cannot conclude that P equals NP. Oh, and yeah, so you can conclude-- oh, I'm sorry. B and d are both correct here. Let me just shut this thing off. So b and d are correct. So if a PSPACE complete problem goes to NP, then NP equals PSPACE, N equals coNP. So the correct answer, b and d. Sorry. I got myself confused. But c is not something you can conclude or a. So somebody is asking me a fair question. I say the reduction method should be weaker than the class. But for example, even in the case of PSPACE, PSPACE might be equal to P. And then it wouldn't be weaker than the class if we use polynomial time reductions. But I think maybe I should say apparently weaker. As far as we know, it's weaker. But we believe it to be weaker. It's true if P equals PSPACE, then every problem in P is going to
2568	be PSPACE complete. It's just going to be a weird world if P equals PSPACE. Same thing for NP and NP. So I'm getting a number of questions also about other possible reducibilities that are even weaker than polynomial time reducibility. So we're going to see very soon weaker reduce-- complexity classes within P. So first of all, PSPACE seems to be bigger than P. We're also going to look at log space. But that's going to be actually in Thursday's lecture. These are classes that seem to be inside. Well, they're inside P. We believe they're properly inside P. But we'll see that later. Let me just see here. So we're almost out of time. Let me put our timer back. In fact, our timer is showing us out of time. So why don't we get going? Let me move this back to-- OK. Continuing. TQBF is PSPACE complete. So first of all, let's remember TQBF. These are all of the quantified Boolean formulas that are true. So TQBF stands for True Quantified Boolean Formulas. And remember, we saw
2569	these examples from the previous lecture that these are two quantified-- these are two QBFs. The first one is true. The second one is false. And it's going to be interesting to think about. Here they're exactly the same except for the order of the quantifiers. And so what's really going on here? I think it's good to understand these expressions. They come up everywhere in mathematics, these quantifiers. In the upper one, when we say for every x, there exists a y, that y can depend on the choice of x. You choose to make a different x. You're allowed to pick a different y. But the lower expression says there's a universal y. There's one particular y that works for every x. So in a sense, the lower statement is a stronger statement. Whatever you have in the quantifier free part. So the lower one implies the upper one. Happens that the lower one in this case is false and the upper one is true. But in general, when you have this change of quantifiers like this, the
2570	lower one would imply the upper one. Anyway, that's sort of a side remark. So let's get back to the proof that TQBF is PSPACE complete. That's what our goal is. All right. Now, as I mentioned, this is the same proof. You're going to be seeing it for the third time today. But there's a certain amount of-- it's sort of the context changes in each case. So now we want to show that TQBF is PSPACE complete. So it's one of these hardest problems now but for PSPACE, where satisfiability was the hardest problem for NP. So we want to show that every language in PSPACE is reducible to TQBF. And so we're going to give polynomial time reductions that map some particular problem a, which can be done in space n to the k. It's a problem solvable in PSPACE. We're going to show how f maps a to TQBF. We have to construct the f. So f is going to be a mapping that map strings which may or may not be in a. So strings
2571	w, which may or may not be in a, to these formulas, these quantified formulas. So w is going to get mapped to some formula phi sub mw. It had exactly the same even symbols we used when the proof of the Cook-Levin theorem about SAT being NP complete. This is a very similar proof. But you'll see that we have to do something more in order to make it work in this case. So w is in a if and only if this formula is going to be in TQBF. In other words, if and only if this formula is true. So this formula is going to kind of express the fact that m accepts w, which means that w is in a, because m is the machine, is the PSPACE machine for a. So this formula says m accepts w, and it achieves that by building in a simulation of m on w. It kind of describes a simulation for m on w which ends up accepting. And if m does not accept w, that description is going
2572	to inevitably be false. So let's just see what that's going to look like. So we're going to use the same idea that we used for the Cook-Levin theorem that SAT is NP complete. This notion of a tableau. So if you remember, it was basically a table which was just simply a way of writing down a computation history for m on w. So the rows are the steps of the machine. The top row is the start configuration. The bottom row is, let's say, some particular accept configuration such as I just described where the machine clears its tapes and moves its head to the left end. So there's only one accepting configuration we have to worry about. And each of the rows here is a configuration of m. Because m runs in space into the k, the tableau kind of similarly to what I described before has width n to the k. So now we're talking about polynomial time machines. So the f, which is the bound, the space bound, is going to be some polynomial n
2573	to the k. So the width of this tableau, the size of these configurations are going to be n to the k. How high is this tableau going to be? Well, that's going to be limited by the possible running time of the machine, which is similar to what we saw before. It's going to be exponential in the space bound. So it's going to be d to the n to the k, where d is essentially the tape alphabet of the machine. So are we all together on this? This is very similar to the proof of SAT is NP complete. The key difference there was m was non-deterministic, which might be something to think about later. But let's not focus on that right now. This m is deterministic. But the important difference was the shape of the tableau. The size of the tableau was very different. In the case of SAT is NP complete, we started off with a polynomial time non-deterministic machine. So it only could run for a polynomial number of steps. Here is a polynomial
2574	space machine, which can run for an exponential number of steps. That's going to be an important difference here. So let's see why. The reduction has to construct this formula phi sub of mw, which basically says that this tableau exists. Now, we already saw how to do that when we proved the Cook-Levin theorem that SAT is NP complete. Remember, we had all of those. We had variables for each cell that told us what the contents of that cell was. And then we had a lot of logic here. We had a bunch of logic that said that all those neighborhoods were correct, which basically says that the tableau corresponds to a correct computation of the machine. So why don't we just do the same thing? Why don't we just build our formula using exactly the same process that we used to build the formula when we had SAT being NP complete? Something goes wrong. We can't quite do that. The problem is that if you remember the formula that we built before was really about as big
2575	as the tableau is. Because it had some logic for each one of the cells. It had a set of some of the variables for each one of the cells and it had some logic for each of those neighborhoods, basically. So it says that each of the cells does the right thing. So it was a pretty big formula, but it was still polynomial. The problem is that tableau is now n to the k by d to the n to the k. That's an exponentially big object. So if your formula is going to be as big as the tableau, there's no way you can hope to produce that formula in polynomial time. And that's the problem. The formula is going to be too big. Remember, we're trying to get a polynomial time reduction from this language a. So we have an input to a, a string that might be an a, which is simulating the machine. And the size of the tableau relative to w is going to be something enormous. And so the formula is as
2576	big as the tableau. There's no way to produce that formula in polynomial time. So this is not going to work. Let's try again. So now we have here-- now, so remember this notation from ci to cj in b steps. So we're going to give a general way of constructing formulas which express this fact that I can get from configuration i of m to configuration j of m in b steps. Whatever that b is. b is going to be some bound. And I want to know can I get from this configuration to that configuration. And I want to write that down as a formula, which is going to express that fact. And it'll be either true or false.
2577	for this formula. So I'm going to build that formula for a value b out of formulas for smaller values of b. So this is going to be a way of constructing that formula in terms of other formulas that I'm going to build. And there's going to be a basis for the recursion when b equals 1. So that's the big picture. So let's see how does this formula look. So let's not worry about the case for b equal 1 right now. This is the case for larger values of b. So the fact that I can get from ci to cj within b steps. I'm going to write this down in this way. And let's try to unpack that and see what it's saying. Without worrying about how are we going to carry this out, let's just try to understand at a high level of semantics of this thing what it's trying to say to you. It's going to say, well, I can get from ci to cj in b steps. So m can get from ci
2578	to cj in b steps. If there is some other configuration c mid, some other configuration, I'm calling it c mid, very much inspired by the previous proof of Savitch's theorem, where there was c mid was that intermediate configuration. So now instead of trying them all, I'm saying does there exist one where I can get from ci to c mid in half the number of steps and from c mid to cj in half the number of steps? So if I can build these two formulas, then I can combine them with this sort of extra stuff out here, and them together, and put an exist quantifier that says, does there exist some configuration, some way to find a configuration such that it works as these formulas require? If I can do that, then I'm going to be good. Because then I can-- well, good. At least I'll be good in terms of making something that is going to work. So first of all, let's understand what I mean by writing down does there exist c mid. It's
2579	really if you're thinking back to the way we did the Cook-Levin theorem, we represented these configurations by variables which were indicator variables for each of the cells. And we're going to do exactly the same thing. So we're going to have a bunch of Boolean variables which are going to represent some configuration. So more formally, or in more detail, what this does, there exists a c mid, really is an assignment to all of those variables that represent the contents of the cells of that configuration. OK, so now let's see how to-- how will the recursion work? So to get this value here, I'm going to do the recursion further. So does there exist a c mid? And now for getting from ci to this c mid, is there some other c mid? This is like another value of w from the previous slide where I'm getting, again, I'm cutting the number of steps in half again. So going from b over 2 steps to b over 4 steps. And I'm going to do the same thing
2580	over here. So I'm just unraveling the construction of this formula in terms of building-- by building it up recursively. And then I'm just going to keep doing that until I get down to the case where b equals 1. And if I'm now trying to make a formula that's going to be, say I can get from ci to cj in just a single step. So this is really talking about a tableau of height 1 or height 2. Then I can just directly write that down the way I-- now the tableau is not very big. So now I can write that down using the neighborhoods and so on that I did in the Cook-Levin theorem proof. And this is how you put it all together. And now if you want to talk about the getting from does m accept w. So I initially say, can I get from the start configuration to the accept configuration in t steps, which is the maximum running time of the machine? So again. And if you followed me, what happened in
2581	Savitch's theorem, it's the same values. Now, the thing is we have to understand how big this formula is. And if you think it through, there's a problem. Because what's going on here? I'm expressing this formula in terms of formulas where the size of b is cut in half. But now there are two of them. So it's two formulas on half the value of b. That's not going to be a recursion that's going to work in our favor. So let's just see what happens. So each recursive level doubles the number of formulas. Here we have two formulas. Here we're going to have four formulas and so on. So the number of formulas doubles each time. So the length of the thing that we're writing down is doubling in size each time we go down the recursion. That's going to be OK if we don't go too many levels. But unfortunately, we are going quite a few levels, because the number of levels is going to be log of this initial exponential size thing. So it's going
2582	to be n to the k levels. And so if you're doubling something n to the k times, you're going to end up with an exponentially sized formula. And again, we failed. OK, so I have a check in on this. But maybe we should spend a couple of minutes just trying to understand what's going on here. Because the next slide is really my last slide, and it's going to fix this problem. But let's make sure we understand what the problem is before we try to fix it. Why can we no longer write over each layer of the recursion as we did in ladder? Oh, that's kind of a cool question. What does it even mean to write over the different-- well, so that's kind of an interesting question here. So in a sense, that's going to be the solution. We're going to reuse things in a certain way. But I want you to understand that this method itself does not work, because this recursion here where I'm writing the formula, I'm building the formula for b
2583	out of formulas for smaller values of b. If I do it that way, I'm going to end up-- if I do it as it's described in this procedure here, I'm going to end up with an exponentially big formula. And that's not good enough. So if you cut the formula in half each time, even though you have two formulas, won't the length be the same? I'm not cutting the formula in half. I'm cutting the value of b in half. So you have to say b is initially an exponentially big value. So we're going to end up with an exponentially big formula. So it's not really cutting the formula in half. Cutting the b in half. b starts out big. I mean, b is initially this value here, d to the n to the k. I'm worried. Not too many questions here. I have a feeling that's probably not a good sign. Well, I mean, if you're hopelessly confused, maybe I can't fix it quickly. So anyway, why don't we move on and see how to repair
2584	this, how to fix this problem. And that is going to be by a trick. In fact, I know the people who were involved with coming up with this. This was actually, this proof was done originally at MIT many years ago in the 1970s. And the folks who were involved with it called it the abbreviation trick. So that's what we're going to do on the next slide. Oh no, there's a check in first. Why shouldn't we be surprised that this construction fails? A, well, we can't-- just the notion of defining a quantified Boolean formula by using recursion is just not allowed. So you can't define formulas that way. Doesn't use the for all quantifier anywhere. Or because we know that TQBF is not in P. You can see we do-- what do you think? Why should we not be surprised? I guess I could have put a d in there. Not surprised because you don't know what's going on. That's another reason not to be surprised. But anyway, hopefully you have some glimmer of what's happening
2585	here. And why don't we just-- almost finished. So I'm going to shut this down in a second. Last call. OK, ending. All right. So in fact, the right answer is b. I mean, one should be suspicious that if there's no for alls appearing in this construction anywhere. So really what we're doing is we're constructing a formula that has only exist qualifiers. So it's a satisfiability problem. So really what we just did was we constructed-- we did in a more complicated way the Cook-Levin construction, because we end up with a SAT formula only with exist quantifiers. And so really try one and try two were the same. So it's not surprising that you end up with an exponentially big formula as a result. I don't know. A lot of you answered we know that TQBF is in P. It's not in P. We don't know that. I don't know where you-- what's happening with you guys? But no. Maybe that was a protest vote. But anyway, we don't know that. And what has that got to
2586	do with anything anyway? So anyway, let's see. We solve this in our remaining few minutes here. So here is the solution. Remember, this part where we're saying we're trying to find c mid, does there exist a c mid such that I can get from ci to c mid in half the number of steps and c mid to cj in half the number of steps. I'm expressing one formula in terms of two formulas. That's where the blow up is occurring. Because these two are then in terms are going to each-- so these two are going to become 4, become 8, and that's not good. Can I express this fact in terms of just one formula? And this kind of a little bit in the spirit of your suggestions. Can we kind of reuse things in a way? And that's what we're actually going to kind do. So here's another way of saying the same thing but with just a single formula. And it uses a for all. And the idea behind it is that an and
2587	is kind of like a for all. Or a for all is kind of like an and. Just like in exist as kind of like an or. So when you're saying does something exist, is it this thing or that thing or that thing or that thing? And when you're saying for all, it has this thing and that thing and that thing and that thing. Ands and for alls are very much related. And so we're going to convert this and into a for all. We're going to say for all configuration cg and ch that are either set to ci c mid or to c mid cj, the formula cg ch-- I can get from cg to ch in half the number of steps. So you have to think about what this is meaning here. And I also want to make sure that you don't feel I'm cheating you, because well, first of all, so now we have just a single formula. We're going to go down to the case b equals 1, as we did before. You
2588	have to make sure that saying this restricted for all is not a cheat. When you have for all x is in s, like we have over here, is equivalent to saying for all x if x happens to be in s, then the other thing follows. And this implication can be expressed using ands and ors. And as before, the initial starting point is going to be going from c start to c accept in t steps. And so the analysis that we get is that because there's no longer a blow up, each recursive level just adds this stuff here in front. The exist c mid and this for all part. So that's going to be adding order n to the formula instead of multiplying because we have two formulas. And now the total number of levels is order n to the k, as before. So the size is going to be n to the k times n to the k order n to the 2k. I actually I had a brief check in here, which I'd like
2589	you to do just in our remaining few seconds. Does this construction depend on m being deterministic? So let me just launch that. I want you to guys to get your check in credit here. But in fact, you have to think this through. That formula says that the tableau, you get a tableau. Is that going to matter depending upon whether it's deterministic or non-deterministic? It's actually, well, it's kind of running 50/50 here. Why don't you just pick something? Because I'd like to just close this out and just get to our last slide. So if you don't follow, don't worry. But it's actually an interesting point that the fact that this-- so I'm going to end this. All in? So in fact, the right answer is it still would work if it's non-deterministic. And this would give you an alternative way of proving Savitch's theorem. So really this all comes down to this proof, which implies Savitch's theorem and then in turn implies the ladder DFA problem. So anyway, that's side note, not critical for understanding, really.
2590	You can take those as all separate, the results, and that's good enough. All right, so coming back. Whoops. Coming back. This is what we did. And so each recursive level, the size of the QBF is not the same. Somebody's asking is it the same at each recursive level. No, we had to add in-- let's just see. Each recursion. This is recursively built here, but now we have to add this part in front and this part here in front. So the quantifier which is quantified over a bunch of variables representing the configuration, that gets added on at each level. So it's not just it stays the same. There's stuff that's get added in. But what's important is that it doesn't blow up exponentially. The stuff gets added in every time but not multiplied. OK. So we're done here. So anybody, you can all take off. I think many of you already have. Bye bye. Thank you.
2591	[SQUEAKING] [RUSTLING] [CLICKING] MICHAEL SIPSER: Welcome back. I hope you had a good Thanksgiving and all refreshed and ready to think about some theory of computation. We're in the homestretch now. We have this lecture and two more to go. And so today, I have for you, a completion of the theorem we started before the break, where we introduced probabilistic computation and we talked about the class BPP, as I hope you remember, and we looked, in particular, at these problems involving branching programs, where we started the proof that the problem of equivalence of two read-once branching programs can be solved in this class BPP. So what I'm going to do is spend the first 15 minutes or so just reviewing where we were, because we started this, it feels like a long time ago now. And I just want to make sure that you're all on the same page and we're all remembering what we were doing. And then, I will finish off the proof. And along with doing that, we're going to introduce an important method.
2592	Well, we started that. We looked at the method of arithmetization last time. So we'll review that. We're going to use that again in the work that we're going to start on Thursday on interactive proof systems. So this is a kind of, in some ways, both an interesting theorem in its own right, and a warm up for what we're going to be doing in the last topic of the semester. OK. So let's just remember what we were doing. So we introduced probabilistic Turing machines. So those are these machines that have-- a kind of non-deterministic machine, but there's a different rule for acceptance. And these are also non-deterministic machines which can either make one choice, just to have a deterministic move at a step, or they can make two choices. And when the machine makes two choices, we actually think of there being a probability there, where the machine is tossing a coin to decide which branch to go on. So with that, there is a tree of possible branches. And the probability of some particular branch
2593	is going to be 1 over 2 to the number of coin tosses on that branch. And so we then use that to define the probability that the machine accepts, which is the sum over all of the probabilities of the accepting branches. And the probability that it rejects is 1 minus the probability that it accepts. So thinking about it-- this captures the idea that if you just run the machine on a random set of inputs from the coin tosses, what the probability that you're going to end up with the machine accepting. That's the probability of acceptance, defined in that way. Now, if we're thinking about the machine deciding some particular language, it's supposed to accept the strings in the language and reject the strings which are not in the language. But because of the probabilistic nature of the machine, it might get the wrong answer on some branches. And so we say that a machine decides a language with a certain error probability, means that the probability of getting the wrong answer is going to be,
2594	"at most, that error probability epsilon over all of the possible inputs to the machine. So if we say that the machine is error probability 1/3 that means that it gets the right answer for every string with probability at least 2/3. OK, so that led us to the definition of this complexity class BPP, which I don't even remember if I told you what it stands for. It's bounded probabilistic polynomial time. That's what BPP stands for. The ""bounded"" means is bounded away from 1/2 because we don't want to allow the machine to have probability 1/2, because then bad things happen. The machine can just toss a coin when it decides to make an answer, and not really give us any information. Then, we also went over the amplification lemma. We did not give the proof, but we went over the statement of the theorem. The proof is really just a calculation that you can drive down that error probability to something extremely tiny just by basically repeating the machine and taking the majority vote of what it"
2595	does on several different runs. If you run the machine 100 times and you see if it's mostly accepting, then you want to accept. And the chances that the machine was really biased toward rejecting, even though you're in your sample see mostly acceptance, is extremely small. And you can calculate that, but you can make that very tiny. So small that, for all practical purposes, it's really giving you the right answer. But it's not deterministic. So it's not quite 100% guaranteed. And the way I like to think about BPP in terms of the computation tree of the machine, so that when it's accepting, most of the branches are accepting, weighted by their probability, of course. So the there are many accepting branches when you're accepting, and many rejecting branches when you're rejecting. So just another way of saying the same thing. Now, we're going to jump right in with a check-in. And this is a little bit more, not exactly the material of the course, but a little bit more on the philosophical side. But let's just
2596	see how you do with it. When you're actually running a probabilistic machine, you imagine the machine, as we're kind of informally describing it, is tossing coins. Every time it has a non-deterministic-- every time it has a choice. So it choice tosses a coin to decide which way to go. Of course, a real computer does not have a coin to toss, presumably. Well, maybe you might actually build some hardware into the machine that lets it access randomness in some sense. Maybe it uses some quantum mechanical effect to get some random value or maybe it uses the timer. I'm not exactly sure. You can imagine having a bunch of ways of implementing that. A typical way that people implement randomness in an algorithm is to use a pseudo random number generator, which is a procedure that might give you some kind of a value that looks random, but may not actually be random. It's, for example, giving you the digits of pi. If you want binary, expressing pi as a binary number, then you might calculate the
2597	different successive digits of pi and use that as for your random number generator. Of course, that's a deterministic procedure, so it's not really random. But often, people do use those kinds of things when they're simulating random machines. So what do you think about doing that? Could we use a pseudo random generator as the source of randomness for our randomized algorithm? Yes, or no, or what do you think? So let's launch a poll on that, so I can see what your opinion about using pseudo random number generators instead of true randomness for our algorithms. I'll give you a few seconds, a minute to weigh in on that. OK. We're going to close this down. Everybody's participated who wants to? 1, 2, 3. OK. Yeah, I think probably the best answer is A. Let's take a look. There were a couple of answers here that, really, that don't make-- that aren't as good. I would say, B, well, usually people think of pseudo random generators as pretty fast procedures. They're not that interesting, otherwise. So I wouldn't
2598	say that B is a good choice because they're usually pretty quick to implement. C is a worse choice, even, because Turing machines can do anything that any other algorithm can do. So, certainly, if there is such a thing as a pseudo random number generator, and there is, then you could implement it on the Turing machine. D is kind of an interesting answer because you're saying, well, that would imply that P equals BPP if you could actually simulate randomness with a deterministic procedure. But in fact, the reason I would not choose D is because it's perfectly conceivable that P does equal BPP. We don't know that P is different from BPP, so it's conceivable that they're equal. And in fact, I think if you polled most complexity theorists, most people in my field would believe that P does equal BPP just for this very reason, that if you had sufficiently good pseudo random number generators, you could actually eliminate the probabalism in these probabilistic computations. You could just run them on the pseudo random number generator.
2599	And in fact, there is some theory around that that has been developed. But at the present time, we do not know how to prove that there were pseudo random number generators. And it has some, actually, there's actually, in some line of this research, has some connection with the P versus NP problem, but we don't know how to prove that there are sufficiently good pseudo random number generators that would allow you to run them on a probabilistic algorithm and have a guaranteed behavior which is as good as running truly random numbers into the probabilistic algorithm. And so the answer that I would pick would be A, that you could use it, sure. You might get the right answer, but it's not guaranteed. We just don't know how to do the analysis for the pseudo random number generators. And if you had ones that were good enough, they would show P is equal to BPP. But that might be, in fact, the correct-- that might actually be true. OK, so let's continue on.
2600	We had these kind of networks of nodes and edges. And there was a procedure, we'll see a couple of examples again, some of the ones that we had from before where you have branching programs that look like this. And you have a bunch of query nodes. You look at the settings of the variables to decide whether to go down to 0 edge or a 1 edge. And eventually, you're going to end up at an output node, and that's going to be the output of the branching program. And in such a way, these branching programs defined Boolean functions, from the settings of the input variables to a 0 or 1 output. Now, you might have two branching programs and wonder whether they're computing the same Boolean function or not. And testing that is a coNP complete problem, as you're asked to show on your homework. Now, if the branching program, however, has a restriction, namely, that it's not allowed to ask to query the same variable more than once on a path, then with that restriction,
2601	we call it a read-once branching program. And then, the situation for testing equivalence seems to be different. In fact, we can give a BPP algorithm for testing the equivalence of read-once branching programs, even though such a thing is unlikely to be the case for general branching programs because of the coNP completeness. OK, so I hope you're comfortable and with me on all of that reasoning. OK. All right. So the idea for proving this is, what we're going to do is we want to take the two branching programs and run them on a randomly-selected input. But as we observed last time, if you just run them on a randomly-selected Boolean input where we assign the variable 0s and 1s, then that doesn't give you the right answer with high probability, because the two branching programs might be different, computing different Boolean functions, but they differ only on a single input setting. And then, just picking them at random, you're not going to have a very high probability of finding that one place of difference. So instead,
2602	what we're going to do is define a way to run these branching programs on non-Boolean inputs, where the variables are set to values other than 0 and 1-- 2, 3, 7, 22-- and make sense of that. And then argue that, by running the two branching programs on a randomly-selected non-Boolean input, that that's very high probability of giving you the right answer. So somehow, by expanding the domain of possibilities, you're going to better your chance of getting the right answer very significantly. OK. So even though these two branching programs might agree on almost all of the Boolean inputs, we're going to show that by doing this arithmetization-- so this is the method-- if they're really not equivalent, they're going to differ almost all of the time on the expanded domain. OK, and then we have the proof. That's where today's work is going to be. OK. So why don't we just stop and make sure we're all together on this? I can take any questions. I'll also review how the arithmetization goes. But I'll do that
2603	next. So, are we all OK on this? Good. So let's move on. So in order to move toward understanding what it means to run the branching programs on these non-Boolean values, we're going to have to get a somewhat different perspective on the computation of a branching program. So the standard perspective is that you take your setting, your assignment to the input, which is 0,1,1 for x1, x2, and x3, and use that to follow an execution path through the machine. So we know x1 is 0, x2 is 1, x3 is 1, the output is 1, as I've indicated in yellow. This other perspective says, well, we're going to operate by labeling the nodes and edges of the machine. And that's going to have a very direct correspondence with the execution path perspective. So we're going to label all of the nodes and edges on the path with a 1, as indicated in yellow, and all of the nodes and edges that are not on the path, all the other nodes and edges are going to be
2604	labeled 0. So by following the 1s, it's like the breadcrumbs in Hansel and Gretel. This is the path you need to follow to get through the machine. The 0s are the places where you don't go. OK, so the output label, here, the output is going to be the label of the one output node, whatever you're labeling that. Because if it's a 1, that means the path went to the 1, and if it's a 0, that means the path didn't go to the 1, it went to the 0. So just by looking at this value, you can see what the output of the machine is. All right. So let's describe a different way of defining this labeling without just looking at the path. Well, it's going to capture exactly the same thing. So we're going to say, if you've already labeled a node, I'll tell you how to label the two edges that emanate from that node. I'm going to label the one edge a and the query variable. Why is that? Well, a is going
2605	to be either a 0 or 1. And it's going to tell us whether or not the path entered that node. So if it's a 1, it entered that node, if 0, it didn't enter that node. The only way it's going to go down this branch here is if it did enter the xi node. If it didn't enter the xi node, there's no way it can go down this branch. So we're going to and that value. So the only way you can go down this branch is if it went through that node-- so that's the a, the value of a-- and the xi is a 1. That's why we say a and xi. So you really have to understand this little expression here. If you don't understand that, you're toast. OK, so you better understand this so we can move forward. I'm happy to take a question. These are the simplest questions are sometimes the most valuable. If you don't understand why I'm labeling it this way, shoot me a chat. OK. Now, the other branch,
2606	I'm going to say, well, I'm only going to go down this edge if, well, a is true, so I did go through that node. And xi is false. So this is going to be a and the complement of xi. All right. So that's how I'm going to label these. This is another way, giving these expressions for labeling these edges based on the label of that node. And similarly, in order to complete the picture, I've got to tell you how to label the nodes based on the edges that are coming into it. So if I know that I have a1, a2, and a3, which tell me the status in terms of the path of whether the path went through any of these edges, well, I know that it's going to go to that node if the or of these values-- if the path went through here, or it went through there, or went through there, then it's going to go to that node. That's why the or is the right thing to say. So this gives
2607	me another way of constructing the labeling over here without even talking about paths. As I describe it, I argue that it's going to give the same result. All right. So there's a question. Can we quickly say again why we can't do that on Boolean? I'm not sure I understand the question. So send it to me again. Right now, everything is Boolean. We haven't done, arithmetically, anything yet. And the reason why we can't just live in the Boolean world is that, just by taking Boolean values of Boolean assignments here, we don't have a high enough probability of catching a difference between the two machines. All right. So let's continue. All right. So now, I'm going to talk about how
2608	using the arithmetization method. So first of all, arithmetization is a simulation of and and or with plus and times, such that if I think about true as a 1 and false as a 0, this is going to give me a faithful simulation. It's going to do the right thing. It's going to compute exactly the same values that we expect. So like a and b, well, times works just like and. It does for 1 and 0 as true and false, times exactly works like and. And negation is 1 minus. Or is going to be the sum minus the product. And then, these just give you the right values, a or b. If you just calculate it out by plugging in 1s or 0s, you get the right answer just by using this arithmetic. So now, what we're going to do, instead of using the Boolean labeling, we'll just use the arithmetical labeling. But it's going to compute exactly the same thing because the arithmetic simulates the Boolean. So we always go through the start node. So
2609	there's no question about labeling the very start node with a 1. But now, I'm going to give expressions just like the Boolean expressions, but now they're going to use plus and times instead of ands and ors. So let's just see. Remember what we did from before. We had a and xi for this edge. I'm going to replace that. What is and? We just look up here in our table, in our translation table. And becomes times. So we're going to replace that with a times xi. And it's going to work exactly the same. But the difference is that this makes sense even when we have non-Boolean values. Times and plus are defined for non-Boolean values, whereas ands and or are not. So what goes down on this edge? Well, this was a and the complement of xi, as you remember. So that's going to become a times 1 minus xi. And then similarly, we had or over here. And here's a little bit of a trick, but that's going to be important for the analysis that
2610	we're going to do. Instead of using the recipe for or in terms of plus and times, we're going to have something a little simpler. It's just going to be the sum. And the reason why that works-- good to understand-- is that because of the acyclic nature of the branching programs, at most, one of these edges can have a path through it. So this is a kind of very special or, sometimes called the disjoint or. You're not allowed to have more than one of the values be 1, because that never happens when you have an acyclical graph. You can never have the path coming down this way, and then, again, coming down that way. Then it would be entering that node twice. Have to be a cycle. So it's going to be good enough for us, and necessary for us to represent this or as a sum. OK. So I think that's all I wanted to say on this slide. So somebody is asking, is it possible for some of these values to be negative? Yes.
2611	As it stands right now, some of these values can be negative. I haven't put any restriction on what the values are going to be. So the input could be a negative number. And then, you're going to just get negative stuff happening. In fact, there's subtractions going on here. So even with positive numbers-- I think we did an example last time. I think I'm going to do that example again of exclusive or, where you get negative numbers coming up. That doesn't matter. But actually, what we're going to end up doing is doing these calculations modulo some prime number q. OK. I'm going to pick some prime like 17, and do all the calculations mod 17. And the reason for doing it that way is really because we're going to be picking random assignments to the variables as our input. And it makes the most sense to do that when you have a finite set of possibilities to pick them up. So we're not going to pick like a random integer. There's infinitely many possibilities. And yeah,
2612	you could set up a distribution there, but that's very complicated. That actually might work. I'm not sure. I haven't actually gone through that analysis. But the typical way people do this is by looking at what's called a finite field. So I'll talk about that in a second. Why is there at most one 1 among a1, a2, and a3? The 1s-- I'll say once again-- but the 1s correspond to the path. So this is a 1 if the path went this way. Just think about it. The path cannot go through a1 and can, at the same time, go through a2, because that means the path went through this node. Then, how is it going to get over to a2? It's going to go through that node twice. In an acyclic graph, you cannot have a path going through it's the same node more than once. So you're going to have to think about that.
2613	So now we're going to talk about the same-- we're going to look at that non-Boolean labeling applied to an example. So here is a very simple branching program that actually computes the exclusive or function in the Boolean world. So this is the labeling that I just developed for you, the arithmetical labeling. And we always label the start node with 1, because the path always goes through there. And now, let's look at this before we jump ahead, let's look at this edge here. Remember what it is. We have to apply this rule here. This is the one edge coming out of a node that already is labeled. So it's that label on that node times the xi. Because if you're thinking about it, that, that's the and, captures the and. So it's just a times xi. So it's x1, in this case. So x1 is a 2 in our input. So it's going to be 1, which is the a, times the x1, which is 2. So this edge gets labeled 2. Now this-- well, OK,
2614	let's look at this edge now. I think that's next. This is the 1 minus xi, it's the 1 minus x1. So it's 1 minus 2. So you're going to end up with a minus 1. 1 minus times minus 2. 1 times 1 minus 2, which is minus 1, so it's a minus 1. Now we're going to label these two nodes using the other rule. So this gets a 2 because that's a sum of the incoming edges. This gets a minus 1, because that's the sum of its incoming edges. And now we're going to look at-- which order did I do this in? OK, I'm going to do this edge now. 0 edge, which is going to be 2 times 1 minus its variable. So it's 1 minus x2. X2 is a 3. So it's 1 minus 3 to minus 2. So 2 times minus 2 is minus 4. OK, I don't want to rush through this. No point in just blabbering on. I'm just trying to work this example so you get the idea. OK,
2615	so could you fill this next one out yourself? So this is the one outgoing edge from this x2 node. So x2 is labeled with 2 here. So there's a is 2. This is the one edge going out, so it's one on this side here. So it's 2 times the x2. x2 is a 3, so it's 2 times 3. So this should be 6. Oops. Right here-- 6. I'm going to do the same thing. So x2 is labeled minus 1. So minus 1 times 1 minus. So you get a 2 here, you get a minus 3 here, just following, again, the same process. And now, what is the label on this 0 node here? So again, you take the sum of its incoming labels. So there was a 2 and a 6. So that's an 8. And this is a a minus 3 and a minus 4 coming in. So it's a minus 7. What's the output? The output is minus 7, because that's the label on the 1 node. OK, output is minus 7. OK.
2616	So this is going to be our way of defining the output of a branching program when it has a non-Boolean setting on its inputs. If you had the Boolean setting on its inputs and you followed this procedure, what would you get out? You would get the same answer that you would get by following the path because the arithmetical simulation is a faithful simulation of the ands and ors. And the ands and ors capture exactly when-- what the path does. So this is a strict extension of the operation of the branching program into a new realm, these non-Boolean values. On the old realm, it behaves just as it did originally. And that's critical to understand that. Yeah, somebody's asking what the final value of the 0s, they'd also be the same. Sure. In the Boolean case, if we follow this in the Boolean cases, all of the labels would be exactly what they were. They would just be the 0s and 1s that we had from before. So does this exactly mimic x or if you
2617	take this all mod 2? I don't know. I'd have to think about that. I don't think that that's essential. In this case, it might behave correctly if you take the answer mod 2 for XOR. But the XOR is going to be very special. And I'm not sure. That might happen to be true. I'd have to think about it for a second, but I'm not sure that's relevant. OK, so this is a good question. If I picked a different branching program that also implements XOR-- or-- so it would be an equivalent branching program-- would it behave the same way on the non-Boolean values? And the answer to that is yes and no. You understand the question? It's a very good question. And actually, we're going to prove this in the analysis. It's going to be easy to prove because I gave you both possibilities, yes and no. But let me tell you what I mean by that. So you understand the question. Suppose I had a different branching program. I'm not sure you can come up
2618	with a different branching program, but let's say you could. You have a different branching program, yeah, sure you can come-- you can do the variables in a different order, for example. So suppose you come up with a different branching program that gives you XOR. And now you plugged in 2 and 3. Would I always get the same value out? Yes, if that other branching program was read-once. No, not necessarily if it's not read-once. And that's why read-once is critical. As we will prove, for two read-once branching programs, if they behave the same way on the Boolean values, they behave the same way even on the non-Boolean values. That's not necessarily true if the branching programs are not read-once. OK, we will see that. We will prove that and use that. That's going to be important. OK, so here is the algorithm sketch, which is kind of a little bit even sort of suggested by that very good question. So what we're going to do is we want to take the two branching programs that we're
2619	trying to test if they're equivalent. We're going to pick a random non-Boolean input assignment-- so set the values here chosen from the field, but we'll get there. A random value for x1, random value for x2, and so on. These could be numbers like 17, and 25, and 23, and so on. And then, using this process, run the branching programs to evaluate them on that non-Boolean assignment. If they disagree, then we're going to know that the two branching programs were not equivalent, even on the non-Boolean case. Even on the Boolean case. Did I say that wrong? So if they disagree, even on the non-Boolean case, they have to be an equivalent even in the Boolean case. Not obvious. But if they agree, then it's not a guarantee that they're equivalent, but it's going to be very strong evidence that they're equivalent. OK, so that's where the probabilistic nature is going to come in. So we're going to prove that. So first, we have to develop an algebraic fact. And that involves polynomials. This is a simple
2620	thing that I think many of you have run into already, perhaps even in high school. I'm not going to prove the algebraic facts, but I'm going to state them. And actually, the proofs are not hard. They're in the textbook. So suppose we have a polynomial of degree d here. It happens to have p. So there's a bunch of constants. These a's are constants. x is the variable of the polynomial. And I presume you've seen polynomials written out like this. And so if you assign x to some value, some constant value z, and the polynomial evaluates to 0, we often call that a root of the polynomial. So these are the places where the polynomial evaluates to 0 that I've of shown over here. Those are the roots. It's not hard to show that a low-degree polynomial cannot have lots of roots. Basically, if the polynomial has degree at most d, it can have at most d roots, as long as the polynomial itself is not the everywhere 0 polynomial, because obviously, then everything is a
2621	root. Oops, typo. Thank you. Should be d minus 2 over there. Pretend that's a 2. All right, so if we have a low-degree polynomial-- let's not get ahead of ourselves. If we have a low-degree polynomial, a polynomial of degree at most d, it has at most d roots. And that's a simple proof. The basic idea is every time you have a-- if you have a root of the polynomial, so if setting x equal to 5 gives you a root of the polynomial, it's a 0 of the polynomial, then x-- you can easily to see that x minus 5 is a factor of the polynomial. You can divide by x minus 5, and you get a new polynomial of degree one less. And you can just, which is going by induction, has one fewer root. So you can just divide out by the roots, basically. It's very straightforward.
2622	And other very important thing-- if I have two polynomials that are both low-degree, they cannot agree on very many places. That follows from what I just proved above. Because what I'll do is I take those two polynomials, and they look at the difference, which is also a low-degree polynomial. Every time there's an agreement between those two original polynomials, there's a zero of the difference polynomial. And because that difference polynomial cannot have too many zeroes, the two original polynomials cannot have too many agreements. So the corollary is that if x and y are both polynomials of degree at most d, and they're not the same polynomial, because then the difference would be the 0 polynomial, then the number of places where they're equal is at most d. So the proof is just letting p be
2623	very standard kind of a trick. Now the above is going to hold for any field. A field is just a set with plus and times with the familiar properties of distributive law and so on and identities and all the stuff that you would expect plus and times to have in the normal world. And so we're going to talk about the finite field that has only q elements-- that has exactly q elements, where q is a prime number. So it turns out that-- and I'm not going to prove all this, but it's pretty simple stuff-- that if you just take the numbers from 1 to q minus 1-- from 0 to q minus 1, and use plus n times mod q, that has all the right properties to be a field. So just think of it-- just modular arithmetic, mod some prime q. And then we can in a natural way pick a random assignment to a variable from the field because it's just choosing from among q possibilities. Yeah, so getting a question here. The
2624	coefficients of the polynomial and the assignment to the variables-- they're all going to come from this field. So everything's going to be operating in this field. Don't let that throw you off. Just your ordinary intuition about the way arithmetic works is going to be just fine. But this is important here from the perspective of thinking about this probabilistically. So I'm going to rethink about this polynomial lemma, which says there are not too many roots. In terms of the probability of picking an element of the field, what are the chances that it happens to be a root? So if you have a low-degree polynomial, and you pick a random value in the field, what's the probability that you've got a root? Well, it's just the number of roots divided by the size of the field. So if you have this really big field, and you have this low-degree polynomial, it's going to be pretty unlikely that you're going to end up picking one of the zeroes, one of the roots, just at random.
2625	So there's at most d roots out of the q possibilities. And the last thing I'm going to introduce here is the multivariable version of this which is called, perhaps somewhat unfairly, but it's called the Schwartz-Zippel lemma, though in various forms, it had been known prior to their work. In some cases, the literature actually goes back a long ways. But anyway, this is called the Schwartz-Zippel lemma. Doesn't really matter, except to the people whose credit is being denied. But that's not one of us. So anyway, the Schwartz-Zippel lemma says that if you have now a polynomial in several variables, which is not the 0 polynomial, where each variable has low degree-- so if I say if it has degree at most d in each xi. So each variable is going to have at most an exponent of d appearing in that polynomial. And now if we pick random values to assign to all of those n variables from the field, the probability that we ended up with a root, that we ended up with a 0,
2626	is something you can bound. So it's m times d, so the number of variables times this maximum degree, divided by the size of the field. And this is going to come up later for us. And this is another fairly simple proof, a little bit more sophisticated than the one that we had above. And in fact, it uses that one as a lemma to prove this theorem. So we're going to-- not going to prove any of that, but I refer you to the book if you're curious. Yeah, so a couple of good questions here. What happens if these values are bigger than q, for example? Then it's not telling you anything. If d is bigger than q, m is bigger than q, or the product is bigger than q, then you learn nothing from this lemma-- from this theorem. So typically in applications, you're going to pick a large-- you're going to have the flexibility. You get to choose q to be something that you want. So we're going to pick the field to be big
2627	enough so that the m and d are going to be relatively small. In fact, d is going to end up being 1, as we will see. And m is the number of variables. So we're going to pick q, which is going to be substantially larger than the number of variables. And how is the degree defined in multivariable polynomials? If the polynomial has xy squared plus 3x to the 5th y squared z, you just pull out each variable separately. And you look at the maximum degree of that variable. So the x in that case had had a degree 5 appearance. The y had a degree 2 appearance. So you take the maximum over all of the variables of the degree of that variable. And that's going to be the bound on the degree of the polynomial. So in fact, in our case, d is going to be 1. So all of the variables-- there's not going to be any exponents on anything. Everything is going to be exponent 1.
2628	Is q related to the number we choose for the mod? Yeah, q is the number we're choosing for the mod. We're doing everything mod q. So all the arithmetic is going to operate in mod q, and that's the size of the field that we're going to pick. So I think we're here at the break. Happy to take some more questions, but why don't we just start that off. And I will see you in five minutes. But in the meantime, happy to shoot me questions. So what happens if we use Boolean assignments in the XOR example? Would that work to be able to check agreement? It would. So it's hard to make an argument based on just a single example. I think the better thing would be to look at two branching programs that just differ in a single place. So I can even suggest two. You can make a branching program that always outputs true. It doesn't even read its variables. Or if it reads them, they always go to the same place. And it
2629	ends up always at the q output. So you imagine a branching program that always outputs 1, no matter what the assignments to the variables are. And you can easily make such a thing. And then you make another branching program that computes the or function. So it reads every variable. And it's going to be 1 if any one of those variables is set to 1. So the only time the or function is 0 is if everything is set to 0. But now if you're trying to randomly check whether the always one function is equal to the or function-- of course, without knowing in advance what they are, because that's cheating. You're just given these two functions, and you want to know-- these two branching programs. And you want to know, are they computing the same thing or not? And by this procedure of randomly sampling, you're always going to get these branching programs both to say 1, unless you just happen to pick the random assignment of everything set to 0. And that's very unlikely that
2630	you're going to pick that. If you imagine you have-- your branching program has 100 variables in it. It's only 2 to the minus 100 chance that you're going to set them all to 0 randomly. And so you're extremely unlikely to find that one place of difference if there's only a single place. If there's lots of places of difference, then it's not so bad. But if the number, the fraction of differences, is low, you're going to have to do a lot of samples in order to find that-- possibly exponentially many samples. And then you won't run in polynomial time. So let me just see if there's other questions here. Why can we accept-- going back to the Boolean labeling side, why can we accept that b1 equals b2 if b1 and b2 agree on-- only on just one input assignment? No, we didn't say that. All right, I'll go back there. Boolean assignment-- is this-- I'm not sure which one you mean. Is this the one you mean? I don't know-- Boolean labeling, so it must
2631	be it. Why do we non-Boolean labeling? No, I see what you're saying. You're saying about this here. We're just going to pick one random assignment. And if they agree on that one random case, then we will say accept, because you might think, well, we should take a whole bunch of samples. That's a good question. But in fact, we're going to arrange the probability such that if the two things are not equivalent, then it's going to be-- the values will be different almost everywhere, or a large number of places. So just picking one and having them agree is going to be strong enough evidence that you're still going to accept. And you'll have still a low probability of getting an error. You'd have to see the analysis. Are we assuming the roots of the polynomials are integers? No, we're operating over a field here. Even talking about integers doesn't totally make sense. But it doesn't really matter. We're not assuming that. Oh, I should have taken this away. The bound still works. The bound still works
2632	even if we have non-integers. I'm not sure if I'm being helpful here. Why don't we just move on? But we're not assuming that these are integers because the bound doesn't matter. If it says there is at most five roots, including the reals, there's still going to be five roots, including the integers. All right, so let's continue. Good, all right. So now everybody's back, I hope? Let's talk about moving forward here. Where we're going with this is we want to analyze the algorithm, which picks a random non-Boolean input and evaluates the two branching programs. And in order to do that, we're going to look a little bit more carefully at what happens when we arithmetize the branching program, and we run it on these non-Boolean values. And so what I'm going to do is take this branching program. Let's say this is the same XOR, exclusive or, branching program. But instead of labeling it as we did before by setting x1 to 2 and x2 to 3, I'm going to leave x1 and x2 variables and
2633	just do a symbolic execution. So I'm going to label these things, just leaving x1 and x2 as variables. So let's just see what we get if we do that. So remember, we assigned this to be 1. Now this edge here is-- here's the rule. It's a, which is 1, times x1. So this should be-- without knowing what the value of x1 is, leaving it as a variable, we're just going to put down x1 over here. Over here, what goes over there? Well, it's 1 times 1 minus x1-- just 1 minus x1. Now we're going to add things up, as we did before. And now what happens, for example-- I think I have this edge coming next. Let's look at this edge, the one edge coming out. The label now is x1 on this node. This is the one edge coming out, so you multiply by the value of x2. We're leaving it as a variable, so we're just going to multiply it by x2. And so we're just going to get x1 times x2-- x1x2
2634	on this edge. And now what happens on this edge? So this x1 times-- think with me-- times 1 minus x2. And similarly over here, we have 1 minus x1 on this node. So I think on the one edge coming out, it's 1 minus x1, now times x2, because that's this rule again. 1 minus x, 1 times x2. And this is going to be 1 minus x1 times 1 minus x2. Now we're going to add this up for the 0 node. So we have this value, 1 minus x1, 1 minus x2, plus x1 x2. And on this note here, we're going to add these two values up. So 1 minus x1 times x2 plus x1 times 1 minus x2. And that's the output, now expressed symbolically. Now you could plug things in, and you're going to get the same value out as you did before. But let's leave it as a polynomial for now because that's going to help us and analyze this. So now, notice the form of this polynomial is something special. What happens
2635	is it's going to look like a bunch of products of xi's and 1 minus xi's added up. So it's a sum of products of that form. So each row here is a product of xi's and 1 minus xi's. And then those rows are all added together. I claim that's going to be the form of this polynomial. You see this already has that form. And the reason for that is every time you go to a node, you're just adding things up. So that's just going to be like adding up more rows. And every time you go down to through an edge, you're multiplying what you have so far either by an xi or a 1 minus xi. So you're just accumulating products of xi's and 1 minus xi's, and you're just adding them up. So this is what that polynomial is going to look like. Now let's look a little bit more carefully at the form of this. So for one thing, could we have higher powers here, like x2 cubed? Could that happen? And when
2636	I say it's products of the xi's and 1 minus xi's, maybe there's going to be some xi's that appear several times in the product. Well, that cannot happen. Why? It's a read once branching program. So every time you multiply by an xi or a 1 minus xi, you're never going to do that again, because doing that would imply you're querying that variable more than once. So this can't happen. So I cross that out. This just appeared. It's off to the side, here. But yeah, I'm crossing that out. That does not happen. Another thing that is part of-- that's worthy-- that's going to be helpful to notice about this polynomial-- and by the way, maybe I'm being confusing here. This I'm supposed to be representing as a generic form of the polynomial. This is not some particularly-- yeah, I should have said this at the beginning. This is not some particular polynomial that came from anything. I'm just trying to describe what the general form of the polynomial looks like, just as an illustration. So this
2637	"polynomial's 1 minus x1 times x2 times 1 minus x3 times x4 and so on, and adding up a bunch of rows like this. I'm just saying this is what the polynomial will look like for maybe some branching program. So every branching program is either going to have some polynomial that looks sort of like this. And what I'm also going to say-- for convenience, now, I want to say that each row is going to have every single variable appear either as an xi or as a 1 minus xi. So in order to get that, I need to make a further minor assumption about the branching program-- that it's a read exactly once. Currently when I say ""read once,"" it can avoid reading some variables on some branches, because it's like a read at most once. But now I want to say that every variable gets read exactly one time on every branch. And what that's going to mean is that every row is going to contain every variable, either as an xi or as a 1"
2638	minus xi. We can eliminate that extra assumption easily. And I'm going to leave that as an exercise to you. It's not very hard to do. So I think if you follow me, you can see-- and you play with it for a minute or two, you'll see that it doesn't really matter. But I think just for the first time through this, let's assume that every row has every variable-- so important to understand. So this is the output polynomial of this branching program. So let's look furthermore at this polynomial and understand the rows. Let's take one row out of this polynomial to understand what it represents. So one row here-- it's a product of a bunch of things, product of a bunch of variables, either variables or 1 minus the variables. Let's think about this in the Boolean setting, first of all. So in the Boolean setting, each of these variables are going to be 0's and 1's. And the 1 minus the variables are also going to be 0's and 1's. So it's going to be
2639	a product of 0's and 1's. If there's a 0 that appears in that product, that product is going to be a 0, because 0 times anything is a 0. So the only way that product cannot be 0 is if all of those values are 1's in the Boolean case. So that means that x1-- well, let's look at the second row. So x1 had to be a 1. x2 had to be a 1. x3 had to be a 1. x4 had to be a 0 in order to continue the product of 1's, and so on. So in fact, there's only a single Boolean assignment to these variables which make that row 1. Every other assignment to those variables makes that row 0. Saying that another way, each of these rows corresponds to one of the rows of the truth table for the Boolean function, where the truth table is true, gives a true value, gives a 1 value for the function on that row. So I hope you're all familiar with the notion of a truth
2640	table of a Boolean function. You just write down the Boolean function, every possible assignment to the Boolean function, and you write down 1 or 0 or true or false for what the value of that function is. It's just a tabular representation of the Boolean function. It's called a truth table. This thing here gives you all of the 1's-- all of the rows that are 1 in that Boolean function. That's what this polynomial gives you. So I think we're at a pause point for this slide. It's deathly silent on the chat. So I have a feeling that that went down rough for you. It's important to understand the form of this polynomial here. It corresponds to the truth table of the Boolean function. So each one of these rows is only going to be-- again, thinking Boolean now, each one of these rows is only going to be 1 on an assignment which makes the function 1-- one of the assignments that makes the function 1. And somebody says, and similarly for the expression for the
2641	0 node. Yeah, the 0 node, which I'm not focusing on, but, yeah, the 0 node would be all of the false rows of the truth table. But the 1 node, the polynomial for the 1 node, are all of the true rows-- correspond to all of the true rows in the function of the branching-- the function that branching program computes. Let me just tell you where we're going. Is it possible to have two rows that are the same? If you think about how the rows are being produced, no. You can't have two rows that are going to be the same, because for one thing, you have to think about what this looks like in the Boolean case. If you have two rows are the same, that means this thing is going to-- would have an output which is non-Boolean because you're going to end up with a 2 coming out that way by adding those rows together. That can never happen. And if you just look at the way it's constructed, you're never going to-- because
2642	every time you have a branching, one way is an xi. The other one is 1 minus xi. So every time you're branching there, every time there's a node, they're different. So you're never going to have two rows that are going to be the same. But let me tell you the importance of connecting up this polynomial with the truth table, because that tells us that if the two functions of the two branching programs that we started off with agree in their Boolean values, then the two polynomials are going to be the same. Because if the two branching programs have the same Boolean function, so they're equivalent, then the truth tables will be the same. And therefore, these polynomials will be the same. And therefore, they will behave the same way on all non-Boolean values, because they're the same polynomial. So I'm getting ahead of myself, but that's what we're going to argue. That's why it's important to understand the connection with the truth table, because it builds on the-- understanding something about how this thing behaves
2643	in the Boolean case is going to give us information about how it behaves in the non-Boolean case. But let's continue here, then. Yeah, this is essentially the last slide, but we're going to spend some time on this one. So here's the algorithm. We are going to take our two branching programs. The variables are x1 to xm. First of all, we're going to find a prime which is at least 3 times m, the number of variables. m is not a very big number. It's just the number of variables. So finding a prime that's bigger than that is straightforward. We're not talking about huge primes here. We're talking about very modest-sized primes. Even trial and error is going to be good enough. Now that's going to be the size of the field. It's going to be a field of size q. And now we're going to pick a non-Boolean assignment to the variables. We're going to pick a non-Boolean assignment to the variables and evaluate the two branching programs on that non-Boolean assignment using the arithmetization. If
2644	they agree, then we'll accept. If they don't agree, then we're going to reject. Now we have to argue that this works. So we're going to first of all arithmetize these two branching programs, and we're going to get these two polynomials. They each have the form that-- as I described, so a bunch of rows that correspond to the truth tables of those two respective branching programs. First claim-- that if the branching programs were equivalent, so they compute the same Boolean function, then the two polynomials agree everywhere. So then the two branching programs are going to get the same value on every non-Boolean case as well as on the Boolean cases. So they agree in the Boolean. That means they always agree, even on the non-Boolean. And I kind of argued that already. The other point is that if the two branching programs are not equivalent, so they differ at some Boolean value, now picking a random value for the polynomial evaluation, you're going to have only a 1/3 chance that they're going to agree, so a
2645	small chance. All right, so now let's prove these two facts. The first one I already kind of argued. If the two branching programs agree on all the Boolean values, then their functions have the same truth table. So then the polynomials are identical because the polynomials correspond to the truth table. And so therefore, they always agree, even on the non-Boolean values. So that means that the probability that if you evaluate the two polynomials on a random place, whether they'll be equal, that's a certainty, because in fact, in this case, p1 and p2 are the same polynomial. Now for two, if the branching programs differ somewhere, even in one place, well you know the polynomials could not be the same. They have to be different polynomials because the polynomials include the behavior in the Boolean case as well as all the rest of the field. So the polynomials have to be the same. And now we're going to apply the Schwartz-Zippel lemma. We have two different polynomials. They can only agree in a relatively small number of
2646	places. So that says that, from the Schwartz-Zippel theorem, then the probability that p1 and p2 agree at this random location is at most this value that we had from before, the degree times the number of variables divided by the size of the field. The degree is 1. And the field is at least 3 times the number of variables in size. So that means you get this inequality here. And so therefore, the probability is a 1/3-- at most 1/3. And that's good enough. This is the probability that you get the wrong answer is going to be at most 1/3. So you're going to get the right answer with at least 2/3 probability. So even just doing a single sample point is going to be enough to give it a PPP algorithm. What I have are a couple of check-ins here now for you. Whoops, somehow this-- going to take me out of here. All right, so this is a little hard, but let's see how you do on it. Suppose the branching program is-- well, maybe
2647	I a little bit discussed this already, but that's OK. The branching programs were not read once. The polynomials might have exponents bigger than 1. So where would the proof fail? Would they fail at the point where b1 and equivalent to b2 implies that they agree on all Boolean inputs? So that's the first step here. Or was it that agreeing on all Boolean inputs implies that the polynomials are the same? Or would it be that having the two polynomials being equal implies that they always agree? So those are the three steps in the proof of part one. So let's see. What do you think there? I'm getting a couple of questions about picking the prime number. The prime number here is-- this is a very small prime number. You could even represent that prime number in unary within the amount of time we have, because don't forget, this is a prime number whose magnitude is at most the number of variables. So you can write that prime number in unary. And finding the prime and testing
2648	primality, testing whether the number is prime, is something that you can do even with a brute-force algorithm, and it would be good enough. You don't have to do anything fancy about testing primality in this case. So why does it have to be prime? You need it to prime in order for it to be a field. So this is just the algebra part. If you did not have a prime number, then some of the field properties don't work. And you may no longer get the fact that the polynomial has a small number of roots. So that's all I can say about that. Is the polynomial like a hash function for the branching program? Are they equal if they are the same, but sometimes the value is also equal if the programs are different? That's an interesting idea. Is the polynomial acting like a hash function? I think there is something to what you're saying, but I think it's actually in the other direction. It's related to a hash function, but it's actually acting more like an
2649	error-correcting code. Let's save that for later. It's a very good point. It's a very good question. Maybe we can talk about it after if you remind me. OK, let's end this poll here. Should C be-- if having these two agree implies-- well, I mean, the question is, should we change p1 and p2 always agree to b1 and b2 always agree? Well, b1 and b2 are behaving exactly the way p1 and p2 behave, so I'm not sure it really matters. Too much time on this chat, on this poll here. Let's end this poll-- oh, sharing results. Yeah, so the correct answer is B, that agreeing on all Boolean inputs implies that they are equal. The other two follow immediately. They're still true. But if it's not read once, even though they agree on all the Boolean inputs, they won't necessarily agree as polynomials. For one thing, if you just take the two polynomials x1 squared and x1, they agree on all the Boolean inputs, but they're not the same. They agree in the Boolean world, because
2650	0 squared is 0, and 1 squared is 1. But they're not the same polynomial. Let's move on. Actually, I have another check-in on the same slide here. And this is actually answering a question that I got in the chat. If p1 and p2 were-- how big are these polynomials? These look like they could be big. If they're exponentially large, would that be a problem for the time complexity? So pick A or B here. We're running out of time here. So why don't I not say too much and just let you go with it. I'm going to close this down. All in? Well, oh, my god, by one point. This is like Georgia here-- do a recount. In fact, B is correct by a hair. They are not polynomial in size. The truth tables can be very large. As we did with the branching program for the exclusive or case, you don't actually write down the polynomials to evaluate them. You can evaluate them as you're going along. The polynomials are huge. But you don't have
2651	to write down the polynomials to evaluate them. That's only part of the proof. The algorithm doesn't have to deal with the polynomials itself, so maybe good to think about this. And somebody says, did I invent this proof? No, I did not invent this proof. It's a wonderful proof, but it's not mine. I would love to have been-- get to take the credit for it. So why don't we wrap this up? Is there some way to simplify the polynomials as we're going along so that we don't end up with them being too big and so that we can then just look at the polynomials? Not that I know of. I think the polynomials are really going to be big. And so there's not going to be any way to view it just as-- if you could, it would be fantastic, because that would give you a deterministic algorithm. I think the only way that people know how to do this in terms of random inputs to a polynomial, which is too big to write down. If
2652	you could write it down and just analyze the polynomials, you'd have a huge, huge result there. Oh, I'm glad people like this proof. That's good. How many actual quantities are there in the formula? I'm not sure what that means. What formula? I mean, the polynomial is huge. The number of different polynomials-- well, I guess I don't understand the question. What motivates the idea of arithmetization? What would make somebody think of this? I'm not sure, actually. But we're going to use it even in a more remarkable way in the last two lectures of the course, so stay tuned. I mean, this is sort of clever, but seems very specialized. But the next part, where we go to the next application, we're going to use this to analyze satisfiability, which is a much more general kind of a situation. And that, I think, is especially remarkable. For the polynomials p1 and p2, it's only a polynomial number-- I don't think so, because-- well, it depends on the size of the field. The size of-- no, it's going
2653	to be something like m to the mth power, right? So those are the number of possible inputs. Each field element has 3m possibilities, roughly. And there are m field elements, so it's m to the 3m different possible inputs that you're picking at random. So anyway, I'm going to shut this down and move over to the office hours Zoom. Feel free to join me there. Otherwise, I will see you all on Thursday. Take care.
2654	[SQUEAKING] [RUSTLING] [CLICKING] MICHAEL SIPSER: OK, folks. Here we are again. Welcome back for another episode of theory of computation. This is lecture number 3. I'm going to review what we've been doing. We've been looking at finite automata and regular languages. Those are the languages that finite automata can recognize. And we talked about nondeterminism. So we had non-deterministic finite automata and deterministic finite automata. We showed that they're equivalent. We looked at the closure properties over the regular operations union, concatenation, and star, and showed that the regular language is really-- the class of regular languages is closed under those regular operations. And we used the constructions that we developed in the proof of those closure properties to show that the-- we can give a way to convert regular expressions to finite automata. So that is-- was partway toward our goal of showing that these regular expressions and finite automata are equivalent with respect to the class of languages they describe, namely, the regular languages. So regular expressions of finite automata are interchangeable from the perspective of what
2655	kinds of languages you can do with them. So we're going to finish that off today. So let's take a look at what our next topics we're going to be covering. We're going to reverse the construction we gave last time which allowed us to convert regular expressions to finite automata. Now we're going to go backwards. We're going to show how to convert finite automata back to regular expressions. And that-- those two constructions together show us that the regular expressions and finite automata can be interconverted from one another, and they're therefore equivalent with respect to the kinds of things they can do in language recognition or generation. Then, we're going to prove that-- we're going to look at how you prove certain languages are not regular, they're beyond the capabilities of finite automata. And finally, at the end, we're going to introduce a new model of computation which is more powerful than the finite automata and regular expressions, namely, the context-free grammars. Those can do other kinds of languages that the simpler finite automata regular expressions models
2656	can't do. And I would also just like to note that a lot of what we're doing is a warm-up toward the more powerful models of computation that we're going to be looking at later-- well, in a week or so-- which are more general purpose computation. But along the way, introducing these models of finite automata in context-free languages is interesting and helpful because many of those-- a number-- those models turn out to be useful in a number of applications, whether it's from linguistics to programming languages. And a variety of different parts of computer science and other fields as well use those notions. So they're useful notions beyond just in this course. So I just want to-- a couple of administrative things to touch on. We are going to have additional check-ins today, as I mentioned to you. We're going to start counting participation-- not correctness, just participation-- in the live check-ins.
2657	As I mentioned, we're going to be showing how to convert finite automata to regular expressions. And that's going to complete our equivalence of finite automata and regular expressions. So just to recap what we did last time, we showed that if you have a regular expression and it describes some language, then that language is regular. So in other words, we have a way of-- we gave a way of converting regular expressions to finite automata, as kind of shown in this diagram. That's what we did last time. Now we're going to go the other way. We're going to show how to convert-- oh, and just a reminder in case you're just getting yourself-- your memory to work, maybe it'll help you just to remember that we actually did an example of that conversion. We looked at this regular expression, a union ab star. And we actually worked through the process of converting that. Oops. I need to make myself smaller so you can see all that. We went through the process of converting a union ab star
2658	as an example of that-- of-- made a mis-- [LAUGHS] OK. Well, we went through the process of actually doing that conversion. And now we're going to show how to do it the other way around. So we're going to invert that and go backwards the other way. So today's theorem is to show that if a is regular, namely, it's the language of some finite automaton, then you can convert it to a regular expression which will describe that same language. So basically, we're going to give a conversion from finite automata to regular expressions. But before we do that, we're going to have to introduce a new concept. So we're not going to be able to dive right into that conversion. We're going to have to do-- introduce a new model first, which is going to facilitate that conversion. And that new model is called--
2659	a Generalized Nondeterministic Finite Automaton, or a Generalized NFA, or just simply a GNFA. So this is yet another variant of the finite automaton model. And conceptually, it's very simple. It's similar to the NFAs. I'll give you-- here's a picture of a GNFA named G, G1. Very similar to the NFAs. But if you look at it for a second, you'll see that the transitions have more complicated labels. For the NFAs, we're only allowing just single symbols, or the empty string, to appear on the labels. Now I'm actually allowing you to put full regular expressions on the labels for the automaton. Now, we have to understand how a GNFA processes its input. And the way it works is not complicated to understand. When you're getting an input string feeding-- when a GNFA is processing an input string, it starts at the start state, just like you would imagine. But now, to go along a transition, instead of reading just a single symbol, or the empty string, as in the case for the nondeterministic machine, it actually gets
2660	to read a whole string at one step, kind of, at one bite. It can read an entire string and go along that transition arrow, provided that chunk of the input that it read is in the regular expression that that transition has as its label. So for example, this-- you can go from q1 to q2 in one step in this GNFA by reading a, a, b, b off the input. So it reads all of those four symbols all at once. It just swoops them up and then moves from q1 to q2 in one step. And then, when it's in q2 it can read aab and move to q3. And q3 happens, there's nowhere to go. So this is going to be a nondeterministic machine. There might be several different ways of processing the input. And if any one of them gets to an accepting state at the end of the input, we say the GNFA accepts. So it's similar to nondeterministic-- to NFAs in the way the acceptance criterion works. So you could do an example.
2661	But hopefully the concept of how this works is reasonably-- you can at least buy it, that it processes the input in chunks at a time. And those chunks have to be described by the regular expressions on the transition arrows, as it moves along those transitions. So what we're going to do now is to convert not DFAs to regular expressions, we're going to convert GNFAs to regular expression. That's even harder, because GNFAs are-- allow you to do all sorts of other things besides just ordinary DFAs. So that's a harder job. Why am I making my life harder? Well, you'll see in a minute that it's going to actually turn out to be helpful to be working with a more powerful model in the way this construction is going to work. Now, before I dive in and do the construction from GNFAs to regular expressions, I'm going to make a simplifying assumption about the GNFAs. I'm going to put them in a special form that's going to make it easier to do the conversion. And that simpler
2662	form is, first of all, I'm going to assume the GNFA has just a single accepting state. And that accepting state is not allowed to be the start state. So it has to have just a single accepting state. I've already violated that convenient assumption in this GNFA, because I have here two accepting states. That's not what I want. I want to have just one. Well, the thing is, it's easy to obtain just one, just to modify the machine so that I have just one by adding a new accepting state which is branched to from the former accepting states by empty transitions. So I can always jump from q2 to q4 at any time without even reading any input, just going along this empty transition. And then I declassify the former accepting states as accepting. And now I have here just a single accepting state. And because it's going to be a new state that I added, it won't be the start state. And I have accomplished that one aspect of my assumption about the form of
2663	the GNFA. But there's another thing that I want to do, too. I want to assume-- as you will see, which is going to be convenient in my construction-- that we will have transition arrows going from every state to every other state. In fact, I want transition arrows going from every state even back to themselves. I want there to be-- all possible transition arrows should be present, with two exceptions. For the start state, there should be only transition arrows exiting the start state. And for the accepting state-- there's just one now-- there should be only transition arrows coming into the start state. So it's kind of what you would imagine as being reasonable. For the other states, which are not accepting or starting, there should be transition arrows leaving and coming from everywhere else. But for the start states, just leaving. And from the accept state, just coming in. And you could easily modify the machine to achieve that. Let's just see how to do that in one example. So from-- notice that from q3 to
2664	q2 there is no transition right now. And that's not good. That's not what I want. I want there to be a transition from q3 to q2. Well, I'll just add that transition in. But I'm going to label it with the empty language regular expression. So that means, yeah, the transition is there, but you never can take it. So it doesn't change the language that the machine is going to be recognizing. But it fulfills my assumption, my convenient assumption, that we have all of these transition arrows being present in the machine. So anyway, I hope you will buy it. It's not going to be-- if you don't quite get this, don't worry. It's not totally critical that you're following all these little adjustments and modifications to the GNFA. But it will be helpful to understand what GNFAs themselves-- how they work. So as I mentioned, we can easily modify
2665	So now we're going to jump in and start doing the conversion. So we're going to have a lemma, which is like a theorem that really is just of local interest here. It's not a general interest theorem. It's going to be relevant just to GNFA, which are really just defined to help us do this conversion. They really don't have any other independent value. So every-- you want to show that every GNFA has an equivalent regular expression R. That's really my goal. And the way we're going to prove that is by induction. It's going to be by induction on the number of states of the GNFA. Now, you really should be familiar with induction as one of the expectations for being in this course. But in case you're a little shaky on it, don't worry. I'm going to unpack it as a procedure. It's really just recursion. You know, induction is just-- a proof that uses induction is really just a proof that calls itself. It's just a proof that-- it's a recursive proof. That's all it
2666	is. So if you're comfortable with recursion, you'll be comfortable with induction. But anyway, I'm going to describe this as a procedure. So if you're a little shaky on induction, don't worry. So the basis is-- so first I'm going to handle the case where the GNFA has just two states. Now, remember, I'm assuming now my GNFAs are in the special form. So you can't even have a GNFA with one state, because it has to have a start state and it has to have an accept state, and they have to not be the same. So the smallest possible GNFA to worry about is a two-state GNFA. Now, if we have a-- if we happen to have a two-state GNFA, it turns out to be very easy to find the equivalent regular expression. Why? Because that two-state GNFA can only look like this. It can have a start state, it can have an accept state, and it can only have a transition going from the start to the accept because no other transitions are allowed. It only has
2667	outgoing from the start, only incoming from the-- to the accept. And so there's only one transition. And it has a label with a regular expression R. So what do you think the equivalent regular expression is for this GNFA? It's just simply the one that's labeling that transition, because that tells us when I can go from the start to the accept. And there's nothing else the machine can do. It just makes one step, which is to accept its input if it's described by that regular expression. So therefore, the equivalent regular expression that we're looking for is simply the label on that single transition. So two-stage GNFAs are easy. But what if-- what happens if you have more states? Then you're going to actually have to do some work. So we call that the induction step. That's when we have more than two states. And what that-- the way the induction works is we're going to assume we already know how to do it for k minus 1 states. And we're going to use that knowledge to
2668	show how to do it for k states. So in other words, we already know how to do it for two states. I'm going to use that fact to show how to do it for three states, and then use the fact that I can do it for three states to show how to do it for four states, and so on, and so on. And the idea for how to do that is actually pretty easy to grasp. What we're going to do is, if we have a k state GNFA that we want to convert, we're going to change that k state GNFA to a k minus 1 state GNFA and then use our assumption that we already know how to do the k minus 1 state GNFA. So in terms of a picture, I'm going to take a k state-- to prove that I can always convert k state GNFAs to regular expressions, I'm going to show how to convert the k state one into an equivalent k minus 1 state GNFA. And then, if you just
2669	like to think of this procedurally, the k minus 1 gets converted to a k minus 2, gets converted to a k minus 3, and so on, and so on, until I get down to two, which then I know how to do directly. So the whole name of the game here is figuring out how to convert a GNFA that has k states into another one that has one fewer state that does the same language. So you have to hold that in your head. I mean, I wish I had more blackboard space here, but it's very limited here. So you have to remember what we're going to be doing on the next slide, because that's going to finish the job for us. As long as I can show in general how to convert a K, state GNFA to a GNFA that has one fewer state but it still does the same language, I'm good, because then I can keep iterating
2670	So here is-- this is the guts of the argument. So I have my k state machine. Here's my start state. Here's my accept state. Here's my k minus 1 state, that machine that I'm going to be building for you. It's actually going to be-- look almost exactly the same. I'm just going to remove one state from the bigger machine. So I'm going to pick any state which is not the start state or the accept state. Here it is pictured here. I mean, all of the states of the k state machine are going to appear in the k minus 1 state machine except for one state that I'm going to rip out. That's the state x. It's now here as a ghost. It's been removed. It's not there anymore. But I'm just helping you to remember that it used to be there by showing this shadow. But it's a-- I have taken my original machine that had k states and basically just ripped out a state. And now I have one fewer state. So the good
2671	news is that I now have a machine with k minus 1 states. That's what I want. But the bad news is that it doesn't do the same language anymore. I broke the machine by rip-- if you're just going to rip out a state, who knows what the new machine is going to do. It's going to be probably not the same as what the original machine did. So what I need to do, then, is repair the damage. I've got to fix the damage that I caused by removing x. And whatever role x was playing in the original machine, I've got to make sure that the new machine that I have, which doesn't have x anymore, can still do the same things that the original machine did. And so the way I'm going to do that is look at all of the paths that could go through x and make sure that they are still present even though I don't have x anymore. And the way I'm going to do that is, I'm going to take-- consider
2672	a part of a path that might use x. So it starts-- let's pick two states, qi and qj, in the machine that had k states. Let me just see here-- I don't know if this-- OK. We have-- if we have-- we'll pick two states, qi and qj, in the original machine. Now, qi might have the possibility of going to state x. And then x might have a self loop. And then it might go to qj. The new machine doesn't have an x anymore. The way I'm going to fix that is by replacing the label that goes directly from i to j with a new label that adds in all of the things I lost when I removed x. That's the whole idea here. So here is qi to qj, but there's no x anymore. How could I get from qi to qj? What were the inputs that could have brought us from qi to qj via x? Well, they would have been an input that read a string described by r1. I might have self-looked
2673	at x a few times, so I might have read several strings that are described by r2. And then I would have read a string that was described by r3. And now I'm at qj. So the new label that I'm going to place over here is going to be the strings that I get from reading r1-- reading a string that's described by r1, then multiple copies of strings-- multiple strings that are possibly describing r2, which is the same as r2 star. Oh, and then multiples-- and then a string that could be described by r3. So that is a new addition to the transition that takes me from qi to qj. Of course, I need to include the things that would have taken me from qi to qj in the first place. So I'm also unioning in r4, which is the direct route from qi to qj that did not transit through x. So by making that new regular expression on the qi to qj transition, I have compensated for the loss of x for paths that
2674	go from qi to x and then out to qj. Now, what I need to do is to do that same thing for every pair qi and qj that are in the original machine. And so if I do that for every possible pair, I'll be modifying all of the transitions in the new machine in a way that compensates for the loss of x. And now the new machine has been repaired from the damage that I caused by removing x. And it does the same language. It's the kind of thing you need to think a little bit about. I understand. But at least hopefully, the spirit of what I just described to you comes through, that we're going to convert this k-- machine with k states to one with k minus 1 states by removing a state and repairing the damage. And now it does the same language. And then I can remove another state and do the same thing over and over again until I get down to two states. So that's the idea. And that
2675	really completes the proof. That shows that I can convert every GNFA to a regular expression. And that really is the end of the story for this. And thus I claim that DFAs, now, and regular expressions are equivalent. So let me-- going to give you a little check-in here on this, really just to see, high-level, if you're following what's going on. So just take a look. So we just showed how to convert GNFAs to regular expression. But we really wanted to convert DFAs to regular expressions. So how do we go from GNFA-- converting GNFAs to converting DFAs? Because they're not the same, obviously. Right? So how do we finish that? So there are three choices here. First, we have to show how to convert DFAs to GNFAs, maybe? Or show how to convert GNFAs to DFAs? Or maybe we're already done? So maybe I better launch that poll while you're reading that. And there you go. Hopefully you can-- all right. Why don't I end this? It's a little worrisome, because I would say we have
2676	a plurality who got the right answer, but not a majority. So let us share the results. I think-- so I sense not all of you are with me. But you're going to have to-- either that or you're playing-- you're reading your email while we're talking. I'm not sure. But whatever it is, you need to think a little bit about what's going on here, because the reason why we are done is because DFAs are a kind of GNFAs. They're just-- they have a very simple kind of regular expression on each transition. They just have the regular expression which is just a single symbol. So all DFAs are automatically GNFAs. So if I can convert GNFAs, I can certainly convert DFAs, because GNFAs include the DFAs. I'm done. It really was-- number C was the correct answer. So good thing we're not [LAUGHS] counting correctness here. So participation is good enough. But I do think you need to think about what's going on and making sure that you're following along. So anyway, that's a-- we'll carry on
2677	here. But it makes me a little concerned.
2678	So we're going to talk a little bit about non-regular languages. So somebody's asking, don't we have to still make the DFAs into the special type? Yes, we do have to make them to the special type. But we already showed how to make GNFAs into the special type. And DFA-- that is going to apply to DFAs as well. They'll become GNFAs. You can add the extra starts-- add a new start state, add a new accept state, add in all the transitions with-- which you didn't have before with the empty language label, and you'll have a GNFA from a DFA. But that applies to GNFAs as-- in general. So it's nothing special about DFAs there. Anyway, I think you need to chew on that. And hopefully you're-- you'll be following going forward. Anyway, let us look now at non-- proving non-regularity. So we're finished with our goal of showing that regular languages-- that the regular languages can either come from DFAs or from regular expressions. Those are the same in terms of-- from the perspective of our
2679	course, they're interchangeable. So now, as we mentioned, there are going to be some languages which are not regular, which can't be done by DFAs. They're actually-- DFAs are actually pretty weak as a computational model. And so there's all sorts of very simple things that they cannot do-- though there are some fairly complicated things that they can do, surprisingly enough. But anyway, there are some simple things they can't do. And so we have to develop a method for showing that a language is not regular. And that's going to be useful for your homework and in general for just understanding the power of DFAs. So how do we show a language is not regular? So remember, if you want to show a language is regular, basically what you need to do is give a DFA. Or you can use the closure properties. That's another way of showing a language is regular. But underneath that, it's basically constructing DFAs. To show a language is not regular you have to give a proof. Generally it's not a construction, it's
2680	a proof that there is no DFA or that whatever--
2681	And we have to develop a method. What is that proof method? Now, there is a tempting-- you know, I've taught this course many times, and there's a tempting approach that many people have. It's not only going to apply for finite automata, but for other things too. And believe me, it's not only people in this class, it's for people out there in the-- who are trying to think about computation in general-- which is to say, well, I have some language. I'm trying to figure out if it's regular or not. And so I thought really hard how to make a DFA, and I couldn't find one. Therefore, it's not regular. That's not a proof. Just because you couldn't find a DFA doesn't mean there is no DFA. You need to prove that the language is not regular using some method. So I'm going to give you an example where that kind of approach can lead you wrong. And that is-- I'll give two examples of languages where you might try to prove they're regular or not, and
2682	you could be in trouble if you just follow that kind of informal approach. So if you take the language B, where these are strings-- well, let's assume our alphabet is zeros and ones. B is the language of all strings that have an equal number of zeros and ones. So you want to know, if I have 1,000 zeros, I need to have 1,000 ones. So basically, the way you test that, you'd have to count up the number of zeros, count up the number of ones, and see if those two counts are the same. And that's going to be really tough to make a DFA do, because how are you going to remember such-- that really big number of zeros that-- the DFA might have 50 states. But you might need to count up to 100 or a million to figure out-- to count up how many zeros you've seen. And it seems really hard to be able to do that kind of a count when you only have 50 states. So whatever number of states you
2683	have, it seems hard to count when you have a finite automaton. So the intuition is, it's not regular because a finite automaton can't count. Which, in this case, you can convert that intuition into a real proof. I would say it's not a real proof yet, but it can be made into a real proof. But compare that case with another language, which I'll call C, which, instead of looking at its input to see whether it has an equal number of zeros and ones, I'm going to look at the input and look at the substrings of 01s and 10s-- those two substrings-- and count the number of occurrences of 01 as a substring and the number of occurrences of 10 as a substring. Just to make sure you're understanding, let's look at some example-- two examples. So the string 0101 is not going to be in C, because if you count up the number of 01s and the number of 10s, not the same. So I'm even going to help you here, if you can see that.
2684	The number of 01s is two. But there's only a single occurrence of 10. So those are-- those two counts are different. And so that's why this input string is not in C. Compare that with the string 0110. Now, if you count up the number of 01 and 10 substrings, you're going to get the same value, because here we have a single 01 and a single 10. And so now the two counts of those number of substrings are the same. And so that's where you're in C. Now my question is, is C a regular language? Well, it looks like it shouldn't be regular for the same reason that B isn't regular-- because you have to count up two quantities and compare them. OK? So now, so if we-- so that's our intuition, that you just can't do it for the-- with a finite automaton, because you have to do the same kind of counting that you would have had to do for language B. But here you'll be-- you would be wrong, because C, in fact,
2685	is regular. It has a much simpler description than the one I gave over here at the beginning. The very same language, C, can be described in a much, much simpler way. I'm not going to tell you what it is. You can mull that over. You can try some examples to figure it out. But it has a much simpler description. It's not a totally trivial description. There is some content there. But there is-- it is the kind of thing that a finite automaton can do. It wouldn't do the counting this way. So the moral is-- the punch line is that sometimes the intuition works, but it can also be wrong. And so the moral of the story is, you need to give a proof when you're doing things like that. So what we're going to do next, in the second half of the lecture, is to give a method for proving languages are not regular. And again, you're going to need to use that on your homework. So I hope you get it. But first of
2686	all-- did I-- never stopped sharing that poll. Forgive me.
2687	our little requested break. And-- for five minutes. And we'll be back in five minutes. So, break time.
2688	And proving languages not regular. The way we're going to prove languages are not regular is by introducing a method called the pumping lemma. And the overarching plan at the pumping lemma, without getting into the specifics of it, is to say-- show that-- that lemma says all regular languages have a certain property, which we will describe. And so to show a language is not regular you simply show the language doesn't have that property, because all regular languages have to have that property. And so by showing a language fails to have the property, it could not be regular. That's the plan. Now, the property itself is a little complicated to describe, but not too bad. I'll try to unpack it for you. But first, let's look at the statement of the lemma, which says that whenever you have a regular language-- let's call it A. So for every regular language A there's always a special value called the pump-- a number. p, we'll call it-- called the pumping length. It's a special number. And it's-- and that
2689	length tells you that whenever a string is in that language and it's longer than that length, then something special happens. You can take that string and you can modify it, and you still stay in the language. So anything that's longer than that special length can be modified in a certain way, and you still stay in the language. So let's look at the actual statement of the lemma. So there is a number p such that if s is a string in the language and it's longer than p, or at least of length p, then you can take s and you can cut it up into three pieces-- x, y, and z-- so that's just breaking s into three pieces-- where you can take that middle piece, repeat it as many times as you like, and you still stay in the language. That's the-- what the pumping lemma is saying. And there's a bunch of other conditions here too. But the spirit of the pumping lemma says, whenever you have a regular language there's some cutoff such
2690	"that all strings longer than that cutoff can be what we call pumped. You can take that string, you can find a section somewhere in the middle of that string or somewhere-- you cut it up in three pieces, you take that center piece, and you can repeat it. You can pump it up. And by repeating that string and repeating that piece, the string gets longer and longer. But you still stay in the language. That's the special property that all regular languages have. So in an informal way-- and we'll do-- I'll try to help you get the feeling for this. Informally, it says that if you have a regular language, then every long string-- so a long is by-- informal way of saying bigger than this value p. Every long string in the language can be pumped. And this result still stays in the language. And by ""pumped"" means I can cut the string into three pieces and repeat that middle piece as many times as I want. That's what I mean by pumping a string."
2691	But first we're going to see how to prove this. And hopefully, that'll give you some feeling, also, for why it's true. So-- and actually, maybe before I actually jump into the proof, let me-- let's look at these three conditions here just to understand it a little bit more thoroughly. So condition one kind of says what I just was telling you. I can break s into three pieces-- x, y, z-- such that if I take x y to the i z-- so that's repeating y as many times as I want. So here's y to the i defined, if that's helpful to you-- it's just y-- i copies of y. So I can take x y to the i z, and I remain in the language for every value of i-- even i equals 0, which means we're just removing y, which is sometimes actually a useful thing to do. But let's not get ahead of ourselves. So if-- you know, I can cut s-- I'm guaranteed to be able to cut s up into x, y,
2692	z so that the string xyyy is still in the language, or xyyyyy-- it's still in the language. That's going to be guaranteed for every regular language. That's a feature that's going to be true. And furthermore-- and this is going to be turning out to be-- it's not really part of the core idea of the pumping lemma, but it actually turns out to be very helpful in applying the pumping lemma. You can always cut it up in such a way that the first two pieces are not longer than that value p. So this-- it restricts on the ways you can cut the thing up. And that actually turns out to be very helpful. But let's first just look at the proof of this, giving a little bit the high-level picture.
2693	So my job is to show, if I have a string in my language-- let's say it's a-- think of it as a long string, really long. So its length is more than p. But I think intuitively, it's just a very long string. And I'm going to feed that string into the machine and watch what happens. Something special happens when I feed the string and I look at how the machine proceeds on that string, because s is so long that as I wander around inside the machine I have to end up coming back to the same place more than once. It's like if you have a small park and you go for a long walk. You're going to end up coming back to where you've-- what you've already seen. You just can't keep on seeing new stuff when you have a more small area of space to explore. So we're guaranteed that M is going to end up repeating some state when it's reading s because s is so long. So in terms-- pictorially, if you
2694	imagine here this wiggly line is describing the path that M follows when it's reading s, it ends up coming back to that state qj more than once. So it comes back here, cycles around, comes back again before it ends up accepting. We know it ends up accepting because we're assuming we have a string that's in the language. So we picked s in the language. So it has to be accepted by M. But the important thing is that it repeats a state. Now, how does that tell me I can cut s up into those three pieces? Well, I'm going to get those three pieces here. First of all, let's observe that here is processing-- as processing s. Here is the-- written right on top of the string, that state repetition occurring, qj, more than once. And now, if I look inside the machine, the part of s that took me to qj I'm going to call x. The part that took me from qj back to itself I'm going to call y. And the part that
2695	took qj to the accept state I'm going to call z. And I'm going to mark those off in s. And that gives me the way to cut s up into three pieces. Now, if you're appreciating what's going on inside the machine, you will see why M will also accept the string xyyz-- because every time-- once you're at qj, if you go around once, you come back to qj. And then if you go again, you'll come back to qj. And as many times as you keep seeing that y, you're just going to keep coming back to qj. So it doesn't matter how many y's you have. You're going to still-- if you follow it by z, which is what you will do-- you'll end up accepting this string. And that's really the proof. I mean, you have to do a little bit more here just to understand-- I should have mentioned why I want to forbid y being the empty string, because if y's the empty string it's not interesting. It doesn't change-- repeating it doesn't
2696	actually change anything. So I have to make sure it's not empty. But anyway, that's a detail here. If you look at the string xyyz, that's still going to be accepted. So that's the proof of the pumping lemma. So let's have a little check-in related to that. This is not going to be-- again, not super hard. But more just a curiosity.
2697	So the pumping lemma depends on the fact that if M has p states and it runs for more than p steps, then it's going to enter some state twice. So you may have seen that before. It actually has a name which some of you may have seen. So let's see how to just get a poll here. And I hope not too many of you are going to pick C, as it's-- some of you are. [LAUGHS] Oh well. Yes, I think this one most of you are-- you've seen this before. This is-- I think you pretty much all got it. This is what's known as the Pigeonhole Principle. So here, sharing the results, obviously I was having a little fun with this. I'm sure some of you were having fun back at me. That's OK.
2698	Let's see how to use the pumping lemma to prove a language is not regular. So I put the pumping lemma up here just so you can remember the statement of it. So let's take the language D, which is the language 0 to the k 1 to the k for any k. So that's some number of zeros followed by an equal number of ones. We're going to prove that language is not regular by using the pumping lemma. And this is going to be just an ironclad proof. It's not going to say, well, I couldn't think of how to-- I couldn't think of how to find it a finite automaton. This is going to be-- this is going to really be a proof. So we want to show that D is not regular. And we're going to give-- these things always go as a proof by contradiction. So proof by contradiction-- hopefully as a reminder to you, the way that works is you're going to assume the opposite of what you're trying to prove. And then from
2699	that, something crazy is going to happen, something you know is obviously false or wrong. And so therefore your assumption, which is the opposite of what you were trying to prove, had to be wrong. And so therefore, the thing you're trying to prove has to be right. That's the essence of what's called proof by contradiction. So first of all, we're going to assume, to get our contradiction, that D is regular, which is what we're trying to show is not the case. Now, if D is regular, then we can apply the pumping lemma up above here, which gives us that pumping length p, which says that any string longer than p can be pumped and you stay in the language. That's what the pumping lemma tells you. So let's pick the string s, which is the string 0 to the p 1 to the p. Here's sort of a picture of s off on the side here. So a bunch of zeros followed by an equal number of ones. And that string is in D because D
2700	is strings of that form. And it's longer than p. Obviously, it's of length 2p. So the pumping lemma tells us there's a way to cut it up satisfying those three conditions. So how in the world could we possibly cut s up? Well, remember the three conditions. And especially condition 3 is going to come in handy here. Say that you can cut s up into three pieces-- x, y, and z-- where the first two pieces lie in the first p symbols of s at most p long. So x and y together are not very big. They don't extend beyond the first half of x-- first half of s. And in particular, they're all zeros. x and y are going to be all zeros. z is going to perhaps have some zeros and will have the rest of the ones-- will have the ones. Now, the pumping lemma says that if you cut it up that way, you can repeat y as many times as you like and you stay in the language. But that's obviously false,
2701	because if you repeat y-- which now has only zeros-- you're going to have too many zeros. And so the resulting string is no longer going to be of the form 0 to the k 1 to the k. It's going to be lots of zeros followed by not so many ones. That's not in the language. And that violates what the pumping lemma tells you is supposed to happen. And that's a contradiction. So therefore, our assumption that D is regular is false. And so we conclude that D is not regular. So that's a fairly simple one. I thought I would do another couple of examples, because you have this on your homework and I thought it might be helpful. So here's the second one-- slightly harder, but not too much. Let's take the language F, which is-- looks like the string's ww. These are strings that-- two copies of the same string. For any string that might be in sigma star, so for any string at all, I'm going to have two copies of that string. And
2702	so F is those strings which can be-- which are just two copies of the same string. We're going to show that F is not regular. These things always go the same way. It's the same pattern. You prove by contradiction. So you assume for contradiction that-- oh, D. That's bad. That was copied from my other slide. That's wrong. Let's see if I can actually make this work here. Good. Assume for contradiction that F is regular. The pumping lemma gives F as above. And so now we need to choose a string s that's in F to do the pumping and show that the pumping lemma is going to fail. You're going to pump and you're going to get something which is not in the language, which is-- shows that the pump-- something has gone wrong. But which s to choose? And sometimes that's where the creativity in applying the pumping lemma comes in, because you have to figure out which is the right string you're going to pump on. So you might try the string-- well, 0
2703	to the p 0 to the p. That's certainly in F. It's two copies of the same string. Here it is. I've written lots of zeros followed by the same number of zeros. The problem is, if you use that string, it actually is a string that you can pump. You can break that string up into three pieces. And then, if you let y be the string 00-- actually, you have to be a little careful. The string just 0 doesn't work, because there's an evenness-oddness phenomenon going here. So you might want to just think about that. But if you let y be the string 00, then if you have the string xy-- x any number of y's-- it's still just going to be a bunch of zeros. And you're going to be able to see that that string is still in the language. So you haven't learned anything. If the pumping lemma works and you're satisfying the pumping lemma, you haven't learned anything. So what you need to find is some other string. That was a bad
2704	choice for s. Find a different string. So here's a different choice, 0 to the p 1 0 to the p 1. So that's two copies of the same string. And you're going to show it can't be-- we're going to show it can't be pumped. So here's a picture of that string here. So zeros followed by 1, zeros followed by 1. And now it's a very similar to the first argument. If you cut it into three pieces in such a way that it satisfies the conditions, the first two pieces are going to be residing only among the zeros. And so therefore, when you repeat a y you're no longer going to have two copies of the same string. And so it won't be in the language. So therefore, you've got a contradiction and F is not regular. So you have to play with the pumping lemma a little bit. If you haven't seen that before it's going to be-- it takes a little getting used to. But you have a few homework questions that need to
2705	be solved using the pumping lemma. So now, let's look at-- lastly, there is another method that can come in, which is combining closure properties with the pumping lemma. So closure properties sometimes help you. So let's look at the language B, which is actually, we saw earlier in the lecture, where we have an equal number of zeros and ones. Now, we could prove that directly, using the pumping lemma, as not being regular. But it's actually even easier. What we're going to prove-- that-- we're going to prove that it's not regular in a different way. First we're going to assume for contradiction, as we often do, that it is regular. And now we're going to use something-- we're going to use some other knowledge. We're not going to use the pumping lemma here because we're going to take advantage of an earlier case where we used the pumping lemma. And so now we know that the string-- the language 0 star 1 star is a regular language, because it's described by a regular expression. If you take
2706	the B, which is the equal numbers of zeros and ones, and you intersect it with 0 star 1 star, that's going to be a regular language if B was regular, using closure under intersection. But this language B intersect 0 star 1 star is the language of equal numbers of zeros and ones where the zeros come first. And that's the language D that we showed two slides back, that we already know can't be regular. So that intersection cannot be regular. And so it violates the closure property. And again, we get a contradiction. So that's a different way of sometimes making a shortcut to prove a language is not regular. So we have-- in our last 10 minutes or so, we're going to shift gears totally, in an entirely different way, and consider a new model of computation which is more powerful, that can actually do things that we can't do with finite automata. And these are called context-free grammars. So this is really just an introduction. We're going to spend all of next lecture looking at
2707	context-free grammars and their associated languages. But let's just do-- get a preview. So a context-free grammar looks like this. You have a bunch of these-- what we call substitution rules, or rules, sometimes, which just look like a symbol, arrow, a string of symbols. That's what a context-free grammar looks like at a high level. Let's define some terms. So a rule, as I just described, is going to be-- look-- it's going to be a symbol, which we're going to call a variable. And that's going to have an arrow to a string of other-- possibly, other variables and symbols called terminals. So a variable is a symbol that appears on the left-hand side of a rule. Anything that appears on the left-hand side is going to be considered to be a variable. So S and R are both variables. Now, other symbols that appear in the grammar which don't appear in the left-hand side-- those are going to be called terminals. So here, 0 and 1 are terminals. Now, you may think that empty string should also
2708	be a terminal . But that's not a symbol. Empty string is a string. It's just a string of length 0. So I'm not considering empty string to be a terminal. So-- and then there's going to be a special variable which is going to be considered the starting variable, just like we had a starting state. And that's typically going to be written as the top-left symbol. So this symbol s, here, is going to be the starting symbol. And grammars can be used to define languages and to-- well, to generate strings and to define languages. So first of all, let's see how a grammar, using this as an illustration, can generate strings. Actually, just to emphasize this terminology here, in this particular example we had three rules. The two variables were R and S. The two terminals were 0 and 1. And the start variable was this top left-hand symbol, as I mentioned-- the S. So grammars generate strings. The way they do is you follow a certain procedure, which is really pretty simple. You write down,
2709	first of all, the start variable. And I'll do an example in a second. You write down the start variable. And then you take a look what you've written down. And if it has any variables in it, you can apply one of the corresponding right-hand sides of a rule as a substitution for that variable. And so-- like, for example, if you have an S in the thing you've written down, you can substitute for that S a 0S1. Or you could substitute for that S an R. Or if you have an R, you can substitute for the S an empty string. So you're just going to keep on doing that substitutions over and over again until there are no variables left, so there's nothing left to substitute. Only terminals remain. At that point, you have generated a string in the language. So the language, then, is the collection of all generated strings. Let's do an example. Here's an example of G1 generating some string. So as I mentioned, first of all, you're going to write down the
2710	start variable. And I'm just going to illustrate this in two parallel tracks here. On the left side I'm going to show you the tree of substitutions. And on the right side I'm going to show you the resulting string that you get by applying those substitutions. So over here I'm going to substitute for S the string 0S1. So on the right-hand side I just have 0S1, because that's what I substituted for S. But you'll see it's not going to-- it's going to look a little different in a second. Here, I'm going to-- again I still have a variable. So I'm going to substitute for S 0S1. Now I have the string-- resulting string 00S11, because I've substituted 0S1 for the previous S, but the 0 and 1 stick around from before. They don't go anywhere. So I have, at this point, 00S11. Now I'm going to take a different choice. I'm going to substitute for S-- I could have gone either way. This would have something-- almost like non-determinism here, because you have a choice. I'm
2711	going to substitute for S-- instead of 0S1 I'm going to substitute R, because that's also legitimate in terms of the rules. And so now I'm going to have 00R11. And now R-- there's no choices here. R can only be substituted for by an empty string. So I get to R becomes just empty string. And in terms of the string generated, empty string doesn't add anything. It just really is-- it's a nothing. So I get the string 0011. And this is a string just of terminal symbols. And so that is a string in the language of the grammar G1. And if you think about it, G1's language is that language that we saw before, which I think we called D-- 0 to the k 1 to the k for k greater than or equal to 0. So this is an example of a language that a context-free grammar can do but a finite automaton cannot do. So that is our little introduction to-- oops. There's one more check-in here. Oh, yeah. So I'm asking you to
2712	actually look at-- let me get myself out of this picture so you don't see me blocking things. And we will do one last check-in. Make sure you're staying around for the whole thing. Now there could be several of these strings that are in the language. You have to click them all-- all of the ones that you have found that are in the language of this grammar that can be generated by grammar G2, you have to click those. I'll give you a little bit more time on this one to see which ones G2 can generate. I'll give you a hint. It's more than one, but not all. So I see you're making some progress here. Interesting. So please-- we're going to wrap this up very quickly. You can-- somebody's telling me you can't unclick. Thank you. Good to know. Still, things are coming in here. So let's not-- we're running toward the end of the hour here. I don't want to go over. So I'm going to end it in five seconds. Click away. And don't
2713	forget, we're not going to charge you if you get it wrong. Sharing results. I don't know why it has an orange one there, because there are several correct answers here. So it's A, B, and D are correct. You can get any of those. It's really sort of two copies of the language we had before next to one another. And so the only thing you cannot get is 1010. So I encourage you to think about that. And I will come to our last side of today, which is just a quick review. I can put myself back. So we showed how to convert DFAs to regular expressions. And the summary is that DFAs, NFAs, GNFAs, even, and regular expressions are all equivalent in the class of languages they can describe. The second thing we did was a method for proving languages not regular by using the pumping lemma or closure properties. And lastly, we introduced context-free grammars. And we're going to see more about those on Thursday. So with that, I think we're out of time. And
2714	thank you for the notes of appreciation. And I will-- I think we're going to end here. And see you on Thursday, if not before.
2715	The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. JOHN GUTTAG: Welcome to Lecture 6. As usual, I want to start by posting some relevant reading. For those who don't know, this lovely picture is of the Casino at Monte Carlo, and shortly you'll see why we're talking about casinos and gambling today. Not because I want to encourage you to gamble your life savings away. A little history about Monte Carlo simulation, which is the topic of today's lecture. The concept was invented by the Polish American mathematician, Stanislaw Ulam. Probably more well known for his work on thermonuclear weapons than on mathematics, but he did do a lot of very important mathematics earlier in his life. The story here starts that he was ill, recovering from some serious illness, and was home and was bored and was playing a lot of games of
2716	solitaire, a game I suspect you've all played. Being a mathematician, he naturally wondered, what's the probability of my winning this stupid game which I keep losing? And so he actually spent quite a lot of time trying to work out the combinatorics, so that he could actually compute the probability. And despite being a really amazing mathematician, he failed. The combinatorics were just too complicated. So he thought, well suppose I just play lots of hands and count the number I win, divide by the number of hands I played. Well then he thought about it and said, well, I've already played a lot of hands and I haven't won yet. So it probably will take me years to play enough hands to actually get a good estimate, and I don't want to do that. So he said, well, suppose instead of playing the game, I just simulate the game on a computer. He had no idea how to use a computer, but he had friends in high places. And actually talked to John von Neumann, who is often
2717	viewed as the inventor of the stored program computer. And said, John, could you do this on your fancy new ENIAC machine? And on the lower right here, you'll see a picture of the ENIAC. It was a very large machine. It filled a room. And von Neumann said, sure, we could probably do it in only a few hours of computation. Today we would think of a few microseconds, but those machines were slow. Hence was born Monte Carlo simulation, and then they actually used it in the design of the hydrogen bomb. So it turned out to be not just useful for cards. So what is Monte Carlo simulation? It's a method of estimating the values of an unknown quantity using what is called inferential statistics. And we've been using inferential statistics for the last several lectures. The key concepts-- and I want to be careful about these things will be coming back to them-- are the population. So think of the population as the universe of possible examples. So in the case of solitaire, it's a universe
2718	of all possible games of solitaire that you could possibly play. I have no idea how big that is, but it's really big, Then we take that universe, that population, and we sample it by drawing a proper subset. Proper means not the whole thing. Usually more than one sample to be useful. Certainly more than 0. And then we make an inference about the population based upon some set of statistics we do on the sample. So the population is typically a very large set of examples, and the sample is a smaller set of examples. And the key fact that makes them work is that if we choose the sample at random, the sample will tend to exhibit the same properties as the population from which it is drawn. And that's exactly what we did with the random walk, right? There were a very large number of different random walks you could take of say, 10,000 steps. We didn't look at all possible random walks of 10,000 steps. We drew a small sample of, say 100 such walks,
2719	computed the mean of those 100, and said, we think that's probably a good expectation of what the mean would be of all the possible walks of 10,000 steps. So we were depending upon this principle. And of course the key fact here is that the sample has to be random. If you start drawing the sample and it's not random, then there's no reason to expect it to have the same properties as that of the population. And we'll go on throughout the term, and talk about the various ways you can get fooled and think of a random sample when exactly you don't. All right, let's look at a very simple example. People like to use flipping coins because coins are easy.
2720	So let's assume we have some coin. All right, so I bought two coins slightly larger than the usual coin. And I can flip it. Flip it once, and let's consider one flip, and let's assume it came out heads. I have to say the coin I flipped is not actually a $20 gold piece, in case any of you were thinking of stealing it. All right, so we've got one flip, and it came up heads. And now I can ask you the question-- if I were to flip the same coin an infinite number of times, how confident would you be about answering that all infinite flips would be heads? Or even if I were to flip it once more, how confident would you be that the next flip would be heads? And the answer is not very. Well, suppose I flip the coin twice, and both times it came up heads. And I'll ask you the same question-- do you think that the next flip is likely to be heads? Well, maybe you would be more inclined
2721	to say yes and having only seen one flip, but you wouldn't really jump to say, sure. On the other hand, if I flipped it 100 times and all 100 flips
2722	that my coin only has a head on both sides, for example. Or is weighted in some funny way that it mostly comes up heads. And so a lot of people, maybe even me, if you said, I flipped it 100 times and it came up heads. What do you think the next one will be? My best guess would be probably heads. How about this one?
2723	and we have 50 heads here, two heads here, And 48 tails. And now if I said, do you think that the probability of the next flip coming up heads-- is it 52 out of 100? Well, if you had to guess, that should be the guess you make. Based upon the available evidence, that's the best guess you should probably make. You have no reason to believe it's a fair coin. It could well be weighted. We don't see it with coins, but we see weighted dice all the time. We shouldn't, but they exist. You can buy them on the internet. So typically our best guess is what we've seen, but we really shouldn't have very much confidence in that guess. Because well, could've just been an accident. Highly unlikely even if the coin is fair that you'd get 50-50, right? So why when we see 100 samples and they all come up heads do we feel better about guessing heads for the 101st than we did when we saw two samples? And why don't we feel so
2724	good about guessing 52 out of 100 when we've seen a hundred flips that came out 52 and 48? And the answer is something called variance.
2725	When I had all heads, there was no variability in my answer. I got the same answer all the time. And so there was no variability, and that intuitively-- and in fact, mathematically-- should make us feel confident that, OK, maybe that's really the way the world is. On the other hand, when almost half are heads and almost half are tails, there's a lot of variance. Right, it's hard to predict what the next one will be. And so we should have very little confidence that it isn't an accident that it happened to be 52-48 in one direction. So as the variance grows, we need larger samples to have the same amount of confidence. All right, let's look at that with a detailed example. We'll look at roulette in keeping with the theme of Monte Carlo simulation. This is a roulette wheel that could well be at Monte Carlo. There's no need to simulate roulette, by the way. It's a very simple game, but as we've seen with our earlier examples, it's nice when we're learning about simulations
2726	to simulate things where we actually can know what the actual answer is so that we can then understand our simulation better. For those of you who don't know how roulette is played-- is there anyone here who doesn't know how roulette is played? Good for you. You grew up virtuous. All right, so-- well all right. Maybe I won't go there. So you have a wheel that spins around, and in the middle are a bunch of pockets. Each pocket has a number and a color. You bet in advance on what number you think is going to come up, or what color you think is going to come up. Then somebody drops a ball in that wheel, gives it a spin. And through centrifugal force, the ball stays on the outside for a while. But as the wheel slows down and heads towards the middle, and eventually settles in one of those pockets. And you win or you lose. Now you can bet on it, and so let's look at an example of that. So here is a
2727	roulette game. I've called it fair roulette, because it's set up in such a way that in principle, if you bet, your expected value should be 0. You'll win some, you'll lose some, but it's fair in the sense that it's not either a negative or positive sum game. So as always, we have an underbar underbar in it. Well we're setting up the wheel with 36 pockets on it, so you can bet on the numbers 1 through 36. That's way range work, you'll recall. Initially, we don't know where the ball is, so we'll say it's none. And here's the key thing is, if you make a bet, this tells you what your odds are. That if you bet on a pocket and you win, you get len of pockets minus 1. So This is why it's a fair game, right? You bet $1. If you win, you get $36, your dollar plus $35 back. If you lose, you lose. All right, self dot spin will be random dot choice among the pockets. And then there is simply
2728	bet, where you just can choose an amount to bet and the pocket you want to bet on. I've simplified it. I'm not allowing you to bet here on colors. All right, so then we can play it. So here is play roulette. I've made game the class a parameter,
2729	You tell it how many spins. What pocket you want to bet on. For simplicity, I'm going to bet on this same pocket all the time. Pick your favorite lucky number and how much you want to bet, and then we'll have a simulation just like the ones we've already looked at. So the number you get right starts at 0. For I and range number of spins, we'll do a spin. And then tote pocket plus equal game dot that pocket. And it will come back either 0 if you've lost, or 35 if you've won. And then we'll just print the results. So we can do it. In fact, let's run it. So here it is. I guess I'm doing a million games here, so quite a few. Actually I'm going to do two. What happens when you spin it 100 times? What happens when you spin it a million times? And we'll see what we get. So what we see here is that we do 100 spins. The first time I did it my expected return was
2730	minus 100%. I lost everything I bet. Not so unlikely, given that the odds are pretty long that you could do 100 times without winning. Next time I did a 100, my return was a positive 44%, and then a positive 28%. So you can see, for 100 spins it's highly variable what the expected return is. That's one of the things that makes gambling attractive to people. If you go to a casino, 100 spins would be a pretty long night at the table. And maybe you'd won 44%, and you'd feel pretty good about it. What about a million spins? Well people aren't interested in that, but the casino is, right? They don't really care what happens with 100 spins. They care what happens with a million spins. What happens when everybody comes every night to play. And there what we see is-- you'll notice much less variance. Happens to be minus 0.04 plus 0.6 plus 0.79. So it's still not 0, but it's certainly, these are all closer to 0 than any of these are. We know
2731	it should be 0, but it doesn't happen to be in these examples. But not only are they closer to 0, they're closer together. There is much less variance in the results, right? So here I show you these three numbers, and ask what do you expect to happen? You have no clue, right? So I don't know, maybe I'll win a lot. Maybe I'll lose everything. I show you these three numbers, you're going to look at it and say, well you know, I'm going to be somewhere between around 0 and maybe 1%. But you're never going to guess it's going to be radically different from that. And if I were to change this number to be even higher, it would go even closer to 0. But we won't bother. OK, so these are the numbers we just looked at, because I said the seed to be the same. So what's going on here is something called the law of large numbers, or sometimes Bernoulli's law. This is a picture of Bernoulli on the stamp. It's one of
2732	the two most important theorems in all of statistics, and we'll come to the second most important theorem in the next lecture.
2733	"with the same actual probability, the chance that the fraction of times the outcome differs from p converges to 0 as the number of trials goes to infinity."" So this says if I were to spin this fair roulette wheel an infinite number of times, the expected-- the return would be 0. The real true probability from the mathematics. Well, infinite is a lot, but a million is getting closer to infinite. And what this says is the closer I get to infinite, the closer it will be to the true probability. So that's why we did better with a million than with a hundred. And if I did a 100 million, we'd do way better than I did with a million. I want to take a minute to talk about a way this law is often misunderstood. This is something called the gambler's fallacy. And all you have to do is say, let's go watch a sporting event. And you'll watch a batter strike out for the sixth consecutive time. The next time they come to the plate, the"
2734	idiot announcer says, well he struck out six times in a row. He's due for a hit this time, because he's usually a pretty good hitter. Well that's nonsense. It says, people somehow believe that if deviations from expected occur, they'll be evened out in the future. And we'll see something similar to this that is true, but this is not true. And there is a great story about it. This is told in a book by Huff and Geis. And this truly happened in Monte Carlo, with Roulette. And you could either bet on black or red. Black came up 26 times in a row. Highly unlikely, right? 2 to the 26th is a giant number. And what happened is, word got out on the casino floor that black had kept coming up way too often. And people more or less panicked to rush to the table to bet on red, saying, well it can't keep coming up black. Surely the next one will be red. And as it happened when the casino totaled up its winnings, it was
2735	a record night for the casino. Millions of francs got bet, because people were sure it would have to even out. Well if we think about it, probability
2736	A pretty small number. But the probability of 26 consecutive reds when the previous 25 rolls were red is what? No, that. AUDIENCE: Oh, I thought you meant it had been 26 times again. JOHN GUTTAG: No, if you had 25 reds and then you spun the wheel once more, the probability of it having 26 reds is now 0.5, because these are independent events. Unless of course the wheel is rigged, and we're assuming it's not. People have a hard time accepting this, and I know it seems funny. But I guarantee there will be some point in the next month or so when you will find yourself thinking this way, that something has to even out. I did so badly on the midterm, I will have to do better on the final. That was mean, I'm sorry. All right, speaking of means-- see? Professor Grimson not the only one who can make bad jokes. There is something-- it's not the gambler's fallacy-- that's often confused with it, and that's called regression to the mean. This term was coined
2737	in 1885 by Francis Galton in a paper, of which I've shown you a page from it here.
2738	what this table says is if somebody's parents are both taller than average, it's likely that the child will be smaller than the parents. Conversely, if the parents are shorter than average, it's likely that the child will be taller than average. Now you can think about this in terms of genetics and stuff. That's not what he did. He just looked at a bunch of data, and the data actually supported this. And this led him to this notion of regression to the mean. And here's what it is, and here's the way in which it is subtly different from the gambler's fallacy. What he said here is, following an extreme event-- parents being unusually tall-- the next random event is likely to be less extreme. He didn't know much about genetics, and he kind of assumed the height of people were random. But we'll ignore that. OK, but the idea is here that it will be less extreme. So let's look at it in roulette. If I spin a fair roulette wheel 10 times and get 10 reds,
2739	that's an extreme event. Right, here's a probability of basically 1.1024. Now the gambler's fallacy says, if I were to spin it another 10 times, it would need to even out. As in I should get more blacks than you would usually get to make up for these excess reds. What regression to the mean says is different. It says, it's likely that in the next 10 spins, you will get fewer than 10 reds. You will get a less extreme event. Now it doesn't have to be 10. If I'd gotten 7 reds instead of 5, you'd consider that extreme, and you would bet that the next 10 would have fewer than 7. But you wouldn't bet that it would have fewer than 5. Because of this, if you now look at the average of the 20 spins, it will be closer to the mean of 50% reds than you got from the extreme first spins. So that's why it's called regression to the mean. The more samples you take, the more likely you'll get to the mean. Yes?
2740	AUDIENCE: So, roulette wheel spins are supposed to be independent. JOHN GUTTAG: Yes. AUDIENCE: So it seems like the second 10-- JOHN GUTTAG: Pardon? AUDIENCE: It seems like the second 10 times that you spin it. Like that shouldn't have to [INAUDIBLE].. JOHN GUTTAG: Has nothing to do with the first one. AUDIENCE: But you said it's likely [INAUDIBLE].. JOHN GUTTAG: Right, because you have an extreme event, which was unlikely. And now if you have another event, it's likely to be closer to the average than the extreme was to the average. Precisely because it is independent. That makes sense to everybody? Yeah? AUDIENCE: Isn't that the same as the gambler's fallacy, then? By saying that, because this was super unlikely, the next one [INAUDIBLE]. JOHN GUTTAG: No, the gambler's fallacy here-- and it's a good question, and indeed people often do get these things confused. The gambler's fallacy would say that the second 10 spins would-- we would expect to have fewer than 5 reds, because you're trying to even out the unusual number of reds in the
2741	first Spin Whereas here we're not saying we would have fewer than 5. We're saying we'd probably have fewer than 10. That it'll be closer to the mean, not that it would be below the mean. Whereas the gambler's fallacy would say it should be below that mean to quote, even out, the first 10. Does that makes sense? OK, great questions. Thank you. All right, now you may not know this, but casinos are not in the business of being fair. And the way they don't do that is in Europe, they're not all red and black. They sneak in one green. And so now if you bet red, well sometimes it isn't always red or black. And furthermore, there is this 0. They index from 0 rather than from one, and so you don't get a full payoff. In American roulette, they manage to sneak in two greens. They have a 0 in a double 0. Tilting the odds even more in favor of the casino. So we can do that in our simulation. We'll look at European
2742	roulette as a subclass of fair roulette. I've just added this extra pocket, 0. And notice I have not changed the odds. So what you get if you get your number is no higher, but you're a little bit less likely to get it because we snuck in that 0.
2743	in which I add yet another pocket. All right, we can simulate those. Again, nice thing about simulations, we can play these games.
2744	100,000, and a million. And what do we see as we look at this? Well, right away we can see that fair roulette is usually a much better bet than either of the other two. That even with only 1,000 spins the return is negative. And as we get more and more as I got to a million, it starts to look much more like closer to 0. And these, we have reason to believe at least, are much closer to true expectation saying that, while you break even in fair roulette, you'll lose 2.7% in Europe and over 5% in Las Vegas, or soon in Massachusetts. All right, we're sampling, right? That's why the results will change, and if I ran a different simulation with a different seed I'd get different numbers. Whenever you're sampling, you can't be guaranteed to get perfect accuracy. It's always possible you get a weird sample. That's not to say that you won't get exactly the right answer. I might have spun the wheel twice and happened to get the exact right answer of
2745	the return. Actually not twice, because the math doesn't work out, but 35 times and gotten exactly the right answer. But that's not the point. We need to be able to differentiate between what happens to be true and what we actually know, in a rigorous sense, is true. Or maybe don't know it, but have real good reason to believe it's true. So it's not just a question of faith. And that gets us to what's in some sense the fundamental question of all computational statistics, is how many samples do we need to look at before we can have real, justifiable confidence in our answer? As we've just seen-- not just, a few minutes ago-- with the coins, our intuition tells us that it depends upon the variability in the underlying possibilities. So let's look at that more carefully. We have to look at the variation in the data. So let's look at first something called variance.
2746	Think of x as just a list of data examples, data items. And the variance is we first compute the average of value, that's mu. So mu is for the mean. For each little x and big X, we compare the difference of that and the mean. How far is it from the mean? And square of the difference, and then we just sum them. So this takes, how far is everything from the mean? We just add them all up. And then we end up dividing by the size of the set, the number of examples. Why do we have to do this division? Well, because we don't want to say something has high variance just because it has many members, right? So this sort of normalizes is by the number of members, and this just sums how different the members are from the mean. So if everything is the same value, what's the variance going to be? If I have a set of 1,000 6's, what's the variance? Yes? AUDIENCE: 0. JOHN GUTTAG: 0. You think this is
2747	going to be hard, but I came prepared. I was hoping this would happen. Look out, I don't know where this is going to go. [FIRES SLINGSHOT] AUDIENCE: [LAUGHTER] JOHN GUTTAG: All right, maybe it isn't the best technology. I'll go home and practice. And then the thing you're more familiar with is the standard deviation. And if you look at the standard deviation is, it's simply the square root of the variance. Now, let's understand this a little bit and first ask, why am I squaring this here, especially because later on I'm just going to take a square root anyway? Well squaring it has one virtue, which is that it means I don't care whether the difference is positive or negative. And I shouldn't, right? I don't care which side of the mean it's on, I just care it's not near the mean. But if that's all I wanted to do I could take the absolute value. The other thing we see with squaring is it gives the outliers extra emphasis, because I'm squaring that distance. Now you
2748	can think that's good or bad, but it's worth knowing it's a fact. The more important thing to think about is standard deviation all by itself is a meaningless number. You always have to think about it in the context of the mean. If I tell you the standard deviation is 100, you then say, well-- and I ask you whether it's big or small, you have no idea. If the mean is 100 and the standard deviation is 100, it's pretty big. If the mean is a billion and the standard deviation is 100, it's pretty small. So you should never want to look at just the standard deviation. All right, here is just some code to compute those, easy enough. Why am I doing this? Because we're now getting to the punch line. We often try and estimate values just by giving the mean. So we might report on an exam that the mean grade was 80. It's better instead of trying to describe an unknown value by it-- an unknown parameter by a single value, say the
2749	expected return on betting a roulette wheel, to provide a confidence interval. So what a confidence interval is is a range that's likely to contain the unknown value, and a confidence that the unknown value is within that range. So I might say on a fair roulette wheel I expect that your return will be between minus 1% and plus 1%, and I expect that to be true 95% of the time you play the game if you play 100 rolls, spins. If you take 100 spins of the roulette wheel, I expect that 95% of the time your return will be between this and that.
2750	10,000 times in European roulette is minus 3.3%. I think that was the number we just saw. And now I'm going to add to that this margin of error, which is plus or minus 3.5% with a 95% level of confidence. What does this mean? If I were to conduct an infinite number of trials of 10,000 bets each, my expected average return would indeed be minus 3.3%, and it would be between these values 95% of the time. I've just subtracted and added this 3.5, saying nothing about what would happen in the other 5% of the time. How far away I might be from this, this is totally silent on that subject. Yes? AUDIENCE: I think you want 0.2 not 9.2. JOHN GUTTAG: Oh, let's see. Yep, I do. Thank you. We'll fix it on the spot. This is why you have to come to lecture rather than just reading the slides, because I make mistakes. Thank you, Eric. All right, so it's telling me that, and that's all it means. And it's amazing how often people don't
2751	quite know what this means. For example, when they look at a political pole and they see how many votes somebody is expected to get. And they see this confidence interval and say, what does that really mean? Most people don't know. But it does have a very precise meaning, and this is it. How do we compute confidence intervals? Most of the time we compute them using something called the empirical rule. Under some assumptions, which I'll get to a little bit later, the empirical rule says that if I take the data, find the mean, compute the standard deviation as we've just seen, 68% of the data will be within one standard deviation in front of or behind the mean. Within one standard deviation of the mean. 95% will be within 1.96 standard deviations. And that's what people usually use. Usually when people talk about confidence intervals, they're talking about the 95% confidence interval. And they use this 1.6 number. And 99.7% of the data will be within three standard deviations. So you can see if you are
2752	outside the third standard deviation, you are a pretty rare bird, for better or worse depending upon which side. All right, so let's apply the empirical rule to our roulette game.
2753	I'm going to run a simple simulation. And the key thing to notice is really this print statement here. Right, that I'll print the mean, which I'm rounding. And then I'm going to give the confidence intervals, plus or minus, and I'll just take the standard deviation times 1.6 times 100, y times 100, because I'm showing you percentages. All right so again, very straightforward code. Just simulation, just like the ones we've been looking at. And well, I'm just going-- I don't think I'll bother running it for you in the interest of time. You can run it yourself.
2754	So when I simulated betting a pocket for 20 trials, we see that the-- of 1,000 spins each, for 1,000 spins the expected return for fair roulette happened to be 3.68%. A bit high. But you'll notice the confidence interval plus or minus 27 includes the actual answer, which is 0. And we have very large confidence intervals for the other two games. If you go way down to the bottom where I've spun, spun the wheel many more times, what we'll see is that my expected return for fair roulette is much closer to 0 than it was here. But more importantly, my confidence interval is much smaller, 0.8. So now I really have constrained it pretty well. Similarly, for the other two games you will see-- maybe it's more accurate, maybe it's less accurate, but importantly the confidence interval is smaller. So I have good reason to believe that the mean I'm computing is close to the true mean, because my confidence interval has shrunk. So that's the really important concept here, is that we don't just guess--
2755	compute the value in the simulation. We use, in this case, the empirical rule to tell us how much faith we should have in that value. All right, the empirical rule doesn't always work. There are a couple of assumptions. One is that the mean estimation error is 0. What is that saying? That I'm just as likely to guess high as gas low. In most experiments of this sort, most simulations, that's a very fair assumption. There's no reason to guess I'd be systematically off in one direction or another. It's different when you use this in a laboratory experiment, where in fact, depending upon your laboratory technique, there may be a bias in your results in one direction. So we have to assume that there's no bias in our errors. And we have to assume that the distribution of errors
2756	And we'll come back to this in just a second. But this is a normal distribution, called the Gaussian. Under those two assumptions the empirical rule will always hold. All right, let's talk about distributions, since I just introduced one. We've been using a probability distribution. And this captures the notion of the relative frequency with which some random variable takes on different values.
2757	drawn from a finite set of values. So when I flip these coins, there are only two possible values, head or tails. And so if we look at the distribution of heads and tails, it's pretty simple. We just list the probability of heads. We list the probability of tails. We know that those two probabilities must add up to 1, and that fully describes our distribution. Continuous random variables are a bit trickier. They're drawn from a set of reals between two numbers. For the sake of argument, let's say those two numbers are 0 and 1. Well, we can't just enumerate the probability for each number. How many real numbers are there between 0 and 1? An infinite number, right? And so I can't say, for each of these infinite numbers, what's the probability of it occurring? Actually the probability is close to 0 for each of them. Is 0, if they're truly infinite. So I need to do something else, and what I do that is what's called the probability density function. This is a different kind
2758	of PDF than the one Adobe sells. So there, we don't give the probability of the random variable taking on a specific value. We give the probability of it lying somewhere between two values. And then we define a curve, which shows how it works. So let's look at an example. So we'll go back to normal distributions.
2759	it's described by this function. And for those of you who don't know about the magic number e, this is one of many ways to define it. But I really don't care whether you remember this. I don't care whether you know what e is. I don't care if you know what this is. What we really want to say is, it looks like this. In this case, the mean is 0. It doesn't have to be 0. I've shown a mean of 0 and a standard deviation of 1. This is called the so-called standard normal distribution. But it's symmetric around the mean. And that gets back to, it's equally likely that our errors are in either direction, right? So it peaks at the mean. The peak is always at the mean. That's the most probable value, and it's symmetric about the mean. So if we look at it, for example, and I say, what's the probability of the number being between 0 and 1? I can look at it here and say, all right, let's draw a line
2760	here, and a line here. And then I can integrate the curve under here. And that tells me the probability of this random variable being between 0 and 1. If I want to know between minus 1 and 1. I just do this and then I integrate over that area. All right, so the area under the curve in this case defines the likelihood. Now I have to divide and normalize to actually get the answer between 0 and 1. So the question is, what fraction of the area under the curve is between minus 1 and 1? And that will tell me the probability. So what does the empirical rule tell us? What fraction is between minus 1 and 1, roughly? Yeah? 68%, right? So that tells me 68% of the area under this curve is between minus 1 and 1, because my standard deviation is 1, roughly 68%. And maybe your eyes will convince you that's a reasonable guess. OK, we'll come back and look at this in a bit more detail on Monday of next week. And
2761	also look at the question of, why does this work in so many cases where we don't actually have a normal distribution to start with?
2762	The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. JOHN GUTTAG: Hi, everybody. Welcome back to class. I have a lot to cover today, so I'm just going to get right to it. So you may remember at the end of last lecture, I talked about the Empirical Rule and said that there were a couple of assumptions underlying it.
2763	And second, that the distribution of errors will be normally distributed. I didn't probably mention at the time, but we often call this distribution Gaussian after the astronomer Carl Gauss. And it looks like that. Normal distributions are very easy to generate in Python. I have a little example here of generating, not a real normal distribution, but a discrete approximation of one. And the thing to really notice about it here is this line random.gauss. So that's a built in function of the random library. The first argument is the mean. And the second argument is the standard deviation or a mu and sigma as they're usually called. Every time I call that, I will get a different-- or usually a different random value drawn from a Gaussian with the mean, in this case of 0 and a standard deviation of 100. I'm then going to produce a plot of those so you can see what it looks like. And I'm going to do that using some things we haven't seen before. So first of all, we've seen histograms.
2764	Bins tells us how many bins we want in the histogram. I said we want 100. The default is 10. Dist is the values it will use for it. And then this is something we haven't seen before, weights. Weights is a keyword argument. So normally when we produce a histogram, we take all of the values, the minimum to the maximum, and in this case, we would divide them into 100 bins, because I said, bins equals 100. So the first bin might be, well, let's say we only had values ranging from 0 to 100. The first bin would be all the 0's, all the 1's up to all the 99's. And it weights each value in the bin by 1. So if the bin had 10 values falling in it, the y-axis would be a 10. If the bin had 50 values falling in it, the y-axis would go up to 50. You can tell it how much you want to weight each bin, the elements in the bins. And say, no, I don't want them each
2765	to count as 1, I want them to count as a half or a quarter, and that will change the y-axis. So that's what I've done here. What I've said is I've created a list and I want to say for each of the bins-- in this case I'm going to weigh each of them the same way-- the weight is going to be 1 over the number of samples. I'm multiplying it by the len of dist, that will be how many items I have. And that will tell me how much each one is being weighted. So for example, if I have, say, 1,000 items, I could give 1,000 values and say, I want this item weighted by 1, and I want this item over here weighted by 12 or a half. We rarely do that. Usually, what we want is to give each item the same weight. So why would I want it not to be weighted at just one? Because I want my y-axis to be more easily interpreted, and essentially give me the fraction of
2766	the values that fell in that bin. And that's what I'm doing here. The other new thing I'm doing here is the plotting commands, including pylab.hist, many of them return values. Usually, I just ignore that value when we just say pylab.plot or pylab.hist. Here I am taking the value. The value in this case for a histogram is a tuple of length 2. The first element is a list or an array, giving me how many items are in each bin. And the second is the patches used to produce the beautiful pictures we're use to seeing. So here what I'm going to do is take this value so that I can do this at the end. Now, why would I want to look at the fraction within approximately 200 of the mean? What is that going to correspond to in this case? Well, if I divide 200 by 2 I get 100. Which happens to be the standard deviation. So in this case, what I'm going to be looking at is what fraction of the values fall within
2767	two standard deviations of the mean? Kind of a check on the empirical rule, right? All right, when I run the code I get this. So it is a discrete approximation to the probability density function. You'll notice, unlike the previous picture I showed you which was nice and smooth, this is jaggedy. You would expect it to be. And again, you can see it's very nice that the peak is what we said the mean should be, 0. And then it falls off. And indeed, slightly more than 95% fall within two standard deviations of the mean. I'm not even surprised that it's a little bit more than 95% because, remember the magic number is 1.96, not 2. But since this is only a finite sample, I only want it to be around 95. I'm not going to worry too much whether it's bigger or smaller. All right? So random.gauss does a nice job of giving us Gaussian values. We plotted them and now you can see that I've got the relative frequency. That's why I see fractions in
2768	the y-axis rather than counts. And that would be because of the way I use the weights command. All right, let's return to PDFs. So as we said last time, distributions can be defined by Probability Density Functions, and that gives us the probability of some random variable lying between two values. It defines a curve where the values in the x-axis lie between the minimum and maximum values of the variable. And it's the area under the curve-- and we'll come back to this-- between those two points that give us the probability of an example falling in that range. So now let's look at it for a normal distribution.
2769	looking formula which defines a PDF for a normal distribution. And here's some code that's as straight forward an implementation as one could imagine of this formula, OK. So that now is a value that, given a mu and a sigma and an x, gives me the x associated with that mu and sigma, OK? And you'll notice there's nothing random about this. All right, it is giving me the value. Now, let's go down here. And I'm going to, for a set of x's, get the set of y's corresponding to that and then plot it. I'm going to set mu to 0 and sigma to 1, the so-called standard normal distribution. And I'm going to look at the distribution from minus 4 to 4. Nothing magic about that other than, as you'll see, it's kind of a place where it asymptotes near 0. So while x is less than 4, I'll get the x-value, I'll get the y-value corresponding to that x by calling Gaussian, increment x by 0.05 and do that until I'm done. And then simply,
2770	I'll plot the x-values against the y-values and throw a title on it using pylab.title. All right, code make sense? Well, this is where I got that beautiful picture we've looked at before. When I plotted here, it looks, actually quite smooth. It's not, it's really connecting a bunch of tiny little lines but I made the points close enough together that it looks at least here smooth at this resolution. So we know what the values on the x-axis are. Those are the values I happen to want to look at, from minus 4 to 4. What are the values on the y-axis? We kind of would like to interpret them as probabilities, right? But we could be pretty suspicious about that and then if we take this one point that's up here, we say the probability of that single point is 0.4. Well, that doesn't make any sense because, in fact, we know the probability of any particular point is 0 in some sense, right? So furthermore, if I chose a different value for sigma, I can actually
2771	get this to go bigger than 1 on the y-axis. So if you take sigma to be say, 0.1-- I think the y-axis goes up to something like 40. So we know we don't have probabilities in the range 40. So if these aren't probabilities, what are they? What are the y values? Well, not too surprising since I claimed this was a probability density function, they're densities. Well, what's a density? This makes sense. I'll say it and then I'll try and explain it. It's a derivative of the cumulative distribution function. Now, why are we talking about derivatives in the first place? Well, remember what we're trying to say. If we want to ask, what's the probability of a value falling between here and here, we claim that that was going to be the area under this curve, the integral. Well, as you know from 18.01, there's a very clear relationship between derivatives and integrals. And so if we interpret each of these points as a derivative, in some sense the slope here, then we can look at
2772	this as the area just by integrating under there. So to interpret a PDF, we always do it mathematically. Actually, I do it just by looking at it. But the only really interesting mathematical questions to ask have to do with area. Once we have the area, we can, then, talk about the probabilities of some value falling within a region of the curve. So what's interesting here is not the numbers per se on the y-axis but the shape of the curve, because those numbers have to be related to the numbers on the x-axis, dx, dy right? We're looking at derivatives. All right, so now, we have to talk about integration. I promise you'll only hear about it for another few minutes then we'll leave the topic. So I mentioned before SciPy as a library that contains a lot of useful mathematical functions. One of them is integrate.quad. Well, the integrate part is obvious. It means integration. Quad is telling you the algorithm it's choosing to do the integration. All of these integrals are going to be actual
2773	approximations to the real integral. SciPy is not doing some clever mathematics to get an analytical solution. It's using a numerical technique to approximate the integral. And the one here happens to be called quadrature, it doesn't matter. All right, you can pass it up to four arguments. You must pass it to function to be integrated, that makes sense. A number representing the lower limit of the integration-- you need to give it that. A number representing the upper limit-- you need to give it that. And then the fourth argument is a tuple supplying all values for the arguments, except the first of the function you are integrating. I'll show you an example of that on the next slide. And we'll see that it returns a tuple, an approximation to the result, what it thinks the integral is, and an estimate of how much error there might be in that one. We'll ignore the error for the moment. All right, let's look at the code.
2774	That gives us all the different integration methods. I'm not going to show you the code for Gaussian since I showed it to you a couple of minutes ago. But I wanted you to remember that it takes three arguments, x, mu, and sigma. Because when we get down here to the integration, we'll pass at the function Gaussian and then the values that we want to integrate over. So those will be the values that x can take upon. And that will change as we go from mu minus the number of standard deviations times sigma to mu plus the number of standard deviations times sigma. And then, this is the optional fourth argument, the tuple, mu, and sigma. Why do I need to pass that in? Because Gaussian is a ternary argument, or a function that takes three values. And I'm going to integrate over values of x so I have to fix mu and sigma to constants, which is what I'm doing down here. And then I'll take the zeroth value, which is its estimate of the
2775	integral. All right, so that's the new thing. The rest of the code is all stuff you've seen. For t and range number of trials, I'm going to choose a random mu between minus 10 and 10 and a random sigma between 1 and 10. It doesn't matter what those constants are. And then for the number of standard deviations in 1, 1.96, and 3, I'm going to integrate Gaussian over that range. And then we're just going to see how many of them fall within that range. In some sense, what we're doing is we're checking the empirical rule. We're saying, take the Gaussian. I don't care what mu and sigma are. It doesn't matter. The empirical rule will still hold, I think. But we're just checking it here, OK? Well, here are the results. So from mu equals 9 and sigma equals 6, I happened to choose those, we'll see the fracture within 1, fraction within 1.96 and 3. And so for these random mus and sigmas, you can see that all of them-- and you can set
2776	them to whatever you want when you get your hand them the code. Essentially, what we have is, whoops, the empirical rule actually works. One of those beautiful cases where you can test the theory and see that the theory really is sound. So there we go. So why am I making such a big deal of normal distributions? They have lots of nice mathematical properties, some of which we've already talked about. But all of that would be irrelevant if we didn't see them. The good news is they're all over the place. I've just taken a few here.
2777	I would never show that to high school students, or GREs to you guys. But you can see that they are amazingly well-distributed along a normal distribution. On down here, this is plotting percent change in oil prices. And again, we see something very close to a normal distribution. And here is just looking at heights of men and women. And again, they clearly look very normal. So it's really quite impressive how often they occur. But not everything is normal. So we saw that the empirical rule works for normal distributions. I won't say I proved it for you. I illustrated it for you with a bunch of examples. But are the outcomes of the spins of a roulette wheel normal? No. They're totally uniform, right? Everything is equally probable-- a 4, a 6, an 11, a 13, double-0 if you're in Las Vegas. They're all equally probable. So if I plotted those, I'd basically just get a straight line with everything at 1 over however many pockets there are. So in that case, why does the empirical rule
2778	work? We saw that we were doing some estimates about returns and we used the empirical rule, we checked it and, by George, it was telling us the truth. And the reason is because we're not reasoning about a single spin of the wheel but about the mean of a set of spins. So if you think about it, what we were reasoning about was the return of betting. If we look at one spin-- well, let's say we bet $1. The return is either minus 1 because we've lost our dollar. Or if we get lucky and our pocket happens to come up, it was 36, I think, or 35. I forget which, OK? But that's all. So if we plotted a histogram, we would see a huge peak at minus 1 and a little bump here at 36 and nothing in the middle. Clearly, not a normal distribution. But what we're reasoning about is not the return of a single spin but the return of many spins. If we played 1,000 spins, what is our expected return? As
2779	soon as we end up reasoning, not about a single event but about the mean of something, we can imply something
2780	And here it is. It's actually for something so important, very simple. It says that given a sufficiently large sample-- and I love terms like sufficiently large but we'll later put a little meat on that-- the following three things are true. The means of the samples in a set of samples, the so-called sample means will be approximately normally distributed. So that says if I take a sample-- and remember, a sample will have multiple examples. So just to remind people. A population is a set of examples. A sample is a subset of the population. So it too is a set of examples, typically. If this set is sufficiently large-- certainly 1 is not sufficiently large-- then it will be the case that the mean of the means-- so I take the mean of each sample and then I can now plot all of those means and so take the mean of those, right-- and they'll be normally distributed. Furthermore, this distribution will have a mean that is close to the mean of the population. The mean of
2781	the means will be close to the mean of the population. And the variance of the sample means will be close to the variance of the population divided by the sample size. This is really amazing that this is true and dramatically useful. So to get some insight, let's check it. To do that, postulate that we have this kind of miraculous die. So instead of a die that when you roll it you get a number 1, 2, 3, 4, 5, or 6, this particular die is continuous. It gives you a real number between 0 and 5, or maybe it's between 1 and 6, OK? So it's a continuous die. What we're going to do is roll it a lot of times. We're going to say, how many die? And then, how many times are we going to roll that number of die? So the number of die will be the sample size-- number of dice will be the sample size. And then we'll take a bunch of samples which I'm calling number of rolls. And then we'll
2782	plot it and I'm just choosing some bins and some colors and some style and various other things just to show you how we use the keyword arguments. Actually, I said the number of rolls is the number of trials. But it isn't quite that because I'm going to get the number of trials by dividing the number of rolls by the number of dice. So if I have more dice, I get to have fewer samples, more dice per sample, all right? Then we'll just do it. So it will be between 0 and 5 because random.random returns a number between 0 and 1 and I'm multiplying it by 5. And then we'll look at the means and we'll plot it all. Again, we're playing games with weights just to make the plot a little easier to read. And here's what we get. If we roll one die, the mean is very close to 2.5. Well, that's certainly what you'd expect, right? It's some random number between 0 and 5. 2.5 is a pretty good guess as to what
2783	it should average. And it has a standard deviation of 1.44. And that's a little harder to guess that that's what it would be. But you could figure it out with a little math or as I did here with the simulation. But now, if I roll 50 dice, well, again, the mean is close to 2.5. It's what you'd expect, right? I roll 50 die, I get the mean value of those 50. But look how much smaller the standard deviation is. More importantly, what we see here is that if we look at the value, the probability is flat for all possible values between 0 and 5 for a single die. But if we look at the distribution for the means, it's not quite Gaussian but it's pretty close. Why is it not Gaussian? Well, I didn't do it an infinite number of times. Did it quite a few, but not an infinite number. Enough that you didn't want to sit here while it ran. But you can see the amazing thing here that when I go from
2784	looking at 1 to looking at the mean of 50, suddenly I have a normal distribution. And that means that I can bring to bear on the problem the Central Limit Theorem. We can try it for roulette. Again I'm not going to make you sit through a million trials of 200 spins each. I'll do it only for fair roulette. And again, this is a very simple simulation, and we'll see what we get. And what we see is it's not quite normal, again, but it definitely has that shape. Now, it's going to be a little bit strange because I can't lose more than one, if I'm betting one. So it will never be quite normal because it's going to be truncated down on the left side, whereas the tail can be arbitrarily long. So again, mathematically it can't be normal but it's close enough in the main region, where most of the values lie, that we can get away with applying the empirical rule and looking at answers. And indeed as we saw, it does work. So
2785	what's the moral here? It doesn't matter what the shape of the distribution of the original values happen to be. If we're trying to estimate the mean using samples that are sufficiently large, the CLT will allow us to use the empirical rule when computing confidence intervals. Even if we go back and look at this anomaly over in the left, what do you think would happen if I, instead of had 200, have, say, 1,000? What's the probability of the average return being minus 1 of 1,000 bets? Much smaller than for 100 bets. To lose 1,000 times in a row is pretty unlikely. So to get all the way to the left is going to be less likely, and, therefore, the thing will start looking more and more normal as the samples get bigger. All right, and so we can use the CLT to justify using the empirical rule when we compute confidence intervals. All right, I want to look at one more example in detail. This is kind of an interesting one. You might think that randomness
2786	is of no use for, say, finding the value of pi because there's nothing random about that. Similarly, you might think that randomness was of no use in integrating a function, but in fact, the way those numerical algorithms work is they use randomness. What you're about to see is that randomness, and indeed things related to Monte Carlo simulations, can be enormously useful, even when you're computing something that is inherently not random like the value of pi here. And we won't ask you to remember that many digits on the quiz and the exam. All right, so what's pi? Well, people have known about pi for thousands and thousands of years. And what people knew was that there was some constant, we'll call it pi. It wasn't always called that. Such that it was equal to the circumference of a circle divided by the diameter, and furthermore, the area was going to be pi r squared. People knew that way back to the Babylonians and the Egyptians. What they didn't know is what that value was. The earliest
2787	known estimate of pi was by the Egyptians, on something called the Rhind Papyrus pictured here.
2788	"squared, or 3.16. Not so bad. About 1,100 years later an estimate of pi appeared in the Bible, Kings 7:23. It didn't say pi is but it described-- I think this was a construction of King Solomon's Temple. ""He made a molten sea, ten cubits from one brim to the other."" it was round. It was a circle. ""His height was five cubits and a line of 30 cubits did compass it round about."" Well, if you do the arithmetic, what does this imply the value of pi to be? 3, and I'm sure that's what Mike Pence thinks it is. About 300 years later, Archimedes did a better job of it. He estimated pi by constructing a 96-sided polygon. There's a picture of one. It looks a lot like a circle. On the left is one with fewer sides. And what he did is he then-- since it was a polygon he knew how to compute its area or it's circumference and he just counted things up and he said, well, pi is somewhere between 223/71 and 22/7. And"
2789	that turns out to actually-- if you take the average of that it will be a really good estimate. 2000 years after Archimedes, the French mathematicians Buffon and Laplace proposed finding the value of pi using what we would today call a Monte Carlo simulation. They did not have a computer to execute this on. So what they proposed-- it started with this mathematics. They took a circle and inscribed it in a square, a square of two units of whatever it is per side. And therefore we know that the area of the square is 2 times 2 or 4. We know that the area of the circle is pi r squared. And since we know that r is 1-- because that's the square it's inscribed in-- we know that the area of a circle is exactly pi. What Buffon then proposed was dropping a bunch of needles at random-- kind of like when Professor Grimson was sorting things-- and seeing where they land. Some would land in the square but not in the circle. Some would land in
2790	the circle. You would ignore any that landed outside the square. And then they said, well, since they're falling at random, the ratio of the needles in the circle to needles in the square should exactly equal the area of the square over the area of the circle, exactly, if you did an infinite number of needles. Does that make sense? Now, given that, you can do some algebra and solve for the area of the circle and say it has to be the area of the square times the number of needles in the circle divided by the needles in the square. And since we know that the area of the circle is pi that tells us that pi is going to equal four times the needles in the circle. That's 4 is the area of the square divided by the number of needles in the square. And so the argument was you can just drop a bunch of these needles, see where they land, add them up and from that you would magically now know the actual value
2791	of pi. Well, we tried a simulation one year in class but rather than using needles we had an archer and we blindfolded him so he would shoot arrows at random and we would see where they ended up. There's a video of this here if you want to see it. I'm going to play only the very end of the video which describes the results. Maybe we should just use Python to build a Monte Carlo simulation instead. So that's what happened. After it was all over, Anna came up and gave me some sound advice. Yeah, I was very proud of that particular shot with the apple. I had hoped the student would put it on his or her head but no one volunteered. That was not done blindfolded. Any rate, so here is the simulation. So first we have throwing the needles. For needles in range 1 to number of needles plus 1, we're going to choose the random x or random y and we're going to see whether or not it's in the circle. And there
2792	we will use the Pythagorean theorem to tell us that, all right? And we'll just do this, and then we're going to return exactly the formula we saw in the previous slide. Now, comes an interesting part. We need to get an estimate. So we start with the number of needles
2793	For t in range number of trials, we'll get a guess by throwing number of needles. And then we'll append that guess to our list of estimates. We'll then compute the standard deviation, get the current estimate which will be the sum of the estimates divided by the len of the estimate, just the mean of the estimate. And then we'll print it, all right? So given a number of needles and a number of trials, we'll estimate pi and we'll give you the standard deviation of that estimate. However, to do that within a certain precision, I'm going to have yet another loop. And I'm showing you this because we often structure simulations this way. So what I have here is the number of trials, which is not so interesting, but the precision. I'm saying, I would like to know the value of pi and I would like to have good reason to believe that the value you give me is within 0.005, in this case, of the true value. Or maybe more precisely, I would like to know
2794	with a confidence of 95% that the true value is within a certain range. So what this is going to do is it's just going to-- and I should probably use 1.96 instead of 2, but oh, well-- it's just going to keep increasing the number of needles, doubling the number of needles until it's confident about the estimate, confident enough, all right? So this is a very common thing. We don't know how many needles we should need so let's just start with some small number and we'll keep going until we're good. All right, what happens when we run it? Well, we start with some estimates that when we had 1,000 needles it told us that pi was 3.148 and standard deviation was 0.047 et cetera. So a couple of things to notice. One, are my estimates of pi getting monotonically better? You'd like to think, as I add more needles, my estimates are getting more accurate. So that's question one. Are they getting more accurate? Not monotonically, right? If we look at it, where are they getting
2795	worse? Well, let's see. All right, 3.148, well, 3.13 is already worse, right? So I double the number of needles and I get a worse estimate. Now, the trend is good. By the time I get here, I've got a pretty good estimate. So overall as I look at larger samples, a bigger subset of the population, my estimates are trending towards better but not every time. On the other hand, let's look at the standard deviations. What we see here is that the standard deviations are, indeed, getting monotonically better. Now, there's nothing mathematical guaranteeing that, right? Because there is randomness here. But I'm increasing the number of needles by so much that it kind of overrides the bad luck of maybe getting a bad random set. And we see those are getting better. So the important thing to see here is not that I happened to get a better estimate, but that I know more about the estimate. I can have more confidence in the estimate because it's closing in on it. So the moral here is it's
2796	not sufficient to produce a good answer. I've said this before. We need to have reason to believe that it is close to the right answer. So in this case, I'm using the standard deviation and say, given that it's gotten quite small-- you know, 1.96 times 0.002 is indeed a small number. I could make it smaller if I wanted. I have good reason to believe I'm close to the right value of pi. Everyone agree with that? Is that right? Not quite, actually. It would be nice if it were true. But it isn't. So let's look at some things. Is it correct to state that 95% of the time we run this simulation you'll get an estimate of pi between these two values? I don't expect you to do the arithmetic in your head but the answer is yes. So that is something we believe is true by the math we've been looking at for the last two lectures. Next statement, with a probability of 0.95, the actual value of pi is between these two things. Is
2797	that true? In fact, if I were to say, with a probability of 1, the actual value is pi is between those two values, would it be true? Yes. So they are both true facts. However, only the first of these can be inferred from our simulation. While the second fact is true, we can't infer it from the simulation. And to show you that, statistically valid is not
2798	I've introduced a bug in my simulation. I've replaced the 4 that we saw we needed by 2, now, an easy kind of mistake to make. And now, if we go to the code-- well, what do you think will happen if we go to the code and run it? We'll try it. We'll go down here to the code. We'll make that a 2. And what you'll see as it runs is that once again we're getting very nice confidence intervals, but totally bogus values of pi. So the statistics can tell us something about how reproducible our simulation is but not whether the simulation is an actually, accurate model of reality. So what do you need to do? You need to do something like a sanity check. So here you might look at a polygon and say, well, clearly that's a totally wrong number. Something is wrong with my code. OK, so just to wrap-up. What we've shown is a way to find pi. This is a generally useful technique. To estimate the area of any region r,
2799	you pick an enclosing region, call it e, such that it's easy to estimate the area of e, and r lies within it. Pick some random sets of points within e, let f be the fraction and fall within r, multiply e by f and you're done. So this for example, is a very common way to do integration. I promised you we'd talk about integration. So here's a sine of x. If I want to integrate the sine of x over some region, as done here, all I need to do is pick a bunch of random points, red and black in this case, and look at the ratio of one to the other. So showing how we can use randomness to again, compute something that is not inherently random. This is a trick people use over and over and over again when confronted with some situation where it's not easy to solve for things mathematically. You just do a simulation and if you do it right, you get a very good answer. All right, we will move on
2800	to a different topic on Wednesday.
2801	The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation, or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. PROFESSOR: Good afternoon, everybody. Welcome to Lecture 8. So we're now more than halfway through the lectures. All right, the topic of today is sampling. I want to start by reminding you about this whole business of inferential statistics. We make references about populations by examining one or more random samples drawn from that population. We used Monte Carlo simulation over the last two lectures. And the key idea there, as we saw in trying to find the value of pi, was that we can generate lots of random samples, and then use them to compute confidence intervals. And then we use the empirical rule to say, all right, we really have good reason to believe that 95% of the time we run this simulation, our answer will be between here and here. Well, that's all
2802	well and good when we're doing simulations. But what happens when you to actually sample something real? For example, you run an experiment, and you get some data points. And it's too hard to do it over and over again. Think about political polls. Here was an interesting poll. How were these created? Not by simulation. They didn't run 1,000 polls and then compute the confidence interval. They ran one poll-- of 835 people, in this case. And yet they claim to have a confidence interval. That's what that margin of error is. Obviously they needed that large confidence interval. So how is this done? Backing up for a minute, let's talk about how sampling is done when you are not running a simulation. You want to do what's called probability sampling, in which each member of the population has a non-zero probability of being included in a sample. There are, roughly speaking, two kinds. We'll spend, really, all of our time
2803	And the key idea here is that each member of the population has an equal probability of being chosen in the sample so there's no bias. Now, that's not always appropriate. I do want to take a minute to talk about why. So suppose we wanted to survey MIT students to find out what fraction of them are nerds-- which, by the way, I consider a compliment. So suppose we wanted to consider a random sample of 100 students. We could walk around campus and choose 100 people at random. And if 12% of them were nerds, we would say 12% of the MIT undergraduates are nerds-- if 98%, et cetera. Well, the problem with that is, let's look at the majors by school.
2804	This is actually the majors at MIT by school. And you can see that they're not exactly evenly distributed. And so if you went around and just sampled 100 students at random, there'd be a reasonably high probability that they would all be from engineering and science. And that might give you a misleading notion of the fraction of MIT students that were nerds, or it might not. In such situations we do something called stratified sampling, where we partition the population into subgroups, and then take a simple random sample from each subgroup. And we do that proportional to the size of the subgroups. So we would certainly want to take more students from engineering than from architecture. But we probably want to make sure we got somebody from architecture in our sample. This, by the way, is the way most political polls are done. They're stratified. They say, we want to get so many rural people, so many city people, so many minorities-- things like that. And in fact, that's probably where the election recent polls were all
2805	messed up. They did a very, retrospectively at least, a bad job of stratifying. So we use stratified sampling when there are small groups, subgroups, that we want to make sure are represented. And we want to represent them proportional to their size in the population. This can also be used to reduce the needed size of the sample. If we wanted to make sure we got some architecture students in our sample, we'd need to get more than 100 people to start with. But if we stratify, we can take fewer samples. It works well when you do it properly. But it can be tricky to do it properly. And we are going to stick to simple random samples here. All right, let's look at an example.
2806	And so our running example today will be sampling to get information about the average temperatures. And of course, as you can see, they're highly variable. And we live in one of the cooler areas. The data we're going to use is real data-- and it's in the zip file that I put up for the class-- from the US Centers for Environmental Information. And it's got the daily high and low temperatures for 21 different American cities, every day from 1961 through 2015. So it's an interesting data set-- a total of about 422,000 examples in the dataset. So a fairly good sized dataset. It's fun to play with. All right, so we're sort of in the part of the course where the next series of lectures, including today, is going to be about data science, how to analyze data. I always like to start by actually looking at the data-- not looking at all 421,000 samples, but giving a plot to sort of give me a sense of what the data looks like. I'm not going to walk
2807	you through the code that does this plot. I do want to point out that there are two things in it that we may not have seen before. Simply enough, I'm going to use numpy.std to get standard deviations instead of my own code for it. And random.sample to take simple random samples from the population. random.sample takes two arguments. The first is some sort of a sequence of values. And the second is an integer telling you how many samples you want. And it returns a list containing sample size, randomly chosen distinct elements. Distinct elements is important, because there are two ways that people do sampling. You can do sampling without replacement, which is what's done here. You take a sample, and then it's out of the population. So you won't draw it the next time. Or you can do sampling with replacement, which allows you to draw the same sample multiple times-- the same example multiple times. We'll see later in the term that there are good reasons that we sometimes prefer sampling with replacement. But usually
2808	we're doing sampling without replacement. And that's what we'll do here. So we won't get Boston on April 3rd multiple times-- or, not the same year, at least. All right. So here's the histogram the code produces. You can run it yourself now, if you want, or you can run it later. And here's what it looks like. The daily high temperatures, the mean is 16.3 degrees Celsius. I sort of vaguely know what that feels like. And as you can see, it's kind of an interesting distribution. It's not normal. But it's not that far, right? We have a little tail of these cold temperatures on the left. And it is what it is. It's not a normal distribution. And we'll later see that doesn't really matter. OK, so this gives me a sense. The next thing I'll get is some statistics. So we know the mean is 16.3 and the standard deviation is approximately 9.4 degrees.
2809	Well, here's a histogram of one random sample of size 100. Looks pretty different, as you might expect. Its standard deviation is 10.4, its mean 17.7. So even though the figures look a little different, in fact, the means and standard deviations are pretty similar. If we look at the population mean and the sample mean-- and I'll try and be careful to use those terms-- they're not the same. But they're in the same ballpark. And the same is true of the two standard deviations. Well, that raises the question, did we get lucky or is something we should expect? If we draw 100 random examples, should we expect them to correspond to the population as a whole? And the answer is sometimes yeah and sometimes no. And that's one of the issues I want to explore today. So one way to see whether it's a happy accident is to try it 1,000 times. We can draw 1,000 samples of size 100 and plot the results. Again, I'm not going to go over the code. There's something in that
2810	code, as well, that we haven't seen before. And that's the ax.vline plotting command. V for vertical. It just, in this case, will draw a red line-- because I've said the color is r-- at population mean on the x-axis. So just a vertical line. So that'll just show us where the mean is. If we wanted to draw a horizontal line, we'd use ax.hline. Just showing you a couple of useful functions. When we try it 1,000 times, here's what it looks like. So here we see what we had originally, same picture I showed you before. And here's what we get when we look at the means of 100 samples. So this plot on the left looks a lot more like it's a normal distribution than the one on the right. Should that surprise us, or is there a reason we should have expected that to happen? Well, what's the answer? Someone tell me why we should have expected it. It's because of the central limit theorem, right? That's exactly what the central limit theorem promised us would
2811	happen. And, sure enough, it's pretty close to normal. So that's a good thing. And now if we look at it, we can see that the mean of the sample means is 16.3, and the standard deviation of the sample means is 0.94. So if we go back to what we saw here, we see that, actually, when we run it 1,000 times and look at the means, we get very close to what we had initially. So, indeed, it's not a happy accident. It's something we can in general expect. All right, what's the 95% confidence interval here? Well, it's going to be 16.28 plus or minus 1.96 times 0.94, the standard deviation of the sample means. And so it tells us that the confidence interval is, the mean high temperature, is somewhere between 14.5 and 18.1. Well, that's actually a pretty big range, right? It's sort of enough to where you wear a sweater or where you don't wear a sweater. So the good news is it includes the population mean. That's nice. But the bad news is
2812	it's pretty wide. Suppose we wanted it tighter bound. I said, all right, sure enough, the central limit theorem is going to tell me the mean of the means is going to give me a good estimate of the actual population mean. But I want it tighter bound. What can I do? Well, let's think about a couple of things we could try. Well, one thing we could think about is drawing more samples. Suppose instead of 1,000 samples, I'd taken 2,000 or 3,000 samples. We can ask the question, would that have given me a smaller standard deviation? For those of you who have not looked ahead, what do you think? Who thinks it will give you a smaller standard deviation? Who thinks it won't? And the rest of you have either looked ahead or refused to think. I prefer to believe you looked ahead. Well, we can run the experiment. You can go to the code. And you'll see that there is a constant of 1,000, which you can easily change to 2,000. And lo and behold, the
2813	standard deviation barely budges. It got a little bit bigger, as it happens, but that's kind of an accident. It just, more or less, doesn't change. And it won't change if I go to 3,000 or 4,000 or 5,000. It'll wiggle around. But it won't help much. What we can see is doing that more often is not going to help. Suppose we take larger samples? Is that going to help? Who thinks that will help? And who thinks it won't? OK. Well, we can again run the experiment. I did run the experiment. I changed the sample size from 100 to 200. And, again, you can run this if you want. And if you run it, you'll get a result-- maybe not exactly this, but something very similar-- that, indeed, as I increase the size of the sample rather than the number of the samples, the standard deviation drops fairly dramatically, in this case from 0.94 0.66. So that's a good thing. I now want to digress a little bit before we come back to this and look at
2814	how you can visualize this-- Because this is a technique you'll want to use as you write papers and things like that-- is how do we visualize the variability of the data? And it's usually done with something called an error bar. You've all seen these things here.
2815	This is plotting pulse rate against how much exercise you do or how frequently you exercise. And what you can see here is there's definitely a downward trend suggesting that the more you exercise, the lower your average resting pulse. That's probably worth knowing. And these error bars give us the 95% confidence intervals for different subpopulations. And what we can see here is that some of them overlap. So, yes, once a fortnight-- two weeks for those of you who don't speak British-- it does get a little bit smaller than rarely or never. But the confidence interval is very big. And so maybe we really shouldn't feel very comfortable that it would actually help. The thing we can say is that if the confidence intervals don't overlap, we can conclude that the means are actually statistically significantly different, in this case at the 95% level. So here we see that the more than weekly does not overlap with the rarely or never. And from that, we can conclude that this is actually, statistically true-- that if you exercise
2816	more than weekly, your pulse is likely to be lower than if you don't. If confidence intervals do overlap, you cannot conclude that there is no statistically significant difference. There might be, and you can use other tests to find out whether there are. When they don't overlap, it's a good thing. We can conclude something strong. When they do overlap, we need to investigate further. All right, let's look at the error bars for our temperatures. And again, we can plot those using something called
2817	Lab So what it takes is two values, the usual x-axis and y-axis, and then it takes another list of the same length, or sequence of the same length, which is the y errors. And here I'm just going to say 1.96 times the standard deviations. Where these variables come from you can tell by looking at the code. And then I can say the format, I want an o to show the mean, and then a label. Fmt stands for format. errorbar has different keyword arguments than plot. You'll find that you look at different ways like histograms and bar plots, scatterplots-- they all have different available keyword arguments. So you have to look up each individually. But other than this, everything in the code should look very familiar to you. And when I run the code, I get this.
2818	And so what I've plotted here is the mean against the sample size with errorbars. And 100 trials, in this case. So what you can see is that, as the sample size gets bigger, the errorbars get smaller. The estimates of the mean don't necessarily get any better. In fact, we can look here, and this is actually a worse estimate, relative to the true mean, than the previous two estimates. But we can have more confidence in it. The same thing we saw on Monday when we looked at estimating pi, dropping more needles didn't necessarily give us a more accurate estimate. But it gave us more confidence in our estimate. And the same thing is happening here. And we can see that, steadily, we can get more and more confidence. So larger samples seem to be better. That's a good thing. Going from a sample size of 50 to a sample size of 600 reduced the confidence interval, as you can see, from a fairly large confidence interval here, ran from just below 14 to almost 19, as
2819	opposed to 15 and a half or so to 17. I said confidence interval here. I should not have. I should have said standard deviations. That's an error on the slides. OK, what's the catch? Well, we're now looking at 100 samples, each of size 600. So we've looked at a total of 600,000 examples. What has this bought us? Absolutely nothing. The entire population only contained about 422,000 samples. We might as well have looked at the whole thing, rather than take a few of them. So it's like, you might as well hold an election rather than ask 800 people a million times who they're going to vote for. Sure, it's good. But it gave us nothing. Suppose we did it only once. Suppose we took only one sample, as we see in political polls. What can we can conclude from that? And the answer is actually kind of surprising, how much we can conclude, in a real mathematical sense, from one sample. And, again, this is thanks to our old friend, the central limit theorem. So if
2820	you recall the theorem, it had three parts. Up till now, we've exploited the first two. We've used the fact that the means will be normally distributed so that we could use the empirical rule to get confidence intervals, and the fact that the mean of the sample means would be close to the mean of the population.
2821	is that the variance of the sample means will be close to the variance of the population divided by the sample size. And we're going to use that to compute something called the standard error-- formerly the standard error of the mean. People often just call it the standard error. And I will be, alas, inconsistent. I sometimes call it one, sometimes the other. It's an incredibly simple formula. It says the standard error is going to be equal to sigma, where sigma is the population standard deviation divided by the square root of n, which is going to be the size of the sample. And then there's just this very small function that implements it. So we can compute this thing called the standard error of the mean in a very straightforward way. We can compute it. But does it work? What do I mean by work? I mean, what's the relationship of the standard error to the standard deviation? Because, remember, that was our goal, was to understand the standard deviation so we could use the empirical rule.
2822	Well, let's test the standard error of the mean.
2823	I'm going to look at a bunch of different sample sizes, from 25 to 600, 50 trials each. So getHighs is just a function that returns the temperatures. I'm going to get the standard deviation of the whole population, then the standard error of the means and the sample standard deviations, both. And then I'm just going to go through and run it. So for size and sample size, I'm going to append the standard error of the mean. And remember, that uses the population standard deviation and the size of the sample. So I'll compute all the SEMs. And then I'm going to compute all the actual standard deviations, as well. And then we'll produce a bunch of plots-- or a plot, actually. All right, so let's see what that plot looks like.
2824	So we see the blue solid line is the standard deviation of the 50 means. And the red dotted line is the standard error of the mean. So we can see, quite strikingly here, that they really track each other very well. And this is saying that I can anticipate what the standard deviation would be by computing the standard error. Which is really useful, because now I have one sample. I computed standard error. And I get something very similar to what I get of the standard deviation if I took 50 samples and looked at the standard deviation of those 50 samples. All right, so not obvious that this would be true, right? That I could use this simple formula, and the two things would track each other so well. And it's not a coincidence, by the way, that as I get out here near the end, they're really lying on top of each other. As the sample size gets much larger, they really will coincide. So one, does everyone understand the difference between the standard deviation and
2825	the standard error? No. OK. So how do we compute a standard deviation? To do that, we have to look at many samples-- in this case 50-- and we compute how much variation there is in those 50 samples. For the standard error, we look at one sample, and we compute this thing called the standard error. And we argue that we get the same number, more or less, that we would have gotten had we taken 50 samples or 100 samples and computed the standard deviation. So I can avoid taking all 50 samples if my only reason for doing it was to get the standard deviation. I can take one sample instead and use the standard error of the mean. So going back to my temperature-- instead of having to look at lots of samples, I only have to look at one. And I can get a confidence interval. That make sense? OK. There's a catch. Notice that the formula for the standard error includes the standard deviation of the population-- the standard deviation of the sample. Well,
2826	that's kind of a bummer. Because how can I get the standard deviation of the population without looking at the whole population? And if we're going to look at the whole population, then what's the point of sampling in the first place? So we have a catch, that we've got something that's a really good approximation, but it uses a value we don't know. So what should we do about that? Well, what would be, really, the only obvious thing to try? What's our best guess at the standard deviation of the population if we have only one sample to look at? What would you use? Somebody? I know I forgot to bring the candy today, so no one wants to answer any questions. AUDIENCE: The standard deviation of the sample? PROFESSOR: The standard deviation of the sample. It's all I got. So let's ask the question, how good is that? Shockingly good. So I looked at our example here for the temperatures. And I'm plotting the sample standard deviation versus the population standard deviation for different sample sizes, ranging
2827	from 0 to 600 by one, I think.
2828	I'm pretty far off. I'm off by 14% here. And I think that's 25. But when the sample sizes is larger, say 600, I'm off by about 2%. So what we see, at least for this data set of temperatures-- if the sample size is large enough, the sample standard deviation is a pretty good approximation of the population standard deviation. Well. Now we should ask the question, what good is this? Well, as I said, once the sample reaches a reasonable size-- and we see here, reasonable is probably somewhere around 500-- it becomes a good approximation. But is it true only for this example? The fact that it happened to work for high temperatures in the US doesn't mean that it will always be true. So there are at least two things we should consider to asking the question, when will this be true, when won't it be true. One is, does the distribution of the population matter? So here we saw, in our very first plot, the distribution of the high temperatures. And it was kind of
2829	symmetric around a point-- not perfectly. But not everything looks that way, right? So we should say, well, suppose we have a different distribution. Would that change this conclusion? And the other thing we should ask is, well, suppose we had a different sized population. Suppose instead of 400,000 temperatures I had 20 million temperatures. Would I need more than 600 samples for the two things to be about the same? Well, let's explore both of those questions. First, let's look at the distributions. And we'll look at three common distributions-- a uniform distribution, a normal distribution, and an exponential distribution. And we'll look at each of them for, what is this, 100,000 points. So we know we can generate a uniform distribution by calling random.random. Gives me a uniform distribution of real numbers between 0 and 1. We know that we can generate our normal distribution by calling random.gauss. In this case, I'm looking at it between the mean of 0 and a standard deviation of 1. But as we saw in the last lecture, the shape will be
2830	the same, independent of these values. And, finally, an exponential distribution, which we get by calling random.expovariate. Very And this number, 0.5, is something called lambda, which has to do with how quickly the exponential either decays or goes up, depending upon which direction. And I'm not going to give you the formula for it at the moment. But we'll look at the pictures. And we'll plot each of these discrete approximations to these distributions.
2831	Quite different, right? We've looked at uniform and we've looked at Gaussian before. And here we see an exponential, which basically decays and will asymptote towards zero, never quite getting there. But as you can see, it is certainly not very symmetric around the mean. All right, so let's see what happens. If we run the experiment on these three distributions, each of 100,000 point examples, and look at different sample sizes, we actually see that the difference between the standard deviation and the sample standard
2832	is not the same. We see, down here-- this looks kind of like what we saw before. But the exponential one is really quite different. You know, its worst case is up here at 25. The normal is about 14. So that's not too surprising, since our temperatures were kind of normally distributed when we looked at it. And the uniform is, initially, much better an approximation. And the reason for this has to do with a fundamental difference in these distributions, something called skew. Skew is a measure of the asymmetry of a probability distribution. And what we can see here is that skew actually matters. The more skew you have, the more samples you're going to need to get a good approximation. So if the population is very skewed, very asymmetric in the distribution, you need a lot of samples to figure out what's going on. If it's very uniform, as in, for example, the uniform population, you need many fewer samples. OK, so that's an important thing. When we go about deciding how many samples we need,
2833	we need to have some estimate of the skew in our population. All right, how about size? Does size matter? Shockingly-- at least it was to me the first time I looked at this-- the answer is no. If we look at this-- and I'm looking just for the uniform distribution, but we'll see the same thing for all three-- it more or less doesn't matter. Quite amazing, right? If you have a bigger population, you don't need more samples. And it's really almost counterintuitive to think that you don't need any more samples to find out what's going to happen if you have a million people or 100 million people. And that's why, when we look at, say, political polls, they're amazingly small. They poll 1,000 people and claim they're representative of Massachusetts. This is good news. So to estimate the mean of a population, given a single sample, we choose a sample size based upon some estimate of skew in the population. This is important, because if we get that wrong, we might choose a sample size that
2834	is too small. And in some sense, you always want to choose the smallest sample size you can that will give you an accurate answer, because it's more economical to have small samples than big samples. And I've been talking about polls, but the same is true in an experiment. How many pieces of data do you need to collect when you run an experiment in a lab. And how much will depend, again, on the skew of the data. And that will help you decide. When you know the size, you choose a random sample from the population. Then you compute the mean and the standard deviation of that sample. And then use the standard deviation of that sample to estimate the standard error. And I want to emphasize that what you're getting here is an estimate of the standard error, not the standard error itself, which would require you to know the population standard deviation. But if you've chosen the sample size to be appropriate, this will turn out to be a good estimate. And then once we've
2835	done that, we use the estimated standard error to generate confidence intervals around the sample mean. And we're done. Now this works great when we choose independent random samples. And, as we've seen before, that if you don't choose independent samples, it doesn't work so well. And, again, this is an issue where if you assume that, in an election, each state is independent of every other state, and you'll get the wrong answer, because they're not. All right, let's go back to our temperature example and pose a simple question. Are 200 samples enough? I don't know why I chose 200. I did. So we'll do an experiment here. This is similar to an experiment we saw on Monday. So I'm starting with the number of mistakes I make. For t in a range number of trials, sample will be random.sample of the temperatures in the sample size. This is a key step. The first time I did this, I messed it up. And instead of doing this very simple thing, I did a more complicated thing of just
2836	choosing some point in my list of temperatures and taking the next 200 temperatures. Why did that give me the wrong answer? Because it's organized by city. So if I happen to choose the first day of Phoenix, all 200 temperatures were Phoenix-- which is not a very good approximation of the temperature in the country as a whole. But this will work. I'm using random.sample. I'll then get the sample mean. Then I'll compute my estimate of the standard error by taking that as seen here. And then if the absolute value of the population minus the sample mean is more than 1.96 standard errors, I'm going to say I messed up. It's outside. And then at the end, I'm going to look at the fraction outside the 95% confidence intervals. And what do I hope it should print? What would be the perfect answer when I run this? What fraction should lie outside that? It's a pretty simple calculation. Five, right? Because if they all were inside, then I'm being too conservative in my interval, right? I want
2837	5% of the tests to fall outside the 95% confidence interval. If I wanted fewer, then I would look at three standard deviations. Instead of 1.96, then I would expect less than 1% to fall outside. So this is something we have to always keep in mind when we do this kind of thing. If your answer is too good, you've messed up. Shouldn't be too bad, but it shouldn't be too good, either. That's what probabilities are all about. If you called every election correctly, then your math is wrong. Well, when we run this, we get this lovely answer, that the fraction outside the 95% confidence interval is 0.0511. That's exactly-- well, close to what you want. It's almost exactly 5%. And if I run it multiple times, I get slightly different numbers. But they're all in that range, showing that, here, in fact, it really does work. So that's what I want to say, and it's really important, this notion of the standard error. When I talk to other departments about what we should cover in 60002,
2838	about the only thing everybody agrees on was we should talk about standard error. So now I hope I have made everyone happy. And we will talk about fitting curves to experimental data starting next week. All right, thanks a lot.
2839	The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. JOHN GUTTAG: So today, we're going to move on to a fairly different world than the world we've been living in. And this will be a world we'll be living in for quite a few lectures. But before I do that, I want to get back to just finish up something that Professor Grimson started. You may recall he talked about family trees and raised the question, was it actually possible to represent all ancestral relationships as a tree? Well, as a counterexample, I'm sure some of you are familiar with Oedipus Rex. For those of you who are not, I'm happy give you a plot summary at the end of the lecture. It's a rather bizarre plot. But it was captured in a wonderful song by Tom Lehrer. The short story is Oedipus ended up
2840	"marrying his mother and having four children. And Tom Lehrer, if you've never heard of Tom Lehrer, you're missing one of the world's funniest songwriters. And he had a wonderful song called ""Oedipus Rex,"" and I recommend this YouTube as a way to go and listen to it. And you can gather from the quote what the story is about. I also recommend the play, by the way. It's really kind of appalling what goes on, but it's beautiful. Back to the main topic, here's the relevant reading-- a small bit from later in the book and then chapter 14. You may notice that we're not actually going through the book in order. And the reason we're not doing that is because we're trying to get you information you need in time to do problem sets. So the topic of today is really uncertainty and the fact that the world is really annoyingly hard to understand. This is a signpost related to 6.0002, but we won't go into too much detail about it. We'd rather things were certain. But in"
2841	fact, they usually are not. And this is a place where 6.0002 diverges from the typical introductory computer science course, which focuses on things that are functional-- given an input, you always get the same output. It's predictable. And we like to do that, because that's easier to teach. But in fact, for reasons we'll be talking about, it's not nearly as useful if you're trying to actually write computations that help you understand the world. You have to face uncertainty head on. An analogy is for many years people, believed
2842	I guess they still do in 8.01 maybe-- that every effect has a cause. An apple falls from the tree because of gravity, and you know where it's going to land. And the world can be understood causally. And people believed this really for quite a long time, most of history, until the early part of the 20th century, when the so-called Copenhagen doctrine was put forth. The doctrine there from Bohr and Heisenberg, two very famous physicists, was one of what they called causal nondeterminism. And their assertion was that the world at its very most fundamental level behaves in a way that you cannot predict. It's OK to make a statement that x is highly likely to occur, almost certain to occur, but for no case can you make a statement x will occur. Nothing has a probability of one. This was hard for us to imagine today, when we all know quantum mechanics. But at the turn of the century, this was a shocking statement. And two other very well-known physicists, Albert Einstein and Schrodinger, basically said,
2843	"no, this is wrong. Bohr, Heisenberg, you guys are idiots. It's just not true. They probably didn't call them idiots. And this is most exemplified by Einstein's famous quote that ""God does not play dice,"" which is indicative of the fact that this was actually a discussion that permeated not just the world of physics, but society in general people really turned it into literally a religious issue, as did Einstein. Well, so now we should ask the question, does it really matter? And to illustrate that, I need two coins. I forgot to bring any coins with me. Does anyone got a coin they can lend me? AUDIENCE: I have some coins. JOHN GUTTAG: All right. Now, this is where I see how much the students trust me. Do I get a penny? Do I get a silver dollar? So what do we got here? This is someone who's entrusting me with quarters, not so bad. So we'll take these quarters, and we'll shake them up, and we'll put them down on the table. And now, we'll ask a"
2844	question-- do we have two heads, two tails, or one head and one tail? So who thinks we have two heads? Who thinks we have two tails? Who thinks we have one of each? Well, clearly, everyone except a few people-- for example, the Indians fan, who clearly believe in the counterfactual-- made the most probabilistic decision. But in fact, there is no nondeterminism here. I know the answer. And so in some sense, it doesn't matter whether it's deterministic, because in fact, it's not causally nondeterministic. The answer is quite clear, but you don't know the answer. And so whether or not the world is inherently unpredictable, the fact that we never have complete knowledge of the world suggests that we might as well treat it as inherently unpredictable. And so this is called predictive nondeterminism. And this really is what's going to underline pretty much everything else we're going to be doing here. No comments about that? I wouldn't do that to you. Thank you. I know you are wishing to get interest on the money, but you
2845	don't get any. AUDIENCE: Was it heads or tails? JOHN GUTTAG: What was that? So when we think about nondeterminism in computation,
2846	And that's any process that's ongoing in which the next state depends upon the previous states in some random element. So typically up till now when we've written code, one line of code did depended only on what the previous lines of code did. There was no randomness. Here, we're going to have randomness. And we can see the difference if we look at these two specifications of rolling a die. The first one, returns an int between 1 and 6, is what I'll call underdetermined. By that I mean you can't tell what it's going to return. Maybe it will return a different number each time you call it, but it's not required to. Maybe it will return three every time you call it. The second specification requires randomness. It says, it returns are randomly chosen int. So it requires a stochastic implementation. Let's look at how we implement a random process in Python. We start by importing the library random. This is not to say you can import any random library you want. It's to say you import
2847	the library called random. Let me get my pen out of here. And we'll use that a lot.
2848	random.choice. It takes as an argument a sequence, in this case a list, and randomly chooses one member of the list. And it chooses it uniformly. It's a uniform distribution. And what that means is that it's equally probable that it will choose any number in that list each time you call it. We'll later look at distributions that are not uniform, not equally probable, where things are weighted. But here, it's quite simple, it's just uniform. And then we can test it using testRoll-- take some number of n and rolls the die that many times and creates a string telling us what we got. So let's consider running this on, say, testRoll of five. And we'll ask the question, if we run it, how probable is it that it's going to return a string of five 1's? How do we do that? Now, how many people here are either in 6.041 or would have taken 6.041? Raise your hand. Oh, good. So very few of you know probability. That helps. So how do we think about that question?
2849	Well, probability, to me at least, is all about counting, especially discrete probability, which is what we're looking at here. What you do is you start by counting the number of events that have the property of interest and the number of possible events and divide one by the other. So if we think about rolling a die five times, we can enumerate all of the possible outcomes of five rolls. So if we look at that, what are the outcomes? Well, I could get five 1's. I could get four 1's and a 2 or four 1's and 3, skip a few. The next one would be three 1's, a 2 and a 1, then a 2 and 2, and finally, at the end, all 6's. So remember, we looked before at when we're looking at optimization problems about binary numbers. And we said we can look at all the possible choices of items in the knapsack by a vector of 0's and 1's. We said, how many possible choices are there? Well, it depended on how many binary
2850	numbers you could get in that number of digits. Well, here we're doing the same thing, but instead of base 2, it's base 6. And so the number of possible outcomes of five rolls is quite high. How many of those are five 1's? Only one of them, right? So in order to get the probability of a five 1's, I divide 1 by 6 to the fifth. Does that makes sense to everybody? So in fact, we see it's highly unlikely. The probability of a five 1's is quite small. Now, suppose we were to ask about the probability of something else-- instead of five 1's, say 53421. It kind of looks more likely than that than five 1's in a row, but of course, it isn't, right? Any specific combination is equally probable. And there are a lot of them. So this is all the probability we're going to think about we could think about this way, as simply a matter of counting-- the number of possible events, the number of events that have the property of interest--
2851	in this case being all 1's-- and then simple division. Given that framework, there were three basic facts about probability we're going to be using a lot of. So one, probabilities always range from 0 to 1. How do we know that? Well, we've got a fraction, right? And the denominator is all possible events. The numerator is the subset of that that's of interest. So it has to range from 0 to the denominator. And that tells us that the fraction has to range from 0 to 1. So 1 says it's always going to happen, 0 never. So if the probability of an event occurring is p, what's the probability of it not occurring? This follows from the first bullet. It's simply going to be 1 minus p. This is a trick that we'll find we'll use a lot. Because it's often the case when you want to compute the probability of something happening, it's easier to compute the probability of it not happening and subtract it from 1. And we'll see an example of that later today.
2852	Now, here's the biggie. When events are independent of each other, the probability of all of the events occurring is equal to the product of the probabilities of each of the events occurring. So if the probability of A is 0.5 and the probability of B
2853	0.5 times 0.4. You guys can figure that out. I think that's 0.2. So you'd expect that, that it should be much smaller than either of the first two probabilities. This is the most common rule, it's something we use all the time in probabilities, the so-called multiplicative law. We have to be careful about it, however, in that it only holds if the events are actually
2854	Two events are independent if the outcome of one has no influence on the outcome of the other. So when we roll the die, we assume that the first roll, the outcome, was independent of the-- or the second roll was independent of the first roll, independent of the fourth roll. When we looked at the two coins, we assume that heads and tails of each coin was independent of the other coin. I didn't, for example, look at one coin and make sure that the other one was different. The danger here is that people often compute probabilities assuming independence when you don't actually have independence. So let's look at an example. For those of you familiar with American football, the New England Patriots and the Denver Broncos are two prominent teams. And let's look at computing the probability of whether one of them will lose on a given Sunday. So the Patriots have a winning percentage of 7 of 8-- they've won 7 of their 8 games so far-- and the Broncos 6 of 8. The probability of
2855	both winning next Sunday, assuming that this is indicative of how good they are, we can get with the multiplicative rule. So it's 7/8 times 6/8, or 42/64. We could simplify that fraction, I suppose. Does that makes sense? So this is probably a pretty good estimate of both of them winning next Sunday. So the probability of at least one of them losing is 1 minus that. So here's an example of why we often use the 1 minus rule, because we could compute the probability of both of them winning by simply multiplying. And we subtract that from 1. However, what about Sunday, December 18? What's the probability? Well, as it happens, that day the Patriots are playing the Broncos. So now suddenly, the outcomes are not independent. The probability of one of them losing is influenced by the probability of the other winning. So you would expect the probability of one of them losing is much closer to 1 than 22/64, which is about 1/3. So in this case, it's easy. But as we'll see, as we
2856	get through the term, there are lots of cases where you have to work pretty hard to understand whether or not two events really are independent. And if you get it wrong, you get a totally bogus answer. 1/3 versus 1 is a pretty big difference. By the way, as it happens, the probability of the Broncos losing is about 1. Let's go look at some code. And we'll go back to our dice, because it's much easier to simulate dice games than it is to simulate football games. So here it is.
2857	So here, rather than rolling the die, I've written a program to do it. We've already seen the code for rolling a die. And so to run this simulation, typically what we're doing here is I'm giving you the goal-- for example, are we going to get five 1's-- the number of trials-- each trial, in this case, will be say of length 5-- so I'm going to roll the same die five times say 1,000 different times, and then just some text as to what I'm going to print. Almost all the simulations we look at are going to start with lines that look a lot like that. We're going to initialize some variable. And then we're going to run some number of trials. So in this case, we're going to get from the length of the goal-- so if the goal is five 1's, then we're going to roll the dice five times; if it's 10 runs, we'll roll it 10 times. So this is essentially one trial, one attempt. And then we'll check the result. And if
2858	it has the property we want-- in this case, it's equal to the goal-- then we're going to increment the total, which we initialized up here by 1. So we'll keep track with just the counting-- the number of trials that actually meet the goal. And then when we're done, what we're going to do is divide the number that met the goal by the number of trials-- exactly the counting argument we just looked at. And then we'll print the result. Almost every simulation we look at is going to have this structure. There'll be an outer loop, which is the number of trials. And then inside-- maybe it'll have a loop, or maybe it won't-- will be a single trial. We'll sum up the results. And then we'll divide by the number of trials. Let's run it. So a couple of things are going to go on here. If you look at the code as we've looked at it before, what you're seeing is I'm computing the estimated probability by the simulation. And I'm comparing it to the
2859	actual probability, which we've already seen how to compute. So if you look at it, there are a couple of things to look at. The estimated probability is pretty close to the actual probability but not the same. So let's go back to the PowerPoint. Here are the results. And there are at least two questions raised by this result. First of all, how did I know that this is what would get printed? Remember, this is random. How did I know that the estimate-- well, there's nothing random about the actual probability. But how did I know that the estimated probability would be 0? And why did it print it twice? Because I messed up the PowerPoint. Any rate, so how do I know what would get printed? Well a confession-- random.choice is not actually random. In fact, nothing we can do in a computer is actually random. You can prove that it's impossible to build a computer that actually generates truly random numbers. What they do instead is generate numbers that called pseudorandom. How do they do that?
2860	They have an algorithm that given one number generates the next number in a sequence. And they start that algorithm with a seed.
2861	Now, typically, they get that seed by reading the clock of the computer. So most computers have a clock that, say, keeps track of the number of microseconds since January 1, 1978. I don't know if that's still true. That's what Unix used to do. So the notion is, you start your program, there's no way of knowing how many microseconds have elapsed. And so you're getting a random number to start the process. Since you don't know where it starts, you don't know what the second number is, you don't know what the third number is, you don't know what the fourth number is. And so it's predictably nondeterministic, because you don't know what the seed is going to be. Now, you can imagine that this makes programs really hard to debug. Every time you run it, something different could happen. Now, we'll see often you want them to be unpredictable. But for now, we want them to be predictable, makes it easier prepare PowerPoint. So what you have is a command. You can call random.seed and give it
2862	a value and say, I don't want you to just choose some random seed, I want you to use 0 as the seed. For the same seed, you always get the same sequence of random values. And so what I've done is I set the seed to be, I think, 0 in this case, not because there's anything magic about 0, it's just sort of habit. But it made it predictable. As you write programs with randomness in and when you're debugging it, you will almost surely want to start by setting random.seed to a value so you get the same answer. But make sure you debug it with more than one value of this, so you didn't just get lucky with your seed. So that's how I knew what would get printed. The next question is, why did the simulation give me the wrong answer? The actual probability is three 0's and 1286. But it's estimated a probability of 0. Why is it wrong? Well, let's think about this. I ran 1,000 trials. What does it mean to say
2863	the probability is zero? It means that I tried it 1,000 times and didn't ever get a sequence of five 1's. So the numerator of the division at the bottom was 0. Hence, the answer is 0. Is this surprising? Well, no. Because if that's the actual probability of getting five 1's, it's not very shocking that in 1,000 trials it never happened. It's not a surprising result. And so we have to be careful when we run these things to understand the difference between what's in this case an actual probability and what statisticians call a sample probability. So what we got with the sample was 0. So what's the obvious thing to do? If you're doing a simulation of an event and the event is pretty rare, you want to try it on a very large number of trials. So let's go back to our code. And we'll change it to instead of 1,000, 1,000,000. You can see up here, by the way, where I set the seed. And now, let's run it. We did a lot better.
2864	If we look at here our estimated probability, it's three 0's 128, still not quite the actual probability but darn close. And maybe if I had done 10 million, it would have been even closer. So if you're writing a simulation to compute the probability of an event and the event is moderately rare, then you better run a lot of trials before you believe your estimated probability. In a week or so, we'll actually look at that more mathematically and say, what is a lot, how do we know what is enough. What are the morals here? Moral one, I've just told you-- takes a lot of trials to get a good estimate of the frequency of a rare event. Moral two, we should always, if we're getting an estimated probability, know that, and probably say that, and not confuse it with the actual probability. The third moral here is, it was kind of stupid to do a simulation. Since it was a very simple closed-form answer that we could compute that would really tell us what the actual
2865	probability is, why even bother with the simulation? Well, we're going to see why now, because simulations can be very useful. Let's look at another problem. This is the famous birthday problem.
2866	What's the probability of at least two people in a group having the same birthday? There's a URL at the bottom. That's pointing to a Google form. I'd like please all of you who have a computing device to go to it and fill out your birthday. It's anonymous, so we won't know how old you are, don't worry. Actually, it's only the date. It's not the year. So suppose there were 367 people in the group, roughly the number of people who took the 6.0001 600 midterm. If they are 367 people, what's the probability of at least two of them sharing a birthday? One, by something called the pigeonhole principle. You got some number of holes. And if you have more pigeons than holes, two pigeons have to share a whole. What about smaller numbers? Well, if we make a simplifying assumption that each birthdate is equally likely, then there's actually a nice closed-form solution for it. Again, this is a question where it's easier to compute the opposite of what you're trying to do and subtract it
2867	from 1. And so this fraction is giving the probability of two people not sharing a birthday. The proof that this is right, it's a little bit elaborate. But you can trust me, it's accurate. But it's a formula, and it's not that complicated a formula. So numbers like 366 factorial are big. So let's approximate a solution. We'll right a simulation and see if we get the same answer that that formula gave us. So here's the code for that-- two arguments-- the number of people in the group and the number that we asking do they have the same birthday. So since I'm assuming for now that every birthday is equally likely, the possible dates range from 1 to 366, because some years have a February 29. I'll keep track of the number of people born in each date by starting with none. And then for p in the range of number of people, I'll make a random choice of the possible dates and increment that element of the list by 1. And then at the end, we
2868	can say, look at the maximum number of birthdays and see if it's greater than or equal to the number of same. So that tells us that. And then we can actually look at the birthday problem-- number of people, the number of same, and, as usual, the number of trials. So the number of hits is 0 for t in range number of trials. If sameDate is true, then we'll increment the number of hits by 1 and then as usual divide by the number of trials. And we'll try it for 10, 20, 40, and 100 people. And then just, we'll print the estimated probability
2869	that formula I showed you. I have not shown you, but I've imported a library called math, because it is a factorial implementation. It's way faster than the recursive one that we've seen before. Let's run it. And we'll see what we get. So for 10, the estimated probability is 0.11 now. So you can see, the estimates are really pretty good. Once again, we have this business that for 100, we're estimating 1, when the real answer is point many, many 9's. But again, this is sample probability. It just means in the number of trials we did, every 1 for 100 people, there was a shared birthday. This is a number that usually surprises people, as to why with 100 people the probability is so high. But we could work out the formula and see it. And as you can see, the estimates are pretty good from my simulation. Now, we're going to see why we did a simulation in the first place. Suppose we want the probability of three people sharing a birthday instead of two. It's
2870	pretty easy to see how we changed the simulation. I even made a parameter. I just changed the number 2 to number 3. The math, on the other hand, is ugly. Why is the math so much uglier for 3 than for 2? Because for 2, the complementary problem-- the number we're subtracting from 1-- is simply the question of, are all birthdays different? So did two people share a birthday is 1 minus or all does everybody have a different birthday. On the other hand, for 3 people, the complementary problem is a complicated disjunct-- a bunch of ors-- either all birthdays are distinct, or two people share a birthday and the rest are distinct, or there are two groups of two people sharing a birthday and everything is distinct. So you can see here, there's a lot of possibilities. And so it's 1 minus now a very complicated formula. And in fact, if you try and look how to do this, most people will tell you don't bother. Here's kind of a good approximation. But the math gets
2871	very hairy. In contrast, changing the simulation is dead easy. We can do that. Whoops. So if we come over here for the code, all I have to do is change this to 2 or 3. And I'm going to leave in this code, which is the wrong code, computing the actual probability now for 2 people sharing rather than 3, because I want to make it easy for you to see the difference between what happens when we look at 3 shared rather than 2 shared. And I get invalid syntax. That's not good. That's what happens when I type in real time. Why do I have invalid syntax? AUDIENCE: Line 56. JOHN GUTTAG: Pardon. AUDIENCE: Line 56. JOHN GUTTAG: One person, Anna. AUDIENCE: Line 56, there's a comma. JOHN GUTTAG: Oh. That's not a good line. So now, we see that if we get, say, to n equals 100, for 2, you'll remember, it was 0.99. But for 3, it's only 0.63. So we see going from two sharing to three sharing gets us a radically different answer,
2872	not surprisingly. But we also-- and the real thing I wanted you to see-- is how easy it was to answer this question with the simulation. And that's a primary reason we use simulations to get probabilistic questions rather than sitting down and the pencil and paper and doing fancy probability calculations, because it's often way easier to do a simulation. We can see that in spades if we look at the next question. Let's think about this assumption that all birthdays are equally likely. Well, as you can see, this is a chart of how common birthdates are in the US, a heat map. And you'll see, for example, that February 29 is quite an uncommon birthday. So we should probably treat that differently. Somewhat surprisingly, you'll see that July 4 is a very uncommon birthday as well. It's easy to understand why February 29. The only thing I can figure out for July 4 is obstetricians don't like working on holidays. And so they induce labor sometime around the 2nd or the 3rd, so they don't have to
2873	come to work on the 4th or the 5th. Sounds a horrible thought. But I can't think of any other explanation for this anomaly. You'll probably, if you look at it, see Christmas day is not so common either. So now, the question, which we can answer, since you've all fill out this form, is how exceptional are MIT students? We like to think that you're different in every respect. So are your birthdays distributed differently than other dates? Have we got that data? So now we'll go look at that. We should have a heat map for you guys. This one? AUDIENCE: Yep. I removed all the February 31. Thank you for those submissions. [LAUGHTER] JOHN GUTTAG: So here it is. And we can see that, well, they don't seem to be banded quite as much in the summer months, probably says more about your parents than it does about you. But you can see that, indeed, we do have-- wow, we have a day where there are five birthdays, that look like? Or no? AUDIENCE: February 12. JOHN
2874	GUTTAG: Wow. You want to raise your hand if you're born on February 12? [LAUGHTER] So you are exceptional in that you lie about when you're born. But if you hadn't lied, I think we would have still seen the probabilities would hold. How many people were there, do we know? AUDIENCE: 146 with 112 unique birthdays. JOHN GUTTAG: 146 people, 112 unique birthdays. So indeed, the probability does work. So we know you're exceptional in a funny way. Well, you can imagine how hard it would be to adjust the analytic model to account for a weird distribution of birthdates. But again, adjusting the simulation model is easy. I could have gone back to that heat map I showed you of birthdays in the US and gotten a separate probability for each day, but I was too lazy. And instead, what I observed was that we had a few days, like February 29, highly unlikely, and this band in the middle of people who were conceived in the late fall and early winter. So what I did is I
2875	duplicated some dates. So the 58th day of the year, February 29, occurs only once. The dates before that, I said, let's pretend they occur four times. What only matters here is not how often they occur but the relative frequency. And then the dates after that occur four times except for the dates in that band, which is going
2876	So now-- and don't worry about the exact details here-- but what I'm doing is simply adjusting the simulation to change the probability of each date getting chosen by same date. And then I can run the simulation model. And, again, with a very small change to code, I've modeled something that's mathematically enormously complex. I have no idea how to actually do this probability mathematically. But the code is, as you can see, quite straightforward. So let's go to that here. So what I'm going to do is comment this one out and uncomment this more complicated set of dates and see what we get. And again, it changes quite dramatically. You might remember, before it was around I think 0.6-something for 100, and now, it's 0.75. So getting away from the notion that birthdays are uniformly distributed to saying some birthdays are more common than others, again, dramatically changes the answer. And we can easily look at that. So that gets us to the big topic of simulation models.
2877	"provides information about the possible behaviors of a system. I say possible behaviors, because I'm particularly interested in stochastic systems. They're descriptive not prescriptive in the sense that they describe the possible outcomes. They don't tell you how to achieve possible outcomes. This is different from what we've looked at earlier in the course, where we looked at optimization models. So an optimization model is prescriptive. It tells you how to achieve an effect, how to get the most value out of your knapsack, how to find the shortest path from A to B in a graph. In contrast, a simulation model says, if I do this, here's what happens. It doesn't tell you how to make something happened. So it's very different, and it's why we need both, why we need optimization models and we need simulation models. We have to remember that a simulation model is only an approximation to reality. I put in an approximation to the distribution of birthdates, but it wasn't quite right. And as the very famous statistician George Box said, ""all models are"
2878	"wrong, but some are actually very useful."" In the next lecture, we'll look at a useful class of models. When do we use simulations? Typically, as we've just shown, to model systems that are mathematically intractable, like the birthday problem we just looked at. In other situations, to extract intermediate results-- something happens along the way to the answer. And as I hope you've seen that simulations are used because we can play what if games by successively refining it. We started with a simple simulation that assumed that we only asked the question of, do two people share a birthday. We showed how we could change it to ask do three people share a birthday. We then saw that we could change it to assume a different distribution of birthdates in the group. And so we can start with something simple. And we get it ever more complexed to answer questions what if. We're going to start in the next lecture by producing a simulation of a random walk. And with that, I'll stop. And see you guys soon."
2879	The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at OCW.mit.edu. PROFESSOR: Welcome back. I hope you didn't spend time doing 6002 problem sets while eating turkey. It's not recommended for digestion. But I hope you're ready to go back into diving into material. And since it's been a week since we got together, let me remind you of what we were doing. We were looking at the issue of how to understand experimental data. Data could come from a physical experiment. We had the example of measuring the spring constant of a linear spring. Could come from biological data. Could come from social data. And what we looked out was the idea of how do we actually fit models to that data in order to understand them. So what I want to do is I want to start with that high level reminder of what we
2880	were after. I want to do about a five minute recap of what we were doing last time, because it has been a while. And then we're going to talk about how do you actually validate models that you're fitting to data to understand are they really good fits or not. And if you remember. I know you spend all your time thinking about 6002. You should remember I left you with a puzzle, where I fit data to-- sorry, fit models to some noisy data. And there was a question of, did the model really have an order 16 fit? Right, so what are we trying to do? Remember, our goal is to try and model experimental data. And really what we want to do is have a model that both explains the phenomena underlying what we see, gives us a sense of what might be the underlying physical mechanism, the underlying social mechanism, and can let us make predictions about the behavior in new settings. In the case of my spring, being able to predict what will the
2881	displacement be when I actually put a different weight on it than something I measured. Or if you want to think from a design perspective, working the other direction and saying, I don't want my spring to deflect more than this amount under certain kinds of weights. So how do I use the model to tell me what the spring constant should be for the spring I want in that case? So we want to be able to predict behavior in new settings. The last piece we know is that, if the data was perfect, this is easy. But it ain't. There's always going to be noise. There's always going to be experimental uncertainty. And so I really want to account for that uncertainty when I fit that model. And while sometimes I'll have theories that will help-- Hooke says models of springs are linear-- in some cases, I don't. And in those cases, I want to actually try and figure out what's the best model to fit even when I don't know what the theory tells me. OK, so
2882	quick recap, what do we use to solve this?
2883	My spring case for different displays for different masses I measured the displacements. Those displacements are my observed values. And if I had a model that would predict what the displacement should be, I can measure how good the fit is by looking at that expression right there, the sum of the squares of the differences between the observed and the predicted data. As I said, we could use other measures. We could use a first order and absolute value. The square is actually really handy, because it makes the solution space very easy to deal with, which we'll get to in a second. So given observed data, get a prediction. I can use the sum of squared differences to measure how good the fit is. And then the second piece is I now what to find what's the best way to predict the data. What's the best curve that fits the data. What's the best model for protecting the values. And we suggest that last time, we'll focus on mathematical expressions, polynomials. Professor Guttag is so excited about polynomial
2884	expressions, he's throwing laptops on the floor. Please don't do that to your laptop. We're going to fit polynomials to these expressions. And since the polynomials have some coefficients, the game is basically, how do I find the coefficients of the polynomial that minimize that expression. And that, we said, was an example of linear regression. So let me just remind you what linear regression says. Simple example, case of the spring. I'm going to get a degree 1 polynomial. So that is something of the form y is ax plus b. a and b are the three variables, the parameters I can change. And the idea is for every x, in the case of my spring, for every mass, I'm going to use that model to predict what's the displacement, measure the differences, and find the thing that minimizes it. So I just want to find values of a and b that let me predict values that minimize that expression. As I suggested, you could solve this. You could write code to do it. It's a neat little piece
2885	of code to write. But fortunately, PiLab provides that for you. And I just want to give you the visualization of what we're doing here. And then we're going to look at examples. I'm going to try to find the best line. It's represented by two values, a and b.
2886	in a space that has one access with values and the other access with b values. Every point in that plane defines a line for me. Now imagine a surface laid over this two dimensional space, where the value or the height of the surface is the value of that objective function at every point. Don't worry about computing it all, but just imagine I could do that. And by the way, one of the nice things about doing sum of squares is that surface always has a concave shape. And now the idea of linear regression is I'm going to start at some point on that surface. And I'm just going to walk downhill until I get to the bottom. There will always be one bottom, one point. And once I get to that point, that a and b value tell me the best line. So it's called linear regression because I'm linearly walking downhill on this space. Now I'm doing this for line with two parameters a,b, because it's easy to visualize. If you're a good mathematician even
2887	if you're not, you can generalize this to think about arbitrary dimensions. So a fourth order surface in a five dimensional space, for example, would solve a cubic example of this. That's the idea of linear regression. That's what we're going to use to actually figure out, to find the best solution.
2888	I gave you a set of data. In about 3 slides, I'm going to tell you where the data came from. But I give you a set of data. We could fit the best line to this using that linear regression idea. And again, last piece of reminder, I'm going to use polyfit from PiLab. It just solves that linear regression problem. And I give it a set of x values. I give a corresponding set of y values, need to be the same number in each case. And I give it a dimension. And in this case, one says, find the best fitting line. It will produce that and return it as a tuple, which I'll store under the name model 1. And I could plot it out. So just remind you, polyfit will find the best fitting n dimensional surface, n being that last parameter there, and return it. In a second, we're going to use polyval, which will say, given that model and a set of x values, predict what the y value should be. Apply them.
2889	OK, so I fit the line. What do you think? Good fit? Not so much, right? Pretty ugly. I mean, you can see it's probably the best-- or not probably. It is the best fitting line. It sort of accounts for the variation on either side of it. But it's not a very good fit. So then the question is, well why not try fitting a higher order model? So I could fit a quadratic. That is a second order model. y equals ax squared plus bx plus c. Run the same code. Block that out. And I get that. That's the linear model. There's the quadratic model. At least my [? i ?] our looks a lot better, right? It looks like it's following that data reasonably well. OK, I can fit a linear model. I can fit a quadratic model. What about higher order models? What about a fourth order model, an eighth order model, a 644th order model? How do I know which one is going to be best? So for that, I'm going to remind you
2890	of the last thing we used. And then we're going to start talking about how to use it further, which is if we try fitting higher order polynomials, do we get a better fit? And to do that, we need to measure what it means for the data to fit. If I don't have any other information. For example, if I don't have a theory that tells me this should be linear in the case afoot, then the best way to do it is to use what's called, the coefficient of determination, r-squared. It's a scale independent thing, which is good. By scale independent, I mean if I take all the data and stretch it out, this will still give me back the same value in terms of the fit. So it doesn't depend on the size of the data. And what it does is it basically tells me the a value between 0 and 1, how well does this model fit the data. So just to remind you, in this case, the y's are the measured values, the p's
2891	are the predicted values. That's what my model is saying, for each one of these cases. And mu down here is the mean or the average of the measured values. The way to think about this is this top expression here. Well, that's exactly what I'm trying to minimize, right? So it's giving me an estimate or a measure of the error in the estimates between what the model says and what I actually measure. And the denominator down here basically tells me how much does the data vary away from the mean value. Now here's the idea. If in fact, I can get this to 0, I can get a model that completely accounts for all the variation in the estimates, that's great. It says, the model has fit perfectly. And that means this is 0 so this r value or r squared value is 1. On the other hand, if this is equal to that, meaning that all of the variation in the estimates accounts for none of the variation in the data, then this is 1 and
2892	this goes to 0. So the idea is that an r-squared value is close to 1 is great. It says, the model is a good fit to the data. r-squared value is getting closer to 0, not so good.
2893	4, 8, and 16. Now you can see that model 2, that's the green line here. That's the one that we saw before. It's basically a parabolic kind of arc. It kind of follows the data pretty well. But if I look at those r-squared values. Wow, look at that. Order 16 fit accounts for all but 3% of the variation in the data. It's a great fit. And you can see. You can see how it follows. It actually goes through most, but not quite all, of the data points. So it's following them pretty well. OK, so if that's the case, the order 16 fit is really the best fit. Should we just use it? And I left you last time with that quote that says, from your parents, right, your mother telling you, just because you can do something doesn't mean you should do something. I'll leave it at that. Same thing applies here. Why are we building the model? Remember, I said two reasons. One is to be able to explain the phenomena. And the second
2894	one is to be able to make predictions. So I want to be able to explain the phenomena in the case of a spring, with things like it's linear and then that gives me a sense of a linear relationship between compression and force. In this case, a 16th order model, what kind of physical process has an order 16 variation? Sounds a little painful. So maybe not a great insight into the process. But the second reason is I want to be able to predict future behavior of this system. In the case of this spring, I put a different weight on than I've done before. I want to predict what the displacement is going to be. I've done a set of trials for an FDA approval of a drug. Now I want to predict the effect of a treatment on a new patient. How do I use the model to help me with that? One that maybe not so good, currently, I want to predict the outcome of an election. Maybe those models need to be fixed from,
2895	at least, what happened the last time around. But I need to be able to make the prediction. So another way of saying it is, a good model both explains the phenomena and let's me make the predictions. OK, so let's go back, then, to our example. And before I do it, let me tell you where that data came from. I actually built that data by looking at another kind of physical phenomenon. And it was a lot of them. Things that follow a parabolic arc. So for example, comets. Any particle under the influence of a uniform gravitational field follows a parabolic arc, which
2896	and then goes away off into the solar system, and comes back around. My favorite example-- I'm biased on this. And I know you all know which team I root for. But there is Tom Brady throwing a pass against the Pittsburgh Steelers. Center of mass of the past follows a nice parabolic arc. Even in design, you see parabolic arcs in lots of places. They have nice properties in terms of disbursement of loads and forces, which is why architects like to use them. So here's how I generated the data. I wrote a little function. Actually, I didn't. Professor Guttag did, but I borrowed it.
2897	ax squared plus bx plus c. I gave it a set of x values. Those are the independent measurements, the things along the horizontal axis. And notice what I did. I generated values given an a, b, and c, for that equation. And then I added in some noise. So random.guass takes a mean and a standard deviation, and it generates noise following that bell shaped curve that goes in the distribution. So the 0 says it's 0 mean, meaning there's no bias. It's going to be equally likely to be above or below the value, positive or negative. But 35 is a pretty good standard deviation. This is putting a lot of noise into the data. And then I just added that into y values. The rest of this, you can see, it's simply going to write it into a file, a set of x and y values. But this will generate, given a value for a, b, and c, data from a parabolic arc with noise added to it. And in this case, I took it as y
2898	"equals 3x squared. And then c and c are 0. And that's how I generated it. What I want to do, I want to see how well this model actually predicts behavior. So one of the ways I could do it, to say, all right, the question I want to ask is, whoa, if I generated the data from a degree 2 polynomial quadratic, why in the world is the 16th order polynomial the, ""best fit?"" So let's test it out. I'm going to give 3-- sorry, 4. I can't count. 4 different degrees, order 2, order 4, order 8, order 16. And I've generated two different datasets, using exactly that code. I just ran it twice. It's going to have slightly different values, because the noise is going to be different in each case. But they're both coming from that a, y equals 3x squared equation."
2899	I'm going to take those two data sets and basically, get the x and y values out, and then fit models. So I'll remind you, genFits takes in a collection of x and y values and a list or a tuple of degrees, and for each degree, finds, using Polyfit, the best model. So models one will be 4 models for order 2, 4, 8, and 16. And similarly, down here, I'm going to do the same thing, but using the second data set. And I'm going to fit, again, a set of models. And then I'll remind you, test fits, which you saw last time. I know it's a while ago, basically takes a set of models, a corresponding set of degrees, x and y values, and says, for each model in that degree, measure how well that model meets the fit, using that r-squared value. So testFits is going to get us back a set of r-squared values. All right, with that in mind, I've got the code here. Let's run it. And here we go. I'm going
2900	to run that code. Ha, I get two fits. Looks good. Let's look at the values.
2901	All right, the green line still is doing not a bad job. The purple line, boy, is fitting it really well. And again, notice here's the best fit. That's amazing. That is accounting for all but 0.4% of the variation in the data. Great fit. Order 16. Came from an order 2 thing. All right, what about the second data set? Oh, grumph. It also says order 16 fit is the best fit. Not quite as good. It accounts for all but about 2% of the variation. Again, the green line, the red line, do OK. But in this case, again, that purple line is still the best fit. So I've still got this puzzle. But I didn't quite test what I wanted, right? I said I want to see how well it predicts new behavior. Here what I did was I took two datasets, fit the model, and I got two different fits, one for each dataset. They both fit well for order 16. But they're not quite right. OK, so best fitting model is still order 16 but
2902	we know it came from an order 2 polynomial. So how could I will get a handle on seeing how good this model is? Well, what we're seeing here is coming from training error. Or another way of saying it is, what we're measuring is how well does the model perform on the data from which it was learned? How well do I fit the model to the training data? I want a small training error. And if you think about it, go back to the first example, when I fit a line to this data, it did not do well. It was not a good model. When I fit a quadratic, it was pretty decent. And then I got better and better as I went on. So I certainly need at least a small training error. But it's, to use the mathematical terms, a necessary, but not sufficient condition to get a great model. I need a small training error, but I really want to make sure that the model is capturing what I'd like. And so for that,
2903	I want to see how well does it do on other gen data, generated from the same process, whether it's weights on springs, different comets besides Haley's comet, different voters than those surveyed when we tried to figure out what's going to happen in an election. And I'm set up to do that, by using a really important tool called, validation or cross-validation. We set the stage, and then we're going to do the example. I'm going to get a set of data. I want to fit a model to it, actually, different models, different degrees, different kinds of models. To see how well they work, I want to see how well they predict behavior under other data than that from which I did the training. So I could do that right here.
2904	but test them on the other. And so in fact, I had one data set. I build a set of models for the first data set. I compared how well it did on that data set. But I could now apply it to the second dataset. How well does that account for that data set? And similarly, take the models I built for the second data set, and see how well they predict the points from the first dataset. What do I expect? Certainly, expect that the testing error is likely to be larger than the training error, because I train on one set of data. And that means this ought to be a better way to think about, how well does this model generalize? How well does it predict other behavior, besides what I started with. So here's the code I'm going to use.
2905	All I want to draw your attention to here is, remember, models one I built by fitting models of degree 2, 4, 8, and 16 to the first data set. And I'm going to apply those models to the second dataset, x vals 2 and y vals 2. Similarly, I'm going to take the models built for the second data set, and test them on the first dataset to see how well they fit. I know you're eagerly anticipating, as I've been setting this up for a whole week. All right, let's look at what happens when I do this. I'm going to run it. And then we'll look at the examples. If I go back over to Python and this code was distributed earlier, if you want to play with it yourself. Should be the right place to do it. I am going to run that code. Now I get something a little different. In fact, if I go look at it, here
2906	And we can both eyeball it and look at the numbers. Eyeballing it, there's that green line, still generally following the form of this pretty well. What about the purple line? The order 16 degree. Remember, that's the purple line from model 1, from training set 1. Wow, this misses a bunch of points, pretty badly. And in fact, look at the r-squared values. Order 2 and order 4, pretty good fit, accounts for all but about 14, 13% of the data. Look what happened to the degree 16, degrees 16 fit. Way down at last. 0.7. Last time around it was 0.997. What about the other direction? Taking the model built and the second data set, testing it on the first data set. Again, notice a nice fit for degree 2 and 4, not so good for degree 16. And just to give you a sense of this, I'm going to go back. There is the model one case. There is the model in the other case. You can see the model that accounts for variation in one doesn't
2907	account for the variation in the other, when I look at order 16 fit. OK, so what this says is something important. Now I can see. In fact, if I look back at this, if I were just looking at the coefficient of determination, this says, in order to predict other behavior, I'm better off with an order 2 or maybe order 4 polynomial. Those r-squared values are both the same. I happen to know it's order 2, because that's where I generated from. But that's a whole lot better than order 16. And what you're seeing here is an example of something that happens a lot in statistics. And in fact, I would suggest is often misused in fitting data to statistical samples. It's called overfitting. And what it means is I've let there be too many degrees of freedom in my model, too many free parameters. And what it's fitting isn't just the underlying process. It's also fitting to the noise. The message I want you to take out of this part of the lecture is, if we
2908	only fit the model to training data, and we look at how well it does, we could get what looks like a great fit, but we may actually have come up with far too complex a model. Order 16 instead of order 2. And the only way you are likely to detect that is to train on one test set and test on a different. And if you do that, it's likely to expose whether, in fact, I have done a good job of fitting or whether I have overfit to the data. There are lots of horror stories in the literature, especially from early days of machine learning of people overfitting to data and coming up with models that they thought wonderfully predicted an effect, and then when it ran on new data really hit the big one. All right, so this is something you want to try and stay away from. And the best way to do it is to do validation.
2909	The upper left is my training data, dataset one. There's the set of models. This is now taking that and applying it to a different dataset from the same process. And notice for the degree to polynomial, the coefficient of determination, 0.86, now 0.87. The fact that it's slightly higher is just accidental. But it's really about the same level. It's doing the same kind of drop on the training data and on the test data. On the other hand, degree 16, coefficient of determination is a wonderful 0.96 here and a pretty awful 9 down there. And that's a sign that we're not in good shape, when in fact our coefficient of determination drops significantly when we try and handle new data. OK, so why do we get a better fit on the training data with a higher order model, but then do less well when we're actually handling new data? Or another way of saying it is, if I started out with, in the case of that with that data, a linear model it didn't fit well, and
2910	then I got to a quadratic model, why didn't that quadratic model still say [INAUDIBLE]? Why was it the case that, as I added more degrees of freedom, I did better. Or another way of asking it is, can I actually get a worse fit to training data as I increase the model complexity? And I see at least one negative head shake. Thank you. You're right. I cannot. Let's look at why. If I add in some higher order terms, and they actually don't matter. If I got perfect data, the coefficient will just be 0. The fit will basically say, this term doesn't matter. Ignore it. And that'll work in perfect data. But if the data is noisy, what the model is going to do is actually start fitting the noise. And while it may lead to a better r-squared value, it's not really a better fit. Right, let me show you an example of that. I'm going to fit a quadratic to a straight line. Easy thing to do. But I want to show you the effect
2911	of overfitting or adding in those extra terms. So let me say it a little bit better. I'm going to start off with this 3, sorry, 3.
2912	4 simple values, 0, 1, 2, 3. The y values are the same as x values. So this is 0,0, 1, 1, 2, 2, 3 3. They're all lying on a line. But I'm going to fit. I'm going to plot them out. And then I'm going to fit a quadratic. y if it equals ax squared plus bx plus c to this. Now I know it's a line, but I want to see what happens if I fit a quadratic. So I'm going to use polyfit to fit my quadratic. I'm going to print out some data about it. And then I'm going to use Polyval to estimate what those values should be. Plot them out. And then compute r squared value, and see what happens. All right, OK, and let me set this up better. What am I doing? I want to just fit it to a line. I know it's a line, but I'm going to fit a quadratic to it. And what I'd expect is, even though there's an extra term there, it shouldn't matter. So
2913	if I go to Python, and I run this, I run exactly that example, look at that. a equals 0, b is 1, c equals 0. Look at the r-squared value. I'll pull that together for you. It says, in this perfect case, there's what I get. The blue line is drawn through the actual values. The dotted red line is drawn through the predicted values. They exactly line up. And in fact, the solution implied says, the higher order term coefficient 0, it doesn't matter. So what it found was y equals x. I know you're totally impressed I could find a straight line. But notice what happened there. I dropped or that system said, you don't need the higher order term. Wonderful r-squared value. OK, let's see how well it predicts. Let's add in one more point, out at 20. So this is 0, 1, 2, 3. That's 0, 1, 2, 3. I'm going to add 20 in there, so it's 0, 0 , 1, 2, 2, 3, 3, 20, 20. Again, I can estimate using the same
2914	model. So I'm not recomputing the model, the model I predicted from using those first set of four points. I can get the estimated y values, plot those out, and you again, compute the r-squared value here. And even adding that point in, there's the line. And guess what. Perfectly predicts it. No big surprise. So it says, in the case of perfect data, adding the higher order terms isn't going to cause a problem. The system will say coefficients are 0. That's all I need. All right, now, let's go back and add in just a tiny bit of noise right there. 0, 0, 1, 1, 2, 2, and 3, 3.1. So I've got a slight deviation in the y value there. Again, I can plot them. I'm going to fit a quadratic to them. I'm going to print out some information about it and then get the estimated values using that new model to see what it should look like. I'm not going to run it. I'm going to show you the result.
2915	And there's the equation it comes up with. Not so bad, right? It's almost y equal to x. But because of that little bit of noise there, there's a small second order term here and a little constant term down there. The y squared value is really pretty good. And if you really squint and look carefully at this, you'll actually see there's a little bit of a deviation between the red and the blue line. It undershoots-- sorry, overshoots there, undershoots here, but it's really pretty close. All right, so am I just whistling in the dark here? What's the difference? Well, now let's add in that extra point. And what happens?
2916	2, 2, 3, and 3.1. I'm going to do 20, 20. Using the model I captured from fitting to that first set, I want to see what happens here. Crap. I'm sorry. Shouldn't say that. Darn. Pick up some other word. Shouldn't surprise you, right? A small variation here is now causing a really large variation up there. And this is why the ideal case overfitting is not a problem, because the coefficients get zeroed out. But even a little bit of noise can cause a problem. Now I'll grant you, we set this up deliberately to show a big effect here. But a 3% error in one data point is causing a huge problem when I get further out on this curve. And by the way, there is the r-squared values. It's 0.7. It doesn't do a particularly good job OK, so how would I fix this? Well, what if I had simply done a first degree fit, same situation. Let's say fit a line to this rather than fitting a quadratic. Remember, my question was, what's the harm
2917	of fitting a higher order model if the coefficients would be zeroed out? We've seen they won't be zeroed out. But if I were just to have fit a line to this, exactly the same experiment, 0, 0, 1, 1, 2, 2, 3, and 3.1, 20 and 20. Now you can see it still does a really good job of fitting. The r-squared value is 0.9988. So again, fitting the right level of model, the noise doesn't cause nearly as much of a problem. And so just to pull that together, basically it says,
2918	is much better than the second order model. And that's why, in this case, I would want to use that first order model. So take home message. And then we're going to amplify this. If I pick an overly complex model, I have the danger of overfitting to the training data, overfitting meaning that I'm not only fitting the underlying process, I'm fitting the noise. I get an order 16 model is the best fit when it's in fact, in order 2 model that was generating it. That increases the risk that it's not going to do well with the data, not what I'd like. I want to be able to predict what's going to go on well here. On the other hand. So that would say, boy, just stick with the simplest possible model. But there's a trade off here. And we already saw that when I tried to fit a line to a data that was basically quadratic. I didn't get a good fit. So I'd want to find the balance. An insufficiently complex model won't explain the
2919	"data well. An overly complex model will overfit the training data. So I'd like to find the place where the model is as simple as possible, but still explains the data. And I can't resist the quote from Einstein that captures it pretty well, ""everything should be made as simple as possible, but not simpler."" In the case of where I started, it should be fit to a quadratic, because it's the right fit. But don't fit more than that, because it's getting overly complex Now how might we go about finding the right model? We're not going to dwell on this but here is a standard way in which you might do it. Start with a low order model. Again, take that data. Fit a linear model to it. Look at not only the r-squared value, but see how well it accounts for new data. Increase the order of the model. Repeat the process. And keep doing that until you find a point at which a model does a good job both on the training data and on predicting"
2920	new data. An after it starts to fall off, that gives you a point where you might say there's a good sized model. In the case of this data, whether I would have stopped at a quadratic or I might have used a cubic or a quartic depends on the values. But I certainly wouldn't have gone much beyond that. And this is one way, if you don't have a theory to drive you, to think about, how do I actually fit the model the way I would like. Let's go back to where we started. We still have one more big topic to do, and we still have a few minutes left. But let's go back to where we started Hooke's law. There was the data from measuring displacements of a spring, as I added different weights to the bottom of the spring. And there's the linear fit. It's not bad. There's the quadratic fit. And it's certainly got a better r-squared value, though. That could be just fitting to the noise. But you actually can see, I think,
2921	that that green curve probably does a better job of fitting the data. Well, wait a minute. Even though the quadratic fit is tighter here, Hooke says, this is linear. So what's going on? Well, this is another place where you want to think about your model. And I'll remind you, in case you don't remember your physics, unless we believe that Hooke was wrong, this should tell us something. And in particular, Hooke's law says, the model holds until you reach the elastic limit of the spring. You stretch a slinky too far, it never springs back. You go beyond that elastic limit. And that's probably what's happening right up there. Through here, it's following that linear relationship. Up at this point, I've essentially broken the spring. The elastic limit doesn't hold anymore. And so really, in this case, I should probably fit different models to different segments. And there's a much better fit. Linear through the first part and another later line once I hit that elastic limit. How might I find this? Well, you could imagine a
2922	little search process in which you try and find where's the best place along here to break the data into two sets, fit linear segments to both, and get really good fits for both examples. And I raise it because that's the kind of thing you've also seen before. You could imagine writing code to do that search to find that good fit. OK, that gives you a sense, then, of why you want to be careful about overfitting, why you want to not just look at the coefficient of determination, but see how well does this predict behavior on new data sets. Now suppose I don't have a theory, like Hooke, to guide me. Can I still figure out what's a good model to fit to the data? And the answer is, you bet. We're going to use cross-validation to guide the choice of the model complexity. And I want to show you two examples. If the data set's small, we can use what's called leave one out cross-validation. I'll give you a definition of that in a second.
2923	If the data sets bigger than that, we can use k-fold cross-validation. I'll give you a definition that a second. Or just what's called, repeated random sampling. But we can use this same idea of validating new data to try and figure out whether the model is a good model or not. Leave one out cross-validation. This is as written in pseudocode, but the idea is pretty simple. I'm given a dataset.
2924	The idea is to walk through a number of trials, number trials equal to the size of the data set. And for each one, take the data set or a copy of it, and drop out one of the samples. So leave one out. Start off by leaving out the first one, then leaving out the second one, and then leaving out the third one. For each one of those training sets, build the model. For example, by using linear regression. And then test that model on that data point that you left out. So leave out the first one, build a model on all of the other ones, and then see how well that model predicts the first one. Leave out the second one, build a model using all of them but the second one, see how well it predicts the second one. And just average the result. Works when you don't have a really large data set, because it won't take too long. But it's a nice way of actually testing validation. If the data set's a lot
2925	bigger, you can still use the same idea. You can use what's called, k-fold. Divide the data set up into k equal sized chunks. Leave one of them out. Use the rest to build the model. And then use that model to predict that first chunk you left out. Leave out the second chunk, and keep doing it. Same idea, but now with groups of things rather than just leaving those single data points. All right, the other way you can deal with it, which has a nice effect to it, is to use what's called, repeated random sampling. OK, start out with some data set. And what I'm going to do here is I'm
2926	I'm going to call that, k. But I'm also going to pick some number of random samples from the data set. Usually, I think, and as I recall, it is somewhere between reserving 20% to 50% of the samples. But the idea is again, walk over all of those k trials. And in each one, pick out at random n elements for the test set. Use the remainder is the training set. Build the model on the training set. And then apply that model to the test set. So rather than doing k-fold, where I select k, in turn, and keep them. This is just randomly selecting which ones to pull out. So I'm going to show you one last example. Let's look at that idea of, I don't have a model here. I want to use this idea of cross-validation to try and figure out what's the best possible model. And for this, I'm going to use a different data set. The data set here is I want to model or the task here is I want to try
2927	model how the mean daily high temperature in the US has varied over about a 55 year period, from '61 to 2015. Got a set of data. It's mean-- sorry, the daily high for every day of the year through that entire period. And what I'm going to do is I'm going to compute the means for each year and plot them out. And then I'm going to try and fit models to them. And in particular, I'm going to take a set of different dimensionalities, linear, quadratic, cubic, quartic And in each case, I'm going to run through a trial where I train on one half of the data, test on the other. There again, is that idea of seeing how well it predicts other data. Record the coefficient of determination. And do that and get out an average, and report what I get as the mean for each of those values across each dimensionality. OK, here we go. Set a code that's pretty easy to see. Hopefully, you can just look at it and grok it. We start
2928	off with a boring class, which Professor guttag suggests refers to this lecture. But it doesn't. This may be a boring lecture, but it's not a boring class. This is a great class. And boy, those jokes are really awful, aren't they? But here we go. Simple class that builds temperature data. This reads in some information, splits it up, and basically, records the high for the day and the year in which I got that. So for each day, I've got a high temperature for that day. I'm going to give you back the high temperature and the year in which it was recorded, because I don't care whether it was in January or June. A little function that opens up a file. We've actually given you a file, if you want to go look at it. And simply walk through the file reading it in and returning a big list of all those data objects. OK, then what I want to do is I want to get the mean high temperature for each year. Given that data, I'm
2929	going to set up a dictionary called, years. I'm just going to run through a loop through all the data points, where in the dictionary, under that year. So there a data point. I use the method get year to get out the year. At that point, I add in the high temperature corresponding to that data point. And I'm using that nice little try except loop. I'll do that, unless I haven't had anything yet for this year, in which case this'll fail. And I'll simply store the first one in as a list. So after I've run through this loop in the dictionary, under the year, I have a list of the high temperatures for each day associated with it. Excuse me. And then I can just compute the average, that is for each year in the years. I get that value. I add them up. I get the length. I divide them out. And I store that in as the average high temperature for the year. Now I can plot it. Get the data, get out the
2930	information by computing those yearly means, run through a little loop that basically, in the x values, puts in the year, in the y values, puts in the high temperature. And I can do a plot. And if I do that, I get that. I'll let you run this yourself. Now this is a little bit deceptive, because of the scale I've used here. But nonetheless, it shows, in the US, over a 55 year period, the mean high day-- I'm sorry. The mean daily high has gone from about 15.5 degrees Celsius up to about 17 and 1/2. So what's changed? Now the question is, how could I model this? Could I actually get a model that would give me a sense of how this is changing? And that's why I'm going to use cross-validation.
2931	I'm going to try and fit four different models, linear, quadratic, cubic, quartic. And for each of these dimensions, I'm going to get out a set of r-squared values. So I'm just going to initialize that dictionary. an empty list. Now here is how I'm going to do this. Got a list of x-values. Those are years. Got a list of y values. Those are average highs, daily highs. I'm going to create a list of random samples. So if you haven't seen this before, random.sample says, given this iterator, which you can think of as the collection from 0 up to n minus 1, it's going to select this many or half of them, in this case, of those numbers at random. So if I give it 0 up to 9, and I say, pick five of them, it will, at random, give me back 5 of those 10 numbers, with no duplicates. Ah, that's nice. Because now notice what I can do. I'm going to set up a training-- sorry, an x and y values for a training
2932	set, x and y values for the test set. And I'm just going to run through a loop here, where if this index is in that list, I'll stick it in the training set. Otherwise, I'll stick it in the test set. And then I just return them. So this is a really nice way of, at random, just splitting the data set into a test set and a training set.
2933	I want to deal with. In each case, get a different training and test set, at random. And then, for each dimension, do the fit. There's polyfit on the training x and training y values in that dimension. Gives you back a model. I could just check to see how well the training set gets, but I really want to look at, given that model, how well does polyval predict the test set, right? The model will say, here's what I expect is the values. I'm going to compare that to the actual values that I saw from the training set, computing that r squared value and adding it in. And then the last of this just says, I'll run this through a set of examples. OK, here's what happens if I do that. I'm not going to run it, although the code will run it. Let me, again, remind you what I'm doing. I got a big set of data I'm going to pick out at random, subsets of it, build the model on one part, test it on
2934	the other part. And if I run it, I get a linear fit, quadratic fit, cubic fit, and a quartic fit. And here's the standard deviation of those samples. Remember, I've got multiple trials. I've got 10 trials, in this case. So this gives me the average over those trials. And this tells me how much they vary. What can I conclude from this? Well, I would argue that the linear fit's probably the winner here. Goes back to Einstein. I want the simplest possible model that accounts for it. And you can see it's got the highest r-squared value, which is already a good sign. It's got the smallest deviation across the trials, which says it's probably a pretty good fit. And it's the simplest model. So linear sounds like a pretty good fit. Now, why should we run multiple data sets to test this? I ran 10 trials of each one of these dimensions. Why bother with it? Well, notice that those deviations-- I'll go back to it here-- they're pretty good. They're about an order of magnitude
2935	less than the actual mean, which says they're pretty tight, but they're still reasonable size. And that suggests that, while there's good agreement, the deviations are large enough that you could see a range of variation across the trials. So in fact, if I had just run one trial, I could have been screwed. Sorry, oh-- sorry, pick your favorite [INAUDIBLE] here. [? Hose ?] is a Canadian expression, in case you haven't seen it. Here are the r-squared values for each trial of the linear fit. And you can see the mean comes up pretty well. But notice, if I'd only run one trial and I happened to get that one, oh, darn. That's a really low r-squared value. And we might have decided, in this case, a different conclusion, that the linear fit was not a good fit. So this is a way of saying, even in a random sampling, run multiple trials, because it lets you get statistics on those trials, as well as statistics within each trial. So with any trial, I'm doing a whole bunch
2936	of different random samples on measuring those values. And then, across those trials, I'm seeing what the deviation is. I'm going to hope my machine comes back, because what I want to do is then pull this together. What have we done? Something you're going to use. We've seen how you can use linear regression to fit a curve to data, 2D, 3D, 6D, however big the data set is. It gives us a mapping from the independent values to the dependent values. And that can then be used to predict values associated with the independent values that we haven't seen yet. That leads, naturally, to both a way to measure, which is r squared, but especially to see that we want to look at how well does that model actually predict new data, because that lets us select the simplest model we can that accounts for the data, but predicts new data in an effective way. And that complexity can either be based on theory, in the case of Hooke, or in more likely cases, by doing cross-validation to
2937	try and figure out which one is the simplest model that still does a good job of predicting out of data behavior. And with that, I'll see you next time.
2938	The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation, or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu.
2939	JOHN GUTTAG: Hello, everybody. Some announcements. The last reading assignment of the semester, at least from us. Course evaluations are still available through this Friday. But only till noon. Again, I urge you all to do it. And then finally, for the final exam, we're going to be giving you some code to study in advance of the exam. And then we will ask questions about that code on the exam itself. This was described in the announcement for the exam. And we will be making this code available later today. Now, I would suggest that you try and get your heads around it. If you are confused, that's a good thing to talk about in office hours, to get some help with it, as opposed to waiting till 20 minutes before the exam and realizing you're confused. All right. I want to pick up where we left off on Monday. So you may recall that we were comparing results of KNN and logistic regression on our Titanic data. And we have this up using 10 80/20 splits for KNN
2940	equals 3 and logistic regression with p equals 0.5. And what I observed is that logistic regression happened to perform slightly better, but certainly nothing that you would choose to write home about. It's a little bit better. That isn't to say it will always be better. It happens to be here. But the point I closed with is one of the things we care about when we use machine learning is not only our ability to make predictions with the model. But what can we learn by studying the model itself? Remember, the idea is that the model is somehow capturing the system or the process that generated the data. And by studying the model we can learn something useful.
2941	"So to do that for logistic regression, we begin by looking at the weights of the different variables. And we had this up in the last slide. The model classes are ""Died"" and ""Survived."" For the label Survived, we said that if you were in a first-class cabin, that had a positive impact on your survival, a pretty strong positive impact. You can't interpret these weights in and of themselves. If I said it's 1.6, that really doesn't mean anything. So what you have to look at is the relative weights, not the absolute weights. And we see that it's a pretty strong relative weight. A second-class cabin also has a positive weight, in this case, of 0.46. So it was indicating you better had a better-than-average chance of surviving, but much less strong than a first class. And if you are one of those poor people in a third-class cabin, well, that had a negative weight on survival. You were less likely to survive. Age had a very small effect here, slightly negative. What that meant is the older"
2942	you were, the less likely you were to have survived. But it's a very small negative value. The male gender had a relatively large negative gender, suggesting that if you were a male you were more likely to die than if you were a female. This might be true in the general population, but it was especially true on the Titanic. Finally, I warned you that while what I just went through is something you will read in lots of papers that use machine learning, you will hear in lots of talks about people who have used machine learning. But you should be very wary when people speak that way. It's not nonsense, but some cautionary notes. In particular, there's a big issue because the features are often correlated with one another. And so you can't interpret the weights one feature at a time. To get a little bit technical, there are two major ways people use logistic regression. They're called L1 and L2. We used an L2. I'll come back to that in a minute. Because that's the default
2943	in Python, or in [INAUDIBLE]. You can set that parameter at L2 and do that to L1 if you want. I experimented with it. It didn't change the results that much. But what an L1 regression is designed to do is to find some weights and drive them to 0. This is particularly useful when you have a very high-dimensional problem relative to the number of examples. And this gets back to that question we've talked about many times, of overfitting. If you've got 1,000 variables and 1,000 examples, you're very likely to overfit. L1 is designed to avoid overfitting by taking many of those 1,000 variables and just giving them 0 weight. And it does typically generalize better. But if you have two variables that are correlated, L1 will drive 1 to 0, and it will look like it's unimportant. But in fact, it might be important. It's just correlated with another, which has gotten all the credit. L2, which is what we did, does the opposite. Is spreads the weight across the variables. So have a bunch of
2944	correlated variables, it might look like none of them are very important. Because each of them gets a small amount of the weight. Again, not so important when you have four or five variables, is what I'm showing you. But it matters when you have 100 or 1,000 variables. Let's look at an example. So the cabin classes, the way we set it up, c1 plus c2 plus c3-- whoops-- is not equal to 0. What is it equal to? I'll fix this right now. What should that have said? What's the invariant here? Well, a person is in exactly one class. I guess if you're really rich, maybe you rented two cabins, one in first and one in second. But probably not. Or if you did, you put your servants in second or third. But what does this got to add up to? Yeah? AUDIENCE: 1. JOHN GUTTAG: Has to add up to 1. Thank you. So it adds up to 1. Whoa. Got his attention, at least. So what this tells us is the values are not independent.
2945	Because if c1 is 1, then c2 and c3 must be 0. Right? And so now we could go back to the previous slide and ask the question well, is it that being in first class is protective? Or is it that being in second or third class is risky? And there's no simple answer to that. So let's do an experiment. We have these correlated variables. Suppose we eliminate c1 altogether. So I did that by changing the init method of class passenger. Takes the same arguments, but we'll look at the code. Because it's a little bit clearer there. So there was the original one. And I'm going to replace that by this. combine that with the original one. So what you see is that instead of having five features, I now have four. I've eliminated the c1 binary feature. And then the code is straightforward, that I've just come through here, and I've just enumerated the possibilities. So if you're in first class, then second and third are both 0. Otherwise, one of them is a 1.
2946	So my invariant is gone now, right? It's not the case that we know that these two things have to add up to 1, because maybe I'm in the third case. OK, let's go run that code and see what happens. Well, if you remember, we see that our accuracy has not really declined much. Pretty much the same results we got before. But our weights are really quite different. Now, suddenly, c2 and c3 have large negative weights. We can look at them side by side here. So you see, not much difference. It actually performs maybe-- well, really no real difference in performance. But you'll notice that the weights are really quite different. That now, what had been a strong positive weight and relatively weak negative weights is now replaced by two strong negative weights. And age and gender change just a little bit. So the whole point here is that we have to be very careful, when you have correlated features, about over-interpreting the weights. It is generally pretty safe to rely on the sign, whether it's
2947	negative or positive. All right, changing the topic but sticking with logistic regression, there is this parameter you may recall, p, which is the probability. And that was the cut-off. And we set it to 0.5, saying if it estimates the probability of survival to be 0.5 or higher, then we're going to guess survived, predict survived. Otherwise, deceased. You can change that. And so I'm going to try two extreme values, setting p to 0.1 and p to 0.9. Now, what do we think that's likely to change? Remember, we looked at a bunch of different attributes. In particular, what attributes do we think are most likely to change? Anyone who has not answered a question want to volunteer? I have nothing against you, it's just I'm trying to spread the wealth. And I don't want to give you diabetes, with all the candy. All right, you get to go again. AUDIENCE: Sensitivity. JOHN GUTTAG: Pardon? AUDIENCE: The sensitivity and specificity. JOHN GUTTAG: Sensitivity and specificity, positive predictive value. Because we're shifting. And we're saying, well, by changing the
2948	probability, we're making a decision that it's more important to not miss survivors than it is to, say, ask gets too high. So let's look at what happens when we run that. I won't run it for you. But these are the results we got. So as it happens, 0.9 gave me higher accuracy. But the key thing is, notice the big difference here. So what is that telling me? Well, it's telling me that if I predict you're going to survive you probably did. But look what it did to the sensitivity. It means that most of the survivors, I'm predicting they died. Why is the accuracy still OK? Well, because most people died on the boat, on the ship, right? So we would have done pretty well, you recall, if we just guessed died for everybody. So it's important to understand these things. I once did some work using machine learning for an insurance company who was trying to set rates. And I asked them what they wanted to do. And they said they didn't want to lose
2949	money. They didn't want to insure people who were going to get in accidents. So I was able to change this p parameter so that it did a great job. The problem was they got to write almost no policies. Because I could pretty much guarantee the people I said wouldn't get in an accident wouldn't. But there were a whole bunch of people who didn't, who they wouldn't write policies for. So they ended up not making any money. It was a bad decision. So we can change the cutoff. That leads to a really important concept of something called the Receiver Operating Characteristic. And it's a funny name, having to do with it originally going back to radio receivers. But we can ignore that. The goal here is to say, suppose I don't want to make a decision about where the cutoff is, but I want to look at, in some sense, all possible cutoffs and look at the shape of it. And that's what this code is designed to do. So the way it works is I'll
2950	take a training set and a test set, usual thing. I'll build one model. And that's an important thing, that there's only one model getting built. And then I'm going to vary p. And I'm going to call apply model with the same model and the same test set, but different p's and keep track of all of those results. I'm then going to plot a two-dimensional plot. The y-axis will have sensitivity. And the x-axis will have one minus specificity. So I am accumulating a bunch of results. And then I'm going to produce this curve calling sklearn.metrics.auc, that's not the curve. AUC stands for Area Under the Curve. And we'll see why we want to get that area under the curve. When I run that, it produces this. So here's the curve, the blue line. And there's some things to note about it. Way down at this end I can have 0, right? I can set it so that I don't make any predictions. And this is interesting. So at this end it is saying what? Remember that
2951	my x-axis is not specificity, but 1 minus specificity. So what we see is this corner is highly sensitive and very unspecific. So I'll get a lot of false positives. This corner is very specific, because 1 minus specificity is 0, and very insensitive. So way down at the bottom, I'm declaring nobody to be positive. And way up here, everybody. Clearly, I don't want to be at either of these places on the curve, right? Typically I want to be somewhere in the middle. And here, we can see, there's a nice knee in the curve here. We can choose a place. What does this green line represent, do you think? The green line represents a random classifier. I flip a coin and I just classify something positive or negative, depending on the heads or tails, in this case. So now we can look at an interesting region, which is this region, the area between the curve and a random classifier. And that sort of tells me how much better I am than random. I can look at the
2952	whole area, the area under the curve. And that's this, the area under the Receiver Operating Curve. In the best of all worlds, the curve would be 1. That would be a perfect classifier. In the worst of all worlds, it would be 0. But it's never 0 because we don't do worse than 0.5. We hope not to do worse than random. If so, we just reverse our predictions. And then we're better than random. So random is as bad as you can do, really. And so this is a very important concept. And it lets us evaluate how good a classifier is independently of what we choose to be the cutoff. So when you read the literature and people say, I have this wonderful method of making predictions, you'll almost always see them cite the AUROC.
2953	Any questions about this or about machine learning in general? If so, this would be a good time to ask them, since I'm about to totally change the topic. Yes? AUDIENCE: At what level does AUROC start to be statistically significant? And how many data points do you need to also prove that [INAUDIBLE]? JOHN GUTTAG: Right. So the question is, at what point does the AUROC become statistically significant? And that is, essentially, an unanswerable question. Whoops, relay it back. Needed to put more air under the throw. I look like the quarterback for the Rams, if you saw them play lately. So if you ask this question about significance, it will depend upon a number of things. So you're always asking, is it significantly better than x? And so the question is, is it significantly better than random? And you can't just say, for example, that 0.6 isn't and 0.7 is. Because it depends how many points you have. If you have a lot of points, it could be only a tiny bit better than 0.5 and still
2954	be statistically significant. It may be uninterestingly better. It may not be significant in the English sense, but you still get statistical significance. So that's a problem when studies have lots of points. In general, it depends upon the application. For a lot of applications, you'll see things in the 0.7's being considered pretty useful. And the real question shouldn't be whether it's significant, but whether it's useful. Can you make useful decisions based upon it? And the other thing is, typically, when you're talking about that, you're selecting some point and really talking about a region relative to that point. We usually don't really care what it does out here. Because we hardly ever operate out there anyway. We're usually somewhere in the middle. But good question. Yeah? AUDIENCE: Why are we doing 1 minus specificity? JOHN GUTTAG: Why are we doing 1 minus specificity instead of specificity? Is that the question? And the answer is, essentially, so we can do this trick of computing the area. It gives us this nice curve. This nice, if you will, concave
2955	curve which lets us compute this area under here nicely if you were to take specificity and just draw it, it would look different. Obviously, mathematically, they're, in some sense, the same right. If you have 1 minus x and x, you can get either from the other. So it really just has to do with the way people want to draw this picture. AUDIENCE: [INAUDIBLE]? JOHN GUTTAG: Pardon? AUDIENCE: Does that not change [INAUDIBLE]? JOHN GUTTAG: Does it not-- AUDIENCE: Doesn't it change the meaning of what you're [INAUDIBLE]? JOHN GUTTAG: Well, you'd have to use a different statistic. You couldn't cite the AUROC if you did specificity directly. Which is why they do 1 minus. The goal is you want to have this point at 0 and this 0.00 and 1.1. And playing 1 minus gives you this trick, of anchoring those two points. And so then you get a curve connecting them, which you can then easily compare to the random curve. It's just one of these little tricks that statisticians like to play to make things
2956	easy to visualize and easy to compute statistics about. It's not a fundamentally important issue.
2957	"Anything else? All right, so I told you I was going to change topics-- finally got one completed-- and I am. And this is a topic I approach with some reluctance. So you have probably all heard this expression, that there are three kinds of lies, lies, damn lies, and statistics. And we've been talking a lot about statistics. And now I want to spend the rest of today's lecture and the start of Wednesday's lecture talking about how to lie with statistics. So at this point, I usually put on my ""Numbers Never Lie"" hat. But do say that numbers never lie, but liars use numbers. And I hope none of you will ever go work for a politician and put this knowledge to bad use. This quote is well known. It's variously attributed, often, to Mark Twain, the fellow on the left. He claimed not to have invented it, but said it was invented by Benjamin Disraeli. And I prefer to believe that, since it does seem like something a Prime Minister would invent. So let's think about"
2958	this. The issue here is the way the human mind works and statistics. Darrell Huff, a well-known statistician
2959	"says, ""if you can't prove what you want to prove, demonstrate something else and pretend they are the same thing. In the daze that follows the collision of statistics with the human mind, hardly anyone will notice the difference."" And indeed, empirically, he seems to be right. So let's look at some examples. Here's one I like. This is from another famous statistician called Anscombe. And he invented this thing called Anscombe's Quartet. I take my hat off now. It's too hot in here. A bunch of numbers, 11 x, y pairs. I know you don't want to look at the numbers, so here are some statistics about them. Each of those pairs has the same mean value for x, the same mean for y, the same variance for x, the same variance for y. And then I went and I fit a linear regression model to it. And lo and behold, I got the same equation for everyone, y equals 0.5x plus 3. So that raises the question, if we go back, is there really much difference between these"
2960	pairs of x and y? Are they really similar? And the answer is, that's what they look like if you plot them. So even though statistically they appear to be kind of the same, they could hardly be more different, right? Those are not the same distributions. So there's an important moral here, which is that statistics about data is not the same thing as the data itself. And this seems obvious, but it's amazing how easy it is to forget it. The number of papers I've read where I see a bunch of statistics about the data but don't see the data is enormous. And it's easy to lose track of the fact that the statistics don't tell the whole story. So the answer is the old Chinese proverb, a picture is worth a thousand words, I urge you, the first thing you should do when you get a data set, is plot it. If it's got too many points to plot all the points, subsample it and plot of subsample. Use some visualization tool to look at the
2961	data itself. Now, that said, pictures are wonderful. But you can lie with pictures. So here's an interesting chart. These are grades in 6.0001 by gender. So the males are blue and the females are pink. Sorry for being such a traditionalist. And as you can see, the women did way better than the men. Now, I know for some of you this is confirmation bias. You say, of course. Others say, impossible, But in fact, if you look carefully, you'll see that's not what this chart says at all. Because if you look at the axis here, you'll see that actually there's not much difference. Here's what I get if I plot it from 0 to 5. Yeah, the women did a little bit better. But that's not a statistically-significant difference. And by the way, when I plotted it last year for 6.0002, the blue was about that much higher than the pink. Don't read much into either of them. But the trick was here, I took the y-axis and ran it from 3.9 to 4.05. I cleverly chose
2962	my baseline in such a way to make the difference look much bigger than it is. Here I did the honest thing of put the baseline at 0 and run it to 5. Because that's the range of grades at MIT. And so when you look at a chart, it's important to keep in mind that you need to look at the axis labels and the scales.
2963	Let's look at another chart, just in case you think I'm the only one who likes to play with graphics. This is a chart from Fox News. And they're arguing here. It's the shocking statistics that there are 108.6 million people on welfare, and 101.7 with a full-time job. And you can imagine the rhetoric that accompanies this chart. This is actually correct. It is true from the Census Bureau data. Sort of. But notice that I said you should read the labels on the axes. There is no label here. But you can bet that the y-intercept is not 0 on this. Because you can see how small 101.7 looks like. So it makes the difference look bigger than it is. Now, that's not the only funny thing about it. I said you should look at the labels on the x-axis. Well, they've labeled them. But what do these things mean? Well, I looked it up, and I'll tell you what they actually mean. People on welfare counts the number of people in a household in which at least
2964	one person is on welfare. So if there is say, two parents, one is working and one is collecting welfare and there are four kids, that counts as six people on welfare. People with a full-time job, is actually does not count households. So in the same family, you would have six on the bar on the left, and one on the bar on the right. Clearly giving a very different impression. And so again, pictures can be good. But if you don't dive deep into them, they really can fool you. Now, before I should leave this slide, I should say that it's not the case that you can't believe anything you read on Fox News. Because in fact, the Red Sox did beat the St. Louis Cardinals 4 to 2 that day. So the moral here is to ask whether the things being compared are actually comparable. Or you're really comparing apples and oranges,
2965	OK, this is probably the most common statistical sin. It's called GIGO. And perhaps this picture can make you guess what the G's stand for GIGO is Garbage In, Garbage Out. So here's a great, again, quote about it. So Charles Babbage designed the first digital computer, the first actual computation engine. He was unable to build it. But hundreds of years after he died one was built according to his design, and it actually worked. No electronics, really. So he was a famous person. And he was asked by Parliament about his machine, which he was asking them to fund. Well, if you put wrong numbers into the machine, will the machine have right numbers come out the other end? And of course, he was a very smart guy. And he was totally baffled. This question seems so stupid, he couldn't believe anyone would even ask it. That it was just computation. And the answers you get are based on the data you put in. If you put in garbage, you get out garbage. So here is an example
2966	from the 1840s. They did a census in the 1840s. And for those of you who are not familiar with American history, it was a very contentious time in the US. The country was divided between states that had slavery and states that didn't. And that was the dominant political issue of the day. John Calhoun, who was Secretary of State and a leader in the Senate, was from South Carolina and probably the strongest proponent of slavery. And he used the census data to say that slavery was actually good for the slaves. Kind of an amazing thought. Basically saying that this data claimed that freed slaves were more likely to be insane than enslaved slaves. He was rebutted in the House by John Quincy Adams, who had formerly been President of the United States. After he stopped being President, he ran for Congress. From Braintree, Massachusetts. Actually now called Quincy, the part he's from, after his family. And he claimed that atrocious misrepresentations had been made on a subject of deep importance.
2967	So you don't even have to look at that statistics to know who to believe. Just look at these pictures. Are you going to believe this nice gentleman from Braintree or this scary guy from South Carolina? But setting looks aside, Calhoun eventually admitted that the census was indeed full of errors. But he said that was fine. Because there were so many of them that they would balance each other out and lead to the same conclusion, as if they were all correct. So he didn't believe in garbage in, garbage out. He said yeah, it is garbage. But it'll all come out in the end OK. Well, now we know enough to ask the question. This isn't totally brain dead, in that we've already looked at experiments and said we get experimental error. And under some circumstances, you can manage the error. The data isn't garbage. It just has errors. But it's true if the measurement errors are unbiased and independent of each other. And almost identically distributed on either side of the mean, right? That's why we
2968	spend so much time looking at the normal distribution, and why it's called Gaussian. Because Gauss said, yes, I know I have errors in my astronomical measurements. But I believe my errors are distributed in what we now call a Gaussian curve. And therefore, I can still work with them and get an accurate estimate of the values. Now, of course, that wasn't true here. The errors were not random. They were, in fact, quite systematic, designed to produce a certain thing. And the last word was from another abolitionist who claimed it was the census that was insane. All right, that's Garbage In, Garbage Out. The moral here is that analysis of bad data is worse than no analysis at all, really. Time and again we see people doing, actually often, correct statistical analysis of incorrect data and reaching conclusions. And that's really risky. So before one goes off and starts using statistical techniques of the sort we've been discussing, the first question you have to ask is, is the data itself worth analyzing? And it often isn't. Now,
2969	you could argue that this is a thing of the past, and no modern politician would make these kinds of mistakes. I'm not going to insert a photo here. But I leave it to you to think which politician's photo you might paste in this frame.
2970	All right, onto another statistical sin. This is a picture of a World War II fighter plane. I don't know enough about planes to know what kind of plane it is. Anyone here? There must be an Aero student who will be able to tell me what plane this is. Don't they teach you guys anything in Aero these days? Shame on them. All right. Anyway, it's a plane. That much I know. And it has a propeller. And that's all I can tell you about the airplane. So this was a photo taken at a airfield in Britain. And the Allies would send planes over Germany for bombing runs and fighters to protect the bombers. And when they came back, the planes were often damaged. And they would inspect the damage and say look, there's a lot of flak there. The Germans shot flak at the planes. And that would be a part of the plane that maybe we should reinforce in the future. So when it gets hit by flak it survives it. It does less damage. So
2971	you can analyze where the Germans were hitting the planes, and you would add a little extra armor to that part of the plane. What's the flaw in that? Yeah? AUDIENCE: They didn't look at the planes that actually got shot down. JOHN GUTTAG: Yeah. This is what's called, in the jargon, survivor bias. S-U-R-V-I-V-O-R. The planes they really should have been analyzing were the ones that got shot down. But those were hard to analyze. So they analyzed the ones they had and drew conclusions, and perhaps totally the wrong conclusion. Maybe the conclusion they should have drawn is well, it's OK if you get hit here. Let's reinforce the other places. I don't know enough to know what the right answer was. I do know that this was statistically the wrong thing to be thinking about doing. And this is an issue we have whenever we do sampling. All statistical techniques are based upon the assumption that by sampling a subset of the population we can infer things about the population as a whole. Everything we've done this
2972	term has been based on that. When we were fitting curves we were doing that. When we were talking about the empirical rule and Monte Carlo Simulation, we were doing that, when we were building models, with machine learning, we were doing that. And if random sampling is used, you can make meaningful mathematical statements about the relation of the sample to the entire population. And that's why so much of what we did works. And when we're doing simulations, that's really easy. When we were choosing random values of the needles for trying to find pi, or random value if the roulette wheel spins. We could be pretty sure our samples were, indeed, random. In the field, it's not so easy. Right? Because some samples are much more convenient to acquire than others. It's much easier to acquire a plane on the field in Britain than a plane on the ground in France. Convenient sampling, as it's often called, is not usually random. So you have survivor bias. So I asked you to do course evaluations. Well, there's survivor
2973	bias there. The people who really hated this course have already dropped it. And so we won't sample them. That's good for me, at least. But we see that. We see that with grades. The people who are really struggling, who were most likely to fail, have probably dropped the course too. That's one of the reasons I don't think it's fair to say, we're going to have a curve. And we're going to always fail this fraction, and give A's to this fraction. Because by the end of the term, we have a lot of survivor bias. The students who are left are, on average, better than the students who started the semester. So you need to take that into account. Another kind of non-representative sampling or convenience sampling is opinion polls, in that you have something there called non-response bias. So I don't know about you, but I get phone calls asking my opinion about things. Surveys about products, whatever. I never answer. I just hang up the phone. I get a zillion emails. Every time I stay
2974	in a hotel, I get an email asking me to rate the hotel. When I fly I get e-mails from the airline. I don't answer any of those surveys. But some people do, presumably, or they wouldn't send them out. But why should they think that the people who answer the survey are representative of all the people who stay in the hotel or all the people who fly on the plane? They're not. They're the kind of people who maybe have time to answer surveys. And so you get a non-response bias. And that tends to distort your results. When samples are not random and independent, we can still run statistics on them. We can compute means and standard deviations. And that's fine. But we can't draw conclusions using things like the Empirical Rule or the Central Limit Theorem, Standard Error. Because the basic assumption underlying all of that is that the samples are random and independent. This is one of the reasons why political polls are so unreliable. They compute statistics using Standard Error, assuming that the samples
2975	are random and independent. But they, for example, get them mostly by calling landlines. And so they get a bias towards people who actually answer the phone on a landline. How many of you have a land line where you live? Not many, right? Mostly you rely on your cell phones. And so any survey that depends on landlines is going to leave a lot of the population out. They'll get a lot of people of my vintage, not of your vintage. And that gets you in trouble. So the moral here is always understand how the data was collected, what the assumptions in the analysis were, and whether they're satisfied. If these things are not true, you need to be very wary of the results. All right, I think I'll stop here. We'll finish up our panoply of statistical sins on Wednesday, in the first half. Then we'll do a course wrap-up. Then I'll wish you all godspeed and a good final. See you Wednesday.
2976	The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. PROFESSOR: Welcome back. Over the last couple of lectures, we've been looking at optimization models. And the idea was how do I find a way to optimize an objective function-- it could be minimize it or maximize it-- relative to a set of constraints? And we saw, or Professor Guttag showed you, one of the ways that naturally falls out is by looking at trees, decision trees, where you pass your way through a tree trying to figure out how to optimize that model. So today, we're going to generalize those trees into another whole broad class of models called graph theoretic or graph models. And we're going to use those to again look at how do we can do optimization on those kinds of models. Just to remind you, there is a great piece of
2977	information in the text. There's the reading for today. And these will, of course, be in the slides that you can download. So let's take a second just to reset again what are we trying to do? Generally, we're trying to build computational models. So what does that mean? The same way we could do a physical experiment, or a social experiment, or model, if you like, a physical system and a social system, to both try and gather data and analyze it or to do predictions. We want to do the same thing computationally. We'd like to be able to build models in code that we can then run to predict effects, which we then might test with an actual physical experiment. And we've seen, for example, how you could take just the informal problem of choosing what to eat and turning it into an optimization problem-- in this case, it was a version of something we called a knapsack problem-- and how you could then use that to find code to solve it. And you've already seen two
2978	different general methods. You've seen greedy algorithms that just try and do the best thing at each stage. And you saw dynamic programming as an elegant solution to finding better ways to optimize this. We're going to now look at broadening the class of models to talk about graphs. So, obvious question is, what's a graph? And a graph has two elements, two components. It has a set of nodes, sometimes called vertices. Those nodes probably are going to have some information associated with them. It could be as simple as it's a name. It could be more complicated. A node might represent a student record-- the grades. And a graph might talk about putting together all of the grades for a class. Associated with that, we can't just-- well, I should say, we could just have nodes, but that's kind of boring. We want to know what are the connections between the elements in my system? And so the second thing we're going to have is what we call edges, sometimes called arcs. And an edge will connect a
2979	pair of nodes. We're going to see two different ways in which we could build graphs using edges. The first one, the simple one, is an edge is going to be undirected. And actually, I should show this to you. So there is the idea of just nodes. Those nodes, as I said, might have information in them, just labels or names. They might have other information in them. When I want to connect them up, the connections could be undirected. If you want to think of it this way, it goes both ways. An edge connects two nodes together, and that allows sharing of information between both of them. In some cases, we're going to see that we actually want to use what we call a directed graph, sometimes called a digraph, in which case the edge has a direction from a source to a destination, or sometimes from a parent to a child. And in this case, the information can only flow from the source to the child. Now in the case I've drawn here, it looks like
2980	there's only ever a single directed edge between nodes. I could, in fact, have them going both directions, from source to destination and a separate directed edge coming from the destination back to the source. And we'll see some examples of that. But I'm going to have edges. Final thing is, those edges could just be connections. But in some cases, we're going to put information on the edges, for example, weights. The weight might tell me how much effort is it going to take me to go from a source to a destination. And one of the things you're going to see as I want to think about how do I pass through this graph, finding a path from one place to another, for example, minimizing the cost associated with passing through the edges? Or how do I simply find a connection between two nodes in this graph? So graphs, composed of vertices or nodes, they're composed of edges or arcs. So why might we want them? Well, we're going to see-- and you can probably already guess-- there
2981	are lots of really useful relationships between entities. I might want to take a European vacation. After November 8, I might really want to take a European vacation. So I'd like to know, what are the possible ways by rail I can get from Paris to London? Well, I could pull out the schedule and look at it. But you could imagine, I hope, thinking about this as a graph. The nodes would be cities. The links would be rail links between them. And then, one of the things I might like to know is, first of all, can I get from Paris to London? And then secondly, what's the fastest way to do it or the cheapest way to do it? So I'd like to explore that. Second example, as you can see on the list, drug discovery, modeling of complex molecule in terms of the relationships between the pieces inside of it and then asking questions like, what kind of energy would it take to convert this molecule into a different molecule? And how might I think about
2982	that as a graph problem? Third and obvious one, ancestral relationships, family trees. In most families, almost all families, they really are trees not graphs. Hopefully you don't come from a family that has strange loops in them. But family trees are-- I know, I'm in trouble here today. Aren't I? Family trees-- stay with me-- are a great demonstration of relationships because there its directional edges. Right? Parents have children. Those children have children. And like I say, it comes in a natural way of thinking about traversing things in that tree. And in fact, trees are a special case of a graph. You've already seen decision trees in the last lecture. But basically, a special kind of directed graph is a tree. And the property of the tree is, as it says there, any pair of nodes are connected, if they are connected, by only a single path. There are no loops. There are no ways to go from one node, find a set of things that brings you back to that node. You can only have a
2983	single path to those points. And Professor Guttag used this, for example, to talk about solving the knapsack problem. A decision trees is a really nice way of finding that solution. Now, I drew it this way. In computer science, we mostly use Australian trees. They're upside down. The roots are at the top. The leaves are at the bottom, because we want to think about starting at the beginning of the tree, which is typically something we call the root and traversing it. But however you use it, trees are going to be a useful way of actually thinking about representing particular kinds of graphs. OK. So, when I talk in a second about how to build graphs, well let's spend just a second about saying, so why are they useful? And if you think about it, the world is full of lots of networks that are based on relationships that could be captured by a graph. We use them all the time. Some of you are using them right now-- computer networks. You want to send an email
2984	message from your machine to your friend at Stanford. That's going to get routed through a set of links to get there. So the network set up by a series of routers that pass it along, sending something requires an algorithm that figures out the best way to actually move that around. There's a great local company started by an MIT professor called Akamai that thinks about how do you move web content around on the web? Again, it's a nice computer network problem. I've already talked about this. We're going to do some other examples. Transportation networks-- here, if you think about it, obvious thing is make the nodes cities. Make the edges roads between them. And now questions are, can I get to San Jose, if you like old songs? And what's the best way to get to San Jose, even if you don't like old songs? A network problem-- how do I analyze it? Financial networks-- moving money around-- easily modeled by a graph. Traditional networks-- sewer, water, electrical, anything that distributes content, if you like, and
2985	the different kind of content in this way around. You want to model that in terms of how you think about flows in those networks. How do I maximize distribution of water in an appropriate way, given I've got certain capacities on different pipes, which would mean those edges in the graph would have different weights? And you get the idea-- political networks, criminal networks, social networks. One of the things we're going to see with graphs is that they can capture interesting relationships. So here's an example. It's from that little web site you can see there. You're welcome to go look at it. And this is a graph analyzing The Wizard of Oz. And what's been done here is the size of the node reflects the number of scenes in which a character shares dialog. So you can see, obviously Dorothy is the biggest node there. The edges represent shared dialog, so you can see who talks to whom in this graph. And then, this group has done another thing, which I'm going to mention. We're not going
2986	to solve today, which is you can also do analysis on the graphs. And in fact, the color here has done something called a min-flow or max-cut problem, which is it's tried to identify which clusters in the graph tend to have a lot of interactions within that cluster but not very many with other clusters. And you can kind of see. There's some nice things here, right, if you can read it. This is all the people in Kansas. This is Glenda and the Munchkins in that part of Oz. There's another little cluster over here that I can't read and a little cluster over there. And then the big cluster down here. But you can analyze the graph to pull out pieces on it. You can also notice, by the way, the book is probably misnamed. It's called The Wizard of Oz. But notice, there's the wizard, who actually doesn't have a lot of interaction with the other people in this story. It's OK, literary choice. But the graph is representing interactions. And I could imagine searching that
2987	graph to try and figure out things about what goes on in The Wizard of Oz. OK. So why are they useful? We're going to see that not only do graphs capture relationships in these connected networks, but they're going to support inference. They're going to be able to reason about them. And I want to set that up. And then we'll actually look at how might we build a graph. And so here are some ways in which I might want to do inference. Given a graph, I might say, is there a sequence of edges, of links, between two elements? Is there a way to get from A to B? What are the sequence of edges I would use to get there? A more interesting question is, can I find the least expensive path, also known as the shortest path? If I want to get from Paris to London, I might like to do it in the least amount of time. What are the set of choices I want to make to get there? A third graph problem
2988	used a lot is called the graph partition problem. Everything I've shown so far-- actually not quite. The first example didn't have it. You might think of all the nodes having some connection to every other node. But that may not be true. There may actually be graphs where I've got a set of connected elements and another component with no connections between them. Can I find those? That's called the graph partition problem. How do I separate the graph out into connected sets of elements? And then the one that we just showed called the min-cut max-flow problem, is is there an efficient way to separate out the highly connected elements, the things that interact a lot, and separate out how many of those kinds of subgraphs, if you like, are there inside of my graph? All right, let me show you a motivation for graphs. And then we'll build them. I use graph theory everyday. I'm a math nut. It's OK, but I use graph theory everyday. You may as well, if you commute. Because I use it
2989	to figure out how to get from my home in Lexington down here to Cambridge. And I use a nice little system called Waze It's a great way of doing this, which does graph theory inside of it. So how do I get to my office? Well, I'm going to model the road system using a directed graph, a digraph. Directed graph because streets can be one way. And so I may only have a single direction there. And the idea is, I'm going to simply let my nodes or my vertices be points where I have intersections. They're places where I can make a choice or places where I have terminals, things I'm going to end up in. The edges would just be the connections between points, the roads on which I can drive. Some Boston drivers have a different kind of digraph in which they don't care whether that road is drivable or not. They just go on it. You may have seen some of these. But I want to keep my graphs as real roads that I
2990	"can drive on. And I'm not going to go against the ""One Way"" sign. Each edge will have a weight. Here I actually have some choices. All right, the obvious one, the one that Waze probably uses, is something like what's the expected time between a source and a destination node? How long do I expect it to take me to get from this point to that? And then, as you can see, I'm going to try and find overall what's the best way to get around it. You could pick just distance. What's the distance between the two? And while there there's a relationship here, it's not direct because it will depend on traffic on it. Or you could take something even funkier like what's the average speed of travel between the source and destination node? And once I've got the graph, then I'm going to solve an optimization problem. What's the shortest weight between my house and my office that gets me into work? You can make a choice here. As I said, a commercial system like Waze"
2991	uses this one. My wife and I actually have arguments about commuting because she's a firm believer in the second one, just shortest distance. I actually like the third one because I get anxious when I'm driving. And so as long as I feel like I'm making progress, I like it. So even though I may be serpentining all the way through the back roads of Cambridge, if I'm driving fast, I feel like I'm getting there. So I like optimizing this bottom one down there. And if you see me on the road, you'll know why I say that, and then get out of the way. Thinking about navigation through systems actually gives us a little bit of history because, in fact, the very first reported use of graph theory was exactly this problem. Early 1700s, it's called the Bridges of Koenigsberg. Koenigsberg is a city that has a set of islands and rivers in it. There are seven bridges that connect up those islands. And the question that was posed is, is it possible to take a walk
2992	that traverses each of the seven bridges exactly once? So could you take a walk where you go over each bridge exactly once? I'm showing you this because it lets us think about how to in fact capture things in a model. This problem was solved by a great Swiss mathematician, Leonhard Euler. And here's what he said. Make each island a node. Each bridge is just an undirected edge. And notice in doing that, he's abstracted away irrelevant details. You don't care what the size of the island is. You don't care how long the bridges are. You simply want to think about what are the connections here? And then you can ask a question. In this graph, is it possible to find a way to walk through it so that you go through each edge exactly once? And as Euler showed, the answer is no. And if you're curious, go look it up on Wikipedia. There's a nice, elegant solution to why that's the case. But here's what we're going to do. We're going to use those graphs
2993	to think about these kinds of problems. And in fact, the example I'm going to show you are going to be shortest path problems. So with that, let's turn to actually building a graph and then thinking about how we're going to use it. So we're going to start by constructing graphs. And then what we're going to do is show how we can build search algorithms on top of those graphs. And I hope that that flicker is going to go away here soon. Here we go. So to build a graph-- actually, I shouldn't have put this slide up so fast. I've got lots of choices here. If I'm thinking about maps, one way to build a graph would really to just be build something with latitude and longitude on it. But as we've already seen, we'd like to extract things away from the graphs. And so a natural choice is to say, let's represent the nodes in the graph just as objects. I'm going to use classes for these. So here's my definition of a node. It's
2994	pretty straightforward. I'm going to assume that the only information for now I store in a node is just a name, which I'm going to assume is a string. So I've got a class definition for node. It inherits from the base Python object class. I need ways to create instances of nodes, so I've got an init function. And I'm simply going to store inside each instance, in other words, inside of self, under the variable name, whatever I passed in as the name of that node. Of course, if I've got ways to create things with a name, I need to get them back out. So I've got a way of selecting it back out. If I ask an instance of a node, what's your name? By calling getName it will return that value. And to print things out, I'm just going to print out the name. This is pretty straightforward. And this, of course, lets me now create as many nodes as I would like. Edges? Well, an edge connects up two nodes. So again, I can
2995	do a fairly straightforward construction of a class. Again, it's going to inherit from the base Python object. To create an instance of an edge, I'm going to make an assumption, an important one which we're going to come back to. And the assumption is that the arguments passed in, source and destination, are nodes-- not names-- the nodes themselves, the actual instances of the object class. And what will I do? Inside of the edge, I'm going to set internal variables. For each instance of the edge, source and destination are going to point to those nodes, to those objects that I created out of the node class. Next two things are straightforward. I can get those things back out.
2996	I want to print out what an edge looks like, I'm going to ask that it print out the name of the source, and then an arrow, and then the name of the destination. So notice what I do there. Given an instance of an edge, I can print it. And it will get the source or the node associated with source inside this instance, get for that the getName method, and then call it. Notice the open-close paren there to actually call it. What does that do? It says, inside the edge I've got something that points to a node. I get that node. I take the method associated with it. And I call it. That returns the string. And then I glue that together with the arrow. I do the same thing on the destination. And I just print it out. Pretty straightforward, hopefully. OK, now I have to make a decision about the graph. I'm going to start with digraphs, directed graphs. And I need to think about how I might represent the graph. I can create
2997	nodes. I can create edges, but I've got to bring them all together. So I'll remind you, a digraph is a directed graph. The edges pass in only one direction. And here's one way I could do it. Given all the sources and all the destinations, I could just create a big matrix called an adjacency matrix. The rows would be all the sources. The columns would be all the destinations. And then in a particular spot in the matrix, if there is an edge between a source and a destination, I'd just put a one. Otherwise I'd put a zero. Note, by the way, because it's a directed graph, it's not symmetric. There might be a one between S and D, but not between D and S, unless there are edges both ways. This would be a perfectly reasonable way to represent a graph, but not the most convenient one. I'd have to go into the matrix to look things up. It may also not be a very efficient way of representing things. For example, if there are very
2998	few edges in the graph, I could have a huge matrix with mostly zeros. And that's not the most effective way to do it. So I'm going to use an alternative called an adjacency list. And the idea here is, for every node in the graph. I'm going to associate with it a list of destinations. That is, for a node, what are the places I can reach with a single edge? OK, so let's see what that does if we want to build it. And yes, there's a lot of code here, but it's pretty easy to look through I hope. Here's the choice I'm going to make. Again, what's a graph? It's a set of nodes. It's a set of edges. I'm going to have a way of putting nodes into the graph. And I'm going to choose to, when I put a node into the graph, to store it as a key in a dictionary. OK? When I initialize the graph, I'm just going to set this internal variable, edges, to be an empty dictionary. And the
2999	second part of it is, when I add an edge to the graph between two nodes from a source to a destination, I'm going to take that point in the dictionary associated with the source. It's a key. And associated with it, I'm going to just have a list of the nodes I can reach from edges from that source. So notice what happens here. If I want to add a node, remember, it's a node not an edge-- I'll first check to make sure that it's not already in the dictionary. That little loop is basic, or that if is saying, if it's in this set of keys, it will return true. And I'm going to complain. I'm trying to copy a node or duplicate a node. Otherwise, notice what I do. When I put a node into the dictionary, I go into that dictionary, edges. I create an entry with the key that is the node. And the value I put in there is initially an empty list. I'm going to say one more piece carefully. It's a
3000	node not a name. And that's OK in Python. It is literally the key is the node itself. It's an object, which is what I'd like. All right, what if I want to add an edge? Well, an edge is going to go from a source to a destination node. So, I'm going to get out from the edge the source piece. I'm going to get out from the edge the destination piece by calling those methods. Again, notice the open-close paren, which takes the method and actually calls it. Because remember, an edge was an object itself. Given those, I'll check to make sure that they are both in the dictionary. That is, I've already added them to the graph. I can't make a connection between things that aren't in the graph. And then notice the nice little thing I do.
3001	I take the dictionary, I index into it with the source node. That gives me a key into the dictionary. I pull out the entry at that point, which is a list, because I created them up here. And I add the destination node with append into the list, stick it back in. So this now captures what I said I wanted to do. The nodes are represented as keys in the dictionary. And the edges are represented by destinations as values in the list associated with the key. So you can see, if I want to see is there an edge between a source and a destination, I would look at our source in the dictionary, and then check in the list to see if the destination is there. OK, the rest of this then follows pretty straightforwardly.
3002	I just go into the dictionary, edges, and look up the value associated with that node. It gives me back the list. I've got all the things I can reach from that particular node. If I want to know if a node is in the graph, I just search over the keys of the dictionary. They'll either return true or false. If I want to get a node by its name, which is going to be probably more convenient than trying to keep track of all the nodes, well I could pass in a name as a string. And what will I do? I'll just search over all the keys in the dictionary, using the getName method associated with it-- there's the call-- then checking to see if it's the thing I'm looking for. And if it is, I'll return M. I'll return the node itself. What about this thing here? It might bother you a little bit. Wait a minute. That raise, isn't it always going to throw an error? No, because I'm going to go through this loop
3003	first. And if I actually find a node, that return is going to pop me out of the call and return the node. So I'll only ever get to this if in fact I couldn't find anything here. And so it's an appropriate way to simply raise the error to say, if I get to this point, couldn't find it, raise an error to say the node's not there. The last piece looks a little funky, Although you may have seen this. I like to print out information about a graph. And I made a choice, which is, I'm going to print out all of the links in the graph. So I'm going to set up a string initially here that's empty. And then I'm going to loop over every key in the dictionary, every node in the graph. And for each one, I'm going to look at all the destinations. So notice, I take the dictionary, I look up the things at that point. That's a list. I loop over that. And I'm just going to add in to
3004	result, the name of the source, an arrow, and the name of the destination followed by a carriage return. I'll show you an example in a second. But I'm simply walking down the graph, saying for each source, what can it reach? I'll print them all out. And then I'll return everything but the last element. I'm going to throw away the last carriage return because I don't really need it. So let me show you an example here, trusting that my Python has come up the way I wanted it to. So I'm going to load that in, ignore that for the moment. And I'm going to set g to-- I've got something we're going to come back to in a second that actually creates a graph. And if I print out g, it prints out, in this case, all of the links from source to destination, each one on a new line. OK. So I can create the graphs. That was digraphs. Suppose I actually want to get a graph. Well, I'm going to make it as a
3005	subclass of digraph. And in particular, the only thing I'm going to do is I'm going to shadow the addEdge method of digraphs. So if you think about it, it's so I make a graph. If I ask it to add edges, it's going to use this version of addEdge. And what am I going to do? I know in a graph, I could have both directions work. So, given an edge that I want to add into this graph,
3006	And I'll add an edge going from source to destination. And then I'll just create an edge the other direction. Destination becomes source. Source becomes destination. And I'll add that into the graph. Nice and easy, straightforward to do. And this is kind of nice because, in a graph, I don't have any directionality associated with the edge. I can go in either direction. I just created something like that. And you might say, well, wait a minute. Why did I pick graph to be a subclass of digraph? Why not the other way around? Reasonable question, and you actually know the answer. You've seen this before. One of the things I'd like to have is the property that if the client code works correctly using an instance of the bigger type, it should also work correctly when it is using an instance of the subtype substituted in, which is another way of saying anything that works for a digraph will also work for a graph, but not vice versa. And as a consequence, it's easier to make the graph
3007	a subclass of digraph. Notice the other thing that's nice here. One little piece of code, just change what it means to make an edge. Everything else still holds. And also notice-- you've seen this before-- how we nicely inherit the method from the subclass by explicitly calling it. It says, from the digraph class, get out the addEdge method and apply it. OK. So we can build graphs. We're going to do that in a second. Let's turn now to thinking about I'd like to search on a graph. And I'm going to start with the classic graph optimization problem. I'd like to find the best path home. So, what's the shortest path from one node to another? And that shortest path initially will just be the shortest sequence of steps. I hope I'm not having a little attack here. You just saw that screen blank out, right? The shortest path of steps with the property that the source of the first edge is the starting point. The destination of the last edge is the thing I'm trying to
3008	get to. And for any edge in between, if I go in my first edge from source to say node one, the next edge has that destination as its source. So there's simply a chain that says can go from here to here to here to here to get all the way through. And I'd like to find what's the shortest number of steps? Edges like that that will get me from source to destination. Ultimately, if those edges have weights on them, the optimization problem I'd like to solve is, what's the shortest weighted path, the shortest amount of work I have to do to get to those places? And if we can solve one, we'll see that we can solve the other one pretty straightforwardly. And we've already seen examples of shortest path problems. Clearly, finding a route navigation is one. Designing communication networks is another great example of a shortest path problem. You'd like your message to get to your friend as quickly as possible and not go as many times around the world before it gets
3009	there. So what's the shortest amount of time or the fewest links I have to use to get there? Lots of nice biological problems that also captured this piece. So here is an example. And we're going to use this to look at two different kinds of algorithms to solve this problem. This is a little navigation problem from a set of cities. Think of it as flight paths. If you're from Arizona, my apologies. But once you get to Phoenix, you can't get out of there unless you grow from the ashes, I guess. [LAUGHTER] But you know, it's a way of dealing with how to get around in places. And to think about this, here's the representation that we'd have in the graph. The adjacency graph here-- or adjacency list
3010	I can get to New York. From Providence, I can get to Boston. I can get to New York. From New York, I can only get to Chicago. Chicago, I can go to Denver or Phoenix. Denver, I can go to Phoenix or New York. And from L.A., you can only come back to Boston. And Phoenix has no exits out of it. So there is that representation. I just want to let you see that. Right? There are the keys in the dictionary. They're all the nodes. And there, each one of those lists is a set of edges from the source to the destination. OK. How would I build this? Well this is the code I just ran. I just want to show it to you. I notice, by the way, in the slides I distributed earlier, the return g is missing there. If you want to correct it, I'll repost it later on. I'm going to create a little function that's going to build a city graph. I'm going to pass in a type of graph, which
3011	I will then call to create it. So I could make this as a digraph. I could make it as a graph. I'm going to start off with it as a digraph. And then notice what I do here. I just run over a little loop with a set of names, creating a node with that name and then adding it into the graph. All right, so node is a class instance. It creates-- or a class definition-- it creates an instance. And once I've got that, addNode as a method on the graph. It will simply add it in. And then this set here, is simply adding in the edges. And I can do that. I'm capturing what I had on that previous slide. And on a given name to getNode, it will get out the actual node. And I use that coming out of the graph g. I do the same thing with the getNode from graph g for Providence. And then I make an edge out of that. And then I use the method from the graph
3012	to add the edge. If this looks like a lot of code, yeah, it's a lot of words. But it's pretty straightforward. I'm literally creating nodes with the names, using the appropriate methods, creating an edge, adding it into the graph. And when I'm done, I'm just going to return the graph g. OK. Now I want to find the shortest path. I'm going to show you two techniques for doing this. The first one is called depth first search. It's similar to something Professor Guttag showed you when you sort of took the left most depth first method in terms of a search tree. The one trick here is, because I've got graphs not trees, there are the potential for loops. So I'm simply going to keep track of what's in the path. And I'm never going to go back to a node that's already in the path. So I don't just run in circles going from New York to Boston to New York to Boston constantly. All right. So, the second thing I'm going to do here is
3013	I'm going to take advantage of a problem you've seen before, which is this is literally a version of divide and conquer. What does that mean? If I want to find a path from a source node to destination node, if I can find a path to some intermediate node from source intermediate, and then I find a path from intermediate to destination, the combination is obviously a path the entire way. So recursively, I can just break this down into simpler and simpler versions of that search problem. So here's the idea behind depth first search. Start off with that source node, that initial node. I'm going to look at all the edges that leave that node in some order, however order it was put into the system. And I'm going to follow the first edge. I'll check to see if I'm at the right location. If I am, I'm done. If I'm not, I'm going to follow the first edge out of that node. So I'm actually creating a little loop here. And I'm going to keep doing
3014	that until I either find the goal node or I run out of options. So let me show you an example. I've got a little search tree here, a very simple one. Here's my source. There is my destination. In depth first, I'm going to start at the source and go down the first path. See if I'm at the right place. I'm not. So I'm going to take the first path out of here, which might be that one. See if I'm in the right place. Actually, let me not do it that way. Let me do it this way. Am I in the right place? I'm not. So I'm going to take the first path out of this one, which gets me there. I'm still not in the right place, so I'm going to take the first path out of that one. And you can see why it's called depth first. I'm going as deep, if you like, in this graph as I can, from here, to there, to there, to there, to there. At this stage, I'm
3015	stuck. There is no place to go to, so I'm going to go back to this node and say, is there another edge? In this case there isn't, so I'll go back to here. There's not another edge. Go back to here. There is another edge. So I'm going to go this direction. And from here, I'll look down there. OK, notice I'm now going depth first down the next chain. There's nothing from here. I backtrack. There's nothing from there. I backtrack over to here. There's no additional choices there, so go all the way back to here to follow that one. And then we'll go down this one again, backtrack, backtrack, and eventually I find the thing I'm looking for. Depth first-- following my way down this path. So let's write the code for-- yes ma'am? AUDIENCE: Pardon me. Is the choice of depth first node we go down, is that random? PROFESSOR: The question is, which node do I, or which edge do I choose? It's however I stored it in the system. So since it's a
3016	list, I'm going to just make that choice. I could have other ways of deciding it. But think of it as, yeah, essentially random, which one I would pick.
3017	Don't panic. It's not as bad as it looks. It actually just captures that idea. Ignore for the moment this down here. It's just going to set it up. Depth first search, I'm going to give it a graph, a start node, an end node, and a path that got me to that start node, which initially is just going to be an empty list, something that tells me what's the shortest path I've found so far, which would be my best solution? And then just a little flag here if I want to print out things along the way. What do I do? I set up path to add in the start node. So if path initially is an empty list, the first time around is just, here's the node I'm at. I print out some stuff and then I say, see if I'm done. I'm just going to stay at home. I'm not going to go anywhere. Unlikely to happen, but you'll see recursively why this is going to be nice. If I'm not done, then notice the
3018	loop. I'm going to loop over all the children of the start node. Those are the edges I can reach. Then those I can reach with a single edge. I pick the first one. And in answer to the question, in this case, it would be the order in which I started in the list. I just pick that one up. I then say, let's make sure it's not already in the path because I want to avoid loops. And assuming it isn't, and assuming I don't yet have a solution, or the best solution I have is smaller than what I've done so far, oh, cool, just do the same search. So notice, there's that nice recursion. Right? I'm going to explore. I just picked the first option out of that first node. And the first thing I do is try and see if there's a path from that node using the same thing. So it's literally like I picked this one. I don't care about those other edges. I'm going to try and take this search down. When
3019	it comes back with a solution, as long as there is a solution, I'll say that's my best solution so far. And then I go back around. Now this last little piece here is just, if in fact the node's already in the path, I'm just going to print something that says don't keep doing it because you don't need to keep going on. And I'm going to do that loop, taking all the paths down until it comes back. And only at that stage do I go to the next portion around this loop. The piece down here just sets this up, calling it with an initial empty list for path and no solution for shortest. So it's just a nice way of putting a wrap around it that gets things started up. This may look a little funky. It may look a little bit twisted. So let's see if it actually does what we'd expect it to. And to do that I'm just going to be a little test function. I'm going to build that city graph I'm
3020	"just going to call ""Shortest Path."" I'm going to print it out. And I'd like to see, is there a way to get from Boston to Chicago? So let's go back over to my Python and try that out. And I've got a call for that. Oh, and it prints out. I start off-- oh, so I did it the wrong way. It's from Chicago to Boston. Yes, Chicago to Denver to Phoenix, from Denver to New York, it comes back and says, I've already visited. Basically concludes I can't get from Chicago to Boston. It's just printing out each stage. Let's actually look at that a little more carefully to see how it got there. So there's my example. There is the adjacency list."
3021	I start off in Chicago. So that's my first node. From Chicago, the first edge goes to Denver. Denver is not what I'm looking for. But since I am in Denver, recursively I'm going to call it again. So the first edge out of there is to Phoenix. Again, sorry if you're from Arizona and Phoenix. There's nowhere to go. So I'm going to have to backtrack. And that will take me back up to Denver. And I look at the next edge. It takes me to New York. From New York I'd like to go to Chicago. But oh, that's nice because, remember, that first check it says, is Chicago already in the path? It is. I don't want to loop, because otherwise I'm simply going to go around and around and around here. And it may be good for frequent flyer miles, but it's not a great way to get to where you're trying to go. So I break out of it. And now, what else do I have left? Chicago to Denver I've explored. I'll look at
3022	Chicago to Phoenix. From Phoenix there's nowhere to go. I go back up to Chicago. There are no more paths. I'm done. OK. Now, it turns out you can actually get somewhere in this graph. So here's just another example. I'm simply going to show you, if I want to go from Boston to Phoenix, notice the set of stages. And you can see, notice how at each stage it tends to be growing. That's that depth first. I'm exploring the edges. I find a path. That's great. But is it the shortest path? I don't know. So having found that path, I try and take the next branch, which finds a loop. And I keep moving through this, finding paths until I look at all the possible paths and I actually return the shortest path. You can try running the code on it. But what I want you to see is, again, this idea that I can explore it. But in fact, I'm going to have to explore it in a particular order. But there is depth first search.
3023	It will find a solution for me. Alternative, it's what's called breadth first search. Sounds almost the same. Again, I'm going to start off with initial load. I'm going to look at all the edges that leave that node, in some order. I'm going to follow the first edge as before and see if I'm at the right place. If I'm not, I'm going to follow the next edge and do the same thing. So whereas this went down through the tree as deeply as it could of the graph, in breadth first, I'm going to start off taking that edge as before. I'm not done. I'm going to keep track of that in case I want to explore more of it. But I'm going to go back over here and follow that edge. I'm not done. Again, I'll keep track of that, but I'll come back up here and explore that one. And oh, cool, I found a solution in three steps. I've reached the destination. And notice, because I'm exploring all the paths of length one before I
3024	get to paths of length two. Once I find a solution, I can stop because I know it's the shortest path. Any other path through here would be longer than that particular solution. So the loop here is a little different.
3025	There are all the paths of length two. And the one thing I'm going to have to do is I'm going to have to keep track of the remaining options here in case I have to come down to them. Because if I didn't find it at the first level, then I come down here and look at things of length two. OK? So let's build that code. Breadth first search, or BFS, again, a graph, a start, and an end node, something that would just print things out as I go along. My initial path is just the start point. But now I've got to keep track of what are the paths that I have yet to explore? And so for that, I'm going to create something called a queue. And a queue is going to be a list of paths. Remember, a path is a list of nodes. A queue is going to be a list of paths. So the initial queue is just where I've started. And then, as long as I've got something still to explore
3026	and I haven't found a solution, I'm going to pop off the queue the oldest element, the thing at the beginning. That's my temporary path. I'll print out some information about it. And then I'll grab the last element of that path. That's the last point in that path. And I'll now explore. Is it the thing I'm looking for? In which case I'm done. I'll return the path. Otherwise, for each node that you can reach from that point, create a new path by adding that on the end of this path and add it into the queue at the end of the queue. So I'm going to keep looping around here until I either find a solution here, which I'll return. And if I get through all of it, I'm going to return none. And right there, there is that nice thing where once I find a solution, I know it's the shortest thing, I can stop. OK, let's look at an example of this. So I'm going to go back over to Python, where I've got a
3027	version of this. I'm going to comment that out. And down here in breadth first search, I've actually added a little piece of code that I don't have in the handout that's going to print out the queue as well so we can see what happens when we call this. So let's take a look at it. My initial call, there's one thing in the queue. It's just Boston. I started in Boston. So the current path is to start in Boston. I take that element off the queue, and I say what are the things I can reach from Boston? Oh, nice, I put two things in. I can get from Boston to Providence. I can get from Boston to New York. The top thing is gone off the queue. I popped it. I've replaced it with two things. Or I take this, and say, OK, from Boston to Providence, where can I get from Providence? Oh, I can get to New York. So I put that in the queue. This has gone off. That one is still there.
3028	And I do that because I haven't yet reached the thing I'm looking for, which was, I think, Phoenix I was trying to get to. And you could see at each stage, I'm taking the top thing off the queue, and asking for all the things that I can get to, and adding them to it. And notice, in some cases, it may be more than one. For example, which one do I want here? Right here, if I take Boston, New York to Chicago, from Chicago I can get to Denver. So there's one new path. I can also get to Phoenix. There's a second new path. Also notice how they are only growing slowly as I build them out. And in fact, if we go back, we can see that nicely by looking at what happens if we were to actually trace this along. So Boston to Phoenix, I start at Boston. Then I look at that and then that. Those are all the paths of length one. Having exhausted those, oh nice, I'm looking at paths of
3029	length two, and then paths of length three, and then paths the length four, until I found the one that I wanted. And here's one other way of looking at it. Breadth first says, I'll look at each path of length one. And then, oh yes, I avoid the loop. I look at each path of length two, then paths of length three, until I actually find the solution. Subtle difference, different performance. Depth first, I'm always following the next available edge until I get stuck and I backtrack. Breadth first, I'm always exploring the next equal length option. And I just have to keep track in that queue of the things I have left to do as I walk my way through. What about weighted shortest path? Well, as the mathematicians say, we leave this is an easy exercise for the reader. It's a little unfair. The idea would be, imagine on my edges, it's not just a step, but I have a weight. Flying to L.A. Is a little longer than flying from Boston to New York. What
3030	I'd like to do is do the same kind of optimization, but now just minimizing the sum of the weights on the edges, not the number of edges. As you might guess, depth first search is easily modified to do this. The cost now would simply be what's the sum of those weights? And again, I would have to search all possible options till I find a solution. Unfortunately, breadth first search can't easily be modified because the short weighted path may have many more than the minimum number of loops. And I'd have to think about how to adjust it to make that happen. But to pull it together, here's a new model-- graphs. Great way of representing networks, collections of entities with relationships between them. There are lots of nice graph optimization problems. And we've just shown you two examples of that. But we'll come back to more examples as we go along. And with that, we'll see you next time.
3031	The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. JOHN GUTTAG: Today we're starting a new topic, which is, of course, related to previous topics. As usual, if you go to either the 60002 or the 600 web site, you'll find both today's PowerPoint and today's Python. You'll discover if you look at the Python file that there is quite a lot of code in there. And I'll be talking only about some of it. But it's probably all worth looking at. And a fair amount of reading associated with this week. Why are we looking at random walks? See a picture here of, think of them as molecules just bouncing around. This is actually a picture of what's called Brownian motion, though Robert Brown probably did not discover it. We're looking at random walks because, well, first of all, they're important in many domains.
3032	There are people who will argue, for example, that the movement of prices in the stock market is best modeled as a random walk. There was a very popular book called A Random Walk Down Wall Street that made this argument. And a lot of modern portfolio analysis is based upon that. Those of you who are not interested in making money, and I presume that's most of you, it's also very important in many physical processes. We use random walks, say, to model diffusion, heat diffusion, or the diffusion of molecules in suspension, et cetera. So they're very important in a lot of scientific, and indeed, social disciplines. They're not the only important thing, so why are we looking at those? Because I think it provides a really good illustration
3033	And it does give me an excuse to cover some important topics related to programming. You'll remember that one of the subtexts of the course is while I'm covering a lot of what you might think of as abstract material, we're using it as an excuse to teach more about programming and software engineering. A little practice with classes and subclassing, and we're going to also look at producing plots. So the first random walk I want to look at is actually not a diffusion process or the stock market, but an actual walk. So imagine that you've got a field which has somehow
3034	and you've got a drunk wandering around the field, taking a step every once in a while in some random direction. We can then ask the question is there an interesting relationship between the number of steps the drunk takes and how far the drunk is from the origin at the end of those steps? You could imagine that if the drunk takes more steps, he's ever further from the origin. Or maybe you could imagine, since it's random, that he just wanders away and he wanders back in all directions and more or less never gets very far. So just out of curiosity, I'll take a poll. Who thinks that the drunk doesn't much matter how many steps he takes, he'll be more or less the same distance away? And who thinks the more steps he takes, the further away he's likely to be? It seems to be a season where when you take polls, they come out almost tied. Let's look at a small example. Suppose he takes one step only. Well, if he takes one step, and
3035	we'll assume for simplicity that he's not so drunk that he moves at random. He either moves north or south, east or west. These are all the places he can get to in one step. What they have in common is that after one step, the drunk is always exactly one unit away from the origin. Well, how about after two steps? So without loss of generality, let's assume that the first step-- let me use the pen that you're supposed to use to write on this, rather than this pen, which would make a real mess on my screen. What did I do with it? Well, I won't write on it.
3036	assume that the drunk is there after one step. Took one step to the east. Well, after two steps, those are all the possible places he could be. So on average, how far is the drunk from the origin? Well, if we look, he could either be two steps away, if he took another step east, zero steps away, if he took a step west, or what do we see for the top two? Well, the top and the bottom one, we can go back and use the Pythagorean theorem. c squared equals a squared plus b squared. And that will tell us that it'll be the square root of a squared plus b squared. And that will tell us how far away the upper two are, and then we can just average them and get a distance. And as we can see, on average, the drunk will be a little bit further away after two steps than after one step. Well how about after 100,000 steps? It would be a little bit tedious to go through the case analysis
3037	I just did. There are a lot of cases after 100,000 steps. So we end up resorting to a simulation. So we'll structure it exactly the same way we've been structuring our other simulations. We're going to simulate one walk of k steps, n such walks, and then report the average distance from the origin of the n walks. Before we do that, in line with the software engineering theme of the course, we'll start by defining some useful abstractions. There are three of them I want to look at. Location, the field that the drunk is in, and the drunk him or herself.
3038	This is going to be an immutable type. So what we see here-- as long as I can't point in the screen, I'll point with a pointer-- is that we'll initiate it. We'll initialize it with an x and y value. That makes sense. We'll be able to have two getters, getX and getY. And here's how we see it's immutable. What move is doing is it's not changing the location, it's returning a new location. Perhaps move is poor choice of name for that. But that is what it's doing. It's just returning a new location where it adds the change in x and the change in y to get two new xy values. Notice, by the way, that I'm not restricting these to be integers, or one, or anything like that. So this would work even if I did not want to take those nice little east-west, north-south steps. I've got a underbar underbar string, _str_, and then here's my implementation-- you can see it's very sophisticated-- of the Pythagorean theorem. So I just do it that way,
3039	and that will get me the distance between two things. It's one of the annoying things about classes in, actually, all languages I know with classes, is you would like to think that self and other-- there's a symmetry here. The distance from self to other is the same as from other to self. But syntactically, because of the way the language is structured, we treat them a little bit differently. How about class Drunk? Well, this is kind of boring.
3040	And that's all. The point of this, and I don't think we've looked at this before, is this is not intended to be a useful class on its own. It's what we call a base class. The notion here is its only purpose is to be inherited. It's not supposed to be useful on itself, but it does give me something that will be used for the two subclasses. And we'll look at two subclasses.
3041	I tried to simulate when I was wandering around, wanders around at random. And a drunk I like to think of it as a New Englander, or a masochistic drunk, who tries forever to move ever northward, because he or she wants to be frozen. I do like this picture of entering the state of Maine in the winter. So here is the usual drunk. Subclass of drunk, and it can take steps at random, one step, either increasing y, a step north, decreasing y, a step south, increasing x, a step east, or decreasing x a step west. So those are the choices. And it's going to return one of those at random. I think we saw random.choice in the last lecture.
3042	almost the same, except the choices are slightly different. If he chooses to head north, he doesn't go one step. He goes 1.1 steps north. And if he chooses to go south, he only goes 9/10 of a step. So what we're seeing here is what's called a biased random walk. And the bias here is the direction of the walk that he's moving either up or down. Pretty simple. How about just for to test things out, we'll ask the question is this an immutable or a mutable type? Are drunks mutable or immutable? This is a deep philosophical question. But if we ignore the philosophical underpinnings of that question, what about the two types here? Who thinks it's immutable? Who thinks it's mutable? Why do you think it's mutable? What's getting changed? The answer is nothing. It gets created, and then it's returning the step, but it's not actually changing the drunk. So so far we have two things that are immutable, drunks and locations. Let's look at fields. Fields are a little bit more complicated. So field
3043	will be a dictionary, and the dictionary is going to map a drunk to his or her location in the field. So we can add a drunk at some location, and we're going to check.
3044	"we're not going to put the drunk in. We're going to raise a value error, ""Duplicate drunk."" Otherwise we're going to set the value of drunkenness mapping to loc. Now you see, by the way, why I wanted drunks to be immutable. Because they have to be hashable so I can use them as a key in a dictionary. So it was not an idle question whether they were immutable. It was an important question. I can get the location of a drunk. If the drunk is not in there, then I'll raise a different value error, ""Drunk not in field."" Otherwise I'll return the location associated with that drunk. And finally, we're going to have moveDrunk."
3045	If the drunk is there, I'm going to get the distance on x and the distance in y by calling drunk.takeStep. So we saw takeStep for a drunk didn't move the drunk anywhere, because the drunks were immutable, but returned new locations. A new x and new values. And then I'm going to use that to move the drunk in the field. So I'll set self.drunk, so drunk to move x distance and y distance. So it's very simple, but having built this set of classes, we can now actually write the simulation. Oh. What about our classes? Are they mutable or immutable? Not classes. What about fields? Any votes for mutable? Yeah, exactly. Because you can see I'm mutating it right here. I'm changing the value of the dictionary. And in fact, every time I add a drunk to the field, I'm changing the value of the dictionary, which is to say mutating the field. So I'll have a bunch of locations, which are immutable objects. Makes sense that a location is immutable. A bunch of drunks, and the
3046	thing I'm going to change is where the drunks are in the field. I said we'd start by simulating a single walk.
3047	will take some number of steps in the field. And you can see this. It's very simple. I just have a loop. Drunk takes some number of random steps, and I'm going to return the distance from the start to the final location of the drunk. So how far is the drunk from the origin? I then need to simulate multiple walks. Notice here that I've got the number of steps, the number of trials, and dClass stands for class of the drunk. And that's because I want to use the same function to simulate as many different kinds of drunks as I care about. We've only seen two here, the masochistic drunk and the usual drunk, but you can imagine many other kinds as well. So let's do it. So here I'm going to simulate a walk for one drunk, Homer.
3048	which is the drunk class. Then the origin, distances, and for t in range number of trials, we'll just do it, and then we'll return the distances. So it's initialized to the empty list. So we're going to return a list for however many trials we do, how far the drunk ended up from the origin. Then we can average that, and we look at the mean. Maybe we'll look at the min or the max. Lots of different questions we could ask about the behavior. And now we can put it all together here. So drunkTest will take a set of different walk lengths, a list of different walk lengths, the number of trials, and the class. And for a number of steps and walk lengths, distances will be simWalks of number of steps, numTrials, dClass. And then I'm going to just print some statistics. You may or may not have seen this. This is something that's built in to Python. I can ask for the name of a class. So dClass, remember, is a class, and _name_ will
3049	give me the name of the class. Might be usual, it might be drunk, in this case. So let's try it. So the code we've looked at. So let's go down here, and we'll run it, and we'll try it for walks of 10, 100, 1,000, and 10,000 steps. And we'll do 100 trials. Here's what we got. So my question to you is does this look plausible? What is it telling us here? Well, it's telling us here that the length of the walk actually doesn't really affect-- the number of steps doesn't affect how far the drunk gets. There's some randomness. 8.6, 8.57, 9.2, 8.7. Not much variance. So we've done this simulation and we've learned something, maybe. So does this look plausible? We can look at it here. I've just transcribed it. What do you think? Well, go ahead. AUDIENCE: I was going to say, it seems plausible because after the first two steps, there's a 50% chance he's going closer to the origin. And a 50% chance he's going away from it. JOHN GUTTAG: So we
3050	have at least one vote for plausible, and it's certainly a plausible argument. Well, one of the things we need to learn to do is whenever we build a simulation, we need to do what I call a sanity check to see whether or not the simulation actually makes sense. So if we're going to do a sanity check, what might we do in this case? We should try it on cases where we think we know the answer. So we say, let's take a really simple case where we're pretty sure we know what the answer is. Let's run our simulation and make sure it gives us the right answer for this simple case. So if we think of a sanity check here, maybe we should look at these numbers. We just did it. We know how far the drunk should get in zero steps. How far should the drunk move in zero steps? Zero. How far should the drunk move in one steps? We know that should be one. Two steps, well, we knew what that should be.
3051	Well, if I run this sanity check, these are the numbers I get. I should be pretty suspicious. I should also be suspicious they're kind of the same numbers I got for 10,000 steps. What should I think about? I should think that maybe there's a bug in my code. So if we now go back and look at the code, yes, this fails the pants on fire test that there's clearly something wrong with these numbers.
3052	Well, numTrials is a constant. It's always 100. What I intended to write here was not numTrials but numSteps. I actually did this the first time I wrote this simulation many years ago. I made this typo, if you will, and I got these bizarre answers. So I looked at the code and I said, well, that's actually wrong. No wonder it's always the same number. I'm calling it with a constant. The constant happens to be 100. So let's go fix the simulation. So this should have been numSteps. Now let's run it again. Well, these results are pretty different. Now we see that in fact, they're increasing. Should I just look at this and be happy? Probably not. I should run my sanity check again and make sure I get the right results for zero, one, and two. So let's go back and do that, just to be a little bit safe. So I'll just change this tuple of values to be-- and I should feel a lot better about this. The mean, the max, and the min
3053	are all zero when he doesn't take any steps. One is exactly what we should expect, and two is also-- the mean is where we would guess it to be, and the max is two, happened to take two steps in the same direction, and the min is zero, happened to end up where he started. So I've passed my sanity check. Doesn't mean my simulation is right, but at least I have reason to be hopeful. So getting back. So we saw these results, and now we're getting the indication that in fact, contrary to what we might have thought, it does appear to be that the more steps the drunk takes, the further away the drunk ends up. And that was the usual drunk. We can try the masochistic drunk,
3054	I won't make you sit through it, but when we run it, here are the usual drunks, the numbers, and I just looked at it for 1,000 and 10,000 so it would fit on the screen. You see for the usual drunk, it's 26.8, roughly 90. Fair dispersion in the min and the max. And the masochistic drunk seems to be making considerably more progress than the usual drunk. So we see is this bias actually appears to be changing the distance. Well, that's interesting. Now we could ask the question why? What's going on? And to do that, I want to go and start visualizing what's the trend? So rather than just looking at two numbers or three numbers, as we've been doing, I'm going to draw a pretty picture. Actually, I'm not going to draw. I'm a terrible artist. But Python will draw us some pretty pictures. We're going to simulate walks of multiple lengths for each kind of drunk, and then plot the distance at the end of each length walk for each kind of drunk. I
3055	"now digress for a moment to talk about how we do plotting. So we're going to use something called Pylab. I've listed here four really important libraries that you will surely end up using extensively if you continue to use Python for research purposes. NumPy adds vectors, matrices, and many high-level mathematical functions. Actually, it might be NumPy. It might be ""Num-Pee."" I'm not sure how to pronounce it. But we'll call it NumPy. So these are really useful things. SciPy adds on top of that a bunch of mathematical classes and functions useful to scientists. Things like-- well, we'll look at some of them as we go on through the term. MatPlotLib adds an object-oriented programming interface for plotting. Anybody here used MATLAB? Great. Well you'll find that MatPlotLib is the Mat, think MATLAB. Lets you, in Python, use all the plotting stuff that you've come to either like or hate in MATLAB. So it's really convenient. If you know how to do plots in MATLAB, you'll know how to do it in Python. PyLab combines all of these"
3056	to give you a MATLAB-like interface to Python. So once you have PyLab, you can do a lot of things that you would normally want to do in MATLAB, for example, produce weird-looking plots like this one. I'm going to show you one of the many, many plotting commands. It is called plot. It takes two arguments, which must be sequences of the same length. The first argument is the x-coordinates, the second argument is the y-coordinates corresponding to the x ones. There are roughly three zillion optional arguments, and you'll see me use only a small subset of them. It plots the points in order. First the first xy, then the second xy, then the third xy. Why is it important that I say it plots them in order? Because by default, as each point is plotted, it draws a line connecting one point to the next point to the next point. And so the order in which they're plotted will determine where the lines go. Now we'll see, as we go on, that we often don't draw the
3057	lines, but by default they are drawn. Here's an example. You start by importing PyLab. Then I've given xVals and yVals1, and if I call pylab.plot of xVals, yVals1. Here is one of the arguments I can give it. I'm saying I'd like this to be plotted in blue, b for blue, and I'd like it to be plotted as a solid line, a single dash. And I want to give that line a label, which I've said is first. YVals2 is a different list. I'll plot it again. Here I'm going to say I want a red dotted line, and the label will be second. And then after plotting it, I'm going to invoke pylab.legend, which puts this nice little box up here in the corner, in this case, saying that first is a solid blue line and second a dashed red line, I should say. Now again, there are lots of arguments, lots of other arguments I could give in plot. Also legend, I can tell it where to put the legend, if I so choose. Here I've
3058	just said, put it wherever you happen to want to put it, or PyLab wants to put it. So a very simple way to produce a plot. There are lots of details and many more examples about plotting in the assigned reading. We've posted a video that Professor Grimson produced for an online course, 600.1x. It's about a 50 minute video broken into multiple segments about how to use plotting in PyLab with a lot more detail than I've given you. You'll see if you read the code for this lecture. And as you see this lecture, there'll be lots of other plots showing up of different kinds. These are my two favorite online sites for finding out what to do. And of course, you can google all sorts of things. That's all I'm going to tell you about how to produce plots in class, but we're going to expect you to learn a lot about it, because I think it's a really useful skill. And at the very least, you should feel comfortable that any plot I show you,
3059	you now-- obviously not right now-- but you will eventually know how to produce. So if you do these things, you'll be more than up to speed. So I started by saying I wanted to plot the trends in distance, and they're interesting.
3060	So you can see, sure enough, the usual drunk, this fuschia line is progressing very slowly and the masochistic drunk, considerably faster. I looked at these, and after looking at those two, I tried to figure out whether there was some mathematical explanation of what was going on, and decided, well, it looked to me like the usual drunk was moving at about the square root of the number of steps. Not so odd to think about it, if you go back to old Pythagoras here. And sure enough, when I plot, and I ran this simulation up to 100,000 steps. When I plot the square root of the number of steps, it's not identical, but it's pretty darn close. Seems to be moving just a tad faster than the square root, but not much. But who knows exactly? But pretty good. And then the masochistic drunk seems to be moving at a rate of numSteps times 0.05. A less intuitive answer than the square root. Why do you think it might be doing that? Well, what we notice is
3061	that-- and we'll look at this-- maybe there's not much difference between what the masochistic drunk and the usual drunk do on the x-axis, east and west. In fact, they shouldn't be. But there should be a difference on the y-axis, because every time, 1/4 of the time, the drunk is taking a step north of 1.1 units, and 1/4 of the time, he's taking a step south of 0.9 units. And so 1/2 the time, the steps are diverging by a small fraction. And if we think about it, 0.1 1/2 the time. We divide it. We get 0.05. So at least we need to do some more analysis, but the data is pretty compelling here that it's a very good fit. Well, let's look at the ending location.
3062	Here I'm showing that you can plot these things without connecting them by lines. And giving them different shapes. So what here I've said is that the masochistic drunk we're going to plot using red triangles, and the usual drunk I'm going to plot using black plus signs. And since I'm going to plot the location at the end of many walks, it doesn't make sense to draw lines connecting everything, because all we're caring about here is the endpoints. So since I only want the endpoints, I'm plotting them a different way. So for example, I can write something like plot( xVals, yVals, and then if I do something like let's see. Just 'b0' in fact. What that says is plot blue circles. I could have written-- in fact I did write 'k+' and that says black plus signs. And I don't actually remember what I did to get the triangles, but it's in the code. And so that's very flexible what you do. And as you can see here, we get the insight I'd communicated earlier that if
3063	you look at east and west, not much difference between this ball and that ball. They seem to be moving about the same spread, the same outliers. But this ball is displaced north. And not surprisingly, after 10,000 steps, you would not expect any of these points to be below zero, where you'd expect roughly half of these points to be below zero. And indeed that's about true. And we see here what's going on that if we look at the mean absolute difference in x and y, we see that not a huge difference between the usual drunk and the masochistic drunk. There happens to be a distance. But a huge difference-- sorry, x and x. Comparing the two y values, there's a big difference, as you see here. So what's the point of all this? It's not to learn about different kinds of drunks. It's to show how, by visualization, we can get insight into our data that if I just printed spreadsheets showing you all of these endpoints, it would be hard to make sense of what
3064	was there. So get accustomed to using plotting to help you understand data. Now let's play a little bit more with the simulation. We looked at different kinds of drunks. Let's look at different kinds of fields. So I want to look at a field with what we'll call a wormhole in it. For those of you of a certain generation, you will recognize the Tardis. So the idea here is that the field is such that as you wander around it, everything is normal. But every once in a while you hit a place where you're magically transported to a different place. So it behaves very peculiarly.
3065	Not odd numbers, but odd as in strange. So it's going to be a subclass of field. We're going to have a parameter that tells us how many worm holes it has. A default value of 1,000. And we'll see how we use xRange and yRange shortly. So what are the first thing we do? Well, we'll call Field _init to initialize the field in the usual way. And then we're going to create a dictionary of wormholes. So for w in the range number of worm holes, I'm going to choose a random x and a random y in xRange minus xRange to plus xRange, minus yRange to yRange. So this is going to be where the worm holes are located. And then for each of those, I'm going to get a random location where you're, in some sense, teleported to if you enter the wormhole. So here we're using random to get random integers. We've seen that before. And so the new location will be the location of the new x and the new y, and we're going
3066	to update this dictionary of wormholes to say that paired with the location x, y is newLoc. Now when we move the drunk, and again this is just changing-- we're overriding moveDrunk, so we're overriding one
3067	So Field.moveDrunk will take a self and a drunk. It's going to get the x value, the y value, and if that is in the wormholes, it's going to move the drunk to the location associated with that wormhole. So we move a drunk, and if the drunk ends up being in the wormhole, he gets transported. So we're using Field.moveDrunk. So notice that we're using the moveDrunk of the superclass, even though we're overriding it here. Because we've overridden it here, I have to say Field. to indicate I want the one from the superclass, not the subclass. And then we're doing something peculiar after the move. So interestingly here, I've taken, I think, a usual drunk and plotted the usual drunk on a walk of 500 steps. One walk, and shown all the places the drunk visited. So we've seen three kinds of plots, one showing how far the drunk would get at different length walks, one showing all the places the drunk would end up with many walks of the same length, and here a single walk,
3068	all the places the drunk visits. And as you can see, the wormholes produce a profound effect, in this case, on where the drunks end up. And again, you have the code. You can run this yourself and simulate it and see what you go. And I think I've set random.Seed to zero in each of the simulations in the code, but you should play with it, change it, to just see that you'll actually get different results with different seeds. Let me summarize here, and say the point of going through these random walks is not the simulations themselves, but how we built them. That we started by defining the classes. We then built functions corresponding to one trial, multiple trials, and reported the results. And then made a set of incremental changes to the simulation so that we could investigate different questions. So we started with a simple simulation with just the usual drunk and the simple field, and we noticed it didn't work. How did we know it? Well, not because when we did the full simulation
3069	we had great insight. I probably could have fooled 1/2 of you and convinced you that that was a reasonable answer. But as soon as we went and did the sanity check, where we knew the answer, we could know something was wrong. And then we went and we fixed it. And then we went and we elaborated it at a step of a time. I first got a more sophistic-- I shouldn't say sophisticated. A different kind of drunk. And then we went to a different kind of field. Finally, we spent time showing how to use plots to get an insight. And in the remaining few minutes of the class, I want to go back and show you some of the plotting commands. To show you how these plots were produced. So one of the things I did, since I knew I was going to be producing a lot of different plots, I decided I would actually not spend time worrying about what kind of markers-- those are the things like the triangles and the plus sign-- or
3070	what colors for each one individually, but instead I'd set up a styleIterator that would just return a bunch of different styles. So once and for all, I could define n styles, and then when I want to plot a new kind of drunk, I would just call the styleIterator to get the next style. So this is a fairly common kind of paradigm to say that I just want to do this once and for all. I don't want to have to go through each time I do this. So what do the styles look like? Let me just get this window. Oh. So here it is. I said there were going to be three styles that I'm going to iterate through. Style one is going to be an m, I guess that's maroon with a line, a blue with a dashed line, and green with a line with a comma and a minus sign. So these are called the styles. And you can control the marker, if you have a marker. You can control the line. You can
3071	control the color. Also you can control the size. You can give the sizes of all these things. What you'll see when you look at the code is I don't like the default styles things, because when they show up on the screen, they're too small. So there's something called rcParams. Those of you who are Unix hackers can maybe guess where that name came from. And I've just said a bunch of things, like that my default line width will be four points. The size for the titles will be 20. You can put titles on the graphs. Various kinds of things. Again, once and for all trying to set some of these parameters so they get used over and over again. And then finally down here, you'll see that I did things like you want to put titles on the slides. So on the graph. So here's the location at end of walk. Title is just a string. You want to label your x and y-axis, so I've labeled them here. And here I've said where I want
3072	the legend to appear in the lower center. I've also set the y-limits and the x-limits on the axis, because I wanted a little extra room. Otherwise, by default it will put points right on the axes, which I find hard to read. Anyway, the point here is not that you understand all of this instantaneously. The point I want to communicate is that it's very flexible. And so if you decide you don't like the way a plot looks and you want to change it, and you know what you want it to look like, there's almost surely a way to make it do that. So don't despair. You can look at the references I gave earlier and figure that out. Next lecture we're going to move on. No more random walks. We'll look at simulating other things, and in particular, we'll look at the question of how believable is a simulation? See you Wednesday if the world has not come to an end.
3073	The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses visit MIT OpenCourseWare at ocw.mit.edu. JOHN GUTTAG: We ended the last lecture looking at greedy algorithms. Today I want to discuss the pros and cons of greedy. Oh, I should mention-- in response to popular demand, I have put the PowerPoint up, so if you download the ZIP file, you'll find the questions, including question 1, the first question, plus the code, plus the PowerPoint. We actually do read Piazza, and sometimes, at least, pay attention. We should pay attention all the time. So what are the pros and cons of greedy? The pro-- and it's a big pro-- is that it's really easy to implement, as you could see. Also enormously important-- it's really fast. We looked at the complexity last time-- it was m log n-- quite quick. The downside-- and this can be either a big problem or
3074	not a big problem-- is that it doesn't actually solve the problem, in the sense that we've asked ourselves to optimize something. And we get a solution that may or may not be optimal. Worse-- we don't even know, in this case, how close to optimal it is. Maybe it's almost optimal, but maybe it's really far away. And that's a big problem with many greedy algorithms. There are some very sophisticated greedy algorithms we won't be looking at that give you a bound on how good the approximation is, but most of them don't do that. Last time we looked at an alternative to a greedy algorithm that was guaranteed to find the right solution. It was a brute force algorithm.
3075	that you enumerate all possible combinations of items, remove the combination whose total units exceed the allowable weight, and then choose the winner from those that are remaining. Now let's talk about how to implement it. And the way I want to implement it is using something called a search tree. There are lots of different ways to implement it. In the second half of today's lecture, you'll see why I happen to choose this particular approach. So what is a search tree? A tree is, basically, a kind of graph. And we'll hear much more about graphs next week. But this is a simple form where you have a root and then children of the root. In this particular form, research C, you have two children. So we start with the root. And then we look at our list of elements to be considered that we might take, and we look at the first element in that list. And then we draw a left branch, which shows the consequence of choosing to take that element, and a right branch,
3076	which shows the consequences of not taking that element. And then we consider the second element, and so on and so forth, until we get to the bottom of the tree. So by convention, the left element will mean we took it, the right direction will mean we didn't take it. And then we apply it recursively to the non-leaf children. The leaf means we get to the end, we've considered the last element to be considered. Nothing else to think about. When we get to the code, we'll see that, in addition to the description being recursive, it's convenient to write the code that way, too. And then finally, we'll choose the node that has the highest value that meets our constraints. So let's look at an example. My example is I have my backpack that can hold a certain number of calories if you will. And I'm choosing between, to keep it small, a beer, a pizza, and a burger-- three essential food groups. The first thing I explore on the left is take the beer, and then
3077	I have the pizza and the burger to continue to consider. I then say, all right, let's take the pizza. Now I have just the burger. Now I taste the burger. This traversal of this generation of the tree is called left-most depth-most. So I go all the way down to the bottom of the tree. I then back up a level and say, all right, I'm now at the bottom. Let's go back and see what happens if I make the other choice at the one level up the tree. So I went up and said, well, now let's see what happens if I make a different decision, as in we didn't take the burger. And then I work my way-- this is called backtracking--
3078	I now say, suppose, I didn't take the piece of pizza. Now I have the beer only and only the burger to think about, so on and so forth, until I've generated the whole tree. You'll notice it will always be the case that the leftmost leaf of this tree has got all the possible items in it, and the rightmost leaf none. And then I just check which of these leaves meets the constraint and what are the values. And if I compute the value and the calories in each one, and if our constraint was 750 calories, then I get to choose the winner, which is-- I guess, it's the pizza and the burger. Is that right? The most value under 750. That's the way I go through. It's quite a straightforward algorithm. And I don't know why we draw our trees with the root at the top and the leaves at the bottom. My only conjecture is computer scientists don't spend enough time outdoors. Now let's think of the computational complexity of this process. The time is
3079	going to be based on the total number of nodes we generate. So if we know the number of nodes that are in the tree, we then know the complexity of the algorithm, the asymptotic complexity. Well, how many levels do we have in the tree? Just the number of items, right? Because at each level of the tree we're deciding to take or not to take an item. And so we can only do that for the number of items we have. So if we go back, for example, and we look at the tree-- not that tree, that tree-- and we count the number of levels, it's going to be based upon the total number of items. We know that because if you look at, say, the leftmost node at the bottom, we've made three separate decisions. So counting the root, it's n plus 1. But we don't care about plus 1 when we're doing asymptotic complexity. So that tells us how many levels we have in the tree. The next question we need to ask is, how
3080	many nodes are there at each level? And you can look at this and see-- the deeper we go, the more nodes we have at each level. In fact, if we come here, we can see that the number of nodes at level i-- depth i of the tree-- is 2 to the i. That makes sense if you remember last time we looked at binary numbers. We're saying we're representing our choices as either 0 or 1 for what we take. If we have n items to choose from, then the number of possible choices is 2 to the n, the size of the powerset. So that will tell us the number of nodes at each level. So if there are n items, the number of nodes in the tree is going to be the sum from 0 to n of 2 to the i because we have that many levels. And if you've studied a little math, you know that's exactly 2 to the n plus 1. Or if you do what I do, you look it up
3081	in Wikipedia and you know it's 2 to the n plus 1. Now, there's an obvious optimization. We don't need to explore the whole tree. If we get to a point where the backpack is overstuffed, there's no point in saying, should we take this next item? Because we know we can't. I generated a bunch of leaves that were useless because the weight was too high. So you could always abort early and say, oh, no point in generating the rest of this part of the tree because we know everything in it will be too heavy. Adding something cannot reduce the weight. It's a nice optimization. It's one you'll see we actually do in the code. But it really doesn't change the complexity. It's not going to change the worst-cost complexity. Exponential, as we saw this, I think, in Eric's lecture, is a big number. You don't usually like 2 to the n. Does this mean that brute force is never useful? Well, let's give it a try. We'll look at some code. Here is the implementation. So
3082	it's maxVal, toConsider, and avail. And then we say, if toConsider is empty or avail is 0-- avail is an index, we're going to go through the list using that to tell us whether or not we still have an element to consider-- then the result will be the tuple 0 and the empty tuple. We couldn't take anything. This is the base of our recursion. Either there's nothing left to consider or there's no available weight-- the Val, as the amount of weight, is 0 or toConsider is empty. Well, if either of those are true, then we ask whether to consider * 0, the first element to look at. Is that cost greater than availability? If it is, we don't need to explore the left branch. because it means we can't afford to put that thing in the backpack, the knapsack. There's just no room for it. So we'll explore the right branch only. The result will be whatever the maximum value is of toConsider of the remainder of the list-- the list with the first element sliced
3083	off-- and availability unchanged. So it's a recursive implementation, saying, now we only have to consider the right branch of the tree because we knew we couldn't take this element. It just weighs too much, or costs too much, or was too fattening, in my case. Otherwise, we now have to consider both branches. So we'll set next item to toConsider of 0, the first one, and explore the left branch. On this branch, there are two possibilities to think about, which I'm calling withVal and withToTake. So I'm going to call maxVal of toConsider of everything except the current element and pass in an available weight of avail minus whatever-- well, let me widen this so we can see the whole code. This is not going to let me widen this window any more. Shame on it. Let me see if I can get rid of the console. Well, we'll have to do this instead. So we're going to call maxVal with everything except the current element and give it avail minus the cost of that next item of
3084	toConsider sub 0. Because we know that the availability, available weight has to have that cost subtracted from it. And then we'll add to withVal next item dot getValue. So that's a value if we do take it. Then we'll explore the right branch-- what happens if we don't take it? And then we'll choose the better branch. So it's a pretty simple recursive algorithm. We just go all the way to the bottom and make the right choice at the bottom, and then percolate back up, like so many recursive algorithms. We have a simple program to test it. I better start a console now if I'm going to run it. And we'll testGreedys on foods. Well, we'll testGreedys and then we'll testMaxVal. So I'm building the same thing we did in Monday's lecture, the same menu. And I'll run the same testGreedys we looked at last time. And we'll see whether or not we get something better when we run the truly optimal one. Well, indeed we do. You remember that last time and, fortunately, this time too,
3085	the best we did was a value of 318. But now we see we can actually get to 353 if we use the truly optimal algorithm. So we see it ran pretty quickly and actually gave us a better answer than we got from the greedy algorithm. And it's often the case. If I have time at the end, I'll show you an optimization program you might want to run that works perfectly fine to use this kind of brute force algorithm on.
3086	So I'm just going through the code again we just ran. This was the header we saw-- toConsider, as the items that correspond to nodes higher up the tree, and avail, as I said, the amount of space. And again, here's what the body of the code loooked like, I took out the comments. One of the things you might think about in your head when you look at this code is putting the comments back in. I always find that for me a really good way to understand code that I didn't write is to try and comment it. And that helps me sort of force myself to think about what is it really doing. So you'll have both versions-- you'll have the PowerPoint version without the comments and the actual code with the comments. You can think about looking at this and then looking at the real code and making sure that you're understanding jibes. I should point out that this doesn't actually build the search tree. We've got this local variable result, starting here, that records the
3087	best solution found so far. So it's not the picture I drew where I generate all the nodes and then I inspect them. I just keep track-- as I generate a node, I say, how good is this? Is it better than the best I've found so far? If so, it becomes the new best. And I can do that because every node I generate is, in some sense, a legal solution to the problem. Probably rarely is it the final optimal solution but it's at least a legal solution. And so if it's better than something we saw before, we can make it the new best. This is very common. And this is, in fact, what most people do with it when they use a search tree-- they don't actually build the tree in the pictorial way we've looked at it but play some trick like this of just keeping track of their results. Any questions about this? All right. We did just try it on example from lecture 1. And we saw that it worked great. It gave
3088	us a better answer.
3089	But we should not take too much solace from the fact that it finished quickly because 2 to the eighth is actually a pretty tiny number. Almost any algorithm is fine when I'm working on something this small. Let's look now at what happens if we have a bigger menu.
3090	Since, as you will discover if you haven't already, I'm a pretty lazy person, I didn't want to write out a menu with a 100 items or even 50 items. So I wrote some code to generate the menus. And I used randomness to do that. This is a Python library we'll be using a lot for the rest of the semester. It's used any time you want to generate things at random and do many other things. We'll come back to it a lot. Here we're just going to use a very small part of it. To build a large menu of some numItems-- and we're going to give the maximum value and the maximum cost for each item. We'll assume the minimum is, in this case, 1. Items will start empty. And then for i in range number of items, I'm going to call this function random dot randint that takes a range of integers from 1 to, actually in this case, maxVal minus 1, or 1 to maxVal, actually, in this case. And it just chooses one
3091	of them at random. So when you run this, you don't know what it's going to get. Random dot randint might return 1, it might return 23, it might return 54. The only thing you know is it will be an integer. And then I'm going to build menus ranging from 5 items to 60 items-- buildLargeMenu, the number of items, with maxVal of 90 and a maxCost of 250, pleasure and calories. And then I'm going to test maxVal on each of these menus. So building menus of various sizes at random and then just trying to find the optimal value for each of them. Let's look at the code. Let's comment this out, we don't need to run that again. So we'll build a large menu and then we'll try it for a bunch of items and see what we get. So it's going along. Trying the menu up to 30 went pretty quickly. So even 2 to the 30 didn't take too long. But you might notice it's kind of bogging down, we got 35. I guess,
3092	I could ask the question now-- it was one of the questions I was going to ask as a poll but maybe I won't bother-- how much patience do we have? When do you think we'll run out of patience and quit? If you're out of patience, raise your hand. Well, some of you are way more patient than I am. So we're going to quit anyway. We were trying to do 40. It might have finished 40, 45. I've never waited long enough to get to 45. It just is too long. That raises the question, is it hopeless? And in theory, yes. As I mentioned last time, it is an inherently exponential problem. The answer is-- in practice, no. Because there's something called dynamic programming, which was invented by a fellow at the RAND Corporation called Richard Bellman, a rather remarkable mathematician/computer scientist. He wrote a whole book on it, but I'm not sure why because it's not that complicated. When we talk about dynamic programming, it's a kind of a funny story, at least to me. I
3093	learned it and I didn't know anything about the history of it. And I've had all sorts of theories about why it was called dynamic programming. You know how it is, how people try and fit a theory to data. And then I read a history book about it, and this was Bellman's own description
3094	And it turned out, as you can see, he basically chose a word because it was the description that didn't mean anything. Because he was doing mathematics, and at the time he was being funded by a part of the Defense Department that didn't approve of mathematics. And he wanted to conceal that fact. And indeed at the time, the head of Defense Appropriations in the US Congress didn't much like mathematics. And he was afraid that he didn't want to have to go and testify and tell people he was doing math. So he just invented something that no one would know what it meant. And years of students spent time later trying to figure out what it actually did mean. Anyway, what's the basic idea? To understand it I want to temporarily abandon the knapsack problem and look at a much simpler problem-- Fibonacci numbers.
3095	when you saw it. N equals 0, n equals 1-- return 1. Otherwise, fib of n minus 1 plus fib of n minus 2. And as I think you saw when you first saw it, it takes a long time to run. Fib of 120, for example, is a very big number. It's shocking how quickly Fibonacci grows. So let's think about implementing it. If we run Fibonacci-- well, maybe we'll just do that. So here is fib of n, let's just try running it. And again, we'll test people's patience. We'll see how long we're letting it run. I'm going to try for i in the range of 121. We'll print fib of i. Comes clumping along. It slows down pretty quickly. And if you look at it, it's kind of surprising it's this slow because these numbers aren't that big. These are not enormous numbers. Fib of 35 is not a huge number. Yet it took a long time to compute. So you have the numbers growing pretty quickly but the computation, actually, seems to be growing faster
3096	than the results. We're at 37. It's going to gets slower and slower, even though our numbers are not that big. The question is, what's going on? Why is it taking so long for Fibonacci to compute these results? Well, let's call it and look at the question. And to do that I want to look at the call tree.
3097	which, I think, most of us would agree was not a very big number. And let's look what's going on here. If you look at this, what in some sense seems really stupid about it? What is it doing that a rational person would not want to do if they could avoid it? It's bad enough to do something once. But to do the same thing over and over again is really wasteful. And if we look at this, we'll see, for example, that fib 4 is being computed here, and fib 4 is being computed here. Fib 3 is being considered here, and here, and here. And do you think we'll get a different answer for fib 3 in one place when we get it in the other place? You sure hope not. So you think, well, what should we do about this? How would we go about avoiding doing the same work over and over again? And there's kind of an obvious answer, and that answer is at the heart of dynamic programming. What's the answer? AUDIENCE: [INAUDIBLE]
3098	JOHN GUTTAG: Exactly. And I'm really happy that someone in the front row answered the question because I can throw it that far. You store the answer and then look it up when you need it. Because we know that we can look things up very quickly. Dictionary, despite what Eric said in his lecture, almost all the time works in constant time if you make it big enough, and it usually is in Python. We'll see later in the term how to do that trick. So you store it and then you'd never have to compute it again. And that's the basic trick behind dynamic programming. And it's something called memoization, as in you create a memo and you store it in the memo. So we see this here. Notice that what we're doing is trading time for space. It takes some space to store the old results, but negligible related to the time we save. So here's the trick. We're going to create a table to record what we've done. And then before computing fib of x, we'll
3099	check if the value has already been computed. If so, we just look it up and return it. Otherwise, we'll compute it-- it's the first time-- and store it in the table. Here is a fast implementation of Fibonacci that does that. It looks like the old one, except it's got an extra argument-- memo-- which is a dictionary. The first time we call it, the memo will be empty. It tries to return the value in the memo. If it's not there, an exception will get raised, we know that.
3100	and then store it in the memo and return it. It's the same old recursive thing we did before but with the memo. Notice, by the way, that I'm using exceptions not as an error handling mechanism, really, but just as a flow of control. To me, this is cleaner than writing code that says, if this is in the keys, then do this, otherwise, do that. It's slightly fewer lines of code, and for me, at least, easier to read to use try-except for this sort of thing. Let's see what happens if we run this one. Get rid of the slow fib and we'll run fastFib. Wow. We're already done with fib 120. Pretty amazing, considering last time we got stuck around 40. It really works, this memoization trick. An enormous difference. When can you use it? It's not that memorization is a magic bullet that will solve all problems. The problems it can solve, it can help with, really, is the right thing. And by the way, as we'll see, it finds an optimal solution, not an
3101	approximation. Problems have two things called optimal substructure, overlapping subproblems. What are these mean? We have optimal substructure when
3102	found by combining optimal solutions to local subproblems. So for example, when x is greater than 1 we can solve fib x by solving fib x minus 1 and fib x minus 2 and adding those two things together. So there is optimal substructure-- you solve these two smaller problems independently of each other and then combine the solutions in a fast way. You also have to have something called overlapping subproblems. This is why the memo worked. Finding an optimal solution has to involve solving the same problem multiple times. Even if you have optimal substructure, if you don't see the same problem more than once-- creating a memo. Well, it'll work, you can still create the memo. You'll just never find anything in it when you look things up because you're solving each problem once. So you have to be solving the same problem multiple times and you have to be able to solve it by combining solutions to smaller problems. Now, we've seen things with optimal substructure before. In some sense, merge sort worked that way-- we
3103	were combining separate problems. Did merge sort have overlapping subproblems? No, because-- well, I guess, it might have if the list had the same element many, many times. But we would expect, mostly not. Because each time we're solving a different problem, because we have different lists that we're now sorting and merging. So it has half of it but not the other. Dynamic programming will not help us for sorting, cannot be used to improve merge sort. Oh, well, nothing is a silver bullet. What about the knapsack problem? Does it have these two properties? We can look at it in terms of these pictures. And it's pretty clear that it does have optimal substructure because we're taking the left branch and the right branch and choosing the winner. But what about overlapping subproblems? Are we ever solving, in this case, the same problem-- add two nodes? Well, do any of these nodes look identical? In this case, no. We could write a dynamic programming solution to the knapsack problem-- and we will-- and run it on this example,
3104	"and we'd get the right answer. We would get zero speedup. Because at each node, if you can see, the problems are different. We have different things in the knapsack or different things to consider. Never do we have the same contents and the same things left to decide. So ""maybe"" was not a bad answer if that was the answer you gave to this question. But let's look at a different menu. This menu happens to have two beers in it. Now, if we look at what happens, do we see two nodes that are solving the same problem? The answer is what? Yes or no? I haven't drawn the whole tree here. Well, you'll notice the answer is yes."
3105	Why is it? Well, in this node, we took this beer and still had this one to consider. But in this node, we took that beer but it doesn't matter which beer we took. We still have a beer in the knapsack and a burger and a slice to consider. So we got there different ways, by choosing different beers, but we're in the same place. So in fact, we actually, in this case, do have the same problem to solve more than once. Now, here I had two things that were the same. That's not really necessary. Here's another very small example. And the point I want to make here is shown by this. So here I have again drawn a search tree. And I'm showing you this because, in fact, it's exactly this tree that will be producing in our dynamic programming solution to the knapsack problem. Each node in the tree starts with what you've taken-- initially, nothing, the empty set. What's left, the total value, and the remaining calories. There's some redundancy here, by the way.
3106	If I know what I've taken, I could already always compute the value and what's left. But this is just so it's easier to see. And I've numbered the nodes here in the order in which they're get generated. Now, the thing that I want you to notice is, when we ask whether we're solving the same problem, we don't actually care what we've taken. We don't even care about the value. All we care is, how much room we have left in the knapsack and which items we have left to consider. Because what I take next or what I take remaining really has nothing to do with how much value I already have because I'm trying to maximize the value that's left, independent of previous things done. Similarly, I don't care why I have a 100 calories left. Whether I used it up on beers or a burger, doesn't matter. All that matters is that I just have 100 left. So we see in a large complicated problem it could easily be a situation where different choices of
3107	what to take and what to not take would leave you in a situation where you have the same number of remaining calories. And therefore you are solving a problem you've already solved. At each node, we're just given the remaining weight, maximize the value by choosing among the remaining items. That's all that matters.
3108	As we see in this tree, for the example we just saw, the box is around a place where we're actually solving the same problem, even though we've made different decisions about what to take, A versus B. And in fact, we have different amounts of value in the knapsack-- 6 versus 7. What matters is we still have C and D to consider and we have two units left. It's a small and easy step. I'm not going to walk you through the code because it's kind of boring to do so. How do you modify the maxVal we looked at before to use a memo? First, you have to add the third argument, which is initially going to be set to the empty dictionary. The key of the memo will be a tuple-- the items left to be considered and the available weight. Because the items left to be considered are in a list, we can represent the items left to be considered by how long the list is. Because we'll start at the front item and just
3109	work our way to the end. And then the function works, essentially, exactly the same way fastFib worked. I'm not going to run it for you because we're running out of time. You might want to run it yourself because it is kind of fun to see how really fast it is.
3110	This column is what we would get with the original recursive implementation where we didn't use a memo. And it was therefore 2 to the length of items. And as you can see, it gets really big or, as we say at the end, huge. But the number of calls grows incredibly slowly for the dynamic programming solution. In the beginning it's worth Oh, well. But by the time we get to the last number I wrote, we're looking at 43,000 versus some really big number I don't know how to pronounce-- 18 somethings. Incredible improvement in performance. And then at the end, it's a number we couldn't fit on the slide, even in tiny font. And yet, only 703,000 calls. How can this be? We know the problem is inherently exponential. Have we overturned the laws of the universe? Is dynamic programming a miracle in the liturgical sense? No. But the thing I want you to carry away is that computational complexity can be a very subtle notion. The running time of fastMaxVal is governed by the number of
3111	distinct pairs that we might be able to use as keys in the memo-- toConsider and available. The number of possible values of toConsider is small. It's bounded by the length of the items. If I have a 100 items, it's 0, 1, 2, up to a 100. The possible values of available weight is harder to characterize. But it's bounded by the number of distinct sums of weights you can get. If I start with 750 calories left, what are the possibilities? Well, in fact, in this case, maybe we can take only 750 because we're using with units. So it's small. But it's actually smaller than that because it has to do with the combinations of ways I can add up the units I have. I know this is complicated. It's not worth my going through the details in the lectures. It's covered in considerable detail in the assigned reading. Quickly summarizing lectures 1 and 2,
3112	Many problems of practical importance can be formulated as optimization problems. Greedy algorithms often provide an adequate though often not optimal solution. Even though finding an optimal solution is, in theory, exponentially hard, dynamic programming really often yields great results. It always gives you a correct result and it's sometimes, in fact, most of the times gives it to you very quickly. Finally, in the PowerPoint, you'll find an interesting optimization problem
3113	that grades into a quiz. And it's simply a question of solving this optimization problem.
3114	The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. JOHN GUTTAG: All right, welcome to the 60002, or if you were in 600, the second half of 600. I'm John Guttag. Let me start with a few administrative things. What's the workload? There are problem sets. They'll all be programming problems much in the style of 60001. And the goal-- really twofold. 60001 problem sets were mostly about you learning to be a programmer. A lot of that carries over. No one learns to be a programmer in half a semester. So a lot of it is to improve your skills, but also there's a lot more, I would say, conceptual, algorithmic material in 60002, and the problem sets are designed to help cement that as well as just to give you programming experience. Finger exercises, small things. If they're taking you more than 15
3115	minutes, let us know. They really shouldn't, and they're generally designed to help you learn a single concept, usually a programming concept. Reading assignments in the textbooks, I've already posted the first reading assignment, and essentially they should provide you a very different take on the same material we're covering in lectures and recitations. We've tried to choose different examples for lectures and from the textbooks for the most part, so you get to see things in two slightly different ways. There'll be a final exam based upon all of the above. All right, prerequisites-- experience writing object-oriented programs in Python, preferably Python 3.5. Familiarity with concepts of computational complexity. You'll see even in today's lecture, we'll be assuming that. Familiarity with some simple algorithms. If you took 60001 or you took the 60001 advanced standing exam, you'll be fine. Odds are you'll be fine anyway, but that's the safest way to do it. So the programming assignments are going to be a bit easier, at least that's what students have reported in the past, because they'll be more focused
3116	"on the problem to be solved than on the actual programming. The lecture content, more abstract. The lectures will be-- and maybe I'm speaking euphemistically-- a bit faster paced. So hang on to your seats. And the course is really less about programming and more about dipping your toe into the exotic world of data science. We do want you to hone your programming skills. There'll be a few additional bits of Python. Today, for example, we'll talk about lambda abstraction. Inevitably, some comments about software engineering, how to structure your code, more emphasis in using packages. Hopefully it will go a little bit smoother than in the last problem set in 60001. And finally, it's the old joke about programming that somebody walks up to a taxi driver in New York City and says, ""I'm lost. How do I get to Carnegie Hall?"" The taxi driver turns to the person and says, ""practice, practice, practice."" And that's really the only way to learn to program is practice, practice, practice. The main topic of the course is what I think"
3117	of as computational models. How do we use computation to understand the world in which we live? What is a model? To me I think of it as an experimental device that can help us to either understand something that has happened, to sort of build a model that explains phenomena we see every day, or a model that will allow us to predict the future, something that hasn't happened. So you can think of, for example, a climate change model. We can build models that sort of explain how the climate has changed over the millennia, and then we can build probably a slightly different model that might predict what it will be like in the future. So essentially what's happening is science is moving out of the wet lab and into the computer. Increasingly, I'm sure you all see this-- those of you who are science majors-- an increasing reliance on computation rather than traditional experimentation. As we'll talk about, traditional experimentation is and will remain important, but now it has to really be supplemented by computation. We'll
3118	talk about three kinds of models--
3119	So let's talk first about optimization models. An optimization model is a very simple thing. We start with an objective function that's either to be maximized or minimized. So for, example, if I'm going from New York to Boston, I might want to find a route by car or plane or train that minimizes the total travel time. So my objective function would be the number of minutes spent in transit getting from a to b. We then often have to layer on top of that objective function a set of constraints, sometimes empty, that we have to obey. So maybe the fastest way to get from New York to Boston is to take a plane, but I only have $100 to spend. So that option is off the table. So I have the constraints there on the amount of money I can spend. Or maybe I have to be in Boston before 5:00 PM and while the bus would get me there for $15, it won't get me there before 5:00. And so maybe what I'm left with is
3120	driving, something like that. So objective function, something you're either minimizing or maximizing, and a set of constraints that eliminate some solutions. And as we'll see, there's an asymmetry here. We handle these two things differently. We use these things all the time. I commute to work using Waze, which essentially is solving-- not very well, I believe-- an optimization problem to minimize my time from home to here. When you travel, maybe you log into various advisory programs that try and optimize things for you. They're all over the place. Today you really can't avoid using optimization algorithm as you get through life. Pretty abstract. Let's talk about a specific optimization problem called the knapsack problem. The first time I talked about the knapsack problem I neglected to show a picture of a knapsack, and I was 10 minutes into it before I realized most of the class had no idea what a knapsack was. It's what we old people used to call a backpack, and they used to look more like that than they look today. So the
3121	knapsack problem involves-- usually it's told in terms of a burglar who breaks into a house and wants to steal a bunch of stuff but has a knapsack that will only hold a finite amount of stuff that he or she wishes to steal. And so the burglar has to solve the optimization problem of stealing the stuff with the most value while obeying the constraint that it all has to fit in the knapsack. So we have an objective function. I'll get the most for this when I fence it. And a constraint, it has to fit in my backpack. And you can guess which of these might be the most valuable items here. So here is in words, written words what I just said orally. There's more stuff than you can carry, and you have to choose which stuff to take and which to leave behind. I should point out that there are two variants of it. There's the 0/1 knapsack problem and the continuous. The 0/1 would be illustrated by something like this. So the 0/1 knapsack
3122	problem means you either take the object or you don't. I take that whole gold bar or I take none of it. The continuous or so-called fractional knapsack problem says I can take pieces of it. So maybe if I take in my gold bar and shaved it into gold dust, I then can say, well, the whole thing won't fit in, but I can fit in a path, part of it. The continuous knapsack problem is really boring. It's easy to solve. How do you think you would solve the continuous problem? Suppose you had over here a pile of gold and a pile of silver and a pile of raisins, and you wanted to maximize your value. Well, you'd fill up your knapsack with gold until you either ran out of gold or ran out of space. If you haven't run out of space, you'll now put silver in until you run out of space. If you still haven't run out of space, well, then you'll take as many raisins as you can fit in. But you can
3123	solve it with what's called a greedy algorithm, and we'll talk much more about this as we go forward. Where you take the best thing first as long as you can and then you move on to the next thing. As we'll see, the 0/1 knapsack problem is much more complicated because once you make a decision, it will affect the future decisions. Let's look at an example, and I should probably warn you, if you're hungry, this is not going to be a fun lecture. So here is my least favorite because I always want to eat more than I'm supposed to eat. So the point is typically knapsack problems are not physical knapsacks but some conceptual idea. So let's say that I'm allowed 1,500 calories of food, and these are my options. I have to go about deciding, looking at this food-- and it's interesting, again, there's things showing up on your screen that are not showing up on my screen, but they're harmless, things like how my mouse works. Anyway, so I'm trying to take some fraction
3124	of this food, and it can't add up to more than 1,500 calories. The problem might be that once I take something that's 1,485 calories, I can't take anything else, or maybe 1,200 calories and everything else is more than 300. So once I take one thing, it constrains possible solutions. A greedy algorithm, as we'll see, is not guaranteed to give me the best answer. Let's look at a formalization of it. So each item is represented by a pair, the value of the item and the weight of the item. And let's assume the knapsack can accommodate items with the total weight of no more than w. I apologize for the short variable names, but they're easier to fit on a slide. Finally, we're going to have a vector l of length n representing the set of available items. This is assuming we have n items to choose from. So each element of the vector represents an item. So those are the items we have. And then another vector v is going to indicate whether or not an
3125	item was taken. So essentially I'm going to use a binary number to represent the set of items I choose to take. For item three say, if bit three is zero I'm not taking the item. If bit three is one, then I am taking the item. So it just shows I can now very nicely represent what I've done by a single vector of zeros and ones. Let me pause for a second. Does anyone have any questions about this setup? It's important to get this setup because what we're going to see now depends upon that setting in your head. So I've kind of used mathematics to describe the backpack problem. And that's typically the way we deal with these optimization problems. We start with some informal description, and then we translate them into a mathematical representation. So here it is. We're going to try and find a vector v that maximizes the sum of V sub i times I sub i. Now, remember I sub i is the value of the item. V sub i is either
3126	zero or one So if I didn't take the item, I'm multiplying its value by zero. So it contributes nothing to the sum. If I did take the item, I'm multiplying its value by one. So the value of the item gets added to the sum. So that tells me the value of V. And I want to get the most valuable V I can get subject to the constraint that if I look at the item's dot weight and multiply it by V, the sum of the weights is no greater than w. So I'm playing the same trick with the values of multiplying each one by zero or one, and that's my constraint. Make sense? All right, so now we have the problem formalized. How do we solve it? Well, the most obvious solution is brute force. I enumerate all possible combinations of items; that is to say, I generate all subsets of the items that are available-- I don't know why it says subjects here, but we should have said items. Let me fix that. This is
3127	called the power set. So the power set of a set includes the empty subset. It includes the set that includes everything and everything in between. So subsets of size one, subsets of size two, et cetera. So now I've generated all possible sets of items. I can now go through and sum up the weights and remove all those sets that weigh more than I'm allowed. And then from the remaining combinations, choose any one whose value is the largest. I say choose any one because there could be ties, in which case I don't care which I choose. So it's pretty obvious that this is going to give you a correct answer. You're considering all possibilities and choosing a winner. Unfortunately, it's usually not very practical. What we see here is that's what the power set is if you have 100 vec. Not very practical, right, even for a fast computer generating that many possibilities is going to take a rather long time. So kind of disappointing. We look at it and say, well, we got a brute
3128	force algorithm. It will solve the problem, but it'll take too long. We can't actually do it. 100 is a pretty small number, right. We often end up solving optimization problems where n is something closer to 1,000, sometimes even a million. Clearly, brute force isn't going to work. So that raises the next question, are we just being stupid? Is there a better algorithm that I should have showed you? I shouldn't say we. Am I just being stupid? Is there a better algorithm that would have given us the answer? The sad answer to that is no for the knapsack problem. And indeed many optimization problems are inherently exponential. What that means is there is no algorithm that provides an exact solution to this problem whose worst case running time is not exponential in the number of items. It is an exponentially hard problem. There is no really good solution. But that should not make you sad because while there's no perfect solution, we're going to look at a couple of really very good solutions that will make
3129	this poor woman a happier person. So let's start with the greedy algorithm. I already talked to you about greedy algorithms. So it could hardly be simpler. We say while the knapsack is not full, put the best available item into the knapsack. When it's full, we're done. You do need to ask a question. What does best mean? Is the best item the most valuable? Is it the least expensive in terms of, say, the fewest calories, in my case? Or is it the highest ratio of value to units? Now, maybe I think a calorie in a glass of beer is worth more than a calorie in a bar of chocolate, maybe vice versa.
3130	So you're about to sit down to a meal. You know how much you value the various different foods. For example, maybe you like donuts more than you like apples. You have a calorie budget, and here we're going to have a fairly austere budget-- it's only one meal; it's not the whole day-- of 750 calories, and we're going to have to go through menus and choose what to eat. That is as we've seen a knapsack problem. They should probably have a knapsack solver at every McDonald's and Burger King. So here's a menu I just made up of wine, beer, pizza, burger, fries, Coke, apples, and a donut, and the value I might place on each of these and the number of calories that actually are in each of these. And we're going to build a program that will find an optimal menu. And if you don't like this menu, you can run the program and change the values to be whatever you like. Well, as you saw if you took 60001, we like to start with
3131	an abstract data type, like to organize our program around data abstractions. So I've got this class food. I can initialize things. I have a getValue, a getCost, density, which is going to be the value divided by the cost, and then a string representation. So nothing here that you should not all be very familiar with. Then I'm going to have a function called buildMenu,
3132	and a list of values of equal length and a list of calories. They're all the same length. And it will build the menu. So it's going to be a menu of tuples-- a menu of foods, rather. And I build each food by giving it its name, its value, and its caloric content. Now I have a menu. Now comes the fun part.
3133	I called it a flexible greedy primarily because of this key function over here. So you'll notice in red there's a parameter called keyfunction. That's going to be-- map the elements of items to numbers. So it will be used to sort the items. So I want to sort them from best to worst, and this function will be used to tell me what I mean by best. So maybe keyfunction will just return the value or maybe it will return the weight or maybe it will return some function of the density. But the idea here is I want to use one greedy algorithm independently of my definition of best. So I use keyfunction to define what I mean by best. So I'm going to come in. I'm going to sort it from best to worst. And then for i in range len of items sub copy-- I'm being good. I've copied it. That's why you sorted rather than sort. I don't want to have a side effect in the parameter. In general, it's not good hygiene to do
3134	that. And so for-- I'll go through it in order from best to worst. And if the value is less than the maximum cost, if putting it in would keep me under the cost or not over the cost, I put it in, and I just do that until I can't put anything else in. So I might skip a few because I might get to the point where there's only a few calories left, and the next best item is over that budget but maybe further down I'll find one that is not over it and put it in. That's why I can't exit as soon as I reach-- as soon as I find an item that won't fit. And then I'll just return. Does this make sense? Does anyone have any doubts about whether this algorithm actually works? I hope not because I think it does work. Let's ask the next question. How efficient do we think it is? What is the efficiency of this algorithm? Let's see where the time goes. That's the algorithm we just looked
3135	at. So I deleted the comment, so we'd have a little more room in the slide. Who wants to make a guess? By the way, this is the question. So please go answer the questions. We'll see how people do. But we can think about it as well together. Well, let's see where the time goes. The first thing is at the sort. So I'm going to sort all the items. And we heard from Professor Grimson how long the sort takes. See who remembers. Python uses something called timsort, which is a variant of something called quicksort, which has the same worst-case complexity as merge sort. And so we know that is n log n where n in this case would be the len of items. So we know we have that. Then we have a loop. How many times do we go through this loop? Well, we go through the loop n times, once for each item because we do end up looking at every item. And if we know that, what's the order? AUDIENCE: [INAUDIBLE]. JOHN GUTTAG:
3136	N log n plus n-- I guess is order n log n, right? So it's pretty efficient. And we can do this for big numbers like a million. Log of a million times a million is not a very big number. So it's very efficient. Here's some code that uses greedy. Takes in the items, the constraint, in this case will be the weight, and just calls greedy, but with the keyfunction and prints what we have. So we're going to test greedy. I actually think I used 750 in the code, but we can use 800. It doesn't matter. And here's something we haven't seen before. So used greedy by value to allocate and calls testGreedy with food, maxUnits and Food.getValue. Notice it's passing the function. That's why it's not-- no closed parentheses after it. Used greedy to allocate. And then we have something pretty interesting. What's going on with this lambda? So here we're going to be using greedy by density to allocate-- actually, sorry, this is greedy by cost. And you'll notice what we're doing is-- we
3137	don't want to pass in the cost, right, because we really want the opposite of the cost. We want to reverse the sort because we want the cheaper items to get chosen first. The ones that have fewer calories, not the ones that have more calories. As it happens, when I define cost, I defined it in the obvious way, the total number of calories. So I could have gone and written another function to do it, but since it was so simple, I decided to do it in line. So let's talk about lambda and then come back to it. Lambda is used to create an anonymous function, anonymous in the sense that it has no name. So you start with the keyword lambda. You then give it a sequence of identifiers and then some expression. What lambda does is it builds a function that evaluates that expression on those parameters and returns the result of evaluating the expression. So instead of writing def, I have inline defined a function. So if we go back to it here, you
3138	can see that what I've done is lambda x one divided by Food.getCost of x. Notice food is the class name here. So I'm taking the function getCost from the class food, and I'm passing it the parameter x, which is going to be what? What's the type of x going to be? I can wait you out. What is the type of x have to be for this lambda expression to make sense? Well, go back to the class food. What's the type of the argument of getCost? What's the name of the argument to getCost? That's an easier question. We'll go back and we'll look at it. What's the type of the argument to getCost? AUDIENCE: Food. JOHN GUTTAG: Food. Thank you. So I do have-- speaking of food, we do have a tradition in this class that people who answer questions correctly get rewarded with food. Oh, Napoli would have caught that. So it has to be of type food because it's self in the class food. So if we go back to here, this x has
3139	to be of type food, right. And sure enough, when we use it, it will be. Let's now use it. I should point out that lambda can be really handy as it is here, and it's possible to write amazing, beautiful, complicated lambda expressions. And back in the good old days of 6001 people learned to do that. And then they learned that they shouldn't. My view on lambda expressions is if I can't fit it in a single line, I just go right def and write a function definition because it's easier to debug. But for one-liners, lambda is great.
3140	So here's this function testGreedy, takes foods and the maximum number of units. And it's going to go through and it's going to test all three greedy algorithms. And we just saw that, and then here is the call of it. And so I picked up some names and the values. This is just the menu we saw. I'm going to build the menus, and then I'm going to call testGreedys. So let's go look at the code that does this. So here you have it or maybe you don't, because every time I switch applications Windows decides I don't want to show you the screen anyway. This really shouldn't be necessary. Keep changes. Why it keeps forgetting, I don't know. Anyway, so here's the code. It's all the code we just looked at. Now let's run it. Well, what we see here is that we use greedy by value to allocate 750 calories, and it chooses a burger, the pizza, and the wine for a total of-- a value of 284 happiness points, if you will. On the other
3141	hand, if we use greedy by cost, I get 318 happiness points and a different menu, the apple, the wine, the cola, the beer, and the donut. I've lost the pizza and the burger. I guess this is what I signed up for when I put my preferences on. And here's another solution with 318, apple, wine-- yeah, all right. So I actually got the same solution, but it just found them in a different order. Why did it find them in a different order? Because the sort order was different because in this case I was sorting by density. From this, we see an important point about greedy algorithms, right, that we used the algorithm and we got different answers. Why do we have different answers? The problem is that a greedy algorithm makes a sequence of local optimizations, chooses the locally optimal answer at every point, and that doesn't necessarily add up to a globally optimal answer. This is often illustrated by showing an example of, say, hill climbing. So imagine you're in a terrain that looks something
3142	like this, and you want to get to the highest point you can get. So you might choose as a greedy algorithm if you can go up, go up; if you can't go up, you stop. So whenever you get a choice, you go up. And so if I start here, I could right in the middle maybe say, all right, it's not up but it's not down either. So I'll go either left or right. And let's say I go right, so I come to here. Then I'll just make my way up to the top of the hill, making a locally optimal decision head up at each point, and I'll get here and I'll say, well, now any place I go takes me to a lower point. So I don't want to do it, right, because the greedy algorithm says never go backwards. So I'm here and I'm happy. On the other hand, if I had gone here for my first step, then my next step up would take me up, up, up, I'd get to here, and
3143	I'd stop and say, OK, no way to go but down. I don't want to go down. I'm done. And what I would find is I'm at a local maximum rather than a global maximum. And that's the problem with greedy algorithms, that you can get stuck at a local optimal point and not get to the best one. Now, we could ask the question, can I just say don't worry about a density will always get me the best answer? Well, I've tried a different experiment. Let's say I'm feeling expansive and I'm going to allow myself 1,000 calories. Well, here what we see is the winner will be greedy by value, happens to find a better answer, 424 instead of 413. So there is no way to know in advance. Sometimes this definition of best might work. Sometimes that might work. Sometimes no definition of best will work, and you can't get to a good solution-- you get to a good solution. You can't get to an optimal solution with a greedy algorithm. On Wednesday, we'll talk about
3144	how do you actually guarantee finding an optimal solution in a better way than brute force. See you then.
3145	The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. ERIC GRIMSON: OK, welcome back or welcome, depending on whether you've been away or not. I'm going to start with two simple announcements. There is a reading assignment for this lecture, actually for the next two lectures, which is chapter 18. And on a much happier note, there is no lecture Wednesday because we hope that you're going to be busy preparing to get that tryptophan poisoning as you eat way too much turkey and you fall asleep. More importantly, I hope you have a great break over Thanksgiving, whether you're here or you're back home or wherever you are. But no lecture Wednesday. Topic for today, I'm going to start with seems like-- sorry, what's going to seem like a really obvious statement. We're living in a data intensive world. Whether you're a scientist, an
3146	engineer, social scientist, financial worker, politician, manager of a sports team, you're spending increasingly larger amounts of time dealing with data. And if you're in one of those positions, that often means that you're either writing code or you're hiring somebody to write code for you to figure out that data. And this section of the course is focusing on exactly that issue. We want to help you understand what you can try to do with software that manipulates data, how you can write code that would do that manipulation of data for you, and especially what you should believe about what that software tells you about data, because sometimes it tells you stuff that isn't exactly what you need to know. And today we're going to start that by looking at particularly the case where we get data from experiments. So think of this lecture and the next one as sort of being statistics meets experimental science. So what do I mean by that? Imagine you're doing a physics lab, biology lab, a chemistry lab, or even something in
3147	sociology or anthropology, you conduct an experiment to gather some data. It could be measurements in a lab. It could be answers on a questionnaire. You get a set of data. Once you've got the data, you want to think about what can I do with it, and that usually will involve using some model, some theory about the underlying process to generate questions about the data. What does this data and the model associated with it tell me about future expectations, help me predict other results that will come out of this data. In the social case, it could be how do I think about how people are going to respond to a poll about who are you voting for in the next election, for example. Given the data, given the model, the third thing we're typically going to want to do is then design a computation to help us answer questions about the data, run a computational experiment to complement the physical experiment or the social experiment we used to gather the data in the first place. And
3148	that computation could be something deep. It could be something a little more interesting, depending on how you're thinking about it. But we want to think about how do we use computation to run additional experiments for us. So I'm going to start by using an example of gathering experimental data, and I want to start with the idea of a spring. How would I model a spring? How would I gather data about a spring? And how would I write software to help me answer questions about a spring? So what's spring? Well, there's one kind of spring, a little hard to model, although it could be interesting what's swimming around in there and how do I think about the ecological implications of that spring. Here's a second kind of spring. It's about four or five months away, but eventually we'll get through this winter and get to that spring and that would be nice, but I'm not going to model that one either. And yes, my jokes are really bad, and yes, you can't do a darn thing
3149	about them because I am tenured because-- while I'd like to model these two springs, we're going to stick with the one that you see in physics labs, these kinds of springs, so-called linear springs. And these are springs that have the property that you can stretch or compress them by applying a force to it. And when you release them, they literally spring back to the position they were originally. So we're going to deal with these kinds of springs. And the distinguishing characteristics of these two springs and others in this class is that that force you require to compress it or stretch it a certain amount-- the amount of force you require varies linearly in the distance. So if it takes some amount of force to compress it some amount of distance, it takes twice as much force to compress it twice as much of a distance. It's linearly related. So each one of these springs-- these kinds of springs has that property. The amount of force needed to stretch or compress it's linear in that distance.
3150	Associated with these springs there is something called a spring constant-- usually represented by the number k-- that determines how much force do you need to stretch or compress the spring. Now, it turns out that that spring constant can vary a lot. The slinky actually has a very low spring constant. It's one newton per meter. That spring on the suspension of a motorcycle has a much bigger spring constant. It's a lot stiffer, 35,000 newtons per meter. And just in case you don't remember, a newton is the amount of force you need to accelerate a one-kilogram mass one meter per second squared. We'll come back to that in a second. But the idea is we'd like to think about how do we model these kinds of springs. Well, turns out, fortunately for us, that that was done about 300-plus years ago by a British physicist named Robert Hooke. Back in 1676 he formulated Hooke's law of elasticity. Simple expression that says the force you need to compress or stretch a spring is linearly related to the distance,
3151	d, that you've actually done that compression in, or another way of saying it is, if I compress a spring some amount, the force that's stored in it is linearly related to that distance. And the negative sign here basically says it's pointing in the opposite direction. So if I compress, the force is going to push it back out. If I stretch it, the force is going to push back into that resting position. Now, this law holds for a wide range of springs, which is kind of nice. It's going to hold both in biological systems as well as in physical systems. It doesn't hold perfectly. There's a limit to how much you can stretch, in particular, a spring before the law breaks down, and maybe you did this as a kid, right. If you take a slinky and pull it too far apart, it stops working because you've exceeded what's called the elastic limit of the spring. Similarly, if you compress it too far, although I think you have to compress it a long ways, it'll stop
3152	working as well. So it doesn't hold completely, and it also doesn't hold for all springs. Only those springs that satisfy this linear law, which are a lot of them. So, for example, it doesn't apply to rubber bands, it doesn't apply to recurved bows. Those are two examples of springs that do not obey this linear relationship. But nonetheless, there's Hooke's law. And one of the things we can do is say, well, let's use it to do a little bit of reasoning about this spring. So we can ask the question, how much does a rider have to weigh to compress this spring by one centimeter? And we've got Hooke's law, and I also gave you a little bit of hint here. So I told you that this spring has a spring constant of 35,000 newtons per meter. So I could just plug this in, right, one centimeter, it's 1/100 of a meter times-- so that's the-- there's the spring constant. There's the amount we're going to compress it. Do a little math, and that says that the
3153	force I need is 350 newtons. So what's a newton? A small town in Massachusetts, an interesting cookie, and a force that we want to think about. I keep telling you guys, the jokes are really bad. So how do I get force? Well, you know that. Mass times acceleration, right, F equals ma. For acceleration here, I'm going to make an assumption, which is that the spring is basically oriented perpendicular to the earth, so that the acceleration is just
3154	9.8 meters per second squared. It's basically pulling it down. So I could plug that back in because remember what I want to do is figure out what's the mass I need. So for the force, I'm substituting that in. I've got that expression, mass times 9.8 meters divided by seconds squared is 350 newtons, divide through by 9.8 both sides, do a little bit of math. And it says that the mass I need is 350 kilograms divided by 9.8. And that k refers to kilograms, not to the spring constant. Poor choice of example, but there I am. And if I do the math, it says I need a rider that weighs 35.68 kilos. And if you're not big on the metric system, it's actually a fairly light rider. That's about 79 pounds. So a 79-pound rider would compress that spring one centimeter. So we can figure out how to use Hooke's law. We're thinking about what we want to do with springs. That's kind of nice. How will we actually get the spring constant? It's really valuable
3155	to know what the spring constant is. And just to give you a sense of that, it's not just to deal with things like slinkies. Atomic force microscopes, need to know the spring constants of the components in order to calibrate them properly. The force you need to deform a strand of DNA is directly related to the spring constants of the biological structures themselves. So I'd really like to figure out how do I get them. How many of you have done this experiment in physics and hated
3156	Right. Well, I don't know if you hated it or not, but you've done it, right? Standard way to do it is I'd take a spring, I suspend it from some point. Let it come to a resting position. And then I put a mass on the bottom of the spring. It kind of bounces around. And when it settles, I measure the distance from where it was before I put the mass on to the distance of where it is after I've added the mass. I measure that distance. And then I just plug in. I plug into that formula there. The force is minus k times d. So k the spring constant is the force, forget the minus sign, divided by the distance, and the force here would be 9.8 meters per second squared or-- kilograms per second squared times the mass divided by d. So I could just plug it in. In an ideal world, I'd plug it in, I'm done, one measurement. Not so much, right. Masses aren't always perfectly calibrated. Maybe the spring has got
3157	not perfect materials in it. So ideally I'd actually do multiple trials. I would take different weights, put them on the spring, make the measurements, and just record those. So that's what I'm going to do, and I've actually done that. I'm not going to make you do it. But I get out a set of measurements. What have I done here? I've used different masses, all increasing by now 0.05 kilograms, and I've measured the distance that the spring has deformed. And ideally, these would all have that nice linear relationship, so I could just plug them in and I could figure out what the spring constant is. So let's take this data and let's plot it. And by the way, all the code you'll be able to see when you download the file, I'm going to walk through some of it quickly. This is a simple way to deal with it,
3158	There's my data, and I actually have done this in some ways the wrong order. These are my independent measures, different masses. I'm going to plot those along the x-axis, the horizontal axis. These are the dependent things. These are the things I'm measuring. I'm going to plot those along the y-axis. So I really should have put them in the other order. So just cross your eyes and make this column go over to that column, and we'll be in good shape. Let's plot this. So here's a little file. Having stored those away in a file, I'm just going to read them in, get data. Just going to do the obvious thing of read in these things and return two tuples or lists, one for the x values-- or if you like, again going back to it, this set of values, and one for the y values. Now I'm going to play a little trick that you may have seen before that's going to be handy to me. I'm going to actually call this function out
3159	I pass in that tuple, and what it does is it converts it into an array, which is a data structure that has a fixed number of slots in it but has a really nice property I want to take advantage of. I could do all of this with lists. But by converting that into array and then giving it the same name xVals and similarly for the yVals, I can now do math on the array without having to write loops. And in particular right here, notice what I'm doing. I'm taking xVals, which is an array, multiplying it by a number. And what that does is it takes every entry in the array, multiplies that entry, and puts it into basically a new version of the array, which I then store into xVals. If you've programmed in Matlab, this is the same kind of feeling, right. I can take an array, do something to it, and that's really nice. So I'm going to scale all of my values, and then I'm going to plot them out some appropriate
3160	things. And if I do it, I get that. I thought we said Hooke's law was a linear relationship. So in an ideal world, all of these points ought to lay along a line somewhere, where the slope of the line would tell me the spring constant. Not so good, right. And in fact, if you look at it, you can kind of see-- in here you can kind of imagine there's a line there, something funky is going on up here. And we're going to come back to that at the end of the lecture. But how do we think about actually finding the line? Well, we know there's noise in the measurement, so our best thing to do is to say, well, could we just fit a line to this data? And how would we do that? And that's the first big thing we want to do today. We want to try and figure out, given that we've got measurement noise, how do we fit a line to it. So how do we fit a curve to data?
3161	Well, what we're basically going to try and do is find a way to relate an independent variable, which were the masses, the y values, to the dependent-- sorry, wrong way. The independent values, which are the x-axis, to the dependent value, what is the actual displacement we're going to see? So another way of saying it is if I go back to here, I want to know for every point along here, how do I fit something that predicts what the y value is? So I need to figure out how to do that fit. To decide-- even if I had a curve, a line that I thought was a good fit to that, I need to decide how good it is. So imagine I was lucky and somebody said, here's a line that I think describes Hooke's law in this case. Great. I could draw the line on that data. I could draw it on this chunk of data here. I still need to decide how do I know if it's a good fit. And for that, we
3162	need something we call an objective function, and it's going to measure how close is the line to the data to which I'm trying to fit it. Once we've defined the objective function, then what we say is, OK, now let's find the line that minimizes it, the best possible line, the line that makes that objective function as small as possible, because that's going to be the best fit to the data. And so that's what I'd like to do. We're going to see-- we're going to do it for general curves, but we're going to start just with lines, with linear function. So in this case, we want to say what's the line such that some function of the sum of the distances from the line to the measured points is minimized. And I'm going to come back in a second to how do we find the line. But first we've got to think about what does it mean to measure it. So I've got a point.
3163	is a good match for the thing fitting the data. How do I measure distance? Well, there's one option. I could measure just the displacement along the x-axis. There's a second option. I could measure the displacement vertically. Or a third option is I could actually measure the distance to the closest point on the line, which would be that perpendicular distance there. You're way too quiet, which is always dangerous. What do you think? I'm going to look for a show of hands here. How many people think we should use x as the thing that we measure here? Hands up. Please don't use a single finger when you put your hand up. All right. Good. How many people think we should use p, the perpendicular distance? Reasonable number of hands. And how about y? And I see actually about split between p and y. And that's actually really good. X doesn't make a lot of sense, right, because I know that my values along the x-axis are independent measurements. So the displacement in that direction doesn't make a
3164	lot of sense. P makes a lot of sense, but unfortunately isn't what I want. We're going to see examples later on where, in fact, minimizing things where you minimize that distance is the right thing to do. When we do machine learning, that is how you find what's called a classifier or a separator. But actually here we're going to pick y, and the reason is important. I'm trying to predict the dependent value, which is the y value, given an independent new x value. And so the displacement, the uncertainty is, in fact, the vertical displacement. And so I'm going to use y. That displacement is the thing I'm going to measure as the distance. How do I find this? I need an objective function that's going to tell me what is the closeness of the fit. So here's how I'm going to do it. I'm going to have some set of observed values. Think of it as an array. I've got some index into them, so the indices are giving me the x values. And the observed
3165	values are the things I've actually measured. If you want to think of it this way, I'm going to go back to this slide really quickly. The observed values are the displacements or the values along the y-axis. Sorry about that. Let's assume that I have some hypothesized line that I think fits this data, y equals ax plus b. I know the a and the b. I've hypothesized it. Then predicted will basically say given the x value, the line predicts here's what the y value should be.
3166	and square them. So the difference makes sense. It tells me how far away is the observed value from what the line predicts it should be. Why am I squaring it? Well, there are two reasons. The first one is that squaring is going to get rid of the sign. It shouldn't matter if my observed value is some amount above the predicted value or some amount below-- the same amount below the predicted value. The displacement in direction shouldn't matter. It's how far away is it. Now, you could say, well, why not just use absolute value? And the answer is you could, but we're going to see in a couple of slides that by using the square we get a really nice property that helps us find the best fitting line. So my objective function here basically says, given a bunch of observed values, use the hypothesized line to predict what the value should be, measure the difference in the y direction-- which is what I'm doing because I'm measuring predicted and observed y values-- square them, sum
3167	them all up. It's called least squares. That's going to give me a measure of how close that line is to a fit. In a second, I'll get to how you find the best line. But this hopefully looks familiar. Anybody recognize this? You've seen it earlier in this class. Boy, that's a terrible thing to ask because you don't even remember the last thing you did in this class other than the problem set. AUDIENCE: [INAUDIBLE] ERIC GRIMSON: Sorry? AUDIENCE: Variance. ERIC GRIMSON: Variance. Thank you. Absolutely. Sorry, I didn't bring any candy today. That's Professor Guttag. I got a better arm than he does, but I still didn't bring any candy today. Yeah, it's variance, not quite. It's almost variance. That's the variance times the number of observations, or another way of saying it is if I divided this by the number of observations, that would be the variance. If I took the square root, it would be the standard deviation. Why is that valuable? Because that tells you something about how badly things are dispersed, how much
3168	variation there is in this measurement. And so if it says, if I can minimize this expression, that's great because it not only will find what I hope is the best fit, but it's going to minimize the variance between what I predict and what I measure, which makes intuitive sense. That's exactly the thing I would like to minimize. This was built on the assumption that I had a line that I thought was a good fit, and this lets me measure how good a fit I have. But I still have to do a little bit more. I have to now figure out, OK, how do I find the best-fitting line? And for that, we need to come up with a minimization technique. So to minimize this objective function, I want to find the curve for the predicted values-- this thing here-- some way of representing that that leads to the best possible solution. And I'm going to make a simple assumption. I'm going to assume that my model for this predicted curve-- I've been using the example
3169	of a line, but we're going to say curve-- is a polynomial. It's a polynomial and one variable. The one variable is what are the x values of the samples. And I'm going to assume that the curve is a polynomial. In the simplest case, it's a line in case order, and two, it's going to be a parabola. And I'm going to use a technique called linear regression to find the polynomial that best fits the data, that minimizes that objective function. Quick aside, just to remind you, I'm sure you remember, so polynomial-- polynomials, either the value is zero, which is really boring, or it is a finite sum of non-zero terms that all have the form c times x to the p. C is a constant, a real number. P is a power, a non-negative integer. And this is basically-- x is the free variable that's going to capture this. So easy way to say it is a line would be represented as a degree one polynomial ax plus b. A parabola is a second-degree polynomial, ax
3170	squared plus bx plus c. And we can go up to higher order terms. We're going to refer to the degree of the polynomial as the largest degree of any term in that polynomial. So again, degree one, linear degree two, quadratic. Now how do I use that? Well, here's the basic idea. Let's take a simple example. Let's assume I'm still just trying to fit a line.
3171	polynomial, y equals ax plus b, as our model of the day. That means for every sample, I'm going to plug in x, and if I know a and b, it gives me the predicted value. I've already seen that's going to give me a good measure of the closeness of the fit. And the question is, how do I find a and b. My goal is find a and b such that when we use this polynomial to compute those y values, that sum squared difference is minimized. So the sum squared difference is my measure of fit. All I have to do is find a and b. And that's where linear regression comes in, and I want to just give you a visualization of this. If a line is described by ax plus b, then I can represent every possible line in a two-dimensional space. One axis is possible values for a. The other axis is possible values for b. So if you think about it, I take any point in that space. It gives me an a
3172	and a B value. That describes a line. Why should you care about that? Because I can put a two-dimensional surface over that space. In other words, for every a and b, that gives me a line, and I could, therefore, compute this function, given the observed values and the predicted values, and it would give me a value, which is the height of the surface in that space. If you're with me with the visualization, why is that nice? Because linear regression gives me a very easy way to find the lowest point on that surface, which is exactly the solution I want, because that's the best fitting line. And it's called linear regression not because we're solving for a line, but because of how you do that solution. If you think of this as being-- take a marble on this two-dimensional surface, you want to place the marble on it, you want to let it run down to the lowest point in the surface. And oh, yeah, I promised you why do we use sum squares, because if
3173	we used the sum of the squares, that surface always has only one minimum. So it's not a really funky, convoluted surface. It has exactly one minimum. It's called linear regression because the way to find it is to start at some point and walk downhill. I linearly regress or walk downhill along the gradient some distance, measure the new gradient, and do that until I get down to the lowest point in the surface. Could you write code to do it? Sure. Are we going to ask you to do it? No, because fortunately-- I was hoping to get a cheer out of that. Too bad. OK, maybe we will ask you to do it on the exam. What the hell. You could do it. In fact, you've seen a version of this. The typical algorithm for doing it is very similar to Newton's method that we used way back in the beginning of 60001 when we found square roots. You could write that kind of a solution, but the good news is that the nice people who wrote
3174	Python, or particularly PyLab, have given you code to do it. And we're going to take advantage of it. So in PyLab there is a built-in function called polyFit. It takes a collection of x values, takes a collection of equal length of y values-- they need to be the same length. I'm going to assume they're arrays. And it takes an integer n, which is the degree of fit, that I want to apply. And what polyFit will do is it will find the coefficients of a polynomial of that degree that provides the best least squares fit. So think of it as polyFit walking along that surface to find the best a and b that will come back. So if I give it a value of n equals one, it'll give me back the a and b that gives me the best line. If I get a value of n equal two, it gives me back a, b, and c that would fit an ax squared plus bx plus c parabola to best fit the data. And I
3175	could pick n to be any non-negative integer, and it would actually come up with a good fit. So let's use it.
3176	The first part up here just comes from plotData. It's exactly the same thing. I read in the data. I convert them into arrays. I convert this because I want to get out the force. I go ahead and plot it. And then notice what I do, I use polyFit right here to take the inputted x values and y values and a degree one, and it's going to give me back a tuple, an a and a b that are the best fit line. Finds that point in the space that best fits it. Once I've got that, I could go ahead and actually compute now what are the estimated or predicted values. The line's going to tell me what I should have seen as those values, and I'm going to do the same thing. I'm going to take x values, convert it into array, multiply it by a, which says every entry in the array is scaled by a. Add b to every entry. So I'm just computing ax plus b for all possible x's. And that then
3177	gives me an estimated set of y values, and I can plot those out. I'm cheating here. Sorry. I'm misdirecting you. I never cheat. I actually don't need to do the conversion to an array there because I did it up here. But because I've borrowed this from plot lab, I wanted to show you that I can redundantly do it here to remind you that I want to convert it into array to make sure I can do that kind of algebra on it. The last thing I could do is say even if I can-- once I show you the fit of this line, I also want to get out the spring constant. Now, the slope of this line is difference in force over difference in distance. The spring constant is the opposite of it. So I could simply take the slope of the line, which is a, invert it, and that gives me the spring constant. So let's see what happens if we actually run this. So I'm going to go over to my code, hoping that
3178	it works properly. Here's my Python. I've loaded this in. I'm going to run it. And there you go. Fits a line, and it prints out the value of a, which is about 0.46, and the value of b. And if I go back and look at this,
3179	which is about the reciprocal of 0.046 if you can figure that out. And you can see, it's not a bad fit to a line through that data. Again, there's still something funky going on over here that we're going to come back to. But it's a pretty good fit to the data. Great. So now I've got a fit. I'm going to show you a variation of this that we're going to use in a second.
3180	I'm going to use another built-in function called polyval. It's going to take a polynomial, which is captured by that model of the thing that I returned, and I'm going to show you the difference again. Back sure we returned this as a tuple. Since it's coming back as a tuple, I can give it a name model. Polyval will take that tuple plus the x values and do the same thing. It will give me back an array of predicted values. But the nice thing here is that this model could be a line. It could be a parabola. It could be a quartic. It could be a quintic. It could be any order polynomial. If you like the abstraction here-- which we're going to see in a little bit, that it allows me to use the same code for different orders of model. And if I ran this, it would do exactly the same thing. I'm going to come back to thinking about what's going on in that spring in a second. But I want to show you
3181	another example.
3182	In a little bit, I'll show you where that mystery data came from. But here's another set of data that I've plotted out. I could run the same thing. I could run exactly the same code and fit a line to it. And if I do it, I get that. What do you think? Good fit? Show of hands, how many people like this fit to the data? Show of hands, how many people don't like this fit to the data? Show of hands, how many hope that I'll stop asking you questions? Don't put your hands up. Yeah, thank you. I know. Too bad. It's a lousy fit. And you kind of know it, right. It's clear that this doesn't look like it's coming from a line, or if it is, it's a really noisy line. So let's think about this. What if I were to try a higher order degree. Let's change the one to a two. So I'm going to come back to it in a second. I've changed the one to a two. That says I'm
3183	still using the polynomial fit, but now I'm going to ask what's the best fitting parabola, ax squared plus bx plus c. Simple change. Because I was using polyval, exactly the same code will work. It's going to do the fit to it. This is, by the way, still an example of linear regression. So think of what I'm doing now. I have a three-dimensional space. One axis is a values. Second axis is b values. Third axis is c values. Any point in that space describes a parabola, and every point in that space describes every possible parabola. And now you've got to twist your head a little bit. Put a four-dimensional surface on that three-dimensional basis, where the point in that surface is the value of that objective function. Play the same game. And you can. It's just a higher-dimensional thing. So you're, again, going to walk down the gradient to find the solution, and be glad you don't have to write this code because PyLab will do it for you freely. But it's still an example of
3184	regression, which is great. And if we do that, we get that fit. Actually just to show you that, I'm going to run it, but it will do exactly the same thing. If I go over to Python-- wherever I have it here-- I'm going to change that order of the model. Oops, it went a little too far for me. Sorry about that. Let me go back and do this again. There's the first one, and there's the second one. So I could fit different models to it. Quadratic clearly looks like it's a better fit.
3185	So how do I decide which one's better other than eyeballing it? And then if I could fit a quadratic to it, what about other orders of polynomials? Maybe there's an even better fit out there. So how do I figure out what's the best way to do the fit? And that leads to the second big thing for this lecture. How good are these fits? What's the first big thing? The idea of linear regression, a way of finding fits of curves to data. But now I've got to decide how good are these. And I could ask this question two ways. One is just relative to each other, how do I measure which one's better other than looking at it by eye? And then the second part of it is in an absolute sense, how do I know where the best solution is? Is quadratic the best I could do? Or should I be doing something else to try and figure out a better solution, a better fit to the data? The relative fit. What are we doing
3186	here? We're fitting a curve, which is a function of the independent variable to the dependent variable. What does it mean by that? I've got a set of x values. I'm trying to predict what the y values should be, the displacement should be. I want to get a good fit to that. The idea is that given an independent value, it gives me an estimate of what it should be, and I really want to know which fit provides the better estimates. And since I was simply minimizing mean squared error, average square error, an obvious thing to do is just to use the goodness of fit by looking at that error. Why not just measure where am I on that surface and see which one does better? Or actually it would be two surfaces, one for a linear fit, one for a quadratic one. We'll do what we always do. Let's write a little bit of code. I can write something that's going to get the average, mean squared error.
3187	simply measures the difference between them, squares them, adds them all up in a little loop here and returns that divided by the number of samples I have. So it gives me the average squared error. And I could do it for that first model I built, which was for a linear fit, and I could do it for the second model I built, which is a quadratic fit. And if I run it, I get those values. Looks pretty good. You knew by eye that the quadratic was a better fit. And look, this says it's about six times better, that the residual error is six times smaller with the quadratic model than it is the linear model. But with that, I still have a problem, which is-- OK, so it's useful for comparing two models. But is 1524 a good number? Certainly better than 9,000-something or other. But how do I know that 1524 is a good number? How do I know there isn't a better fit out there somewhere? Well, good news is we're going to be
3188	able to measure that. It's hard to know because there's no bound on the values. And more importantly, this is not scale independent. What do I mean by that? If I take all of the values and multiply them by some factor, I would still fit the same models to them. They would just scale. But that measure would increase by that amount. So I could make the error as big or as small as I want by just changing the size of the values. That doesn't make any sense. I'd like a way to measure goodness of fit that is scale independent and that tells me for any fit how close it comes to being the perfect fit to the data. And so for that, we're going to use something called the coefficient of determination
3189	So let me show you what this does, and then we're going to use it. The y's are measured values. Those are my samples I got from my experiment. The p's are the predicted values. That is, for this curve, here's what I predict those values should be. So the top here is basically measuring as we saw before the sum squared error in those pieces. Mu down here is the average, or mean, of the measured values. It's the average of the y's. So what I've got here is in the numerator-- this is basically the error in the estimates from my curve fit. And in the denominator I've got the amount of variation in the data itself. This is telling me how much does the data change from just being a constant value, and this is telling me how much do my errors vary around it. That ratio is scale independent because it's a ratio. So even if I increase all of the values by some amount, that's going to divide out, which is kind of nice. So
3190	I could compute that, and there it is.
3191	I'll take in a set of observed values, a set of predicted values, and I'll measure the error-- again, these are arrays. So I'm going to take the difference between the arrays. That's going to give me piecewise or pairwise that difference. I'll square it. That's going to give me at every point in the array the square of that distance. And then because it's an array, I can just use the built-in sum function to add them all up. So this is going to give me the-- if you like, the values up there. And then I'm going to play a little trick. I'm going to compute the mean error, which is that thing divided by the number of observations. Why would I do that? Well, because then I can compute this really simply. I could write a little loop to compute it. But in fact, I've already said what is that? If I take that sum and divide it by the number of samples, that's the variance. So that's really nice. Right here I can say, get the
3192	variance using the non-p version of the observed data. And because that has associated with it division by the number of samples, the ratio of the mean error to the variance is exactly the same as the ratio of that to that. Little trick. It lets me save doing a little bit of computation. So I can compute r squared values. So what does r squared actually tell us? What we're doing is we're trying to compare the estimation errors, the top part, with the variability in the original values, the bottom part. So r squared, as you're going to see there, it's intended to capture what portion of the variability in the data is accounted for by my model. My model's a really good fit. It should account for almost all of that data. So what we see then is if we do a fit with a linear regression, r squared is always going to be between zero and one. And I want to just show you some examples. If r squared is equal to one, this is great.
3193	It says the model explains all of the variability in the data. And you can see it if we go back here. How do we make r squared equal to one? We need this to be zero, which says that the variability in the data is perfectly predicted by my model. Every point lies exactly along the curve. That's great. Second option at the other extreme is if r squared is equal to zero, you basically got bupkis, which is a well-known technical term, meaning there's no relationship between the values predicted by the model and the actual data. That basically says that all of the variability here is exactly the same as all the variability in the data. The model doesn't capture anything, and it's making this one, which is making the whole thing zero. And then in between an r squared of about a half says you're capturing about half the variability. So what you would like is a system in which your fit is as close to an r squared value of one as possible because it
3194	says my model is capturing all the variability in the data really well. So two functions that will do this for us.
3195	The first one called generate fits, or genFits, will take a set of x values, a set of y values, and a list or a tuple of degrees, and these will be the different degrees of models I'd like to fit. I could just give it one. I could give it two. I could give a 1, 2, 4, 8, 16, whatever. And I'll just run through a little loop here where I'm going to build up a set of models for each degree-- or d in degrees. I'll do the fit exactly as I had before. It's going to return a model, which is a tuple of coefficients. And I'm going to store that in models and then return it. And then I'm going to use that, because in testFits I will take the models that come from genFits, I'll take the set of degrees that I also passed in there as well as the values. I'll plot them out, and then I'll simply run through each of the models and generate a fit, compute the r squared value,
3196	plot it, and then print out some data. With that in mind, let's see what happens if we run this. So I'm going to take, again, that example of that data that I started with, assuming I picked the right one here, which I think is this one. I'm going to do a fit with a degree one and a degree two curve. So I'm going to fit the best line. I'm going to fit the best quadratic, the best parabola, and I want to see how well that comes out. So I do that. I got some data there. Looks good. And what does the data tell me?
3197	I know you don't believe it, but it is because notice what it says, it says the r squared value for the line is horrible. It accounts for less than 0.05% of the data. You could say, OK, I can see that. I look at it. It does a lousy job. On the other hand, the quadratic is really pretty good. It's accounting for about 84% of the variability in the data. This is a nice high value. It's not one, but it's a nice high value. So this is now reinforcing what I already knew, but in a nice way. It's telling me that that r squared value tells me that the quadratic is a much better fit than the linear fit was. But then you say maybe, wait a minute. I could have done this by just comparing the fits themselves. I already saw that. Part of my goal is how do I know if I've got the best fit possible or not. So I'm going to do the same thing, but now I'm going to run it
3198	with another set of degrees. I'm going to go over here. I'm going to take exactly the same code. But let's try it with a quadratic, with a quartic, an order eight, and an order 16 fit. So I'm going to take different size polynomials. As a quick aside, this is why I want to use the PyLab kind of code because now I'm simply optimizing over a 16-dimensional space. Every point in that 16-dimensional space defines a 16th-degree polynomial. And I can still use linear regression, meaning walking down the gradient, to find the best solution. I'm going to run this. And I get out a set of values. Looks good. And let's go look at them.
3199	Here is the r squared value for quadratic, about 84%. Degree four does a little bit better. Degree eight does a little bit better. But wow, look at that, degree 16-- 16th order polynomial does a really good job, accounts for almost 97% of the variability in the data. That sounds great. Now, to quote something that your parents probably said to you when you were much younger, just because something looks good doesn't mean we should do it. And in fact, just because this has a really high r squared value doesn't mean that we want to use the order 16th polynomial. And I will wonderfully leave you waiting in suspense because we're going to answer that question next Monday. And with that, I'll let you out a few minutes early. Have a great Thanksgiving break.
3200	The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation, or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. PROFESSOR: Hello, everybody. Before we start the material, a couple of announcements. As usual, there's some reading assignments, and you might be surprised to see something from Chapter 5 suddenly popping up. But this is my relentless attempt to introduce more Python. We'll see one new concept later today, list comprehension. Today we're going to look at classification. And you remember last, on Monday, we looked at unsupervised learning. Today we're looking at supervised learning. It can usually be divided into two categories. Regression, where you try and predict some real number associated with the feature vector, and this is something we've already done really, back when we looked at curve fitting, linear regression in particular. It was exactly building a model that, given some features, would predict a point. In this case, it was pretty
3201	simple. It was given x predict y. You can imagine generalizing that to multi dimensions.
3202	which is very common, in many ways more common than regression for-- in the machine learning world. And here the goal is to predict a discrete value, often called a label, associated with some feature vector. So this is the sort of thing where you try and, for example, predict whether a person will have an adverse reaction to a drug. You're not looking for a real number, you're looking for will they get sick, will they not get sick. Maybe you're trying to predict the grade in a course A, B, C, D, and other grades we won't mention. Again, those are labels, so it doesn't have to be a binary label but it's a finite number of labels. So here's an example to start with. We won't linger on it too long. This is basically something you saw in an earlier lecture, where we had a bunch of animals and a bunch of properties, and a label identifying whether or not they were a reptile. So we start by building a distance matrix. How far apart they are,
3203	an in fact, in this case, I'm not using the representation you just saw. I'm going to use the binary representation, As Professor Grimson showed you, and for the reasons he showed you. If you're interested, I didn't produce this table by hand, I wrote some Python code to produce it, not only to compute the distances, but more delicately to produce the actual table. And you'll probably find it instructive at some point to at least remember that that code is there, in case you need to ever produce a table for some paper. In general, you probably noticed I spent relatively little time going over the actual vast amounts of codes we've been posting. That doesn't mean you shouldn't look at it. In part, a lot of it's there because I'm hoping at some point in the future it will be handy for you to have a model on how to do something. All right. So we have all these distances. And we can tell how far apart one animal is from another. Now how do we use
3204	those to classify animals? And the simplest approach to classification, and it's actually one that's used a fair amount in practice is called nearest neighbor. So the learning part is trivial. We don't actually learn anything other than we just remember. So we remember the training data. And when we want to predict the label of a new example, we find the nearest example in the training data, and just choose the label associated with that example.
3205	of red dots and black dots. I have a fuschia colored X. And if I want to classify X as black or red, I'd say well its nearest neighbor is red. So we'll call X red. Doesn't get much simpler than that. All right. Let's try and do it now for our animals. I've blocked out this lower right hand corner, because I want to classify these three animals that are in gray. So my training data, very small, are these animals. And these are my test set here. So let's first try and classify the zebra. We look at the zebra's nearest neighbor. Well it's either a guppy or a dart frog. Well, let's just choose one. Let's choose the guppy. And if we look at the guppy, it's not a reptile, so we say the zebra is not a reptile. So got one right. Look at the python, choose its nearest neighbor, say it's a cobra. The label associated with cobra is reptile, so we win again on the python. Alligator, it's nearest neighbor is clearly a chicken.
3206	And so we classify the alligator as not a reptile. Oh, dear. Clearly the wrong answer. All right. What might have gone wrong? Well, the problem with K nearest neighbors, we can illustrate it by looking at this example. So one of the things people do with classifiers these days is handwriting recognition. So I just copied from a website a bunch of numbers, then I wrote the number 40 in my own inimitable handwriting. So if we go and we look for, say, the nearest neighbor of four-- or sorry, of whatever that digit is. It is, I believe, this one. And sure enough that's the row of fours. We're OK on this. Now if we want to classify my zero, the actual nearest neighbor, in terms of the bitmaps if you will, turns out to be this guy. A very poorly written nine. I didn't make up this nine, it was it was already there. And the problem we see here when we use nearest neighbor is if something is noisy, if you have one noisy piece of
3207	data, in this case, it's rather ugly looking version of nine, you can get the wrong answer because you match it. And indeed, in this case, you would get the wrong answer. What is usually done to avoid that is something called K nearest neighbors. And the basic idea here is that we don't just take the nearest neighbors, we take some number of nearest neighbors, usually an odd number, and we just let them vote. So now if we want to classify this fuchsia X, and we said K equal to three, we say well these are it's three nearest neighbors. One is red, two are black, so we're going to call X black is our better guess. And maybe that actually is a better guess, because it looks like this red point here is really an outlier, and we don't want to let the outliers dominate our classification. And this is why people almost always use K nearest neighbors rather than just nearest neighbor. Now if we look at this, and we use K nearest neighbors, those are
3208	the three nearest to the first numeral, and they are all fours. And if we look at the K nearest neighbors for the second numeral, we still have this nine but now we have two zeros. And so we vote and we decide it's a zero. Is it infallible? No. But it's typically much more reliable than just nearest neighbors, hence used much more often. And that was our problem, by the way, with the alligator. The nearest neighbor was the chicken, but if we went back and looked at it-- maybe we should go do that. And we take the alligator's three nearest neighbors, it would be the chicken, a cobra, and the rattlesnake-- or the boa, we don't care, and we would end up correctly classifying it now as a reptile. Yes? AUDIENCE: Is there like a limit to how many [INAUDIBLE]? PROFESSOR: The question is is there a limit to how many nearest neighbors you'd want? Absolutely. Most obviously, there's no point in setting K equal to-- whoops. Ooh, on the rebound-- to the size of the
3209	training set. So one of the problems with K nearest neighbors is efficiency. If you're trying to define K nearest neighbors and K is bigger, it takes longer. So we worry about how big K should be. And if we make it too big-- and this is a crucial thing-- we end up getting dominated by the size of the class. So let's look at this picture we had before. It happens to be more red dots than black dots. If I make K 10 or 15, I'm going to classify a lot of things as red, just because red is so much more prevalent than black. And so when you have an imbalance, which you usually do, you have to be very careful about K. Does that make sense? AUDIENCE: [INAUDIBLE] choose K? PROFESSOR: So how do you choose K? Remember back on Monday when we talked about choosing K for K means clustering? We typically do a very similar kind of thing. We take our training data and we split it into two parts. So we have training
3210	and testing, but now we just take the training, and we split that into training and testing multiple times. And we experiment with different K's, and we see which K's gives us the best result on the training data. And then that becomes our K. And that's a very common method. It's called cross-validation, and it's-- for almost all of machine learning, the algorithms have parameters in this case, it's just one parameter, K. And the way we typically choose the parameter values is by searching through the space using this cross-validation in the training data. Does that makes sense to everybody? Great question. And there was someone else had a question, but maybe it was the same. Do you still have a question? AUDIENCE: Well, just that you were using like K nearest and you get, like if my K is three and I get three different clusters for the K [INAUDIBLE] PROFESSOR: Three different clusters? AUDIENCE: [INAUDIBLE] PROFESSOR: Well, right. So if K is 3, and I had red, black, and purple and I get one of each,
3211	then what do I do? And then I'm kind of stuck. So you need to typically choose K in such a way that when you vote you get a winner. Nice. So if there's two, any odd number will do. If it's three, well then you need another number so that there's some-- so there's always a majority. Right? You want to make sure that there is a winner. Also a good question. Let's see if I get this to you directly. I'm much better at throwing overhand, I guess. Wow. Finally got applause for something. All right, advantages and disadvantages KNN? The learning is really fast, right? I just remember everything. No math is required. Didn't have to show you any theory. Was obviously an idea. It's easy to explain the method to somebody, and the results. Why did I label it black? Because that's who it was closest to. The disadvantages is it's memory intensive. If I've got a million examples, I have to store them all. And the predictions can take a long time. If I have
3212	an example and I want to find its K nearest neighbors, I'm doing a lot of comparisons. Right? If I have a million tank training points I have to compare my example to all a million. So I have no real pre-processing overhead. But each time I need to do a classification, it takes a long time. Now there are better algorithms and brute force that give you approximate K nearest neighbors. But on the whole, it's still not fast. And we're not getting any information about what process might have generated the data. We don't have a model of the data in the way we say when we did our linear regression for curve fitting, we had a model for the data that sort of described the pattern. We don't get that out of k nearest neighbors. I'm going to show you a different approach where we do get that. And I'm going to do it on a more interesting example than reptiles. I apologize to those of you who are reptologists. So you probably all heard of the
3213	Titanic. There was a movie about it, I'm told. It was one of the great sea disasters of all time, a so-called unsinkable ship-- they had advertised it as unsinkable-- hit an iceberg and went down. Of the 1,300 passengers, 812 died. The crew did way worse. So at least it looks as if the curve was actually pretty heroic. They had a higher death rate. So we're going to use machine learning to see if we can predict which passengers survived. There's an online database I'm using. It doesn't have all 1,200 passengers, but it has information about 1,046 of them. Some of them they couldn't get the information. Says what cabin class they were in first, second, or third, how old they were, and their gender. Also has their name and their home address and things, which I'm not using. We want to use these features to see if we can predict which passengers were going to survive the disaster. Well, the first question is something that Professor Grimson alluded to is, is it OK, just to look
3214	at accuracy? How are we going to evaluate our machine learning? And it's not. If we just predict died for everybody, well then we'll be 62% accurate for the passengers and 76% accurate for the crew members. Usually machine learning, if you're 76% you say that's not bad. Well, here I can get that just by predicting died. So whenever you have a class imbalance that much more of one than the other, accuracy isn't a particularly meaningful measure. I discovered this early on in my work and medical area. There are a lot of diseases that rarely occur, they occur in say 0.1% of the population. And I can build a great model for predicting it by just saying, no, you don't have it, which will be 0.999% accurate, but totally useless. Unfortunately, you do see people doing that sort of thing in the literature. You saw these in an earlier lecture, just to remind you,
3215	Sensitivity, think of that as how good is it at identifying the positive cases. In this case, positive is going to be dead. How specific is it, and the positive predictive value. If we say somebody died, what's the probability is that they really did? And then there's the negative predictive value. If we say they didn't die, what's the probability they didn't die? So these are four very common metrics. There is something called an F score that combines them, but I'm not going to be showing you that today. I will mention that in the literature, people often use the word recall to mean sensitivity or sensitivity I mean recall, and specificity and precision are used pretty much interchangeably. So you might see various combinations of these words. Typically, people talk about recall n precision or sensitivity and specificity. Does that makes sense, why we want to look at the measures other than accuracy? We will look at accuracy, too, and how they all tell us kind of different things, and how you might choose a different balance.
3216	For example, if I'm running a screening test, say for breast cancer, a mammogram, and trying to find the people who should get on for a more extensive examination, what do I want to emphasize here? Which of these is likely to be the most important? Or what would you care about most? Well, maybe I want sensitivity. Since I'm going to send this person on for future tests, I really don't want to miss somebody who has cancer, and so I might think sensitivity is more important than specificity in that particular case. On the other hand, if I'm deciding who is so sick I should do open heart surgery on them, maybe I want to be pretty specific. Because the risk of the surgery itself are very high. I don't want to do it on people who don't need it. So we end up having to choose a balance between these things, depending upon our application. The other thing I want to talk about before actually building a classifier is how we test our classifier, because this is
3217	very important. I'm going to talk about two different methods, leave one out class of testing and repeated random subsampling. For leave one out, it's typically used when you have a small number of examples, so you want as much training data as possible as you build your model. So you take all of your n examples, remove one of them, train on n minus 1, test on the 1. Then you put that 1 back and remove another 1. Train on n minus 1, test on 1. And you do this for each element of the data, and then you average your results. Repeated random subsampling is done when you have a larger set of data, and there you might say split your data 80/20. Take 80% of the data to train on, test it on 20. So this is very similar to what I talked about earlier, and answered the question about how to choose K. I haven't seen the future examples, but in order to believe in my model and say my parameter settings, I do this
3218	repeated random subsampling or leave one out, either one. There's the code for leave one out. Absolutely nothing interesting about it, so I'm not going to waste your time looking at it.
3219	What I've done here is I first sample-- this one is just to splitted 80/20. It's not doing anything repeated, and I start by sampling 20% of the indices, not the samples. And I want to do that at random. I don't want to say get consecutive ones. So we do that, and then once I've got the indices, I just go through and assign each example, to either test or training, and then return the two sets. But if I just sort of sampled one, then I'd have to do a more complicated thing to subtract it from the other. This is just efficiency. And then here's the-- sorry about the yellow there-- the random splits. Obviously, I was searching for results when I did my screen capture. I'm just going to for range and number of splits, I'm going to split it 80/20. It takes a parameter method, and that's interesting, and we'll see the ramifications of that later. That's going to be the machine learning method. We're going to compare KNN to another method called logistic regression.
3220	I didn't want to have to do this code twice, so I made the method itself a parameter. We'll see that introduces a slight complication, but we'll get to it when we get to it. So I split it, I apply whatever that method is the training the test set, I get the results, true positive false positive, true negative false negatives. And then I call this thing get stats, but I'm dividing it by the number of splits, so that will give me the average number of true positives, the average number of false positives, etc. And then I'm just going to return the average. Get stats actually just prints a bunch of statistics for us. Any questions about the two methods, leave one out versus repeated random sampling? Let's try it for KNN on the Titanic. So I'm not going to show you the code for K nearest classify. It's in the code we uploaded. It takes four arguments the training set, the test set, the label that we're trying to classify. Are we looking for the people
3221	who died? Or the people who didn't die? Are we looking for reptiles or not reptiles? Or if case there were six labels, which one are we trying to detect? And K as in how many nearest neighbors? And then it returns the true positives, the false positives, the true negatives, and the false negatives. Then you'll recall we'd already looked at lambda in a different context. The issue here is K nearest classify takes four arguments, yet if we go back here, for example, to random splits, what we're seeing is I'm calling the method with only two arguments. Because after all, if I'm not doing K nearest neighbors, maybe I don't need to pass in K. I'm sure I don't. Different methods will take different numbers of parameters, and yet I want to use the same function here method. So the trick I use to get around that-- and this is a very common programming trick-- in math. It's called currying, after the mathematician Curry, not the Indian dish. I'm creating a function a new function called KNN.
3222	This will be a function of two arguments, the training set and the test set, and it will be K nearest classifier with training set and test set as variables, and two constants, survived-- so I'm going to predict who survived-- and 3, the K. I've been able to turn a function of four arguments, K nearest classify, into a function of two arguments KNN by using lambda abstraction. This is something that people do fairly frequently, because it lets you build much more general programs when you don't have to worry about the number of arguments. So it's a good trick to keeping your bag of tricks. Again, it's a trick we've used before. Then I've just chosen 10 for the number of splits, and we'll try it, and we'll try it for both methods of testing. Any questions before I run this code? So here it is. We'll run it. Well, I should learn how to spell finished, shouldn't I? But that's OK. Here we have the results, and they're-- well, what can we say about them? They're
3223	not much different to start with, so it doesn't appear that our testing methodology had much of a difference on how well the KNN worked, and that's actually kind of comforting. The accurate-- none of the evaluation criteria are radically different, so that's kind of good. We hoped that was true. The other thing to notice is that we're actually doing considerably better than just always predicting, say, didn't survive. We're doing better than a random prediction. Let's go back now to the Power Point. Here are the results. We don't need to study them anymore. Better than 62% accuracy, but not much difference between the experiments. So that's one method. Now let's look at a different method, and this is probably the most common method used in machine learning. It's called logistic regression. It's, in some ways, if you look at it, similar to a linear regression, but different in some important ways. Linear regression, you will I'm sure recall, is designed to predict a real number. Now what we want here is a probability, so the probability of
3224	some event. We know that the dependent variable can only take on a finite set of values, so we want to predict survived or didn't survive. It's no good to say we predict this person half survived, you know survived, but is brain dead or something. I don't know. That's not what we're trying to do. The problem with just using regular linear regression is a lot of time you get nonsense predictions. Now you can claim, OK 0.5 is there, and it means has a half probability of dying, not that half died. But in fact, if you look at what goes on, you could get more than one or less than 0 out of linear regression, and that's nonsense when we're talking about probabilities. So we need a different method, and that's logistic regression. What logistic regression does is it finds what are called the weights for each feature. You may recall I complained when Professor [? Grimson ?] used the word weights to mean something somewhat different. We take each feature, for example the gender, the cabin
3225	class, the age, and compute for that weight that we're going to use in making predictions. So think of the weights as corresponding to the coefficients we get when we do a linear regression. So we have now a coefficient associated with each variable. We're going to take those coefficients, add them up, multiply them by something, and make a prediction. A positive weight implies-- and I'll come back to this later-- it almost implies that the variable is positively correlated with the outcome. So we would, for example, say the have scales is positively correlated with being a reptile. A negative weight implies that the variable is negatively correlated with the outcome, so number of legs might have a negative weight. The more legs an animal has, the less likely it is to be a reptile. It's not absolute, it's just a correlation. The absolute magnitude is related to the strength of the correlation, so if it's being positive it means it's a really strong indicator. If it's big negative, it's a really strong negative indicator. And then we
3226	use an optimization process to compute these weights from the training data. It's a little bit complex. It's key is the way it uses the log function, hence the name logistic, but I'm not going to make you look at it. But I will show you how to use it. You start by importing something called sklearn.linear_model. Sklearn is a Python library, and in that is a class
3227	It's the name of a class, and here are three methods of that class. Fit, which takes a sequence of feature vectors and a sequence of labels and returns an object of type logistic regression. So this is the place where the optimization is done. Now all the examples I'm going to show you, these two sequences will be-- well all right. So think of this as the sequence of feature vectors, one per passenger, and the labels associated with those. So this and this have to be the same length. That produces an object of this type, and then I can ask for the coefficients, which will return the weight of each variable, each feature. And then I can make a prediction, given a feature vector returned the probabilities of different labels. Let's look at it as an example. So first let's build the model.
3228	data, and I just said whether we're going to print something. You'll notice from this slide I've elighted the printed stuff. We'll come back in a later slide and look at what's in there. But for now I want to focus on actually building the model. I need to create two vectors, two lists in this case, the feature vectors and the labels. For e in examples, featurevectors.a ppend(e.getfeatures e.getfeatures e.getlabel. Couldn't be much simpler than that. Then, just because it wouldn't fit on a line on my slide, I've created this identifier called logistic regression, which is sklearn.linearmo del.logisticregression. So this is the thing I imported, and this is a class, and now I'll get a model by first creating an instance of the class, logistic regression. Here I'm getting an instance, and then I'll call dot fit with that instance, passing it feature vecs and labels. I now have built a logistic regression model, which is simply a set of weights for each of the variables. This makes sense? Now we're going to apply the model, and I
3229	think this is the last piece of Python I'm going to introduce this semester, in case you're tired of learning about Python. And this is at least list comprehension. This is how I'm going to build my set of test feature vectors.
3230	let's look at how list comprehension works. In its simplest form, says some expression for some identifier in some list, L. It creates a new list by evaluating this expression Len (L) times with the ID in the expression replaced by each element of the list L. So let's look at a simple example. Here I'm saying L equals x times x for x in range 10. What's that going to do? It's going to, essentially, create a list. Think of it as a list, or at least a sequence of values, a range type actually in Python 3-- of values 0 to 9. It will then create a list of length 10, where the first element is going to be 0 times 0. The second element 1 times 1, etc. OK? So it's a simple way for me to create a list that looks like that. I can be fancier and say for x times L equals x times x for x in range 10, and I add and if. If x mod 2 is equal to 0. Now
3231	instead of returning all-- building a list using each value in range 10, it will use only those values that satisfy that test. We can go look at what happens when we run that code. You can see the first list is 1 times 1, 2 times 2, et cetera, and the second list is much shorter, because I'm only squaring even numbers. Well, you can see that list comprehension gives us a convenient compact way to do certain kinds of things. Like lambda expressions, they're easy to misuse. I hate reading code where I have list comprehensions that go over multiple lines on my screen, for example. So I use it quite a lot for small things like this. If it's very large, I find another way to do it. Now we can move forward.
3232	of x, my e.getfeatures for e in test set, so that will give me the features associated with each element in the test set. I could obviously have written a for loop to do the same thing, but this was just a little cooler. Then we get model.predict for each of these. Model.predict_proba is nice in that I don't have to predict it for one example at a time. I can pass it as set of examples, and what I get back is a list of predictions, so that's just convenient. And then setting these to 0, and for I in range len of probs, here a probability of 0.5. What's that's saying is what I get out of logistic regression is a probability of something having a label. I then have to build a classifier, give a threshold. And here what I've said, if the probability of it being true is over a 0.5, call it true. So if the probability of survival is over 0.5, call it survived. If it's below, call it not survived. We'll later see
3233	that, again, setting that probability is itself an interesting thing, but the default in most systems is half, for obvious reasons. I get my probabilities for each feature vector, and then for I in ranged lens of probabilities, I'm just testing whether the predicted label is the same as the actual label, and updating true positives, false positives, true negatives, and false negatives accordingly. So far, so good?
3234	I'm defining something called LR, for logistic regression. It takes the training data, the test data, the probability, it builds a model, and then it gets the results by calling apply model with the label survived and whatever this prob was. Again, we'll do it for both leave one out and random splits, and again for 10 random splits. You'll notice it actually runs-- maybe you won't notice, but it does run faster than KNN. One of the nice things about logistic regression is building the model takes a while, but once you've got the model, applying it to a large number of variables-- feature vectors is fast. It's independent of the number of training examples, because we've got our weights. So solving the optimization problem, getting the weights, depends upon the number of training examples. Once we've got the weights, it's just evaluating a polynomial. It's very fast, so that's a nice advantage. If we look at those-- and we should probably compare them to our earlier KNN
3235	on the right. And I guess if I look at it, it looks like logistic regression did a little bit better. That's not guaranteed, but it often does outperform because it's more subtle in what it does, in being able to assign different weights to different variables. It's a little bit better. That's probably a good thing, but there's another reason that's really important that people prefer logistic regression, is it provides
3236	We can look at the feature weights. This code does that, so remember we looked at build model and I left out the printing? Well here I'm leaving out everything except the printing. Same function, but leaving out everything except the printing. We can do model underbar classes, so model.classes underbar gives you the classes. In this case, the classes are survived, didn't survive. I forget what I called it. We'll see. So I can see what the classes it's using are, and then for I in range len model dot cof underbar, these are giving the weights of each variable. The coefficients, I can print what they are. So let's run that and see what we get. We get a syntax error because I turned a comment into a line of code. Our model classes are died and survived, and for label survived-- what I've done, by the way, in the representation is I represented the cabin class as a binary variable. It's either 0 or 1, because it doesn't make sense to treat them as if they were
3237	really numbers because we don't know, for example, the difference between first and second is the same as the difference between second and third. If we treated the class, we just said cabin class and used an integer, implicitly the learning algorithm is going to assume that the difference between 1 and 2 is the same as between 2 and 3. If you, for example, look at the prices of these cabins, you'll see that that's not true. The difference in an airplane between economy plus and economy is way smaller than between economy plus him first. Same thing on the Titanic. But what we see here is that for the label survived, pretty good sized positive weight for being in first class cabin. Moderate for being in the second, and if you're in the third class well, tough luck. So what we see here is that rich people did better than the poor people. Shocking. If We look at age, we'll see it's negatively correlated. What does this mean? It's not a huge weight, but it basically says that
3238	if you're older, the bigger your age, the less likely you are to have survived the disaster. And finally, it says it's really bad to be a male, that the men-- being a male was very negatively correlated with surviving. We see a nice thing here is we get these labels, which we can make sense of. One more slide and then I'm done. These values are slightly different, because different randomization, different example, but the main point I want to say is you have to be a little bit wary of reading too much into these weights. Because not in this example, but other examples-- well, also in these features are often correlated, and if they're correlated, you run-- actually it's 3:56. I'm going to explain the problem with this on Monday when I have time to do it properly. So I'll see you then.
3239	The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high-quality educational resources for free. To make a donation, or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. JOHN GUTTAG: I'm a little reluctant to say good afternoon, given the weather, but I'll say it anyway. I guess now we all do know that we live in Boston. And I should say, I hope none of you were affected too much by the fire yesterday in Cambridge, but that seems to have been a pretty disastrous event for some. Anyway, here's the reading. This is a chapter in the book on clustering, a topic that Professor Grimson introduced last week. And I'm going to try and finish up with respect to this course today, though not with respect to everything there is to know about clustering. Quickly just reviewing where we were. We're in the unit of a course on machine learning, and we always follow the same paradigm. We observe some set of examples,
3240	which we call the training data. We try and infer something about the process that created those examples. And then we use inference techniques, different kinds of techniques, to make predictions about previously unseen data. We call that the test data. As Professor Grimson said, you can think of two broad classes. Supervised, where we have a set of examples and some label associated with the example-- Democrat, Republican, smart, dumb, whatever you want to associate with them-- and then we try and infer the labels. Or unsupervised, where we're given a set of feature vectors without labels, and then we attempt to group them into natural clusters. That's going to be today's topic, clustering. So clustering is an optimization problem. As we'll see later, supervised machine learning is also an optimization problem. Clustering's a rather simple one. We're going to start first with the notion of variability. So this little c is a single cluster, and we're going to talk about the variability in that cluster of the sum of the distance between the mean of the cluster and
3241	each example in the cluster. And then we square it. OK? Pretty straightforward. For the moment, we can just assume that we're using Euclidean distance as our distance metric. Minkowski with p equals two. So variability should look pretty similar to something we've seen before, right? It's not quite variance, right, but it's very close. In a minute, we'll look at why it's different. And then we can look at the dissimilarity of a set of clusters, a group of clusters, which I'm writing as capital C, and that's just the sum of all the variabilities. Now, if I had divided variability by the size of the cluster, what would I have? Something we've seen before. What would that be? Somebody? Isn't that just the variance? So the question is, why am I not doing that? If up til now, we always wanted to talk about variance, why suddenly am I not doing it? Why do I define this notion of variability instead of good old variance? Any thoughts? What am I accomplishing by not dividing by the size of
3242	the cluster? Or what would happen if I did divide by the size of the cluster? Yes. AUDIENCE: You normalize it? JOHN GUTTAG: Absolutely. I'd normalize it. That's exactly what it would be doing. And what might be good or bad about normalizing it? What does it essentially mean to normalize? It means that the penalty for a big cluster with a lot of variance in it is no higher than the penalty of a tiny little cluster with a lot of variance in it. By not normalizing, what I'm saying is I want to penalize big, highly-diverse clusters more than small, highly-diverse clusters. OK? And if you think about it, that probably makes sense. Big and bad is worse than small and bad. All right, so now we define the objective function. And can we say that the optimization problem we want to solve by clustering is simply finding a capital C that minimizes dissimilarity? Is that a reasonable definition? Well, hint-- no. What foolish thing could we do that would optimize that objective function? Yeah. AUDIENCE: You could
3243	have the same number of clusters as points? JOHN GUTTAG: Yeah. I can have the same number of clusters as points, assign each point to its own cluster, whoops. Ooh, almost a relay. The dissimilarity of each cluster would be 0. The variability would be 0, so the dissimilarity would be 0, and I just solved the problem. Well, that's clearly not a very useful thing to do. So, well, what do you think we do to get around that? Yeah. AUDIENCE: We apply a constraint? JOHN GUTTAG: We apply a constraint. Exactly. And so we have to pick some constraint. What would be a suitable constraint, for example? Well, maybe we'd say, OK, the clusters have to have some minimum distance between them. Or-- and this is the constraint we'll be using today-- we could constrain the number of clusters. Say, all right, I only want to have at most five clusters. Do the best you can to minimize dissimilarity, but you're not allowed to use more than five clusters. That's the most common constraint that gets placed in
3244	the problem. All right, we're going to look at two algorithms. Maybe I should say two methods, because there are multiple implementations of these methods. The first is called hierarchical clustering, and the second is called k-means. There should be an S on the word mean there. Sorry about that. All right, let's look at hierarchical clustering first.
3245	It's a strange algorithm. We start by assigning each item, each example, to its own cluster. So this is the trivial solution we talked about before. So if you have N items, you now have N clusters, each containing just one item. In the next step, we find the two most similar clusters we have and merge them into a single cluster, so that now instead of N clusters, we have N minus 1 clusters. And we continue this process until all items are clustered into a single cluster of size N. Now of course, that's kind of silly, because if all I wanted to put them all it in is in a single cluster, I don't need to iterate. I just go wham, right? But what's interesting about hierarchical clustering is you stop it, typically, somewhere along the way. You produce something called a [? dendogram. ?] Let me write that down. At each step here, it shows you what you've merged thus far. We'll see an example of that shortly. And then you can have some stopping criteria.
3246	We'll talk about that. This is called agglomerative hierarchical clustering because we start with a bunch of things and we agglomerate them. That is to say, we put them together. All right? Make sense? Well, there's a catch. What do we mean by distance? And there are multiple plausible definitions of distance, and you would get a different answer depending upon which measure you used.
3247	These are called linkage metrics. The most common one used is probably single-linkage, and that says the distance between a pair of clusters is equal to the shortest distance from any member of one cluster to any member of the other cluster. So if I have two clusters, here and here, and they have bunches of points in them, single-linkage distance would say, well, let's use these two points which are the closest, and the distance between these two is the distance between the clusters. You can also use complete-linkage, and that says the distance between any two clusters is equal to the greatest distance from any member to any other member. OK? So if we had the same picture we had before-- probably not the same picture, but it's a picture. Whoops. Then we would say, well, I guess complete-linkage is probably the distance, maybe, between those two. And finally, not surprisingly, you can take the average distance. These are all plausible metrics. They're all used and practiced for different kinds of results depending upon the application of the
3248	clustering.
3249	All right, let's look at an example. So what I have here is the air distance between six different cities, Boston, New York, Chicago, Denver, San Francisco, and Seattle. And now let's say we're-- want to cluster these airports just based upon their distance. So we start. The first piece of our [? dendogram ?] says, well, all right, I have six cities, I have six clusters, each containing one city. All right, what happens next? What's the next level going to look like? Yeah? AUDIENCE: You're going from Boston [INAUDIBLE] JOHN GUTTAG: I'm going to join Boston and New York, as improbable as that sounds. All right, so that's the next level. And if for some reason I only wanted to have five clusters, well, I could stop here. Next, what happens? Well, I look at it, I say well, I'll join up Chicago with Boston and New York. All right. What do I get at the next level? Somebody? Yeah. AUDIENCE: Seattle [INAUDIBLE] JOHN GUTTAG: Doesn't look like it to me. If you look at San Francisco and
3250	Seattle, they are 808 miles, and Denver and San Francisco is 1,235. So I'd end up, in fact, joining San Francisco and Seattle. AUDIENCE: That's what I said. JOHN GUTTAG: Well, that explains why I need my hearing fixed. [LAUGHTER] All right. So I combine San Francisco and Seattle, and now it gets interesting. I have two choices with Denver. Obviously, there are only two choices, and which I choose depends upon which linkage criterion I use. If I'm using single-linkage, well, then Denver gets joined with Boston, New York, and Chicago, because it's closer to Chicago than it is to either San Francisco or Seattle. But if I use complete-linkage, it gets joined up with San Francisco and Seattle, because it is further from Boston than it is from, I guess it's San Francisco or Seattle. Whichever it is, right? So this is a place where you see what answer I get depends upon the linkage criteria. And then if I want, I can consider to the next step and just join them all. All right? That's hierarchical clustering.
3251	So it's good because you get this whole history of the [? dendograms, ?] and you get to look at it, say, well, all right, that looks pretty good. I'll stick with this clustering. It's deterministic. Given a linkage criterion, you always get the same answer. There's nothing random here. Notice, by the way, the answer might not be optimal with regards to that linkage criteria. Why not? What kind of algorithm is this? AUDIENCE: Greedy. JOHN GUTTAG: It's a greedy algorithm, exactly. And so I'm making locally optimal decisions at each point which may or may not be globally optimal. It's flexible. Choosing different linkage criteria, I get different results. But it's also potentially really, really slow. This is not something you want to do on a million examples. The naive algorithm, the one I just sort of showed you, is N cubed. N cubed is typically impractical. For some linkage criteria, for example, single-linkage, there exists very clever N squared algorithms. For others, you can't beat N cubed. But even N squared is really not very good. Which
3252	gets me to a much faster greedy algorithm called k-means. Now, the k in k-means is the number of clusters you want. So the catch with k-means is if you don't have any idea how many clusters you want, it's problematical, whereas hierarchical, you get to inspect it and see what you're getting. If you know how many you want, it's a good choice because it's much faster.
3253	All right, the algorithm, again, is very simple. This is the one that Professor Grimson briefly discussed. You randomly choose k examples as your initial centroids. Doesn't matter which of the examples you choose. Then you create k clusters by assigning each example to the closest centroid, compute k new centroids by averaging the examples in each cluster. So in the first iteration, the centroids are all examples that you started with. But after that, they're probably not examples, because you're now taking the average of two examples, which may not correspond to any example you have. Actually the average of N examples. And then you just keep doing this until the centroids don't move. Right? Once you go through one iteration where they don't move, there's no point in recomputing them again and again and again, so it is converged. So let's look at the complexity. Well, at the moment, we can't tell you how many iterations you're going to have, but what's the complexity of one iteration? Well, let's think about what you're doing here. You've got k
3254	centroids. Now I have to take each example and compare it to each-- in a naively, at least-- to each centroid to see which it's closest to. Right? So that's k comparisons per example. So that's k times n times d, where how much time each of these comparison takes, which is likely to depend upon the dimensionality of the features, right? Just the Euclidean distance, for example. But this is a way small number than N squared, typically. So each iteration is pretty quick, and in practice, as we'll see, this typically converges quite quickly, so you usually need a very small number of iterations. So it is quite efficient, and then there are various ways you can optimize it to make it even more efficient. This is the most commonly-used clustering algorithm
3255	Let's look at an example. So I've got a bunch of blue points here, and I actually wrote the code to do this. I'm not going to show you the code. And I chose four centroids at random, colored stars. A green one, a fuchsia-colored one, a red one, and a blue one. So maybe they're not the ones you would have chosen, but there they are. And I then, having chosen them, assign each point to one of those centroids, whichever one it's closest to. All right? Step one. And then I recompute the centroid. So let's go back. So we're here, and these are the initial centroids. Now, when I find the new centroids, if we look at where the red one is, the red one is this point, this point, and this point. Clearly, the new centroid is going to move, right? It's going to move somewhere along in here or something like that, right? So we'll get those new centroids. There it is. And now we'll re-assign points. And what we'll see is this point is
3256	"now closer to the red star than it is to the fuchsia star, because we've moved the red star. Whoops. That one. Said the wrong thing. They were red to start with. This one is now suddenly closer to the purple, so-- and to the red. It will get recolored. We compute the new centroids. We're going to move something again. We continue. Points will move around. This time we move two points. Here we go again. Notice, again, the centroids don't correspond to actual examples. This one is close, but it's not really one of them. Move two more. Recompute centroids, and we're done. So here we've converged, and I think it was five iterations, and nothing will move again. All right? Does that make sense to everybody? So it's pretty simple. What are the downsides? Well, choosing k foolishly can lead to strange results. So if I chose k equal to 3, looking at this particular arrangement of points, it's not obvious what ""the right answer"" is, right? Maybe it's making all of this one cluster. I don't"
3257	know. But there are weird k's and if you choose a k that is nonsensical with respect to your data, then your clustering will be nonsensical. So that's one problem we have think about. How do we choose k? Another problem, and this is one somebody raised last time, is that the results can depend upon the initial centroids. Unlike hierarchical clustering, k-means is non-deterministic. Depending upon what random examples we choose, we can get a different number of iterations. If we choose them poorly, it could take longer to converge. More worrisome, you get a different answer. You're running this greedy algorithm, and you might actually get to a different place, depending upon which centroids you chose. So these are the two issues we have to think about dealing with. So let's first think about choosing k. What often happens is people choose k using a priori knowledge about the application. If I'm in medicine, I actually know that there are only five different kinds of bacteria in the world. That's true. I mean, there are subspecies, but five
3258	large categories. And if I had a bunch of bacterium I wanted to cluster, may just set k equal to 5. Maybe I believe there are only two kinds of people in the world, those who are at MIT and those who are not. And so I'll choose k equal to 2. Often, we know enough about the application, we can choose k. As we'll see later, often we can think we do, and we don't. A better approach is to search for a good k. So you can try different values of k and evaluate the quality of the result. Assume you have some metric, as to say yeah, I like this clustering, I don't like this clustering. And we'll talk about do that in detail. Or you can run hierarchical clustering on a subset of data. I've got a million points. All right, what I'm going to do is take a subset of 1,000 of them or 10,000. Run hierarchical clustering. From that, get a sense of the structure underlying the data. Decide k should be 6, and
3259	then run k-means with k equals 6. People often do this. They run hierarchical clustering on a small subset of the data and then choose k. And we'll look-- but one we're going to look at is that one. What about unlucky centroids? So here I got the same points we started with. Different initial centroids. I've got a fuchsia one, a black one, and then I've got red and blue down here, which I happened to accidentally choose close to one another. Well, if I start with these centroids, certainly you would expect things to take longer to converge. But in fact, what happens is this-- I get this assignment of blue, this assignment of red, and I'm done. It converges on this, which probably is not what we wanted out of this. Maybe it is, but the fact that I converged on some very different place shows that it's a real weakness of the algorithm, that it's sensitive to the randomly-chosen initial conditions. Well, couple of things you can do about that. You could be clever and try
3260	and select good initial centroids. So people often will do that, and what they'll do is try and just make sure that they're distributed over the space. So they would look at some picture like this and say, well, let's just put my centroids at the corners or something like that so that they're far apart. Another approach is to try multiple sets of randomly-chosen centroids, and then just select the best results. And that's what this little algorithm on the screen does. So I'll say best is equal to k-means of the points themselves, or something, then for t in range number of trials, I'll say C equals k-means of points, and I'll just keep track and choose the one with the least dissimilarity. The thing I'm trying to minimize. OK? The first one is got all the points in one cluster. So it's very dissimilar. And then I'll just keep generating for different k's and I'll choose the k that seems to be the best, that does the best job of minimizing my objective function. And this is
3261	a very common solution, by the way, for any randomized greedy algorithm. And there are a lot of randomized greedy algorithms that you just choose multiple initial conditions, try them all out and pick the best.
3262	All right, now I want to show you a slightly more real example. So this is a file we've got with medical patients, and we're going to try and cluster them and see whether the clusters tell us anything about the probability of them dying of a heart attack in, say, the next year or some period of time. So to simplify things, and this is something I have done with research, but we're looking at only four features here-- the heart rate in beats per minute, the number of previous heart attacks, the age, and something called ST elevation, a binary attribute. So the first three are obvious. If you take an ECG of somebody's heart, it looks like this. This is a normal one. They have the S, the T, and then there's this region between the S wave and the T wave. And if it's higher, hence elevated, that's a bad thing. And so this is about the first thing that they measure if someone is having cardiac problems. Do they have ST elevation? And then with
3263	each patient, we're going to have an outcome, whether they died, and it's related to the features, but it's probabilistic not deterministic. So for example, an older person with multiple heart attacks is at higher risk than a young person who's never had a heart attack. That doesn't mean, though, that the older person will die first. It's just more probable. We're going to take this data, we're going to cluster it, and then we're going to look at what's called the purity of the clusters relative to the outcomes. So is the cluster, say, enriched by people who died? If you have one cluster and everyone in it died, then the clustering is clearly finding some structure related to the outcome.
3264	So the file is in the zip file I uploaded. It looks more or less like this. Right? So it's very straightforward. The outcomes are binary. 1 is a positive outcome. Strangely enough in the medical jargon, a death is a positive outcome. I guess maybe if you're responsible for the medical bills, it's positive. If you're the patient, it's hard to think of it as a good thing. Nevertheless, that's the way that they talk. And the others are all there, right?
3265	All right, let's look at some code. So I've extracted some code. I'm not going to show you all of it. There's quite a lot of it, as you'll see. So we'll start-- one of the files you've got is called cluster dot pi. I decided there was enough code, I didn't want to put it all in one file. I was getting confused. So I said, let me create a file that has some of the code and a different file that will then import it and use it. Cluster has things that are pretty much unrelated to this example, but just useful for clustering. So an example here has name, features, and label. And really, the only interesting thing in it-- and it's not that interesting-- is distance. And the fact that I'm using Minkowski with 2 says we're using Euclidean distance. Class cluster. It's a lot more code to that one. So we start with a non-empty list of examples. That's what init does. You can imagine what the code looks like, or you can look at
3266	it. Update is interesting in that it takes the cluster and examples and puts them in-- if you think of k-means in the cluster closest to the previous centroids and then returns the amount the centroid has changed. So if the centroid has changed by 0, then you don't have anything, right? Creates the new cluster. And the most interesting thing is computeCentroid. And if you look at this code, you can see that I'm a slightly unreconstructed Python 2 programmers. I just noticed this. I really shouldn't have written 0.0. I should have just written 0, but in Python 2, you had to write that 0.0. Sorry about that. Thought I'd fixed these. Anyway, so how do we compute the centroid? We start by creating an array of all 0s. The dimensionality is the number of features in the example. It's one of the methods from-- I didn't put up on the PowerPoint. And then for e in examples, I'm going to add to vals e.getFeatures, and then I'm just going to divide vals by the length of self.examples,
3267	the number of examples. So now you see why I made it a pylab array, or a numpy array rather than a list, so I could do nice things like divide the whole thing in one expression. As you do math, any kind of math things, you'll find these arrays are incredibly convenient. Rather than having to write recursive functions or do bunches of iterations, the fact that you can do it in one keystroke is incredibly nice. And then I'm going to return the centroid.
3268	Variability is exactly what we saw in the formula. And then just for fun, so you could see this, I used an iterator here. I don't know that any of you have used the yield statement in Python. I recommend it. It's very convenient. One of the nice things about Python is almost anything that's built in, you can make your own version of it. And so once I've done this, if c is a cluster, I can now write something like for c in big C, and this will make it work just like iterating over a list. Right, so this makes it possible to iterate over it. If you haven't read about yield, you probably should read the probably about two paragraphs in the textbook explaining how it works, but it's very convenient. Dissimilarity we've already seen.
3269	All right, now we get to patients. This is in the file lec 12, lecture 12 dot py. In addition to importing the usual suspects of pylab and numpy, and probably it should import random too, it imports cluster, the one we just looked at. And so patient is a sub-type of cluster.Example. Then I'm going to define this interesting thing called scale attributes. So you might remember, in the last lecture when Professor Grimson was looking at these reptiles, he ran into this problem about alligators looking like chickens because they each have a large number of legs. And he said, well, what can we do to get around this? Well, we can represent the feature as a binary number. Has legs, doesn't have legs. 0 or 1. And the problem he was dealing with is that when you have a feature vector and the dynamic range of some features is much greater than the others, they tend to dominate because the distances just look bigger when you get Euclidean distance. So for example, if we wanted to cluster
3270	the people in this room, and I had one feature that was, say, 1 for male and 0 for female, and another feature that was 1 for wears glasses, 0 for doesn't wear glasses, and then a third feature which was weight, and I clustered them, well, weight would always completely dominate the Euclidean distance, right? Because the dynamic range of the weights in this room is much higher than the dynamic range of 0 to 1. And so for the reptiles, he said, well, OK, we'll just make it a binary variable. But maybe we don't want to make weight a binary variable, because maybe it is something
3271	So what we do is we scale it. So this is a method called z-scaling. More general than just making things 0 or 1. It's a simple code. It takes in all of the values of a specific feature and then performs some simple calculations, and when it's done, the resulting array it returns has a known mean and a known standard deviation. So what's the mean going to be? It's always going to be the same thing, independent of the initial values. Take a look at the code. Try and see if you can figure it out. Anybody want to take a guess at it? 0. Right? So the mean will always be 0. And the standard deviation, a little harder to figure, but it will always be 1. OK? So it's done this scaling. This is a very common kind of scaling called z-scaling. The other way people scale is interpolate. They take the smallest value and call it 0, the biggest value, they call it 1, and then they do a linear interpolation of all the values
3272	between 0 and 1. So the range is 0 to 1. That's also very common. So this is a general way to get all of the features sort of in the same ballpark so that we can compare them.
3273	And we'll look at what happens when we scale and when we don't scale. And that's why my getData function has this parameter to scale. It either creates a set of examples with the attributes as initially or scaled. And then there's k-means. It's exactly the algorithm I showed you with one little wrinkle, which is this part. You don't want to end up with empty clusters. If I tell you I want four clusters, I don't mean I want three with examples and one that's empty, right? Because then I really don't have four clusters. And so this is one of multiple ways to avoid having empty clusters. Basically what I did here is say, well, I'm going to try a lot of different initial conditions. If one of them is so unlucky to give me an empty cluster, I'm just going to skip it and go on to the next one by raising a value error, empty cluster. And if you look at the code, you'll see how this value error is used. And then try k-means. We'll
3274	call k-means numTrial times, each one getting a different set of initial centroids, and return the result with the lowest dissimilarity.
3275	Then I have various ways to examine the results. Nothing very interesting, and here's the key place where we're going to run the whole thing. We'll get the data, initially not scaling it, because remember, it defaults to true. Then initially, I'm only going to try one k. k equals 2. And we'll call testClustering with the patients. The number of clusters, k. I put in seed as a parameter here because I wanted to be able to play with it and make sure I got different things for 0 and 1 and 2 just as a testing thing. And five trials it's defaulting to. And then we'll look at testClustering is returning the fraction of positive examples
3276	OK? So let's see what happens when we run it. All right. So we got two clusters. Cluster of size 118 with .3305, and a cluster of size 132 with a positive fraction of point quadruple 3. Should we be happy? Does our clustering tell us anything, somehow correspond to the expected outcome for patients here? Probably not, right? Those numbers are pretty much indistinguishable statistically. And you'd have to guess that the fraction of positives in the whole population is around .33, right? That about a third of these people died of their heart attack. And I might as well have signed them randomly to the two clusters, right? There's not much difference between this and what you would get with the random result. Well, why do we think that's true? Because I didn't scale, right? And so one of the issues we had to deal with is, well, age had a big dynamic range, and, say, ST elevation, which I told you was highly diagnostic, was either 0 or 1. And so probably everything is getting
3277	All right, so we have an easy way to fix that. We'll just scale the data. Now let's see what we get. All right. That's interesting. With casting rule? Good grief. That caught me by surprise. Good thing I have the answers in PowerPoint to show you, because the code doesn't seem to be working. Try it once more. No. All right, well, in the interest of getting through this lecture on schedule, we'll go look at the results that we get-- I got last time I ran it. All right. When I scaled, what we see here is that now there is a pretty dramatic difference, right? One of the clusters has a much higher fraction of positive patients than others, but it's still a bit problematic. So this has pretty good specificity, or positive predictive value, but its sensitivity is lousy. Remember, a third of our initial population more or less, was positive. 26 is way less than a third, so in fact I've got a class, a cluster, that is strongly enriched, but I'm still lumping most
3278	"of the positive patients into the other cluster. And in fact, there are 83 positives. Wrote some code to do that. And so we see that of the 83 positives, only this class, which is 70% positive, only has 26 in it to start with it. So I'm clearly missing most of the positives. So why? Well, my hypothesis was that different subgroups of positive patients have different characteristics. And so we could test this by trying other values of k to see with-- we would get more clusters. So here, I said, let's try k equals 2, 4, and 6. And here's what I got when I ran that. So what you'll notice here, as we get to, say, 4, that I have two clusters, this one and this one, which are heavily enriched with positive patients. 26 as before in the first one, but 76 patients in the third one. So I'm now getting a much higher fraction of patients in one of the ""risky"" clusters. And I can continue to do that, but if I look at"
3279	k equals 6, we now look at the positive clusters. There were three of them significantly positive. But I'm not really getting a lot more patients total, so maybe 4 is the right answer. So what you see here is that we have at least two parameters to play with, scaling and k. Even though I was only wanted a structure that would separate the risk-- high-risk patients from the lower-risk, which is why I started with 2, I later discovered that, in fact, there are multiple reasons for being high-risk. And so maybe one of these clusters is heavily enriched by old people. Maybe another one is heavily enriched by people who have had three heart attacks in the past, or ST elevation or some combination. And when I had only two clusters, I couldn't get that fine gradation. So this is what data scientists spend their time doing when they're doing clustering, is they actually have multiple parameters. They try different things out. They look at the results, and that's why you actually have to think to manipulate
3280	data rather than just push a button and wait for the answer. All right. More of this general topic on Wednesday when we're going to talk about classification. Thank you.
3281	The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. JOHN GUTTAG: Hello, everybody. Well, here we are at the last lecture. We're going to finish talking about statistical sins and then do a little bit of a wrap-up. Let's look at a hot topic-- global fiction-- or global warming, fact or fiction. You've done a problem set related
3282	Here is a plot generally accepted of the change in temperatures on the planet between 1880 and 2014. Now, if we look at this plot, we could see this commits one of the statistical sins I complained about on Monday, that look where it's starting the y-axis, way down here at 55. And you remember, I told you to beware of charts for the y-axis doesn't start at 0. So maybe the people who are trying to claim about global warming are just deceiving us with this trick of the axis. So here's what happens when you put it at 0. And as you can see-- or barely see-- this axis runs from 0 up to 110 as the average temperature. And as you can see quite clearly, it's hardly changed at all. So what's the deal here? Well, which is a more accurate presentation of the facts? Which conveys the accurate impression? Let's look at another example, maybe a little less controversial than climate change-- fever and flu.
3283	you might run a fever. So here is someone who had the flu. And this is plotting their fever from the beginning to its peak. And it does appear, if we were to fit a curve to this, it would look pretty much like that. On the other hand, if we assume that somebody's temperature could range between 0 and 200, we can see that, in fact, your temperature doesn't move at all when you get the flu. So the moral is pretty clear, I think. Even though on Monday I talked about being suspicious when people start the y-axis too far from 0, you should truncate it to eliminate totally preposterous values. No living person has a temperature of 0 degrees Fahrenheit. So again, don't truncate it just to make something look like it isn't, but don't expand it to deceive either. Let's return to global warming.
3284	shown on the floor of the US Senate by a senator from Texas, who I shall not name. And obviously, the argument here was that, well, sure global warming bounces up and down. But if we go back, we can see here, the date is 19-- can we see it? I can see it. Maybe 1986, I think. You can see that the argument here is, in fact, if you fit a trend line to this, as he's done, it hasn't changed at all. And so even though we've had a lot of carbon emissions during this period, maybe global warming is not actually happening. This is in contradiction to the trend I showed before. Well, what's going on here? This is a very common way that people use statistics poorly. They confuse fluctuations with trends. What we see in any theories of data-- time series, or other series-- you always have fluctuations. And that's not to be confused with the trend. And in particular, what you need to think about when you're looking at a phenomenon is choose an
3285	interval consistent with the thing that's being considered. So we believe that climate change is something that happens over very long periods of time. And it's a little bit silly to look at it on a short period of time. Some of you may remember two years ago, we had a very cold winter here. And there were people who were saying, well, that shows we don't have global warming. Well, you can't really conclude anything about climate change looking at a year, or probably not even looking at 10 years or 20 years. It's a very slow phenomenon. On the other hand, if you're looking at the change in somebody's heart rate, seeing if they have a heart condition, you probably don't want to look at it over a 10-year period. So you have to decide what you're doing and find an interval that lets you look at the trends rather than the fluctuations. Any rate, maybe even if we're having global warming, at least the Arctic ice isn't melting, though apparently, I read in the paper this morning
3286	they found a huge crack in it. So this was reported in the Financial Post on April 15, 2013. You can read it yourself. But the basic import of it is they took the period from April 14, 1989 to April 15, 2013 and said, look, it's not changing. In fact, the amount of arctic ice is unchanged. Well, what's the financial-- not the financial-- what's the statistical sin being committed here? If we look at this data, this is an anomaly chart. I think you saw one of these in one of the problems sets, where you fix something at 0 and then you show fluctuations relative to that. So here, it's the Arctic ice relative to a point. And what we see here is that if you go and choose the right date-- say this one in 1989-- and you come over here and you choose the right date in 2013-- say this one-- you can then draw a line and say, oh, look, it hasn't changed. This is something people frequently do, is they take a whole
3287	set of data, and they find two points that are consistent with something they believe. And they draw a line between those two points, fit a curve to those two points, and draw some conclusion. This is what we call cherry picking, I guess from the notion that when you go to pick cherries you only want to pick the right ones, leave the others to ripen for a bit on the tree. It's really bad. And it's something that, unfortunately, the scientific literature is replete with, where people look at a lot of data, and they pick the points that match what they want to prove. And so as you can see, while the trend is quite clear, you could prove almost anything you wanted by selecting two points very carefully. I could also show that it's crashing much faster than people think it is by picking these two points. If I wanted to argue that it's catastrophic, I'd pick those two points and say, look at that, it's disappearing at an incredible rate. So you can lie in
3288	either direction with this data by careful cherry picking. As a service to you, I know the holidays are coming and many of you have not bought presents for your parents, so here's a modest gift suggestion, that the family that shoots together something or other. Well, all right, so we can ask, is this a good gift? Well, probably. We can look at this statistic. It's not dangerous at least. We see that 99.8% of the firearms in the US will not be used to commit a violent crime. So guns apparently are not actually dangerous, or at least not in the hands of criminals. Well, let's look at this. How many privately owned firearms are there in the US? And anyone want to guess who hasn't looked ahead? Yeah. AUDIENCE: 400 million. JOHN GUTTAG: 400 million. 340 million people and 400 million guns is the guess, more than one per person. You certainly are the right order of magnitude. I think it's about 300 million, but it's hard to count them. Maybe this doesn't count water pistols. So
3289	if you assume there are 300 million firearms and 0.2% of them are used to commit a violent crime in every year, we see that how many crimes is that? 600,000. So in fact, it's not necessarily very meaningful to say that most of them are not used to commit a crime. Well, let's look at another place where we look at a statistic. Probably most of you don't even remember the scary swine flu epidemic. This was a big headline. And people got so scared of the swine flu they were doing things like closing schools to try limit the spread of the flu. New York City closed some schools because of it, for example. So is this a scary statistic? Well, maybe, but here's an interesting statistic. How many deaths per year are from the seasonal flu in the US-- the ones we try and prevent with a flu shot? 36,000. So what we see is that, it doesn't make a lot of sense to panic over 159 in the light of this number. So the point here
3290	for both this and the issue about the firearms is that context matters.
3291	Yeah, I love this cartoon. A number without context is just a number. And numbers by themselves don't mean anything. So to say that there were 159 deaths from the swine flu is not very meaningful without some context. To say that only 0.2% of firearms are used to commit a violent crime is not very meaningful without context. Whenever you're presenting a statistic, reading about a statistic, and you just see a number that seems comforting or terrifying, try and put some context around it. So a related thing is relative to what? Suppose I told you that skipping lectures increases your probability of failing this course by 50%. Well, you would all feel great, because you're here. And you would be laughing at your friends who are not here, because figuring that will leave much better grades for you. What does this mean, though? Well, if I told you that it changed the probability of failing from a half to 0.75, you would be very tempted to come to lectures. On the other hand, if I told you
3292	that it changed the probability from 0.005 to 0.0075, you might say, the heck with it, I'd rather go to the gym. Again this, is an issue. And this is something that we see all the time when people talk about percentage change. This is particularly prominent in the pharmaceutical field. You will read a headline saying that drug x for arthritis increases the probability of a heart attack by 1% or 5%. Well, what does that mean? If the probability was already very low, increasing it by 5%, it's still very low. And maybe it's worth it not to be in pain from arthritis. So talking in percentages is, again, one of these issues of it doesn't make sense without the context. In order to know what this means, I need to know what regime I'm in here in order to make a intelligent decisions about whether to attend lecture or not. It goes without saying, you have all made the right decision. So beware of percentage change when you don't know the denominator. You get a percentage by
3293	dividing by something. And if you don't know what you're dividing by, then the percentage is itself a meaningless number. While we're sort of talking about medical things, let's look at cancer clusters to illustrate another statistical question.
3294	"""a greater-than-expected number of cancer cases that occurs in a group of people in a geographic area over a period of time."" And the key part of this definition is greater-than-expected. About 1,000 cancer clusters per year are reported in the US, mostly to the Centers for Disease Control, but in general to other health agencies. Upon analysis, almost none of them pass this test. So the vast majority, some years all of them, are deemed actually not to be cancer clusters. So I don't know if-- has anyone here seen the movie Erin Brockovich? Subsequent analysis showed that was actually not a cancer cluster. It's a good movie, but turns out statistically wrong. This, by the way, is not a cancer cluster. This is a constellation. So let's look at a hypothetical example. By the way, the other movie about cancer clusters was the one set in Massachusetts. What was the name? A Civil Action. Anyone see that? No. That was a cancer cluster. Massachusetts is about 10,000 square miles. And there are about 36,000 cancer cases per year"
3295	reported in Massachusetts. Those two numbers are accurate. And the rest of this is pure fiction.
3296	partitioned the state into 1,000 regions of 10 square miles each and looked at the distribution of cancer cases in these regions trying to find cancer clusters that he or she could file a lawsuit about. Well, you can do some arithmetic. And if there are 36,000 new cancer cases a year and we have 1,000 regions, that should say that we should get about 36 cancer cases per year and per region. Well, when the attorney look at the data, this mythical attorney, he discovered that region number 111 had 143 new cancer cases over a three-year period. He compared that to 3 times 36 and said, wow, that's 32% more than expected. I've got a lawsuit. So he went to tell all these people-- they lived in a cancer cluster. And the question is, should they be worried? Well, another way to look at the question is, how likely is it that it was just bad luck? That's the question we've always ask when we do statistical analysis-- is this result meaningful, or is it just random variation
3297	that you would expect to see? So I wrote some code to simulate it to see what happens-- so number of cases, 36,000, number of years, 3. So all of this is just the numbers I had on the slide. We'll do a simulation. We'll take 100 trials. And then what I'm going to do is for t in the range number of trials, the locations, the regions, if you will, I'll initialize each to 0, 1,000 of them, in this case. And then for i in the range number of years times number of cases per year, so this will be 3 times 36,000. At random, I will assign the case to one of these regions. This is the random. Nothing to do with cancer clusters, just at random, this case gets assigned to one of the 1,000 regions. And then I'm going to check if region number 111 had greater than or equal to 143, the number of cases we assumed it had. If so, we'll increment the variable num greater by 1, saying, in this trial of
3298	100, indeed, it had that many. And then we'll see how often that happens. That will tell us how improbable it is that region 111 actually had that many cases. And then we'll print it. Does that makes sense to everyone, that here I am doing my simulation to see whether or not how probable is it that 111 would have had this many cases? Any questions? Let's run it. So here's the code we just looked at. Takes just a second. That's why I did only 100 trials instead of 1,000. I know the suspense is killing you. It's killing me. I don't know why it's taking so long. We'll finish. I wish I had the Jeopardy music or something to play while we waited for this. Anna, can you home some music or something to keep people amused? She will not. Wow. So here it is. The estimated probability of region 111 having at least 1 case-- at least 143 cases-- easier to read if I spread this out is 0.01. So it seems, in fact, that it's
3299	pretty surprising-- unlikely to have happened at random. Do you buy it? Or is there a flaw here? Getting back to this whole question. Yes. AUDIENCE: I think it's flawed because first off you have to look at the population. That is more important. JOHN GUTTAG: You have to look at what? AUDIENCE: Population as opposed to like the number of areas, because when you get past the Boston area, you'd expect a-- JOHN GUTTAG: Let's assume that, in fact, instead of by square miles-- let's assume the populations were balanced. AUDIENCE: Then I also think it's flawed because I don't think the importance of block 111 having 143 is important. I think the importance is just one area having a higher-- JOHN GUTTAG: Exactly right. Exactly right. I'm sorry, I forgot my candy bag today. Just means there'll be more candy for the final. What we have here is a variant of cherry picking. What I have done in this simulation is I've looked at 1,000 different regions. What the attorney did is, not in a simulation, is he
3300	looked at 1,000 different regions, found the one with the most cancer cases, and said, aha, there are too many here. And that's not what I did in my simulation. My simulation didn't ask the question, how likely is it that there is at least one region with that many cases. But it asked the question, how likely is it that this specific region has that many cases. Now, if the attorney had reason in advance to be suspicious of region 111, then maybe it would have been OK to just go check that. But having looked at 1,000 and then cherry pick the best is not right. So this is a simulation that does the right thing. I've left out the initialization. But what you can see I'm doing here is I'm looking at the probability of there being any region that has at least 143 cases. What this is called in the technical literature, what the attorney did is multiple hypothesis checking. So rather than having a single hypothesis, that region 111 is bad, he checked 1,000 different
3301	hypotheses, and then chose the one that met what he wanted. Now, there are good statistical techniques that exist for dealing with multiple hypotheses, things like the Bonferroni correction. I love to say that name. But you have to worry about it. And in fact, if we go back to the code and comment out this one and run this one, we'll see we get a very different answer. The answer we get is-- let's see. Oh, I see. All right, let me just comment this out. Yeah, this should work, right? Well, maybe you don't want to wait for it. But the answer you'll get is that it's actually very probable. My recollection is it's a 0.6 probability that at least one region has that many cases. And that's really what's going on with this whole business of people reporting cancer clusters. It's just by accident, by pure randomness, some region has more than its share. This particular form of cherry picking also goes by the name of the Texas sharpshooter fallacy. I don't know why people pick on
3302	Texas for this. But they seem to.
3303	and you see a barn with a bunch of bullet holes in the wall right in the middle of a target. But what actually happened was you had a barn. The farmer just shot some things at random at the barn, then got out his paint brush and painted a target right around where they happened to land. And that's what happens when you cherry pick hypotheses. What's the bottom line of all these statistical fallacies? When drawing inferences from data, skepticism is merited. There are, unfortunately, more ways to go wrong than to go right. And you'll read the literature that tells you that in the scientific literature more than half of the papers were later shown to be wrong. You do need to remember that skepticism and denial are different. It's good to be skeptical. And I love Ambrose Bierce's description of the difference here. If you had never read Ambrose Bierce, he's well worth reading. He wrote something called The Devil's Dictionary,
3304	of a lot of words. And he went by the nickname Bitter Bierce. And if you read The Devil's Dictionary, you'll see why. But this, I think, has a lot of wisdom in it. Let's, in the remaining few minutes, wrap up the course. So what did we cover in 6.0002? A lot of things. If you look at the technical, things were three major units-- optimization problems, stochastic thinking, and modeling aspects of the world. But there was a big subtext amongst all of it, which was this. There was a reason our problem sets were not pencil and paper probability problems, but all coding. And that's because we really want, as an important part of the course, is to make you a better programmer. We introduced a few extra features of Python. But more importantly, we emphasized the use of libraries, because in the real world when you're trying to build things, you rarely start from scratch. And if you do start from scratch, you're probably making a mistake. And so we wanted to get you used to
3305	the idea of finding and using libraries. So we looked at plotting libraries and machine learning libraries and numeric libraries. And hopefully, you got a lot of practice in that you're a way better programmer than you were six weeks ago. A little more detailed-- the optimization problems, the probably most important takeaway is that many important problems can be formulated in terms of an objective function that you either maximize or minimize and some set of constraints. Once you've done that, there are lots of toolboxes, lots of libraries that you can use to solve the problem. You wrote some optimization code yourself. But most of the time, we don't solve them ourselves. We just call a built-in function that does it. So the hard part is not writing the code, but doing the formulation. We talked about different algorithms-- greedy algorithms, very often useful, but often don't find the optimal solution. So for example, we looked at k-means clustering. It was a very efficient way to find clusters. But it did not necessarily find the optimal set of
3306	clusters. We then observed that many optimization problems are inherently exponential. But even so, dynamic programming often works and gives us a really fast solution. And the notion here is this is not an approximate solution. It's not like using a greedy algorithm. It gives you an exact solution and in many circumstances gives it to you quickly. And the other thing I want you to take away is, outside the context of dynamic programming, memoization is a generally useful technique. What we've done there is we've traded time for space. We compute something, we save it, and when we need it, we look it up. And that's a very common programming technique. And we looked at a lot of different examples of optimization-- knapsack problems, several graph problems, curve fitting, clustering, logistic regression. Those are all optimization problems, can all be formulated as optimization problems. So it's very powerful and fits lots of needs. The next unit-- and, of course, I'm speaking as if these things were discrete in time, but they're not. We talked about optimization at the
3307	beginning. And I talk to an optimization last week. So these things were sort of spread out over the term. We talked about stochastic thinking. And the basic notion here is the world is nondeterministic, or at least predictably nondeterministic. And therefore, we need to think about things in terms of probabilities most of the time, or frequently. And randomness is a powerful tool for building computations that model the world. If you think the world is stochastic, then you need to have ways to write programs that are stochastic, if you're trying to model the world itself. The other point we made is that random computations-- randomness is a computational technique-- is useful even for problems that don't appear to involve any randomness. So we used it to find the value of pi. We showed you can use it to do integration. There's nothing random about the value of the integral of a function. Yet, the easiest way to solve it in a program is to use randomness. So randomness is a very powerful tool. And there's this whole
3308	area of random algorithms-- research area and practical area that's used to solve non-probabilistic problems. Modeling the world-- well, we just talked about part of it. Models are always inaccurate. They're providing some abstraction of reality. We looked at deterministic models-- the graph theory models. There was nothing nondeterministic about the graphs we looked at. And then we spent more time on statistical models. We looked at simulation models. In particular, spent quite a bit of time on the Monte Carlo simulation. We looked at models based on sampling. And there-- and also when we talked about simulation--
3309	that we need to be able to characterize how believable the results are. It's not good enough to just run a program and say, oh, it has an answer. You need to know whether to believe the answer. And the point we made is it's not a binary question. It's not yes, it's right, no, it's wrong. Typically, what we do is we have some statement about confidence intervals and confidence levels. We used two variables to describe how believable the answer is. And that's an important thing. And then we looked at tools we use for doing that. We looked at the central limit theorem. We looked at the empirical rule. We talked about different distributions. And especially, we spent a fair amount of time on the normal or Gaussian distribution. And then finally, we looked at statistical models based upon machine learning. We looked at unsupervised learning, basically just clustering, looked at two algorithms-- hierarchical and k-means. And we looked at supervised learning. And there, we essentially focused mostly on classification. And we looked at two ways of
3310	doing that-- k-nearest neighbors and logistic regression. Finally, we talked about presentation of data-- how to build plots, utility of plots, and recently, over the last two lectures, good and bad practices in presenting results about data. So my summary is, I hope that you think you've come a long way, particularly those of you-- how many of you were here in September when we started 6.0001? All right, most of you. Yeah, this, by the way, was a very popular ad for a long time, saying that, finally women are allowed to smoke, isn't this great. And Virginia Slims sponsored tennis-- the women's tennis tour to show how good it was that women were now able to smoke. But anyway, I know not everyone in this class is a woman. So just for the men in the room, you too could have come a long way. I hope you think that, if you look back at how you struggled in those early problems sets, I hope you really feel that you've learned a lot about how to build programs.
3311	And if you spend enough time in front of a terminal, this is what you get to look like. What might be next? I should start by saying, this is a hard course. We know that many of you worked hard. And the staff and I really do appreciate it. You know your return on investment. I'd like you to remember that you can now write programs to do useful things. So if you're doing a UROP, you're sitting in a lab, and you get a bunch of data from some experiments, don't just stare at it. Sit down and write some code to plot it to do something useful with it. Don't be afraid to write programs to help you out. There are some courses that I think you're now well-prepared to take. I've listed the ones I know best-- the courses in course 6. 6.009 is a sort of introduction to computer science. I think many of you will find that too easy after taking this course. But maybe, that's not a downside. 6.005 is a software engineering
3312	course, where they'll switch programming languages on you. You get to program in Java. 6.006 is a algorithms course in Python and I think actually quite interesting. And students seem to like it a lot, and they learn about algorithms and implementing them. And 6.034 is an introduction to artificial intelligence also in Python. And I should have listed 6.036, another introduction to machine learning in Python. You should go look for an interesting UROP. A lot of students come out of this course and go do UROPs, where they use what they've learned in this course. And many of them really have a very positive experience. So if you were worried that you're not ready for a UROP, you probably are-- a UROP using what's been done here. You can minor in computer science. This is now available for the first time this year. But really, if you have time, you should major in computer science, because it is really the best major on campus-- not even close, as somebody I know would say. Finally, sometimes people ask me
3313	"where I think computing is headed. And I'll quote one of my favorite baseball players. ""It's tough to make predictions, especially about the future."" And instead of my predictions, let me show you the predictions of some famous people. So Thomas Watson, who was the chairman of IBM-- a company you've probably heard of-- and he said, ""I think there is a world market for maybe five computers."" This was in response to, should they become a computer company, which they were not at the time. He was off by a little bit. A few years later, there was an article in Popular Mechanics, which was saying, computers are amazing. They're going to change enormously. Someday, they may be no more than 1 and 1/2 tons. You might get a computer that's no more than 3,000 pounds-- someday. So we're still waiting for that, I guess. I like this one. This is, having written a book recently, the editor in charge of books for Prentice Hall. ""I traveled the length and breadth of this country and talked with the best"
3314	"people. And I can assure you that data processing is a fad that won't last out the year."" MIT had that attitude for a while. For about 35 years, computer science was in a building off campus, because they weren't sure we were here to stay. Maybe that's not why, but that's why I interpret it. Ken Olsen, an MIT graduate-- I should say, a course 6 graduate-- was the founder and president and chair of Digital Equipment Corporation, which in 1977 was the second largest computer manufacturer in the world based in Maynard, Massachusetts. None of you have ever heard of it. They disappeared. And this is in part why, because Ken said, ""there's no reason anyone would want a computer in their home,"" and totally missed that part of computation. Finally, since this is the end of some famous last words, Douglas Fairbanks, Sr., a famous actor-- this is true-- the last thing he said before he died was, ""never felt better."" Amazing. This was from the movie The Mark of Zorro. Scientists are better. Luther Burbank, his"
3315	last words were, I don't feel so good. And well, I guess not. [LAUGHTER] And this is the last one.
3316	"This is a true story. He was riding behind the lines and trying to rally his men to not hide behind the stone walls but to stand up and shoot at the enemy. And he said, ""they couldn't hit an elephant at this distance."" Moments later, he was shot in the face and died. [LAUGHTER] And I thought this was an apocryphal story. But in fact, there's a plaque at the battlefield where this happened, documenting this story. And apparently, it's quite true. So with that, I'll say my last words for the chorus, which is I appreciate all your coming. And I guess you were the survivors. So thank you for being here. [APPLAUSE]"
3317	The following content is provided under a Creative Commons license. Your support will help MIT OpenCourseWare continue to offer high quality educational resources for free. To make a donation or to view additional materials from hundreds of MIT courses, visit MIT OpenCourseWare at ocw.mit.edu. ERIC GRIMSON: OK. Welcome back. You know, it's that time a term when we're all kind of doing this. So let me see if I can get a few smiles by simply noting to you that two weeks from today is the last class. Should be worth at least a little bit of a smile, right? Professor Guttag is smiling. He likes that idea. You're almost there. What are we doing for the last couple of lectures? We're talking about linear regression. And I just want to remind you, this was the idea of I have some experimental data. Case of a spring where I put different weights on measure displacements. And regression was giving us a way of deducing a model to fit that data. And In some cases it was easy. We knew, for
3318	example, it was going to be a linear model. We found the best line that would fit that data. In some cases, we said we could use validation to actually let us explore to find the best model that would fit it, whether a linear, a quadratic, a cubic, some higher order thing. So we'll be using that to deduce something about a model. That's a nice segue into the topic for the next three lectures, the last big topic of the class, which is machine learning. And I'm going to argue, you can debate whether that's actually an example of learning. But it has many of the elements that we want to talk about when we talk about machine learning. So as always, there's a reading assignment. Chapter 22 of the book gives you a good start on this, and it will follow up with other pieces. And I want to start by basically outlining what we're going to do. And I'm going to begin by saying, as I'm sure you're aware, this is a huge topic. I've listed
3319	"just five subjects in course six that all focus on machine learning. And that doesn't include other subjects where learning is a central part. So natural language processing, computational biology, computer vision robotics all rely today, heavily on machine learning. And you'll see those in those subjects as well. So we're not going to compress five subjects into three lectures. But what we are going to do is give you the introduction. We're going to start by talking about the basic concepts of machine learning. The idea of having examples, and how do you talk about features representing those examples, how do you measure distances between them, and use the notion of distance to try and group similar things together as a way of doing machine learning. And we're going to look, as a consequence, of two different standard ways of doing learning. One, we call classification methods. Example we're going to see, there is something called ""k nearest neighbor"" and the second class, called clustering methods. Classification works well when I have what we would call labeled data. I"
3320	know labels on my examples, and I'm going to use that to try and define classes that I can learn, and clustering working well, when I don't have labeled data. And we'll see what that means in a couple of minutes. But we're going to give you an early view of this. Unless Professor Guttag changes his mind, we're probably not going to show you the current really sophisticated machine learning methods like convolutional neural nets or deep learning, things you'll read about in the news. But you're going to get a sense of what's behind those, by looking at what we do when we talk about learning algorithms. Before I do it, I want to point out to you just how prevalent this is. And I'm going to admit with my gray hair, I started working in AI in 1975 when machine learning was a pretty simple thing to do. And it's been fascinating to watch over 40 years, the change. And if you think about it, just think about where you see it. AlphaGo, machine learning based system
3321	from Google that beat a world-class level Go player. Chess has already been conquered by computers for a while. Go now belongs to computers. Best Go players in the world are computers. I'm sure many of you use Netflix. Any recommendation system, Netflix, Amazon, pick your favorite, uses a machine learning algorithm to suggest things for you. And in fact, you've probably seen it on Google, right? The ads that pop up on Google are coming from a machine learning algorithm that's looking at your preferences. Scary thought. Drug discovery, character recognition-- the post office does character recognition of handwritten characters using a machine learning algorithm and a computer vision system behind it. You probably don't know this company. It's actually an MIT spin-off called Two Sigma, it's a hedge fund in New York. They heavily use AI and machine learning techniques. And two years ago, their fund returned a 56% return. I wish I'd invested in the fund. I don't have the kinds of millions you need, but that's an impressive return. 56% return on your money in one
3322	year. Last year they didn't do quite as well, but they do extremely well using machine learning techniques.
3323	Another great MIT company called Mobileye that does computer vision systems with a heavy machine learning component that is used in assistive driving and will be used in completely autonomous driving. It will do things like kick in your brakes if you're closing too fast on the car in front of you, which is going to be really bad for me because I drive like a Bostonian. And it would be kicking in constantly. Face recognition. Facebook uses this, many other systems do to both detect and recognize faces. IBM Watson-- cancer diagnosis. These are all just examples of machine learning being used everywhere. And it really is. I've only picked nine. So what is it? I'm going to make an obnoxious statement. You're now used to that. I'm going to claim that you could argue that almost every computer program learns something. But the level of learning really varies a lot. So if you think back to the first lecture in 60001, we showed you Newton's method for computing square roots. And you could argue, you'd have to stretch
3324	it, but you could argue that that method learns something about how to compute square roots. In fact, you could generalize it to roots of any order power. But it really didn't learn. I really had to program it. All right. Think about last week when we talked about linear regression. Now it starts to feel a little bit more like a learning algorithm. Because what did we do? We gave you a set of data points, mass displacement data points. And then we showed you how the computer could essentially fit a curve to that data point. And it was, in some sense, learning a model for that data that it could then use to predict behavior. In other situations. And that's getting closer to what we would like when we think about a machine learning algorithm. We'd like to have program that can learn from experience, something that it can then use to deduce new facts. Now it's been a problem in AI for a very long time. And I love this quote.
3325	1959 is the quote in which he says, his definition of machine learning is the field of study that gives computers the ability to learn without being explicitly programmed. And I think many people would argue, he wrote the first such program. It learned from experience. In his case, it played checkers. Kind of shows you how the field has progressed. But we started with checkers, we got to chess, we now do Go. But it played checkers. It beat national level players, most importantly, it learned to improve its methods by watching how it did in games and then inferring something to change what it thought about as it did that. Samuel did a bunch of other things. I just highlighted one. You may see in a follow on course, he invented what's called Alpha-Beta Pruning, which is a really useful technique for doing search. But the idea is, how can we have the computer learn without being explicitly programmed? And one way to think about this is to think about the difference between how we would normally program
3326	and what we would like from a machine learning algorithm. Normal programming, I know you're not convinced there's such a thing as normal programming, but if you think of traditional programming, what's the process? I write a program that I input to the computer so that it can then take data and produce some appropriate output. And the square root finder really sits there, right? I wrote code for using Newton method to find a square root, and then it gave me the process of given any number, I'll give you the square root. But if you think about what we did last time, it was a little different. And in fact, in a machine learning approach, the idea is that I'm going to give the computer output. I'm going to give it examples of what I want the program to do, labels on data, characterizations of different classes of things. And what I want the computer to do is, given that characterization of output and data, I wanted that machine learning algorithm to actually produce for me a program,
3327	a program that I can then use to infer new information about things. And that creates, if you like, a really nice loop where I can have the machine learning algorithm learn the program which I can then use to solve some other problem. That would be really great if we could do it. And as I suggested, that curve-fitting algorithm is a simple version of that. It learned a model for the data, which I could then use to label any other instances of the data or predict what I would see in terms of spring displacement as I changed the masses. So that's the kind of idea we're going to explore. If we want to learn things, we could also ask, so how do you learn? And how should a computer learn? Well, for you as a human, there are a couple of possibilities. This is the boring one. This is the old style way of doing it, right? Memorize facts. Memorize as many facts as you can and hope that we ask you on the final exam
3328	instances of those facts, as opposed to some other facts you haven't memorized. This is, if you think way back to the first lecture, an example of declarative knowledge, statements of truth. Memorize as many as you can. Have Wikipedia in your back pocket. Better way to learn is to be able to infer, to deduce new information from old. And if you think about this, this gets closer to what we called imperative knowledge-- ways to deduce new things. Now, in the first cases, we built that in when we wrote that program to do square roots. But what we'd like in a learning algorithm is to have much more like that generalization idea. We're interested in extending our capabilities to write programs that can infer useful information from implicit patterns in the data. So not something explicitly built like that comparison of weights and displacements, but actually implicit patterns in the data, and have the algorithm figure out what those patterns are, and use those to generate a program you can use to infer new data about objects,
3329	about string displacements, whatever it is you're trying to do. OK. So the idea then, the basic paradigm that we're going to see, is we're going to give the system some training data, some observations. We did that last time with just the spring displacements. We're going to then try and have a way to figure out, how do we write code, how do we write a program, a system that will infer something about the process that generated the data? And then from that, we want to be able to use that to make predictions about things we haven't seen before. So again, I want to drive home this point. If you think about it, the spring example fit that model. I gave you a set of data, spatial deviations relative to mass displacements. For different masses, how far did the spring move? I then inferred something about the underlying process. In the first case, I said I know it's linear, but let me figure out what the actual linear equation is. What's the spring constant associated with it?
3330	And based on that result, I got a piece of code I could use to predict new displacements. So it's got all of those elements, training data, an inference engine, and then the ability to use that to make new predictions. But that's a very simple kind of learning setting. So the more common one is one I'm going to use as an example, which is, when I give you a set of examples, those examples have some data associated with them, some features and some labels. For each example, I might say this is a particular kind of thing. This other one is another kind of thing. And what I want to do is figure out how to do inference on labeling new things. So it's not just, what's the displacement of the mass, it's actually a label. And I'm going to use one of my favorite examples. I'm a big New England Patriots fan, if you're not, my apologies. But I'm going to use football players. So I'm going to show you in a second, I'm going to
3331	give you a set of examples of football players. The label is the position they play. And the data, well, it could be lots of things. We're going to use height and weight. But what we want to do is then see how would we come up with a way of characterizing the implicit pattern of how does weight and height predict the kind of position this player could play. And then come up with an algorithm that will predict the position of new players. We'll do the draft for next year. Where do we want them to play? That's the paradigm. Set of observations, potentially labeled, potentially not. Think about how do we do inference to find a model. And then how do we use that model to make predictions. What we're going to see, and we're going to see multiple examples today, is that that learning can be done in one of two very broad ways.
3332	And in that case, for every new example I give you as part of the training data, I have a label on it. I know the kind of thing it is. And what I'm going to do is look for how do I find a rule that would predict the label associated with unseen input based on those examples. It's supervised because I know what the labeling is. Second kind, if this is supervised, the obvious other one is called unsupervised. In that case, I'm just going to give you a bunch of examples. But I don't know the labels associated with them. I'm going to just try and find what are the natural ways to group those examples together into different models. And in some cases, I may know how many models are there. In some cases, I may want to just say what's the best grouping I can find. OK. What I'm going to do today is not a lot of code. I was expecting cheers for that, John, but I didn't get them. Not a lot of
3333	"code. What I'm going to do is show you basically, the intuitions behind doing this learning. And I""m going to start with my New England Patriots example. So here are some data points about current Patriots players. And I've got two kinds of positions. I've got receivers, and I have linemen. And each one is just labeled by the name, the height in inches, and the weight in pounds. OK? Five of each. If I plot those on a two dimensional plot, this is what I get. OK? No big deal. What am I trying to do? I'm trying to learn, are their characteristics that distinguish the two classes from one another? And in the unlabeled case, all I have are just a set of examples. So what I want to do is decide what makes two players similar with the goal of seeing, can I separate this distribution into two or more natural groups. Similar is a distance measure. It says how do I take two examples with values or features associated, and we're going to decide how far"
3334	apart are they? And in the unlabeled case, the simple way to do it is to say, if I know that there are at least k groups there-- in this case, I'm going to tell you there are two different groups there-- how could I decide how best to cluster things together so that all the examples in one group are close to each other, all the examples in the other group are close to each other, and they're reasonably far apart. There are many ways to do it. I'm going to show you one. It's a very standard way, and it works, basically, as follows. If all I know is that there are two groups there, I'm going to start by just picking two examples as my exemplars. Pick them at random. Actually at random is not great. I don't want to pick too closely to each other. I'm going to try and pick them far apart. But I pick two examples as my exemplars. And for all the other examples in the training data, I say which one
3335	is it closest to. What I'm going to try and do is create clusters with the property that the distances between all of the examples of that cluster are small. The average distance is small. And see if I can find clusters that gets the average distance for both clusters as small as possible. This algorithm works by picking two examples, clustering all the other examples by simply saying put it in the group to which it's closest to that example. Once I've got those clusters, I'm going to find the median element of that group. Not mean, but median, what's the one closest to the center? And treat those as exemplars and repeat the process. And I'll just do it either some number of times or until I don't get any change in the process. So it's clustering based on distance. And we'll come back to distance in a second. So here's what would have my football players. If I just did this based on weight,
3336	And it kind of makes sense. All right? These three are obviously clustered, and again, it's just on this axis. They're all down here. These seven are at a different place. There's a natural dividing line there.
3337	This is what my algorithm came up with as the best dividing line here, meaning that these four, again, just based on this axis are close together. These six are close together. But it's not nearly as clean. And that's part of the issue we'll look at is how do I find the best clusters. If I use both height and weight, I get that, which was actually kind of nice, right? Those three cluster together. they're near each other, in terms of just distance in the plane. Those seven are near each other. There's a nice, natural dividing line through here. And in fact, that gives me a classifier. This line is the equidistant line between the centers of those two clusters. Meaning, any point along this line is the same distance to the center of that group as it is to that group. And so any new example, if it's above the line, I would say gets that label, if it's below the line, gets that label. In a second, we'll come back to look at how do
3338	we measure the distances, but the idea here is pretty simple. I want to find groupings near each other and far apart from the other group. Now suppose I actually knew the labels on these players. These are the receivers. Those are the linemen. And for those of you who are football fans, you can figure it out, right? Those are the two tight ends. They are much bigger. I think that's Bennett and that's Gronk if you're really a big Patriots fan. But those are tight ends, those are wide receivers, and it's going to come back in a second, but there are the labels. Now what I want to do is say, if I could take advantage of knowing the labels, how would I divide these groups up? And that's kind of easy to see. Basic idea, in this case, is if I've got labeled groups in that feature space, what I want to do is find a subsurface that naturally divides that space. Now subsurface is a fancy word. It says, in the two-dimensional case, I want
3339	to know what's the best line, if I can find a single line, that separates all the examples with one label from all the examples of the second label. We'll see that, if the examples are well separated, this is easy to do, and it's great. But in some cases, it's going to be more complicated because some of the examples may be very close to one another. And that's going to raise a problem that you saw last lecture. I want to avoid overfitting. I don't want to create a really complicated surface to separate things. And so we may have to tolerate a few incorrectly labeled things, if we can't pull it out. And as you already figured out, in this case, with the labeled data, there's the best fitting line right there. Anybody over 280 pounds is going to be a great lineman. Anybody under 280 pounds is more likely to be a receiver. OK. So I've got two different ways of trying to think about doing this labeling. I'm going to come back to both of
3340	them in a second. Now suppose I add in some new data. I want to label new instances. Now these are actually players of a different position. These are running backs. But I say, all I know about is receivers and linemen. I get these two new data points. I'd like to know, are they more likely to be a receiver or a linemen? And there's the data for these two gentlemen. So if I go back to now plotting them, oh you notice one of the issues. So there are my linemen, the red ones are my receivers, the two black dots are the two running backs. And notice right here. It's going to be really hard to separate those two examples from one another. They are so close to each other. And that's going to be one of the things we have to trade off. But if I think about using what I learned as a classifier
3341	Now you see, oh, I've got an interesting example. This new example I would say is clearly more like a receiver than a lineman. But that one there, unclear. Almost exactly lies along that dividing line between those two clusters. And I would either say, I want to rethink the clustering or I want to say, you know what? As I know, maybe there aren't two clusters here. Maybe there are three. And I want to classify them a little differently. So I'll come back to that. On the other hand, if I had used the labeled data, there was my dividing line. This is really easy. Both of those new examples are clearly below the dividing line. They are clearly examples that I would categorize as being more like receivers than they are like linemen. And I know it's a football example. If you don't like football, pick another example. But you get the sense of why I can use the data in a labeled case and the unlabeled case to come up with different ways of building the
3342	clusters. So what we're going to do over the next 2 and 1/2 lectures is look at how can we write code to learn that way of separating things out? We're going to learn models based on unlabeled data. That's the case where I don't know what the labels are, by simply trying to find ways to cluster things together nearby, and then use the clusters to assign labels to new data. And we're going to learn models by looking at labeled data and seeing how do we best come up with a way of separating with a line or a plane or a collection of lines, examples from one group, from examples of the other group. With the acknowledgment that we want to avoid overfitting, we don't want to create a really complicated system. And as a consequence, we're going to have to make some trade-offs between what we call false positives and false negatives. But the resulting classifier can then label any new data by just deciding where you are with respect to that separating line. So here's
3343	what you're going to see over the next 2 and 1/2 lectures. Every machine learning method has five essential components. We need to decide what's the training data, and how are we going to evaluate the success of that system. We've already seen some examples of that. We need to decide how are we going to represent each instance that we're giving it. I happened to choose height and weight for football players. But I might have been better off to pick average speed or, I don't know, arm length, something else. How do I figure out what are the right features. And associated with that, how do I measure distances between those features? How do I decide what's close and what's not close? Maybe it should be different, in terms of weight versus height, for example. I need to make that decision. And those are the two things we're going to show you examples of today, how to go through that. Starting next week, Professor Guttag is going to show you how you take those and actually start building
3344	more detailed versions of measuring clustering, measuring similarities to find an objective function that you want to minimize to decide what is the best cluster to use. And then what is the best optimization method you want to use to learn that model. So let's start talking about features. I've got a set of examples, labeled or not. I need to decide what is it about those examples that's useful to use when I want to decide what's close to another thing or not. And one of the problems is, if it was really easy, it would be really easy. Features don't always capture what you want. I'm going to belabor that football analogy, but why did I pick height and weight. Because it was easy to find. You know, if you work for the New England Patriots, what is the thing that you really look for when you're asking, what's the right feature? It's probably some other combination of things. So you, as a designer, have to say what are the features I want to use. That quote, by
3345	the way, is from one
3346	I think captures it well. So feature engineering, as you, as a programmer, comes down to deciding both what are the features I want to measure in that vector that I'm going to put together, and how do I decide relative ways to weight it? So John, and Ana, and I could have made our job this term really easy if we had sat down at the beginning of the term and said, you know, we've taught this course many times. We've got data from, I don't know, John, thousands of students, probably over this time. Let's just build a little learning algorithm that takes a set of data and predicts your final grade. You don't have to come to class, don't have to go through all the problems, because we'll just predict your final grade. Wouldn't that be nice? Make our job a little easier, and you may or may not like that idea. But I could think about predicting that grade? Now why am I telling this example. I was trying to see if I could get a
3347	few smiles. I saw a couple of them there. But think about the features. What I measure? Actually, I'll put this on John because it's his idea. What would he measure? Well, GPA is probably not a bad predictor of performance. You do well in other classes, you're likely to do well in this class. I'm going to use this one very carefully. Prior programming experience is at least a predictor, but it is not a perfect predictor. Those of you who haven't programmed before, in this class, you can still do really well in this class. But it's an indication that you've seen other programming languages. On the other hand, I don't believe in astrology. So I don't think the month in which you're born, the astrological sign under which you were born has probably anything to do with how well you'd program. I doubt that eye color has anything to do with how well you'd program. You get the idea. Some features matter, others don't. Now I could just throw all the features in and hope that the
3348	machine learning algorithm sorts out those it wants to keep from those it doesn't. But I remind you of that idea of overfitting. If I do that, there is the danger that it will find some correlation between birth month, eye color, and GPA. And that's going to lead to a conclusion that we really don't like. By the way, in case you're worried, I can assure you that Stu Schmill in the dean of admissions department does not use machine learning to pick you. He actually looks at a whole bunch of things because it's not easy to replace him with a machine-- yet. All right. So what this says is we need to think about how do we pick the features. And mostly, what we're trying to do is to maximize something called the signal to noise ratio. Maximize those features that carry the most information, and remove the ones that don't. So I want to show you an example of how you might think about this. I want to label reptiles. I want to come up with
3349	a way of labeling animals as, are they a reptile or not. And I give you a single example. With a single example, you can't really do much. But from this example, I know that a cobra, it lays eggs, it has scales, it's poisonous, it's cold blooded, it has no legs, and it's a reptile. So I could say my model of a reptile is well, I'm not certain. I don't have enough data yet. But if I give you a second example, and it also happens to be egg-laying, have scales, poisonous, cold blooded, no legs. There is my model, right? Perfectly reasonable model, whether I design it or a machine learning algorithm would do it says, if all of these are true, label it as a reptile. OK? And now I give you a boa constrictor. Ah. It's a reptile. But it doesn't fit the model. And in particular, it's not egg-laying, and it's not poisonous. So I've got to refine the model. Or the algorithm has got to refine the model. And this, I want to
3350	remind you, is looking at the features. So I started out with five features. This doesn't fit. So probably what I should do is reduce it. I'm going to look at scales. I'm going to look at cold blooded. I'm going to look at legs. That captures all three examples. Again, if you think about this in terms of clustering, all three of them would fit with that. OK. Now I give you another example-- chicken. I don't think it's a reptile. In fact, I'm pretty sure it's not a reptile.
3351	Because, while it has scales, which you may or not realize, it's not cold blooded, and it has legs. So it is a negative example that reinforces the model. Sounds good. And now I'll give you an alligator. It's a reptile. And oh fudge, right? It doesn't satisfy the model. Because while it does have scales and it is cold blooded, it has legs. I'm almost done with the example. But you see the point. Again, I've got to think about how do I refine this. And I could by saying, all right. Let's make it a little more complicated-- has scales, cold blooded, 0 or four legs-- I'm going to say it's a reptile. I'll give you the dart frog. Not a reptile, it's an amphibian. And that's nice because it still satisfies this. So it's an example outside of the cluster that says no scales, not cold blooded, but happens to have four legs. It's not a reptile. That's good. And then I give you-- I have to give you a python, right? I mean, there has to
3352	be a python in here. Oh come on. At least grown at me when I say that. There has to be a python here. And I give you that and a salmon. And now I am in trouble. Because look at scales, look at cold blooded, look at legs. I can't separate them. On those features, there's no way to come up with a way that will correctly say that the python is a reptile and the salmon is not. And so there's no easy way to add in that rule. And probably my best thing is to simply go back to just two features, scales and cold blooded. And basically say, if something has scales and it's cold blooded, I'm going to call it a reptile. If it doesn't have both of those, I'm going to say it's not a reptile. It won't be perfect. It's going to incorrectly label the salmon. But I've made a design choice here that's important. And the design choice is that I will have no false negatives. What that means is there's not
3353	going to be any instance of something that's not a reptile that I'm going to call a reptile. I may have some false positives. So I did that the wrong way. A false negative says, everything that's not a reptile I'm going to categorize that direction. I may have some false positives, in that, I may have a few things that I will incorrectly label as a reptile. And in particular, salmon is going to be an instance of that. This trade off of false positives and false negatives is something that we worry about, as we think about it. Because there's no perfect way, in many cases, to separate out the data. And if you think back to my example of the New England Patriots, that running back and that wide receiver were so close together in height and weight, there was no way I'm going to be able to separate them apart. And I just have to be willing to decide how many false positives or false negatives do I want to tolerate. Once I've figured out what
3354	features to use, which is good, then I have to decide about distance. How do I compare two feature vectors? I'm going to say vector because there could be multiple dimensions to it. How do I decide how to compare them? Because I want to use the distances to figure out either how to group things together or how to find a dividing line that separates things apart. So one of the things I have to decide is which features. I also have to decide the distance. And finally, I may want to decide how to weigh relative importance of different dimensions in the feature vector. Some may be more valuable than others in making that decision. And I want to show you an example of that. So let's go back to my animals. I started off with a feature vector that actually had five dimensions to it. It was egg-laying, cold blooded, has scales, I forget what the other one was, and number of legs. So one of the ways I could think about this is saying I've got
3355	four binary features and one integer feature associated with each animal. And one way to learn to separate out reptiles from non reptiles is to measure the distance between pairs of examples and use that distance to decide what's near each other and what's not. And as we've said before, it will either be used to cluster things or to find a classifier surface that separates them.
3356	For each of these examples, I'm going to just let true be 1, false be 0. So the first four are either 0s or 1s. And the last one is the number of legs. And now I could say, all right.
3357	or anything else, but these kinds of feature vectors? Here, we're going to use something called the Minkowski Metric or the Minkowski difference. Given two vectors and a power, p, we basically take the absolute value of the difference between each of the components of the vector, raise it to the p-th power, take the sum, and take the p-th route of that. So let's do the two obvious examples. If p is equal to 1, I just measure the absolute distance between each component, add them up, and that's my distance. It's called the Manhattan metric. The one you've seen more, the one we saw last time, if p is equal to 2, this is Euclidean distance, right? It's the sum of the squares of the differences of the components. Take the square root. Take the square root because it makes it have certain properties of a distance. That's the Euclidean distance. So now if I want to measure difference between these two, here's the question. Is this circle closer to the star or closer to the cross? Unfortunately,
3358	I put the answer up here. But it differs, depending on the metric I use. Right? Euclidean distance, well, that's square root of 2 times 2, so it's about 2.8. And that's three. So in terms of just standard distance in the plane, we would say that these two are closer than those two are. Manhattan distance, why is it called that? Because you can only walk along the avenues and the streets. Manhattan distance would basically say this is one, two, three, four units away. This is one, two, three units away. And under Manhattan distance, this is closer, this pairing is closer than that pairing is. Now you're used to thinking Euclidean. We're going to use that. But this is going to be important when we think about how are we comparing distances between these different pieces. So typically, we'll use Euclidean. We're going to see Manhattan actually has some value. So if I go back to my three examples-- boy, that's a gross slide, isn't it? But there we go-- rattlesnake, boa constrictor, and dart frog. There
3359	is the representation. I can ask, what's the distance between them? In the handout for today, we've given you a little piece of code that would do that. And if I actually run through it, I get,
3360	are the distances between those vectors using Euclidean metric. I'm going to come back to them. But you can see the two snakes, nicely, are reasonably close to each other. Whereas, the dart frog is a fair distance away from that. Nice, right? That's a nice separation that says there's a difference between these two. OK.
3361	Sounds like a Dungeons & Dragons game. I throw in the alligator, and I want to do the same comparison. And I don't get nearly as nice a result. Because now it says, as before, the two snakes are close to each other. But it says that the dart frog and the alligator are much closer, under this measurement, than either of them is to the other. And to remind you, right, the alligator and the two snakes I would like to be close to one another and a distance away from the frog. Because I'm trying to classify reptiles versus not. So what happened here? Well, this is a place where the feature engineering is going to be important. Because in fact, the alligator differs from the frog in three features. And only in two features from, say, the boa constrictor. But one of those features is the number of legs. And there, while on the binary axes, the difference is between a 0 and 1, here it can be between 0 and 4. So that is weighing the
3362	distance a lot more than we would like. The legs dimension is too large, if you like. How would I fix this? This is actually, I would argue, a natural place to use Manhattan distance. Why should I think that the difference in the number of legs or the number of legs difference is more important than whether it has scales or not? Why should I think that measuring that distance Euclidean-wise makes sense? They are really completely different measurements. And in fact, I'm not going to do it, but if I ran Manhattan metric on this, it would get the alligator much closer to the snakes, exactly because it differs only in two features, not three. The other way I could fix it would be to say I'm letting too much weight be associated with the difference in the number of legs.
3363	Either it doesn't have legs or it does have legs. Run the same classification. And now you see the snakes and the alligator are all close to each other. Whereas the dart frog, not as far away as it was before, but there's a pretty natural separation, especially using that number between them. What's my point? Choice of features matters. Throwing too many features in may, in fact, give us some overfitting. And in particular, deciding the weights that I want on those features has a real impact. And you, as a designer or a programmer, have a lot of influence in how you think about using those. So feature engineering really matters. How you pick the features, what you use is going to be important. OK. The last piece of this then is we're going to look at some examples where we give you data, got features associated with them. We're going to, in some cases have them labeled, in other cases not. And we know how now to think about how do we measure distances between them. John.
3364	JOHN GUTTAG: You probably didn't intend to say weights of features. You intended to say how they're scaled. ERIC GRIMSON: Sorry. The scales and not the-- thank you, John. No, I did. I take that back. I did not mean to say weights of features. I meant to say the scale of the dimension is going to be important here. Thank you, for the amplification and correction. You're absolutely right. JOHN GUTTAG: Weights, we use in a different way, as we'll see next time. ERIC GRIMSON: And we're going to see next time why we're going to use weights in different ways. So rephrase it. Block that out of your mind. We're going to talk about scales and the scale on the axes as being important here. And we already said we're going to look at two different kinds of learning, labeled and unlabeled, clustering and classifying. And I want to just finish up by showing you two examples of that. How we would think about them algorithmically, and we'll look at them in more detail next time. As we
3365	look at it, I want to remind you the things that are going to be important to you. How do I measure distance between examples? What's the right way to design that? What is the right set of features to use in that vector? And then, what constraints do I want to put on the model? In the case of unlabelled data, how do I decide how many clusters I want to have? Because I can give you a really easy way to do clustering. If I give you 100 examples, I say build 100 clusters. Every example is its own cluster. Distance is really good. It's really close to itself, but it does a lousy job of labeling things on it. So I have to think about, how do I decide how many clusters, what's the complexity of that separating service? How do I basically avoid the overfitting problem, which I don't want to have? So just to remind you, we've already seen a little version of this, the clustering method. This is a standard way to do it,
3366	simply repeating what we had on an earlier slide. If I want to cluster it into groups, I start by saying how many clusters am I looking for? Pick an example I take as my early representation. For every other example in the training data, put it to the closest cluster. Once I've got those, find the median, repeat the process. And that led to that separation. Now once I've got it, I like to validate it. And in fact, I should have said this better. Those two clusters came without looking at the two black dots. Once I put the black dots in, I'd like to validate, how well does this really work? And that example there is really not very encouraging. It's too close. So that's a natural place to say, OK, what if I did this with three clusters?
3367	I like the that. All right? That has a really nice cluster up here. The fact that the algorithm didn't know the labeling is irrelevant. There's a nice grouping of five. There's a nice grouping of four. And there's a nice grouping of three in between. And in fact, if I looked at the average distance between examples in each of these clusters, it is much tighter than in that example. And so that leads to, then, the question of should I look for four clusters? Question, please. AUDIENCE: Is that overlap between the two clusters not an issue? ERIC GRIMSON: Yes. The question is, is the overlap between the two clusters a problem? No. I just drew it here so I could let you see where those pieces are. But in fact, if you like, the center is there. Those three points are all closer to that center than they are to that center. So the fact that they overlap is a good question. It's just the way I happened to draw them. I should really draw these, not
3368	as circles, but as some little bit more convoluted surface. OK? Having done three, I could say should I look for four? Well, those points down there, as I've already said, are an example where it's going to be hard to separate them out. And I don't want to overfit. Because the only way to separate those out is going to be to come up with a really convoluted cluster, which I don't like. All right? Let me finish with showing you one other example from the other direction. Which is, suppose I give you labeled examples. So again, the goal is I've got features associated with each example. They're going to have multiple dimensions on it. But I also know the label associated with them. And I want to learn what is the best way to come up with a rule that will let me take new examples and assign them to the right group. A number of ways to do this.
3369	will separate those examples. In my football case that were in the plane, what's the best line that separates them, which turns out to be easy. I might look for a more complicated surface. And we're going to see an example in a second where maybe it's a sequence of line segments that separates them out. Because there's not just one line that does the separation. As before, I want to be careful. If I make it too complicated, I may get a really good separator, but I overfit to the data. And you're going to see next time. I'm going to just highlight it here. There's a third way, which will lead to almost the same kind of result called k nearest neighbors. And the idea here is I've got a set of labeled data. And what I'm going to do is, for every new example, say find the k, say the five closest labeled examples. And take a vote. If 3 out of 5 or 4 out of 5 or 5 out of 5 of those labels are
3370	the same, I'm going to say it's part of that group. And if I have less than that, I'm going to leave it as unclassified. And that's a nice way of actually thinking about how to learn them. And let me just finish by showing you an example. Now I won't use football players on this one. I'll use a different example. I'm going to give you some voting data. I think this is actually simulated data. But these are a set of voters in the United States with their preference. They tend to vote Republican. They tend to vote Democrat. And the two categories are their age and how far away they live from Boston. Whether those are relevant or not, I don't know, but they are just two things I'm going to use to classify them. And I'd like to say, how would I fit a curve to separate those two classes? I'm going to keep half the data to test. I'm going to use half the data to train. So if this is my training data, I
3371	can say what's the best line that separates these? I don't know about best, but here are two examples. This solid line has the property that all the Democrats are on one side. Everything on the other side is a Republican, but there are some Republicans on this side of the line. I can't find a line that completely separates these, as I did with the football players. But there is a decent line to separate them. Here's another candidate. That dash line has the property that on the right side you've got-- boy, I don't think this is deliberate, John, right-- but on the right side, you've got almost all Republicans. It seems perfectly appropriate. One Democrat, but there's a pretty good separation there. And on the left side, you've got a mix of things. But most of the Democrats are on the left side of that line. All right? The fact that left and right correlates with distance from Boston is completely irrelevant here. But it has a nice punch to it. JOHN GUTTAG: Relevant, but not accidental.
3372	ERIC GRIMSON: But not accidental. Thank you. All right. So now the question is, how would I evaluate these? How do I decide which one is better? And I'm simply going to show you, very quickly, some examples. First one is to look at what's called the confusion matrix. What does that mean?
3373	the solid line. Here are the predictions, based on the solid line of whether they would be more likely to be Democrat or Republican. And here is the actual label. Same thing for the dashed line. And that diagonal is important because those are the correctly labeled results. Right? It correctly, in the solid line case, gets all of the correct labelings of the Democrats. It gets half of the Republicans right. But it has some where it's actually Republican, but it labels it as a Democrat. That, we'd like to be really large. And in fact, it leads to a natural measure called the accuracy. Which is, just to go back to that, we say that these are true positives. Meaning, I labeled it as being an instance, and it really is. These are true negatives. I label it as not being an instance, and it really isn't. And then these are the false positives. I labeled it as being an instance and it's not, and these are the false negatives. I labeled it as not being an instance,
3374	and it is.
3375	over all of the labels. The true positives and the true negatives, the ones I got right. And in that case, both models come up with a value of 0.7. So which one is better? Well, I should validate that. And I'm going to do that in a second by looking at other data. We could also ask, could we find something with less training error? This is only getting 70% right. Not great. Well, here is a more complicated model. And this is where you start getting worried about overfitting. Now what I've done, is I've come up with a sequence of lines that separate them. So everything above this line, I'm going to say is a Republican. Everything below this line, I'm going to say is a Democrat. So I'm avoiding that one. I'm avoiding that one. I'm still capturing many of the same things. And in this case, I get 12 true positives, 13 true negatives, and only 5 false positives. And that's kind of nice. You can see the 5. It's those five red ones down
3376	there. It's accuracy is 0.833.
3377	It has an accuracy of about 0.6. I could use this idea to try and generalize to say could I come up with a better model. And you're going to see that next time. There could be other ways in which I measure this. And I want to use this as the last example. Another good measure we use is called PPV, Positive Predictive Value which is how many true positives do I come up with out of all the things I labeled positively. And in this solid model, in the dashed line, I can get values about 0.57. The complex model on the training data is better. And then the testing data is even stronger. And finally, two other examples are called sensitivity and specificity. Sensitivity basically tells you what percentage did I correctly find. And specificity said what percentage did I correctly reject. And I show you this because this is where the trade-off comes in. If sensitivity is how many did I correctly label out of those that I both correctly labeled and incorrectly labeled as being
3378	negative, how many them did I correctly label as being the kind that I want? I can make sensitivity 1. Label everything is the thing I'm looking for. Great. Everything is correct. But the specificity will be 0. Because I'll have a bunch of things incorrectly labeled. I could make the specificity 1, reject everything. Say nothing as an instance. True negatives goes to 1, and I'm in a great place there, but my sensitivity goes to 0. I've got a trade-off. As I think about the machine learning algorithm I'm using and my choice of that classifier, I'm going to see a trade off where I can increase specificity at the cost of sensitivity or vice versa. And you'll see a nice technique called ROC or Receiver Operator Curve that gives you a sense of how you want to deal with that. And with that, we'll see you next time. We'll take your question off line if you don't mind, because I've run over time. But we'll see you next time where Professor Guttag will show you examples of
3379	this.
3380	[SQUEAKING] [RUSTLING] [CLICKING] JASON KU: Good morning, everybody. STUDENT: Morning-- JASON KU: My name's Jason Ku. I'm going to be teaching this class in Introduction to Algorithms with two other instructors here-- faculty in the department-- Eric Demaine and Justin Solomon. They're excellent people, and so they will be working on teaching this class with me. I will be teaching the first lecture, and we'll have each of them teach one of the next two lectures, and then we'll go from there. This is Intro to Algorithms.
3381	content now. What is this course about? It's about algorithms-- introduction to algorithms. Really what the course is about is teaching you to solve computational problems. But it's more than that. It's not just about teaching you to solve computational problems. Goal 1-- solve computational problems. But it's more than that. It's also about communicating those solutions to others and being able to communicate that your way of solving the problem is correct and efficient. So it's about two more things-- prove correctness, argue efficiency, and in general, it's about communication-- I can't spell, by the way-- communication of these ideas. And you'll find that, over the course of this class, you'll be doing a lot more writing than you do in a lot of your other courses. It really should maybe be a CI kind of class, because you'll be doing a lot more writing than you will be coding, for sure. Of course, solving the computational problem is important, but really, the thing that you're getting out of this class and other theory classes that you're not getting
3382	in other classes in this department is that we really concentrate on being able to prove that the things you're doing are correct and better than other things, and being able to communicate those ideas to others, and not just to a computer-- to other people, convince them that it's correct. OK, so that's what this class is about. So what do I mean when I say solve a computational problem? What is a problem? What is an algorithm? People make fun of me because I start with this question, but anyone want to answer that question? No? What's a problem, computationally? No? OK, so it's not such a stupid question. Yeah?
3383	JASON KU: Something you want to compute-- OK, yes, that's true. Right. But a little bit more abstractly, what I'm going to think of a computational problem being-- and this is where your prerequisite in discrete mathematics should come in-- a problem is-- you've got a set of inputs. Maybe I have one, two, three, four, five possible inputs I could have to my algorithm. Then I have a space of outputs. I don't know. Maybe I have more of them than I do inputs, but these are the possible outputs to my problem. And what a problem is is a binary relation between these inputs and outputs. Essentially, for each input, I specify which of these outputs is correct. It doesn't necessarily have to be one. If I say, give me the index in an array containing the value 5, there could be multiple 5's in that array, and so any of those indices would be correct. So maybe this guy maps to that output, and maybe this guy maps to-- I don't know-- two or three outputs. This
3384	input goes to one, two-- I don't know. There's some kind of mapping here. These edges represent a binary relation, and it's kind of a graph, a bipartite graph between these inputs and outputs. And these are specifying which of these outputs are correct for these inputs. That's really the formal definition of what a problem is. Now, generally, if I have a problem-- a computational problem, I'm not going to specify the problem to you by saying, OK, for input 1, the correct answer is 0, and for input 2, the correct answer's 3, and so on and so forth. That would take forever, right? Usually what we do when defining a problem is specify some kind of predicate, saying that, oh, we can check-- if I give you an input and an output, I can check whether that output is correct or not. That's usually how we define a problem is, if I am checking for whether this index contains a 5, I can just go to that array, look at index 5, and-- or the index you
3385	gave me, and see if it equals 5. So usually, we're putting it in terms of predicates because, in general, we don't really want to talk about small instances of problems. So let's say I had the problem of, among the students in this classroom, do any pair of you have the same birthday? All right, well, probably, if there's more than 365 of you, the answer is yes. Right? By what? Pigeonhole principle-- two of you must have the same birthday. So let's generalize it a little bit, say that-- I don't know-- I need a bigger space of birthdays for this question to be interesting. Maybe I tack on the year. Maybe I tack on the hour that you were born. And that's a bigger space of inputs, and I wouldn't necessarily expect that two of you would be born in the same year on the same day in the same hour. That would be a little less likely. In fact, as long as that space is larger than something like the square of the number of you,
3386	then I'm less likely than even to have a pair of you. That's a birthday problem you may have seen in 042, potentially. But in general, I don't-- I'm not going to mess with probability so much here. I want a deterministic algorithm, right away of checking whether two of you have the same birth time, let's say. OK, so in general, in this class, we're not going to concentrate on inputs such as, is there a pair of you in this class that have the same birthday? That's kind of boring. I could do a lot of different things, but what we do in this class-- this is for a fixed classroom of you. I want to make algorithms that are general to any classroom-- to go to your recitation. I want an algorithm that will apply to your recitation. I want an algorithm that not only applies to this classroom, but also the machine learning class before you. I want an algorithm that can change its-- it can accept an arbitrarily sized input. Here we have a class
3387	of maybe 300, 400 students, but I want my algorithm to work for a billion students. Maybe I'm trying to check if there's a match of something in the Facebook database
3388	So in general, we are looking for general problems that have arbitrarily sized inputs. So these inputs could grow very large, but we want kind of a fixed size algorithm to solve those problems. So what is an algorithm, then? I really can't spell-- told you. I didn't lie to you. So an algorithm is a little different than a problem. A problem specification-- I can tell you what this graph looks like. An algorithm is really-- I don't know what the outputs are. I don't know what these edges are. But I want a fixed size machine or procedure that, if I give it an input, it will generate an output. And if it generates an output, it better be one of these correct outputs. So if I have an algorithm that takes in this input, I really want it to output this output, or else it's not a correct algorithm. Similarly, for this one, it could output any of these three outputs, but if it outputs this guy for this input, that would not be a correct algorithm.
3389	And so generally, what we want is an algorithm is a function. It takes inputs to outputs. An algorithm is some kind of function that takes these inputs, maps it to a single output, and that output better be correct based on our problem. So that's what our algorithm is. It solves the problem if it returns a correct output for every problem input that is in our domain. Does anyone have a possible algorithm for checking whether any two of you have the same birth time, as specified before? I'm going to let someone else have a try. Sure. STUDENT: Just ask everyone one by one, and every time [INAUDIBLE] JASON KU: Great-- so what your colleague has said is a great algorithm. Essentially, what it's going to do is I'm going to put you guys in some order, I'm going to give you each of you a number, one through however many number of students there are in this class. And I'm going to interview you one by one. I'm going to say, what's your birthday? And I'm
3390	going to write it down. I'm going to put it in some kind of record. And then, as I keep interviewing you, I'm going to find out your birthday. I'm going to check the record. I'm going to look through all the birthdays in the record. If I find a match, then I return, yay-- I found a pair-- and I can stop. Otherwise, if I get through the record list, I don't-- and I don't find a match, I just stick you at the end of the record-- I add you to the record, and then I move on to the next person. I keep doing this. OK, so that's a proposed algorithm for this birthday problem. For birthday problem, what's the algorithm here? Maintain a record. Interview students in some order. And what does interviewing a student mean? It means two things. It means check if birthday in record. And if it is, return a pair. So return pair. Otherwise, add a new student to record. And then, at the very end, if I go through everybody and
3391	I haven't found a match yet, I'm going to return that there is none. OK, so that's a statement of an algorithm. That's kind of the level of description that we'll be looking for you in the three parts of this-- theory questions that we ask you on your problem sets. It's a verbal description in words that-- it's maybe not enough for a computer to know what to do, but if you said this algorithm to any of your friends in this class, right they would at least understand what it is that you're doing. Yeah? STUDENT: Does an algorithm have to be a pure function in a mathematical sense? JASON KU: Does an algorithm have to be a pure function in a mathematical sense? As in it needs to map to a single output? STUDENT: As in it can't modify some external state.
3392	JASON KU: So we're talking about kind of a functional programming definition of a function. I am talking about the mathematical-- I have a binary relation, and this thing has an output for every input, and there is exactly one output to every input. That's the mathematical definition of function that I'm using for when I'm defining an algorithm. Yeah? STUDENT: Basically, is an algorithm like a plan? JASON KU: Yeah. An algorithm's a procedure that somehow-- I can do whatever I want, but I have to take one of these inputs and I have to produce an output. And at the end, it better be correct. So it's just a procedure. You can think of it as like a recipe. It's just some kind of procedure. It's a sequence of things that you should do, and then, at the end, you will return an output. S here's a possible algorithm for solving this birthday problem. Now, I've given you-- what I argue to you, or I'm asserting to you, is a solution to this birthday problem. And maybe you
3393	guys agree with me, and maybe some of you don't. So how do I convince you that this is correct? If I was just running this algorithm on, say, the four students in the front row here, I could argue it pretty well to you. I could assign these for people birthdays in various combinations of either their-- none of them have the same birthday, some two of them have the same birthday. I could try all possibilities, and I could go through lots of different possibilities and I need to check that this algorithm returns the right answer in all such cases. But when I have-- I don't know-- 300 of you, that's going to be a little bit more difficult to argue. And so if I want to argue something is correct in-- I want to prove something to you for some large value, what kind of technique do I use to prove such things? Yeah? Induction, right? And in general, what we do in this class, what we do is-- as a computer scientist is we write
3394	a constant sized piece of code that can take on any arbitrarily large size input. If the input can be arbitrarily large, but our code is small, then that code needs to loop, or recurse, or repeat some of these lines of code in order to just read that output. And so that's another way you can arrive at this conclusion, that we're going to probably need to use recursion, induction. And that's part of the reason why we ask you to take a course on proofs, and inductive reasoning, and discrete mathematics
3395	OK, so how do we prove that this thing is correct? We got to use induction. So how can we set up this induction? What do I need for an inductive proof? Sure. STUDENT: [INAUDIBLE] JASON KU: Base case-- we need a base case. We need some kind of a predicate. Yeah, but we need some kind of statement of a hypothesis of something that should be maintained. And then we need to have an inductive step, which basically says I take a small value of this thing, I use the inductive hypothesis, and I argue it for a larger value of my well-ordered set that I'm inducting over. For this algorithm, if we're going to try to prove correctness, what I'm going to do is I'm going to-- what do I want to prove for this thing? That, at the end of interviewing all of you, that my algorithm has either already-- it has returned with a pair that match, or if we're in a case where there wasn't a pair somewhere in my set, that it returned none.
3396	Right? That would be correct. So how can I generalize that concept to make it something I can induct on? What I'm going to do is I'm going to say-- let's say, after I've interviewed the first K students, if there was a match in those first K students, I want to be sure that I've returned a pair-- because if, after I interview all of you, I've maintained that property, then I'll be sure, at the end of the process, I will have returned a pair, if one exists. So here's going to be my inductive hypothesis. If first K students contain a match, algorithm returns a match before interviewing, say, student K plus 1. So that's going to be my inductive hypothesis. Now, if there's n students in this class, and at the end of my thing, I'm trying to interview a student n plus 1-- oh, student n plus 1's not there. If I have maintained this, then, if I replace K with n, then I will have returned a match before interviewing the last student-- when
3397	I have no more students left. And then this algorithm returns none, as it should. OK, so this inductive hypothesis sets up a nice variable to induct on. This K I can have increasing, up to n, starting at some base case. So what's my base case here? My base case is-- the easiest thing I can do-- sure-- 2? That's an easy thing I could do. I could check those possibilities, but there's an even easier base case. Yeah? There's an even easier base case than 1. STUDENT: 0-- JASON KU: 0, right? After interviewing 0 students, I haven't done any work, right? Certainly, the first 0 can't have a match. This inductive hypothesis this is true just because this initial predicate is false. So I can say, base case 0-- check. Definitely, this predicate holds for that. OK. Now we got to go for the meat of this thing. Assume the inductive hypothesis true for K equals, say, some K prime. And we're considering K prime plus 1. Then we have two cases. One of the nice things
3398	about abduction is that it isolates our problem to not consider everything all at once, but break it down into a smaller interface so I can do less work at each step. So there are two cases. Either the first K already had a match-- in which case, by our inductive hypothesis, we've already returned a correct answer. The other case is the-- it doesn't have a match, and we interview the K plus 1th student-- the K prime plus 1th student. If there is a match in the first K prime plus 1 students, then it will include K plus-- the student K prime plus 1, because otherwise, there would have been a match in the things before it. So there are two cases. If K contains match, K prime. If first K contains match-- already returned by induction. Else, if K prime plus 1 student's contains match, the algorithm checks all of the possibilities-- K prime checks against all students, essentially by brute force. It's a case analysis. I check all of the possibilities. Check if birthday is
3399	in record-- I haven't told you how to do that yet, but if I'm able to do that, I'm going to check if it's in the record. If it's in the record, then there will be a match, and I can return it. Otherwise, I have-- re-establish the inductive hypothesis for the K prime plus 1 students. Does that makes sense, guys? Yeah. OK, so that's how we prove correctness. This is a little bit more formal than we would ask you to do in this class all the time, but it's definitely sufficient for the levels of arguments that we will ask you to do. The bar that we're usually trying to set is, if you communicated to someone else taking this class what your algorithm was, they would be able to code it up and tell a stupid computer how to do that thing. Any questions on induction?
3400	and so if you are unfamiliar with this line of argument, then you should go review some of that. That would be good. OK, so that's correctness, being able to communicate that the problem-- the algorithm we stated was correct. Now we want to argue that it's efficient. What does efficiency mean? Efficiency just means not only how fast does this algorithm run, but how fast does it compare to other possible ways of approaching this problem? So how could we measure how fast an algorithm runs? This is kind of a silly question. Yeah? STUDENT: [INAUDIBLE] JASON KU: Yeah. Well, just record the time it takes for a computer to do this thing. Now, there's a problem with just coding up an algorithm, telling a computer what to do, and timing how long it takes. Why? Yeah? STUDENT: [INAUDIBLE] JASON KU: It would depend on the size of your data set. OK, we expect that, but there's a bigger problem there. Yeah? STUDENT: [INAUDIBLE] JASON KU: It depends on the strength of your computer. So I would expect that,
3401	if I had a watch calculator and I programmed it to do something, that might take a lot longer to solve a problem than if I asked IBM's research computer to solve the same problem using the same algorithm, even with the same code, because its underlying operations are much faster. How it runs is much faster. So I don't want to count how long it would take on a real machine. I want to abstract the time it takes the machine to do stuff out of the picture. What I want to say is, let's assume that each kind of fundamental operation that the computer can do takes some fixed amount of time. How many of those kinds of fixed operations does the algorithm need to perform to be able to solve this problem? So here we don't measure time. Instead, count fundamental operations. OK? We'll get to what some of those fundamental operations are in a second, but the idea is we want a measure of how well an algorithm performs, not necessarily an implementation of that algorithm--
3402	kind of an abstract notion of how well this algorithm does. And so what we're going to use to measure time or efficiency is something called asymptotic analysis. Anyone here understand what asymptotic analysis is? Probably, since it's in both of your prerequisites, I think-- but we will go through a formal definition of asymptotic notation in recitation tomorrow, and you'll get a lot of practice in comparing functions using an asymptotic analysis. But just to give you an idea, the idea here is we don't measure time. We instead measure ops. And like your colleague over here was saying before, we expect performance-- I'm going to use performance, instead of time here-- we expect that to depend on size of our input. If we're trying to run an algorithm to find a birthday in this section, we expect the algorithm to run in a shorter amount of time than if I were to run the algorithm on all of you. So we expect it to perform differently, depending on the size of the input, and how differently is how
3403	we measure performance relative to that input. Usually we use n as a variable for what the size of our input is, but that's not always the case. So for example, if we have an array that I give you-- an n-by-n array, that-- we're going to say n, but what's the size of our input? How much information do I need to convey to you to give you that information? It's n squared. So that's the size of our input in that context. Or if I give you a graph, it's usually the number of vertices plus the number of edges. That's how big-- how much space I would need to convey to you that graph, that information. We compare how fast an algorithm is with respect to the size of the input. We'll use the asymptotic notation. We have big O notation, which corresponds to upper bounds. We will have omega, which corresponds to lower bounds. And we have theta, which corresponds to both. This thing is tight. It is bounded from above and below by a function
3404	of this form. We have a couple of common functions that relate an algorithm's input size to its performance, some things that we saw all the time. Can anyone give me some of those? STUDENT: [INAUDIBLE] JASON KU: Say again. STUDENT: [INAUDIBLE] JASON KU: Sorry. Sorry. I'm not asking this question well, but has anyone heard of a linear algorithm-- a linear time algorithm? That's basically saying that the running time of my algorithm-- performance of my algorithm is linear with respect to the size of my input. Right? Yeah? STUDENT: [INAUDIBLE] JASON KU: Say again. STUDENT: Like putting something in a list-- JASON KU: Like putting something in a list-- OK. There's a lot behind that question that we'll go into later this week. But that's an example of, if I do it in a silly way, I stick something in the middle of a list and I have to move everything. That's an operation that could take linear time. So linear time is a type of function. We've got a number of these. I'm going to start with
3405	this one. Does anyone know this one is? Constant time-- basically, no matter how I change the input, the amount of time this running time-- the performance of my algorithm takes, it doesn't really depend on that. The next one up is something like this. This is logarithmic time. We have data n, which is linear, and log n. Sometimes we call this log linear, but we usually just say n log n. We have a quadratic running time. In general, if I have a constant power up here, it's n to the c for some constant. This is what we call polynomial time, as long as c is some constant. And this right here is what we mean by efficient, in this class, usually. In other classes, when you have big data sets, maybe this is efficient. But in this class, generally what we mean is polynomial. And as you get down this thing, things are more and more efficient. There's one class I'm going to talk to you about over here, which is something like-- let's do this--
3406	2 to the theta of n, exponential time. This is some constant to a function of n that's, let's say, super linear, that's going to be pretty bad. Why is it pretty bad? If I were to plot some of these things as a function of n-- let's say I plot values of up to 1,000 on my n scale here. What does constant look like? Maybe this is 1,000 up here. What does a constant look like? Looks like a line-- it looks like a line over here somewhere. It could be as high as I want, but eventually, anything that's an increasing function will get bigger than this. And on this scale, if I use log base 2 or some reasonable small constant, what does log look like? Well, let's do an easier one. What does linear look like? Yeah, this-- that's what I saw what a lot of you doing. That's linear. That's the kind of base that we're comparing everything against. What does log look like? Like this-- OK, but at this scale, really, it's much
3407	closer to constant than linear. And actually, as n gets much, much larger this almost looks like a straight line. It almost looks like a constant. So log is almost just as good as constant. What does exponential look like? It's the exact inverse of this thing. It's almost an exact straight line going up. So this is crap. This is really good. Almost anything in this region over here is better right. At least I'm gaining something. I'm able to not go up too high relative to my input size. So quadratic-- I don't know-- is something like this, and n log n is something like this. n log n, after a long time, really starts just looking linear with a constant multiplied in front of it. OK, so these things good, that thing bad-- OK? That's what that's trying to convey. All right, so how do we measure these things if I don't know what my fundamental operations are that my computer can use? So we need to define some kind of model of computation for what our
3408	computer is allowed to do in constant time, in a fixed amount of time. In general, what we use in this class is a machine called a word RAM, which we use for its theoretical brevity. Word RAM is kind of a loaded term. What do these things mean? Does someone know what RAM means? STUDENT: [INAUDIBLE] JASON KU: Random access memory-- it means that I can randomly access different places in memory in constant time. That's the assumption of random access memory. Basically, what our model of a computer is you have memory, which is essentially just a string of bits. It's just a bunch of 1's and 0's. And we have a computer, like a CPU, which is really small. It can basically hold a small amount of information, but it can change that information. It can operate on that information, and it also has instructions to randomly access different places in memory, bring it into the CPU, act on it, and read it back. Does that makes sense? But in general, we don't have an address for
3409	every bit in memory, every 0 and 1 in memory. Does anyone know how modern computers are addressed? Yeah? STUDENT: [INAUDIBLE]
3410	Actually, what a modern computer is addressed in is bytes, collections of 8 bits. So there's an address I have for every 8 bits in memory-- consecutive 8 bits in memory. And so if I want to pull something in into the CPU, I give it an address. It'll take some chunk, and bring it into the CPU, operate on it, and spit it back. How big is that chunk? This goes to the answer that you were asking, which-- or saying, which is it's some sequence of some fixed number of bits, which we call a word. A word is how big of a chunk that the CPU can take in from memory at a time and operate on. In your computers, how big is that word size? 64 bits-- that's how much I can operate on at a time. When I was growing up, when I was your age, my word size was 32 bits. And that actually was a problem for my computer, because in order for me to be able to read to address in memory,
3411	I need to be able to store that address in my CPU, in a word. But if I have 32 bits, how many different addresses can I address? I have a limitation on the memory addresses I can address, right? So how many different memory addresses can I address with 32 bits? 2 to the 32, right? That makes sense. Well, if you do that calculation out, how big of a hard disk can I have to access? It's about 4 gigabytes. So in my day, all the hard drives were limited to being partitioned-- even if you had a bigger than 4 gigabyte hard drive, I had to partition it into these 4 gigabyte chunks, which
3412	That was very limiting, actually. That's a restriction. With 64 bits, what's my limitation on memory that I can address-- byte addressable? Turns out to be something like 20 exabytes-- to put this in context, all data that Google stores on their servers, on all drives throughout the world-- it's about 10.
3413	So what do we got we've got a CPU. It can address memory. What are the operations I can do in this CPU? Generally, I have binary operations. I can compare to words in memory, and I can either do integer arithmetic, logical operations, bitwise operations-- but we're not going to use those so much in this class. And I can write and write from an address in memory, a word in constant time. Those are the operations that I have available to me on most CPUs.
3414	but this is generally what we analyze algorithms with respect to. OK? But you'll notice that my CPU is only built to operate on a constant amount of information at once-- generally, two words in memory. An operation produces a third one, and I spit it out. It takes a constant amount of time to operate on a constant amount of memory. If I want to operate on a linear amount of memory-- n things-- how long is that going to take? If I just want to read everything in that thing, it's going to take me linear time, because I have to read every part of that thing. OK, so in general, what we're going to do for the first half of this class mostly-- first eight lectures, anyway-- is talk about data structures. And it's going to be concerned about not operating on constant amount of data at a time, like our CPU is doing, but instead, what it's going to do is operate on-- store a large amount of data and support different operations on that data.
3415	So if I had a record that I want to maintain to store those birthdays that we had before, I might use something like a static array, which you guys maybe are not familiar with, if you have been working in Python is your only programming language. Python has a lot of really interesting data structures, like a list, and a set, and a dictionary, and all these kinds of things that are actually not in this model. There's actually a lot of code between you and the computer, and it's not always clear how much time that interface is taking. And so what we're going to do starting on Thursday is talk about ways of storing a non-constant amount of information to make operations on that information faster. So just before you go, I just want to give you a quick overview of the class. To solve an algorithms class-- an algorithm problem in this class, we essentially have two different strategies. We can either reduced to using the solution to a problem we know how to solve, or
3416	we can design our own algorithm, which is going to be recursive in nature. We're going to either put stuff in the data structure and solve a sorting problem, or search in a graph. And then, to design a recursive algorithm, we have various design paradigms. This is all in your notes, but this is essentially the structure of the class. We're going to spend quiz 1, the first eight lectures on data structures and sorting. Second quiz will be on shortest paths, algorithms, and graphs, and then the last one will be on dynamic programming. OK, that's the end of the first lecture. Thanks for coming.
3417	[SQUEAKING] [RUSTLING] [CLICKING] ERIK DEMAINE: Good morning. AUDIENCE: Morning! ERIK DEMAINE: Welcome to 006, Introduction to Algorithms, lecture two. I am Erik Demaine and I love algorithms. Are you with me? [APPLAUSE] Yeah. Today, we're not doing algorithms. No, we're doing data structures. It's OK. There's lots of algorithms in each data structure. It's like multiple algorithms for free. We're going to talk about sequences,
3418	Fairly simple data structures today. This is the beginning of several data structures we'll be talking about in the next few lectures. But before we actually start with one, let me tell you/remind remind you of the difference between an interface-- which you might call an API if you're a programmer, or an ADT if you're an ancient algorithms person like me-- versus a data structure. These are useful distinctions. The idea is that an interface says what you want to do. A data structure says how you do it. So you might call this a specification. And in the context of data structures, we're trying to store some data. So the interface will specify what data you can store, whereas the data structure will give you an actual representation and tell you how to store it. This is pretty boring. Just storing data is really easy. You just throw it in a file or something. What makes it interesting is having operations on that data. In the interface, you specify what the operations do, what operations are supported, and
3419	in some sense, what they mean. And the data structure actually gives you algorithms-- this is where the algorithms come in-- for how to support those operations. All right. In this class, we're going to focus on two main interfaces and various special of them. The idea is to separate what you want to do versus how to do it. Because-- you can think of this as the problem statement. Yesterday-- or, last class, Jason talked about problems and defined what a problem was versus algorithmic solutions to the problem. And this is the analogous notion for data structures, where we want to maintain some data according to various operations. The same problem can be solved by many different data structures. And we're going to see that. And different data structures are going to have different advantages. They might support some operations faster than others. And depending on what you actually use those data structures for, you choose the right data structure. But you can maintain the same interface. We're going to think about two data structures. One is called
3420	a set and one is called a sequence. These are highly loaded terms. Set means something to a mathematician. It means something else to a Python programmer. Sequence, similarly. I guess there's not a Python sequence data type built in. The idea is, we want to store n things. The things will be fairly arbitrary. Think of them as integers or strings. And on the one hand, we care about their values. And maybe we want to maintain them in sorted order and be able to search for a given value, which we'll call a key. And on the other hand, we care about representing a particular sequence that we care about. Maybe we want to represent the numbers 5, 2, 9, 7 in that order and store that. In Python, you could store that in a list, for example. And it will keep track of that order. And this is the first item, the second item, the last item. Today, we're going to be focusing on this sequence data structure, although at the end, I'll mention the interface for
3421	sets. But we're going to be actually solving sequences today. And in the next several lectures, we'll be bouncing back and forth between these. They're closely related. Pretty abstract at the moment. On the other hand, we're going to have two main-- let's call them data structure tools or approaches. One is arrays and the other is pointers-- pointer-based or linked data structures. You may have seen these. They're used a lot in programming, of course. But we're going to see both of these today. I'll come back to this sort of highlight in a moment. Let's jump into the sequence interface, which I conveniently have part of here. There's a few different levels of sequences that we might care about. I'm going to start with the static sequence interface. This is where the number of items doesn't change, though the actual items might. Here, we have n items. I'm going to label them x 0 to x n minus 1, as in Python. So the number of items is n. And the operations I want to support are build,
3422	length, iteration, get, and set. So what do these do? Build is how you get started. To build a data structure in this interface, you call build of x. Exactly how you specify x isn't too important, but the idea is, I give you some items in some order. In Python, this would be an iterable. I'm going to want to also know its length. And I want to make a new data structure of size and a new static sequence of size n that has those items in that order. So that's how you build one of these. Because somehow, we have to specify n to this data structure, because n is not going to be allowed to change. I'm going to give you a length method. Methods are the object-oriented way of thinking of operations that your interface supports. Length will just return this fixed value n. Iter sequence. This is the sense in which we want to maintain the order. I want to be able to output x 0 through x n minus 1 in the sequence
3423	"order, in that specified order that they were built in or that it was changed to. This is going to iterate through all of the items. So it's going to take at least linear time to output that. But more interesting is, we can dynamically access anywhere in the middle of the sequence. We can get the ith item, x i, given the value i, and we can change x i to a given new item. OK. So that's called get_at and set_at. Pretty straightforward. This should remind you very closely of something-- a data structure. So this is an interface. This is something I might want to solve. But what is the obvious data structure that solves this problem? Yeah? AUDIENCE: A list. ERIK DEMAINE: A list. In Python, it's called a list. I prefer to call it an array, but to each their own. We're going to use ""list."""
3424	to this interface problem-- the natural solution-- is what I'll call a static array. Jason mentioned these in lecture one. It's a little tricky because there are no static arrays in Python. There are only dynamic arrays, which is something we will get to. But I want to talk about, what is a static array, really? And this relates to our notion of-- our model of computation, Jason also talked about, which we call the word RAM, remember? The idea, in word RAM, is that your memory is an array of w-bit words. This is a bit circular. I'm going to define an array in terms of the word RAM, which is defined in terms of arrays. But I think you know the idea. So we have a big memory which goes off to infinity, maybe. It's divided into words. Each word here is w bits long. This is word 0, word 1, word 2. And you can access this array randomly-- random access memory. So I can give you the number 5 and get 0 1, 2, 3, 4,
3425	5, the fifth word in this RAM. That's how actual memories work. You can access any of them equally quickly. OK, so that's memory. And so what we want to do is, when we say an array, we want this to be a consecutive chunk of memory. Let me get color. Let's say I have an array of size 4 and it lives here. Jason can't spell, but I can't count. So I think that's four. We've got-- so the array starts here and it ends over here. It's of size 4. And it's consecutive, which means, if I want to access the array at position-- at index i, then this is the same thing as accessing my memory array at position-- wherever the array starts, which I'll call the address of the array-- in Python, this is ID of array-- plus i. OK. This is just simple offset arithmetic. If I want to know the 0th item of the array, it's right here, where it starts. The first item is one after that. The second item is one after
3426	that. So as long as I store my array consecutively in memory, I can access the array in constant time. I can do get_at and set_at as quickly as I can randomly access the memory and get value-- or set a value-- which we're assuming is constant time. My array access is constant time. This is what allows a static array to actually solve this problem in constant time per get_at and set_at operation. This may seem simple, but we're really going to need this model and really rely on this model increasingly as we get to more interesting data structures. This is the first time we're actually needing it. Let's see. Length is also constant time. We're just going to store that number n, along with its address. And build is going to take linear time. Iteration will take linear time. Pretty straightforward. I guess one thing here, when defining build, I need to introduce a little bit more of our model of computation, which is, how do you create an array in the beginning? I claim I could
3427	do it in linear time, but that's just part of the model. This is called the memory allocation model. There are a few possible choices here, but the cleanest one is just to assume that you can allocate an array of size n in theta n time. So it takes linear time to make an array of size n. You could imagine this being constant. It doesn't really matter much. But it does take work. And in particular, if you just allocate some chunk of memory, you have no idea whether it's initialized. So initializing that array to 0s will cost linear time. It won't really matter, constant versus linear, but a nice side effect of this model is that space-- if you're just allocating arrays, the amount of space you use is, at most, the amount of time you use. Or, I guess, big O of that. So that's a nice feature. It's pretty weird if you imagine-- it's unrealistic to imagine you can allocate an array that's infinite size and then just use a few items out of
3428	it. That won't give you a good data structure. So we'll assume it costs to allocate memory. OK, great. We solved the sequence problem. Very simple, kind of boring. These are optimal running times. Now, let's make it interesting-- make sure I didn't miss anything--
3429	to talk about in the word RAM. A side effect of this assumption that array access should take constant time, and that accessing these positions in my memory should take constant time, is that we need to assume w is at least log n or so. w, remember, is the machine word size. In real computers, this is currently 64-- or 256, in some bizarre instructions. But we don't usually think of the machine as getting bigger over time, but you should think of the machine as getting bigger over time. This is a statement that says, the word size has to grow with n. It might faster than log n, but it has to grow at least as fast as log n. Why do I say that? Because if I have n things that I'm dealing with-- n, here, is the problem size. Maybe it's the array I'm trying to store-- whatever. If I'm having to deal with n things in my memory, at the very least, I need to be able to address them. I should be able
3430	to say, give me the ith one and represent that number i in a word. Otherwise-- because the machine is designed to only work with w-bit words in constant time, they'll want to be able to access the ith word in constant time, I need a word size that's at least log n just to address that and n things in my input. So this is a totally reasonable assumption. It may seem weird because you think of a real machine as having constant size, but a real machine has constant size RAM, also. My machine has 24 gigs of RAM, or whatever. That laptop has 8. But you don't think of that as changing over time. But of course, if you want it to process a larger input, you would buy more RAM. So eventually, when our n's get really, really big, we're going to have to increase w just so we can address that RAM. That's the intuition here. But this is a way to bridge reality, which are fixed machines, with theory. In. Algorithms, we care about
3431	scalability for very large n. We want to know what that growth function is and ignore the lead constant factor. That's what asymptotic notation is all about. And for that, we need a notion of word size also changing in this asymptotic way. All right. That would be more important next week, when we talk about hashing and why hashing is a reasonable thing to do. But let's move on to dynamic sequences, which is where things get interesting. I have the update here. We start with static sequences. All of these operations are still something we want to support in a dynamic sequence, but we add two dynamic operations-- somewhat controversial operations, very exciting. I want to be able to insert in the middle of my sequence and I want to be able to delete from the middle of my sequence. Here's my sequence, which I'm going to think of in a picture. I'm going to draw it as an array. But it's stored however it's stored. We don't know. This is an interface, not an implementation. So we
3432	have x 0, x 1, x 2, x 3. And let's say I insert at position 2. Position 2 is here. So I come in with my new x, and I would like x to be the new x 2, but I don't want to lose any information. If I did set_at 2, then I would erase this and replace it with x. But I want to do insert_at, which means all of these guys, conceptually, are going to shift over by 1 in terms of their indices. Then, I would get this picture that's one bigger. And now I've got the new x. I've got what was the old x 2, which I don't-- I hesitate to call x 2 because that's its old name, not its new name. I'm going to draw arrows to say, these guys get copied over. These ones are definitely unchanged. Our new x 2, which prime is x This is x3 prime, 4 prime, and so on. I want to be careful here-- and of course, the new n prime is n plus
3433	1. I want to be careful about the labeling, because the key-- what makes insert_at interesting is that, later, when I call get_at, it's with the new indexing. So previously, if I did get_at at 2, I would get this value. And afterwards, if I did get_at at 2, I would get the new value. If I did get_at at 3 down here, I would get the value that used to be X 2. That's maybe hard to track. But this is a conceptually very useful thing to do, especially when you're inserting or deleting at the ends. So we're going to define, in particular, insert and delete first and last. These are sometimes given-- if you have an insert, it has an x. If you do a delete, it has no argument. This means insert_at the beginning of the array, which would be like adding it here. And insert_last means adding it on here. insert_last doesn't change the indices of any of the old items. That's a nice feature of insert_last. Insert-first changes all of them. They all get
3434	incremented by 1. And we're also interested in the similar things here. We could do get-first or -last or set-first or -last, which are the obvious special cases of get_at and set_at. Now, these special cases are particularly interesting in an algorithms context. If you were a mathematician, you would say, well, why do I even bother? This is just shorthand for a particular call to get or set. But what makes it interesting from a data structures perspective is that we care about algorithms for supporting these operations. And maybe, the algorithm for supporting get-first or set-first, or in particular, insert-first or insert_last, might be more efficient. Maybe we can solve this problem better than we can solve insert_at. So while, ideally, we could solve the entire dynamic sequence interface constant time preparation, that's not actually possible. You can prove that. But special cases of it-- where we're just inserting and leading from the end, say-- we can do that. That's why it's interesting to introduce special cases that we care about. Cool. That's the definition of the dynamic
3435	sequence interface. Now, we're going to actually solve it.
3436	You've taken, probably-- you've probably seen linked lists before at some point. But the main new part here is, we're going to actually analyze them and see how efficiently they implement all of these operations we might care about. First, review. What is a linked list? We store our items in a bunch of nodes. Each node has an item in it and a next field. So you can think of these as class objects with two class variables, the item and the next pointer. And we assemble those into this kind of structure where we store-- in the item fields, we're going to store the actual values that we want to represent in our sequence, x 0 through x n minus 1, in order. And then we're going to use the next pointers to link these all together in that order. So the next pointers are what actually give us the order. And in addition, we're going to keep track of what's called the head of the list. The data structure is going to be represented by a head.
3437	If you wanted to, you could also store length. This could be the data structure itself. And it's pointing to all of these types of data structures. Notice, we've just seen an array-based data structure, which is just a static array, and we've seen a pointer-based data structure. And we're relying on the fact that pointers can be stored in a single word, which means we can de-reference them-- we can see what's on the other side of the pointer-- in constant time in our word RAM model. In reality, each of these nodes is stored somewhere in the array of the computer. So maybe each one is two words long, so maybe one node is-- the first node is here. Maybe the second node is here. The third node is here. They're in some arbitrary order. We're using this fact, that we can allocate an array of size n in linear time-- in this case, we're going to have arrays of size 2. We can just say, oh, please give me a new array of size 2. And that
3438	will make us one of these nodes. And then we're storing pointers. Pointers are just indices into the giant memory array. They're just, what is the address of this little array? If you've ever wondered how pointers are implemented, they're just numbers that say where, in memory, is this thing over here? And in memory, they're in arbitrary order. This is really nice because it's easy to manipulate the order of a linked list without actually physically moving nodes around, whereas arrays are problematic. Maybe it's worth mentioning. Let's start analyzing things. So we care about these dynamic sequence operations. And we could try to apply it to the static array data structure, or we could try to implement these operations in a static array. It's possible, just not going to be very good. And we can try to implement it with linked lists. And it's also not going to be that great.
3439	Our goal is the next data structure, which is dynamic arrays. But linked lists and static arrays each have their advantages. Let's first analyze dynamic sequence operations, first on a static array and then on a linked list. On a static array, I think you all see, if I try to insert at the beginning of the static array-- that's kind of the worst case. If I insert first, then everybody has to shift over. If I'm going to maintain this invariant, that the ith item in the array represents-- I guess I didn't write it anywhere here. Maybe here. Static array. We're going to maintain this invariant that a of i represents x i. If I want to maintain that at all times, when I insert a new thing in the front, because the indices of all the previous items change, I have to spend time to copy those over. You can do it in linear time, but no better. Static array. Insert and delete anywhere costs theta n time-- actually, for two reasons. Reason number one is that,
3440	if we're near the front, then we have to do shifting. What about insert or delete the last element of an array? Is that any easier? Because then, if I insert the very last element, none of the indices change. I'm just adding a new element. So I don't have to do shifting. So can I do insert and delete last in constant time in a static array? Yeah? AUDIENCE: No, because the size is constant. ERIK DEMAINE: No, because the size is constant. So our model is that remember allocation model is that we can allocate a static array of size em but it's just a size n I can't just say please make it bigger by 1 I need I need space to store this extra element. And if you think about where things are in memory, when you call to this memory allocator, which is part of your operating system, you say, please give me a chunk of memory. It's going to place them in various places in memory, and some of them might be next to
3441	each other. So if I try to grow this array by 1, there might already be something there. And that's not possible without first shifting. So even though, in the array, I don't have to do any shifting, in memory, I might have to do shifting. And that's outside the model. So we're going to stick to this model of just-- you can allocate memory. You can also de-allocate memory, just to keep space usage small. But the only way to get more space is to ask for a new array. And that new array won't be contiguous to your old one. Question? AUDIENCE: [INAUDIBLE] ERIK DEMAINE: What is the dynamic array will be the next topic, so maybe we'll come back to that. Yeah? In a static array, you're just not allowed to make it bigger. And so you have to allocate a new array, which we say takes linear time. Even if allocating the new array didn't take linear time, you have to copy all the elements over from the old array to the new one. Then you
3442	can throw away the old one. Just the copying from an array of size n to an array of size n plus 1, that will take linear time. So static arrays are really bad for dynamic operations-- no surprise. But you could do them. That's static array. Now, linked lists are going to be almost the opposite-- well, almost. If we store the length, OK, we can compute the length of the array very quickly. We can insert and delete at the front really efficiently. If I want to add a new item as a new first item, then what do? I do I allocate a new node, which I'll call x. This is insert-first of x. I'll allocate a new array of size 2. I'm going to change-- let me do it in red. I'm going to change this head pointer. Maybe I should do that later. I'm going to set the next pointer here to this one, and then I'm going to change this head pointer to point to here. And, boom, now I've got a linked list.
3443	Again, we don't know anything about the order and memory of these lists. We just care about the order that's represented implicitly by following the next pointers repeatedly. Now, I've got a new list that has x in front, and then x 0, and then x 1, and so on. So insert- and delete_first, at least are really efficient. We won't get much more than that, but the linked list, insert- and delete_first are constant time. So that's cool. However, everything else is going to be slow. If I want to get the 10th item in a linked list, I have to follow these pointers 10 times. I go 0, 1, 2, 3, and so on. Follow 10 next pointers and I'll get the 10th item. Accessing the ith item is going to take order i time. Get- and set_at need i time, which, in the worst case, is theta n. We have sort of complementary data structures here. On the one hand, a static array can do constant time get_at/set_at. So it's very fast at the random access aspect
3444	because it's an array. Linked lists are very bad at random access, but they're better at being dynamic. We can insert and delete-- at the beginning, at least-- in constant time. Now, if we want to actually insert and delete at a particular position, that's still hard, because we have to walk to that position. Even inserting and leading at the end of the list is hard, although that's fixable. And maybe I'll leave that for problem session or problem set. But an easy-- here's a small puzzle. Suppose you wanted to solve get-last efficiently in a linked list. How would you solve that in constant time? Yeah? AUDIENCE: Doubly linked list. ERIK DEMAINE: Doubly linked list. It's a good idea, but actually not the right answer. That's an answer to the next question I might ask. Yeah? AUDIENCE: [INAUDIBLE] ERIK DEMAINE: [INAUDIBLE] pointer to the last element. That's all we need here. And often, a doubly linked list has this. They usually call this the tail-- head and tail. And if we always just store a pointer to the
3445	last list-- this is what we call data structure augmentation, where we add some extra information to the data structure and-- we have to keep it up to date all the time. So if we do an insert_last or something, insert_last also becomes easy because I can just add a new node here and update the pointer here. delete_last is trickier. That's where you get a doubly linked list. But whenever I add something to the end of this list, I have to update the tail pointer also. As long as I maintain this, now, suddenly get-last is fast in constant time. So linked lists are great if you're working on the ends, even dynamically. Arrays are great if you're doing random access and nothing dynamic-- nothing adding or deleting at the ends or in the middle. Our final goal for today is to get sort of the best of both worlds with dynamic arrays. We're going to try to get all of the good running times of linked lists and all of the good running times of static arrays.
3446	We won't get quite all of them, but most of them. And in some sense, another way to describe what these introductory lectures are about is telling you about how Python is implemented. What we're going to talk about next, dynamic arrays, I've alluded to many times. But these are what Python calls lists. You don't have to implement a dynamic array by hand because it's already built into many fancy new languages for free, because they're so darn useful. This lecture is about how these are actually implemented and why they're efficient. And in recitation nodes, you'll see how to actually implement them if all you had were static arrays. But luckily, we have dynamic arrays, so we don't have to actually implement them. But inside the Python interpreter, this is exactly what's happening. The idea is to relax the constraint-- or the invariant, whatever-- that the size of the array we use equals n, which is the number of items in the sequence. Remember, in the sequence problem, we're supposed to represent n items. With a static array,
3447	we allocated an array of size exactly n. So let's relax that. Let's not make it exactly n. Let's make it roughly n. How roughly, you can think about for a while. But from an algorithms perspective, usually, when we say roughly, we mean throw away constant factors. And that turns out to be the right answer here. It's not always the right answer. But we're going to enforce that the size of the array is theta n-- probably also greater than or equal to n. 0.5 n would not be very helpful. So it's going to be at least n, and it's going to be at most some constant times n. 2n, 10n, 1.1 times n. Any of these constants will work. I'm going to use 2n here, but there are lots of options. And now, things almost work for free. There's going to be one subtlety here. And I'm going to focus on-- we're still going to maintain that the ith item of the array represents x i. This data structure-- let me draw a picture. We've got
3448	an array of some size. The first few items are used to store the sequence. But then, there's going to be some blank ones at the end. Maybe we'll keep track of this-- so the data structure itself is going to have an array and it's going to have a length. Something like this. We're also going to keep track of the length. So we know that the first length items are where the data is, and the remainder are meaningless. So now, if I want to go and do an insert_last, what do I do? I just go to a of length and set it to x. And then I increment length. Boom. Easy. Constant time. Yeah? AUDIENCE: [INAUDIBLE] ERIK DEMAINE: How do you have enough room. Indeed, I don't. This was an incorrect algorithm. But it's usually correct. As long as I have extra space, this is all I need to do for insert_last. But I am also going to store the size of the array. This is the actual-- this whole thing is size, and this part
3449	is length. Length is always going to be less than or equal to size. And so there's a problem. If length equals size, then I don't have any space. Just add to end unless n equals size. I'm using n length for the same thing. So length here is the same as n. That's our actual number of things we're trying to represent. And size-- this is great. This is the interface size. This is what we're trying to represent. And this is the representation size. This is the size of my array. These are the number of items I'm trying to store in that array. This is the interface versus data structure. Here's the interface. Here's the data structure. OK, cool.
3450	What do I do in the case when n equals size? I'm going to have to make my array bigger. This should sound just like static arrays. For static arrays, we made our array bigger every time we inserted. And that was this linear cost of allocation. We're going to do that sometimes. With static arrays, we had to do it every single time, because size equaled n. Now, we have some flexibility. We're only going to do it sometimes. It's like, cookies are a sometimes food, apparently, according to modern Cookie Monster. I don't understand. But if n equals size, we're going to allocate a new array of size-- any suggestions? AUDIENCE: Bigger. ERIK DEMAINE: Bigger. I like it. Greater than size. How much bigger? AUDIENCE: Twice. ERIK DEMAINE: Twice. JASON KU: Five things. ERIK DEMAINE: Five things. Size plus 5? Come on, Jason. Trolling me. All right. There are a couple of natural choices here. One is a constant factor larger. You could use 1.1, or 1.01, or two, or 5, or 10. They will all work. Or
3451	you could use Jason's trolling answer of size plus a constant, like 5. Why is this bad? Yeah? AUDIENCE: [INAUDIBLE] ERIK DEMAINE: You'll have to do it again. You'll have to resize frequently. When? Five steps later. In the original static array, we were reallocating every single time. That's like n plus 1. If we do n plus 5, that really doesn't change things if we ignore constant factors. Now, we'll have to spend linear time every five steps instead of linear time every one step. That's still linear time per operation, just, we're changing the constant factor. Whereas 2 times size, well, now we have to think a little bit harder.
3452	we're inserting at the end of an array. Let's say we do n insert_lasts from an empty array. When do we resize? Well, at the beginning-- I guess I didn't say what we do for an empty array. Let's say size equals 1. We can insert one item for free. As soon as we insert the second item, then we have to resize. That seems bad. Immediately, we have to resize. Then we insert the third item. OK, now let's draw a picture. So we start with one item. We fill it up. Then, we grow to size 2, because that's twice 1. Then we fill it up. Immediately, we have to resize again. But now we start to get some benefit. Now, we have size 4, and so we can insert two items before we have to resize. And now, we're size 8, and we get to insert four items before we refill. This is going to resize-- and again, resizes are expensive both because we have to pay to allocate the new array-- I drew it as just
3453	extending it, but in fact, we're creating a whole new array, and then we have to copy all of the items over. So there's the allocation cost and then the copying costs. It's linear either way. But we're going to resize at n equals 1, 2, 4, 8, 16-- you know this sequence. All the powers of 2, because we're doubling. That is exactly powers of 2. So we pay a linear cost. This resize cost, the allocation and the copying, is going to be-- it's linear each time. So it's 1 plus 2 plus 4 plus 8 plus 16. Really, I should write this as sum from i equals 1 to roughly log n. Log base 2 of n is lG of 2 to the i. If you want a terminus here, it's roughly n. It's actually the next-- the previous power of 2 of n, or something. But that won't matter. That will just affect things by a constant factor. What is the sum of 2 to the i? This is a geometric series. Anyone know the answer?
3454	Yeah? AUDIENCE: [INAUDIBLE] ERIK DEMAINE: 2 to the top limit plus 1 minus 1. Yeah. So this is the identity. Sum of 2 to the i from i equals 1 to k is 2 to the k plus 1, plus 1 minus 1. So the plus 1 is upstairs. The minus one is downstairs. An easy way to remember this is if you think in binary-- as we all should. We're computer scientists. 2 to the i means you set the ith bit to 1. Here's a bit string. This is the ith bit. This is 2 to the i. 0 is down here. If I sum them all up, what that means is, I'm putting 1s here. And if you think about what this means, this is up to k from 0-- sorry, I should do 0 to be proper. If I write-- that's the left-hand side. The right-hand side is 2 to the k plus 1, which is a 1 here, and the rest 0s. So if you know your binary arithmetic, you subtract-- if you add 1
3455	to this, you get this. Or if you subtract 1 from this, you get this. This is why this identity holds. Or the higher-level thing is to say, oh, this is a geometric series. So I know-- you should know this. I'm telling you now. Geometric series are dominated by the last term-- the biggest term. If you have any series you can identify as geometric, which means it's growing at least exponentially, then in terms of theta notation, you can just look at the last term and put a theta around it, and you're done. So this is theta of the last term, like 2 to the log n, which is theta n. Cool. Linear time. Linear time for all of my operations. I'm doing n operations here, and I spent linear total time to do all of the resizing. That's good. That's like constant each, kind of.
3456	which we call amortization. I want to say an operation takes t of n amortized time if, let's say, any k of those operations take, at most, k times t of n time. This is a little bit sloppy, but be good enough. The idea is here, if this works for n or k, to do n operations from an empty array here takes linear time, which means I would call this constant amortized. Amortized means a particular kind of averaging-- averaging over the sequence of operations. So while individual operations will be expensive, one near the end, when I have to resize the array, is going to take linear time just for that one operation. But most of the operations are cheap. Most of them are constant. So I can think of charging that high cost to all of the other operations that made it happen. This is averaging over the operation sequence. Every insert_last over there only takes constant time, on average, over the sequence of operations that we do. And so it's almost constant. It's not quite
3457	as good as constant, worst case, but it's almost as good. And it's as good as you could hope to do in this dynamic array allocation model. Let me put this into a table. And you'll find these in the lecture notes, also. We have, on the top, the main operations of sequence interface, which we will revisit in lecture seven. We'll see some other data structures for this. Get_at and set_at in the first column. Insert_ and delete_first, insert_ and delete_last, insert_ and delete_at an arbitrary position. We've seen three data structures now. Arrays were really good at get_at/set_at. They took constant time. That's the blue one. We're omitting the thetas here. All of the other operations took linear time, no matter where they were. Linked lists were really good at insert- and delete_first. They took constant time, but everything else took linear time, in the worst case. These new dynamic arrays achieve get_at and set_at in constant time because they maintain this invariant here that a of i equals x i. So we can still do get- and
3458	set_at quickly. And we also just showed that insert_last is constant amortized. delete_last, you don't have to resize the array. You could just decrease length and, boom, you've deleted the last item. It's not so satisfying, because if you insert n items and then delete n items, you'll still have an array of size theta n, even though your current value of n is 0. You can get around that with a little bit more trickery, which are described in the lecture notes. But it's beyond the-- we're only going to do very simple amortized analysis in this class-- to prove that that algorithm is also constant amortized, which it is. You'll see in 046, or you can find it in the CLRS book. That's it for today.
3459	[SQUEAKING][RUSTLING][CLICKING] ERIK DEMAINE: Today we're going to, in one lecture, cover an entire field, which is computational complexity. It's sort of-- it meets algorithms in an interesting way, which is, algorithms is mostly about showing how to solve problems well and showing that you can solve a problem well. And computational complexity is more about the lower bound side, proving that you can't prove-- you can't solve a problem very well, you can't find a good algorithm to solve it. We've seen a little bit about lower bounds several lectures ago, proving search and sorting lower bounds in a bounded branching decision tree model. But these are much stronger notions of badness. This is not about n versus n log n or constant versus log n. This is about polynomial versus exponential, which has been the sort of bread-and-butter model in this class. Polynomial is a good running time, and we're always striving for that. Exponential is usually pretty trivial to get. And so we're going to talk about some different-- they're called complexity classes that talk about this issue
3460	and different ways to prove hardness. This is a pretty high-level lecture, so you're not going to be expected to be able to prove hardness. But you'll get a flavor of what it's like, and this will segue nicely into other follow-on classes, which is-- we're at pretty much the end of 006, so natural to talk about what other things you might study. One result we'll prove today is that most problems actually have no algorithm, which is kind of shocking, and lots of other fun things. So let's get started with the notion of P. This is the set of all problems solvable in polynomial time. We talked about what polynomial time means a bunch last lecture. So just recall that polynomial time means polynomial in the problem size, which I'll denote as n here, the number of words in your input. OK, so these are the problems that are efficiently solvable. P is the set of all of them. And for contrast, EXP is the set of all problems solvable in exponential time. It's the problems solvable
3461	in exponential time. Exponential here means something like 2 to the n to the constant. That's one reasonable definition of exponential, so just the exponentiation of this-- of polynomial. So as you might expect, most-- every problem that we've talked about in this class so far can be solved in exponential time rather easily. And algorithms, in some sense, is about distinguishing these two, which problems are in P versus are in say EXP minus P. So to formalize this a little bit, I'm going to draw a picture, which is a bit of a simplification of reality, but for the purposes of this class will suffice, and I think is a really helpful way to think about things, which is to have a big axis for-- a single axis for, how hard is your problem, what is the difficulty of solving your problem? And I want to be sure to leave-- so the easiest problems are over here. And each problem is a dot on this axis. Hardest problems are way down the line. And I want to make
3462	sure to leave enough space for all the things that I care about. So P, I'm just going to call this segment up front. And then I'm going to have a bigger thing for exponential time. So this is just to say that P is nested inside EXP. Every problem that can be solved in polynomial time can also be solved in exponential time because polynomial is less than or equal to exponential. These are just upper bounds. Being an EXP means you're somewhere from this line to the left. Being in P means you're somewhere from this line to the left, in terms of difficulty. But formally, we would write P is contained in EXP as sets. In fact, they're also known to be different from each other. There are problems that can be solved in exponential time that cannot be solved in polynomial time. For example-- I'll put that here, sure. For example, n by n chess is in exponential time, but not polynomial time. So what is the n by chess problem? This is, I give you
3463	an n by n chessboard, and I describe to you a position. Here's where all the white pieces are. Here's where all the black pieces are. You can have an arbitrary number of queens and bishops and pawns of each color, of course, up to n squared of them so they don't overlap each other. And I want to know, does white win from this position? Let's say it's white to move. Can white win? And that problem can be solved in an exponential time by exploring the entire tree of all possible games. But it cannot-- but you can prove that it cannot be solved in polynomial time. So that's a nice example.
3464	is negative weight cycle detection. I guess it's literally negative, but it's morally positive. Negative weight cycle detection is the following problem. I give you a graph, a directed graph with weights, and I want to know, does it have a negative weight cycle, yes or no? And this problem is in? AUDIENCE: P. ERIK DEMAINE: P, because we saw a polynomial time algorithm for this. You run Bellman-Ford on an augmented graph. So this is an example of a problem we know how to solve. This whole class is full of examples that we know how to solve in polynomial time. But this is a nice, non-trivial and succinct one to phrase. It's also an example of a decision problem. A lot of-- basically all the problems I'll talk about today are decision problems, like we talked about last class, meaning, the answer is just yes or no. Can white win from this position, yes or no? Is there a negative weight cycle, yes or no? Tetris we can also formulate as a problem. This is a version of
3465	Tetris that we might call perfect information Tetris. Suppose I give you a Tetris board. It has some garbage left over from your past playing, or maybe it started that way. And I give you the sequence of n pieces that are going to come. And I want to know, can I survive this sequence of n pieces? Can you place each of these pieces as they fall such that you never overflow the top of the board on an n by n board? This problem can be solved in exponential time. But we don't know whether it can be solved in polynomial time. We will talk about that more in a moment. It's a problem that very likely is not in P, but we can't actually prove it yet. All right, so there's one other class I want to define at this point. And we'll get to a fourth one also. But R is the class of all problems that can be solved in finite time. R stands for finite. R stands for recursive, actually. This is a notion
3466	by Church way back in the foundations of computing. As we know, we write recursive algorithms to solve problems. In the beginning, that was the only way to do it. Now we have other ways with loops. But they're all effectively recursion in the end. So R is all the problems that can be solved in finite time on any computer. So very general, this should include everything we care about. And it's bigger than EXP, but includes problems that take doubly exponential time or whatever. So I will draw a region for R. So everything-- it includes P. It includes EXP. And so we also have containment but not equal R. There's, of course, many classes in between. You could talk about problems that take double A exponential time, and that would have a thing in between here. Or there's also-- between P and EXP there's a lot of different things. We will talk about one of them. But before we get to the finer side of things, let me talk in particular about R. So we have a
3467	nice example, we being computational complexity theory-- or I guess this is usually just called theoretical computer science-- has a problem. And if you're interested in this, you can take 6041, I think. That doesn't sound right. That's a probability. It'll come to me. We have an explicit problem that is not in R. So this class has been all about problems that are in P. You have the number? AUDIENCE: 6045. ERIK DEMAINE: 6045, thank you. It's so close to this class. Or it's so close to 6046, which is the natural successor to this class. So in 6045 we talk about this. So this class is all about problems that are in P, which is very easy. But in fact, there are problems way out here beyond R. And here is one such problem, which we won't prove here today.
3468	Given a computer program, does it ever halt? Does it ever terminate? This would be a great thing if we knew how to solve. It's basically an infinite loop detector. If your problem doesn't halt, then it has an infinite loop of some sort. And you'd like to tell your user, hey, you have a bug in your program. So this is one part of bug detection. And it's impossible. There is no algorithm that always-- that solves all inputs to this problem. Maybe given one program that, say, has 0 lines of code, it could solve that. It says, yeah, that one terminates. And maybe you can detect simple kinds of infinite loops. So there's some inputs, some computer programs that you could detect. But there's no one algorithm that solves all inputs. This is kind of sad news.
3469	This is just another word for being not in R. OK, and next thing I'd like to do is prove to you that most decision problems are uncomputable, or sketcher proof. So remember, decision problems are problems where the answer is just yes or no. This is a very special kind of problem. And even those, almost all of them, cannot be solved. So halting is an example of a problem we want-- we can't solve. This whole class, this 006, is about problems we can solve. But today I'm going to show you that, actually, those are in the minority. Most problems cannot be computed. This is very strange and also a little depressing. So we'll talk more about that in a moment. First let me argue why this is the case. So I'm going to be a little informal about what exactly is a computer program and what exactly is a decision problem. But roughly, all I need to do, the only level of precision I need is just to count how many are there. What is a
3470	computer program? Well, it's usually a file. What's a file? It's like a string of characters. What's a character? It's a string of bits. So a program is just, in the end, a string of bits, finite string of bits. We all understand that. Whatever language you define, in the end, every program is just a string of bits. And a string of bits we can translate into a number. So we can convert between strings of bits and numbers. When I say number, I mean what's usually called a natural number or a non-negative integer. This is usually represented by bold board bold-- blackboard bold capital N. So this is just 0, 1, 2, and so on. Now, what about decision problems? Decision problem is a specification of what we want to solve. So we can think of it as saying, for every input, is the answer yes or no? That's literally what a decision problem is. The only question is, what is an input? And we've talked about inputs and the size of inputs. And there's lots of
3471	different ways to measure them. But in the end, we can think of an input as a string of bits also. It's just a file. So a decision problem is a function from inputs to yes or no. And inputs we're going to say, well, that's a string of bits, which we can associate with a number in N. So here we can start to tie things together. So in other words, a program is a finite string of bits, and a problem is, in some sense, an infinite string of bits because there are infinitely many possible inputs. And for each of them, we specify yes or no. So this is basically an infinite string of bits. So we can imagine 011010001110, infinitely. Just some-- for every string of bits, we can say, OK, if your input is the number 0, here's the answer-- no. If your input is the number 1, then the answer is yes. If your input is the number 2, your answer is yes, and so on down this line. Every infinite string of bits
3472	corresponds to exactly one decision problem, which specifies for every possible input integer, which corresponds to a string of bits, what is the answer, yes or no? So this may seem subtle, or it may seem like not a big deal. This is a finite string of bits. This is an infinite string of bits. But mathematics has well studied this problem. And infinite strings of bits, there are very many of them, infinitely many. It's not surprising. There are also infinitely many integers. So maybe it doesn't seem that deep. But there's a difference in infinitude. Programs and integers are countably infinite. And infinite strings of bits are what's called uncountable. I think the most intuitive way to see this is, an infinite string of bits, if I put a decimal or a binary point in front, this encodes a real number between 0 and 1. So this is roughly a real number in 01. And when I'm writing approximately equal here, this really goes in both directions. Given a decision problem, I can define a string of bits,
3473	of course giving me the answer for all inputs. And I can convert that into a real number between 0 and 1. But also the other direction, if I take any real number, that is a corresponding decision problem. These are 1 to 1 bijection between them. And the bad news is, real numbers are uncountable, and natural numbers are countable, which means there's a lot more of these than there are these. So one way you might phrase this is, informally, the number of natural numbers is way smaller than the number of real numbers. And so from that, we derive that most problems are unsolvable, because every program solves exactly one decision problem. We can also run a program, conceptually, on all possible inputs, and we will figure out what function at solving. And if we don't allow random numbers in our program, which I'm not here, then every program solves exactly one decision problem. Possibly, it's even worse for us because multiple programs probably solve the same decision problem. They're just-- they add irrelevant lines of code
3474	or they don't do anything different. Or you run Bellman-Ford versus running Bellman-Ford five times, you'll get the same result. And that's actually the bad direction for us. We'd like to know whether there is a program that solves every decision problem. And because there are only this many programs and this many decision problems, it just-- there aren't enough to go around.
3475	Not nearly enough programs for all problems, and so there's no assignment of programs to problems because there's just too many problems. More money, more problems, I guess. So when I first saw this result, I was shocked and dismayed that-- why are we even doing computer science if most problems can't be solved? Luckily, it seems like most of the problems we care about can be solved. That's what this class is all about. And in fact, even the problems that seem really, really hard for us to solve, like n by n chess, where we can prove it takes exponential time, there is an algorithm to solve chess. It's just really slow. And this is a statement about, most problems can even be solved in finite time no matter how much time you give them. So it's not all bad. Luckily, most problems we care about are in R. I don't know why. This is sort of a mystery of life. But it's good news. Or it's why we keep persevering trying to solve problems with algorithms. AUDIENCE:
3476	Is it because when we state problems, the statement tends to be small? ERIK DEMAINE: Well, this-- so the question was, maybe it's just because these short statement problems are easy. But this is a pretty short statement, and it's hard. I think-- I don't have a great reason why. I wish I understood. There's a general result that if you have any question about the program itself, then there's no algorithm to solve it. Basically, any non-trivial question about programs is hard, is not in R. And I guess if you took-- if you imagine taking a random statement of a problem, then maybe this will be in the middle of it with some probability. Maybe that's why most. But this is a very strong notion of most. There are so many more real numbers than natural numbers that-- I don't know. I want to add one more class to this picture, which is NP. It nestles in between P and EXP. So we know that P is contained in or equal to NP. And NP is contained in
3477	or equal to EXP. We don't know whether there's a quality here or here. Probably not, but we can't prove it. But what is this class?
3478	you might find one way or the other more intuitive. They're equivalent. So as long as you understand at least one of them, it's good. NP is just a class of decision problems. So I define P and EXP and R arbitrary. They can be problems with any kind of output. But NP only makes sense for decision problems. And it's going to look almost like the definition of P-- problem solvable in polynomial time. We've just restricted to decision problems. But we're going to allow a strange kind of computer or algorithm, which I like to call a lucky algorithm. And this is going to relate to the notion of guessing that we talked about for the last four lectures in dynamic programming. With dynamic programming, we said, oh, there are all these different choices I could make. What's the right choice? I don't know, so I'd like to make a guess. And what that meant in terms of a real algorithm is, we tried all of the possibilities, and then took the max or the OR or whatever
3479	over all those possibilities. And so we were-- but what we were simulating is something that I call a lucky algorithm, which can make guesses and always makes the right guess. This is a computer that is impossible to buy. It would be great if you could buy a computer that's lucky. But we don't know how to build such a computer. So what does this mean? So informally, it means your algorithm can make lucky guesses, and it always makes the right guess. And whereas in DP, we had to try all the options and spend time for all of them, the lucky algorithm only has to spend time on the lucky guess, on the correct guess. More formally, this is called a non-deterministic model of computation. And this N is the-- the N in non-determinism is the N for NP. So this is non-deterministic polynomial time. So algorithm can make guesses. And then in the end, it should output yes or no. Like say if you're exploring a maze, this algorithm could say, should I go left or
3480	go right? I'm going to guess whether to go left or go right. And let's say it guesses left. And so then it just goes left. And then it reaches another junction. It says, should I go left or right? And it'll say, I'll guess, and it'll say, guess right this time. And in the end, if I get to some dead end maybe and I say no, or if I get to the destination I'm trying to get to, I say yes. So that's a non-deterministic algorithm. And what does it mean to run that algorithm? What does it mean for the guesses to be lucky? Here's what it means. These guesses are guaranteed-- which way you end up going is guaranteed to lead you to a yes if there is one-- if possible. So in my maze analogy, if my destination is reachable from my source, then I'm guaranteed, whenever I guessed left or right, I will choose a path that leads me to my destination. Whereas, if the destination is in some disconnected part of the maze
3481	and I can't get there, then I don't know what the guesses do. It doesn't really matter. Because no matter what I do, I'll end up in a dead end and say no. That's the model. As long as you have an algorithm that always outputs yes or no in polynomial time-- because we're only talking about polynomial time, lucky algorithms-- if there's any way to get to a yes, then your machine will magically find it without having to spend any time to make these decisions. So it's a pretty magical computer, and it's not a computer that exists in real life. But it's a computer that's great to program on. It's very powerful. You could solve lots of things with it. Yeah. AUDIENCE: If you had this magical computer, it can guess whether it's yes or no, why doesn't it just answer the question? ERIK DEMAINE: Right. So what if we-- so a nice check is, does this make all problems trivial, all decision problems? Maybe I should say, well, I don't know whether the answer to the
3482	problem is yes or no, so I'll just guess yes or no. This is problematic because-- so I might say, it will guess A or B, and if I choose the A option, I will output yes, and if I choose the B option, I will output no. In this model, that algorithm will always output yes. Because what it's saying is, if there's any way to get to a yes answer, I will do that way. And so such an algorithm that tries to cheat and just guess the whole answer to the problem will actually end up always saying yes, which means it doesn't solve a very interesting problem. It only solves the problem, which is represented by the bit vector 1111111, where all the answers are yes. But good check. Yeah. AUDIENCE: Does there have to be a bound of a number of things it has to choose between when it [AUDIO OUT] ERIK DEMAINE: Yes. AUDIENCE: Does it have an exponential number of them? ERIK DEMAINE: Exponential number of choices is OK. I usually like to
3483	think of it, as you can only guess one bit at a time. But we're allowed polynomial time, so you're actually allowed to guess polynomial number of bits. At that point, you can guess over an exponential size space, but not more than exponential. So it's-- yeah, polynomial time let's say in the one-bit guessing model. What did I say? Makes guesses-- let's add binary here. Otherwise we get some other class, which I don't want. OK, let's do an example, a real example of such an algorithm
3484	So I claim Tetris is in NP because there is a lucky algorithm and non-deterministic polynomial time algorithm that can solve the Tetris game. So again, you're given a board, you're given some sequence of pieces, and you want to know whether there's some way to place the pieces that lets you survive. And so what I'm going to do is, for each piece, I'm going to guess how to place it. So for the first piece, I'm going to guess how far left or right do I move it. Then I let it fall one step. Maybe I rotate it. I choose a sequence of moves among left, right, down, rotate right, rotate left. And all along the way, I check, is that move valid? If the move is invalid at any point, I just say, return no. And then if the piece gets nestled into a good spot, I continue to the next piece. I do the same thing, guess all the possible things I could do to that. Again, I only need to guess one bit at
3485	a time. And I'll only need to do a polynomial number of guesses, like a linear number of guesses, for each piece about where it falls in, so maybe a quadratic number of guesses overall. And then at the end, if I survived-- oh, I also have to check if a line clears. Then I clear the line. And if in the end I survive, I return yes. So this is a non-deterministic algorithm. So I would say, check the rules of the game. And if we survive, return yes. And if at any point we violate the rules-- for example, we go off the top of the board-- we return no. So this is an algorithm that sometimes returns no and sometimes returns yes depending on what choices you make. And this model guarantees, if there's any way to get to a yes, it will find it. If I swapped these answers, if I returned yes when I violated the rules and returned no if I survived, this would be an uninteresting algorithm. Because it's very easy to lose
3486	in Tetris. The hard part is to survive. If I say, is there any way to play the game in such a way that I violate the rules, then, of course, the answer is yes. You can just stack pieces and go off the top. There's an asymmetry in this definition of yes versus no. It always finds yes answers if possible. It doesn't always find no answers if possible. So it's very important the way that I wrote these questions. It's important that I define Tetris as the problem of, can I survive? The problem of can I not survive, is it impossible to survive, that's a different question. That problem is not in NP, probably. OK, so slight subtlety there, yes versus no. Let me give you the other definition of NP. So if this one's confusing, which-- although I prefer this definition. Most people do not. So this is confusing. Let's do the other definition. So another definition is that NP is a set of decision problems that can be checked in polynomial time. This actually came
3487	up in the last lecture where we talked about subset sum. I said, here's a bunch of integers, here's a target integer, and I can prove to you that this integer can be represented as a sum of numbers from my subset of numbers from my set, because here they are. I gave you this plus this plus this equals the target sum. And so that is a solution, in some sense, that can be checked for a yes example. If I can represent my number as a subset sum of a given set, it's easy for me to prove that to you. And you can check it just by adding up the numbers and checking that each number was in the set. Whereas no instances, I had an example of a target sum that could not be reached. And the only reason I knew that is because I had brute-forced the thing. And there's no succinct way to prove to you that that number can't be represented. A similar thing with Tetris, what I would say is-- so this
3488	is version 1, version 2-- for Tetris is that, a certificate for a yes input of Tetris is a sequence of moves for the pieces. OK, if it's possible to survive in Tetris, I can prove it to you. I can just play the game and show you that I survived. No answers, I don't know, it's hard to prove to you that I can't survive a given sequence of pieces. But yes answers are easy. I just show you, here's the sequence of button presses I'll do for this piece, then for this piece, then for this piece. Notice it's exactly the same thing that I guessed in the beginning of this algorithm. And then I did some other work to implement the rules. And similarly, if I gave you a certificate, which is the things that I wanted to guess of how to play the game, I can check this certificate by just implementing the rules of Tetris and seeing whether I survived. And if you violate the rules at any point, you say no. And if you
3489	survive, you return yes. That's what's called a verification algorithm. So let me formalize this notion. Given a problem input plus a certificate, like that one over there, there is a polynomial time-- so this is yet another definition. This is what I mean by this definition of NP-- verification algorithm that satisfies two properties. One is, for every yes input-- so every input where the answer is yes to the problem--
3490	So this is saying, it's possible to prove to me that an answer is yes, because if you ever have an input that the answer happens to be yes, you can prove it to me by giving me a certificate. There's always some certificate that proves the answer's yes. Because the verifier, which runs in regular polynomial time-- this is a regular, old-fashioned, down-to-earth verification algorithm, polynomial time in our usual sense-- it will say yes. And furthermore, the yes answers from the verifier are actually meaningful, because if I ever give it a no input, it always says no, no matter what certificate I give it. So this should really formalize what all this means. It's equivalent to the previous definition. This is saying that proofs exist for yes instances. And this is saying that proofs don't exist for no instances, meaning there are no false proofs. So if the verifier ever outputs yes, you know that the answer to your problem is yes. But if it outputs no, you're not sure. Maybe you got the certificate wrong because
3491	we only know there's some certificate where the verifier will say yes. Or maybe it was a no input, and then it didn't matter what certificate you used. But it's nice, because it says on, say, Tetris, if I give you the sequence of pieces, it's very easy to write down a verifier which just implements the rules of Tetris. And so then you can at least check whether a solution is valid in the yes case. In the no case, we don't have anything useful. So NP is a structure, some additional structure about the yes inputs in your problem. And a lot of decision problems are in NP. A lot of the problems that we care about can be phrased as an NP problem. As long as it's a decision problem, usually, answering yes or no is provable, like subset sum, like Tetris. These are all problems where, if the answer is yes, I can give you a convincing proof why. And it turns out a lot-- so a lot of problems fall into this NP setting. And
3492	so we have some tools for talking about problems being hard with respect to NP. Let me first talk a little bit about P. Does not equal NP, question mark. A lot of people conjecture that P does not equal NP. It's sort of a standard conjecture in theoretical computer science. But we don't know how to prove whether P equals NP or does not equal NP. And so in this picture, I've drawn the hypothesis, which is that NP is a strictly bigger region than P is. But we don't actually know whether there are problems in this region. We don't know whether there are problems in this region between NP and EXP. We conjecture there are problems here and there are problems here. There's definitely problems here or problems here, but we don't know which one. Because we know P does not equal EXP, but we don't know whether P equals NP, and we don't know whether P equals EXP. If you could prove that P does not equal NP, or disprove it, you would win $1 million,
3493	which not that much money these days. But you would be famous to for the rest of time if you could ever prove this. Every year, there's usually a crackpot proof that doesn't work out. Some of them go to me. Please don't send them. And anyway, it's a very hard problem. It is sort of the core problem in theoretical computer science, how to prove P does not equal NP. But for the most part, we just assume it. Now, what does this conjecture mean? It essentially means-- the way I like to say it is, you cannot engineer luck. Because NP problems are problems you can solve by lucky algorithms. P are problems you can solve by regular old algorithms. And so if P equalled NP, it means luck doesn't buy you anything, which seems weird. If I can magically make these super powerful guesses, then I can solve the problem that that's NP, that seems super powerful, way more powerful than regular algorithms, where we have to actually brute-force and try all the choices. And so it
3494	seems pretty solid that P does not equal NP. That's my-- of course, we don't know how to prove it. Another phrasing is that it's harder to come up with proofs than it is to check them, from a mathematical perspective. This is equivalent to P does not equal NP. So that's why you should believe it. Now, let's go over here.
3495	The next notion is NP-hardness. So in particular, I want to claim-- this is a theorem that exists in the literature-- that if P does not equal NP, then Tetris is not NP. So I said right here, Tetris is in EXP, but we don't know whether it's in NP. But in fact, we conjecture it is not NP because we conjecture that P does not equal NP. If you could prove this conjecture-- and there's a lot of theorems that are conditioned assuming P does not equal NP-- then we get some nice results, like Tetris cannot be solved in polynomial time. It cannot figure out whether I can win a Tetris game in polynomial time in the input size. Why? This is a consequence of another theorem, which is that Tetris is NP-hard. I'm going to define NP-hard informally first, and then I'll define it slightly more formally in a second. But this means, roughly, that Tetris is as hard as all problems in NP. So let me draw this in the picture. So NP-hard is this part.
3496	Did I leave myself enough room? Maybe not. Well, we'll squeeze it in. There's another region here for EXP-hard. So your problem being in NP was a positive result. It says you're no more difficult than this line. You're either at this position or to the left. Being in P was also a positive statement. It says you're here or to the left. Being in P is better than being in NP because this is a subset of that. NP-hard is a lower bound. It says, you are at this point, at this level of difficulty, or to the right. And so it goes from here off to infinity in difficulty. And EXP-hard says you're at least as hard as the right extent of the EXP set, or you're harder than that, in a sense that we will formalize in a moment. And this place right here, as you might imagine, is kind of interesting. It's exactly where NP meets NP-hard. This thing is called NP-complete. You probably have heard about NP-completeness, a famous notion. And this is what it
3497	means. It is, the problems that are in NP-- so they have a lucky algorithm that solves them, they can be verified, there are certificates that can be verified-- and they are NP-hard. So they're in NP, and they are the hardest among problems in NP. Now, they're not the hardest problem. There are actually many problems right here at this single level of difficulty called NP-complete. Among them is Tetris. There are many others, which I will list in a moment. So that is NP-completeness. So because these problems are the hardest problems in NP, if there's any problems here in between-- in NP minus P, then these must be among them. And so if you assume that P does not equal NP, as most people do, then you know that all problems at this right-most extreme of NP, the hardest of the problems in NP, they must not be NP. And that's why I can say, if P does not equal NP, Tetris is not NP, and also, any NP complete problem is not NP. OK, what does
3498	"""as hard as"" mean?"
3499	This is our good friend reductions. We talked about reductions a lot in this class. Reductions are the easy way to use algorithms. You just take your problem and reduce it to a problem you already know how to solve. You take the input to some problem that you want to solve, and you convert it into an input to some other problem, like single source shortest paths or something like that that you already have an algorithm for solving. So if you have an algorithm that solves problem B, you can convert that into a solution for B. And a reduction should also tell me how to-- given a solution to B, how to convert it back into a solution for A. And when I say solution here, I actually mean certificate from over there. So how-- so if I-- so if I have-- so reduction consists of these two pieces-- how to convert an input at A to an input for B, and given a solution to B, how to convert it to a solution to A. Let
3500	me give you some examples of reductions you've already seen. You've seen a lot of them. If I have unweighted shortest paths on the left-- unweighted single source shortest paths-- I can reduce that to weighted shortest paths. How? AUDIENCE: Set all the weights to 1. ERIK DEMAINE: Set all the weights to 1. So here I'm given a graph without weights. If I set all the weights to 1, that turns it into an input for a weighted single source shortest paths. So if you didn't know how to solve this, you could solve it by converting it. If you've already written, say, a Dijkstra algorithm, you could apply it to solve unweighted single source shortest paths. Now, we know a faster way to solve this, but it's only a log factor faster. And here we're talking about polynomial versus exponential. So this is a valid reduction. It's not the most interesting one from an algorithmic standpoint, but it is an algorithm. Another one we've seen is, if you have integer weights in the left, you can convert that
3501	to unweighted on the right, positive integer weights, by subdividing each edge of weight W into W edges of no weight. So that's maybe a little bit less efficient. It depends what the sum of the weights are. Another version that we've seen is longest path in a graph. We can-- weighted path we can reduce to shortest path in a graph, weighted by negating all the weights. We did this in some of the dynamic programming things. Like oh, longest path on a DAG? We can convert that into shortest path on a DAG just by negating all the weights. So these are all examples of converting one problem to another. Usually, you convert from-- for algorithms, you convert from a problem you want to solve into a problem that you already know how to solve. But it turns out the same tool reductions can be used to prove negative results too. And in this case, we're going to reduce from a problem that we think cannot be solved and reduce it to the problem that we're interested in
3502	solving. So let me write more precisely what this means. If you can find a reduction like this, it means that solving A is at least as easy as solving B. Because I could solve A, in particular, by converting it into B, solving B, and then converting it back to a solution to A. So in other words, if I can solve B, I can solve A, which I can phrase informally as, A is at least as easy as B. And now using grammar, contrapositive whatever, this is the same thing as saying that B is at least as hard as A. And this is what I mean by at least as hard as. So this is my definition of at least as hard, in this notion of NP-hardness. So what NP-hard means is that I'm at least as hard as all problems in NP. So what that means is, every problem in NP can be reduced to Tetris, which is kind of funny. But in particular, that means that if there's an algorithm for Tetris, there's an
3503	algorithm for all problems in NP. And so that's actually the contrapositive of this statement. So this is saying, if there's a polynomial-- if I take the contrapositive of this, this is saying, if there's a polynomial time algorithm for Tetris, then P equals NP, there's a polynomial time algorithm for every problem in NP. And the way we prove that is by reductions. We take an arbitrary problem in NP, and we reduce it to Tetris. Luckily, that's not as hard as it sounds because it's already been done once. There is already a reduction from NP to-- from all problems in NP to singular problems out there, the NP-complete problems. There is some first NP-complete problem, which I guess is the Turing machine. It's basically simulating a lucky algorithm, so it's kind of a not very interesting problem. But from that problem, if you can reduce it to any other problem, you know that problem is NP-hard as well. And so briefly, I want to show you some examples of that here. So I want to start out
3504	with a problem that I'm just going to assume is NP-complete. And it's called 3-partition. One way to phrase it is, I give you a bunch of integers-- I think I have it written down over here, also the board. I give you n integers, and I'd like to divide them up into n over 3 groups of size 3, such that each group of size 3 has the same sum. And it's written there on the board. So you can also think of this as the following problem. I give you a bunch of rectangles that are a side length-- or a bunch of sticks, let's say, of varying lengths, and I want to group them up like on the right diagram, so in groups of 3, such that the total length of each group is exactly the same. This is just a problem. And just believe for now that it is NP-complete. I won't prove that. But what I'd like to show you is a reduction from this problem to another problem-- solving jigsaw puzzles. So you might
3505	think jigsaw puzzles are really easy, and especially easy if I lose the projector. But in fact, if you have a jigsaw puzzle where some of the matches are ambiguous, if there's multiple pieces that could fit against a given tab or pocket, then I claim I can represent this 3-partition problem by building little sticks, like here. So if I want to represent a stick of length ai, I'm just going to build an ai-- I didn't mention they're all integers, and they're polynomial-sized integers. I'm going to represent that by ai different pieces here. And the red tabs and pockets are designed to be unique global to the puzzle, like a regular jigsaw puzzle. Given this piece on the left and this tab on the right, there's a unique pocket, there's a piece with unique pocket that fits perfectly into that piece. So this joining is forced. And also this joining is forced. But the blue tabs and pockets are different. They're all the same. They're all identical. And so if I build this frame using the red
3506	unique assignments, and I build these rectangles, if I want to pack these rectangles into this rectangle, that's exactly the 3-partition problem, with some details that I didn't fill in. But it turns out you'd be forced to group these into groups of size 3, something like this, with varying lengths. OK, so that's an example of a reduction. If you believe the 3-partition is NP-hard, this proves to you that jigsaw puzzles are NP-hard,
3507	Every time you solve a jigsaw puzzle, you can feel good about yourself now, especially if it has ambiguous mates. Next is Tetris. So here is a reduction from the same 3-partition problem, which is one of my favorite problems, to Tetris. It starts out with this strange board. It has a bunch of columns here where I could put pieces. So I'm not allowed to put pieces in these dark regions. They all have height T. T is the target sum that we want all of the numbers to-- all of the triples of numbers to add up to. And there's n over 3 of these slots where I can try to put pieces. And it's-- because of this thing over on the right, there's no way to clear lines in this game. And now to represent a single number ai, I'm going to give you this sequence of pieces, which starts with an L piece. And then it has ai repetitions of this pattern, and then it ends with these two pieces. And so what ends up happening
3508	is that-- this is in the intended solution-- you first place an L at the bottom of one of these buckets, and then you repeat this pattern in this nice way. And it fills up the ai, roughly, height of this bucket. And then at the end, you have to put the I here. And what this ends up guaranteeing is that all of these pieces go into a single bucket. You can check. It's tedious. But if you tried to put some of these pieces in one bucket and other pieces in a different bucket, you would lose some space, and then you would die. So if you want to survive, you have to put all these pieces into one bucket. And so again, we're just stacking rectangles. We're putting a whole bunch of rectangles in one pocket and then a bunch of rectangles another pocket. We can switch back and forth however we want. But the only way to win, it turns out, is if you get all of those rectangles to add up to exactly the right
3509	height. Then you get a picture like this. If you don't get a picture like this, you can prove you end up dying. Then I'll give you a bunch of Ls. Then I'll finally give you this T, which clears some lines. And then I'll give you-- the most satisfying Tetris game ever-- I'll give you a ton of I's, and you get Tetris, Tetris, Tetris, and you clear the entire board. And so if you can solve the 3-partition problem you can clear the board and win the game and be the best Tetris player ever. And if there is no solution to 3-partition, you're guaranteed to lose.
3510	Cool. So what else do I want to say, briefly? I think that's the main idea. So another example-- so this spot is called EXP-completeness. And this includes problems such as n by n chess. So we know that chess requires exponential time because, in fact, it's among the hardest problems in exponential time. But most common are the-- that's somehow because of the two-player nature of the game. Most common are NP-complete problems. And we have a bunch of example NP-complete problems I'll just briefly mention here. So we saw the subset sum problem, which we had a polynomial time algorithm for-- sorry, a pseudo polynomial time algorithm for last class-- in fact has no polynomial time algorithm, assuming P equals NP. So pseudo poly is the best you can hope for for subset sum. There's a related notion called weakly NP-hardness, which I won't get into here. 3-partition is one we saw. We saw some reductions to other problems. So these are all NP complete. Longest common subsequence is another dynamic programming problem we saw with two sequences.
3511	I mentioned you could solve it for three or four or any constant number. But if I give you n sequences each of length n, that problem is NP-hard, NP-complete. Longest simple path in a graph-- we know how to solve longest path. You just solve shortest path and negative weights. But longest simple path, where you don't repeat vertices, that's NP-complete. Relatedly, one of the most famous NP-complete problems is traveling salesman problem, finding the shortest path that visits all vertices in a given graph. So instead of just going from A to B, I want to visit all the vertices in the graph. A lot of these problems I'm phrasing as optimization problems. But when I say NP-complete, I actually mean a decision version of the problem. For example, with this one, the decision question is, is the shortest path that visits all vertices in a graph less than or equal to a given value x. If you can solve this, then by binary search you can solve the overall weight. 3-coloring a graph is hard, even though
3512	2-coloring a graph is polynomial. 3-coloring is NP-complete. Assigning three colors to the vertices so that no adjacent vertices have the same color, finding the largest clique in a given graph, which would be useful for analyzing social networks, whatever. This is a fun one for me as a geometer. If you're in a three-dimensional world, which I am, and I want to find the shortest path from here to there that doesn't collide with any obstacles, like this desk and all the chairs and so on, in 3D, this problem-- if you can fly, so if you're a drone flying among all these obstacles, you want to find the shortest path from A to B, this is NP-complete. It's quite surprising. In two dimensions, it's polynomial. You can reduce it to graph shortest paths. But in 3D, it's NP-hard. This is a formula problem that comes up a lot. Given a Boolean formula with AND, OR, or NOT, can you ever make it true, if it has some variables that are not assigned? And some more fun examples are
3513	Minesweeper or Sudoku. Basically any paper and pencil puzzle you've ever played, there's probably a paper out there proving that it's NP-complete. And on the video game side, Super Mario Brothers is NP-hard. Legend of Zelda is NP-hard. Pokemon is NP-hard. These problems are actually all a little bit harder than NP, in a different class called P-space, which I won't go into. But if you're interested in this stuff, there is a whole class devoted to it, which has online video lectures, so you can watch them whenever you want, called 6.892, that gives a bunch of especially fun examples of NP-hardness and other types of hardness proofs from a sort of algorithm perspective for lots of games and puzzles you might care about. And that's it.
3514	[SQUEAKING] [RUSTLING] [CLICKING] ERIK DEMAINE: All right, welcome back to data structures land. Today we continue and complete our segment on binary trees. So this is part two. If you missed part one, go back and watch part one. Last time, we talked about binary trees in general. We had each node stored an item, and also a left pointer and a right pointer to other nodes, and a parent pointer to another node. This was an example of a tree. B, and C are A's children. A is the parent of B and C, and also the root of the entire tree. We defined the height of a node. We didn't use this too much yet. But we're going to use it a lot today. So remember, the height is as drawn in red here. Height of the node is the length of the longest downward path counting edges. So B, for example, has a length 2 paths. So we write a 2 here. You can also think of it as if you just live within the subtree rooted
3515	at B, B subtree, then what is the maximum depth of those nodes, if you prefer to think about it that way. Either way is fine. And in particular, we distinguished h, the height of the root node, as the height of the entire tree. And what we achieved last time was basically all of our operations ran in order h time. So we had subtree insert, subtree delete, subtree first and last. We could compute the predecessor and successor of a node, all in order h time. So as long as h was small, we were happy. And remember, what does predecessor and successor mean? It's talking about an implicit order in the tree, which is what we call traversal order, which is defined recursively as recursively traverse the left subtree, then output the root, then recursively traverse the right subtree. So in this example, the traversal order is F is the-- if you go all the way left, that was the first in the traversal order. Then we have-- right, I'll make me some space here. Then we
3516	have D, then we have B. Then we do the right subtree of B, which is E. Then we have the root, because we finished the left subtree of the root. So that's A. And then we have C. So there's an implicit linear order encoded by this tree. And the whole point of binary trees is that we can efficiently update the tree much faster than we could explicitly write down an order in an array or something like that.
3517	now, quickly is not so quick right now. Because everything is order h. And in the worst case, h is linear. Because we can have a tree like this. But today, we're going to make-- we're going to guarantee that h is log n. And so the goal of today is to take all of these operations that run in order h time and get them to run an order log n time, just by modifying the data structure we've already seen. So we've done a lot of the hard work, just a little bit more work we need to do today on something called
3518	But before we get there, I want to talk a little bit more-- at the very end of the last lecture, we talked about once you have these subtree operations-- so I can insert and delete in the subtree-- how do I actually use that to solve the problems that we care about in this class, which are sequence data structure and set data structure? So we talked mostly about the set data structure last time. So in general, we're going to define what traversal order we maintain by a binary tree. And so for a set, because for the set interface, we're interested in doing queries like find_next and find_previous, given a key, if it's not there, tell me the previous one or the next one, this is something we could do with binary search. And so the big, cool thing that binary trees let us do, if we let the traversal order always be all of the items stored in increasing key order, then we are effectively maintaining the items in order-- in the traversal order sense. Again,
3519	we're not explicitly maintaining them in order. But up here, we're maintaining a tree that represents items in key order. And so this lets us do a subtree_find operation-- which you could easily use to implement find, and find_previous, and so on-- as follows. We start at the root of the tree. So we can say, node equals root initially. And then we can recursively search for a key k as follows. We check, well, if the item at the root has a key that's bigger than k-- let me draw a little picture. So we're at some node here. This is a node. And it has left subtree and a right subtree. And there's some item with some key. So if the key we're looking for is less than the node's item, that means it's down here in the left subtree. And so we recurse on node.left. If they're equal, that means that this item is the item we're looking for. So we can just return it or the node, depending on what you're looking for. And if the
3520	key in here is greater than the key
3521	If you think about it a little bit, this is exactly binary search on an array. It just happens to be on a tree instead. If you think of an array like this, what does binary search do? It first looks at the key in the middle. I'm going to draw that as the root. And then, it recurses either on the left chunk, which I will draw recursively, or on the right chunk. And so if you happen to have a perfect binary tree like this one, it is simulating exactly binary search in this array. But this we're going to be able to maintain dynamically-- not perfect any more, but close. Whereas this we could not maintain in sorted order. So this is like a generalization of binary search to work on trees instead of on arrays. And for this reason, set binary trees are called binary search trees, because they're the tree version of binary search. So there's many equivalent names. So binary search tree is another name for set binary tree. And the key thing that
3522	makes this algorithm work is the so-called binary search tree property, which is all the keys in the left subtree of a node are less than the root, or of that node, and that key is less than all the keys in the right subtree. And this is true recursively all the way down. And so that's how you prove that this algorithm is correct by this property. Why is this true? Because if we can maintain traversal order to be increasing key, then that's exactly what traversal order means. It tells you all the things in the left subtree come before the root, which come before all the things in the right subtree.
3523	And how do you maintain things in increasing key order? It's pretty easy. If you want to insert an item, where does it belong? Well, you do this search to find where it would belong if it was there. If it's there, you can overwrite the value stored with that key. If it's not, this search will fall off the tree at some point, and that's where you insert a new node in your tree. That was covered in recitation, so I don't want to dwell on it. What I want to focus on today is the other application. How do we-- this is for representing a set, which is relatively easy. A challenge to sort of set ourselves up for, but we need a little more work, is to make sequence binary trees. So suppose I have a binary tree, and what I would like-- we mentioned at the end of last time-- is that I want the traversal order of my tree to be the sequence order, the order that I'm trying to represent that's changed by operations
3524	like insert_at. So I'd just like to do the same thing. But now, I have to think about how do I do a search, how do I do a insert_at, that sort of thing. And here is an algorithm for what I would like to work. But it's not going to quite work yet. So suppose I give you a subtree, so specified by a node. So there's all the descendants of that node. And I'd like to know what is in the traversal order of that subtree, which starts here, and ends here, and the root will be somewhere in the middle. Give me the ith node. So if I ask i equals 0, I want to get this leftmost descendant. If I ask for i equals the size of the tree minus 1, I want to get the rightmost descendant. That was the first and last in the subtree that we talked about. But we know how to find the first and last. Just walk left or walk right. But we don't know how to find the ith
3525	node--
3526	And the idea is, well, it seems like size matters. [CHUCKLES] Sorry if you heard otherwise. So in particular, I mentioned size when I was talking about the last node in the sequence. The index of that node is size of the subtree minus 1. So let's define the size of a node to be the number of nodes in its subtree-- we were calling that subtree(node)-- including the node itself. So if I somehow knew the size, this seems important for understanding indexes. Let's just assume that I knew that magically in constant time. Then, I claim that the size of the left subtree-- so why don't I expand this diagram a little bit? So we have node as before. But we have left subtree and a right subtree. So this node here is node.left. This node here is node.right. They might not exist, but let's ignore those exceptional cases
3527	Let's suppose we knew not only the size of node, but we knew the size of node.left, so that is the size of this tree on the left. I'm going to call that nL. So let's suppose that there are nL nodes down here. I claim that lets me do the equivalent of a binary search. Because I'm looking for some index i. And if i is less than nL, then I know that it must be down here. For example, if i equals 0, it's going to be in the left subtree, as long as nL is greater than 0, right? So that's exactly this check. If i is less than nL, I'm going to recurse to the left, call subtree at of node.left, i. That's what's written here. If i equals nL, if you think about it for a second-- so nL is the number of nodes here. And so that means this node has index nL. The index of this node is nL. And so if i equals-- if the one index we're looking for is that
3528	one, then we just return this node. We're done. And otherwise, i is greater than nL. And that means that the node we're looking for is in the right subtree, because it comes after the root. Again, that's what it means. That's what traversal order means. So if we define it to be sequence order, then we know all the things that come after this node, which is index nL, must be over here. Now when we recurse down here, our numbering system changes. Because for node, 0 is here. And then for node.right is here. So we need to do a little bit of subtraction here, which is when we recurse to the right, we take i minus nL minus 1-- minus nL for these guys, minus 1 for the root node. And that will give us the index we're looking for within this subtree. So my point is, this algorithm is basically the same as this algorithm. But this one uses keys, because we're dealing with a set, and in sets we assume items have keys. Over here,
3529	items don't have to have keys. In fact, we're not touching the items at all. We're just asking, what is the ith item in my sequence, which is the same thing as what is the ith item in my traversal order, which is the same thing as asking what is the ith node in the traversal order? And this algorithm gives it to you exactly the same way in order h time. Now, I'm not going to show you all the operations. But you can use subtree_at to implement get_at set_at. You just find the appropriate node and return the item or modify the item. Or you can use it to-- most crucially, you can use it to do insert_at delete_at. This is a new thing we've never been able to do before. What do you do? Just like over here, if I'm trying to insert an item, I search for that item over here. So if I'm trying to insert at i, for example, I look for i.
3530	before that one. And conveniently, we already have-- I didn't mention, but we have a subtree insert. We had two versions-- before and after. I think we covered after, which I use successor before I use predecessor. But we can just call subtree insert before at that node, and boom, we will have added a new item just before it. And great, so magically, somehow, we have inserted in the middle of this sequence. And all of the indices update, because I'm not storing indices. Instead, to search for an item at index i, I'm using the search algorithm. But there's a problem. What's the problem? This seems a little too good to be true. I insert in the middle of this tree, and then somehow, I can magically search and still find the ith item, even though all the indices to the right of that item incremented by 1. It's almost true. Answer? Yeah? AUDIENCE: [INAUDIBLE] ERIK DEMAINE: Because we have to update the sizes, right. I didn't say, how do I compute the size of the left subtree?
3531	So that is the next topic.
3532	We're almost done. This will actually work. It's really quite awesome. But for it to work, we need something called subtree augmentation, which I'll talk about generally. And then, we'll apply it to size. So the idea with subtree augmentation is that each node in our binary tree can store a constant number of extra fields. Why not? And in particular, if these fields are of a particular type-- maybe I'll call them properties. I'm going to define a subtree property to be something that can be computed from the properties of the nodes' children. So I should say this is of a node. So children are node.left and node.right. You can also access constant amount of other stuff,
3533	But the point of a subtree property is it's downward looking. If I have a node here, and I want to compute some property about it-- call it, we want to store P of the node-- and suppose we already know P over here, the property computed for the left subtree or for the left node, and we already know the property for the right node, then what I'd like is for this to be computable in constant time. So I can compute P of this node given P of the left node and P of the right node. That's a subtree property. Now, in particular, size is a substrate property. Why? Because I can write this kind of recurrence, node.size equals node.left.size-- this is very tedious to write-- plus node.right.size, plus? 1, thank you. The size of the entire subtree here, called node, is the size of the left subtree plus size of the right subtree, plus 1 for that node itself. So this is an update rule. It takes constant time to evaluate. It's two editions. Sorry, my
3534	t's look kind of like plus signs. I'll make the pluses a little bigger. So we're just summing those three things. Boom, we can get node.size. So I claim that as long as my property has this feature, I can maintain it dynamically as I'm changing the tree. Now, this is a little bit of a forward reference, because we haven't said exactly how we're going to change the tree yet. But question?
3535	then how is it happening in constant time? Wouldn't it be happening [INAUDIBLE]?? ERIK DEMAINE: Why is this-- OK, good question. So one natural way, you can think of this as a recursion, which gives you a recursive algorithm. So I wrote-- but didn't write it. But I could have written size of node equals this-- size of node.left plus-- and that would give you a linear time algorithm to count the size. And if you don't have any information, that is what you would do. And that would be very painful. So that would make this algorithm really slow. If I'm calling size as a recursive function, it's bad. What I'm instead doing is storing the sizes on every single node and pre-computing this. So in fact, I'm going to define the size of node in-- so this is the definition mathematically. But the algorithm for this function is just going to be return node.size. So that's constant time. So the challenge now is I have to keep these sizes up to date, no matter what I do to
3536	the tree. And you could look back at last lecture and see, OK, what were all the changes that I did in a tree? We only did changes during insert and delete. And I will just claim to you, when we did insert and delete, what they ended up doing in the end, they add or remove a leaf of the tree. Remember, a leaf was a node with no children. So let's just think about if I add a new leaf in a tree-- here's a tree, suppose I add a leaf here-- which subtrees change? Well, which subtrees contain that node? It is its own new subtree. Then it's in its parent subtree, and its grandparent subtree, and the overall subtree. In general, these nodes are called the ancestors of this node that we added. And those are the ones that update. This subtree over here didn't change. It didn't change size. And because it's a subtree property, no subtree property will change over here, because the subtree was untouched. So when I touch this guy, I just
3537	have to update the subtree property here, update the subtree property here, update subtree property here. How many of these are there? Yeah? h-- I'll say order h to be safe. But I think it's exactly h. So also, when I remove a leaf, the same thing-- if I remove this leaf, then the subtrees that change are exactly its former ancestors. Cool, so we're going to update those order h ancestors in order up the tree. So what do I mean by update? I mean apply this rule. For size, it's this rule. But in general, the subtree property gives me an update rule that takes constant time. And so I'm going to apply that update rule to this node, which will fix whatever property is stored in there. Maybe there's more than one property. And then I'll apply it to this node. And because this is already correct by induction, and this is already correct because I didn't touch this subtree-- it's unchanged-- then I can update the value at this node-- the property at this node in
3538	constant time. Then I update this one. And because this one is already correct by induction, and this one is already correct because this subtree is unchanged, I can update the property correctly here in constant time. So when I make a change in order h time, because I'm making h calls to this constant time algorithm, I can update a constant number of subtree properties. This is very powerful. Data structure augmentation is super useful. You will use it on your problem set. We will use it again today. Let me give you some examples of subtree properties. They could be-- common ones are, like, the sum, or the product, or the min, or the max, or sum of squares, or all sorts of things, of some feature of every node in the subtree. In fact, subtree size is an example of such a thing. It is the sum over all nodes in the subtree of the value 1. It's another way to say count the number of nodes. But you could also say, what's the sum of the
3539	keys in these nodes? Or you could say, what's the maximum key in these nodes? Or you could say, what is the maximum value in these nodes? You can take any property. It doesn't have to be key. It doesn't have to be anything in particular. It's very powerful. You can take all sums, products and maintain them as long as they're downward looking-- as long as you're only thinking about the subtree. Some examples of things you cannot maintain are-- not a nodes index. So if you get a little bit too excited about augmentation, you might think, oh, I could do everything. I needed to support subtree_at, or let's just say, get_at globally, I wanted to know what is the ith node in my tree? Well, I'll just use data structure augmentation and store in every node what is its index, 0 through n minus 1. I can't maintain that efficiently. Because if I insert at the beginning of my traversal order, then all the indices change. So that's an example of a edit. So if I insert
3540	a new node over here, so this guy's index was 0, now it's 1. This guy's index was 1, now it's 2. This was 2, now it's 3, and so on. Every node changes its index. Index is not a subtree property, and that's why we can't maintain it. Because it depends on all of the nodes in the tree. Or it depends on all the nodes to its left-- all the predecessors.
3541	on how many nodes are over here on the left, which is not in the subtree of that node. So that's where you have to be careful. Don't use global properties of the tree. You can only use subtree properties. Another example is depth. Depth Is annoying to maintain, but it's not obvious why yet. We will see that in a moment. The rest of today is about going from order h order log n, which is what this slide is showing us. So at this point, you should believe that we can do all of the sequence data structure operations in order h time-- except for build and iterate, which take linear time-- and that we can do all of the set operations in order h time, except build and iterate, which take n log n and n respectively. And our goal is to now bound h by log n. We know it's possible at some level, because there are trees that have logarithmic height. That's like this perfect tree here. But we also know we have to be
3542	careful, because there are some bad trees, like this chain. So if h equals log n, we call this a balanced binary tree. There are many balanced binary trees in the world, maybe a dozen or two-- a lot of different data structures. Question? AUDIENCE: [INAUDIBLE] you said not to think about things on a global level so we'll think of them [INAUDIBLE]..
3543	ERIK DEMAINE: OK, what does it mean for a property to be local to a subtree versus global? The best answer is this definition. But that's maybe not the most intuitive definition. This is what I mean. Something that can be computed just knowing information about your left and right children, that is the meaning of such a property. And those are the only things you're allowed to maintain. Because those are the only things that are easy to update by walking up this path. And the contrast is that global property like index, it's global, in particular, because I can do one change, add one node, and all of the node's properties change. So that's an extreme example of global. We want this very particular notion of local, because that's what we can actually afford to recompute. Hopefully that clarifies. Yeah? AUDIENCE: Doesn't size not work with that [INAUDIBLE]?? ERIK DEMAINE: You're right that if we added-- oh, no. OK, let's think about that. If we added a new parent to the tree-- this is not something that we've
3544	ever done. But even if we did that, which subtrees change? Only this one. This node, it's a totally new subtree. But the subtree of this node is completely unchanged. Because subtrees are always downward looking, if I added a new root, I didn't change any subtrees except for one.
3545	Now, there are-- I mean, I could completely redraw the tree. And that's an operation that requires everything to be recomputed. So it is limited exactly what I'm allowed to do in the tree. But I claim everything we'll do, last class and today, we can afford this augmentation. So it's a feature, not of all binary trees necessarily, but of the ones that we would cover. Yeah? AUDIENCE: What is a min? ERIK DEMAINE: What is a min? AUDIENCE: [INAUDIBLE] ERIK DEMAINE: Binary tree, yeah. OK, this will make a little more sense in a moment when I say what we're actually going to do with trees. We need a new tool for manipulating a tree.
3546	And we did adding and removing a leaf. That's not enough. We're going to need something else to let us guarantee logarithmic height. And that something else is called a rotation.
3547	What does this something else need to do? This is just a tool for rebalancing the tree. So it should not change the data that's represented by the tree. What is the data represented by the tree? Traversal order. Traversal order is sacrosanct. We're not allowed to touch it. It's already defined two different ways, depending on whether you're using a set or sequence. So we want to modify the tree in a way that doesn't modify the traversal order. So we're exploiting redundancy. If you wrote down the traversal order in an array, there's exactly one representation of a given order. But in a tree, there's many representations. It could be a long line. It could be a balance thing. They could represent the exact same order on the nodes if you label them right. In fact, there are exponentially many different representations of the same thing. And we're going to exploit that, the same order, and define-- this is just a thing you need to know. Let me label, A, X, B, Y, C. You can tell I've
3548	drawn this diagram before many, many times. This is a very powerful tool in all tree data structures, which are most of data structures. And they are called right rotate of y and left rotate of x. So if I have this tree-- which I'm just black boxing some of the subtrees into little triangles. If I have a node, and it has a left child, then I'm allowed to right rotate this edge, which means take this edge and go like this-- 90 degrees, kind of. Or you could just think of it as rewriting it this way. Now, you might also have keeping track of the parent pointer. Parent pointer moves around. Before, this was the parent of y. Now it's the parent of x. So x and y are switching places. But we couldn't just swap these items around, because that would change traversal order. In this picture, x comes before y,
3549	And over here, now y is in the right subtree of x. So it comes after x. So in both cases, x comes before y. And indeed, in all of these pictures the traversal order-- I mean, not just for x and y, but also for A, B, and C, the traversal order is consistent. It is A, X, B, y, C, where, when I write a triangle, I mean recursively the traversal order of all the things in the triangle. So if you just apply the traversal order algorithm here versus here, you get the same output, which means these operations preserve traversal order.
3550	can do in a tree that won't affect any of the stuff we've done so far. It's a tool that we can use to rebalance. Notice how deep things are in the tree changes. Our problem with this linear tree is that there are some nodes of linear depth. We want to get rid of those. How? Well, we could take these edges and start rotating them up. If you look at depths, in this picture, A and B are deeper than C. And in this picture, B and C are deeper than A. So it's a trade off. This one moved up. This one moved down. This one stayed at the same depth. So hopefully, if A is too deep and C is too shallow, they can trade off like this. It may sound difficult, but in fact, there's a pretty simple way, which are called AVL trees, that maintain balance in a particular way called height balance. This is if we take the height of node.left-- actually, I'd prefer to-- node.right, minus height of node.left,
3551	I want this to always be minus 1, 0, or plus 1. So this is saying that if I have any node, and I look if its left subtree and its right subtree, I measure their heights-- remember, that's downward distance, maximum distance to a leaf-- I measure the height of this tree-- maximum height-- and I measure the maximum height of this subtree, I want these to be within 1 of each other. Ideally, they're equal. That would be the perfect case. But let's let them differ by 1. So maybe this is k and this is k plus 1. Or maybe this is k and this is k minus 1. In this picture, what is the height of this node? It's good practice. k plus 2, good. What's the longest path from this node to a leaf? Well, it could go through this subtree. And that would be length k plus 1, because it's k in here plus 1 for this edge. Or it could be through here, and that's k plus 1 plus 1. So the biggest
3552	is to go to the right. So the height-- if I told you the height of these subtrees, we can derive the height of this node.
3553	So, the first claim is that if I could maintain height balance, then I will guarantee that h equals log n. So in other words, height balance implies balance. So let's prove that first quickly. And then, the interesting part is how do we actually prove-- or how do we actually maintain the balance property? We're going to do that using rotations. But how is a big question. So why does height balance imply balance? So what this is saying is that all height balanced trees have logarithmic height. So what I'd like to think about is sort of the least balanced height balanced tree. The least balanced one is going to have every node a mismatch. Let's say the left subtree is shallower than the right subtree by 1, and recursively all the way down. So every node has a gap here, a-- what do we call it-- a skew of 1, which I'm going to write-- I'm going to introduce some notation. I'll write a dissenting rightward arrow of this one is higher than the left subtree. So
3554	the easy way to think about this is this is sort of our worst case. This is going to be the fewest nodes for the maximum depth. Let's just count how many nodes are in this tree. I'm going to write that as a recurrence, which is the number of nodes in a tree of height h. So if this whole tree has height h, as we said in this picture, if I just subtract 2 from all these numbers, then this one has height h minus 2, and this one has height h minus 1. So how many nodes are in here? Well, this is a recurrence I'm going to write. So this will be N sub h minus 2. This will be N sub h minus 1. And then I just count how many nodes are in this picture. It is Nh minus 1 plus Nh minus 2 plus 1, or this node. Now you might ask, what is Nh a recurrence for? But it is the number of nodes in this sort of worst case if the
3555	worst case has total height h. So you can also think of it as what is the minimum number of nodes I could have in an AVL tree, which is a height balanced tree, that has a height h in a height balanced tree? OK, so now I just need to solve this recurrence. This recurrence look familiar-ish? It's like Fibonacci numbers. If I remove the plus 1, it's Fibonacci. And if you happen to know the Fibonacci numbers grow as, like, a golden ratio to the n, then we know that this is exponential, which is what we want. Because if Nh is exponential in h, that means h is logarithmic in N, because log is inverse of exponential. But maybe you don't know about Fibonacci numbers. And so we can still easily show that this is exponential as follows. I want to prove that it's at least an exponential, because that gives me that h is at most logarithmic. So we need a lower bound. And so we have these two terms which are hard to compare-- Nh
3556	minus 1 and Nh minus 2. It's kind of ugly. But if we're allowed to be sloppy-- and we'll see if we're not too sloppy-- and still get an exponential answer, let's just make them equal like so. So this is a true statement, in fact, strictly greater than. Why? Because I removed the plus 1. That should only make something smaller. And I replaced Nh minus 1 with Nh minus 2. Here, I'm implicitly using a fact, which is obvious by induction, that this tree on height-- if I take this tree versus this tree, this one has more nodes than this one. If I have larger height, this construction is going to build a bigger tree, at least as big. It doesn't even need to be strictly bigger. So certainly, Nh minus 1 is greater than or equal to Nh minus 2. Now, this is 2 times Nh minus 2. And this is an easy recurrence. This is just powers of 2. I keep multiplying by 2, and subtracting 2 from h. So this solves to 2 to
3557	the h over 2, maybe with a floor or something. But I'm using a base case here, which is N sub 0 equals 1. Maybe it's a ceiling then. But the point is this is exponential. So this implies that the height is always, at most, 2 times log n. This 2 corresponds to this 2. If you just invert this formula, this was a number of nodes is going to be at least 2 to the h over 2. And so h is, at most, 2 log n. So it's not log n. That would be perfect. But it's within a factor of 2 of log n. So AVL trees are always quite balanced. Number of levels is at most double what you need to store n nodes. Great. We're left with the main magic-- not domain magic. That's different. And let's see, we're going to use subtree augmentation. Keep that. Big remaining challenge is how do we maintain this high balance property using rotations? We have all the ingredients lined up for us. We have subtree augmentation. What
3558	does that let me do? It's relevant to AVL trees. Well, it lets me store height. I need to be able to compute the height of a node. That, in general, takes linear time, because I have to look at all the downward paths-- all the leaves within that subtree. But height is a subtree property-- so, yes-- height. Why? Because-- let me just write it here-- node.height equals 1 plus max of node.left.height and node.right.height and of max. Let me put this in a box. This equation, or I guess it's an assignment operation--
3559	is the thing we've been doing over and over. When I said what is the height of this node, you just figured that out, right? You took the height of the left subtree maxed with the height of the right subtree and added 1 to account for these edges. So this is a general update rule. It matches this subtree property pattern. If I have the property of left and right, I can compute it for node. And this takes constant time to do. And so it's a subtree property. And so I can maintain, through all the things I'm doing, the height of every node. Oh by the way, whenever I do a rotation, I'm also going to have to update my subtree properties. When I rotate this edge, A does not change, B does not change, C does not change. So that's good. But x's subtree changes. It now has y. It didn't before. So we're going to have to also update the augmentation here in y. And we're going to have to update the augmentation in x.
3560	And we're going to have to update the augmentation of all of the ancestors of x eventually. So rotation is locally just changing a constant number of pointers. So I usually think of rotations as taking constant time. But eventually, we will have to do-- this is constant time locally. But we will need to update h ancestors in order to store all of-- keep all of our augmentations up to date. We'll worry about that later. All right, so great. Now we have the height of all the nodes. We can compute the skew of all the nodes, cool. We have this rotation operation. And we want to maintain this height balance property. Height of left node-- left and right of every node-- is plus or minus 1, or 0.
3561	so the only things that change the tree are when we insert or delete a new node. And the way that we implemented those so far is to add or remove a leaf. So we should still be thinking about adding or removing a leaf. The problem is, when I add a new leaf, now maybe this tree is higher than it used to be. So some node here may no longer be height balanced. But because height is a subtree property, the only nodes we need to check are the ones up this ancestor path. And there's only log n of them, because now height is log n. That's what we just proved as long as we have this property. Now, we right now don't have it for, like, maybe these few nodes. But it was long n before. It's at most log n-- 2 log n plus 1 right now, because we just added a node. So what I want to do is check all of these ancestor nodes in sequence from bottom up, and find one that's
3562	out of balance. So let's take the lowest out of balance node. I'm going to call that x. Now, because we just insert or deleted a single leaf, it's only out of balance by 1, because we only changed height-- one height went up by 1, or one height went down by 1. And before, all of our skews were plus or minus 1, or 0. So now, it's-- the bad case is when it's plus or minus 2. If it happens to still be in this range for all the nodes, we're happy. But if it's outside this range, it's only going to be out by 1. So this means the skew is n plus 2 or minus 2. And let's say that it's 2 by symmetry. So my picture is-- I'm going to draw double right arrow
3563	OK, so that's bad and we want to fix it. The obvious thing to do is to rotate this edge. Because that'll make this-- this is too high and this is too low. So if we rotate, this should go down by 1 and this should go up by 1. And that works most of the time. So case one is the skew of y. What is y? I want y to be the right child of x. Because we have a positive skew, we know there is a right child. Now, because this was the lowest bad node, we know that y is actually good. It's either right heavy-- or even the two subtrees have the same height-- or left heavy. The easy cases are when skew of y is either 1 or 0, which I will draw. So a double right arrow, let's say single right arrow-- so I'm just going to add some labels here to make this picture consistent-- k plus 1, k plus 2. I'm riding the heights. So this is an example where C
3564	is taller than B. A and B are the same height. And then if you compute the heights up here, indeed this one is right leaning. This one is doubly right leaning. Because this one has height k plus 1. This one has height k minus 1. That's bad. But if we do this right rotation on x, we get exactly what we want. So I'm just going to copy the labels on A, B, C-- we have k minus 1, k minus 1, and k-- and then recompute. That means this guy has height k, this one has height k plus 1. And now, all the nodes in this picture that I've highlighted-- A, B, and C haven't changed. They were height balanced before. They still are. But now, x and y-- x wasn't height balanced before, y was. Now, both x and y are height balanced. That's case one. In case two, the skew of y is flat, which means that this is a k, and this is a k, and this is a k plus 1, and
3565	this is a k plus 2. But still, all the nodes are balanced-- height balanced. They're still plus or minus 1. So those are the easy cases. Unfortunately, there is a hard case-- case three. But there's only one, and it's not that much harder. So it's when skew of y is minus 1. In this case, we need to look at the left child of y. And to be alphabetical, I'm going to rename this to z. So this one, again, is double right arrow. This one is now left arrow. And this is letter y. And so we have A, B, C, and D potential subtrees hanging off of them. And I'm going to label the heights of these things. These are each k minus 1 or k minus 2. This one's k minus 1. And now, compute the inside. So this is going to height k for this to be left leaning. So this is k plus 1, and this is k plus 2. But the problem is this is 2 higher than this. The height of
3566	"z is 2 higher than the height of A. This case, if I do this rotation, things get worse, actually. I'll just tell you the right thing to do is-- this is the one thing you need to memorize. And let me draw the results. You can also just think of it as redrawing the tree like this. But it's easier from an analysis perspective to think about it as two rotations. Then we can just reduce. As long as we know how rotations work, then we know that this thing works-- ""works"" meaning it preserves traversal order and we can maintain all the augmentations. So now, if I copy over these labels-- the height labels-- I have k minus 1. I have, for these two guys, k minus 1 or k minus 2. The biggest one is k minus 1. This is k minus 1. And so this will be k. This will be k. This will be k plus 1. And lo and behold, we have a nice, height balanced tree in all three cases for this one"
3567	node. Now, this was the lowest node. Once we update this one, it could be that we changed the height of the root. Before it was k plus 2, now it's k plus 1. Or sometimes, we keep it the same, like over in this case. And so now, we have to check the parent. Maybe the parent is out of balance. And we just keep walking up the node, and also maintain all the augmentations as we go. Then, we'll keep track of height and subtree size if we want them, or any other augmentations. And after order h operations, we will have restored height balanced property, which means all the way through, h equals order log n. And so all of our operations now are magically order log n.
3568	[SQUEAKING] [RUSTLING] [CLICKING] ERIK DEMAINE: All right, welcome back to 006 Data Structures. Today, we're going to cover a different kind of tree-like data structure called a heap-- a binary heap. It's going to let us solve sorting problem in a new way. Let me first remind you of a portion-- the problem we're going to be solving today is called priority queue. This is the interface. We'll see several data structures,
3569	And this is a subset of the set interface. And subsets are interesting because, potentially, we can solve them better, faster, simpler, something. And so you'll recognize-- you should recognize all of these operations, except we didn't normally highlight the max operation. So here, we're interested in storing a bunch of items. They have keys which we think of as priorities. And we want to be able to identify the maximum priority item in our set and remove it. And so there's lots of motivations for this. Maybe you have a router, packets going into the router. They have different priorities assigned to them. You want to route the highest priority first. Or you have processes on your computer trying to run on your single threaded-- single core, and you've got to choose which one to run next. And you usually run higher priority processes first. Or you're trying to simulate a system where events happen at different times, and you want to process the next event ordered by time. All of these are examples of the priority queue interface.
3570	We'll even see applications within this class when we get to graph algorithms. But the main two things we want to be able to support are inserting an item, which includes a key, and leading the maximum item, and also returning it at the same time. We'll also talk some about being able to build the structure faster than just inserting it. But of course, we could implement build by starting empty and repeatedly inserting. And also the complexity of just finding the max without deleting it, this you could simulate with these two operations by deleting the max and then reinserting it, which works. But often, we can do faster. But the two key, main operations are insert and delete max. And we're going to see a few data structures to do this. Any suggestions among the data structures we've seen in this class? What should we use to solve priority queue interface? Many possible answers.
3571	ERIK DEMAINE: Sequence AVL? Ooh, that's interesting! Sequence AVL is a good answer, but maybe the fancier version. Yeah? AUDIENCE: Set AVL? ERIK DEMAINE: Set AVL sounds good. Set AVL supports these operations and many more. All in log n time except for build, which takes n log n time because you have to sort first. So set AVL a good way to do this. We'll come back to your sequence AVL idea later. This gets log n for operation. Great. I mean, this is-- set AVL is our most powerful data structure. It does all the operations we care about on the set side. And the sequence AVL does all the operations on the sequence side. But note that this is a set, not a sequence. We care about keys. There are hacks to get around that with sequence AVLs, but let's do that later. So great, if we wanted to, for example, speed up find_max in a set AVL. We could add augmentation. We could-- remember subtree property augmentations? We can use that to get constant time find_max
3572	by storing in every node the maximum key item within the subtree. And that's a subtree property. It's one we mentioned last class. So we could even improve that to cut some time. Great. So we're done. End of lecture. [CHUCKLES] In some sense, that's true. But what we're going to see today is another data structure called a binary heap, which is, in some sense, a simplification of set AVL. It achieves basically the same time bounds. Build will be faster by a log factor. But that's not the main reason we care about them. The main advantage is that they're simpler and they give us an in-place sorting algorithm.
3573	I've been talking about-- build, insert, and delete_max. So we have set AVL trees there-- n log n build, log n insert, log n delete. So along the way to our heap, I want to mention two other data structures. One is a dynamic but unsorted array. And the other is a dynamic sorted array. These are simpler data structures we've talked about many times before. And they're useful kind of motivations for getting started, because a heap is going to be built on top of arrays instead of-- well, it's sort of a fusion between arrays and trees. So if I have an unsorted array, this is very easy to insert into, right? I just append to the end. This is what we called insert last. So insert is fast, constant amortized. We might have to resize the array, but so that's the amortized part. But delete max is slow. In an unsorted array, I don't know where the maximum is. So I have to scan through the whole array. So I scan through the array, identify that the
3574	max is somewhere in the middle, and then, if I want to delete it-- I want to delete that maximum element, well, in a dynamic array, all I can really do is delete the last element efficiently. So I could, for example, swap it with the last element. So I take this element and put it here, and then delete the last element in that array, which is pop in Python or delete_last in our world. So overall, this is linear time, which is bad. But I wanted to highlight exactly how it's done for a reason we'll get to in a moment. A sorted array is sort of the reverse. It's very easy to find the max. Where is it? At the end. delete_max, the maximum element is always the last element in a increasing sorted array. I guess that's constant amortized, because then I have to delete it, which may incur resizing. Insert, though, is going to be linear, because maybe I can binary search to find where the added item belongs. Let's say I just added this
3575	item here. I could binary search to find it, but then I'm going to have to do a big shift. So I might as well just swap repeatedly until I find the position where the added item x belongs. And now I've restored sorted order. That takes linear time, which is bad. And what we want is somehow the best of these two worlds. Insert is fast for array. Delete is fast for a sorted array. We can't get constant time for both. But we can get log n time for both. We already know how with set AVL trees. But we're going to see a different way to do it today. And the main motivation for a different way to do this is sorting. So I want to define a priority queue sort. So given any data structure that implements a priority queue interface, in particular insert and delete_max, I can make a sorting algorithm. What do I do? Insert all the items, delete all the items. But because when I delete them they come out largest first, I
3576	get them in reverse sorted order. Then I could reverse in linear time and I've sorted my items. So we can insert (x) for x in A, or (build(A)), and then repeatedly delete_max. How much time does this algorithm take? I'm going to introduce some notation here. It takes however long it takes to build n items, call that T sub build (n) plus-- sorry-- plus n times the time to do a delete_max. Or we can write this as n times time to do an insert, plus time to do a delete_max. So I'm using these T functions to just abstract what are the running times provided by my data structure that implements this interface. Interface says what's correct is, and these T functions give me my performance bounds. So if I plug in each of these data structures, I get a sorting algorithm. I get AVL sort, I get array sort, I get assorted array sort. What do those look like? It turns out many of these are familiar. So set AVLs take log n per operation. So
3577	we get an n log n sorting algorithm out of them, which is insert all of the items into the AVL tree. I don't want to use AVL build because that uses sort, and not allowed to sort in order to implement sort. But we saw how to insert into an AVL tree and keep the thing balanced. So that takes log n each. And then we can find the max, delete it, rebalance, and so on. Total time will be n log n. This is an algorithm we call AVL sort. It's a bit complicated, because AVL trees are complicated. But it gives us optimal comparison bound and log n. Now, what about array sort? So suppose I use an unsorted array. I insert the item. So if I insert the items-- so I'm doing all the insertions here before all the deletions. So what's going to happen is I just insert the items in the original array order. In other words, I just take the array. And then what I do is repeatedly extract the maximum item by
3578	searching for it, moving it to the end of the array, and then repeating that process. That sound familiar? That's selection sort from lecture three. So this-- arrays give us selection sort. This is a new way to think about what we were doing way back then. With a sorted array, what are we doing? We insert all the items. That's actually where all the work happens, because we maintain the sorted array. So we start with an empty array. It's sorted. We add an item. OK, it's still sorted. We add a second item, and we swap if we need to in order to sort. In general, when we add an item, we swap it to the left until it's sorted again. That is insertion sort. Kind of cool, this is a unifying framework for three sorting algorithms that we saw before. We didn't actually talk about AVL sort last time, but it was in the notes. And so that is the right part of this table.
3579	They take linear time for some of the operations. So the sorting algorithms are not efficient. But they're ones we've seen before, so it's neat to see how they fit in here. They had the-- selection sort and insertion sort had the advantage that they were in place. You just needed a constant number of pointers or indices beyond the array itself. So they're very space efficient. So that was a plus for them. But they take n squared time, so you should never use them, except for n, at most, 100 or something. AVL tree sort is great and then it gets n log n time, probably more complicated than merge sort and you could stick to merge sort. But neither merge sort nor set AVL tree sort are in place. And so the goal of today is to get the best of all those worlds in sorting to get n log n comparisons, which is optimal in the comparison model, but get it to be in place. And that's what we're going to get with binary heaps. We're
3580	going to design a data structure that happens to build a little bit faster-- as I mentioned, linear time building. So it's not representing a sorted order in the same way that AVL trees are. But it will be kind of tree-based. It will also be array-based. We're going to get logarithmic time for insert and delete_max. It happens to be amortized, because we use arrays. But the key thing is that it's an in-place data structure. It only consists of an array of the items. And so, when we plug it into our sorting algorithm-- priority queue sort or generic sorting algorithm-- not only do we get n log n performance, but we also get an in-place sorting algorithm. This will be our first and only-- to this class-- n log n in-place sorting algorithm. Cool. That's the goal.
3581	So what we're going to do, because we're in place, basically we have to have an array storing our end items. That's sort of the definition of in-place, just using n slots of memory exactly the size of the number of items in our structure. But we're obviously not going to use a regular unsorted array or a regular sorted array. We're going to use array just as sort of the underlying technology for how things are stored. But we'd really like logarithmic performance, which should make you think tree. Only way to get a log is the binary tree, more or less. So somehow, we want to embed a tree into an array. Let me grab an example.
3582	Let me draw a tree. If I got to choose any old tree I want, I would choose a tree that's basically perfectly balanced. Perfectly balanced would be like this, where-- what's the property? That I have all of these levels-- all of these depths are completely filled with nodes. This is depth 0. Remember, this is depth 1, this is depth 2, this is depth 3. So what I'd really like is to have 2 to the i nodes at depth i. That would be a perfect binary tree. But that only works when n is 1 less than a power of 2, right? I can't always achieve that for any n. And so the next best thing I could hope for is 2 to the i at nodes at depth i until the very last i-- the largest depth. And in that level, I'm still going to restrict things. I'm going to force all of the nodes to be as far left as possible.
3583	I'll call them left justified. And these two properties together is what I call a complete binary tree. Why is this interesting? Because I claim I can represent a tree like this as an array. I've narrowed things down enough that I can draw an array down here. And what I'm going to do is write these nodes in depth order. So I write A first, because that's step 0. Then B, C, that's step 1. Then, well, they're alphabetical. I made it that way. D, E, F, G is depth 2. And then H, I, J is step 3. This is very different from traversal order of a tree. Traversal order would have been H, D, I, B, J, E, A, F, C, G, OK? But this is what we might call depth order, do the lowest depth nodes first-- very different way to lay things out or to linearize our data. And this is what a heap is going to look like. So the cool thing is, between complete binary trees and arrays is a bijection. For every
3584	array, there's a unique complete binary tree. And for every complete binary tree, there's a unique array. Why? Because the complete constraint forces everything-- forces my hand. There's only-- if I give you a number n, there is one tree shape of size n, right? You just fill in the nodes top down until you get to the last level. And then you have to fill them in left to right. It's what you might call reading order for writing down nodes. And the array is telling you which keys go where. This is the first node you write down at the root, this is the next node you write down at the left child of the root, and so on. So here we have a binary tree represented as an array, or array representing a binary tree. The very specific binary tree, it has a clear advantage, which is it is guaranteed balance. No rotations necessary in heaps, because complete binary trees are always balanced. In fact, they have the best height they possibly could, which is ceiling of
3585	log n. Balanced, remember, just meant you were big O of log n. This is 1 times log n. So it's the best level of balance you could hope for. So somehow, I claim, we can maintain a complete binary tree for solving priority queues. This would not be possible if you were trying to solve the whole set interface. And that's kind of the cool thing about heaps, is that by just focusing on the subset of the set interface, we can do more. We can maintain this very strong property. And because we have this very strong property, we don't even need to store this tree. We're not going to store left and right pointers and parent pointers, we're just going to store the array.
3586	basically means no pointers, just an array of the n items. How are we going to get away without storing pointers? I'd still like to treat it like a tree. I'd still like to know the left child of B is D and the right child B is E. We'll see why in a moment. Well, we can do this with index arithmetic. So maybe I should add some labels before I get there. So this array naturally has indices. This is index 0. This is index 1, index 2, index 3, index 4, index 5, index 6, 7, 8, 9, because there are 10 items, 0 through 9. And I can apply those labels up here, too. These are the same nodes, so 0, 1, 2. This is just a depth order. But once I have this labeling, it's going to be a lot easier to figure things out. So if I wanted to know the left child of B is D, somehow, given the number 1, I want to compute the number 3. Add 2, there are all
3587	sorts-- multiply by 3, there are all sorts of operations that take 1 and turn it into 3. But there's only one that's going to work in all cases. And the intuition here is, well, I have to 2 the i nodes at level i. If I want to go to the child level, there's 2 to the i plus 1 nodes down there-- exactly double. So it's the very last one, but that won't really matter. If there is a left child, it will behave the same. And so, intuitively, I have this space of size 2 to the i. I have to expand it to a space of size 2 to the i plus 1, So I should multiply by 2. And that's almost right, but then there's some constants. So I'd like to say 2 times i. But if we look at the examples here, 1 times 2 is 2, which is 1 less than 3. 2 times 2 is 4, which is 1 less than 5. Hey, we almost got it right. It's just off by
3588	1. Off by 1 is-- index errors are the most common things in computer science. What about the right child? If the left child is a 2i plus 1, where is the right child? I hear lots of mumbles. 2i plus 2-- one more. Because we're writing things left to right in depth order, the right child is the right sibling of the left child. So it's just one larger, OK? Given those rules, we can also compute parent. It's just whatever is the inverse of both of these functions, which I want to divide by 2 at some point. I want to get back to i given 2i plus 1 or given 2i plus 2. And so if I subtract 1 from i, then I either get 2i or 2i plus 1. And then, if I take an integer division by 2, I get i-- the original i. Sorry, maybe I'll call this j to be clearer. So j is the left or right child. Then I can reconstruct i, which was the parent. So this is constant number
3589	arithmetic operations. So I don't have to store left and right pointers. I can just compute them whenever I need them. Whenever I'm at some node like E, and I want to know what's its left child-- sorry, given the node index 4, which happens to contain the item E, and I want to know what's its left child, I just multiply by 2 and add 1. I get 9. And then, I can index into this array at position 9. Because I don't-- this is just in my head, remember. We're just thinking that there's a tree here. But in reality, on the computer, there's just the array. So if we want to go from E to J, we can, from 4 to 9. If we go try to go to the right child, we multiply by 2. 8 add 2-- 10. And we see, oh, 10 is beyond the end of the array. But our array stores its size, so we realize, oh, E does not have a right child. This is something you can only do in
3590	a complete binary tree. In a general binary tree you don't have these nice properties. Cool, so this is basically a heap. I just need to add one more property, naturally called the heap property.
3591	So there are multiple types of heaps. This type of heap is called a binary heap. We will talk about others in future lectures. I'm going to call it Q. Explicit thing-- this is an array representing a complete binary tree, called the array Q. And we want every node to satisfy the so-called max-heap property, which says Q[i] is greater than or equal to Q[j] for both children left of i and right of i. So we have a node i. And it has two children-- 2i plus 1 and 2i plus 2. These are two values of j. What we want is a greater than or equal to relation here and here. So this node should be bigger than both this one and this one. Which of these is larger? We don't know, and we don't care-- very different from binary search trees or set binary trees, where we said these guys were less than or equal to this one, this one was less than or equal to all the nodes in the subtree here. We're just locally
3592	saying, this node is greater than or equal to this node and this node. So the biggest is at the top. So one nice lemma about these heaps-- this is weird. Let me give you some more intuition. If you are a binary heap, if you satisfy this max-heap property everywhere, then in fact, you learn that every node i is greater than or equal to all nodes in its subtree. These are what we call descendants in subtree of i. Let me look at this example. So I haven't written any numbers here. You can imagine. So A here is greater than or equal to both B and C, and B is greater than or equal to D and E, and C is greater than or equal to F and G, D is greater than or equal to H and I, and E is greater than or equal to J. That would make this structure a heap, not just a complete binary tree. So what does that imply? It implies that A must be the maximum. So you look
3593	at any node here, like J, A is greater than or equal to B is greater than or equal to E is greater than or equal to J. And in general, what we're saying is that A is greater than or equal to all nodes in the tree. B is greater than or equal to all nodes in its subtree down here. C is greater than or equal to all nodes in its subtree. That's what this lemma is saying. You can prove this lemma by induction. But it's really simple. If you have two nodes, i and j, and j is somewhere in the subtree, that means there's some downward path from i to j. And you know that, for every edge we traverse on a downward path, our key is going down non-strictly. So every child is less than or equal to its parent. i is greater than or equal to this, is greater than or equal to this, is greater than or equal to this, is greater than or equal to j, OK? So by transitivity of
3594	less than or equal to, you know that i is, in fact, greater than or equal to j. Or sorry, the key in i is greater than or equal to the key in j. This is what we're calling i, the index. This is what we would call Q of i. This is Index j Q of j. Very different way to organize keys in a tree, but as you might imagine, this is going to be good for priority queues. Because priority queues just need to find the maximum elements. Then they need to delete it. That's going to be harder, because leading the root is, like-- that's the hardest node to delete, intuitively. I'd really prefer to delete leaves. But leading leaves and keeping a complete binary tree is actually kind of hard. If I want to delete H, that doesn't look like a binary tree, or it doesn't look like a complete binary tree anymore. It's not left justified. Similarly, if I want to delete F, that's bad. Because now, I don't have four nodes here. The
3595	one node that's easy to delete is J, right? If I remove that node, I still have a complete tree. The last leaf, the last position in my array, is the one that's easy to delete. That's good, because arrays are good at leading the last item. But what I've set up here is it's easy to find the max. It's going to be up here at the root. Deleting it is annoying. I'd like to somehow take that key and put it at position-- at the last position at the last leaf, because that's the one that's easy to delete. And that's indeed what we're going to do in a delete algorithm. Let me first do insert. I guess that's a little simpler, kind of symmetric to what we just said. So if I want to insert a key or an item x which has some key, again, the only thing I really can do in an array-- if I want to add a new item, it has to go at the end. The only thing we know how
3596	to do is insert at the end of an array. This is what we called insert_last. this? Corresponds to adding a node containing x-- the item x-- in the very last level of the complete binary tree. Either it goes to the right of all the existing nodes, or starts a new level. But it's always going to be the last leaf. After we do the insertion, it will be at position size of Q minus 1. This is probably not enough, though. We just inserted an arbitrary item in a leaf. And now, it may not satisfy the max-heap property anymore. So let's just check if it does, and if it doesn't, fix it. That's what we know how to do. But this time, we're not even going to need rotations, which is cool. So I'm going to define an operation called max_heapify_up. This will make things more like a max-heap. We're going to start at size of Q minus 1 for our value i. But it's going to be recursive, so what we're going to do is look
3597	at a node i, in particular the one that just got inserted. And where could it violate things? Well, with its parent, because we have no idea what key we just put here. Maybe it's less than our parent. Then we're happy. But if it's greater than our parent, we're in trouble and we should fix it. So if the item in the parent's key is less than i's key-- ah, I see I forgot to write key and all these spots. This should be dot key and dot key, because Q[i] is an item that gets its key. So this is the bad case. This is if the parent is smaller than the child. We wanted the parent to always be greater than or equal to its children. So in that case, what could we do? Swap them. Let's swap Q parent of i-- excellent, more chalk-- with Q[i]. Now they're in the right order. Now, we need to think about what about the other child of that node? And what about its parent? So I have some numbers
3598	here. Let's say this was 5 and this was 10. What do I know about this picture before? Well, I know that 10 is this newly inserted item. It's the only one that could have caused violations when I first inserted it. So I know that before this-- before I moved 10 around, I knew all the things in this left subtree are less than or equal to 5, and everything up here are created equal to 5. I also know that the nodes in here, in fact, were less than or equal to 5. Other than this node 10 that we just inserted, this was a correct heap. So 5 was a separator between-- things above it on the ancestor chain are greater than or equal to 5, and things in its subtree are less than or equal to it. So after I do this swap, which I'm just going to do-- after I swap the items 5 and 10, 10 is up here, 5 is here. And now, I realize, OK, great, this edge is happy, because now
3599	10 is greater than or equal to 5. But also this edge is happy, because it used to be happy, and we only made its parent larger. Now this edge maybe is bad. And so we need to recurse-- recurse on the parent. But that's it. So we fixed this one edge. Initially, this happens way down at the leaf. But in general, we're taking our item that we inserted, which is x, and it starts at the last leaf, and it may be bubbles up for a while. And maybe it gets all the way to the root if we inserted a new maximum item. But in each step, it goes up one. And so the running time of all this stuff is the height of the tree, which is log n. And because there's only this one item that could potentially be wrong, if it ever stops moving, we've just checked that it satisfies the max-heap property. If it gets to the root, you can also check it satisfies the max-heap property. So there's a base case I
3600	didn't write here, which is if i equals 0, we're at the root, we're done. And then you can prove this correct by induction. There's just one item that's in the wrong spot, initially. And we put it into a right spot. There are many places it could go, but we will move it to the, I guess, unique ancestor position that is correct-- that satisfies max-heap property, OK? So that's insert.
3601	sorry, delete_max, thank you. You can of course define all of these things for min instead of max. Everything works the same. I just have a hard time remembering which one we're doing. Just don't switch you can't use a max-heap to do delete_min. You can't use a min-heap to do delete_max, but you can use a min-heap to do delete_min. That's fine. So like I said, the only node we really know how to delete is the last leaf on the last level, which is the end of the array. Because that's what arrays can delete efficiently. And what we need to delete is the root item, because that's always the maximum one, which is at the first position in the array. So what do we do? Swap them, our usual trick. I think the cool thing about heaps is we never have to do rotations. We're only going to do swaps, which is something we had to do with trees also-- binary trees. Q[0] with Q of the last item-- great, done. Now we have the last item
3602	is the one we want to delete. So we do delete_last, or pop in Python, and boom, we've got-- we've now deleted the maximum item. Of course, we may have also messed up the max-heap property just like we did with insert. So with insert, we were adding a last leaf. Now, what we're doing is swapping the last leaf with the-- I'm pointing at the wrong picture. Let me go back to this tree. What we did is swap item J with A. So the problem is now-- and then we deleted this node. The problem is now that that root node has maybe a very small key. Because the key that's here now is whatever was down here, which is very low in the tree. So intuitively, that's a small value. This is supposed to be the maximum value, and we just put a small value in the root. So what do we do? Heapify down. We're going to take that item and somehow push it down to the tree until the-- down in the tree until max-heap
3603	property is satisfied. So this is going to be max_heapify_down. And we will start at position 0, which is the root. And max_heapify_down is going to be a recursive algorithm. So we'll start at some position i. And initially, that's the root. And what we're going to do is look at position i and its two children. So let's say we put a very small value up here, like 0. And let's say we have our children, 5 and 10. We don't know-- maybe I'll swap their order just to be more generic, because that looks like not quite a binary search tree, but we don't know their relative order. But one of them is greater than or equal to the other in some order. And so what would I like to do to fix this local picture? Yeah, I want to swap. And I could swap-- 0 is clearly in the wrong spot. It needs to go lower in the tree. I can swap 0 with 5 or 0 with 10. Which one? 10. I could draw the picture
3604	with 5, but it will not be happy. Why 10? We want to do it with the larger one, because then this edge will be happy, and also this edge will be happy. If I swapped 5 up there instead, the 5/10 edge would be unhappy. It wouldn't satisfy the max-heap property. So I can do one swap and fix max-heap property. Except that, again, 0 may be unhappy with its children. 0 was this one item that was in the wrong spot. And so it made it have to go farther down. But 5 will be-- 5 didn't even move. So it's happy. Everything in this subtree is good. What about the parent? Well, if you think about it, because everything was a correct heap before we added 0, or before we put 0 too high, all of these nodes will be greater than or equal to 10 on the ancestor path. And all of these nodes were less than or equal to 10 before, unless you're equal to 5. So that's still true. But you see, this tree
3605	is happy. This tree still may be unhappy. 0 still might need to push down farther. That's going to be the recursion. So we check down here. There's a base case, which is if i is a leaf, we're done. Because there's nothing below them. So we satisfy the max-heap property at i because there's no children. Otherwise, let's look at the leaf among the left-- sorry, left not leaf-- among the two children left and right of i. Right if i might not exist. Then ignore it. But among the two children that exist, find the one that has maximum key value, Q[j].key. That was 10 in our example. And then, if these items are out of order, if we do not satisfy-- so greater than would be satisfy. Less than Q[j] would be the opposite of the max-heap property here. If max-heap property is violated, then we fix it by swapping Q[i] with Q[j], and then we recurse on j-- call max_heapify_down of j. That's it. So pretty symmetric. Insert was a little bit simpler, because we only
3606	have one parent. Delete_min, because we're pushing down, we have two children. We have to pick one. But there's a clear choice-- the bigger one. And again, this algorithm-- this whole thing-- will take order h time, the height of the tree, which is log n, because our node just sort of bubbles down. At some point, it stops. When it stops, we know the max-heap property was satisfied there. And if you check along the way, by induction, all the other max-heap properties will be satisfied, because they were before. So almost forced what we could do here. The amazing thing is that you can actually maintain a complete binary tree that satisfies the max-heap property. But once you're told that, the algorithm kind of falls out. Because we have an array. The only thing we can do is insert and delete the last item. And so we've got to swap things to there in order-- or out of there in order to make that work. And then, the rest is just checking locally that you can fix the
3607	property. Cool. So that's almost it, not quite what we wanted. So we now have log n amortize insert and delete_max in our heap. We did not yet cover linear build. Right now, it's n log n if you insert n times. And we did not yet cover how to make this an in-place sorting algorithm. So let me sketch each of those. I think first is in-place. So how do we make this algorithm in-place? I guess I want that, but I don't need this. So we want to follow priority queue sort. Maybe I do want that. But I don't want to have to grow and shrink my array. I would just like to start with the array itself. So this is in place. So what we're going to do is say, OK, here's my array that I want to sort. That's given to me. That's the input to priority queue sort. And what I'd like is to build a priority queue out of it. Initially, it's empty. And then I want to insert the items one at
3608	a time, let's say. So in general, what I'm going to do is maintain that Q is some prefix of A. That's going to be my priority queue. It's going to live in this sub array-- this prefix. So how do I insert a new item? Well, I just increment. So to do an insert, the first step is increment size of Q. Then I will have taken the next item from A and injected into this Q. And conveniently, if we look at our insert code, which is here, the first thing we wanted to do was add an item at the end of the array. So we just did it without any actual work, just conceptual work. We just said, oh, our Q is one bigger. Boom! Now this is at the end of the array. no more amortization, in fact, because we're not ever resizing our array, we're just saying, oh, now Q is a little bit bigger of a prefix. It just absorb the next item of A. Similarly, delete_max is going to, at the end,
3609	decrement the size of Q. Why is that OK? Because at the end of our delete_max operation-- not quite at the end, but almost the end-- we deleted the last item from our array. So we just replaced that delete last with a decrement, and that's going to shrink the Q by 1. It has the exact same impact as leading the last item. But now, it's constant time, worst case not amortized. And the result is we never actually build a dynamic array. We just use a portion of A to do it. So what's going to happen is we're going to absorb all the items into the priority queue, and then start kicking them out. As we kick them out, we kick out the largest key item first, and we put it here, then the next largest, then the next largest, and so on. The minimum item is going to be here. And, boom, it's sorted. This is the whole reason I did max-heaps instead of min-heaps, is that in the end, this will be a upward sorted
3610	array with the max at the end. Because we always kick out items at the end. We delete the max first. So that is what's normally called heapsort. You can apply this same trick to insertion sort and selection sort, and you actually get the insertion sort and selection sort algorithms that we've seen which operate in prefixes of the array. Cool, so now we have-- we've achieved the y up there, which is n log n sorting algorithm that is in-place. So that was our main goal-- heapsort. Let me very quickly mention you can build a heap in linear time with a clever trick. So if you insert the items one at a time, that would correspond to inserting down the array. And every time I insert an item, I have to walk up the tree. So this would be the sum of the depth of each node. If you do that, you get n log n. This is the sum over i of log i. That turns out to be n log n. It's a log of
3611	n factorial. The cool trick is to, instead, imagine adding all the items at once and not heapifying anything, and then heapify up-- sorry, heapify down from the bottom up. So here we're heapifying up. Now, we're going to heapify down. And surprisingly, that's better. Because this is the sum of the heights of the nodes. And that turns out to be linear. It's not obvious. But intuitively, for a depth, this is 0, this is log n, and we've got a whole ton of leaves. So right at the leaf level, you can see, we're paying n log n, right? Because there are n of them, and each one costs log n. Down here, at the leaf level, we're paying constant. Because the height of the leaves are 1. Here, the height of the root is log n. And this is better. Now we're paying a small amount for the thing of which there are many. It's not quite a geometric series, but it turns out this is linear. So that's how you can do linear building heap. To
3612	come back to your question about sequence AVL trees, turns out you can get all of the same bounds as heaps, except for the in-place part, by taking a sequence AVL tree, storing the items in an arbitrary order, and augmenting by max, which is a crazy idea. But it also gives you a linear build time. And yeah, there's other fun stuff in your notes. But I'll stop there.
3613	[CREAKING] [CLICKING] [SQUEAKING] [RUSTLING] [CLICKING] JUSTIN SOLOMON: We just started a new unit on graph theory, which is going to be sort of our focus for the next couple of lectures in 6006.
3614	at the beginning the lecture because, as usual, I've muddled together a lot of notions in our previous lecture, and then start with some new ideas. So basically, in our previous lecture, we talked about an algorithm called breadth-first search. And then almost always you see that paired with a second algorithm called depth-first search. And following tradition, and basically logic, we'll do the same thing in 006 today. But in any event, for today we'll stick to the technical material. So as a little bit of review, I guess actually,
3615	was actually draw a graph. So we should probably start with that. So if you recall, graph is a collection of nodes or vertices depending-- I don't know, is it like a European American thing or something-- and edges. So here's an example, which as usual, I'm not managing to draw particularly clearly. So this graph is kind of like a cycle. So I have directed edges here, here, here, and here. And of course, there are many kind of variations on the theme, right?
3616	is that we have some set V, which is like the set of vertices. And then we have a set E, which is set of edges. And this was a subset of V cross V. And this is nothing more than fancy notation for saying that an edge is a pair of vertices, like a from and a to vertex. Of course, there are many variations on this theme. You could have a directed versus an undirected graph. So this one is directed, meaning the edges look like arrows. If they didn't have arrowheads, they'd be undirected. We define something called a simple graph where you have essentially no repeated edges. So for instance, you can't do something like this where you have the same edge twice. And then there are a couple of different definitions that were kind of useful. So in particular-- I'm going to erase this, whoops-- useless edge here. Maybe make my graph slightly more interesting. So add another edge going in the reverse direction. So maybe I have-- I'm going to give my vertices labels.
3617	x, y, z, and w. Then we talked about the neighbors of a given vertex, which are the vertices that you can reach by following edges in or out of your vertex.
3618	which we sort of implicitly defined in our previous lecture but didn't call it out, we're going to notate with Adj+. And these are all of the things that you can reach by going out of a vertex into the next one. So for example, Adj+ of w is going to be the set of vertices. We'll notice I can get from w to y and also from w to z. Yeah. So. Nope, nope. y comma z. OK. So to continue just our tiny amount of review for the day, remember that a graph-- there are many different ways to represent a graph. The sort of brain dead one would be just like a big long list of edges. But of course, for our algorithms it's not a particularly efficient way to check things like, does this edge exist in my graph. So the basic representation that I think we're mostly working from in this course is to think of a graph like a set of vertices, each of which maps to another set of vertices. So roughly every
3619	vertex maybe stores its outgoing set of edges. And so this is kind of nice because, of course, very quickly we can answer questions like, is this edge inside of our graph? Or we can iterate over the neighbors of a vertex and so on, which are the kind of typical things that we do in a lot of graph algorithms.
3620	we started talking about paths. So a path is like a chain of vertices that can get me from one vertex to the other only following edges of my graph. There is a term that I think I forgot to define last time because it didn't really matter a ton, which is a simple path, which is just a path that doesn't have the same vertex more than once. And then, of course, there are many different questions you could ask about a graph that are basically different problems involving computing paths. So for instance, the shortest path between two vertices is sort of our canonical one in graph theory. Or you could ask questions about reachability and so on. So there's our basic review from our previous lecture. Does our course staff have any questions about things so far? Excellent. OK. And there's one additional piece of terminology that I fudged a little bit last time-- or rather, my co-instructor suggested a bit of an attitude adjustment. So I thought I'd better clarify really quick. There's this interesting phrase,
3621	linear time, which we all know and love in computer science theory. And this sort of implicit thing, especially in this course, is that when we say linear time, we mean in the size of the input. Right? And so if we have a linear time graph algorithm, well, how much space does it take to store a graph? Well, we need a list of vertices and a list of edges, if nothing else. So a reasonable way to interpret this phrase linear time is that it's an algorithm that looks like what we've shown on the screen. The times proportional to maybe the sum of the number of vertices and the number of edges. If that makes you uncomfortable like it does for me because one of these can kind of scale on the other, I think it's always fine to add more detail. Right? So if you want to say, linear in the sum of the number of vertices and edges, that's perfectly fine. But if you see this phrase, that's how you should interpret it. Hopefully that's
3622	a fair way to put it. Excellent. OK.
3623	search-- BFS, for those in the know. Breadth-first search is an algorithm. And the reason we use the word breadth is because it's kind of, remember, we talked about level sets last time because we talked about breadth-first search in the context of computing shortest paths. And in particular, we have our source node all the way on the left-hand side. And then breadth-first search constructed all the nodes that were distance 1 away. Right. That's the first level set, and then all the distance 2 away, and then all the distance 3 away, and so on. So in particular, the level set L3 isn't visited until we're completely done with level set L2.
3624	is called depth-first search, which doesn't do that, but rather, starts with its first vertex and just starts walking all the way out until it can't do that anymore. And then it kind of backtracks. That's one way to think about it. And so somehow, in breadth-first search, we're like, drawing concentric circles. In depth-first search, we're doing the opposite. We're like, shooting outward until we reach the outer boundary, and then exploring the graph that way. OK. And these are sort of the two extremes in terms of graph search kind of techniques that are typically used under the basic building blocks for algorithms in graph theory. So in order to motivate and think about depth-first search, we're going to define a second problem, which is closely related to shortest path, but not exactly the same. And that's the reachability problem. So here I have the world's simplest directed graph. So the black things are the edges. And the circles are the nodes or the vertices. And I've marked one special node in blue. And his name is the
3625	source node. And now the question I want to ask is, what are all of the other nodes in my graph that I can reach by following edges-- directed edges-- starting with the source? So obviously, I can get to the node in the lower right, no problem. And of course once I get there, I can traverse and edge upward to get to that second green vertex. Notice that I was really sneaky and evil, and I drew edges in this graph that might make you think that the red node is reachable. The red one being on the upper left. I'm realizing now that for colorblind people, this isn't a great slide. But of course, because all the edges from the red vertex on the left here point out, I can't actually reach it from the blue source node. So the reachability problem is just asking, which nodes can I reach from a given source? Pretty straightforward, I think. Of course, there are many ways to solve this. Right? In fact, one way we could do it would
3626	be to use our previous lecture. We could compute the shortest path distance from the source to all the other nodes. And then what would the length of the shortest path from the source to an unreachable node be? Any thoughts from our audience here? Infinity. Thank you, Professor Demaine. Right. So in addition to this, of course, a totally reasonable question, thinking back to our shortest path lecture, there are sort of two queries we might make. Right? One is just what is the length of the shortest path? The other is like, what is the actual shortest path from the source to a given vertex? We can ask a very similar thing here, which is like, OK. You tell me that the green guy is reachable, but how? Give me a path as evidence or a certificate, if you want to be fancy about it. So in order to do that, just like last time, remember, we defined a particular data structure that was the shortest path tree. We can do something very similar here. In particular, this
3627	is like the extent of my PowerPoint skills here. If I have a reachability problem, I can additionally store-- I can decorate every node in my graph with one other piece of information, which is the previous node along some path from my source to that thing. Right? And just like last time, if I want to get an actual path from the source to w, what could I do? I can start with w and then just keep following those parent relationships until I get back to the source. Then if I flip the order of that list of vertices, I get a path from the source to the target that's valid. So this object is called a path tree, just like we talked-- or a parent tree, rather. Just like we talked about in our last lecture, there's no reason why this thing should ever have a cycle in it. It's certainly a tree. Right. So that's the basic reachability problem. And in addition to that, we can compute this object P, which is going to give me
3628	sort of information about how any given node was reachable. There's a slight difference between the parent tree that I've defined here and the shortest path tree, which I defined last time, which is, I'm not going to require that the shortest path I get-- oh, man-- the path I get when I backtrack along my tree P is the shortest path, it's just a path because for the reachability problem, I actually don't care. Like, I could have a weird, circuitous, crazy long path. And it still tells me that a node is reachable. Right. So that's our basic set up and our data structure. And now we can introduce a problem to solve reachability. Again, we already have an algorithm for doing that, which is to compute shortest paths. And remember that our shortest path algorithm from previous lecture took linear time and the size of the input. It took v plus e time. Now the question is, can we do a little better? The answer, obviously, is yes, because I just asked it, and I gave you
3629	this problem. OK. And here's a technique for doing that, which unsurprisingly, is a recursive algorithm. I'm going to swap my notes for my handwritten notes.
3630	And here's the basic strategy. I'm going to choose a source node and label that Node 1 here. I suppose it actually would have made sense for me to actually 0 index this. Maybe in the slides I'll fix it later. But in any event, I'm going to mark my source node. And now I'm going to look at every node, every edge coming out of that node, and I'm going to visit it recursively. So that's our sort of for loop inside of this function visit. And then for each neighboring node, if I haven't visited it before, in other words, I currently haven't given it a parent. That's our if statement here. Then I'm going to say, well, now they do have a parent. And that parent is me. And I'm going to recurse. You guys see what this is doing? It's kind of crawling outward inside of our graph. So let's do the example on the screen. And I purposefully designed this experiment-- or this example-- to look a little bit different from breadth-first search, at least
3631	if you choose to do the ordering that I did. So here's our graph. 1, 2, 5, 3, 4. OK. And let's think about the traversal order that the depth-first search is going to do. Right. So here's our source. And now what does the source do? It rec-- so let's think about our recursion tree. So we have the source all the way up in here. And now he's going to start calling the visit function recursively. So. And I'll go ahead and number these the same as on the screen. Well, he has one outgoing neighbor, and it hasn't been visited yet. So of course, the very first recursive call that I'll make is to that neighbor 2. Now the neighbor 2 also recurses. Hopefully this kind of schematic picture makes some sense, what I'm trying to draw here. And well now, the 2 has two neighbors, a 3 and a 5. So let's say that we choose 3 first. Well, the 3 now recurses and calls 4. And then the recursion tree is kind of done. So
3632	now it goes back out. And then finally, well, now, the 3-- or, oh, boy. Yeah. The 2 looks at his next neighbor, which is the 5 and visits that recursively. Notice that this is not following the level sets. Right? The depth-first search algorithm got all the way to the end of my tree in the recursive calls and then kind of backed its way out to the 2 before calling the 5. These are not the same technique. One goes all the way to the end and then kind of backtracks. When I say backtrack, what I mean is the recursion is kind of unraveling. Whereas in breadth-first search, I visit everything in one level set before I work my way out. That distinction make sense? OK. So of course, we need to prove that this algorithm does something useful. So let's do that now.
3633	So our claim is going to be that-- let's see here-- the depth-first search algorithm visits all, I guess reachable v, and that it correctly sets the parent in the process. OK. So in order to prove this, of course, as with almost everything in this course, we're going to use induction. And in particular, what we're going to do is do induction on the distance from the source. So we're going to say that, like, for all vertices in distance k from the source, this statement is true. And then we're going to prove this inductively on k. OK? So we want to do induction on k, which is the distance to the source vertex. So as with all of our inductive proofs, we have to do our base case and then our inductive step. So in the base case, k equals 0. This is a hella easy case because, of course, what is the thing that is distance 0 from the source? It's the source! Yeah. And take a look at our strategy all the way at the
3634	top of the slide. We explicitly set the correct parent for the source, and in some sense, visit it because the very first thing we do is call visit of s. So there's kind of nothing to say here. Yeah? Or there's plenty to say if you write it on your homework. But your lazy instructor is going to write a check mark here. OK. So now we have to do our inductive step. So what does that mean? We're going to assume that our statement is true for all nodes within a distance k. And then we're going to prove that the same thing is true for all nodes within a distance k plus 1. OK. So let's do that. Let's consider a vertex v that's distance k plus 1 away. So in other words, the distance from the source to v is equal to k plus 1. And what's our goal? Our goal is to show that the parent of v is set correctly. Yeah? What was that? AUDIENCE: [INAUDIBLE]. JUSTIN SOLOMON: Oh, sorry. I forgot that the
3635	distances in this class are in order. Yeah. That's absolutely right. So it should be the distance from s to v. Yeah. Sorry. I'm really not used to thinking about directed graphs. But that's a good fix. OK. So now what can we do? Well, there's this number is distance here. So in particular, the shortest path from s to v. So remember our argument last time that essentially, when we look at shortest path and we kind of truncate by 1, it's still shortest path? That property doesn't matter so much here. But at least we know that there's another vertex on the path, which is 1 distance from one less away. So let's take u, which is also a vertex, to be the previous node on the shortest path from s to v. Right. And so in particular, we know that the distance from s to u is equal to k. And conveniently, of course, by our inductive hypothesis here, we know that our property is true for this guy. OK. So now our algorithm, what do we
3636	know? Well, because our property is true, the visit function at some point in its life is called on this vertex u. That's sort of what our induction assumes. So we have two cases. Right. So when we visit u, we know that when we call this visit function, well, remember that v kind of by definition is in Adj+ of u. Right. So in particular, DGS is going to consider v when it gets called. OK. And now there's two cases. Right? So either when this happens, P of v does not equal None. Right. Well, what does that mean? Well, it means that we already kind of found a suitable parent for v. And we're in good shape. Otherwise, p of v does equal None. Well, in this case, the very next line of code correctly sets the parent. And we're all set. So in both of these two cases, we show that the parent of u was set correctly either by that line of code right here or just previously. And so in either case, our induction
3637	is done. All right. I guess given the feedback I received from our previous lecture, we now can end our LaTeX suitably. OK. So what did we just show? We showed that the depth-first search algorithm can dig around in a graph and tell me all of the things that are searchable, or rather, are reachable from a given source, just basically by calling visit on that source and then expanding outward recursively. OK. So I think this is certainly straightforward from an intuitive perspective. It's easy to get lost when you write these kind of formal induction proofs because they always feel a tiny bit like tautology. So you should go home and kind of convince yourself that it's not. OK. So of course, what do we do in this class? We always follow the same kind of boring pattern. The first thing we do, define an algorithm. Second thing we do, make sure that it's the right algorithm. What's the third thing we need to do? AUDIENCE: Analyze it. JUSTIN SOLOMON: Analyze it. That's right. In particular, make
3638	sure that it finishes before the heat death of the universe. And indeed, depth-first research doesn't really take all that long, which is a good thing. So let's think about this a bit. So what's going to end up happening in depth-first search, well, we're going to visit every vertex at most once, kind of by definition here. And in each case, we're going to just visit its neighboring edges. Can we ever traverse an edge more than one time? No. Right. Because the visit function only ever gets called one time per vertex. And our edges are directed. Right. So kind think about the from of every edge, the from vertex is only ever visited one time. And hence, every edge is only visited one time. Do we ever visit-- ah, yes. AUDIENCE: Does DFS work for an undirected graph? JUSTIN SOLOMON: An undirected graph. Absolutely. So there's sort of different ways to think about it. One is to think of an undirected graph like a directed graph with two edges pointed either way, which I think is in
3639	this class how we actually kind of notated it in the previous lecture. Yeah. Actually, that's probably a reasonable way to reduce it.
3640	Right. Now, does DFS ever visit a vertex that is not reachable from the source? Well, the answer is no because all I ever do is recursively call on my neighbors. And so kind of by definition, if I'm not reachable, DFS will never see it. So if I think about my runtime carefully, it's not quite the same as breadth-first search. Remember that breadth-first search took v plus e time. In depth-first search, it just takes order e time because I'm expanding outward from the source vertex, hitting every edge adjacent to every vertex that I've seen so far. But I never reach a vertex that I haven't-- that isn't reachable. Right? And so because this only ever touches every edge one time, we're in good shape. And I see a question here. Yeah. AUDIENCE: Does BFS reach vertices that are not reachable? JUSTIN SOLOMON: Does BFS reach vertices that are not reachable? I guess not, now that you mention it. But at least in my boring proof of order v time last time, our very first step of
3641	BFS, reserve space proportional to v, which is enough to already make that runtime correct. Good question. Yeah. So I guess the way that we've talked about it where you can stretch one little set after a time, if you think of that as reachability, then no. It doesn't reach it in the for loop. But just by construction, when we started we already took the time that we're talking about here. So notice these run times aren't exactly the same. So for example, if my graph has no edges, BFS still is going to take time because it still has to take order v time, at least in the sort of brain-dead way that we've implemented it last time. Obviously, in that case, we could probably do something better. Whereas the way that we've defined the DFS algorithm, it only takes edge time. I see confusion on my instructor's face. No? OK. Good. The one thing to notice is that these are algorithms for slightly different tasks in some sense. The way that we wrote down breadth-first search last
3642	time, conveniently, it gives us the shortest path. There are breadth-first search algorithms that doesn't. I think in this class we kind of think of breadth-first search-- we motivate it in terms of the shortest path problem. But it's just kind of a strategy of working outwards from a vertex. Whereas here, the way we've written down depth-first search, there's no reason why the path that we get should be the shortest. Right? So to think of a really extreme example, let's say that I have a cycle graph. So I get a big loop like this. Let's say that I do depth-first search starting from this vertex. Well, what will happen? Well, this guy will call its neighbor recursively, who will then call its neighbor recursively, who will then call his neighbor recursively, and so on. So of course, when I do depth-first search, when I get to this vertex, there's a chain of 1, 2, 3, 4 vertices behind it. Is that the shortest path from the source to the target here? Well, clearly not. Right? I could
3643	have traversed that edge. I just chose not to. OK. So that's the depth-first search algorithm. It's just essentially a recursive strategy where I traverse all my neighbors, and each of my neighbors traverses their neighbors, and so on. OK. So why might we want to use this algorithm? Well, we've already solved the reachability problem. So let's solve a few more things using the same basic strategy here. So there's some notions that we've sort of-- actually, in some sense, already used in the lecture here. But we might as well call them out
3644	So a graph is connected if there's a path getting from every vertex to every other vertex. Right. Now connectivity in a directed graph is kind of a weird object. Like, for instance, think of a directed graph with just two edges. And one edge goes from u to v. Then I can get from v to u, but not vise versa. That's kind of a weird notion. So here in 6006 we'll mostly worry about connectivity only for undirected graphs because they're-- the vertices just basically come in like, big connected clumps. Or the more technical term for a big connected clump is a connected component. Yeah? So let's see an example. So let's say that I have a graph, which has an edge and then a triangle. This is one graph. Do you see that? There's a collection of vertices, and there's a collection of edges. But it has two connected components-- the guy on the right and the guy on the left, meaning that each vertex here is reachable from every other vertex here. Each vertex here
3645	is reachable from every vertex here. But there's no edge that goes from the triangle to the line segment. Yeah? And so in the connected components problem, we're given a graph like this guy. And initially, we don't, you know-- OK. When I draw it like this, it's pretty clear that my graph has two connected components. Maybe my graph-embedding algorithm failed and it drew an edge like that. Well, then maybe-- I don't know-- it's still pretty obvious that there's two connected components. But you can imagine a universe where you don't know that a priori. And the problem you're trying to solve is just to enumerate all these clumps of vertices that are reachable from one another in an undirected graph. And conveniently, we can use depth-first search to solve this problem pretty easily. Right? So how could we do it? Well, in some sense how can we find one connected component? So let's say that I just choose a vertex in my graph. Well, what do I know about everything in its connected component? Well, it's reachable
3646	from that vertex. Remember, we just solved the reachability problem, which says, if I have a vertex, I can now tell you all the other vertices that are reachable from this guy. So I could call DFS on, well, any vertex of this cycle here. Call the reachability thing. And I know that for every vertex there's one of two things. Either the vertex has a parent in that object P, or it's the source. So I can very easily find the connected component corresponding to that vertex. Does that makes sense? Have I found all the connected components? No. I found one. I found the one corresponding to the arbitrary vertex that I just chose. So how could I fix this? Well, it's super simple. I could put a for loop on the outside, which just loops over all the vertices, maybe. And if that vertex is not part of a connected component yet, then I need to make a new one. So then I call DFS on that vertex. I collect all the vertices that I got. And
3647	I iterate.
3648	we're going to call full DFS. By the way, you could do the same thing with full breadth-first search. That's perfectly fine. Just kind of by analogy here. Right. So what is full D-- oh, this chalk is easier. Well, I'm going to iterate over all my vertices. Where I stands for for loop. Of-- right. So if v is unvisited, then I'm going to do to DFS starting at v. I guess we used visit to refer to this in the previous slide. And that's going to kind of flood fill that whole connected component. And then I can collect that connected component and continue. We have to be a little bit careful because, of course, we don't want like, checking things-- something to be visited to somehow take a bunch of time and make my algorithm slower than it needs to be. But of course, we have a set data structure that we know can do that and order one time at least in expectation.
3649	So this is the full DFS algorithm. It's really simple. Of DFS because I called DGS on every vertex. And it's full because I looped over all the vertices. Right. And so if we think about it, how much time does this algorithm take? It's little bit sneaky because somehow I have a for loop over all the vertices. Then I could imagine a universe where I get, like, vertices times some other number because there's a for loop, and then there's something inside of it. I think that's how we're used to thinking about runtime of for loops. But in this case, that actually doesn't happen because there's never a case where an edge gets traversed more than one time. Because if I'm in one connected component, then by definition, I can't be in another connected component. Right? And so what happens is, in some sense, this innocent looking call to DFS-- I suppose if you were like a LISP or a programmer, you somehow wouldn't like this. It has a side effect, which is that I marked all
3650	"the vertices in that connected component as ""don't touch me again."" Right. And so implicitly I kind of removed edges in this process."
3651	the runtime of this full DFS algorithm is v plus e time because every edge is touched no more than one time. Kind of amortized over all the different calls to DGS here. And there's this for loop over vertices. So there's clearly an order v that you need here. Does that argument make sense? So again, we call that linear in the size of the input. I'm going to say it as many times to get it in my own head correctly. OK. Right. So this is the basic problem. This comes up all the time, by the way. Like, it seems like somehow a totally brain dead weird algorithm. Like, somehow, why would you want an algorithm that finds connected components. Like, why would you even have a graph that's disconnected or something? But of course, that can happen a lot. So for instance, maybe you work at a social media company, and people have friends. But like, Eric and I are friends. And we're not friends with anybody else. We have a-- there's like, a blood oath
3652	kind of thing. Then that might be not so easy to find in the graph because, of course, we're just two among a sea of students in this classroom, all of which have different interconnections that are just enumerated based on the list of edges. And so even though like, pictorially, it's kind of hard to draw a connecting component algorithm in a way that doesn't make it sound kind of like a useless technique from the start, because it's very clear there are two connected components there. Of course, we still have to be able to write code to solve this sort of thing. OK. So for once, I think I'm almost on time in lecture today. So we have one additional application of depth-first search in our class today, which is sort of on the opposite end of the spectrum. So we just talked about graphs that are undirected and thinking about cycles. Now, on the opposite end we might think of a DAG. So a DAG is a Directed Acyclic Graph. Can anyone think of a special
3653	case of a DAG? I suppose I should define it first. And then we'll come back to that question, which means exactly what it sounds like. So it's a graph that has directed edges now and doesn't have any cycles in it. So actually, the graph I gave you all the way at the beginning of lecture I think secretly was an example of one of these. So let's say that I have directed edges. Maybe if I make the head a triangle, it's a little easier to see. I'm not so sure. In any event, so I'm going to have an edge up and an edge to the right, and similarly, an edge down and an edge to the right. This graph looks like a cycle. But it's not because the only direction that I can move is from the left-hand side to the right-hand side. So this is a directed graph. And it doesn't contain any cycles, meaning there's no path that it can take from a vertex that gets back to itself along the directed edges. OK.
3654	And DAGs show up all the time. Now that I've defined what a DAG is,
3655	that we've already seen in 6006? AUDIENCE: A tree. JUSTIN SOLOMON: A tree. At least if we orient all all the edges kind of pointing downward in the tree. Yeah. Otherwise, it gets kind of debatable over whether it's a DAG or not. If there's no direction to the edges, then somehow the definition just doesn't apply. OK. So in processing directed acyclic graphs, there's a really useful thing that you can do that's going to show up in this class apparently quite a bit, which is kind of interesting to me, I'm curious to see what that looks like, which is to compute a topological order on the graph. We're at topologies here.
3656	But in this case, a topological order is a fairly straightforward thing. Actually, it's defined on the screen, and I have bad handwriting anyway.
3657	So topological ordering. So we think of f as a function that assigns maybe every node an index in array. I guess I shouldn't use the word array here. But just like an index, an ordering. So like, this is the first vertex. And this is the second vertex. And so on. Then a topological order is one that has the properties shown here, which is that if I have a directed edge from u to v, then f of u is less than f of v. So in other words, if I look at the ordering that I get on my topological order, u has to appear before v. Yeah? Let's look at our example again. So let's give our nodes names. So here's A, B, C, D. Well, what clearly has to be the first node in my topological order? A. Right. It goes all the way to the left-hand side. Yeah. Well, after that it's a bit of a toss-up. What do we know? We know that B and C have to appear before D. So maybe
3658	"just to be annoying, I do A, C, B-- that's a B-- and then D. So it's a topological order. Notice that things that are on the left appear in my graph before things that are on the right, where the word ""before"" here means that there's an edge that points from one to the other. OK. By the way, are topological orderings unique? No. So if we look at our graph example here, ABCD is also a topological order. And what that means is somehow very liberating. It means that when we design an algorithm for finding a topological order, so there's some design decisions that we can make. And we just have to find one among many. But in any event, we're going to define a slightly different notion of order. And then we're going to show that they're closely"
3659	And that is the finishing order. So in the finishing order, we're going to call full DFS on our graph. Remember, that means we iterate over all our nodes. And if we haven't seen that node yet, we call DFS on it. And now we're going to make an order in which as soon as the call to a node in that visit function is complete, meaning I've already iterated over all my neighbors, then I add my node to the ordering. That make sense? It's like a little bit backward from what we're used to thinking about. So it's the order in which full DFS finishes visiting each vertex. Yeah? And now here's the claim, is that if we have a reverse finishing order, meaning that we take the finishing order and then we flip it backward. That's exactly going to give us a topological ordering of the vertices in our graph. Right. So let's do that really quickly. So in other words, our claim here-- I think, yeah, let's see-- is that if I have a directed graph.
3660	So G is a DAG. Then let's see here. Then the-- oops. My notes are backwards. So I should switch to my-- Jason's notes, which of course, are correct. Right. So if I have a graph that's a DAG, then the reverse of the finishing order is a topological order. By the way, we're not going to prove the converse that if I have a topological order, that somehow that thing is the reverse of DFS, at least the way that maybe I coded it. There's a slightly different statement, which is, does there exist a DFS that has that ordering? But that's one that we'll worry about another time around piazza or whatever. OK. So let's see here. So we need to prove this thing. So what are we going to do? Well, what do we need to check is the topological order is that if I look at any edge of my graph, it obeys the relationship that I have on the screen here. So in particularly, we're going to take uv inside of my set of edges.
3661	And then what I need is that u is ordered before v using the reverse of the finishing order that we've defined here. OK. So let's think back to our call to the DFS algorithm, where call this visit function. Right. So we have two cases. Either u is visited before v. Or it ain't. Yeah. So let's do those two cases. So case Number 1 is, u is visited before v. OK. All right. So what does that mean? Well, remember that there's an edge. Like, pictorially, what's going on? Well, there's all kinds of graph stuff going on. And then there's u. And we know that there's a directed edge from u to v. That's our picture. Right? And maybe there's other stuff going on outside of us. So in particular, well, just by the way that we've defined that visit function, what do we know? We know that when we call visit on u, well, v is one of its outgoing neighbors. So in particular, a visit on u is going to call visit v. And we
3662	know that because well, u is visited before v. So currently, v's parent is l when I get to you That make sense? Now, here's where reverse ordering, we're going have to keep it in our head because now, well, visit of u calls visit of v. So notice that visit of v has to complete before visit of u. Right? V completes before visit of u. Well. So in reverse, sorting-- in reverse finishing order here, what does that mean? Well, if this completes before the other guy, then they get flipped backward in the list, which is exactly what I want because there's an edge from u to v. OK. So Case 1 is done. Now we have Case 2, which is that v is visited before u. OK. So now I'm going to make one additional observation. OK. So now I'm going to go back to my other notes because I like my schematic better. Right. So what's our basic picture here? Oh, no. I-- Oh, you know what it was? I printed out another copy of
3663	this. That's OK. I can do it off the top of my head. OK. So here's my source vertex. His name is S. Now, there's a bunch of edges and whatever. There's a long path. And now eventually, what happens? Well. I have a node v. And somewhere out there in the universe is another node u. And what do I know? I know that by assumption, I know that there's an edge from u to v. That make sense? So that's our sort of picture so far. OK. So what do we know? We know that our graph is acyclic. Yeah? Kind of by definition, that's our assumption. So can we reach u from v? In other words, does there exist a path from v to u? So that would look like this. No because our graph is acyclic, and I just drew a cycle. So this is a big X. There's a frowny face here. Can't do it. He has hair, unlike your instructor. OK. So right. So what does this mean? Well, OK. So by this picture,
3664	I suppose, we know that u cannot be reached from v. Yeah. So what does that mean? Well, it means that the visit to v is going to complete and never see u because remember, the visit to v only ever call things that are kind of descendants of v. So in other words, visit of v completes without seeing u. Well, that's exactly the same thing that we showed in our first case. Right? So by the same reasoning, what does that mean? In our reverse finishing order, the ordering from u to v is preserved. OK. So that sort of completes our proof here that reverse finishing order gives me a topological order, which is kind of nice. And so this is a nice convenient way of taking all of the nodes in a directed acyclic graph and ordering them in a way that respects the topology or the connectivity of that graph. So we're going to conclude with one final problem, which I don't have a slide on.
3665	And that's cycle detection. So there's a bit of an exercise left to the reader here. So the problem that we're looking for now is that we're given a directed graph. There's a G in graph, in case you're wondering. But now, we don't know if it's a DAG or not. And so the question that we're trying to ask is, does there exist a cycle in our directed acyclic graph? So we're just given our graph, and we want to know, can we do this? Let's think through the logic of this a bit. So what do we know? We know that if our graph were a DAG, then I could call DGS, get the ordering out, and then I guess flip its ordering backwards. So I could compute the reverse finishing order. And it would give me a topological order of my graph. So if I were a DAG, I would get a topological order when I call DFS. So let's say that I ran DFS. I got whatever ordering I got. And now I found an edge
3666	the points in the wrong direction. I can just double check my list of edges, and I find one that does not respect the relationship that I see in the second bullet point here. Can my graph be a DAG? No. Because if my graph were a DAG, the algorithm would work. I just proved it to you. Right? So if my graph were a DAG, then I could do reverse finishing order. And what I would get back is a topological order. So if I found a certificate that my order wasn't topological, something went wrong, and the only thing that could go wrong is that my graph isn't a DAG. Yeah. Isn't a DAG. In fact, sort of an exercise left to the reader and/or to your section-- do we still have section? I think we do, as of now-- is that this is an if and only if, meaning that the only time that you even have a topological ordering in your graph is if your graph is a DAG. This is a really easy fact to
3667	sanity check, by the way. This is not like, a particularly challenging problem. But you should think through it because it's a good exercise to make sure you understand the definitions, which is to say that if you have a topological order, your graph is a DAG. If you don't have a topological order, your graph isn't a DAG. So in other words, we secretly gave you an algorithm for checking if a graph is a DAG at all. Right? What could I do? I could compute reverse finishing order. Check if it obeys the relationship on the second bullet point here for every edge. And if it does, then we're in good shape. My graph is a DAG. If it doesn't, something went wrong. And the only thing that could have gone wrong is not being a DAG. OK. So in other words, secretly we just solved-- well, I guess the way that I've written it here, we've solved the cycle detection problem here, which is to say that, well, I have a cycle if and only if I'm
3668	"not a DAG, which I can check using this technique. Of course, the word ""detection"" here probably means that I actually want to find that cycle, and I haven't told you how to do that yet. All we know how to do so far is say, like, somewhere in this graph there's a cycle. And that's not so good. So we can do one additional piece of information in the two minutes we have remaining to sort of complete our story here, which is to modify our algorithm ever so slightly to not only say thumbs up, thumbs down, is there a cycle in this graph, but also to actually return the vertices as a cycle. And here's the property that we're going to do that, which is following, which is that if G contains a cycle, right, then full DFS will traverse an edge from a vertex v to some ancestor of v. I guess we haven't carefully defined the term ""ancestor"" here. Essentially, if you think of the sort of the running of the DFS algorithm, then an"
3669	ancestor is like something that appears in the recursive call tree before I got to v. OK. So how could we prove that? Well, let's take a cycle. And we'll give it a name. In particular, we'll say that it's a cycle from v0 v1 to vk. And then it's a cycle, so it goes back to v0. OK. And I can order this cycle any way I want. Notice that if I permute the vertices in this list in a cyclical way, meaning that I take the last few of them and stick them at the beginning of the list, it's still a cycle. That's the nice thing about cycles. So in particular, without loss of generality, we're going to assume that v0 is the first vertex visited by DFS. What does that mean? That means, like, when I do my DFS algorithm making all these recursive calls, the very first vertex to be touched by this technique is v0. OK. Well, now what's going to end up happening? Well, think about the recursive call tree starting at v0.
3670	By the time that completes, anything that's reachable from v0 is also going to be complete. Do you see that? So for instance, v0 somewhere in its call tree might call v2. And notice that v2 was not already visited. So in fact, it will. For v1 I got to call v2 and so on. And in particular, we're going to get all the way to vertex k. Right? So in other words, we're going to visit a vertex vk. And notice what's going to happen. So remember our algorithm. In fact, we should probably just put it up on the screen would be easier than talking about it a bunch. Well, vk is now going to iterate over every one of the neighbors of vk. And in particular, it's going to see vertex v0. Right? So we're going to see the edge from vk to v0, which is an edge kind of by definition because we took this to be a cycle here. But notice that's exactly the thing we set out to prove, namely that full DFS traverses
3671	an edge from a vertex to one of its ancestors. Here's a vertex k. Here's the ancestor v0. Why do we know that it's an ancestor? Well, because v0 was called in our call tree before any of these other guys. Right? So we wanted an algorithm that not only did cycle detection, but also actually gave me the cycle. What could I do? Well, it's essentially a small modification of what we already have. Right. So-- whoops. Right. If I want to compute topological order or whatever, I can just do DFS. And that'll tell me like, yay or nay, does there exist a cycle. If I want to actually find that cycle, all I have to do is check that topological order property at the same time that it traversed the graph during DFS. And the second that I find an edge that loops back, I'm done. And so that's our basic algorithm here. And this is a technique for actually just finding the cycle in a graph using the DFS algorithm.
3672	[SQUEAKING] [RUSTLING] [CLICKING] JASON KU: Hi, everyone. Welcome to the 11th lecture of 6.006, our first lecture on weighted shortest paths. Until now, we've only been talking about graphs that-- where we measure distance in terms of the number of edges in a path. Today, we're going to generalize that notion. But I just want to go over what we've talked about in the last two lectures. In the last two lectures, we've talked about two algorithms, breadth-first search and depth-first search to solve a range of problems. Here's some of the problems that we've been solving. Single-source shortest paths, where distances are measured in number of edges in a path. And we used BFS to solve this problem, starting from a single source, usually a vertex s that we call. And we solve that in linear time. And we solve that in order v plus e. That's what we called linear time for a graph. For the special case of single-source reachability, here we had to return a shortest path distance for every vertex. And there was, at most,
3673	E things reachable from a vertex. So this is the bound we got. But in the special case for single-source reachability, when our output only has to list the vertices that are reachable from me, the number of things reachable in basically a spanning tree of the connected component of my source can almost be of order E. And so for all the little singleton vertices in my graph, I don't really care. So I can get this in order E, but that's kind of a little optimization.
3674	about connected components. And we didn't just reduce to using a search algorithm like a single-source reachability algorithm like BFS or DFS. We put a for loop around that to explore the entire graph by basically saying, if I've explored one connected component, then I can look at any other vertex I haven't seen and explore the next one. And so that actually with some-- a little analysis, also got linear time, because I'm at most traversing any component of my graph once. That's kind of the idea. And we can use that using BFS or DFS really, because we're just trying to get a thing that searches an entire connected component. And then this topological sort we did at the end of the last lecture. We used full DFS to give an ordering of the vertices in a DAG-- maybe I'll specify clearly that this is only for a DAG-- where we have an ordering of the vertices so all the edges go forward in that order, for example. And that we also did in linear time. All right,
3675	in this lecture, and in actually the next four lectures, what we're going to do is instead of measuring distance in terms of the number of edges in a path-- so previously, distance equaled number of edges-- we're going to generalize that notion. So instead counting an edge, we're going to count an integer associated with that edge.
3676	So here's an example of a weighted graph G. And I've labeled, in red, weights for each of these edges. This is a directed graph on eight vertices. And I've got an integer associated with each edge. You'll notice, some of them are positive, some of them are negative. It's OK to be zero as well. It's just any integer edge weight here. So generally we're going to be-- along with our graph G, we're going to be given a weight function that maps the edges of G to, we're going to say, integers, in this class anyway. In other contexts, in mathematics, you might have these be real numbers. But in this class, we're going to deal with integers. So each edge, if you have an edge, we're going to say this is the edge weight-- the weight of this edge e, from e. Sometimes, if this edge e is u, v, we might sometimes say the weight from u to v, since we have a simple graph that's unambiguous. All right, so but this is just talking about
3677	our notation. So in general, for example, the weight from vertex b to f in this graph is what? Can someone tell me? AUDIENCE: Minus 4. JASON KU: Minus 4, right? It's right here. And I'll be consistent with my coloring, because I've got colored chalk today. Minus 4. Happiness.
3678	"to our graph? Well, this comes up a lot in many applications. For example, distances in a road network. if I have a road from here-- so from Mass Ave, front of MIT, to Central Square, we might think of that as one road. Maybe you've got each road is a connection between two intersections in my road network. But an edge, it takes longer to go from, say, Vassar Street to Amherst. That takes a shorter amount of time than it does to go from Memorial Drive across the river to Beacon Street. So we might want to associate a larger distance or a weight associated with that edge. Latency in a network, for example. Maybe strength of relationships in a social network. And you could imagine that it's possible maybe you're ""frenemies"" with someone, you don't like them, and so maybe you have a negative weight associated with an edge in a social network. I'm not sure. Maybe not. But there are lots of applications where you might want weights on your edges. So that comes to the"
3679	next question of, how do I represent-- how do I give the user, or the algorithm, these weights in my graph? We had a representation for a graph. Our common way to represent a graph was store a set data structure on the vertices mapping to the adjacencies of each vertex, which we stored in what we called an adjacency list, which really could be any data structure. Commonly, it's just an array of the adjacencies. But you could also have that be a set data structure, where you can query in constant time what-- if a particular adjacency exists in that graph. So there are two common ways to store these weights. One is just, with every adjacency, I'm going to store its weight. Maybe just in a tuple. With each adjacency, also store weight of the edge that it corresponds to, just in any way. A second way, instead of trying to modify our graph structure that we gave you before, let's just have a dictionary of all the edges mapping to their weights. And we already know
3680	how to do that. Just any set data structure-- any separate set data structure mapping edges to their, I guess, weights. Bad notation, but you get the idea. And it doesn't really matter how we're doing this. The assumption that we're going to rely on here is that, given an edge, given this vertex pair, I can query what the weight of that edge is in constant time. And so if I'm going to do that, I can either store it with maybe a hash table of hash tables-- a hash table mapping the set of vertices to their adjacencies, and then each adjacency list stores its adjacencies in a hash table. And that way, in constant time, I can check what the weight is there. Or here, I'm just-- I could even have just a single hash table mapping the pair, the edge, the tuple, constant size, to its weight. So either way is fine. We're just going to assume that we can query an edge in constant time-- the weight of an edge in constant time. OK, so
3681	this is that graph example. It's a little busy here. I'm probably going to erase that in just a second. But we're going to move on to what giving these edges weights implies for these problems that we've defined in terms of unweighted graphs. In particular, we are going to be concentrating on single-source shortest paths, again, at least for the next three lectures. We'll generalize that even still in the next lecture-- I mean, in the fourth-- in three lectures from now. But what we had here was that the distance before in an unweighted graph was the number of edges in the path. Here, we're going to generalize that notion kind of obviously to weighted paths. And the weight of a path, I'm going call it pi. So some weight of path pi is just going to be the sum of the weights in the edges in the path. So edge in the path, I'm going to sum their weights. So that's all the weight of a path means. It's just I'm going to sum all the weights
3682	in a path. So if I took a look at the-- maybe there's a particular path here. The path from a to b to f to g is going to be minus 5, minus 4, 2. It's going to be minus 9 plus 2 is minus 7. So just as an example. So then what is the shortest path then? Well, kind of obviously among all paths between two vertices, it's going to be one with the minimum weight. Yeah, question. AUDIENCE: Can I use the same edge more than once? JASON KU: Can I use the same edge more than once? Right now, you're asking about the distinction in our class which we have between paths and simple paths. So here, a weighted path doesn't really care if we visit an edge more than once. So if an edge appears more than once in pi, we have to count that more than once in the edge weight-- in the weight of the path. OK, great question. But what we're going to see later on is shortest paths cannot repeat
3683	an edge more than once in certain contexts. So we're going to get to the problem there a little later in this lecture. And we're going to solve that in tomorrow's lecture. But if you have-- we're getting a little ahead of ourselves. But when we have negative weights in a graph, it's possible that things go wrong. We're going to get there in about five lines. OK, great. So a shortest path-- and in this case, I'm going to clarify that this is the weighted shortest path-- is a minimum-- min-i-mum-- sure-- is a minimum weight path from s to t. Nothing too interesting here, but there's actually some subtleties we have to deal with here. We're going to call-- just like we did with breadth-first search when we talked about shortest paths, we're going to define an expression for what the distance or the shortest path weight is between two vertices. And I'm going to represent that by a delta. A delta from a vertex s to t is going to be-- let's-- I'm going to do the
3684	wrong thing first-- the minimum over the weight of all paths for all paths pi from s to t. OK, so there's a couple things that go wrong here. First thing that goes wrong is the same thing that went wrong with breadth-first search. Anyone remember what could go wrong with breadth-first search for this delta definition? AUDIENCE: Maybe there's no path. JASON KU: Maybe there's no path, right. So except if no path. Just by convention, we're setting delta s, t, to equal infinity. But there's one additional problem with weighted shortest paths, and it's a little subtle. It's possible that a finite shortest-- finite length shortest path doesn't exist. And what do I mean by that? It means I could keep going through edges in my graph and continually getting a shorter path. So if the shortest-- the minimum weight of a path from s to t actually goes through an infinite number of edges, then this isn't really well-defined. So I'm going to change this minimum here to-- in mathematics we would, just to be specific, we
3685	call it an infimum. So if in the case where the weight of a shortest path can approach arbitrarily small, then we'll call this thing minus infinity. So when does that occur? When does that occur? When could we have our shortest path go through lots and lots of vertices? Well, let's actually take a look at this example here. Can someone tell me what the shortest path is from a to actually any vertex in this graph? AUDIENCE: b, f, g, c. JASON KU: Ah, OK. So well, we could look at this path I have to b. Let's just take a look at b. I have a path going from a to b that is minus 5. OK, that's pretty good. That's pretty small. And it seems that if I go around this graph through another way, it might be bigger. So I go 7 plus 3 plus 8-- that's 15-- minus 1-- that's 14. That's much bigger than minus 5, so it seems like minus 5 should be good, right? Anyone have a problem with this path
3686	or a problem with this being the shortest path? And what your colleague just informed me was that there is something interesting happening here in this graph in particular. We have a cycle from b to f to g to c that has negative total weight back to b. This has minus 4 plus 2 plus 1 minus 1. So that total cycle has a cycle weight of minus 2, this negative weight cycle. So if I want to get to b, I could go there via this minus 5 weight edge. But every time I circled around this cycle, I incur minus 2 to my path weight. So I just keep going around this cycle over and over and over and over and over and over again, and I don't have any finite length minimum weight path. And in such cases, we just say that delta is minus infinity. So the problem here is that we could have negative weight cycles-- deserves a capital letter-- Negative weight cycles. It's a problem. In particular, if there exists a path from
3687	s to some vertex v that goes through a vertex on a negative weight cycle, then I can take that path to that vertex, circle around the negative weight cycle, and then proceed to v, and I can take that cycle as many times as I want. Then this delta s,v we're going to set to minus infinity. And in such cases, in our shortest paths algorithm, we don't really care about what the shortest path is. We're not even going to deal with parent pointers here, because there is no finite length shortest path. So I'm just going to kind of throw up my hands in the air and say, you know what, I can't return you a shortest path, but I might want to return to you a negative weight cycle. If you told me that this thing has bad weight, maybe I want you to tell me what a path is that goes through a negative weight cycle to get back to s. So that's what we're going to talk about next lecture. This lecture, we are
3688	not going to talk about that. We are going to talk about weighted shortest paths, though. That's what the remainder of this unit on graphs is really about is weighted shortest paths. OK, so in weighted shortest paths, we actually know an algorithm already to solve a subset of weighted shortest parts, namely BFS, right? Now, you're like wait, Jason, BFS doesn't solve weighted shortest paths. We didn't even know about weighted graphs then. How does that solve weighted shortest paths? Well, there's a couple cases where
3689	BFS. Can anyone think of such a scenario? So let's say, I mean, kind of what we did before was we counted the number of edges. So if we gave a weight of 1 to every edge in my graph, then just that graph, that weighted graph, corresponds to an unweighted graph using the other distance metric. So in that case, BFS just solves our problem. And in fact, we can generalize further. What if all of our weights were positive, but the same value? If it was all positive and the same value, then we could just divide by that value. Now we have an unweighted graph which we can run BFS, and then multiply shortest path distances by that value later on. And in fact, there's one further generalization we can make, which is a little bit of a tricky graph transformation problem.
3690	for weighted single-source shortest paths in contexts where the weights aren't that large. So if I have positive edge weights-- if I have a positive edge weight, let's say-- using my weight color here-- that's, like, weight of 4, that's kind of problematic, because I don't know how to simulate that using an unweighted graph. Or do I? Anyone have an idea of how I could simulate an edge of weight 4 with an unweighted graph? Yeah. AUDIENCE: Have four edges of weight 1. JASON KU: Yeah, I can just put four edges of weight 1 in parallel here-- I'm sorry, in series, the opposite of parallel. I can just convert this here into 1, 2, 3, 4 edges. And if I do that for every edge in my graph and we have positive edge weights, then that transformation can hold. Now, that's not necessarily a good transformation to make. Why? AUDIENCE: The weight might be very big. JASON KU: Yeah, the weights might be very big compared to the number of vertices and edges in my graph. However, if
3691	the sum of all weights in my graph is asymptotically less than v plus e, we can get a linear time algorithm again by reducing to BFS. OK, so that's great. But in general, that gives us a linear time algorithm in these very special cases. And in general, it's an open problem. We don't know whether we can solve the single-source shortest paths problem in the weighted context for general graphs in linear time. We don't know how to do it. But what we do know are some algorithms that do pretty well. And that's what we use all the time. But one more special case we're going to go over today is when we have this really nice structure where we have a DAG, a Directed Acyclic Graph, like we were talking about in the last lecture. For any set of edge weights-- remember, with BFS, we needed to restrict our edge weights to be positive and maybe bounded to get this good running time? For any set of edge weights, if our graph structure is DAG-- it
3692	really has nothing to do with the weights-- if the graph structure is a DAG, then we can actually solve this single-source shortest paths problem in linear time, which is pretty awesome. Now, for general graphs, we're going to show you in the next lecture how to, for any graph-- even with cycles, even with negative weight cycles-- we're going to show you how to solve this single-source shortest paths problem in something like a quadratic running time bound. Now, this isn't the best known, but it's a really practical algorithm and people use it all the time. And we are going to show Bellman-Ford in the context of the DAG algorithm we're going to solve today. So that's the very general case in terms of restrictions on our graph. But in reality, most problems that come up in applications occur with graphs that have positive edge weights. You can think of a road network. You've got-- or non-negative ones anyway. You're traveling along, and it's not ever useful to go back to where you came from, because you want
3693	to make progress to where you're going. So in the context where you don't have negative weights, you don't have this problem where you have negative weight cycles. We can actually do a lot better by exploiting that property. And we get a bound that's a little bit-- that looks a little bit more like n log n. It's pretty close to linear. You're losing a log factor on the number of vertices.
3694	This is called Dijkstra, and we'll get to that in two lectures. OK, so that's the roadmap of what we're going to do for at least the next three lectures. But before we go on to showing you how to solve single-source shortest paths in a DAG using this algorithm that I'm calling DAG relaxation here, I'm going to go back to a thing that we talked about in breadth-first search, where in breadth-first search when we solved single-source shortest paths, we output two things. We output single-source shortest paths, these deltas, for the other definition of distance, the weights-- I mean, not the weights, the distances, the shortest distances. But we also returned parent pointers. We return parent pointers back along paths to the source along shortest paths. We call this the shortest paths tree. So I'm going to revisit this topic of shortest paths tree-- shortest path trees-- shortest path trees. And in particular, it's kind of going to be annoying to talk about both of these quantities-- distances and parent pointers-- as we go through all three
3695	of these algorithms. It's basically going to be bookkeeping to-- distances are actually sufficient for us to reconstruct parent pointers if we need them later. So what I'm going to show for you-- prove to you now is that, if I give you the shortest path distances for the subset of the graph reachable from s that doesn't go through negative weight cycles, if I'm giving you those distances, I can reconstruct parent pointers along shortest paths in linear time for any graph I might give you if I give you those shortest path distances. OK, so that's what I'm going to try to show to you now. So here's the algorithm. For weighted-- there's the caveat here I'm going to write down. For weighted shortest paths, only need parent pointers for v with finite shortest path distance-- only finite shortest path distance. We don't care about the infinite ones or the minus infinite ones, just the finite ones. OK, so here's the algorithm. I can initialize all Pv to equal-- sorry, oh, getting ahead of myself. I'm writing down
3696	DAG. Init parent pointer data structure to be empty. At first, I'm not going to sort any parent pointers. But at the beginning, I'm going to set the parent pointer of the source to be none. So that's what we kind of did in breadth-first search as well. Now, what I've given you is-- I'm trying to show that, given all the shortest path distances, I can construct these parent pointers correctly. So what I'm going to do is, for each vertex u in my graph, where my delta s of u is finite, what am I going to do? I'm going to say, well, let's take a look at all my outgoing neighbors. This is kind of what we do in every graph algorithm. For each v in the adjacency, the outgoing adjacencies of u, if there is no parent pointer assigned to this v, there's the potential that i-- u-- [CHUCKLES] I, you-- this u, this vertex u, is the parent of v. It's possible. It's some incoming edge to v. When will it be an incoming edge
3697	to v? If v not in P-- I haven't assigned it a parent pointer-- and-- so this means it could be my parent. When is it my parent along the shortest path? Sure. AUDIENCE: Sum the distance along the edge to the distance of the other. JASON KU: Yeah, so we have some edge from u to v. It has some weight. If I already know the shortest path distance to u, and I know the shortest path distance to v, if the shortest path distance from s to u-- let's draw a picture here. We've got s, we've got some path here to u, and we know we've got an edge from u to v. If this shortest path distance plus this edge weight is equal to the shortest path distance from s to v, then it better-- I mean, there may be more than one shortest path, but this is certainly a shortest path, so we can assign a parent pointer back to u. So let's write that condition down. If the shortest path distance from s to
3698	v equals the shortest path distance from s to u, and then traversing the edge from u to v, then exists shortest path that uses edge u, v, in particular this one. So set the parent of u-- of v to u. OK, so this is the algorithm. I'm not going to prove to you that this is correct. But it kind of intuitively makes sense, right? If I have these shortest path distances, you can prove by induction that not only does this parent pointer point to the right place along some shortest path here, but it also does so in linear time, because I'm looping over all the vertices and looping over its outgoing adjacencies once. Same analysis as we had for both BFS and DFS, essentially. And then, since we can do this, since we can compute parent pointers from these distances, we're going to ignore computing these parent pointers from now on. We're just going to concentrate on computing the distances, because we're going to have to take linear time anyway at least. And all these
3699	other things take more time. So we can compute the distances in more time, and then compute the parents after. OK, so that's what we're going to do. So now, with all that buildup, let's show an algorithm.
3700	in a DAG in linear time? Well, a DAG-- I mean, this is actually a super useful, convenient thing in algorithms in general. DAGs are just nice things. They're kind of ordered in a way. There's this topological sort order that we were talking about before. This is going to play a key role. There's a really nice structure to DAGs not having cycles, not having to deal with this negative weight cycle problem. You can only go in one direction along this graph. It's a very nice structure to exploit. And so we're going to exploit it. And here's the idea. DAG relaxation, what it's going to do is it's going to start out with some estimates of what these distances should be. So maintain distance estimates. And now I'm going to try to be careful here about how I draw my Ds. This is a d, this is a delta. This is shortest paths. This is a distance estimate. So that's what I'm going to be using for the rest of this time. So we're going to maintain
3701	these estimates of distance d, which are going to start at initially infinite. I don't know what they are. I don't know what the shortest paths are, but they better be less than infinite or else I don't care. So that's the worst case scenario. It can't be worse than this-- for every vertex. And we're going to maintain the property that estimates upper bound-- that should probably be two words-- upper bound delta s, v-- we're going to maintain that they upper-bound this thing and gradually lower until they're equal. So this is the idea. We start from an over-estimate, an upper bound on the distance estimate. And then we're repeatedly going to lower that value as we gain more information about the graph, maintaining that we're always upper-bounding the distance. And we're going to keep doing it, keep doing it, keep doing it, until, as we will try to prove to you, these estimates reach, actually reach down, all the way to our shortest path distances. So when do we lower these things? When do we lower these
3702	things? We are going to lower these distance estimates whenever
3703	we're going to call the triangle inequality. OK, what is the triangle inequality? Triangle inequality is actually a pretty intuitive notion. It's basically saying, if I have three points-- thus, triangle-- maybe bigger so I can write a letter in them. It's basically saying that if I have a vertex u, a vertex v, vertex x, for example, the shortest path distance-- the shortest path distance delta of u, v-- that's the shortest distance from u to v-- it can't be bigger then a shortest path from u to v that also goes through x. Of my paths, I'm now restricting the paths I have to the ones that go through x. The shortest path distance from u to v can't be bigger than restricting paths that go through x and taking that shortest distance, getting the shortest path distance from here and adding it to the shortest path distance here-- delta u, x, delta x, v. That's just a statement of, I'm restricting to a subset of the paths. I can't decrease my minimum distance.
3704	that the shortest path distance from u to v can't be bigger than the shortest path distance from u to x plus the shortest path distance from x to v for any x in my graph that's not u and v. So that's the triangle inequality. Pretty intuitive notion, right? Why is this useful? OK, well, if I find-- if I find an edge in my graph, if there's an edge u, v, in my graph such that this condition is violated for the estimates that I have-- it obviously can't be violated on my shortest path distances, but if it violates it on the estimates-- u, v, is bigger than u, x-- sorry, u-- how am I going to do this? I want this to be s. I'm calculating shortest path distances from s and shortest path distances from s to some incoming vertex u plus the edge weight from u to v. All right, so what is this doing? I have some edge u, v in my graph. Basically, what I've said is that I have some distance
3705	estimate to u, but going through-- making a path to v by going through u, and then the edge from u to v is better than my current estimate, my shortest path estimate to v. That's bad, right? That's violating the triangle inequality. These cannot be the right weights. These cannot be the right distances. So how we're going to do that is lower-- this is what we said, repeatedly lower these distance estimates. I'm going to lower this guy down to equal this thing. In a sense, this constraint was violated. But now we're relaxing that constraint so that this is no longer violated. So relax is a little weird word here. We're using it for historical reasons. But that's what we mean by when we say relax. This thing is a violated constraint. It's got some pressure to be resolved. And so what we're doing is, to resolve it, we're just setting this guy equal to this, so it at least resolves, locally, that constraint. Now, it may violate the triangle inequality other places now that we've done
3706	this change. But at least this constraint is now relaxed and satisfied. OK, so relax edge by lowering d of s, v, to this thing. That's what we're going to mean by relaxing an edge. And relaxing an edge is what I'll call safe. It's safe to do. What do I mean by relaxation is safe? It means that as I am computing these shortest path distances, I'm going to maintain this property that each one of these estimates-- sorry, these estimates here-- has the property that it's either infinite or it is the weight of some path to v. So that's the thing the-- relaxation is safe. OK, so each distance estimate, s, v, is weight of some path from s to v or infinite. And this is a pretty easy thing to prove. If I had the invariant that these were all weights of shortest paths, let's try to relax an edge. And we need to show that this property is maintained. Relax edge u, v, OK? Now, if I relax edge u, v, what do I do?
3707	I set this thing-- or, sorry, I set this thing, my shortest path distance to v, to be this thing plus this thing. There's a weight of an edge from u to v. Now, by my assumption that we're maintaining that this is the weight of some path in my graph, if this thing is bigger, I'm setting it to the weight of some path on my graph to u, plus an edge from u to v, and so this checks out. So assign d of s, v, to weight of some path. I'm not going to write down all the argument that I just had here. But basically, since this distance estimate was by supposition before the weight of some path to v-- to u, then this is, again, the weight of some path to v. OK, great. So now we're ready to actually go through this algorithm. So DAG relaxation, from over there, initializes all of our distance estimates to equal infinity, just like we did in BFS. Then, set my distance estimate to myself to be 0.
3708	Now, it's possible that this might be minus infinity or negative at some point. But right now, I'm just setting it to 0. And either way, 0 is going to upper-bound the distance to s. So in particular, at initialization, anything not reachable from s is set correctly. And s itself is set as an upper bound to the shortest path distance. Now we're going to process each vertex u in a topological sort order. So remember, our input to DAG relaxation is a DAG. So this thing has a topological sort order. We're going to process these vertices in that order. You can imagine we're starting at the top, and all my vertices are-- all my edges are pointed away from me. And I'm just processing each vertex down this topological sort line. And then for each of these vertices, what am I going to do? I'm going to look at all the outgoing neighbors. And if the triangle inequality is violated, I'm going to relax that edge. The algorithm is as simple as that. For each outgoing neighbor
3709	of v-- sorry, of u-- I always get u and v mixed up here. If my shortest path estimate to v violates the triangle inequality for an edge, for an incoming edge, then I'm going to set-- relax u, v, i.e. set d, s,v, equal to d, s,u, plus w, u,v. So that's the algorithm. So if I were to take a look at this example graph over here, maybe a is my start vertex. I initialize it to-- AUDIENCE: DAG. JASON KU: This is not a DAG. Thank you. Let's make it a DAG. I claim to you now this is a DAG. In particular, a topological sort order is when there's a path through all the vertices, then there's a unique topological sort order-- a, b, e, f, g, h, d, c. This is a topological order. You can check all the edges. So I'm going to start by setting the-- actually, let's use e. Let's use shortest paths from e. Why not? Shortest paths from e. Vertex a actually comes before e in the topological order. So
3710	it has no-- I mean, its shortest path distance, when I initialize, I'm going to initialize this to 0. I'm going to initialize this to infinite, infinite, infinite, infinite, all these things to infinite. These are my estimates. These are not quite the shortest paths yet-- distances. But when I get here, clearly I can't be-- distance to me being infinite can never violate the triangle inequality with something infinite or finite. It doesn't matter, right? So I don't do anything to a. Anything before my source vertex in the topological order can't be visited, because it's before in the topological order. That's kind of the point. There's no path from my source vertex to anything before it in the topological order. So same with b. b is before a in the topological order. Now, I'm at e, and it's possible we are violating triangle inequality, in particular here. I think the shortest path distance to f is infinite. But actually, if I go to e through this edge with a weight 3, I know that this is violating triangle
3711	inequality. So actually, this thing is wrong, and I can set it equal to 3. Now, that might not be the shortest path distance. But right now it's a better estimate, so we've set it. Now, I'm moving on. I'm done with this guy. I move to the next vertex in my topological order. And again, I relax edges out of f. OK, so here, looking at 8, 3 plus 8 is better than infinite, so we'll say that that's 11. And 3 plus 2 is better than infinite, so that's 5. Now, I keep going in the topological order. g is the next. 5 plus 1 is 6. OK, so we found a better estimate here. So this 11 is not as good. 6 is better, so we replace it. Here, we haven't visited before. It's still infinite. So 5 plus minus 2 is 3. This is the next in the topological order. 3 plus 9 is bigger than 6, so that's not a shorter path. 3 plus 4 is certainly smaller than infinite, so set that equal to
3712	7. Then, 7 plus 5 is also bigger than 6. And actually, you can confirm that these are all the shortest path distances from e. So this algorithm seems to work. Does it actually work? Let's take a look. The claim to you is that at the end of relaxation, this algorithm, we've set-- claim at end, all the estimates equal shortest path distances. The basic idea here is that if I take the k-th vertex in the topological order, assuming that these distances are all equal for the ones before me in the topological order, I can prove by induction. We can consider a shortest path from s to v, the k-th vertex, and look at the vertex preceding me along the shortest path. That vertex better be before me in the topological order or we're not a DAG. And we've already set its shortest path distance to be equal to the correct thing by induction. So then when we processed u-- s to u to v-- when we processed u in DAG relaxation here, processed the vertex and
3713	looked at all its outgoing adjacencies, we would have relaxed this edge to be no greater than that shortest path distance. So this is correct. You can also think of it as the DAG relaxation algorithm for each vertex looks all at its incoming neighbors, assuming that their shortest path distances are computed correctly already. Any shortest path distance to me needs to be composed of a shortest path distance to one of my incoming neighbors through an edge to me, so I can just check all of them. That's what DAG relaxation does. And again, we're looping over every vertex and looking at its adjacencies doing constant work. This, again, takes linear time. OK, so that's shortest paths and a DAG. Next time, we'll look at, for general graphs, how we can use kind of the same technique in an algorithm we call Bellman-Ford. OK, that's it for today.
3714	[SQUEAKING] [RUSTLING] [CLICKING] JASON KU: Good morning, everybody. How's everybody doing? Nice long weekend we just came from-- I'm doing well. I'm actually getting over a little cold. Aw-- yeah, unfortunately. But after this, I don't have anything else this week, so that's good. OK, so last time, last week, we talked about how-- we looked at the search problem that we talked about earlier that week and showed that, in a certain model of computation, where I could only compare two objects that I'm storing in my-- that I'm storing and get some constant number of outputs on what I could-- how I could identify these things, like equal, or less than, or something like that, then we drew a decision tree and we got this bound that, if I had n outputs, I would require my decision tree to be at least log n height. And so in this model, I can't find the things faster than log n time. But luckily, we are in a model of computation which
3715	namely, random accessing. And if we stored the things that we're looking for, we have unique keys, and those keys are integers. Then, if I have an item with key K, if I store it at index K in my array, then I can find it and manipulate it in constant time.
3716	That's what we called a direct access array. A direct access array-- really not different than a regular array, except how are you using it when we were talking about sequences is we are giving extrinsic semantics to the slots where we are storing these things. Basically, I could put any item in any slot. Where it was in my array had nothing to do with what those things were. Here we are imposing intrinsic semantics on my array that, if I have an item with key K, it must be at index K. That's the thing that we're taking advantage of here. And then we can use this nice, powerful linear branching random access operation to find that thing in constant time, because that's our model of computation. OK, then what was the problem with this direct access array? Anyone shout it out. Space-- right. So we had to instantiate a direct access array that was the size of the space of our keys. In general, my index location is-- could go from 0 to some positive number. If
3717	I a very large positive numbers, if I was sorting-- if I was searching among your MIT IDs, I'd have to have a direct access array that was that spanned that space of possible keys you could have. And that could be much larger than n. And so the rest of the time we talked about how to fix that space problem. We can reduce the space by taking that larger key space from 0 to u, which could be very large, and map it down to a small space. Now, in general, if I give you a fixed hash function there, that's not going to be good in-- for all inputs. If your inputs are very well distributed over the key space, then it is good, but in general, there would be hash functions with some inputs that will be bad. That's what we argued. And so for the rest of the time there, we talked about hash families, choosing a hash function randomly from among a large set of hash functions, which had a property that, if I
3718	chose this thing randomly and you, generating your input, didn't know which random numbers I was picking, the expectation over my random choice-- me-- I'm the one running the algorithm, not you giving me the input-- that random choice-- my algorithm actually behaves really well in expectation. In particular, I got constant time for finding, inserting, and deleting into this data structure, in expectation. We did a little proof of-- that the chain links where we stored collisions in our hash function-- in our hash table-- sorry-- those wouldn't be very long, and so if they were constant, then I don't have to search more than a constant number of things when I go to an-- a hashed index location. Does everyone remember what we talked about last week? I didn't show you this chart at the end, but I'm showing it to you now. Essentially, what we had was we have a bunch of different ways to deal with this set interface. And last week, we talked about the sorted array, and then we talked about this direct access
3719	array and this hash table, which do better for these dictionary-- the find, and insert, and delete operations--
3720	What's the worst case performance of a hash table? If I have to look up something in a hash table, and I happen to choose a bad hash table-- hash function, what's the worst case here? What? n, right? It's worse than a sorted array, because potentially, I hashed everything that I was storing to the same index in my hash table, and to be able to distinguish between them, I can't do anything more than a linear search. I could store another set's data structure as my chain and do better that way. That's actually how Java does it. They store a data structure we're going to be talking about next week as the chains so that they can get, worst case, log n. But in general, that hash table is only good if we're allowing-- OK, I want this to be expected good, but in the worst case, if I really need that operation to be worst case-- I really can't afford linear time ever for an operation of that kind-- then I don't want to use a
3721	hash table. And so on your p set 2, everything we ask you for is worst case, so probably, you don't want to be using hash tables. OK? Yes? AUDIENCE: What does the subscript e mean? JASON KU: What does the subscript e mean? That's great. In this chart, I put a subscript on this is an expected runtime, or an A meaning this is an amortized runtime. At the end, we talked about how, if we had too many things in our hash table, then, as long as we didn't do it too often-- this is a little hand wavey argument, but the same kinds of ideas as the dynamic array-- if, whenever we got a linear-- we are more than a linear factor away from where we are trying-- basically, the fill factor we were trying to be, then we could just completely rebuild the hash table with the new hash function randomly chosen from our hash table with a new size, and we could get amortized bounds. And so that's what Python-- how Python implements dictionaries, or
3722	sets, or even objects when it's trying to map keys to different things. So that's hash tables. That's great. The key thing here is, well, actually, if your range of keys is small, or if you as a programmer have the ability to choose the keys that you identify your objects with, you can actually choose that range to be small, to be linear, to be small with respect to your items. And you don't need a hash table. You can just use a direct access array, because if you know your key space is small, that's great. So a lot of C programmers probably would like to do something like that, because they don't have access to-- maybe C++ programmers would have access to their hash table. Any questions on this stuff before we move on? Yeah? AUDIENCE: So why is [INAUDIBLE]? JASON KU: Why is it expected? When I'm building, I could insert-- I'm inserting these things from x 1 by 1 into my hash table. Each of those insert operations-- I'm looking up to see whether that--
3723	an item with that key already exists in my hash table. And so I have to look down the chain to see where it is. However, if I happen to know that all of my keys are unique in my input, all the items I'm trying to store are unique, then I don't have to do that check and I can get worst case linear time. Does that make sense? All right. It's a subtlety, but that's a great question. OK, so today, instead of talking about searching, we're talking about sorting. Last week, we saw a few ways to do sort. Some of them were quadratic-- insertion sort and selection sort-- and then we had one that was n log n. And this thing, n log n, seemed pretty good, but can I do better? Can I do better? Well, what we're going to show at the beginning of this class is, in this comparison model, no. n log n is optimal. And we're going to go through the exact same line of reasoning that we had last week.
3724	So in the comparison model, what did we use when we were trying to make this argument that any comparison model algorithm was going to take at least log n time? What we did was we said, OK, I can think of any model in the comparison model-- any algorithm in the comparison model as kind of this-- some comparisons happen. They branch in a binary sense, but you could have it generalized to any constant branching factor. But for our purposes, binary's fine. And what we said was that there were at least n outputs-- really n plus 1, but-- at least order n outputs. And we showed that-- or we argued to you that the height of this tree had to be at least log n-- log the number of leaves. It had to be at least log the number of leaves. That was the height of the decision tree. And if this decision tree represented a search algorithm, I had to walk down and perform these comparisons in order, reach a leaf where I would output something.
3725	If the minimum height of any binary tree on a linear number of leaves is log n, then any algorithm in the comparison model also has to take log n time, because it has to do that many comparisons to differentiate between all possible outputs. Does that make sense? All right. So in the sort problem, how many possible outputs are there?
3726	What is the output of a sorting algorithm? AUDIENCE: [INAUDIBLE] JASON KU: What? What's up? A list-- in particular, given my input-- some set of items A that has size n-- what I'm going to give you is some permutation of that list. So for each index, say, I could tell you where it goes. Another way I could say is, where does the first item go to, where does the second item go to, where does the third item go to-- blah, blah, blah-- like that. So how many different choices of a permutation are there? Well, how many choices do I have for the first thing of where it could be in the final sorted array? It could be in any of the places, so it's n. How about this one, the second one? Well, it can't go to where this one went, right but it can go anywhere else. So it's n minus 1. And since these are independent choices I'm making, if I multiply them all together, I get 9 factorial permutations that are the number
3727	of possible outputs that I have to my sorting algorithm. So for me, to have an output to my sorting algorithm be correct, I need at least n factorial leaves. Does that make sense? OK. The nice thing about doing this last week is this is really just the number of leaves and this is really the number of leaves. So what's the number of leaves is theta n factorial. Here it's actually n factorial, but I'm just going to put it there. And here we get an n factorial. I see. So it's at least omega n factorial. Does that make you happier? Theta here-- thank you-- has to be at least. So this was right. OK, so at least this many-- there are algorithms that, if it got-- it could take two different routes to get to the same output. So this is a lower bound on the number of leaves. OK? So what this argument is saying is that, if I just replace the number of leaves n here with n factorial, I get a similar comparison
3728	sort lower bound now. So what is log of n factorial? This is familiar from p set 1 maybe. So one thing I could do is I could put in Sterling formula, right? And that'll give me something of the form n log n. But what's another way I could lower bound n factorial? Well, I have a bunch of things here. That's n factorial. Half of these things-- these half, n/2 things-- are bigger than or equal to n/2. That make sense? So I can certainly lower bound this thing by n/2 to the n/2. That's a little easier thing to take a log of. If you take a log of that, that's asymptotically n log n. So what we're getting here is any sorting algorithm here takes at least n log n comparisons, and so a merge sort's the best we can do. That make sense to everybody? We're just piggybacking on the analysis we had about decision trees, connecting leaves with the minimum height of any binary tree on that number of leaves, and just replacing n
3729	with n factorial-- nothing super interesting here. Yeah? AUDIENCE: [INAUDIBLE] the n over 2. JASON KU: Yeah, sure. You can just plug in Sterling formula, but I did this, so I might as well clarify. There are n terms here in the product. Half of them are at least n/2. Does that make sense? I can lower bound this product by something smaller than half of the terms-- a product of that, and that'll be fine. So I'm taking n/2 of them and I'm multiplying n/2 altogether, n/2 times. Does that make sense? It's just providing a lower bound. I just need something that's smaller than all of these terms. And multiply them all together, and that'll give me a lower bound. OK, so we can't do better than n log n in the comparison model, but what we did last week was use random access and a direct access array to do better. OK? Can anyone think of how to use that idea to sort faster? And I'm going to give you a caveat here. I'm going to let
3730	you assume that the keys of the things you're trying to sort out are unique.
3731	So how could I use a direct access array to sort faster? Any ideas? Yeah? AUDIENCE: Could you just literally insert [INAUDIBLE] into a direct access array? JASON KU: Uh-huh. AUDIENCE: And then you look at that array and how to sort it. JASON KU: OK. So what your colleague is saying is exactly correct. It's something that I like to call direct access array sort. We won't really call it that, because there's something more general that we'll talk about in just a second. But what your colleague was saying is, instantiate a big direct access array-- direct access array sort. I'm instantiating this big direct access array of the space of my keys, and what your colleague was saying was I take each one of the items in my-- the things that I'm trying to sort, I look at each one of their keys, and I stick it in the direct accessory exactly where it needs to go, in constant time. That's great. Now, I gave you this caveat that all the keys were unique, so I don't
3732	have to deal with collisions here. But then, after I'm done with this, all of these things are now in sorted order, and what I can do is I can just walk down this list. A lot of these cells are empty, potentially. Some of the keys might not be there, but what I can do is just walk down this list, pick off every item that does exist, stick them in an array-- I'm done. Stick a key into here and then-- all right. Make direct access array. Store items-- item x in index x.key. Walk down direct access array, and return items seen in order. Does that make sense to everybody? All right, how long does this step take? Building a direct access array order u-- OK, so this is order u-- how long does this take? How many items you have to insert? Order n, or just n-- and how long does it take to insert each one of these things into my direct access array? Worst case constant time-- so this is n times worst case
3733	constant time-- great. How long does this last one take? Anyone? O of u also-- right, because I'm walking down the entire length of u. So this algorithm takes, in total, n plus u time. This is great. u is bigger than n, because we assumed distinct keys. But if u is on the order of n, then we now have linear time sorting algorithm. Yes? What's up? AUDIENCE: [INAUDIBLE] JASON KU: I'm sorry. You have to speak up.
3734	JASON KU: How do I attach keys to my inputs in my-- for a set data structure that we've been talking about, all of my items have keys. That's just something that we impose on our input. AUDIENCE: [INAUDIBLE] JASON KU: Each of the keys is-- in this case, it has to be a number. That's a nice point. We do this to talk about sorting items generally so that we don't have to deal with potentially if these keys have values associated with-- or other stuff associated-- put them on that item, and they'll still be there. But in general, if you just wanted to sort integers, you could say that .key is-- points back to the object itself, if you want to just sort some integers. Does that make sense? It's a good question, though. OK, so that gives us a linear time algorithm when u is small, and under this condition that I have unique keys when I want to sort. Those are fairly restrictive, so we might want to generalize this a little bit. OK? So
3735	that's direct access array sort. What if we had a set of keys that was a little larger? So let's say u is theta n implies linear time sorting. That's great. So now, what happens if we expand that range a little bit? Say u is less than or equal to n squared-- maybe just less than. OK, this is a bigger range And if we instantiated a direct access array of quadratics size, we'd have a quadratic time algorithm. This is not helpful. Anyone have a way in which we could sort integers that are between 0 and n squared? Maybe using the stuff that we had above-- Yeah? AUDIENCE: [INAUDIBLE] sort by the first n, kind of like the first digit. JASON KU: Your colleague is saying exactly the thing that I'm looking for, which is great, which is maybe we could break this larger number into two smaller numbers. Any integer that is between 0 n squared can be written as-- key can be some a and b, where a is essentially the higher n and b
3736	is the lower n. This is kind of weird. OK, so what do I actually mean by this? I mean that let's let a be K, when I divide it by n-- integer, the floor-- key integer to divide by n. And b equals K mod n. So this is a number that's less than n and this is a number that's less than n. Does that make sense? And actually, I can recover K at any time by saying K equals an plus b. I've essentially decomposed this into a base n representation of this number. And I have two digits in that number. This is the n-th-- n digit, and this is the ones digit. Does that make sense? All right, so now let's say I have this list of numbers-- 17, 3, 24, 22, 12. Here I have five numbers. So what's n in this case? 5-- OK, not so interesting. n is 5 here. And I'm going to represent this as five pairs of numbers that are each within the bounds of 0 to 4. Does
3737	that makes sense? So what is my a, b representation of 17? 3, 2-- OK. Yeah, so there are 3 times 5 plus 2. That's good. That's 17. Yeah? I think your colleague did that, right? I have all of these written down, so I'm just going to write it out. And I hope I did it correctly. OK-- 3, 2; 0, 3; 4, 4; 4, 2; 2, 2-- OK. So now I have a bunch of things that I want to sort based on this function that I have. These are no longer just integers that I need to sort. I need to sort by this transformation of this thing into a number. Does that make sense? So anyone have any ideas on how we could-- by the way, these are both constant time operations on your computer, as long as it's an integer division and this is mod. Python also has a nice thing, I think, in its standard operations, which is divmod of K, n. Is that right? Yeah. So if you want to use that, you
3738	can. OK, so how do we sort these tuples? These are tuples, right? You guys are, I'm sure, very familiar with tuples by now. How do I sort these tuples? What's the most important digit of this thing? If I had to sort one of the digits and get something that's close to sorted, what's more important-- the 1's digit or the n's digit? OK, we have discrepancy here. Who says 1? Who says n? Someone who said n tell me why. Oh, you all think that way for no reason. AUDIENCE: [INAUDIBLE] JASON KU: Yeah. Sorry. This is a little confusing. This is the 1's digit. This is the n's digit. This is the n's digit. This is the 1's digit in how I'm writing this. Does that makes sense? Yeah? AUDIENCE: [INAUDIBLE] have a different ones digit inside of it. So you could have [INAUDIBLE] but that only tells you where they are with regard to the specific n category they're in. So it's more of a [INAUDIBLE]. JASON KU: Yeah. So what your colleague is saying is
3739	exactly correct. I could vary b all I want right with the same a. If I change a by 1, it doesn't matter what b is-- it's going to be bigger. Does that make sense? The K is much more sensitive to a than it is to b, so a is more important than b. Does that make sense? So if I just wanted to get some linear time algorithm, I could just sort by their bigger digits and hope they don't differ very much on the smaller things. I've kind of sorted these things. Does that make sense? OK. What if I actually want to sort these things? Any hints? Yeah? I need to sort on both, in some sense. What I'm going to tell you right now is an algorithm that I like to call tuple sort, but you can also think of it as Excel spreadsheets sort. I have an Excel spreadsheet of a bunch of data. I have a prioritization on how important the keys are to me-- the columns. And if I have a very
3740	important column and an order of the columns of how important they are to me, I can repeatedly sought on the columns until they're sorted based on my preference. That's something that you may have done. Now, if I have an ordering on the preferences of my columns, do I start by sorting all of them on the most important thing or the least important thing? What? Who says most? Who says least? There's discrepancy here. All right, let's try it out. All right, tuple sort-- let's start by sorting these things by least significant first, and then-- no, most significant first and then least significant. That was the first thing I asked you, right? All right, so these are the most significant things, the first ones. And these are the less significant things. All right, instead of writing it as tuples, I'm going to write them as 32, 03, 44, 42, 22. Is everyone cool that? This is just base five representation. All right, so let's start by sorting all of these things by the most significant thing, which
3741	is by this guy, this guy, this guy, this guy, and this guy. So how do I do it? The first one is 03, second one is 22, the next one is 32, 42, and then 44-- maybe 44? I don't know. Does it matter, the order in which I put these things? I don't know. I'm just going to keep it the same order for now. All right, so I've sorted it by the least significant-- or the most significant-- sorry-- the leading term. And now I'm going to sort by the least significant. So what's the least significant here? 22-- then 2 is also-- this is also 2. This is also 2. This is 3. And sorted list-- voila. Why did that not work? Yeah? AUDIENCE: [INAUDIBLE] JASON KU: Yeah. So what happened is I did take into account the significant digit sort, but when I did the less significant thing, it erased all of my work from up here. Does that make sense? In the case of ties, we want the more significant thing to take precedence,
3742	so we want to do that thing last. Does that makes sense? So the right way to do this-- this is the most significant first [INAUDIBLE] not good. All right, at least significant first-- let's try that. So least significant here is 2. OK, so I see 32, 42, 22, 03, and then 44. OK? Sound good? Least significant first-- now I do most significant. I sort the most significant thing. OK, so what's the most significant thing? 03, 22, 32-- most significant four-- 44, and 42-- cool. We're sorted, right? I did what you told me to do. I sorted by the most significant thing. What's the problem here? What did I do wrong? You wanted me to put 42 here and 44 here, right? Because 42 came first in the input and 44 came second, right? OK, if a sorting algorithm maintains this property that, if they are the same thing, then the output maintains their order from the input to the output--
3743	algorithm. And so if we have a stable sorting algorithm when we're doing tuple sort, when we're sorting on different keys or columns of a set, we really want to be using a stable sorting algorithm. Does that makes sense? Because otherwise, we may mess up work we did before in a previous sort of the less significant things. And so yes, we want a stable sorting algorithm here, because then we will end up sorting our thing. Does that make sense? Yes? AUDIENCE: [INAUDIBLE] JASON KU: So what your colleague is saying-- let's sort by most significant, then look at all of the things with one of those that are the same, and now sort that. That's something we could do. How long would that take? Well, let's say I didn't use half of my more significant set of digits. Say I'm only using n/2 or-- that's not quite going to get what I want. AUDIENCE: [INAUDIBLE] JASON KU: Say again. AUDIENCE: We'll take n squared [INAUDIBLE].. JASON KU: Yeah. So what we're going to do, if we have
3744	direct access array sort-- if I then go into each one of these digits and try to sort the things that are in there, that's going to take time. It's going to take time for each of those digits. There might be a ton of collisions into one of the things, and so I might take more time to sort that than linear. Does that make sense? So I would prefer to do this tuple sort kind of behavior, sorting the smaller thing, sorting the bigger thing. And because I only have a constant number of things in my tuples, this is important, because I only have two things I'm worried about here. I only have to do two passes of a sorting algorithm to be able to sort these numbers. However, can I use direct access array sort here? What was the initial stipulation I had on direct access array? That the keys were unique-- that's exactly the opposite of what we have here. We have things that could be the same. So we give up-- can't do it.
3745	What do we do instead? Yeah? AUDIENCE: [INAUDIBLE] JASON KU: You've already said the thing that I'm looking for, so that's great. Your colleague said, why can't we just put more things at a key? Why can't we put a list there?
3746	This is called counting sort. And what we do here is we still have this direct access array of space u minus 0 to u minus 1, but instead of storing one thing here at each key K, we store a pointer to a chain. This sounds like hashing, right? But the important thing is that I need to make sure, as I'm inserting things in here, that I'm maintaining the order in which they came in. I can't just throw them willy nilly, or else we have this problem up here that we had before.
3747	structure, something that will maintain the order that I-- the extrinsic order that I had when I'm putting these things in. So as I have multiple things with K, I'm going to put them in the order. I can put-- have a pointer to a dynamic array or a linked list, where I just add things to the end. And then, at the end of my algorithm, when I read off the things, I can just look at anyone that has a non-empty data structure under here and read them off in the order that they came. Does that makes sense? So for this example, I'm just going to do this last step here from the first row to the second row. I'm going to have this direct access array with 0, 1, 2, 3, 4 on the slots. So how am I going to do this counting sort now? I have 32, 42, 22, 03, and 44. I can take the first one, 32. I'm sorting by the most significant thing. I stick it here-- 32, and then 44--
3748	42-- sorry-- 42, 22. This is not so much different yet then dynamic array-- direct access array sort. But when we get to this duplicate, 44 here, we now have two things in this thing. And because we are keeping them in order in this sequence, I'm appending to the end. Then, when I go and read off the different things, then I'm returning them in a stable way in the way that I want them to be. Does that makes sense. And it's not overwriting the work I did on the lower significant digits. So how long does this take? This also only takes order n plus u, because I'm instantiating this thing of size u. And then, how big are these data structures? Well, maybe I'm storing one, a constant amount for each index. So that's a u overhead. And then I'm paying 1 for every item I'm storing. These things are only the lengths. The sum total of their lengths is n, because I'm only storing n things in there. So the total amount of space, the
3749	total amount of work I have to do is order-- I need to be able to spend in constant time and I need to be able to cycle through these things, iterate over them in linear time. But if I have that, I get n plus u. Yeah? AUDIENCE: How do you ensure that, within your linked list or your dynamic-- those elements, like four equals four-- how do you make sure that those are sorted? JASON KU: So your colleague is saying, how do I ensure that the things in these lists, where they collide, how do you ensure that they're sorted? I don't. I just ensure that they came in the order that they came. But as long as I sorted the lower order digits correctly in the previous things, then I'm assuming that their order as they come in will be sorted, if they collide. That's the assumption. That's the reason why I'm doing these building up from the least significant to the most significant is so that I know that, when they collide, the underlying stuff
3750	there is sorted already in the input. Does that make sense? Great-- yeah? AUDIENCE: So this array isn't as big as u. It's as big as n. JASON KU: I'm using a direct access array on the keys-- oh, this is n. So counting sort is general for any u. I just happened to pick u being n in this case when I broke this thing up into n squared. But this general concept is-- doesn't matter what I choose for u. Does that make sense? OK.
3751	larger ranges of numbers. This was exactly the idea. We're going to combine tuple sort, use counting sort as its auxiliary sorting-- stable sorting algorithm to do all its work on these digits. And so to sort of on n squared size numbers, I get linear time, which is great, because u is n in this case. But can I extend that? What if I had n cubed? What if I had up to size u equals n cubed, or less than n cubed? How many digits would I have there? How many size n digits what I need to represent a number of size n cubed? Any ideas? What did we do here? We divided off an n. We took it and stored it. We're left with something of size n. If I had a number of size n cubed, I could divide off an n. I'm left with something of n squared. I don't know how to deal with something of n squared. Actually, I do. I can split it up into two size n numbers. So if
3752	I had numbers bound-- upper bounded by a cubic-- n cubed-- I could split it up into three digits. Three is still constant. And so I could split it up into three digits, tuple sort them in their increasing priority, and sort those. Again, I'm doing linear work per digit. I have a constant number of digits, so I get a linear time algorithm. Yeah? AUDIENCE: When it comes to sorting [INAUDIBLE]---- JASON KU: Uh-huh. AUDIENCE: Are you ensuring that that runtime is also big O of n plus u? JASON KU: Yeah. So it's always going to be big O of n plus u, but because I'm bounding my digit size to be n, u is n there, and so I'm getting linear time. Does that make sense? Yeah. So the idea here-- this is what we call radix sort. Radix sort-- break up integers, max size u, into a base and tuple. So basically, each one of my digits can range from 0 to n. How many base n digits do if I have a number of size
3753	u? Yeah, log n of u-- number of digits is log n of u-- log base n of u. And then tuple sort on digits using counting sort, from least to most significant-- that's the algorithm. How long does that take? How long does it take to sort on a digit that spans the key 0 to n? Linear time, right? Order n time-- how many times do I have to do this tuple sort? The number of digits times, right? So the running time of this algorithm-- first, I have to do this stuff, break up each of the integers. That takes n time-- n times the number of digits. I had to create each one of these tuples-- so n plus n times the number of digits-- log base n of u. So here I had to loop through all the things. And then here, for each thing, I broke it up into log base n of u digits, and that's how long the first thing took. And then, how long did it take me to tuple sort?
3754	n time per digit-- so I also get this factor. Does that make sense? How long is that? Is that good? Is that bad? For what values of u is this linear time? If u is less than n to the c for some constant c, then the c comes out of the logarithm, log n of n is 1, and we get a linear time algorithm. Does that makes sense? OK. So that's how we can sort in linear time, if our things are only polynomially large. So in counting sort, we get n plus u. In radix sort, we get also a stable sorting algorithm where the running time is n plus n times log base n of u. Does that makes sense? And then, in the situations where-- there's a typo there in counting sort-- that should be when u is order n-- counting short runs in linear time. And it's linear time also in the case of rating sort, if our things are bounded by a polynomial in n, by n to the c for some
3755	constant c. Does that make sense? All right, so that's how to sort in linear time, with the caveat that your numbers aren't too big. OK, see you next week.
3756	[SQUEAKING] [RUSTLING] [CLICKING] JUSTIN SOLOMON: OK, team. Let's get started for the day. It's a pleasure to see all of you guys. In case you don't remember, I'm Justin. I'm the third instructor of 006 that you probably forgot about, but you're going to see a lot more of me in the graph theory part of our course because that's the part of algorithms that I like. If I were reincarnated as a theoretical computer scientist, I would probably go into this area. Hey, guys. OK. We have our PhD admit visit days coming up for the next couple of days I'm working on my camp counselor cheerleader voice. So don't make me wake all of you guys up for the day. You're not going to like it. But in any event, so in 6.006 if you look back at the course outline, we're officially
3757	There are a few corollaries to that fact. So unless there are any questions about that, we'll get started with our new unit in 6.006 which is a graph theory. If you're wondering, there's a graph on the screen here. But of course, we'll fill in a little bit more information today throughout our lecture. When I was learning how to teach, which I'm still doing, actually my PhD advisor told me if you want somebody to learn something, you have to write it as big as possible. And so I'm really leaning into that approach today in our slides. So in any event, so today we're going to have our first lecture on graphs which I think will somewhat be a review for many of you guys. And if it's not, that's cool too. Because we'll start from the beginning and kind of build up all the notions that we need to understand and process graphs and hopefully by the end of lecture, have some style of algorithm for computing the shortest path from one vertex to all the
3758	other ones.
3759	some people call this network, but sometimes that term is overloaded with a few different kind of variations on the theme-- is a collection of two things. That's what this parentheses notation means. There's a set of vertices and a set of edges. And the edges, like you can see in the sort of third point on our screen here, are a subset of v cross v. Now this is fancy notation for something really, really simple. Because what is this telling me? This is telling me that an edge, like in the picture that we see on the screen here. it just just something that connects to vertices together. So if I think of there being a pair of vertices, like the from and the to, then that is a subset of the cross product of v and itself. So hopefully the notation in that third line on the screen makes some sense. This is just fancy notation for edges are pairs of vertices. But of course, inside of that notation there are two special cases that we care
3760	about in this class. One is when you have a directed graph, and one is when you have an undirected graph-- because I said them in opposite order from what's on the screen. So in an undirected graph, I guess we still think of an edge like a pair of vertices, but really I should have notated this slightly differently-- in fact, maybe I'll revise it in the slides before they go into OCW-- where instead of writing e equals w comma v, I should write in fact equals v comma w. And notice that there's a slight difference between the notation on the slide and what I've written on the board, which is the set notation here. What's the difference between parentheses and squiggly lines is that this guy is unordered. This is a set of things. And what's on the board is ordered-- or what's on the screen rather. And of course, in an undirected edge there's no such thing as an edge from w to v being distinct from an edge from v to w. Those are
3761	the same thing. They're undirected. It just is a notion of connectivity. Whereas in a directed graph, now we're going to use that parenthetical notation to say that the edge from w to v is different than the edge from v to w. That's going to make a big difference. So for example in the graph on the right-- let's maybe redraw it on the board here. So we have four vertices. I drew this last night, and I'm hoping that this example actually works. Like that-- can I get from the upper right vertex to the lower left vertex following edges in this graph? I heard one person. Everybody on three-- 1, 2, 3. AUDIENCE: No. JUSTIN SOLOMON: No, right. Because if I wanted to-- I mean maybe I think of drawing this path here-- but of course, if I would go from the upper right to the lower left-- this is like the ugliest thing I've ever done, I'm so sorry-- you can notice that the edges are pointing in the up direction here. So I'd have to
3762	go against the stream of the water, but that's not allowable in the directed graph case. Of course, I'm already anticipating the notion of a path which we haven't really defined yet. But I think intuitively, that's sort of the big difference between a directed and undirected graph. Does that distinction makes sense to all of you all or have I managed to lose you in four minutes or less? Excellent.
3763	notes because I figured we'd define what a graph is first before telling you what the implications are. But in any event, I think it's really not a big stretch of the imagination to say that graphs are literally everywhere in our everyday life, right. Any time that we come up with a network of stuff connected together, implicitly the right abstraction often in the back of our heads is to think about a graph. So some simple examples that I think would all come to mind for us would be like computer networks-- so the nodes or the vertices of your graph in that case, maybe are computers, and then the edges are roughly the cables connecting them together in my very coarse understanding of how networks work-- or maybe at a social network-- the nodes are people on your social network, and the edges are friend relationships or frenemy relationships or whatever. In fact, I think you could think of both directed and undirected versions of that particular network. In road networks, maybe I'm working for Google and
3764	I want to tell you the shortest path between your house and MIT. Of course, in order to do that and essentially behind the scenes, we're solving some version of computing the shortest path between two vertices in a graph. That's a tiny bit of a lie in the sense that there's a lot of structure in that problem that we're not going to leverage in this course. A road network is a very special type of graph, and if you take an advanced course maybe you'll say, well, if I know a little more about my graph I can do better than the general case we'll talk about here. But the basic algorithms that we'll talk about in 6.006 are certainly relevant in that case and are really the building blocks for what goes on in the tools that are used every day on your phone when you open Google Maps or Ways or whatever. And of course, there's many others. So for instance, an example that maybe is a little bit more subtle would be the set of
3765	states and transitions of a discrete thing. So think about like a Rubik's cube. So I could make a graph where the node is every configuration of my Rubik's cube, like every rotation. And then the edges are like can I get from this configuration to that one by making one simple transition, like one flip. I don't actually know the terminology in Rubik's cube, I have a feeling you do, for one rotation. Twist-- thank you. And of course, there are many other places. So for instance, in my day job here at MIT
3766	And actually graph theory, although we talk about it very differently, appears in that world constantly. Because of course, with sitting behind any 3D model on your computer is a giant network of triangles. This is called a triangulated surface-- like this torus we see here. And this is nothing more than a graph. And in fact, if you squint at the algorithms that we cover in six eight three eight, you'll see they're roughly just graph algorithms in disguise. In fact, if you take my graduate course one thing we'll do is we'll spend a lot of time doing differential geometry. And then we'll step back 10 feet and notice that exactly the algorithms we are using for computing curvature and bendiness on triangle meshes, just looks like a graph algorithm and can be applied to networks in exactly the same way. So it will be a nice kind of fun reveal there. And of course, there's one last kind of fun application. I actually was gone the last couple of days at a conference on political redistricting. And
3767	the funny thing is most of the discussion at that conference was about graph theory. And the reason for that is sort of a theme that shows up a lot in geometry world, which is if I take my state, in this case I think these are the voting precincts in some state or another, and I look at adjacency relationships, then maybe I put a node for every precinct and an edge any time that they share a boundary with one another. Well now I have a network. And maybe a region on my graph is like a connected piece of this network. And so anyway, this is one of these examples where graphs and networks and connectivity and so on just show up literally no matter where you go. They're totally unavoidable. And so that's what we'll be spending quite a bit of time on in this class here. Now you could easily take, I would argue, at least three entire courses on graph theory here at MIT, and you could easily build a PhD dissertation doing nothing
3768	more than really simple problems on graphs. Of course, in this class we're limited to just a few lectures out of many. So we're going to make a couple of assumptions both on the problems we want to solve, as well as in the graphs that we care about. So in particular, one simplifying assumption, which actually really doesn't affect
3769	but it's worth noting explicitly, is that we'll mostly be thinking about a particular type of graph which is a simple graph. And in fact often, depending on how you define your graph, you kind of accidentally made your graph simple even if you didn't intend to. So for example, we wrote that our edges were a subset of v cross v. Which maybe means that I can't have multiple edges that sort of traverse the same pair of vertices. So let's see an example of a graph that is not simple. So sorry, I haven't actually defined it. A simple graph is a graph that has no self loops, so it can't go from a vertex to itself, and every edge is distinct. So let's make the most non simple graph we can think of. Like let's say I have two vertices. So maybe if I want to make my-- so there's a graph, right, two vertices and one edge. This is simple. If I wanted to be annoying and make it not simple, maybe I take this edge
3770	and I'd duplicate it three times just for fun. That violates the second assumption. And now to make it even worse, I could violate the first one by adding an edge that goes from this vertex to itself. This is not simple. I don't know what you would call it actually-- general graph, I guess-- complicated because it's not simple. I don't know-- a multigraph. I always thought of that-- anyway, it doesn't matter. But in any event, in this class we're not going to worry about this particular circumstance. And of course, in many applications of graph theory that's a totally reasonable assumption to make. Any questions about the definition of a simple graph? OK, so from now on whenever we think about a graph, in the back of our head we're going to think of our graph as simple. There's one nice property that a simple graph has, which I've written in really big text on the screen here, which is that the edges are big O of v squared. And in fact, let's expand that formula just
3771	a tiny bit. So there's sort of two cases, one is when my graph is undirected, the other is when my graph is directed. So if I have a directed graph-- well, let's think about how many edges we could possibly have. So an edge is a pair of a from vertex and a to vertex, and I can never repeat it twice. That's sort of like the second assumption here. So in particular, what do we know? We know that mod E-- or rather the number of edges in our graph is upper bounded by what? Well, I can take any pair of vertices-- like that-- but I have to be a little bit careful because my graph is directed-- so from and to matter here. So this is v choose 2 is saying that I can take any unique pair of vertices, but I have to put a factor of 2 in front of it to account for the fact that the source and the target can be flip back and forth. And of course, if I want
3772	to do the undirected I don't have to worry about that. We'll get E here is less than or equal to just mod v choose 2. So this is just a fancy way of saying that every edge consists of two vertices, and my edges are unique. And one thing, if you just write down the formula for our binomial coefficient here, we'll see that both of these things-- oops, oh, yeah, sorry-- are at worse mod v squared here. And that makes perfect sense, because of course, an edge is a pair of vertices. You kind of expect there to be a square there. Yes? AUDIENCE: [INAUDIBLE] JUSTIN SOLOMON: I'm so sorry. I can't hear you. AUDIENCE: So the 2 comes from the fact that it's from the source. JUSTIN SOLOMON: Yes, exactly. So the 2 for the director case, comes from the fact that an edge from v to w is different than an edge from w to v. So remember that the binomial coefficient here, it's just counting the number of ways that I can choose two
3773	things from a set of size v, but it doesn't care about ordering. Yeah, any other questions? Fabulous. So why is this going to matter? Well, these sorts of bounds, I mean they might seem a little bit obvious to you, but we're going to write down graph algorithms. And now when we analyze the runtime and the space that they take, we now have sort of two different numbers that we can think about-- the number of vertices and the number of edges. And so for instance, if I write down an algorithm whose runtime is proportional to the number of edges, maybe then genErikally I could also think of the algorithm as having a runtime that looks like the number of vertices squared unless I put some additional assumptions on my graph. And so there's some connection between all of these different constants, and it's useful to kind of keep that at the back of our head. That sometimes you'll see a bunch of different expressions that really are encoding roughly the same relationship just in different language
3774	Of course, that also means that we can be more precise. So sometimes a graph is what we would call sparse. So in my universe, almost all graphs that I deal with in my day to day life are extremely sparse. This is a consequence of topology. And because of that, an algorithm that scales like the number of edges might actually be much preferable to an algorithm that scales like the number of vertices squared because, in practice, often there are fewer edges than like every single possible pair. And so that's the sort of reason why it's we're thinking about these numbers.
3775	So some other ones that we should think about involve the topology or the connectivity of our graph-- in particular, thinking about neighbors. So in general we kind think about pairs of vertices as being neighbors of one another if there's an edge between them. We have to be a little bit careful because, of course, when we have a directed edge, we have to be careful who's on the sort of giving and the receiving end of this neighbor relationship. Yeah, so let's draw a really, really simple graph. So here's vertex 0, here's vertex 1, here's vertex 2. And maybe we'll have an edge going up, an edge going down, and then a cycle here. OK. Now we can define a lot of different notions of neighbors-- like the outgoing neighbor set, the incoming neighbor set. And the basic idea here is that we want to keep track of edges going from a vertex and edges pointing into one. Yeah, so for instance, the outgoing neighbor set, which we're going to notate as Adj plus here-- what is
3776	the outgoing neighbor set of node 0 here? Well, if we take a look, notice that there's one edge going out of node 0, and it points to node 2. So of course, this is a set which just contains one other node. And similarly, the incoming neighbor set of node 0, well notice that there's one incoming neighbor from vertex 1, so that is a set like that. Now of course, in an undirected graph the sort of distinction between these two things doesn't matter. So if you look at our final bullet point here, often in the undirected case we just drop that plus or minus superscript because it sort of doesn't matter. In any event, there's one additional piece of terminology that matters quite a bit, which is degree. And this is nothing more than just counting the size of this set. So the out degree is the number of edges that point out of a vertex. And the in degree is the number of edges that point in. So notice in this case, both of those
3777	numbers are 1. Let's see an example where they're not. So in node 1, notice there's two edges that come out. So the out degree of node 1 is 2. There's one edge that points in, so the in degree is 1. OK, so often why are we going to do this? Well, we're going to get a lot of graph algorithms that like have a FOR loop over the neighbors of a given vertex. And then this degree number is going to come into play. It's worth bounding these things just a tiny bit. So in particular, one thing we could think about-- I write too big, and I'm going to run out of space really quickly here-- is the following. So let's take a look at all of the possible nodes inside of my graph, and now let's sum up all of their degrees. So I'm going to-- let's see, if I look at this graph notice there's three edges adjacent to this vertex here, three edges adjacent to that one, two adjacent to this. So we sum
3778	them all together. So it's just a convenient bound to have around-- is to sum these things, because we're going to have algorithms that look like for every vertex, for every neighbor do something. So we might as well know roughly how much time that's going to take. Let's think about this. So what do we know? In an undirected graph every edge is adjacent to two vertices. So if we think about how we account for degree what do we know? Well we know that an edge sort of contributes to the degree of two different vertices. So if we think about it carefully here, what we're going to see is that if our graph is undirected-- oh, sorry-- is that right, wait I'm backward again. So if I have a graph with two vertices and one edge and it is undirected, notice that is the number of edges here is 1. What is the sum of the degree? Well, it's 1 plus 1 equals 2. Yeah, so there's a 2 here if my graph is undirected, and E
3779	if my graph is directed, if what I'm counting is just the outgoing degree. Does that makes sense? I think I managed to totally botch that sentence, so maybe let's try that again. So if I'm counting just the number of edges pointing out of every vertex, and I count that over all of the possible vertices, then there's two cases-- one is directed and one is undirected. So in the undirected case you get a 2 here because essentially every edge is simultaneously in going and outgoing. Whereas you get a 1 as the coefficient in the directed case. Does that makes sense? I'm sorry I botched that for a second. OK, excellent.
3780	Now we think about graphs, of course, we just spent the last couple of weeks thinking about data structures. We should think about how to store a graph on a computer, and there's many different options. In fact, really one thing that you can do is sort of pair-- just like when we talked about sets. There are many different ways to store sets. And one way to think about it was depending on how we're going to interact with that set we might choose one data structure or another to sort optimize the types of interactions we're going to have with that set and make them as fast as possible. This is exactly the same story for a graph. So for instance, the world's dumbest representation of a graph would be to just have a long list of edges. So for example, for this graph up here maybe I have 0, 1, that's an edge, and then 0, 2, that's another edge, and then 1, 2, and then 2, 1. There's a big list of edges. It's really a
3781	set. I don't care about the order. AUDIENCE: The first one's 1, 2. JUSTIN SOLOMON: 1-- oh, you're right. I'm sorry. Yeah, the edge points up-- thanks Erik, or not Erik-- Jason. OK, so let's say that I have a graph algorithm, and I'm going to have to do something like check whether there exists an edge from v to w a bunch of times. How long is that going to take in this data structure? Well, if I just have like a hot mess disorganized list of edges and I want to know does there exist an edge from v to w, all I can do is write a FOR loop that just goes along this and says, like this the edge I'm looking for. No. Is that the edge I'm looking for? No. So every single time I want to find an edge, it's going to take me time proportional to the number of edges of my graph which could potentially be up to v squared. Yeah, so this is not such a great representation of a graph
3782	on my computer. So if we're thinking back to our data structure we may say, OK, so an edge list is probably not the way to go. Although notice that the way we notated what is a graph kind of looks like an edge list. But in any event, the more common thing to do is to source something like an adjacency list. So the basic idea of an adjacency list is that what I'm going to store is a set that maps a vertex u to everything adjacent to u. So in other words, I'm just going to keep track of all the outgoing edges from every vertex. And now I have to decide, how am I going to store this object. And oftentimes, we're going to have to answer queries like does there exist an edge from v to w. So how could I do that? First, I would look up v, and I get back sort of a list or a set of all the things that are adjacent to v. And I have to query that
3783	thing. And I want it to be pretty fast. So maybe what I do is I store the set of adjacent stuff as something like a direct access array or a hash table to make that look up fast. So for example, how long would it take-- I see, I'm going to finish the sentence here-- how long would it take me to check if an edge existed in my graph? Well, what would I do? I would first pull out this object, and then I'd look inside of here. So if I stored this as a hash table, then the expected time I would have order one look up, because this is order one and then you have another order one look up there. So we went from v squared to one with one simple trick. Yes? AUDIENCE: Does it matter what direction [INAUDIBLE] JUSTIN SOLOMON: That's a great question. So this is a design decision here. I'm sorry, in my head I think a lot about undirected graphs, and I'm going to make this mistake a lot. And
3784	I'm glad that you caught me. There's a totally reasonable thing to do, which is maybe just to keep track of the outgoing edges for every vertex. This is a design decision. For an algorithm maybe I want to keep track of the incoming edges. Whatever, I just have to make sure that it aligns with what I want to do with my graph later. Excellent point. Sorry, as a geometry person we rarely encounter directed graphs. But it's important to keep remembering that not everybody works on the same problems that I do. OK, now if I wanted to be totally extreme about it-- as just a third example of representation, which actually, in some sense, you could think of like an adjacency list-- we need an adjacency matrix where now I just keep a giant v by v array of like does this exist, does that edge exist. Now it's really, really easy to check if an edge exists. But now let's say that I make a graph algorithm that's going to have a FOR loop over all
3785	the neighbors of some vertex. So here, if I wanted to loop over all the neighbors of u, I could do that in time proportional to the number of neighbors of u. But if I just have a big adjacency matrix, just a bunch of binary values-- like for every pair of vertices are these vertices adjacent-- yea or nay. If I want to iterate over all my neighbors, now I have to iterate over all the vertices and check is that number one and then do something. So actually that can incur some additional time and additional space. Does that makes sense? So in any event, that's a sort of a lazy man's graph representation. I use it a lot when I'm coding because adjacency matrices are easy to work with. But it does incur a lot of additional space, and it's not always the most efficient thing even if you have the space because iterating over neighbors, it actually can take quite a bit of time.
3786	is to start introducing sort of the canonical problem that we all worry about on graphs which is computing paths, in particular shortest paths. So the first thing we should do is, of course, define what a path is on a graph. So we're going to talk about our graph like a road network. Let's think of maybe every node here as an intersection. So this is a roughly Kendall Square. See it's a square. But in any event, let's say that I want to find-- maybe a question one would be does there exist a way to get from vertex 1 to vertex 3. And then a better question to ask would be does there exists a short way to get from vertex 1 to vertex 3. Then of course, the first thing I have to do is to define my enemy. I have define what I'm looking for, which is a path. So a path is nothing more than a sequence of vertices in a graph where every pair of adjacent vertices in that sequence is an edge.
3787	I think this all aligns with our intuition of what a path is in a graph. So for instance, here's a path p equals v1, v2, v3. So notice that there's an edge from v1 to v2 and also an edge from v2 to v3. So it satisfies the assumptions set forth in our definition. What would not be a path in our graph-- would be like v1 comma v3, because there's no edge there. OK, so if we talk about paths, then there's a very natural notion which is the length. Length, I guess you could think of like the number of vertices in your path minus 1, or the number of edges that your path traverses. Those are the same thing. So for instance, the length of the path p here is 2. Does everybody see that? A very common coding bug that I encounter a lot is adding 1 to that number by accident. Because of course, there's one more vertex in your path than there are edges. OK, and there are many different-- there could be
3788	potentially more than one path between any pair of vertices. So let's say that I have an undirected graph that looks like the following. So it's just a square plus a diagonal. So here are nodes. So then a perfectly valid path from the lower left to the upper right would be to go one over and one up, but of course, there's a more efficient way to get from the lower left to the upper right, which is to go across the diagonal. And so when we talk about the shortest path, it's nothing more than the length of the path that has the fewest number of edges or vertices between any pair of vertices in my graph. OK, so this is our enemy. This is what we're after. It's computing the shortest path between vertices in a graph. And this is the thing that we'll be talking about quite a bit in this course. Because of course, it's a very practical matter. Like when I want to solve routing problems, I want to move packets out of my
3789	network, I'd prefer not to-- well, unless I'm doing Tor-- I would prefer them not to hit too many computers in between. Then maybe I want a computer shortest path. Or on a surface maybe I want to move information
3790	But of course, there's sort of many variations on that theme when we talk about shortest path or even just existence of a path. So these are three sort of model problems that we might solve on a graph. So the first one, which in this of course we're calling the single pair reachability, would be the idea that I take two vertices s and t on my graph g, and I ask you does there exists a path between s and t. So what would be the sort of extreme example where this problem may not always give back the answer yes? Somehow in our head, I think we think of all graphs as being connected. But a perfectly valid graph the way we've defined it would be like 10 vertices and no edges. This function would be very easy to code if that were the only graph you ever cared about. But any event, the existence of a path is already a query that takes a little bit of algorithmic thinking. We haven't figured out how to do
3791	that yet. Now another problem we can solve would be the shortest path. Given a graph and two vertices, we might say, well, how far apart are these vertices of my graph if I want to use the shortest possible distance from one to the other. Notice that I can use the second problem to solve the first one. Because what's the length of the shortest path between two vertices that don't have a path between them? Infinity or a shrug-- that's actually a totally valid answer. Yeah, that's right. So how could I implement the reachability code? Well, I could call my shortest path code, and it gives me infinity. Then I return no, it's not reachable. And if it gives me not infinity, I return yes. So remember that a key idea in an algorithms class is this idea of reduction. That I can use one function to solve another. So in case, if we can solve shortest path, then we can certainly solve the reachability problem by calling that piece of code. And then finally we could
3792	talk about single source shortest path. So notice now that there's only one input node here s-- so what this problem is saying is give me the length of the shortest path from s to every single other vertex in my graph. Does that makes sense? Like maybe I return a big array with all the information, every single shortest distance. So can we solve single pair shortest path using single source shortest path? Absolutely. I could take s in my single pair shortest path problem, compute the shortest path from s to literally everything else, and then throw away all of that information except the shortest path to t, and now I'm good. Now I haven't justified that this is the fastest possible way to solve that second problem, but at least it shows that if I can solve problem three I can also solve problem two. If I can solve from two I can also solve problem one. So in today's lecture, we're just going to worry about problem three. In other words, these things are sort of
3793	listed in increasing order of their difficulty. OK, so in order to think about the single source shortest path problem, we're going to make one additional construction. And this is an idea called the shortest path tree. I got lazy drawing PowerPoint slides at 2:00 AM yesterday,
3794	So let's draw a graph. So here we have a, b-- I'm going to use letters instead of numbers to refer to nodes from now on because I don't want to confuse the length of the shortest path with the index of my node. So here's a, b, c-- I'm going to match my notes here-- d, e, f. Here's a graph-- again undirected because your instructor likes to think about undirected graphs. But I know I'm going to get feedback that I shouldn't have done that later. But in any event, let's say that I want to compute the shortest path from a to everything else-- or the length rather. So first of all, even without talking about an algorithm, I think it's pretty easy to guess what it is. So clearly the shortest path from a to a has length 0. The shortest length from a to b is 1, from a to c is 2-- because I can follow these guys. Now it gets complicated. It branched. So the next shortest path is length 3, and then
3795	4 like that. Does everybody agree with me that the numbers I've decorated here are the length of the shortest path from a to everything else? But what have I not done? I haven't told you how to actually compute the path, I've just given you the length of the path. So I may want a piece of code that in addition to doing single source shortest path length, also gives me a single source shortest path. So initially when I think about that, I might think about, well, how do I even write down a data structure that can store all of those paths. Well every path could have like v vertices in it, right. It could be that for whatever reason, there's a lot of branching in my graph. And all the paths are super long. Actually, I guess I have to think about whether branching would make them longer or shorter. But in any event, I could have a really boring data structure that just for every single vertex keeps track of the shortest path from a
3796	to that vertex. How big would that data structure be? Well, if the only bound I have on the length of a path is that-- it certainly at most it takes all the vertices in my graph-- then any one path will take v space. So that would take v squared space total. That wouldn't be so good. Because somehow I have an amount of information on my graph currently that's linear. It's just the length of the path. If I want to actually reconstruct that path, initially sort of spiritually feels like I need way more space to do that. But the answer is that we actually don't. That we're going to only need linear space, and the idea for that is to store an object called the shortest path tree. Yes? AUDIENCE: Just for [INAUDIBLE] previous [INAUDIBLE].. JUSTIN SOLOMON: So the question was about recursion. We haven't actually written down any graph algorithms. So we're going to defer on that until we actually recurse. And then we'll think about it more carefully. Yeah, but it's a totally reasonable
3797	question. There are plenty of recursive graph algorithms out there. And then we'll have to do our counting very carefully for sure. Right, so instead, we're going to define an object called the shortest path tree. And the basic trick here is to say, well, how did I get from a to c? Well, there's always a vertex, which is its predecessor, on the shortest path. And shortest path have this really beautiful property, which is that the shortest path from a to c, if I truncate it-- right, so it goes a to b to c-- then the truncated one is also the shortest path to that previous vertex. So let's think about that a little bit, because that sentence was, as usual, poorly phrased by your instructor. So let's say that I have the shortest path from a to d, which is very clearly a, b, c, d. I think we can all agree. And now I take like this sublist. I just look from a to c. Is there ever a circumstance when this is not the
3798	shortest path or a shortest path from a to c? No, right because if there existed a shorter path from a to c, I could splice it in here and find the shortest path from a to d. Do you see that? So based on that reasoning, rather than string like this giant set of shortest paths, sort of actually applying, in some senses, recursive suggestion, instead I can just think of the one vertex that's before me in my shortest path. I'm going to trace backwards. So let's take a look at our graph here. Essentially, the object I'm going to keep track of is like a predecessor, right. So what is the predecessor of f on the shortest path? It's actually either d or e. It doesn't matter in this case. Maybe the predecessor is e for fun, right. What's the predecessor of e? Well, clearly the previous vertex on the shortest path is c. Similarly for d-- now we have b and a and a bunch of arrows that point this way. So for every vertex I'm
3799	just going to start an arrow pointing toward the previous vertex on the shortest path. I'm not going to store the whole shortest path, just the very last edge. So first of all, how much storage does this take? It takes v space. Do you see that? Or the size of the vertices space. Because every vertex just has to store one thing, which is the previous vertex on the shortest path. Now what does my algorithm for tracing shortest path? It's really simple. I just start walking along these edges all the way until I get back to a. Now this object is called the shortest path tree. Notice I snuck in one additional word which is tree. Why is that? Can I ever have a cycle in this graph? It wouldn't really make any sense, right. These are shortest path. You should be able to kind of follow the gradient back to the original vertex. OK, so in other words, I'm going to basically decorate my graph with one additional thing. We'll call it p of v which
3800	is the previous vertex on the shortest path from my source point to my vertex v. And what I think I've tried to argue to you guys today is that if I have this information, that's actually enough to reconstruct the shortest path. I just keep taking p of v, and then p of p of v, and then p of p of p of v, and so on, which sounds more complicated than it is, until I trace back to my original vertex. And this object conceptually is called the shortest path tree. Any questions about that? Yes? AUDIENCE: [INAUDIBLE] JUSTIN SOLOMON: If I had an edge that connected a to d, OK. AUDIENCE: [INAUDIBLE] JUSTIN SOLOMON: Oh, OK so the question was, let's say that our colleague here added an edge-- this is a great question. You know somebody was evil, my adversarial neural network, stuck an edge here because it was adversarial, and it wanted my shortest path code to fail. And now somehow the tree that I gave you is no longer correct. And my answer
3801	to that is yes. Why is that? Well, by adding this edge here, the length of my shortest path changed. The shortest path from a to d is now 1. So this tree is no longer valid. I need a new tree. So now what would be the previous p of d here? Well, rather than being c, it would be a. Yes, that's absolutely right. And it actually is reflective of a really annoying property of shortest path, which is if I add one edge to my graph, the length of the shortest path to every vertex can change. Well, I guess with the exception of the source vertex. Yeah, and that's actually a really big headache in certain applications. So for instance-- and then I'll shut up about applications and do math again-- I work a lot with 3D models. And there's a big data set of 3D models of like ballerinas. And ballerinas are really annoying because sometimes they put their hands together like that. And then suddenly the shortest path between your fingers goes from your
3802	entire body to like 0. And so incremental algorithms for computing shortest path can fail here, right. Because I have to update like everything if I accidentally glued together fingers like that. So anyway, I'll let you think about how you might fix that problem. If you want to know more, you should take 6.838. Yes? AUDIENCE: [INAUDIBLE]. JUSTIN SOLOMON: If you change your source node, the shortest possible change again. Yeah, so this is going to be one of these really boring things where I'm going to keep answering like any time I change anything about my problem-- I change my source, I change my edges-- I have to just recompute all the shortest paths. There are obviously algorithms out there that don't do that. But we're not going to think about them yet. OK. So as usual, I've talked too much and left myself about 10 minutes to do the actual algorithm that's interesting in the lecture here-- although actually, it's really not so complicated,
3803	which is how do I actually compute shortest paths? Yeah, and the basic thing we're going to do is sort of build on this tree analogy here. We are going to define one more object, which I really like-- actually I enjoy this from Jason's notes because it looks like calculus, and I enjoy that-- and that's an idea of the level set. And so this is a whole set of things L sub k. And these are all the vertices that are distance k away from my source. So for instance, if my source vertex in this example is the vertex all the way on the left, then L0 obviously contains just that vertex, right. L1 is the next one. L2 is the third one. But now L3 is a set of three vertices because those are all the things that are distance 3 away from the source. That's what I've labeled in pink here. OK, so that's all that this notation here means. Oh, I've made a slight typo because in this class distance is delta and not
3804	d, but whatever. AUDIENCE: [INAUDIBLE] JUSTIN SOLOMON: The shortest distance-- that's absolutely right. So for instance, I could have a very long distance from L0 to L2, right. I could just flip back and forth between L0 and L1, maybe go over to L4 and then go back. But that wouldn't be a terribly helpful thing to compute. That's absolutely right. Yes? AUDIENCE: [INAUDIBLE]. JUSTIN SOLOMON: Oh, the red background is the set L. So for example, L3 contains these three vertices because they're all the things that are distance 3 away from the left. I got a little too slick drawing my diagram late last night. I'm kind of proud of it. OK, so essentially if I wanted to compute the length of the shortest path from all the way on the left to all the other vertices, one way to do that would be to compute all these level sets and then
3805	So we're going to introduce an algorithm called Breadth-First search which does roughly that. So Breadth-First search, the way we'll introduce it today is going to be an algorithm for computing all of those level sets, L sub i, and then from that, we can construct the length and even the shape of the shortest path. And I'm going to move to my handwritten notes. OK, and here's what our algorithm is going to do. I'm going to write it in a slightly different way than what's in the notes and on the screen, but only slightly. So first of all, one thing I think we can all agree on is that level set 0-- oh, that's-- this chalk bifurcated-- it contains one node. What should that node be? The source because the only thing that's distance is 0 away from the source, is the source node. OK, and in addition to that, we can initialize the distance from the source to itself. Everybody on three, what is the distance from the source to itself-- 1, 2, 3. AUDIENCE: 0.
3806	JUSTIN SOLOMON: Thank you. See you're waking up now, it's almost 11:00-- 12:00. What time is it? Almost 12:00-- OK, and then finally-- well maybe initially we don't really know anything about the array p, so we just make it empty. Because p of the source, it somehow doesn't matter. Because once I've made it back to the source, I'm done computing shortest path. So we're going to write an algorithm that computes all the level sets and fills in this array p and fills in the distances all in one big shot. We're going to call it Breadth-First search. OK, so let's do that.
3807	So we can use the notation here. And notice that there's basically an induction going on, which is I'm going to compute level set 1 from level set 0, level set 2 from level set 1, and so on, until I fill in all my level sets. Does that makes sense? So here's a slightly different way to notate the same thing. I'm going to use a WHILE loop, which I know is like slightly non-kosher, but that's OK. So I'm going to initialize a number i to be 1. This is going to be like our counter. I'm going to say WHILE the previous level set is not empty, meaning that potentially there's a path that goes through the previous level set into the next one. Because as soon as one of my levels is empty, notice that like the Li for even bigger i are also going to be empty. There's like never a case when there's something not distance i but then distance i plus 5. OK, so now what am I going to do? Well, let's
3808	think back to our graph. So like now I know that this guy is distance 0 away. That's what I started with. So now I'm going to look at all the neighbors of this vertex. And I'm going to make them distance 1 away. Does that makes sense? And similarly here, this guy is distance 2. And eventually I'm going to get in trouble because maybe-- well, what's a good example here. I won't even try to draw. I could run into trouble if I don't want to add a vertex twice to two different level sets. Once I've put it in Li then I don't want to put it in Li plus 5 because I already know that it's distance i away. Does that makes sense? OK, so what I'm going to do is I'm going to iterate over all the vertices in my previous level set. And now I'm going to look at every vertex that is adjacent to u. Because what do I know? I know that if I can get to u in i minus 1
3809	steps, how many steps should it take me to get to any neighbor of u? i steps because I can go through the path, which is the length of i minus 1, add one additional edge, and I'll get to that new guy. So what can I do? I can iterate over all of v, which is in the adjacent set of u. But I have to be a little bit careful because what if I have an edge backwards? So like for instance, here I have an edge back to the source. I guess this is-- yeah, that's a valid example. I wouldn't want to add the source to the third level set because I already added it in the previous guy. So I want to get rid of the union of all of the previous level sets. Does that make sense? So in other words, I'm only going to look at the adjacent vertices that I haven't visited yet in my level set computational algorithm. And all I have to do is update my arrays, right. So in
3810	particular, I'm going to add vertex v to level set i because I haven't seen v yet. I'm going to set the distance from s to v equal to i because I'm currently filling in my level set i. And then finally what is p of v? What is the previous vertex to v in my shortest path from my source? It's u, right. Because that's the guy in the previous level set that I'm building my path from, right. I'm going to set that to u. And then-- sorry, I ran out of space-- but I also have to increment i. OK, so what does this algorithm do? It's just building one level set at a time. If we go back to our picture, so it starts by initializing L0 to just be the source vertex, then it looks at all the edges coming out of that-- in that case just one-- it makes that length 1-- and so on. And so this is just incrementally building up all these level sets. Now there's a pretty straightforward proof by
3811	induction that this algorithm correctly computes the L's the p's and the deltas which is all the information that we need to compute the shortest path. I think you guys can do that in your recitation if you still need a little bit of induction proof practice here. And the final thing that we should check is what is the runtime of this algorithm. I'm going to squeeze it in there just at the last second here. So let's take a look. So first of all, I did something a little-- oh, no it's OK-- in my algorithm actually in step zero I had to make an array which was the size equal to the number of vertices. Remember that in 6.006 how much time does it take to allocate memory? Yeah, it takes the amount of time proportional to the amount of memory that I allocate. So already-- Steph, I see your hand but we're low on time. So we're to make it to the end. Already we've incurred v time because our shortest pathway array takes v space.
3812	But in addition to that, we have this kind of funny FOR loop where for every node I have to visit all of its neighbors. But first of all, do I ever see a node of twice here? No, because I'm going in order of distance. And the second that I've seen a node in one level set, it can't be in another. That's our basic construction here. Well, conveniently for you guys, you already proved exactly the formula that we need. And if I'm lucky, I didn't trace it. Yeah, here we are. So if we take a look here, this is exactly the scenario that we're in. Because what did we do? We iterated over all the nodes in our graph, and then we iterated over all the neighbors of those nodes. And that's the basic computational time in our algorithm. So that FOR loop, or that WHILE loop rather, in my code is incurring time proportional to the number of edges. So what is the total run time for Breadth-First search? Well, we need to construct that
3813	array. So just at step zero, we've incurred v time. And then we have to iterate over something that takes up most the number of edges. So overall our algorithm takes big O of mod v plus mod e time. Now, notice that this is-- you might view this as kind of redundant. By the way this-- I have a little bit of a quibble with Jason. But in this class we will call this a linear time algorithm because it's linear in the space that you're using to store your graph. I think that's a little fishy personally because this scale could scale quadratically in v, but I digress. In any event, why do we need both of these terms here? Well, notice that if I had no edges in my graph, now this term is going to dominate. But as I add edges to my graph, this thing could go up to v squared. So this is somehow a more informative expression than just saying, well at worst this is v squared time. Does that makes sense? It's
3814	a slightly better formula to have. OK, so with that we just squeaked into the finish line. We have an algorithm for computing shortest paths. And I will see you guys again I guess on Tuesday.
3815	[SQUEAKING] [RUSTLING] [CLICKING] JASON KU: Welcome, everybody, to the second-to-last lecture of 6.006. In this lecture, we've mostly covered all of the testable material that we're going to have on the final, or on quiz 3. Today, really what we're talking about is putting into context all the material that we've learned over the course of the term at a high level and talk about where we can go from here in terms of other theory classes and other classes in the department that are related to this material. Now, most things in the department are in some way related to this material. And so that's why there's a foundational course. But we're going to try to talk about it from a high level and talk about how some future things that you might be interested relate. OK, so we started out the term, in lecture one, talking about 6.006, and we had four main goals that we had for our course-- really three main goals Does anyone remember what those goals were? So you got to the last one
3816	first.
3817	"to be able to solve problems. So this is kind of like the ""let's make an algorithm"" part of the course. 1, solve hard computational problems. I guess ""hard"" here maybe should be in quotes because we saw in the last lecture what hard means in a technical sense. Hard could mean that there's no efficient algorithm that we know how to solve a problem on. That's getting a little bit of ahead of ourselves. Computational problems with algorithms is really the key part about this goal. It's kind of the same goal that you have in a class like 6.0001 or 6.009. You're trying to convince a computer that you solved a problem on a finite set of inputs. But really what this class is about is two other things, which is more about communication to people rather than computers. Your algorithm might be correct or efficient, but you need to be able to communicate that to humans. And that's what the other two goals are. So second one is argue correctness. Basically, the thing that I'm doing to"
3818	my inputs is always going to lead me to a correct output. No matter what input I give it, any valid input-- there could be an infinite space of possible inputs, and in this class, that's the case, because we want our input size to grow arbitrarily large-- we need to be able to argue correctness that it's going to return me the correct thing no matter what my inputs are. And in order to do that, that's essentially-- that's 6.042. This whole class has basically been applied 6.042. I've given you some procedures, and you have to prove things about these procedures. Or most of the time, we proved it for you, and then you've used them as black boxes.
3819	"And the third one is efficiency-- argue that it's ""good,"" for lack of a better thing. This is efficiency. What does ""good"" mean? Well, that was hard to know at the beginning of our class. And so we set up this model of computation, a framework, through which we could determine how good or bad our algorithms were by saying-- by defining a model of computation, saying what things we can do in constant time, and then just building off of that. So this is basically our model plus some asymptotics or something like that. Ran out of space. What? AUDIENCE: It's about scalability. JASON KU: Yeah, this is about scalability. A model of computation tells us how much time we can spend, but it's compared to our input size. This is always about, how does our algorithm perform relative to the rate that our problem size grows? And so that's what we mean by ""good."" And in this class, we don't tend to talk about constant size problems. It's about how algorithms can scale as you have arbitrarily large"
3820	inputs. That's why we need recursion and induction to be able to prove things about our algorithms, because they're for arbitrary n. And that's why we need this relative-to-input size, the growth factor of our algorithm's performance, relative to the input. OK, and then the last thing is, to me, one of the most important things, is communicating these things to another human. So communication is key here. If you can always write good code that's always right, good for you. I can't do that all the time. But that might mean that you can be very-- a competent, independent computer programmer. But you are going to be limited in what you can do if you're only able to rely on yourself. A lot about computer science is working with others to solve computational problems. And when you're working with others to solve computational problems, you need to be able to communicate with them, and you need to be able to communicate them both what it is you're doing and why it is you're doing it-- that you're doing the
3821	correct thing and that it's efficient. And so that's a big part about what this course is. At the end of the day, on your quiz, if you write down Python script for a correct algorithm, but we don't know what it's doing, but it's correct, we're not going to give you full points on that, because you're not satisfying the conditions of this class. It's really about the communication here. OK, so just to review, since we've not discussed how the most recent lecture fits into your problem sets. We didn't have any problem sets that covered complexity, so how does that fit in? Well, argue that the ways that we're solving our problems are good. What we proved in the last lecture was that most problems cannot be solved good. They can't be solved in polynomial time with respect to the size of your input. However, most of the problems that we think about, in a sense, I can prove to you that it's a yes solution. I can show you a simple path in this graph that
3822	"has a certain length. Or I can show you a subset that sums to a certain value in a particular problem. I can give you a certificate that I can prove to you in a reasonable amount of time that, yes, I can prove to you that this is-- the answer to this thing is correct. And that's what we talked about in the last lecture. So not always ""good"" algorithms to solve problems, but many problems we think about can be either checked in polynomial time-- this is the concept of having a certificate that I could give you of polynomial size that could be checked in polynomial time-- in a sense, that's a way-- check-- checked in polynomial time. This leads to our class of decision problems, NP. Or it can be solved by brute force in exponential time. Most of the things that we've talked about in this class fall into one of these two categories. We can just brute force over the combinatorial space of possible outputs and check to see if they're correct. Or I"
3823	can give you a certificate basically saying, look, I can solve-- actually, anything that's of this form can be checked in this form, because there's only a polynomial number of things to check-- or, sorry, an exponential possible number of certificates of polynomial length to check. But basically, this is saying that the problems that we think of mostly fall into these two categories. And so there usually are algorithms to solve the problems that we care about, even if most random problems in terms of bit strings that we gave an analysis in the last lecture actually prove that most random problems are not solvable. In a sense, the problems we think about are not random. They kind of have this structure that they can be checked pretty quickly. OK, so that's what we mean when we are talking about complexity. For the purposes of the final, you'll be able to see on your final exam practice problems that we're going to give you, most of what we cover in terms of material on the final that will be
3824	testing the lecture 19 material will be in terms of the definitions. Do you understand what the decision problem class NP is? EXP is? Do you know how these relate to each other? EXP is definitely a superset of NP here. NP nestles inside here. They could be equal-- probably not. Those are the types of things that we would address. Knowing a directionality of a reduction. If you have a problem A and a problem B, and I know that this one is difficult by some measure-- I already happened to know that it's very hard, like NP-hard or something like that. If this is a problem that I'm interested in knowing the complexity about, and I can prove that I can solve it if I had a black box to solve B-- any black box to solve B, and I could make this reduction in polynomial time, and if this is hard, that means this can't be-- that means that if this is hard, then I better not be able to solve this in polynomial time, because then
3825	I would be able to solve this in polynomial time. So that's basically the type of argument usually in a true/false question we might have on the final exam for you to kind of understand the basic high-level definitions involved in what was talked about in lecture 19. Hardness-- the very most difficult problems of these classes-- and completeness-- sorry, anything harder than things in these classes. Whereas completeness is the ones that are in this set, but at least as hard as anything in those classes. So that's just to give you a brief overview of the only material that hasn't been tested but might be tested on the final. So when we don't have a good algorithm, we can actually prove that it probably doesn't have a good algorithm. And that's a problem that you'll be able to solve in future classes, if you continue along this track. OK, so what's the actual content that we talked about? This is a very high-level overview of why we're taking this class, why you're taking this class. But what is
3826	the content we actually covered? I like to break it up into three units and, in a sense, two subunits. So quiz 1 material and quiz 2 material was about showing you some nice black boxes. Basically, if I'm going to have inputs of non-constant size, it's going to be useful for me to be able to find things among those elements. So that's really what quiz 1 is all about-- data structures for finding things in non-constant size database. Sure. And when we were storing these things, we want to support maybe two different types of queries-- ones that were intrinsic to the items, what the items were, and ones based on what-- an extrinsic order was placed on these items. And that was a way in which we broke down, how should I approach looking at this problem? I want to be able to support queries and maintain an extrinsic order on these things. I might want a sequence. This is a sequence extrinsic order. Or I want to be able to look up, is this thing in
3827	my set, by a key that we identify, with a unique key. So this is some intrinsic queries, and often order. A hash table doesn't maintain any order on my keys. But it does support intrinsic queries-- is this thing in my set or not? But we did show you other set data structures that do support an intrinsic order that allows me to see what the next larger and the next previous-- the next larger and the next smaller item is in my set. So here's a summary of those data structures that we had. I'm not going to go into how to use these things or how to choose from among them here. That's what your quiz 1 review lecture was all about. But basically, the idea here is, if we have a sequence, most of the time when you're programming, being able to push and pop at the end of a list is pretty good. Which is why Python, the most fundamental data structure that you have, is a list, because it's a super useful thing. I
3828	just want to store a bunch of things, have random access to the, say, 10th element to my thing, but I'm not necessarily having to dynamically update the order of these things dynamically. I don't necessarily have to insert something in the middle of the list. But most of the time, what I can do is put it at the end of the list and maybe swap it down into place if I need to. So that's why a list is super useful. A sequence AVL tree, useful, but not as ubiquitous as a linked list-- I mean, as a dynamic array, sorry. I said linked list, I meant Python list, which is a dynamic array. So the dynamic array tended to be, in your coding practice, your most common sequence data structure here. Though, we can get pretty good for this insert in the middle operation with the sequence AVL. OK, then on the set data structure side, I categorize these things into a couple different categories
3829	These are all intrinsic operations-- finding things, inserting, deleting things. I think of the first three as being dictionary operations. I want to just look up whether something's there. Whereas the last two are order-preserving operations, where it matters what the order of these things are stored in. And so as you can see from the asymptotic complexity of the various operations here, the hash table is actually super good if you want the dictionary oper-- if you just want to support dictionary operations. But in the cases where you need to maintain order dynamically, a set AVL is the way to go. But if you don't need it dynamic, but you still need those order operations, a sorted array is just good enough if you don't need to change what they are. So that's a quick overview of quiz 1-type data structures material. But then we used most of these data structures to get faster sorting algorithms in different contexts. Basically, everything on this list involved making a data structure and exploiting that data structure to get a better
3830	running time, all except for merge sort, really. The first two we presented in terms of a priority queue, whether we used a sorted array or an array. We represented it at the end of lecture eight to get n-squared running time. We generalized that down to n log n by using a heap. That was a nice optimization. But we also got interesting data structures using an-- I mean, interesting sorting algorithms using an AVL tree because of the power of maintaining a dynamic order over time. But then exploiting a direct access array to be able to sort in linear time for small-bounded-- bounded in terms of the input, polynomially bounded in terms of the input-- ranges of numbers. So we leverage that direct axis array to get counting sort. And then we kind of amplified that effect by sorting on a bunch of digits multiple times to get basically polynomial blow-up in terms of the numbers that we could sort in linear time. So that's an overview of the content of quiz 1. In quiz 2, we
3831	were kind of like, OK, now you know how to find things within a set of just a flat list of things, you can put it in a data structure. But in a sense, a graph is a special kind of data structure that relates the different things in your input. So if you've got a bunch of vertices, there's a relation now between those vertices that are your edges. And this is a super useful framework in talking about discrete systems, because you can think of a vertex as a state of your system, and then connect these transitions as a graph. That's the reason why-- I mean, graphs are awesome, but they're awesome because they can be used to model so many different things within our world. It's not just about road networks. It can also be about playing your favorite turn-based game, like Tilt. OK, so we talked about a lot of different types of problems that you could solve, various algorithms, with a focus on a bunch of different ways of solving single-source shortest paths. And
3832	again, just like the sorting algorithms and just like the data structures, we presented multiple of them, because we had this trade-off of generality of the graph that they apply to contrasted with the running time. So I guess, in particular, the top line there is, in some sense, the most restrictive. We don't have any cycles in our graph. That's a very special type of graph, and we're able to get linear time. But then even if we do have cycles in our graph, we can do better if we have a bound on the weights in our thing, whether they be-- there's an easy conversion to a linear time algorithm via an unweighted process, or whether these things are non-negative, so there can't be negative weight cycles, and we don't have to deal with that. OK, so that's quiz 2 material. And then quiz 3 material was kind of applying this graph material to a recursive framework. What was our recursive framework? Everyone say it with me. AUDIENCE: Dynamic programming. JASON KU: Dynamic programming, and the framework was
3833	SRT BOT, right? Missing a letter, but SORT BOT, right? You can actually think of the quiz 3 material as really an application of the graph material. What are we doing in SORT BOT? We're defining a set of subproblems. These are a set of vertices in a graph. What is the relationship doing? It's saying, what are the relation between the subproblems, essentially defining the edges of a graph? And then this topological order and the base cases, all of these things are just saying, what is the problem that I want to solve on this graph? And how do I compute that for things that don't have any outgoing edges? I need to start writing on the board again. This is graphs. There was sorting in here, too. This is basically an application. OK, graphs was basically a relationship on these non-constant things. So this was kind of like useful black boxes that you can just bundle up and stick in some inputs, stick out some outputs, and you're golden. Whereas quiz 3 was very different,
3834	Dynamic programming, while it was, in some sense, related to this graph material-- I'm constructing a graph-- I have to construct that graph. There's a creative process in trying to construct that graph. I don't give you a set of vertices. Usually what I give you are a set of-- a sequence or something like that. And you have to construct vertices, subproblems, that will be able to be related in a recursive way so you can solve the problem. This is a very much more difficult thing than these other things, I think, because there's a lot more creativity in this. In the same way that just applying-- reducing to the graph algorithms we have is fairly easy. But actually doing some graph transformations to change the shape of the graph so that you can apply these algorithms, that's a harder thing to do. The difficulty with these two sets of materials is very similar. Figuring out what the graph should be, figuring out what the subproblems should be and how they relate, is really the entire part of
3835	the-- the entire difficulty with solving problems recursively. And we've only given you a taste of solving problems recursively. In future classes, like 6.046, which is the follow-on to this one in the undergraduate curriculum, this is all about introduction to algorithms. The next one's about design and analysis of algorithms. It's quite a bit more difficult, because we've mostly left it to you to use the things that we gave you or make your own algorithms based on this very nice cookbook-like framework that you can plug in a recursive algorithm to. Now actually, that cookbook is super nice for any way of looking at a problem recursively, but while in dynamic programming, the inductive hypothesis of combining your subproblems is almost trivial, in other types of recursive algorithms, that's not necessarily the case. Especially when instead of looking at all possible choices, for example, in a greedy algorithm where you're just looking at one of the choices, the locally best thing, and recursing forward, you're not doing all the work. You're not locally brute-forcing. Your locally picking an
3836	optimal thing locally and hoping that will lead you to good thing. That's a much harder algorithmic paradigm to operate under. And so that's more like the material that you'll be talking about in 6.046. So that's 006, a very quick overview of the content of this class. And we really like the structure of how this class is laid out, because it gives you a fundamental idea of the things people use to store information on a computer and a sense of how you solve problems computationally and how to argue that they're correct and efficient. That's really what this problem-- this course is about. And if you feel like you enjoy this kind of stuff, that's where you go to take 6.046. And 6.046 was actually the first algorithms class I ever took here at MIT, as a grad student actually. This was hard for me. It's actually hard to look at these problems, these types, and think in a computational way, especially having not taken this class, 6.006. So hopefully you guys are all in a better
3837	position than I was when I took it. There's two ways I like to think of the content in 6.046. One is kind of just as an extension of 006. It's the natural follow-on to the things that we do in this class. They still talk about data structures. This isn't the core part of 046, but they do touch on data structures for more complicated-- that have more complicated analyses involved in them. It's really about-- usually in 046, stating what the algorithm is doing is not so hard. Basically, giving you the algorithm, number one here, is not so difficult, to state what's happening in the algorithm. But the number two and number three here, arguing that that thing is correct and arguing that thing is efficient, that's where the complexity comes in in 046. The analysis part is quite a bit more complicated in 046 than in 006. So they solve a problem called union-find and give a much-- we talked a little bit about amortization. This goes into a much better-- a much more formal way
3838	of proving things run in amortized time. So this is basically amortization via what we call a potential analysis. It's basically making that notion that we talked about when we were talking about dynamic arrays of, we're not doing this expensive thing too often. Basically what we do is we keep track of the cost of all sequence of operations and prove that the average cost is small. That's kind of what this potential analysis is doing. It's a little bit more formal process for making that argument a little more formal. Right. OK. So then on the graph side, this is kind of an extension of quiz 1-type material.
3839	It's basically-- it's a set type thing, where I can make a set of just a single element, I can take two sets, merge them together, make them their union, and then given an object, I say, which set am I part of, essentially by electing a leader within a set and saying, return me a pointer to that one. And so this can be useful in dynamically maintaining, say, the connected components in a dynamically changing graph supporting the query of, am I in the same component as this other guy? That could be a very useful thing to know about a graph as it's changing. So that's an application of this problem. And they get near-constant performance for a lot of these queries. It's not quite, but pretty close. OK, on the graph side, they solve
3840	Minimum Spanning Tree-- so I'm trying to find a tree connecting all of the vertices in a connected component of my graph. And I'm trying to find-- in a weighted graph, I'm trying to find the spanning tree that has minimum total weight. So that's a problem-- a fundamental problem in weighted-graph algorithms. They've solved this via a greedy algorithm. And network flows and I guess cuts. So this is-- what is this? This is, I'm given a weighted graph. Basically, each of the weights correspond to a capacity. I could push water through along this edge. And I may be given a source vertex and a sink vertex. And I want to say, I want to shove water through the source vertex along the edges with their various capacities. And I'll get some amount of water on the other end in the source. So the question is, what's the most amount of water that I can push through this? Well, I could build that pipe network with the different things and just do this experimentally. I just stick a
3841	bunch of-- maybe-- I'm a mechanical engineer, so that maybe makes sense to me. But you want to be able to just look at those numbers and be able to tell me how much water can I push through. That's what the max flow in a network is talking about.
3842	basically incremental algorithms that, kind of like Dijkstra, or kind of like Bellman-Ford, will incrementally update estimates to-- of a max flow and improve them over time. Then on the, basically, design paradigms, you've got more involved making your own divide-and-conquer algorithms, dynamic programming algorithms, greedy algorithms. Basically, they go a lot more in depth in terms of how to design these algorithms and these paradigms than we do in this class. And then the last thing is-- we only touched on complexity. And in a sense, 046 is only going to touch on complexity. It's a very big field. But it will give you the tools to be able to prove that something is NP-hard, whereas we just kind of say that, oh, there's this thing called a reduction. We didn't give you any problems in which you actually had to reduce one problem to another. And you'll do a lot more of that here. So, reductions. So in a big sense, 046 is really just a natural extension to the 006 material, plus some additional stuff, which I'm
3843	going to get to in a second. Yeah, question? AUDIENCE: Do you want to add randomization for time paradigms? JASON KU: I'm going to talk about that slightly in a separate-- I'll get to your question in just a second. I like to think of it as a separate topic, which I will go into right now. The separate topic I like to think of it as, instead of being the natural extension to the things in the 006 units, what I'm going to do is kind of relax either what it means to have a correct algorithm or relax what it means to-- what my model of computation is. So 006, this is kind of as an extension of 006. And this is kind of like 6.046 as change my definition of what it means to be correct or efficient. So we've already kind of done this a little bit in 006. Basically, one of the things that we can do,
3844	about, was about randomized algorithms, which is a big part of 046 actually-- randomized analysis of algorithms that are not deterministic. It's not guaranteed that it'll give you the same output every time or not guaranteed that it will do the same computations over the course of the algorithm every time. But it exploits some randomization. And in 006, this is-- we've mostly not touched on this, except in one area. Where did we use randomization? In hashing, right? When we used hashing, what were we doing? We changed the definition of correct versus efficient. We didn't really change the definition, what we did was we said that it was OK that sometimes our algorithm was slower than we-- than on-- in expectation. That's what we meant there. We're relaxing the idea of efficient, but we're still saying it's good, because most of the time it is good. So there's two types of randomized algorithms. They have these weird names based on betting regions of the world, shall we say? There are-- this is L-O? Los Vegas? It is Las,
3845	OK, Vegas algorithms. These are always correct, but probably efficient. In a sense, that's what hashing is. I'm always going to give you the right thing, whether this thing is in my set or not. But some of the time, it's inefficient. I have to look through a chain of length of-- that's linear in the size of the things that I'm storing. And this is in contrast to a Monte Carlo algorithm, which is always efficient for some definition of efficient, but only probably correct. And I mean, I could define you a hash table that has Monte Carlo semantics instead. Say, for example, I say that I'm going-- it's going to be exactly the same as a hash table, except instead of storing all the things that collide in a place, I just store the first two, say. Well, actually, that's actually going to be always efficient. I'm going to look through the things and see if it's in there. And the chains that I'm storing there only have two things. It's going to be always efficient. It's
3846	always going to give me constant time. But some of the time, it's going to be the wrong thing, because I'm not storing everything in that chain. So there's some probability that that's not going to be correct. And so that's a different kind of-- maybe I want my hash tables to always be fast, but I can afford to be wrong some of the time. I don't know. In practice, this is actually sometimes a good trade-off in real systems. Sometimes it's OK to be wrong some of the times, if we get good performance. OK, but generally can do better if you allow randomization. And by better I mean, usually we can get faster bounds on a lot of problems if we allow randomization and things aren't necessarily always correct or always efficient. So this is a big area in 046 that requires a lot more analysis using randomness and probability. So if you need some primers on that-- we didn't have a lot of this in 006, but if you go on to 046, that's going to
3847	be a really important thing for you to brush up on. The next part on 006 is kind of changing what our definition of correct or efficient means. I mean, we've restricted ourselves in this class to a class of problems where we only talk about integers. But there's tons of problems in this world, especially in scientific computing, where I want to be able to find out what this real number is. And I can't even store a real number on my computer. So what the hell, Jason? What are you talking about? I can't do that on a computer. But what I can do is basically compute things in a numerical sense-- numerical algorithms. And in 046, a lot of times we put this in the context of continuous optimization, continuous being the opportune word here, not discrete systems. You have a continuum of possible solutions, real numbers essentially. How do we do this on a computer that's a discrete system? Basically, in 046 what you can do, and in other numerical methods classes, what you can say
3848	is, well, I know that you can't return me a real number. I got that. Or you can maybe have a model of computation that allows integers to represent other kinds of real numbers, like radicals or rationals or something like that. And I can do manipulations on those. But really what these algorithms are usually about is computing real numbers not completely, but to some bounded precision. And I pay for that precision. The more bits of precision I want on my number, I have to pay for them. So this is basic-- I think of these as an approximation-- approximation of real number to some precision, and I pay for precision with time. So let's say I wanted to compute the square root of a number. I could have an algorithm just like the algorithms-- or I guess division, right, long division.
3849	You all know the algorithm of long division. You put the quotient under here with these-- an AB and you get the C on top or whatever. That's an algorithm. That's a procedure using essentially small numbers. I'm only talking about the digits zero to nine here when I'm doing that algorithm. So it's a procedure that only uses small integers to compute arbitrary precision of a division. So that's an algorithm, and I have to pay time to get more digits. So that's an example of this kind of-- how we live in the world of real numbers when all we have is a discrete system. And then the last category I'd like to talk about here
3850	Whereas this is kind of an approximation algorithm, I'm approximating my outputs, this is an approximation algorithm from the standpoint of, well, there's a lot of problems that I can't solve efficiently. They're NP-hard. They're in EXP or even harder problems. But maybe I'm OK with not getting the optimal solution. So this is in the domain of optimization problems. So most of the dynamic programming problems that we gave you were optimization problems. They're the shortest paths problems. Those are optimization problems. Basically, the possible outputs are ranked in some way-- the distance of a path that you return or something like that. They're ranked in some way. There is an optimal one-- the one with the smallest metric or something like that. Well, in an approximation algorithm what I do is, OK, I get that it's computationally difficult for you to give me the longest simple path in this graph, or the shortest possible route for my traveling salesman, but maybe that's OK. I mean, my engineering Spidey-sense tells me that within 10% is fine. So maybe instead
3851	of giving me the most optimal thing, can I give you an algorithm that's guaranteed to be within a certain distance from the optimal thing? Usually, we're looking for constant factor approximations which have low constant, or maybe even have to do for worse if such things don't exist. OK, so that's approximation algorithms. Can we get close to an optimal solution in polynomial time? OK. And then the last way we could change things in, especially future classes, though sometimes they talk about this in 046
3852	We could basically change something about our computer to be put in some other weird paradigm of solving problems with more power essentially, or you're
3853	OK, so change in the model of computation. So what we've been talking to you in terms of model of computation is our word-RAM-- word-RAM. And that essentially says I can do arithmetic operations, and I can look up stuff in my memory in constant time. And but if I allocate a certain amount, I have to pay that amount and that kind of thing. So that's this word-RAM model. But in actuality, all of your computers, it's a lot easier for me to figure-- to find and read memory that's on my CPU in a register than it is for me to go out to the hard disk, ask this-- well, in my day, it used to be this movable mechanical head that had to go and scan over a bit on a CD-ROM drive and actually read what that thing was. So we can add complexity to our model to better account for the costs of operations on my machine.
3854	cache model. It's basically a hierarchy of memory. I have my registers on board my CPU. I have maybe an L1 cache that's close to my CPU. Then I have another set of caches and another set of caches maybe out to RAM. And reading from a hard disk, a solid state drive of some kind, that's the slowest thing to access. And I can put a cost associated with each of those things. And instead of having to-- having all of our operations be said to be constant, the constants are actually different, and I have to pay for that difference. And so that's extending our model to be a little bit more realistic to our machine. Another one is we have computers right now that operate in classical physics, that exploit things in classical physics. But in actuality, our world allows for even more complicated types of operations, like quantum operations, where you're exploiting entanglement and superposition of different atoms to potentially get operations that I can act on my data that are actually provably stronger than the
3855	classical models in some sense. So this is a huge reason why there's a lot of work being done in, say, lots of industry research facilities in figuring out these models. Because maybe if you can make a big enough quantum computer, you can break encryption and stuff in polynomial time. And that's something that maybe the NSA is interested in. And I'm not going to go into that. But, you know. I mean, some people-- you look at artificial intelligence and things like discussions around artificial intelligence, my brain might be doing things that a classical computer cannot. It could be using quantum superposition in some way. And our computers that are in your phone and your laptop and things like that aren't exploiting those operations, so how could we ever get intelligence, because in some sense, our brains are more powerful. And so a lot of what AI should be looking into is, what is the actual model of computation of our brains that can give us the power to have sentience? OK, so that's kind of quantum
3856	computing. I don't know much about it actually. And then there's things like, maybe I have more than one CPU. I mean, most computers-- all the computers you have, even the ones in your phone, probably have multiple cores. In a sense, you have lots of CPUs running in parallel. So this is like par-- there's one R in parallel? Parallel computing basically says, it's cheap for me to make another computer potentially. If I have two computers running on the same problem, maybe I can get a two-fold speed-up on my-- on the time in which it takes to solve my problem. Now, suppose I had then 100 CPUs running on a machine. Maybe I can get 100-fold speed-up. And actually, in real life, 100-fold speed-up makes a difference. It's, am I waiting for this for 10 minutes? Or am I waiting for this for 1,000 minutes? That's, like, all day. I don't want to do that. Maybe it's on weeks. I don't even remember. But parallel computing, if I can get a 100-fold speed-up, that might be a
3857	huge win. But for some problems, it's not possible-- if I have k CPUs, can I get a k-factor speed-up?
3858	And so parallel computing is another paradigm in which there's a lot of interesting theory going on. There's a lot of complications there, because there are a couple different models. You can have multicore set-up, where you have a lot of computers that are accessing the same bank of memory. And then you don't want them all to be reading and writing from them at different times, because you don't necessarily know what their state is, and you get these collisions, which are something that you really have to think about in this world. Or you have situations where maybe I have a bunch of nano-flies or something that are going around, and they have very small computer brains themselves. But they can talk to each other and pass information to each other, but they don't have access to one central network repository of information. That's what we call a distributed parallel system, where all of the CPUs that you have can interact with each other maybe locally, but don't have access to the same memory system. So they have
3859	to work together to learn information about the system. OK, so that's a brief overview of the different directions this class, 6.006, and theory in general, could lead you-- into a huge array of different branches theory and different problems that you could address with different types of computers. So I know this is a very high-level lecture and maybe less-applied than some of you might like. But I hope this gives you a good understanding of the directions you can go after this class that I think are really excited in terms of how to solve problems computationally. So with that, I'd like to end there.
3860	JASON KU: Welcome to the fourth lecture of 6.006. Today we are going to be talking about hashing. Last lecture, on Tuesday, Professor Solomon was talking about set data structures, storing things so that you can query items by their key right, by what they intrinsically are-- versus what Professor Demaine was talking about last week, which was sequence data structures, where we impose an external order on these items and we want you to maintain those. I'm not supporting operations where I'm looking stuff up based on what they are. That's what the set interface is for. So we're going to be talking a little bit more about the set interface today. On Tuesday, you saw two ways of implementing the set interface-- one using just a unsorted array-- just, I threw these things in an array and I could do a linear scan of my items to support basically any of these operations. It's a little exercise you can go through. I think they show it to you in the recitation notes, but if you'd like to implement
3861	it for yourself, that's fine. And then we saw a slightly better data structure, at least for the find operations. Can I look something up, whether this key is in my set interface? We can do that faster. We can do that in log n time with a build overhead that's about n log n, because we showed you three ways to sort. Two of them were n squared. One of them was n log n, which is as good as we showed you how to do yesterday. So the question then becomes, can I build that data structure faster? That'll be a subject of next week's Thursday lecture. But this week we're going to concentrate on this static find. we got log n, which is an exponential improvement over linear right, but the question now becomes, can I do faster than log n time? And what we're going to do at the first part of this lecture is show you that, no, you-- AUDIENCE: [INAUDIBLE] JASON KU: What's up? No? OK-- that you can't do faster than log n
3862	time, in the caveat that we are in a slightly more restricted model of computation that we were-- than what we introduce to you a couple of weeks ago. And then so if we're not in that more constrained model of computation, we can actually do faster. Log n's already pretty good. Log n is not going to be larger than like 30 for any problem that you're going to be talking about in the real world on real computers, but a factor of 30 is still bad. I would prefer to do faster with those constant factors, when I can. It's not a constant factor. It's a logarithmic factor, but you get what I'm saying. OK, so what we're going to do is first prove that you can't do faster for-- does everyone understand-- remember what find key meant? I have a key, I have a bunch of items that have keys associated with them, and I want to see if one of the items that I'm storing contains a key that is the same as the one that
3863	I searched for. The item might contain other things, but in particular, it has a search key that I'm maintaining the set on so that it supports find operations, search operations based on that key quickly. Does that make sense? So there's the find one that we want to improve, and we also want to improve this insert delete. We want to be-- make this data structural dynamic, because we might do those operations quite a bit. And so this lecture's about optimizing those three things. OK, so first, I'm going to show you that we can't do faster than log n for find, which is a little weird. OK, the model of computation I'm going to be proving this lower bound on-- how I'm going to approach this is I'm going to say that any way that I store these-- the items that I'm storing in this data structure-- for anyway I saw these things, any algorithm of this certain type is going to require at least logarithmic time. That's what we're going to try to prove. And the
3864	model of computation that's weaker than what we've been talking about previously
3865	And a comparison model means-- is that the items, the objects I'm storing-- I can kind of think of them as black boxes. I don't get to touch these things, except the only way that I can distinguish between them is to say, given a key and an item, or two items, I can do a comparison on those keys. Are these keys the same? Is this key bigger than this one? Is it smaller than this one? Those are the only operations I get to do with them. Say, if the keys are numbers, I don't get to look at what number that is. I just get to take two keys and compare them. And actually, all of the search algorithms that we saw on Tuesday we're comparison sort algorithms. What you did was stepped through the program. At some point, you came to a branch and you looked at two keys, and you branched based on whether one key was bigger than another. That was a comparison. And then you move some stuff around, but that was the
3866	general paradigm. Those three sorting operations lived in this comparison model.
3867	like are they equal, less than, greater than, maybe greater than or equal, less than or equal? Generally, you have all these operations that you could do-- maybe not equal. But the key thing here is that there are only two possible outputs to each of these comparitors. There's only one thing that I can branch on. It's going to branch into two different lines. It's either true and I do some other computation, or it's false and I'll do a different set of computation. That makes sense? So what I'm going to do is I'm going to give you a comparison-- an algorithm in the comparison model as what I like to call a decision tree. So if I specify an algorithm to you, the first thing it's going to do-- if I don't compare items at all, I'm kind of screwed, because I'll never be able to tell if my keys in there or not. So I have to do some comparisons. So I'll do some computation. Maybe I find out the length of the array and I
3868	do some constant time stuff, but at some point, I'll do a comparison, and I'll branch. I'll come to this node, and if the comparison-- maybe a less than-- if it's true, I'm going to go this way in my computation, and if it's false, I'm going to go this way in my computation. And I'm going to keep doing that with various comparisons-- sure-- until I get down here to some leaf in which I I'm not branching. The internal nodes here are representing comparisons, but the leaves are representing-- I stopped my computation. I'm outputting something. Does that make sense, what I'm trying to do? I'm changing my algorithm to be put in this kind of graphical way, where I'm branching what my program could possibly do based on the comparisons that I do. I'm not actually counting the rest of the work that the program does. I'm really only looking at the comparisons, because I know that I need to compare some things eventually to figure out what my items are. And if that's the only way
3869	I can distinguish items, then I have to do those comparisons to find out. Does that make sense? All right, so what I have is a binary tree that's representing the comparisons done by the algorithm. OK. So it starts at one comparison and then it branches. How many leaves must I have in my tree? What does that question mean, in terms of the program? AUDIENCE: [INAUDIBLE] JASON KU: What's up? AUDIENCE: The number of comparisons-- JASON KU: The number of comparisons-- no, that's the number of internal nodes that I have in the algorithm. And actually, the number of comparisons that I do in an execution of the algorithm
3870	So what do the leaves actually represent? Those represent outputs. I'm going to output something here. Yep? AUDIENCE: [INAUDIBLE] JASON KU: The number of-- OK. So what is the output to my search algorithm? Maybe it's the-- an index of an item that contains this key. Or maybe I return the item is the output-- the item of the thing I'm storing. And I'm storing n things, so I need at least n outputs, because I need to be able to return any of the items that I'm storing based on a different search parameter, if it's going to be correct. I actually need one more output. Why do I need one more output? If it's not in there-- so any correct comparison searching algorithm-- I'm doing some comparisons to find this thing-- needs to have at least n plus 1 leaves. Otherwise, it can't be correct, because I could look up the one that I'm not returning in that set and it would never be able to return that value. Does that make sense? Yeah? AUDIENCE: [INAUDIBLE] JASON KU:
3871	What's n? For a data structure, n is the number of things stored in that data structure at that time-- so the number of items in the data structure. That's what it means in all of these tables. Any other questions? OK, so now we get to the fun part. How many comparisons does this algorithm have to do? Yeah, up there-- AUDIENCE: [INAUDIBLE] JASON KU: What's up? All right, your colleague is jumping ahead for a second, but really, I have to do as many comparisons in the worst case as the longest root-to-leaf path in this tree-- because as I'm executing this algorithm, I'll go down this thing, always branching down, and at some point, I'll get to a leaf. And in the worst case, if I happen to need to return this particular output, then I'll have to walk down the longest thing, just the longest path. So then the longest path is the same as the height of the tree, so the question then becomes, what is the minimum height of any binary tree that has
3872	at least n plus 1 leaves? Does everyone understand why we're asking that question? Yeah? AUDIENCE: Could you over again why it needs n plus 1 leaves? JASON KU: Why it needs n plus 1 leaves-- if it's a correct algorithm, it needs to return-- it needs to be able to return any of the n items that I'm storing or say that the key that I'm looking for is not there-- great question. OK, so what is the minimum height of any binary tree that has n plus 1-- at least n plus 1 leaves? You can actually state a recurrence for that and solve that. You're going to do that in your recitation. But it's log n. The best you can do is if this is a balanced binary tree. So the min height is going to be at least log n height. Or the min height is logarithmic, so it's actually theta right here. But if I just said height here, I would be lower bounding the height. I could have a linear height, if I just
3873	changed comparisons down one by one, if I was doing a linear search, for example. All right, so this is saying that, if I'm just restricting to comparisons, I have to spend at least logarithmic time to be able to find whether this key is in my set. But I don't want logarithmic time. I want faster. So how can I do that? AUDIENCE: [INAUDIBLE] JASON KU: I have one operation in my model of computation I presented a couple of weeks ago that allows me to do faster, which allows me to do something stronger than comparisons. Comparisons have a constant branching factor. In particular, I can-- if I do this operation-- this constant time operation-- I can branch to two different locations. It's like an if kind of situation-- if, or else. And in fact, if I had constant branching factor for any constant here-- if I had three or four, if it was bounded by a constant, the height of this tree would still be bounded by a log base the constant of that number of leaves.
3874	So I need, in some sense, to be able to branch a non-constant amount. So how can I branch a non-constant amount? This is a little tricky. We had this really neat operation in the random access machine that we could randomly go to any place in memory in constant time based on a number. That was a super powerful thing, because within a single constant time operation, I could go to any space in memory. That's potentially much larger than linear branching factor, depending on the size of my model and the size of my machine. So that's a very powerful operation. Can we use that to find quicker? Anyone have any ideas? Sure. AUDIENCE: [INAUDIBLE] JASON KU: We're going to get to hashing in a second, but this is a simpler concept than hashing-- something you probably are familiar with already. We've kind of been using it implicitly in some of our sequence data structure things. What we're going to do is, if I have an item that has key 10, I'm going to keep an array and
3875	store that item 10 spaces away from the front of the array, right at index 9, or the 10th index. Does that make sense? If I store that item at that location in memory, I can use this random access to that location and see if there's something there. If there's something there, I return that item. Does that make sense? This is what I call a direct access array.
3876	that we've been talking about earlier in the class. We got an array, and if I have an item here with key equals 10, I'll stick it here in the 10th place. Now, I can only now store one item with the key 10 in my thing, and that's one of the stipulations we had on our set data structures. If we tried to insert something with the same key as something already stored there, we're going to replace the item. That's what the semantics of our set interface was. But that's OK. That's satisfying the conditions of our set interface. So if we store it there, that's fantastic. How long does it take to find, if we have an item with the key 10? It takes constant time, worst case-- great. How about inserting or deleting something? AUDIENCE: [INAUDIBLE] JASON KU: What's that? AUDIENCE: [INAUDIBLE] JASON KU: Again, constant time-- we've solved all our problems. This is amazing. OK. What's not amazing about this? Why don't we just do this all the time? Yeah? AUDIENCE: You don't know how
3877	high the numbers go. JASON KU: I don't know how high the numbers go. So let's say I'm storing, I don't know, a number associated with that the 300 or 400 of you that are in this classroom. But I'm storing your MIT IDs. How big are those numbers? Those are like nine-digit numbers-- pretty long numbers. So what I would need to do-- and if I was storing your keys as MIT IDs, I would need an array that has indices that span the tire space of nine-digit numbers. That's like 10 to the-- 10 to the 9. Thank you. 10 to the 9 is the size of a direct access road off to build to be able to use this technique to create a direct access array to search on your MIT IDs, when there's only really 300 of you in here. So 300 or 400 is an n that's much smaller than the size of the numbers that I'm trying to store. What I'm going to use as a variable to talk about the size of the
3878	numbers I'm storing-- I'm going to say u is the maximum size of any number that I'm storing. It's the size of the universe of space of keys that I'm storing. Does that make sense? OK, so to instantiate a direct access array of that size, I have to allocate that amount of space. And so if that is much bigger than n, then I'm kind of screwed, because I'm using much more space. And these order operations are bad also, because essentially, if I am storing these things non-continuously, I kind of just have to scan down the thing to find the next element, for example. OK, what's your question? AUDIENCE: Is a direct access array a sequence data structure? JASON KU: A direct access array is a set data structure. That's why it's a set interface up there. Your colleague is asking whether you can use a direct accessory to implement a set-- I mean a sequence. And actually, I think you'll see in your recitation notes, you have code that can take a set data structure and
3879	implement sequence data structure, and take sequence data structure and implement a set data structure. They just won't necessarily have very good run time. So this direct access array semantics is really just good for these specific set operations. Does that makes sense? Yeah? AUDIENCE: What is u? JASON KU: u is this the size of the largest key that I'm allowed to store. That makes sense? The direct access array is supporting up to u size keys. Does that make sense?
3880	That's the problem, right? When u largest key-- we're assuming integers here-- integer keys-- so in the comparison model, we could store any arbitrary objects that supported a comparison. Here we really need to have integer keys, or else we're not going to be able to use those as addresses. So we're making an assumption on the inputs that I can only store integers now. I can't store arbitrary objects-- items with keys. And in particular, I also need to-- this is a subtlety that's in the word RAM model-- how can I be assured that these keys can be looked up in constant time? I have this little CPU. It's got some number of registers it can act upon. How big is those registers? AUDIENCE: [INAUDIBLE] JASON KU: What? Right now, they're 64 bits, but in general, they're w. They're the size of your word on your machine. 2 to the w is the number of dresses I can access. If I'm going to be able to use this direct accessory, I need to make sure that the u
3881	is less than 2 to the w, if I want these operations to run in constant time. If I have kids that are much larger than this, I'm going to need to do something else, but this is kind of the assumption. In this class, when we give you an array of integers, or an array of strings, or something like that on your problem or on an exam, the assumption is, unless we give you bounds on the size of those things-- like the number of characters in your string or the size of the number in the-- you can assume that those things will fit in one word of memory. w is the word size of your machine, the number of bits that your machine can do operations on in constant time. Any other questions? OK, so we have this problem. We're using way too much space, when we have a large universe of keys. So how do we get around that Problem any ideas? Sure. AUDIENCE: Instead of [INAUDIBLE].. JASON KU: OK, so what your colleague is
3882	saying-- instead of just storing one value at each place, maybe store more than one value. If we're using this idea, where I am storing my key at the index of the key, that's getting around the us having to have unique keys in our data structure. It's not getting around this space usage problem. Does that make sense? We will end up storing multiple things at indices, but there's another trick that I'm looking for right now. We have a lot of space that we would need to allocate for this data structure. What's an alternative? Instead of allocating a lot of space, we allocate-- less space. Let's allocate less space. All right.
3883	This is our space of keys, u. But instead, I want to store those things in a direct access array of maybe size n, something like the order of the things that I'm going to be storing. I'm going to relax that and say we're going to make this a length m that's around the size of the things I'm storing. And what I'm going to do is I'm going to try to map this space of keys-- this large space of keys, from 0 to u minus 1 or something like that-- down to arrange that 0 to m minus 1.
3884	this is what I'm going to call h-- which maps this range down to a smaller range. Does that make sense? I'm going to have some function that takes that large base of keys-- sticks them down here. And instead of staring at an index of the key, I'm going to put the key through this function, the key space, into a compressed space and store it at that index location. Does that make sense? Sure. AUDIENCE: [INAUDIBLE] JASON KU: Your colleague is-- comes up with the question I was going to ask right away, which was, what's the problem here? The problem is it's the potential that we might be-- have to store more than one thing at the same index location. If I have a function that matches this big space down to this small space, I got to have multiple of these things going to the same places here, right? It can't be objective. But just based on pigeonhole principle, I have more of these things. At least two of them have to go to something over
3885	here. In fact, if I have, say, u is bigger than n squared, for example, there-- for any function I give you that maps this large space down to the small space, n of these things will map to the same place. So if I choose a bad function here, then I'll have to store n things at the same index location. And if I go there, I have to check to see whether any of those are the things that I'm looking for. I haven't gained anything. I really want a hash function that will evenly distribute keys over this space. Does that make sense? But we have a problem here. If we need to store multiple things at a given location in memory-- can't do that. I have one thing I can put there. So I have two options on how to deal-- what I call collisions. If I have two items here, like a and b, these are different keys in my universe of space. But it's possible that they both map down to some hash that
3886	has the same value. If I first hash a, and a is-- I put a there, where do I put b? There are two options. AUDIENCE: Is the second data structure [INAUDIBLE] so that it can store [INAUDIBLE]?? JASON KU: OK, so what your colleague is saying-- can I store this one is a linked list, and then I can just insert a guy right next to where it was? What's the problem there? Are linked lists good with direct accessing by an index? No, they're terrible with get_at and set_at They take linear time there. So really, the whole point of direct this array is that there is an array underneath, and I can do this index arithmetic and go down to the next thing. So I really don't want to replace a linked list as this data structure. Yeah? What's up? AUDIENCE: [INAUDIBLE] JASON KU: We can make it really unlikely. Sure. I don't know what likely means, because I'm giving you a hash function-- one hash function. And I don't know what the inputs are. Yeah? Go
3887	ahead. AUDIENCE: [INAUDIBLE] JASON KU: OK, right. So there are actually two solutions here. One is I-- maybe, if I choose m to be larger than n, there's going to be extra space in here. I'll just stick it somewhere else in the existing array. How I find an open space is a little complicated, but this is a technique called open addressing, which is much more common than the technique we're going to be talking about today in implementations. Python uses an open addressing scheme, which is essentially, find another place in the array to put this collision. Open addressing is notoriously difficult to analyze, so we're not going to do that in this class. There's a much easier technique that-- we have an implementation for you in the recitation handouts. It's what your colleague up here-- I can't find him-- over there was saying-- was, instead of storing it somewhere else in the existing direct access array down here, which we usually call the hash table-- instead of storing it somewhere else in that hash table, we'll instead,
3888	at that key, store a pointer to another data structure, some other data structure that can store a bunch of things-- just like any sequence data structure, like a dynamic array, or linked list, or anything right. All I need to do is be able to stick a bunch of things on there when there are collisions, and then, when I go up to look for that thing, I'll just look through all of the things in that data structure and see if my key exists. Does that make sense? Now, we want to make sure that those additional data structures, which I'll call chains-- we want to make sure that those chains are short. I don't want them to be long. So what I'm going to do is, when I have this collision here, instead I'll have a pointer to some-- I don't know-- maybe make it a dynamic array, or a linked list, or something like that. And I'll put a here and I'll b here. And then later, when I look up key K, or look up
3889	a or b-- let's look up b-- I'll go to this hash value here. I'll put it through the hash function. I'll go to this index. I'll go to the data structure, the chain associated to that index, and I'll look at all of these items. I'm just going to do a linear find. I'm going to look. I could put any data structure here, but I'm going to look at this one, see if it's b. It's not b. Look at this one-- it is b. I return yes. Does that make sense? So this is an idea called chaining. I can put anything I want there. Commonly, we talk about putting a linked list there, but you can put a dynamic array there. You can put a sorted array there to make it easier to check whether the key is there. You can put anything you want there. The point of this lecture is going to try to show that there's a choice of hash function I can make that make sure that these chains are small so
3890	that it really doesn't matter how I saw them there, because I can just-- if there's a constant number of things stored there, I can just look at all of them and do whatever I want, and still get constant time. Yeah? AUDIENCE: So does that means that, when you have [INAUDIBLE] let's just say, for some reason, the number of things [INAUDIBLE] is that most of them get multiple [INAUDIBLE].. Is it just a data structure that only holds one thing? JASON KU: Yeah. So what your colleague is saying is, at initialization, what is stored here? Initially, it points to an empty data structure. I'm just going to initialize all of these things to have-- now, you get some overhead here. We're paying something for this-- some extra space and having pointer and another data structure at all of these things. Or you could have the semantics where, if I only have one thing here, I'm going to store that thing at this location, but if I have multiple, it points to a data structure. These are kind
3891	of complicated implementation details, but you get the basic idea. If I just have a 0 size data structure at all of these things, I'm still going to have a constant factor overhead. It's still going to be a linear size data structure, as long as m is linear in n. Does that makes sense? OK. So how do we pick a good hash function? I already told you that any fixed hash function I give you is going to experience collisions. And if u is large, then there's the possibility that I-- for some input, all of the things in my set go directly to the same hashed index value. So that ain't great. Let's ignore that for a second. What's the easiest way to get down from this large space of keys down to a small one? What's the easiest thing you could do? Yeah? AUDIENCE: [INAUDIBLE] JASON KU: Modulus-- great. This is called the division method. And what its function is is essentially, it's going to take a key and it's going to say equal to be
3892	K mod m. I'm going to take something of a large space, and I'm going to mod it so that it just wraps around-- perfectly valid thing to do. It satisfies what we're doing in a hash table. And if my kids are completely uniformly distributed-- if, when I use my hash function, all of the keys here are uniformly distributed over this larger space, then actually, this isn't such a bad thing. But that's imposing some kind of distribution requirements on the type of inputs I'm allowed to use with this hash function for it to have good performance. But this plus a little bit of extra mixing and bit manipulation is essentially what Python does. Essentially, all it does is jumbles up that key for some fixed amount of jumbling, and then mods it m, and sticks it there. It's hard coded in the Python library, what this hash function is, and so there exist some sequences of inserts into a hash table in Python which will be really bad in terms of performance, because these chain links
3893	are the amount number of collisions that I'll get at a single hash is going to be large. But they do that for other reasons. They want a deterministic hash function. They want something that I do the program again-- it's going to do the same thing underneath. But sometimes Python gets it wrong. But if your data that you're storing is sufficiently uncorrelated to the hash function that they've chosen-- which, usually, it is-- this is a pretty good performance. But this is not a practical class. Well, it is a practical class, but one of the things that we are-- that's the emphasis of this class is making sure we can prove that this is good in theory as well. I don't want to know that sometimes this will be good. I really want to know that, if I choose-- if I make this data structure and I put some inputs on it, I want a running time that is independent on what inputs I decided to use, independent of what keys I decided to store. Does that
3894	makes sense? But it's impossible for me to pick a fixed hash function that will achieve this, because I just told you that, if u is large-- this is u-- if u is large, then there exists inputs that map everything to one place. I'm screwed, right? There's no way to solve this problem. That's true if I want a deterministic hash function-- I want the thing to be repeatable, to do the same thing over and over again for any set of inputs. What can I do instead? Weaken my notion of what constant time is to do better-- OK, use a non-deterministic-- what does non-deterministic mean? It means don't choose a hash function up front-- choose one randomly later. So have the user-- they pick whatever inputs they're going to do, and then I'm going to pick a hash function randomly. They don't know which hash function I'm going to pick, so it's hard for them to give me an input that's bad. I'm going to choose a random hash function. Can I choose a hash function from
3895	the space of all hash functions? What is the space of all hash functions of this form? For every one of these values, I give a value in here. For each one of these independently random number between this range, how many such hash functions are there? m to the this number-- that's a lot of things. So I can't do that. What I can do is fix a family of hash functions where, if I choose one from-- randomly, I get good performance. And so the hash function I'm going to use, and we're going to spend the rest of the time on,
3896	It satisfies what we call a universal hash property-- so universal hash function. And this is a little bit of a weird nomenclature, because I'm defining this to you as the universal hash function, but actually, universal is a descriptor. There exist many universal hash functions. This just happens to be an example of one of them. OK? So here's the hash function-- doesn't look actually all that different. Goodness gracious-- how many parentheses are there-- mod p, mod m. OK. So it's kind of doing the same thing as what's happening up here, but before modding by m, I'm multiplying it by a number, I'm adding a number, I'm taking it mod another number, and then I'm getting by m. This is a little weird. And not only that-- this is still a fixed hash function. I don't want that. I want to generalize this to be a family of hash functions, which are this habk for some random choice of a, b in this larger range. All right, this is a lot of notation here. Essentially what this
3897	is saying is, I have a has family. It's parameterized by the length of my hash function and some fixed large random prime that's bigger than u. I'm going to pick some large prime number, and that's going to be fixed when I make the hash table. And then, when I instantiate the hash table, I'm going to choose randomly one of these things by choosing a random a and a random b from this range. Does that makes sense? AUDIENCE: [INAUDIBLE] JASON KU: This is a not equal to 0. If I had 0 here, I lose the key information, and that's no good. Does this make sense? So what this is doing is multiplying this key by some random number, adding some random number, modding by this prime, and then modding by the size of my thing. So it's doing a bunch of jumbling, and there's some randomness involved here. I'm choosing the hash function by choosing an a, b randomly from this thing. So when I start up my program, I'm going to instantiate this thing with
3898	some random a and b, not deterministically. The user, when they're using this thing, doesn't know which a and b I picked, so it's really hard for them to give me a bad example. And this universal hash function-- this universal hash family, shall we say-- really, this is a family of functions, and I'm choosing one randomly within that family-- is universal. And universality says that-- what is the property of universality? It means that the probability, by choosing a hash function from this hash family, that a certain key collides with another key is less than or equal to 1/m for all-- any different two keys in my universe. Does that make sense? Basically, this thing has the property that, if I randomly-- for any two keys that I pick in my universe space, if I randomly choose a hash function, the probability that these things collide is less than 1/m. Why is that good? This is, in some sense, a measure of how well distributed these things are. I want these things to collide with 1/m probability
3899	so that these things don't collide very-- it's not very likely for these things to collide. Does that make sense? So we want proof that this hash family satisfies this universality property. You'll do that in 046. But we can use this result to show that, if we use a universal-- this universal hash family, that the length of our change-- chains is expected to be constant length. So we're going to use this property to prove that. How do we prove that? We're going to do a little probability. So how are we going to prove that? I'm going to define a random variable, an indicator random variable. Does anyone remember what an indicator in a variable is? Yeah, it's a variable that, with some amount of probability,
3900	So I'm going to define this indicator random variable xij is a random variable over my choice-- over choice of a hash function in my has family. And what does this mean? It means xij equals 1, if hash Ki equals hKj-- these things collide-- and 0 otherwise. So I'm choosing randomly over this hash family. If, for two keys-- key i and and j-- if these things collide, that's going to be 1. If they don't, then it's 0. OK? Then, how can we write a formula for the length of a chain in this model? So the size of a chain-- or let's put it here-- the size of the chain at i-- at i in my hash table-- is going to equal-- I'm going to call that the random variable xi-- that's going to equal the sum over j equals 0 to-- what is it-- over, I think, u minus 1 of summation-- or sorry-- of xij. So basically, if I fix this location i, this is where this key goes. Sorry. This is the size of
3901	chain at h of Ki. Sorry. So I look at wherever Ki goes is hashed, and I see how many things collide with it. I'm just summing over all of these things, because this is 1 if there's a collision and 0 if there's not. Does that make sense? So this is the size of the chain at the index location mapped to by Ki. So here's where your probability comes in. What's the expected value of this chain length over my random choice? Expected value of choosing a hash function from this universal hash family of this chain length-- I can put in my definition here. That's the expected value of the summation over j of xij. What do I know about expectations and summations? If these variables are independent from each other-- AUDIENCE: [INAUDIBLE] JASON KU: Say what? AUDIENCE: [INAUDIBLE] JASON KU: Linearity of expectation-- basically, the expectation sum of these independent random variables is the same as the summation of their expectations. So this is equal to the summation over j of the expectations of these individual
3902	ones. One of these j's is the same as i. j loops over all of the things from 0 to u minus 1. One of them is i, so when xhi is hj, what is the expected value that they collide? 1-- so I'm going to refactor this as being this, where j does not equal i, plus 1. Are people OK with that? Because if i equals-- if j and i are equal, they definitely collide. They're the same key. So I'm expected to have one guy there, which was the original key, xi. But otherwise, we can use this universal property that says, if they're not equal and they collide-- which is exactly this case-- the probability that that happens is 1/m. And since it's an indicator random variable, the expectation is there are outcomes times their probabilities-- so 1 times that probability plus 0 times 1 minus that probability, which is just 1/m. So now we get the summation of 1/m for j not equal to i plus 1. Oh, and this-- sorry. I did this wrong.
3903	This isn't u. This is n. We're storing n keys. OK, so now I'm looping over j-- this over all of those things. How many things are there? n minus 1 things, right? So this should equal 1 plus n minus 1 over m. So that's what universality gives us. So as long as we choose m to be larger than n, or at least linear in n, then we're expected to have our chain lengths be constant, because this thing becomes a constant if m is at least order n. Does that make sense? OK. The last thing I'm going to leave you with is, how do we make this thing dynamic? If we're growing the number of things we're storing in this thing, it's possible that, as we grow n for a fixed m, this thing will stop being-- m will stop being linear in n, right? Well, then all we have to do is, if we get too far, we rebuild the entire thing-- the entire hash table with the new m, just like we did with
3904	a dynamic array. And you can prove-- we're not going to do that here, but you can prove that you won't do that operation too often, if you're resizing in the right way. And so you just rebuild completely after a certain number of operations. OK, so that's hashing. Next week, we're going to be talking about doing a faster sort.
3905	[SQUEAKING] [RUSTLING] [CLICKING] JASON KU: OK, let's get started. Welcome to the 12th lecture of 6.006. This is our second lecture talking about weighted graphs, and in particular, weighted shortest paths, algorithms. Last time we talked about weighted graphs. This is a kind of a generalization of what we mean by distance in an unweighted graph instead of each edge having a weight of 1, essentially. We generalize that to be any integer. And last time, we showed how to solve shortest single-source shortest paths in a graph that doesn't have cycles even if it has 0 or negative weights in linear time using an algorithm called DAG relaxation. We also showed in that lecture how in linear time, if we are given the shortest path weights to all the things reachable in finite-- or with shortest path distance that's finite, we can construct a shortest paths tree from those weights in linear time. So this is motivating why we're not really going to talk about parent pointers for the next couple of lectures. We're just going to concentrate on
3906	the shortest path weights. And so today, we're going to be talking about our most general algorithm we'll be showing for solving single source shortest paths, in particular in graphs that could contain cycles and could have negative weights.
3907	single source shortest paths in linear time. Last time we discussed another linear time algorithm, DAG relaxation. And today we're going to be talking about Bellman-Ford, which isn't limited to asymptotic graphs. In particular, there could be negative weight cycles in our graph. If it has cycles, if it has negative weights, the worry is that we could have negative weight cycles, in which case there-- if a negative weight cycle is reachable from our source, then the vertices in that cycle and anything reachable from that cycle will potentially
3908	There's not a bound on the number of edges for a shortest path, because I could just keep going around that cycle as many times as I want and get a shorter path. And so we assign those distances to be minus infinity. So that's what we're going to do today in Bellman-Ford. In particular, what we're going to do is compute our shortest path distances, the shortest path waits for every vertex in our graph, setting the ones that are not reachable to infinity, and the ones that are reachable through a negative weight cycle to minus infinity, and all other ones we're going to set to a finite weight. And another thing that we might want is if there's a negative weight cycle in the graph, let's return one. So those are the two kinds of things that we're trying to solve in today's lecture. But before we do that, let's warm up with two short exercises. The first one, exercise 1, given an undirected graph, given undirected graph G, return whether G contains a negative weight cycle.
3909	Anyone have an idea of how we can solve this in linear time, actually? In fact, we can do it in order E. No-- yes, yes. Reachable from S. I guess-- let's just say a negative weight cycle at all. Not in the context of single-source shortest paths.
3910	JASON KU: Ah. Your colleague has determined an interesting fact about undirected graphs. If you have a negative weight edge in an undirected graph, I can just move back and forth along that edge. That's a cycle of length 2-- or I guess three vertices back to where we came from. There is of negative weight, because I'm just traversing that weight over and over and over again. So the question of single-source shortest paths of finding negative weights is not particularly interesting in the undirected case. What I can do is just for every negative weight edge, undirected edge in my graph, I can just find the readability from the vertices-- the endpoints of that edge and label them as minus-- basically if the connected component containing S has a negative weight edge, then everything in the graph is accessible from a negative weight cycle. So this is not such an interesting problem. And so we're going to restrict our discussion today to directed graphs. So this is if and only if exists negative weight edge. OK, exercise 2,
3911	kind of a little preview for what's to come, we're actually not going to show you an algorithm directly that meets this Bellman-Ford running time, V times E. What instead we're going to show you is an algorithm that solves single-source shortest paths in-- So given an algorithm, Alg A, solves single-source shortest paths in order V times V plus E time. OK, what is that? That's V squared plus V times E. That's close to what this V times E is. That's what we're going to show you. But if I had such an algorithm, can anyone tell me a single-source shortest paths algorithm-- how we can use this algorithm to solve single-source shortest paths in just V times E time? Show how to solve SSSP in order the V times E. I guess we can put a dot there as well. So this is a little tricky. It's kind of related to the difference we had between the reachability problem and the single-source shortest paths problem that we saw last lecture. When are these asymptotically different in their
3912	upper bound is when V is asymptotically larger than E. But the connected component containing S can have at most E vertices, or order E. It can actually have at most E plus 1 vertices, because otherwise it wouldn't be connected. So, what we can do if we had such an algorithm, we could first, when we're giving our graph, explore everything in the graph using BFS or DFS, find all the things reachable from S, and then just throw away everything else. Now I have a graph for which V is asymptotically no bigger than E, and then we can use this algorithm to solve single-source shortest paths in V times E time. I'm not going to write all that down here. You can see it in the notes. Yeah? AUDIENCE: Does this work if your graph isn't simple? JASON KU: Does this work as your graph isn't simple? I haven't thought about it. We are not going to talk about non-simple graphs in this class, but probably not because you've got a lot of edges. Though in our
3913	class if we're talking about single-source shortest paths, if we have multiple edges between two vertices, we can just take the minimum weight one because it's never better to take the larger ones. Does that answer your question? Great. All right. So those are our warm-ups, that's our goal. We need to find an algorithm for single-source shortest paths. And general graphs, graphs with-- potentially graphs with cycles, and negative weights, and solve it in this V times linear kind of time. That makes sense? All right. So first, before we get to the algorithm, we're going to discuss a little bit about simple short-- about shortest paths in general. If we didn't-- the problem here is negative weights. How do we find-- if we had negative weight cycles, there seems to be these problems, because we could have minus infinities is in our deltas. But if we didn't have negative weights, I'd like to assert to you that our shortest paths, even if there are negative weights, are going to be simple. They won't repeat vertices. So that's the
3914	first thing we're going to show you. Let's see. Simple shortest paths. OK. So, claim. I'm going to give my claims numbers today just because I'm going to have a lot of them. If my shortest path distance from S to some vertex is finite, meaning it's not infinite or minus infinite-- some finite value, there exists a shortest path-- a shortest S to V path that is simple. And remember, simple means not going through a vertex more than once. All right. How are we going to prove this? Well, consider if this claim was not true. If every shortest path contained a cycle, essentially. It repeated a vertex. Then my path looks something like this. I mean, there's some vertices along here, and then I go to V. So here's S, and then there's some cycle I repeat, some vertex. I'm going to call this cycle C. Now what do I know about this path? I know that it has-- it's a shortest path and it has finite weight. So in particular, this path-- this delta distance is
3915	not minus infinity. But if this is not minus infinity, what do I know about the weight of this cycle? AUDIENCE: It's not negative. JASON KU: Yeah. It can't be negative. Because if it was negative, I could keep going around this cycle, and this would have a non-finite weight. Shortest path distance from S. So I know this is-- can't be negative, so it must be 0 or positive. But if it's 0 or positive and this is a shortest path-- went through this cycle, then I could remove it, and now I have a new path with one fewer cycle. I could just keep doing this to create a simple path. So that checks out. OK. So, that's interesting. If it's simple, what do we know about the number of edges in a simple shortest paths? How many could there possibly be? How long in number of edges could a simple shortest path be? If I can't repeat vertices, I can have at most vertices on my simple path, which means I can use at most V minus
3916	1 edges-- fence posting. So, simple paths have at most V minus 1 edges. That's a nice little thing I'd like to box off. That's a really nice property. So while a shortest path here could have an infinite number
3917	I know I only have to check paths that use up to V minus 1 edges. In particular, this is finitely bounded in terms of the number of paths I have to consider. It's exponential, potentially, but at least it's finite. The other way, I potentially had to check every possible path of which there could be infinite if there's cycles in my graph. OK. So I have an idea. What if I could find shortest-path distances by limiting the number of edges I go through? So not the full shortest path distance from S to V, but let's limit the number of edges I'm allowed to go through, and let's talk about those shortest-path distances, just among the paths that have at most a certain number of edges. I'm going to call this k-edge distance. And I'm just going to provide a little notation here. Instead of having a delta, I'll have a delta k here. That means how many edges I'm limited by. So from S to V is shortest S to V path using at most k
3918	edges. Short-- weight-- weight of a. Shortest path, shortest S to V path using at most k edges. And these notions seem somewhat symmetric. If I were able to compute this thing for V minus 1, then-- for all the vertices, then if the distance is finite, then I'll have successfully computed the real shortest paths because of this statement. Now that doesn't mean that if this is-- it doesn't mean the other way. If this is minus infinity, if the shortest-path distance is minus infinity, it doesn't say anything about what this is. It just says the shortest path using at most V minus 1 vertices, using at most V minus 1 edges would be whatever this is. But really, the shortest path length needs to consider an infinite number of edges. So it doesn't really tell us much about that. But for the finite ones it does. It works well. And so if we are able to compute this thing for k equals
3919	cycles, we'd be done. I claim to you a stronger statement, that if the shortest path using at most V edges from s to v Is less than-- strictly less than delta of V minus 1-- this is all in the subscript here. Basically this is the shortest-path distance of any simple path, and possibly ones that also contain cycles, but definitely it includes all the simple paths. If there's a shorter path to my vertex that goes through more than V minus 1 edges, that this path can't be simple, because it goes through a vertex more than once. Otherwise it would be included in this distance set. So if this is the case, and I found a shorter path to V that uses v edges-- yeah, that use V edges, that path can't be simple, which means that path or some path there contains a negative weight cycle. So if this is true, then I know that the real shortest-path distance from S to V must be minus infinity. I'm going to call such a vertex a witness.
3920	If we can find a vertex that has this property-- I mean, I haven't shown you how to compute these things yet, but if I were able to find a vertex V-- and these are capital V's if you're having trouble. This V is different than this V, this is cardinality. If we can find such a vertex V, that certifies that there is a negative weight cycle in our graph. So I'm going to call V is a witness. OK. So, if this property is true, it's a witness and it definitely has this. Is it possible, you think-- I'm going to claim to you that it's possible that a vertex could have minus infinite distance but not have this property halt. I could probably give you an example-- I don't have one off the top of my head right now, but that's possible. You could imagine, there might be no path going to a vertex on a negative weight cycle that goes through V exactly V edges. It might go through more edges, a shorter one. So this
3921	equation would be inequality and would not certify that this is true. But I claim to you, if a vertex has this property, if it's its shortest path distances minus infinite, then it must be reachable from a witness. So that's the claim. If delta S, V is minus infinity, then V is reachable from a witness. Reachable from a vertex that has this property-- that has this property. And if it's reachable from something that has minus infinity shortest pathway, then I can take that path go to my reachable vertex, and that's also minus infinite path. OK. So how do we prove this? Well, let's consider-- let's I'm going to state a somewhat stronger statement that we'll prove instead. It suffices to prove that every negative weight cycle contains a witness. If we are to prove that, then every vertex with this property, every vertex with this property is reachable from a negative weight cycle by definition. So, if we can prove that every-- prove every negative weight cycle contains witness. If we can prove that every negative
3922	weight cycle contains a witness, then every vertex reachable from one of those witnesses-- in particular, reachable from the negative weight cycle-- has shortest distance minus infinity, and that should prove the claim. This thing has to be reachable from a negative weight cycle. And so if we prove negative weight cycles contain witnesses, then all of these vertices are reachable from a witness. OK, great, great. Confusing myself there for a second. OK. So let's consider a negative weight cycle. NG. Here's a directed negative weight cycle. Recall. This will be my negative weight cycle C. All of the sum of the edges in this thing, the weights has negative weight. And I'm going to have a little bit notation-- if I have a vertex V here, I'm going to say that its predecessor in the cycle, I'm just going to call it V prime. That's just some notation. All right. So, if I have computed these shortest-path distances to every vertex in my graph, shortest-path distance going through at most V vertices and the shortest path distance going
3923	through at most V minus 1 vertices, then I know the following thing holds. Delta V going from S to V for any vertex in my cycle can't be bigger than delta V minus 1 from S to U plus the weight-- sorry, not U-- V prime, its predecessor, plus the weight going from the predecessor to my vertex. Why is that? Why is that? Because this is the weight of some vertex-- this is the weight-- the shortest-path distance to my predecessor using one fewer edge. And so this in particular is the weight of some path that uses V edges. So if this is the shortest such path distance, this has to upper bound it at least-- at most. Yeah? AUDIENCE: Is that the triangle inequality? JASON KU: That is a statement of the triangle inequality, thank you. All right. So, yes, this is just by triangle inequality. OK. Now what we can say is, let's take this equation summed over all vertices in my cycle. So I'm just going to add summation here of all vertices in
3924	my cycle of this whole thing. I'm going to do that out a little bit neater. Summation of delta, not d. Delta V S, V. I guess I don't need this open parentheses. Equals-- or less than or equal to sum of V and C of delta V minus 1 V prime. And here, I'm summing over V and C, and this is just my notation for the predecessor. And then I'm going to sum over the weights in my cycle V and C. These are the sum of the weights in my cycle. Well, what do I know about this cycle? This is just the weight of C. The weight of C-- that's awful handwriting. C, what do I know about the weight of the cycle? It's negative. So, this is less than 0, which means that if I remove this, this needs to be a strict equality. But if the sum of all of these is strictly less than the sum of all these, we can't have none of the vertices in my graph satisfying-- not satisfying this
3925	property. If all of them are not witnesses, then this thing is bigger than this thing-- at least as big as this thing for every vertex in my cycle, which is a contradiction. So, the claim holds, if we have a negative infinite shortest-path distance, then V is reachable from a witness. So it suffices for us to find all the witnesses, find all the vertices reachable from the witnesses, and then mark them as minus infinity. Does that make sense? OK. So, now we finally are able to get to our algorithm. Bellman-Ford. And what I'm going to show you today is a little different than what is normally presented as Bellman-Ford. The original Bellman-Ford algorithm does something a little different. And because it does something a little different, which we'll talk about at the end, it's a little hairier to analyze. I'm going to show you a modification that is a little easier to analyze and has this nice property that we're going to be able to use the algorithm to give us a negative weight cycle if
3926	it exists. So, we're going to say this is maybe a modified Bellman-Ford.
3927	many versions of a vertex. And I want this version of the vertex to correspond to whether I came here using 0 edges, 1 edge, 2 edges, 3 edges-- I have a different vertex version of the vertex for each one of these-- for a path going through, at most, a certain number of edges. OK. So this is an idea called graph duplication. Idea, graph duplication. And this is a very common technique for solving graph-related problems. Because essentially what I get to do is I get to store information. If I'm having different versions of a vertex, I can have that vertex correspond to reaching that vertex in a different state. So that's what we're going to do here. The idea here is make V plus 1 levels-- basically duplicate vertices in our graph-- where vertex Vk in level k represents reaching vertex V using at most k edges. OK, so this definition seems similar to what we're doing up here. If we have vertices that have this property, then their shortest paths in this new graph might
3928	correspond to these k edge distances. And really, the name of the game here is to compute these two for every vertex, because then we can-- then if d is finite, delta is finite, then this guy will be the length of our shortest path. And if they are different, that will be a witness and we can explore from it. So-- and if we connect edges from one level to only higher levels, basically levels with a higher k, then this graph is going to be a DAG. Whoa. That's cool. Why is that cool? Because we saw how to solve single-source shortest paths in a DAG and linear time. Now this graph that we're going to construct is going to have V plus 1 levels. So could have-- our graph kind of explodes V times. We're going to do that in a second. I'm going to be more precise with what I mean there. But if we're multiplying our graph V plus 1 times, then the size of our graph is now V times larger. Now that doesn't--
3929	that's not so hard to believe. But if we made our graph V times larger and we ran a shortest path algorithm in linear time with respect to that graph, then that graph has something like size V times V plus E size. That looks familiar, maybe? That's this running time. So if we can find an algorithm that runs in that running time, we can get down to V times E. So let's try to do that.
3930	Here's the transformation I'm going to show you. I'm going to show you first with an example. Here's an example of a directed graph that does contain a negative weight cycle. Can anyone find it for me? bcd. Has weigh minus 4 plus 3 minus 1. It has a minus 2 total weight. So that's a negative weight cycle. So in order to take shortest paths from a, I will want to say at the end of my algorithm, this better be 0, and all of these better be minus infinity. So that's what I want in my algorithm. So what's my algorithm going to be? I'm going to make V plus 1 copies of this graph, and I'm going to kind of stretch it out. OK. So here, I have V 0, 1, 2, 3, 4-- there are four vertices in my graph. So this is 1, 2, 3, 4, 5 copies of my graph. I have a version of vertex a for each one of those copies, a version of vertex b for each of those copies, c
3931	and d, et cetera. So I have this nice grid of vertices. And I'm not going to put any edges within a layer, within a level. Because then-- I mean, this graph has cycles. And I don't want cycles in my graph. What I'm going to do instead is for every edge in my original graph-- for example, the edge from a to b, I'm going to connect it to the b in the next level. So a0 is connected to b1 with an edge weight of minus 5, just like in the original. And I'm going to do that for every edge in my graph, and I'm going to repeat that down all the way. In addition, I'm going to add zero-weight edge from a0 to a1 or from every vertex all the way down the line. These are all zero-weight edges corresponding to-- I'm not going to traverse an edge, I'm just going to stay at this vertex. That's going to allow us to simulate this at most k edges condition. Now if you take a look at
3932	paths in this graph from a0, our starting vertex, clearly none of the other vertices in that level are reachable from a0, just as we want. Because the shortest-path distance to any of these vertices using at most 0 edges should be infinite. I can't get there in 0 edges. But then any path in this graph using at most k edges is going to correspond to a path from a0 to a vertex in that level, the corresponding level. So for example, if I had a-- if I was looking for paths 2b using at most three edges, any path-- a path from a0 to b3 in this graph would correspond to a path in this graph that uses at most three edges. so Let's find such a path. So going from a0, b1, stay at b1-- stay at b, sorry. Yeah, that's a path using fewer than three edges-- or at most three edges. But there's another path here. Where is it? Going from a, a, a to b-- OK, that's not such an interesting one. That's the
3933	same path. So I might have more than one path in here corresponding to a path in there, but my claim is that any path in here corresponds to a path in here. So what's a path of length? 3, that's non-trivial. Yeah, a to c to d to b. So a to c to d to b. Yeah, that's a path. And basically, because I constructed this so that the edges always moved from level to level, as I traverse these edges, I always change levels. Yeah? AUDIENCE: But my original graph doesn't have these self-loops with 0 weight. JASON KU: Yes. My original graph doesn't have an edge from a to a. That's true. I'm using these edges to correspond to-- I'm deciding not to take an edge. It's not that I'm like doing any work here, I'm just staying there for a state. And that's what's going to allow me to get this at most edges. All right. So, this is the graph construct. Hopefully you understand that we made these V layers. This is V. And
3934	a vertex-- we made V copies of every vertex and connected them using edges in this way. OK. So, first step of Bellman-Ford is construct this graph. So, Bellman-Ford, construct G prime as described above. It has how many vertices? V times V plus 1. V times V plus 1 vertices. And how many edges? Well, I have one edge for outgoing edge for each vertex corresponding to just staying in the same place. So that's V squared vertices-- I mean edges. And then I have one edge-- for every edge in my graph, I have-- sorry. I have a V minus 1-- sorry. Just V. I have V edges for every edge in my graph. So that means-- so this is the number of vertices. And V times V plus V times E, this is V V plus E. All right, cool. So that's how many edges I have. So constructed in that way, it's a DAG. If we only have edges going to increasing levels, then this thing can't have cycles, because otherwise that would mean there would
3935	be an edge pointing backwards.
3936	All right. So we construct this graph G prime. We can do that in linear time with respect to these things. I just go through all the edges, I make these edges, and I make these vertices. It doesn't take anything-- I just do it naively. Right I can do that in time V times V plus E asymptotically. OK. Now I run DAG relaxation, our nice algorithm we had last time, from-- in there was a0. I'm going to say it's S0, our source. Our source vertex. Single source shortest paths. So that I compute delta of S0 to Vk for all k and-- what is it? 0 to V. That's what single source shortest paths does. It computes for me this distance from my source-- at some source to every other vertex in the graph. And so in particular I get these. Well, that is all of them. Then for each vertex V, set-- the thing I'm going to return, d-value, S to V, equal to the shortest-path distance I got from DAG relaxation to a particular vertex.
3937	V V minus 1. Why am I doing this? I'm setting it to be the shortest-path distance to the guy in the second-to-last row here or column in my modified graph. The hope is that this distance in my DAG corresponds to this distance in my original graph. The distance to V using at most V minus 1 edges. So that's the claim-- that's a claim we're going to prove in just a second. I'm going to write it down just so that we have-- just to continue our train of thought. Claim, delta S0 Vk equals delta k, the k edge distance, from S to V. That's what we want to claim. That would then-- what would that mean, then? That would mean that I'm correctly setting the shortest-path distance here for all vertices whose distances finite. Great. I mean, I set values to things where they're not finite, where they're minus infinity also, but in particular I set the ones correctly if they're finite. OK. So the last thing we need to do is deal with these minus
3938	infinity vertices. But we know how to do that. We just look at the witnesses. Because we've computed this value for k equals V equals V minus 1, and if that claim over there is true, then those shortest-path distances are the same as these k edge shortest-path distances. And we can just, for every vertex, we compare these things. If this is satisfied, we got a witness. OK. So for each witness U and V where delta S0 U V is less than, strictly, S0 U V minus 1-- that's the definition of a witness here, close the parentheses. Then for each vertex V reachable from U set-- sorry, d, is what we're returning, d of S, V equal to minus infinity. That's the end of the algorithm. Basically I'm looking for all the witnesses. For each witness, I find all of the vertices reachable from it and set it to minus infinity just as we argued before. OK. So, it remains to prove this claim. How do we prove this claim? Well, we can induct on k. Is
3939	this true for k equals 0? Yeah. We kind of already argued it over here when we are talking about our initialization step or what DAG relaxation does. It'll set this to be the shortest path from this guy to all these vertices. These aren't reachable from here, and so these are infinite.
3940	So the base case-- so induct on k base case, k equals 0? Check. That's all good. Now we-- in our inductive step, let's take a look at the shortest-path distance from 0-- from S0 to V of k prime for some k prime. And the assumption is, the inductive hypothesis is that this distance is the k edge distance for all k prime less than-- I mean all k less than k prime. Well, kind of by definition of a shortest path, this is the minimum overall incoming vertices of the shortest path from S0 to U of k prime minus 1 plus the weight of the edge from U of k prime minus to Vk prime for all Uk prime minus 1 in the adjacencies, the incoming adjacencies of Vk prime. OK, what does this mean? I'm just saying in my graph G prime, a shortest path to this vertex needs to go first through some vertex in the layer before it, which is one of these. And in particular, I'm only connected to things adjacent to me.
3941	"That's all this is saying. I have to go through that vertex and take some shortest path to one of those previous vertices. Now s actuality, these adjacencies, I constructed them to be similar to the adjacencies in my original graph in addition to one edge coming from my original vertex, from vertex V. So this is the same as the minimum of this set delta S0. Same thing. Plus W U, V for all U in the adjacent-- incoming adjacencies of my original vertex. In addition to one more term. What is that other term? These are all of the things corresponding to my incoming edges in my original thing, but I also have that one edge coming from the V before it. So this is-- I'm going to union-- union-- union this with delta S0 V of k prime minus 1. Awful. I think there's another one here. This is S0 of k prime minus 1. I""m not going to rewrite it. OK. Then by induction, this thing and this thing must be the edge shortest paths using"
3942	k minus 1 vertices. And then that's just the statement of what the shortest path should be using at most k prime edges going from S to V. So, these things are the same as we claimed. Yay, check. All right. And then it's not such-- it's kind of a trivial leap, then, to say that at the end of Bellman-Ford, these guys-- sorry, the things that we return, these guys, are the shortest-path distances, because here, if they're finite, we set them to their true shortest-path distance; and if they're minus infinity, that invariant means that these things correspond to exactly this claim over here. It's a witness.
3943	And then finding all the vertices reachable from those witnesses, we set all of the infinite ones to be minus infinity as desired. OK, so what's the running time of this thing? Well, we had to construct this graph, so we had to take that time. We ran DAG relaxation, that takes the same amount of time. For every vertex, we did order V at work. And then for each witness, how many could there be? And most, V. Checking the reachability of each vertex, that can be done in how long? Order E time. Because we don't need to consider the things that aren't connected to S-- or aren't connected to the witness. So this thing takes order V times E work. So we're upper-bounded by this time it took to construct the original graph and by the claim we had before, that takes V times E time. OK. So that's Bellman-Ford. I'm just going to leave you with two nuggets. First, the shortest path, if for any witness-- let's say we have a witness here. Do I have
3944	any witnesses here? I didn't fill in all these. But is there a vertex on this cycle that goes through who has the shortest path? That goes through four vertices that's smaller than any other. OK. I can go from a to c to b to d to b to c. And you can work out this algorithm-- I have it in the notes that you can take a look at. This will actually have a shorter path for vertex-- sorry. It'll have a shorter path for vertex b. a to b to c to d to b. Thank you. That's a path of length 4, of four edges. That has shorter path than any path that has fewer edges. In particular, there's only one other path to b using fewer than four-- there's two other paths. One path of length-- that has one edge, that has weight minus 5, and one path-- this path that has weight 9 minus 1 is 8. Whereas this path, minus 5, minus 4, 3, minus 1 has minus 10 plus 3 is minus
3945	7, which is shorter than minus 5. So b and d is a witness. And if we actually take a look at that path through this graph, going from a to b to c to d back to b we see that there's a negative weight cycle in this graph. b to c to d to b. And indeed, that's always the case for our witnesses. You can see a proof of that in the notes, and you can see in recitation a little space optimization to make us not have to construct this entire graph on the fly, but actually only use order V space while they're going. OK. So that's Bellman-Ford. Sorry for running a little late.
3946	[SQUEAKING] [RUSTLING] [CLICKING] JASON KU: Hi, everybody. Welcome to the last lecture of 6.006. Last lecture, we talked about summing up this class and talking about future courses in the department that use this material. Just as a pointer to some of those classes, I have a little slide here I didn't get to at the last lecture, talking about what I was talking about at the end of the last lecture about different models-- different specialized classes on different aspects of 006 material-- for example, more graph stuff, different models of computation, randomness, complexity. All of these things have their own specialized classes in the department, as well as a lot of applications for this material in subjects like biology, cryptography, and in particular, for your instructors, the realm of graphics and geometry. All of your instructors this term happened to be geometers and be interested in geometry-related problems. Me in particular, I didn't start out in computer science. I started out in mechanical engineering. And the thing that was my passion coming into MIT was origami. Here's a
3947	couple of pieces that I designed-- origami pieces, one square sheet of paper without cutting. Here's a lobster, and here's a copyrighted dinosaur from a particular movie of the year that I designed it. When I was young, in high school, I started designing my own origami models. And what I didn't realize was, the procedures that I went about designing these models was actually algorithms. And I just didn't have the mathematical language to understand exactly what I was doing, but I could gain some intuition as an origami artist and design these things by using some of those algorithmic techniques. It wasn't until grad school, as a mechanical engineer, that I started talking with our other instructor here, Professor Demaine, about using algorithms and computer science to design not just origami, which we both do, but also folded structures that can be used for mechanical applications like space flight, deployable bridges in times when you can't-- you need a temporary bridge or shelter or something like that. Deployable structures where you might need to make folded structures-- transformable
3948	structures that can have different applications for different purposes-- need to reconfigure. The dream being that, we have these powerful devices in our pockets right now-- cell phones-- which are really powerful because we can reconfigure the bits in them to make software of all different kinds, right? There's an exponential number of different programs that we can write. And that's part of why you're here, is to write the next best one. Right? So that's how to make kind of a universal device at the electronic level. What if we could do that from a material standpoint? What if I could reprogram the matter in my phone so that, not only could I reprogram the app that's on your phone, but instead of having, say, the iPhone 10 or whatever that you have, and you want to go by the iPhone 11, instead, you download a software app that then reconfigures the matter in your phone-- it folds or reconfigures into the next generation iPhone. You don't have to throw away that old one. You can essentially recycle the
3949	material that you have to potentially save material, save cost, and be better for the environment, potentially. So I started moving into computer science because I found that it was a really good way to model the world and solve some really interesting problems about folding that I really enjoyed. The three of us today are going to spend some time talking a little bit about how we can use algorithms-- 6.006 material and beyond-- in our own research. And we're going to start off with Professor Demaine, and then Professor Solomon. ERIK DEMAINE: Thanks. So let me just jump in here to computational origami and geometric folding algorithms, sort of a broader umbrella for folding-related things, which is encapsulated by this class, 6.849, which is happening next fall. So you should all take it. 006 should be a reasonable background. And in general, we're interested in two kinds of problems. One-- the big one is origami design, or in general, folding design, where you have some specifications of what you would like to build. In this case I wanted
3950	to make a logo for 6.849. And I imagined extruding that text into third dimension. And then I wanted an algorithm to tell me how to fold that structure. And so there is an algorithm, which I'll talk about in a moment, that gives you a crease pattern. And then, currently, you fold it by hand. The dream is, we'll eventually have folding machines that do it all for us. And so that's the origami design, where you go from the target shape back to the crease pattern. The reverse direction is sort of foldability. If I gave you a structure like this and I wanted to know, does it fold? That's the problem we call foldability-- in general, class of problems. And sadly, most of those problems are NP-hard. Jason and I proved that foldability is hard for a general-- given a crease pattern like that, telling you whether folds into anything, it turns out to be NP-hard. So that's bad news. So we focus a lot on the design problem, because that actually tends to be easier. We
3951	can solve it with algorithms like that one you're seeing. A long time ago, we proved that you can fold everything. If I give you a square piece of paper and you take any polygon you want to make-- or maybe the paper's white on one side, black on the other, you want to fold some two-color pattern, like a zebra, or in general, some three-dimensional surface, like these guys, there is a way to fold it from a large enough square of paper. And it's actually really easy to prove that with an algorithm. I have the sketch of the two pages of proof that we go over in 6.849, but I'll just hand-wave a little bit. If you take a piece of paper, like my lecture notes here, the first thing you do is fold it down into a very long, narrow strip-- much longer and narrower than this one-- wasting most of the material. And then you take your strip, and you just figure out how to turn it in some general way, and then you just
3952	sort of zigzag back and forth along the surface. So it's very cool in that you can prove with an algorithm, and in a very short amount of time, to someone you can actually fold everything. Of course, it's a terrible folding, because in the very first step, we throw away all but epsilon of the material. But it's a starting point. That was back in the '90s-- late '90s-- one of the first results in computational origami. And in modern times, we look for better algorithms that are more efficient, that try to minimize the scale factor from, how big of a piece of paper do I start from to, how big of a model do I get? And one of the cool ways these days, which was invented by Tomohiro Tachi and then analyzed by the two of us-- it's called Origamizer. It's free software. You take a 3D model and you can-- it makes it into a pattern that you fold from a square. In this case, it uses 22% of the area, which is pretty good--
3953	similar to these guys in terms of efficiency. But very, very different kind of folding than what you would get from more traditional origami design, which uses different algorithms, which I'm not going to talk about. But you should take the class. Jason gives a lecture in the class, so you can learn from him. But the vision is, we can take any sheet of material that can hold a crease, like this sheet of steel that Tomohiro is folding. It was cut by a big laser cutter at MIT. And this is him in this Data Center several years ago, folding it into a steel bunny. And so this is a totally new way to manufacture 3D objects. And you can make particularly interesting objects that either collapse flat for transportation or transform, like Jason was talking about. But I'm just giving you a flavor. I think the first paper we wrote together was on maze folding. So this is an example of folding a maze from a rectangle of paper. And you can all try this out. You
3954	just google for our Maze Folder. You can generate a random maze. And this 3D structure can be folded from this crease pattern. That's a really hard one, so maybe try something smaller. You can also write your favorite message and fold this maze-- extruded graph-- from this crease pattern. Might want to start with something smaller, but that's the general idea. And it's actually quite easy to prove this algorithmically, if you have a really good origamist like Jason on your team. What you do is design how to fold each type of vertex. This is just a graph on a grid. There are some constant number of different ways that each vertex could look. It could be degree 4. It could be degree 3, as a T. It could be degree 2, either a turn or a straight. And you design little gadgets, little crease patterns, that fold into each of those little structures. And if you can do it in a way that these boundaries are compatible, then to fold the whole thing, you just sort of
3955	gluon together those crease patterns. And that's how that software works. This was particularly interesting, because you can fold an arbitrarily complicated graph-- arbitrarily complicated maze, n by n, with a constant scale factor. As long as the height that you're extruding that maze is constant, then this is one family of shapes we know how to fold really well. In general, we're trying to understand, what makes this lobster a nice shape in that it can be represented with a not-too-large piece of paper. And we don't have general answers to that problem. I think that was a whirlwind tour of computational origami. I also play a lot in algorithmic sculpture. One of the leading edges in origami and origami math is understanding how curved creases work. And one of our favorite models is this one, where you fold concentric circles alternating mountain and valley, cut a circular hole out, and it folds into this kind of Pringle shape as a nice physics equilibrium thing. And then you can turn it into fun sculptures like this. These are done
3956	with my dad, Martin Demaine, who's also here at MIT, or this guy. This paper has been printed with a pattern according to getting burned by glass. And then it gets folded and then put inside glass, also. Made here at MIT. We use sculpture to try to explore and understand intuitively how curved creases work, and then we get better and better understanding of the mathematics of even-- we don't even know whether this surface exists, whether it's possible to fold in this way, although getting close to proving it. That was sort of in the top level of this hierarchy. Computational geometry is a bigger umbrella, which is represented by another class, 6.850, that's being taught this term. And then I talked about geometric folding within that branch. Let me briefly tell you about another world of geometry-- very different in terms of model of computation. Oh, I jumped ahead a little bit. Rewind. Let me show you one more fun demo, which-- if I find my scissors. If I take a rectangle of paper, and I fold
3957	it flat and make one straight cut, what shapes can I get? It's called the folding cut problem. It's hundreds of years old. Here, for example, I get a swan. Here, I get-- one straight cut. I unfold and get angelfish. Tough audience today. I've got to keep going. You've seen all of these before. This is this one is a particularly difficult one to fold-- to only fold. And to cut, yeah. OK. That works well. This is the MIT logo. Ooh, ah. AUDIENCE: Ooh, aah. MIT, yeah! ERIK DEMAINE: Yeah. Go, MIT. All right. That's actually the first problem I worked on in computational origami. It's a lot of fun. And there's a really interesting algorithm here, also, for computing the crease pattern, how to fold your piece of paper to align-- in fact, any graph you draw on a piece of paper, you can align all of those edges and nothing else. So you cut along the line and you get exactly what you want.
3958	All right. Now, I want to talk about something completely different, which is self-assembly. A fun thing you can do with DNA, which we all have. Just pick out some cool DNA strands and design them in a clever way so they fit together to form a kind of square with dangling ends, which I'll call glues and each of those dangling ends can have a very particular pattern, and only identical or complementary patterns will attach to each other. And so you can use this to design your own self-assembling system, like biology does, but engineered, for example, to build a computer. This is an example of taking a bunch of these square tiles and building a binary counter. This thing is roughly counting in binary along the diagonal. It's a little skewed, so it's hard to see. But the general model is, you have squares-- this is sort of the computational model-- with four different glues. And you can build any square you want, but you don't have very many of these different glues, ideally. And then, if
3959	"you have two tiles with complementary glues, they will want to match together. But it depends how strong this glue is, how much affinity there is for how long those DNA dangling ends are, and also, the temperature of your system. If you have really high temperature, nothing. Will stick together low temperature, things will stick together even if they're not supposed to. If you tune your system really well, you can design a system so that maybe these guys-- these glues are really strong. And so let's, I don't know, write ""E"" here-- Erik. And so these tiles will always glue together, but only when all three of these are glued together can this tile-- which has C complement and F complement. Then it will, if you set the temperatures just right, only because both of these edges match will this dial be able to come in. And that's the basis for building that binary counter. This is a very different model of computation from what we're used to in this class, where you think of instructions, and they"
3960	run one at a time. Here the, model of computation is geometric. It's these squares that are just floating around and gluing together. And so your program, at any moment, is some conglomerate of squares. I just wanted to mention it because it's a really fun model. You can prove cool things in this model, like how to build any shape by a sequence of pores mixing between tiles that you can execute in parallel. And so it only takes log and time of parallel steps, a linear number of different mix operations, to make an arbitrary shape-- even using a constant number of different glues, which is cool,
3961	You can also use it to build a replicator, where you're given an object like this that you don't know the shape of-- like, we don't know whether this exists, and we can't model it mathematically very well, and you stick it in a vat, and all of these tiles would attach and basically build a mold, and then start photocopying, in 3D, that mold. And you can build that with a system with only two steps, I believe, and a constant number of tile types. And it does all of that, in this model, in constant time. In reality, you would have to feed this machine and wait for it to print out all of these things, and these experiments take hours, if not days, to run. But in theory, it's really cool. And you get some really fun models and very general results. You can also use it to build a miniaturizer or a magnifier and other fun stuff.
3962	That was a brief tour of computational geometry. I work mostly in four different areas of algorithms-- geometry, data structures, graph algorithms, and what I call recreational algorithms. I think I made up that term. And let's go into data structures, which is represented by this class, 6.851. All of the classes I mentioned have online video lectures, especially for those watching at home on OpenCourseWare. Most of these classes are on OpenCourseWare, and if not, they're on my webpage. 6.851, Advanced Data Structures, is an extension of the sorts of data structures you've seen here, in 006 and the ones you will see in 6.046. I thought I would give you a flavor of one such result, which is a problem we've seen in this class done better. Suppose you want to store a dynamic ordered set. This is the set interface. Dynamic in the sense that I have insert and delete, and ordered in the sense that I want to support find-next and find-previous. Exactly which subset of the set interface you choose influences what data structure you've
3963	seen. We've seen, for dynamic sets, you want to use hashing. If you don't care about find-next, if you just care about find, then hashing is great-- constant expected. You can prove stronger things about hashing. And we do in that class. But if you want dynamic and ordered, you cannot do constant time per operation. You can prove that, which is cool. What data structure have we seen that solves this problem pretty well? Set AVL trees, which solve everything in log n. So log n is one competitor. Yeah. I'm interested in the word RAM model, which is the only model we've seen in this class. This happens to work in a stronger model. And we can do better than log n in the following-- it will take me a while before I get better, but here's, at least, a different bound we can get-- log w. This is via a structure called van Emde Boas, who is a person. AVL is two people. van Emde Boas, I've actually met. Log w-- remember, w is our word size.
3964	So this is a bit of a weird running time. It's great if w is log n, then this is log log n. And we know w is at least log n, but it could be bigger. We don't really have a sense of how big w could get. Maybe it's even n. Maybe it's big-- and then these are the same. Maybe it's bigger than n, and then this is maybe worse. But for most ws, this is actually pretty good-- and indeed, optimal. But it's not strictly better, in any sense, yet. On the other hand, there's another data structure which runs in log n divided by log w. This is called fusion trees. This was invented around the time that cold fusion was in the news, and so they wanted data structures to represent. We can achieve this bound or we can achieve this bound. And this bound is good is if w is large. This band as good if w is small. You can always take the min of the two, whatever is better. And in
3965	particular, the min of those two things is at most-- I think it's square root log n over log log n. If you want to bound just in terms of n, then the crossover point between these two is this place. And so you're always, at most, this, which is quite a bit better than the log n of AVL. We've got a square root and we've got a slight thing in the denominator. Pretty tiny. But the big thing is the square root. And that's kind of cool. And it turns out, that's pretty much optimal. In terms of an n bound, this is optimal. The min of these two, in general, is roughly optimal up to log log terms. For fun, I threw up the actual formula for the right-bound, which is tight up to constant factors of matching upper and lower bounds, which we talk about. It's min of three things-- four things, including log of w over a divided by log of log w over a log of log n over a. That's the last term
3966	that I just read. This was messy. Surprisingly, that is the right answer for this very particular problem-- a very natural problem. AUDIENCE: What is a? ERIK DEMAINE: A is the log of the space you're using. So it's the address size. Good question. If you throw it-- so it depends. If you have a polynomial space data structure, then basically, these are optimal. And this is generalizing to beyond that. Maybe you have a little bit more than polynomial space. Cool. So that's data structures. I'm going to jump ahead to graph algorithms, which, if you want to take this class, I recommend a time travel device.
3967	It may never get taught again. But it has video, so you can watch-- instead of time traveling, if you don't want to watch it live, you can just watch the recorded version. It was taught by a bunch of postdocs that were here, and a bit myself. What I like to do with graphs is the world of planar graphs, or near-planar graphs. We've talked a lot about, this class, algorithms that work for arbitrary graphs. And the algorithms we've seen in this class are pretty much the best we know for a lot of problems for arbitrary graphs. But if your graph has some structure, like it's a road network and there aren't too many overpasses, you can usually draw these graphs in the plane without crossings. That's the meaning of planar. Maybe not exactly. Maybe just a few crossings. There's a generalization of this, which I won't get into. But let's just think about planar graphs. Planar graphs have some nice features, like they always have a linear number of edges. They're always sparse. So you can
3968	immediately plug that into our existing bounds. But even so, Dijkstra, in such a graph, would take v log v time. For planar graphs, you can do the equivalent of Dijkstra, meaning, I can compute single-source shortest paths with negative edge weights in linear time. No log. Not that impressive, but remove a log. More impressive is, we can do the equivalent of Bellman-Ford, which is a single-source shortest paths with arbitrary edge weights in a planar graph in some time-- almost linear time. The log squared v over log log v. So there's a couple of factors here-- but for almost linear time, whereas Bellman-Ford would take v squared time. So this is a huge improvement over what we've seen in the class. These are quite complicated algorithms, but they're covered in that class, if you're interested in them. Then the area I work in a lot is approximation algorithms for planar graphs. And let me just give you a fun flavor using something we know, which is breadth-first search. Breath-first search you can think of as building sort
3969	of rings around a single root node. And there's this general approach-- this was introduced by Baker in 1994, we've used for lots of different problems. We want to solve some NP-hard problem on a graph. So just run breadth-first search from an arbitrary vertex and decompose your graph into these layers. You could number them-- 0, 1, 2, 3. These are levels. And let's just, like, delete some of those layers. Let's say, let's delete every fourth layer. So maybe I delete this one. I delete all of the vertices in that layer. And then I delete all of the things in layer 8, and layer 12, and so on. Guessing-- I don't know which one to start with, but from-- I'll just try them all. And then I delete every fourth layer after that. So I've deleted, on average, about a quarter of the graph. And it turns out, for a lot of problems that you care about, like choosing where to place fire stations in this graph to minimize travel time for if there's a fire somewhere
3970	in the graph-- this happens, you know? Fires and graphs. Then this will only hurt your solution by, like, a factor of 1 plus a quarter. So you will get a solution that's within 25% of the optimal, for a lot of problems. And that works for any value 4. So I could do it for 10, and then I would get within 10% of the optimal solution. OK, but how do I actually solve the problem once I delete every fourth layer? Well, then your graph has this extra special structure, which is a constant number of layers, let's say. A constant number of breadth-first search layers. If you just look at this portion, this connected component, or this connected component in here, you can-- your graph is almost like a cycle. It's like four cycles stacked up together with some connections between them. And it turns out, that's something you can solve with very fancy dynamic programming, like the stuff we've seen in this class, which focuses on just a single path or a single cycle. If you
3971	just have a constant number of cycles, with more work, you can still do everything in polynomial time. This is a very general approach for getting arbitrarily good approximation algorithms. We call these 1 plus epsilon approximation for any epsilon. But the larger the epsilon, the more time you take. It's something like 2 to the order 1 over epsilon times polynomial n. So as long as epsilon is constant, this is polynomial time. This is called a PTAS. Anyway, that was graph algorithms. Last topic is recreational algorithms, which is maybe best encompassed by this class.
3972	It changes names every once in a while. And I mentioned it in the hardness complexity lecture, because this class is all about hardness proofs, analyzing fun games and puzzles. We saw the Tetris NP-hardness in that lecture. But you can also prove Super Mario Brothers is hard, or Portal is hard, or Mario Kart is hard, or The Witness, a modern video game, is hard. Or, one of our latest results is that Recurse-- that game in the top right-- is undecidable. There's no algorithm to play that game perfectly. And you can even download the level-- an example of the level and play it, if you dare. So that's a lot of-- we have a lot of fun in that world of hardness of different games and puzzles. Where do I want to go next? OK. Next topic is balloon twisting. Totally different. This is recreational, but not about hardness. This is an octahedron twisted from one balloon. I made another one on a stick. Each of these is made for one balloon. What graphs can you make
3973	for one balloon? Well, you should read our paper.
3974	need to make each polyhedron. And some of these problems are NP-hard, and it's a lot of fun. Cool. I think that's the end of the slides. The last thing I wanted to show you is a problem, a puzzle/magic trick-- it comes from the puzzle world-- called the picture hanging problem. So imagine you have a picture. You want to hang it on a wall. So you invested in some nice rope, and you hang it on a nail. If the nail falls out, the picture falls, and you're sad. So you invest in two nails, like I have here, and maybe you hang your picture on both those nails. Now, if one of the nails falls out, you still have a crookedly hung picture. If the other nail falls out, OK, it's gone. I want to hang a picture on two nails such that, if I remove either nail, the picture falls. So, Jason, pick a nail, left or right. Left, we remove. Make sure this doesn't fall off-- and, boom, the picture falls. Same wrapping. You can
3975	check-- you can rewind the video, make sure I did the same wrapping. JASON KU: And take out the right. ERIK DEMAINE: Then take out the right one. Good choice. Then, also, the picture falls. This is a classic puzzle, but you can generalize it. So let me do it for three nails, which is all I have here. This nail is sagging a little bit. y, x-- y inverse, x inverse. I think that's right. So this is one way to hang a picture on three nails such that, if I remove any of the nails, the picture falls. Justin, 1, 2, or 3? 2. OK. Yeah, I want to get out of the way and make sure I don't go over the edge here. Yeah. It's a lot easier to make this one work. But you can see, boom, picture falls there. And of course, imagine infinite gravity. And the picture falls. Ta-da! You can generalize this to do essentially any-- what's called a monotone Boolean function-- on any set of nails. I mean, you can make any
3976	subset of the nails cause the picture to fall and any collection of subsets of nails to make it fall. Of course, if you remove more nails, it's still going to fall. That's the monotone sense. But otherwise, you can do an arbitrary pattern, which is fun. That's actually a result with Ron Rivest and a bunch of other people. I think I'm approximately on time. So that was a quick tour. And there are obviously various classes here you can take. 6.892, the hardness class, was just offered last semester, so it probably won't be for a while. But all of these classes are online. Watch the videos, feel free to ask me questions. And now we have Justin. I left you space here for your outline. You don't have to, but I'll put your name. JUSTIN SOLOMON: Thank you. JASON KU: So Justin is also a geometer. ERIK DEMAINE: Yeah, we've got a lot of geometry people in 006 this semester. JUSTIN SOLOMON: Thank you. OK. I can't help but share that, on our instructor chat, Erik was
3977	texting that he was going to be-- he was somehow nervous that the applied guy would have all of the cool stuff to show off, and now I feel totally boring. [LAUGHING] Right. Yeah. We have three different geometry instructors in this class. In this class, I think we have many different flavors of geometry that are kind of represented in this room here, from mechanical engineering, to theory plus lots of other cool stuff, to whatever it is that I do. I'm a professor, also, in CSAIL, and lead a group that studies slightly more applied geometry problems, in some sense, and in CSAIL, we kind of cross a lot of boundaries-- actually, closer to the math department than to the theory group and computer science, which I would argue is largely a historical artifact rather than anything interesting about computer science or math. Continuing in our whirlwind tour of interesting geometry classes here at MIT, I have some more fun things to add to the list. And we'll introduce some of the ideas in the next couple of
3978	slides here.
3979	which is the introduction to computer graphics course. In fact, my background was working in an animation studio for a little bit of time, and got one movie credit out of it until they changed the standards for movie credits, and then that stopped happening. But in any event, if you watch-- what's that movie-- Up, with the old man. If you hit pause at just the right moment, you can find me right above the list of babies that were born during production. But in any event-- although computer graphics might not sound like an algorithmic discipline, I'll try to convince you guys that, in some sense, you could take just about anybody in our department, have them teach 6.006, and give a similar talk that, like, the material that you've encountered in this course is going to be relevant to your life. The other course that I teach that might be of interest-- and actually, is a little more theoretically flavored-- that I teach is 6.838. So since Erik so kindly put my name on the board here,
3980	I guess I can draw The So the main object of interest in 6.838 is a particular thing called the simplicial complex. Usually, in 6.006, we spend a lot of time thinking about graphs. Let me draw you a graph. So I'm going to take a square and subdivide it. And now, let's say I put edges diagonally like that. Now, in 6.006, this thing is just a bunch of nodes connected by edges. In fact, if I took this edge and I moved it down or something, it would be the same graph. But of course, in a lot of computer graphics applications, this thing also looks an awful lot like a square. And the reason is that, of course, the graph here contains triangles inside of it. And so for instance, maybe I think of my graph as a collection of vertices, a collection of edges. This is the sort of notation we've seen before. And then I add a third thing to my description, which is a set of triplets. That's a set of triangles here. And
3981	we can take a lot of the algorithms that we've talked about in this class and extend it to this case. For example, here's a deceptively annoying one. Let's say that I want the shortest path between two vertices of my graph. We certainly have learned Dijkstra's algorithm. That's one technique to do that. And indeed, common practice in computer graphics, which is shameful, is on your triangle mesh, if you want the shortest path between two vertices, run Dijkstra's algorithm on the edges. And let's see if that works really quick. Let's say that I want the shortest path between-- and, by the way, I'm going to assume the length of my edges are the lengths as I've drawn them on the board here. So it's like 1, 1, square root of 2. OK. So let's say I want the shortest path between the bottom left and the upper right. If I run Dijkstra's algorithm, we're in good shape, right? We get-- I'll let you do the computations at home. You'll get the path that is these two edges.
3982	But here's a really annoying thing. Let's say, instead, I wanted the shortest path from the upper left to the lower right. If I run Dijkstra's algorithm on this triangulated square, what's going to be the shortest path? Yeah. In fact, there's a bunch of them. One of them might go all the way down, and then all the way to the right. What's the length of this path? 1, 2, 3, 4. Is that the length of the shortest path? Well, probably not. Well, we would like our shortest path to do something like that. But graphs don't know how to talk to triangles. And this is going to be a problem. In fact, it wasn't until fairly recently [INAUDIBLE] history terms that we were able to kind of work out the correct algorithm for the shortest path in a triangulated domain like this. And that's the runtime that we would expect. This is called MMP. I'm guessing Erik and Jason could do a better job describing it than I can. But the basic idea of the MMP algorithm
3983	actually is a really-- happens to be a nice extension of the way that we taught Dijkstra's algorithm in 6.006, because they really do keep track of these level sets of the distance function. But now, the level sets have to-- oops-- have to window and edge like that when I compute shortest path, which is a giant headache. This is one of these algorithms that was known in theory about 10 years before anybody bothered to implement it in a way that they could convince themselves it ran in n log n time. And nowadays, there's a cottage industry in computer graphics research papers to implement this and then speed it up in different ways. And sadly, the reality is that a different algorithm that we cover in 6.838 called fast marching-- which doesn't actually give you the shortest path, but some approximation thereof-- is faster, easier to use, and basically indistinguishable. In any event, in 6.838, we kind of have an interesting dual-mindset. We'll talk about a lot of algorithms that look like what we've done in whatever
3984	this class is-- 6.006. But at the same time, start to have a more geometric flavor, and we don't worry quite as much about [INAUDIBLE].. So in our computation model, oftentimes, we're kind of OK with real numbers, because that's not where the headache is. And of course, when you write code in this class, you use double-precision floating-point. If you're more responsible, like in Jason's previous lecture, you should probably keep track of the number of operations to make sure that your error is counted. But I'm not sure that we really bother with that. In any event, this allows us to have two different mindsets. There's one mindset, which is discrete. There's another mindset, which is smooth. We think about understanding geometry, like these triangular domains, as an approximation of a smooth surface. And then we might want to do stuff like compute curvature and so on, which is really associated with computing derivatives, which of course, we'll have on these kinds of simplicial objects. And that leads to this really fun area of math and computer science,
3985	whatever, called discrete differential geometry, which sounds like a contradiction in terms. And it's something that we covered in quite some detail in this course. So we build up, all of calculus, that the only calculations you're left to do are on the vertices and edges and triangles of a triangle mesh. And get pretty far, including some constructions of topology, like the Duran complex, and so on. I would argue, actually, if you take our course and then the differential geometry courses in that department, somehow, some of the indices and headaches that you often encounter in that world are much more concrete when you try to make them work on a mesh. In any event, I think I've already spent all of my time.
3986	I really lead kind of a weird, extremely [INAUDIBLE] group, where some of our students are essentially theory students-- touch your keyboard. I'm sorry. It was a reflex. But it was fast. All right. So we have some students whose background is in math, other ones that we're in autonomous driving industry and decided to come back and work in research. Because of that, we have this extremely broad set of research problems, everything from the sort of classic machine learning problems you might encounter in geometry world-- like if I have a self-driving car and I want to identify pedestrians and other cars on the road in an efficient and accurate fashion. By the way, part of that is machine learning and deep whatever, but there's another part, which is algorithms. Because actually, what comes into your LiDAR scanner is on the order of [INAUDIBLE] with points and some minuscule fraction of time. And time complexity of your learning algorithm actually is really critical to get it right, and something that there are a lot of open problems right
3987	now, because it's really not compatible with the hardware architecture that these cars often use. We also look at [INAUDIBLE] geometry problems, like if I give you data, can I find a geometric structure? So it's a classic example of natural language processing. When we use words like near and far, in terms of semantics and meaning, all the time. The question is, can we actually find an embedded of our word data into a geometric space to facilitate the statistical algorithms that we care about? And of course, we apply geometry to lots of practical problems, everything from meshing and scientific computing, which I think is sort of a classic one-- in fact, I think we're the first group that sort of enumerated all of the cool things that may happen to decahedral meshes, which is this bottom figure here. I should show this to people. There's some fun things to look at there. To other practical problems, like taking-- Erik took a zebra and folded it. We can take a zebra and move its texture onto a cat
3988	or a pig-- or, actually, off the side of the screen. But if we don't move the paper, [INAUDIBLE] for the 3D scan of what it might [INAUDIBLE]. In any event, in my five minutes remaining here, I thought I would dig into a little bit of detail of two-- or maybe one application, depending on when Jason and Erik get bored. And essentially, my message for you guys is, of course, [INAUDIBLE]. I'm not really a central CS theory group member here at MIT. But unfortunately for you guys, 6.006 is unavoidable. Even if you want to go into deep learning, statistics, whatever-- data science-- you're going to encounter the material that you've seen in this course. And in fact, it's really the bread and butter of just about everything everybody does here in this Data Center. So then, I'll give you two quick examples, one of which
3989	If you continue with me next fall, we'll teach 6.837, which is the Intro to Computer Graphics course. One thing that's always amazing to students is, these, algorithms that produce these really beautiful images, can fit in about 10, 20 lines of code. So really, this is totally facetious, because if you want those beautiful images and you use those 20 lines of code, you'll be waiting until the death of the universe to actually compute these things. But in any event, one nice one for rendering-- so drawing a bunch of shapes [INAUDIBLE],, something called ray casting, or its better known cousin, ray tracing. Typically, the difference is whether your rays can bounce off of the surface and have a secondary thing. Right. Here's the ray casting algorithm. Let's say I have a scene built out of spheres and cubes. I'm going to have a for loop over every pixel on the computer screen. For every pixel, I've got to discover what color that should be. So I shoot a ray from my eyeball through that pixel and find
3990	the first object that it runs into. It's not so hard to intersect a line of a sphere or a line of a cube. So what is that algorithm? I've given it to you on the screen here. Not too bad to think about. And I think you guys are all extremely well equipped to analyze the runtime of this, which is roughly the number of pixels times the number of objects. Because for every pixel, I've got to decide what object the ray out of my eyeball hits first. So I need a for loop over [INAUDIBLE].. Make sense? Cool. So let's look at a basic rendering problem.
3991	There's a very famous 3D model called the Stanford bunny. The Stanford bunny is actually a great example of a simplicial complex-- in fact, a manifold one, triangulated surface. Actually, I'm not sure it's manifold in its original form. But usually, it is. And this innocent-looking, extremely famous 3D model is actually quite pernicious. It's composed of 69,000 triangles. And if I wanted 1080p-- like a high def rendering of my triangle-- then, of course, there's two million pixels on the screen. So if we look at our big O expression, roughly, our computation time scales like the product of those two big numbers. So just to render this ugly gray bunny takes me a pretty large amount of time. And in fact, the reality-- by the way, the bunny is this famous test case in computer graphics, so if you take my class, you'll be rendering buddies all day. The reality is, we don't want just grayed, flat-shaded bunnies. We want bunnies that are transparent, and reflecting stuff, and I shoot my bunny with a bullet and shatters into
3992	a million pieces, and all of these cool things. So of course that, ray casting algorithm, with each one of these new graphics features I add, only adds to the time complexity of the technique that I implement. So pretty quickly-- and indeed, if you write your own ray tracer at home, which I strongly encourage you to do-- what you will discover is that a [INAUDIBLE] would be the technical phrase. What is our way out of this?
3993	that our way out of these problems, in graphics, is data structures and algorithms. It's completely unavoidable. For instance, obviously, we spent quite a bit of time in this course talking about AVL trees. In 837, we'll spend a big chunk of our tours talking about space partitioning trees. Here-- I actually forgot what kind of tree this is. I think it's a KD tree. Doesn't matter. In any event, one thing I could do is take all of the triangles of my bunny, and I could put the entire bunny in a giant cube with the property that the cube is outside the bunny. Let's say I cast a ray and the ray doesn't touch the cube. Can the ray touch the bunny? No, right? It zings right past it. So suddenly, I just saved myself a lot of computation time, right? I don't have to iterate over all the triangles inside of the body to see whether they hit the ray or not, because I already convinced myself, by this conservative test, that I didn't hit even the
3994	bounding box of the whole bunny. Well, that's sort of a nice order 1 speed-up. But depending on how big the bunny is relative to the size of my rendered image, that might not be a super useful efficiency test. But of course, what could I do? I could take the box containing the bunny, I could slice it in half, and now it's saying, does my ray hit the front or the back of the bunny? Or maybe both. That's where you've got to-- that's where things get gnarly. And so on. So now you have this nice recursive tree structure, where I keep taking the box containing my bunny and chopping it in half and placing-- in some sense, usually, the triangles-- maybe not the leaves of my tree, but [INAUDIBLE] that's probably good enough. You get a structure like what you see on the screen here. And why should you do that? Well, remember, it takes pn time to render my image of my bunny normally. Well, now, the picture is actually misleadingly suggestive. But you might
3995	think that, maybe, it takes roughly-- remember, n is the number of objects in my scene-- p log n time to render my bunny now, because I can kind of traverse the tree of objects in my scene. Of course, notice, I put a question mark here. And the devil's in the details here. In fact, I think computer graphics people often believe that their rendering algorithm takes p log n time. That's often not possible, although kind of an interesting question, which is, the heuristics they use for building these sorts of trees often do, on average, give them log n time. And so there's something about the data that's making this problem easier than it might seem. So we'll dig into that a little bit in the graphics class. Of course, you're not going to proof as many bounds as you might in a theory course. But we're certainly building on the intuition that we've seen in this class to build on practical data structures. And these data structures appear everywhere in computer graphics. For instance, directed acyclic
3996	graphs appear all over the place in computer graphics literature to describe 3D scenes. For example, this classroom is a stark reminder of why we need DAGs and computer graphics, because we have all of these empty seats here, and they're all copies of one another. So would it make sense for me to store however many, like, 100 3D molds of the same chair? Probably not. So instead, what do I do? I store one instance of a chair, and then some instructions on how to tile it into my entire scene. One way that I can do that is to think of there being a node in a graph which knows how to draw one chair. And now, I can have a bunch of different nodes in my scene for all of the instances of the chair and then store a different transformation for each one. So if you think about the graph structure here, each of those ones is going to point into the same 3D model of the chair for rendering. And that makes a directed
3997	acyclic graph structure called a scene graph, which we'll spend quite a bit of time talking about in 837, how to traverse and construct all that good stuff. And there are lots of different models of computation in that universe, as well. Your graphics card is a very specific kind of parallel processor that's kind of like Lucille Ball on the conveyor belt, hammering at the same object over and over again. But if you ask it to do anything other than the one thing it knows how to do to a bunch of data at a time, then all of your computation grinds to a halt. This is called Single Instruction Multiple Data parallelism, SIMD. Numerical algorithms matter a lot for things like fluid simulation. And approximation algorithms are quite critical, too. In computer graphics, the complexity is kind of interesting, because of course, your eyeball is sensitive to about 29.97 frames per second worth of material. You can choose that time to do really well-rendering one object, but then you take out of the time rendering something else.
3998	There's kind of an interesting conservation law that you have to balance when you solve these kinds of problems, which is an interesting balance, now, between complexity and runtime of your algorithm and perception. What things can you get away with when you draw a scene? And maybe I can do tons of extra computation to get that extra shadow, but it's just not worth it. I'll quickly sketch out another completely different application of the material that we've covered in 6.006 from my own research. Again, just like Erik-- I guess, in a funny way, both of our groups, I think, are kind of broad in terms of subject material, rather than-- some of our colleagues have really laser focus on one topic or another. Another Research area that I have sort of backed into is the area of political redistricting. This is relevant in the United States. Recently, I've been reading this great proposal about other countries, which is really interesting, how they do this stuff. In the US, when we vote for people in Congress-- by the
3999	way, not necessarily for presidents. This is a common misconception. But certainly for Congress, your state is divided into little regions, each of which elects one member of the House. And there's sort of a subtle problem if you're not used to thinking about it, or one that's staring you in the face and screaming, depending on how often you read the news and politics. There is an issue called gerrymandering, where your legislature draws the lines for what area on the map elects a member of Congress. And depending on how you draw the lines, you can engineer different results for who's likely to get elected. So for instance, maybe there's some minority. I can cluster them all together into one voting district. Then they will only get the opportunity to elect one person. But maybe, if I divide the space where they live into two, I managed to engineer two districts with a high probability of electing somebody with their political interests in mind. It turns out that political redistricting, in a broad sense, is a great problem,
4000	computationally. Even if you're a totally heartless theorist, there are some really fun problems here. So for example, the state of Iowa-- we all pick on Iowa because it has a unique law, which is that districts have to be built out of counties, which are much larger than the typical census unit, so it computationally is easier. But even in Iowa, which is a giant grid-- with the exception of one shift in the middle, which is fascinating to me-- I know [INAUDIBLE], fun fact. Literally, people were making the map of Iowa, and they worked from the bottom up and the top down, and it meets in the middle and their grids were shifted, and now we're stuck with that. And it has an interesting effect on the topology of the graph, because it looks like squares, but then there's triangles in the middle. But in any event, even though there's only 99 counties in four districts, there's approximately quintillions of possible ways you can divide that state into four contiguous districts that satisfy the rules as they
4001	"were-- at least, if you read the code literally in the law. It seems like computers are useful, but unfortunately, it's a little subtle how. For instance, there's no single ""best"" districting plan out there. I can't think of a single state with a law that gives you an objective function, similar to whatever cute characters that we've had in 6.006. They often have very clear objectives in life, but unfortunately, redistricting, that's very rarely the case. You have to balance contiguity, population balance, compactness, all of these different things. Reality check number two is that, even if somebody did give you an objective function, for just about any interesting objective function, it's very obvious that generating the best possible districting plan is NP-hard. And by the way, it doesn't even matter, because the law doesn't say that computers have to draw the best districts. Even if P equals NP really could extract the best possible districting plan using an algorithm, it doesn't mean you have to use it, at least the way the law's written now. Interestingly, this is"
4002	not true in certain parts of Mexico, where they actually make you compare your districting plan against a computer-generated one, which is philosophically really interesting, although in practice, it doesn't work terribly well. Our researchers studied analysis of districting plans instead. So instead of running a piece of software that takes in your state, draws your districts, and then you're done-- instead, we ask statistical questions about, I propose a districting plan, what does it look like relative to the space of the possibilities? So that, of course, begs the question, what are the possibilities? So these are the connected graph partitions. Meaning, you have a graph, and you take the vertices and you cluster them together in a way where they're connected to one another. The one thing that we all agree on-- actually, philosophically, it's questionable why-- is that you should be able to start at any point in your district and walk to any other one without leaving. These days, with the internet, it's not clear that that's actually the best criterion. But that's a law that,
4003	I think, is never going to get passed in the near future. Anyway, I think I'm out of time, so I don't think I'll walk you guys through the theory here. Maybe I'll leave it in the slides. There's a sort of very simple proof that can show that, at least the very simplest thing you might think of for analyzing your districting plan, which is to say, you propose a plan, and now, I want your plan to be at least as good, under some axis, as it's a randomly drawn one from the space of all possible connected partitions-- all of the possible ways I could draw the lines. Well, then, it might be useful to have a piece of software that could just randomly draw such a thing. So in other words, to draw something where the probability of any one partition is 1 over the number of partitions. This seems innocent. In fact, there's a number of papers that claim to do things like this. But it turns out that it's computationally difficult, assuming that you
4004	believe that P doesn't equal NP. So I'll maybe leave some suggestive pictures in the slide that we can-- if you guys text me, or if we have a professor-student chat, I'm happy to sketch it out to you then. There's a very nice, easy proof that reduces this to Hamiltonian cycle, and shows you that maybe you shouldn't trust these tools, as much as they're argued about, literally, in the Supreme Court a couple of months ago. By the way, it was pretty fun. Our expert report was referenced in the defense of the case last summer. And when you read the discussion, you can see the judges trying to talk their way around complexity. And it's an interesting, if somewhat dry, read. In any event, that's just the starting point for our research, which says that, of course, these sampling problems are really hard. The questions is, what can you do?
4005	But the real message here is, of course, that this course is unavoidable. Even in these extremely applied problems showing up in court cases or on your graphics card, you still-- complexity and algorithms and data structures are going to come back to play. So with that, our other two instructors up here for our final farewell-- suitably distance ourselves. ERIK DEMAINE: So algorithms are everywhere. I hope you enjoyed this class. It's been a lot of fun teaching you and having you as students. Even though you're not here physically in the room, we still feel your presence. And I look forward to seeing you all soon. Thanks for being a part of this fun thing. I want to thank our two-- my two co-instructors for an awesome time this semester. It's been a lot of fun teaching to you guys. JASON KU: Thanks for spending 006 with us this term. JUSTIN SOLOMON: Yeah. Thank you. And hopefully we'll see you again soon. ERIK DEMAINE: Bye. JASON KU: Bye.
4006	[SQUEAKING][RUSTLING][CLICKING] JASON KU: Welcome, everybody, to our lecture 14 of 6.006. This is our last lecture on graph algorithms, in particular, the last lecture we'll have on weighted shortest paths. But we're going to talk about a slightly different problem today, different than single source shortest paths. We're going to be talking about all-pairs shortest paths. But first, let's review our single source shortest paths algorithms. We had BFS, DAG relaxation, Dijkstra, which we saw last time, which gets pretty close to linear. V log V plus E is pretty close to linear. It's much closer to linear than the general algorithm we have for solving single source shortest paths, namely, Bellman-Ford, which is a little bit more like quadratic. This is like the difference between-- for sparse graphs, this is like the difference between sorting, using insertion sort and n squared, and merge sort in N log N, for example. We're going to get actually quite a big bonus for large input sizes by using Dijkstra when we can. Today, we're going to be focusing
4007	It's not really complicated. Instead of having a single source, we are essentially wanting to, given an input-- this is our weighted graph, where we've got a graph V, E, and we've got a weight function from the edges to the integers. This is our general weighted graph. We want our output to be something like, the shortest path distance from u to v for every u and v in our vortex set. That's what we want to return. Now, there's one caveat here that, if there's a negative weight cycle in our graph-- in other words, if any of these delta u, v's is minus infinity,
4008	So unless, I guess-- or abort if G contains a negative weight cycle. So we're not actually going to worry about negative weight cycles in today's class. If we have a graph, it could have negative weights. These are any integers. It could include negative weight edges. But as long as all of our path distances are bounded from below, none of them are negative infinity, we don't have any negative weight cycles, then I want you to output all of these shortest path distances. Now, in particular, this output could-- any of these outputs needs to have size theta of V squared. Because for every pair of vertices, I need to return to you a number, or infinity, or minus infinity or something like that. But we are not dealing with a case with minus infinity. The output could have size-- this is a theta here. It does have size V squared. But in particular, it's at least V squared because I need to give a number for each pair of vertices. And so we couldn't hope for linear
4009	time in the size of this graph for this problem, right? Single source shortest paths, for certain versions of the problem, we need to read the graph. And so we need to use linear time. But in this problem, our output has quadratic size in the number of vertices. So in a sense, we can't do better than this. We can't do better than quadratic. And actually, what's one way we could solve all-pairs shortest paths by using stuff we've already done in this class? That's why I put this slide up here. Yeah, we could just solve a single source shortest paths algorithm from every vertex in my graph. That seems like a stupid thing to do. It's almost brute force on the vertices. But it's certainly a way we could solve this problem, in polynomial time. And we could definitely solve it in order V squared E time, using Bellman-Ford. We just take V steps of Bellman-Ford and deal with a graph on any set of vertices. We can do better than this. We can do better than
4010	this for graphs that are special in some way. We can do V times V plus E, V times linear. If our weights are positive and bounded, we can use BFS V times. Or if our graph doesn't have cycles, we could use DAG relaxation V times. Or if our graph had non-negative edge weights, we could get, basically, V squared log V plus V times E. And that's actually not bad. In sparse graphs, this is what Bellman-Ford would give us. But if we had Dijkstra's, for example, if we had all positive edge weights-- or non-negative, sorry, we could get V squared log V plus V, E time. This is V times Dijkstra. OK, so how do these running times compare? This is V times Bellman-Ford. This is V times Dijkstra. Let's just get a feel for this separation here. If we had a sparse graph where V is upper-bounded by the number of vertices, this one looks like V squared log V. This one looks like V cubed. And we need to spend at least V squared
4011	time. So actually, this is really close to linear in the size of the graph, just off by a log factor, just like sorting would entail. And this one would have a linear factor. In the sparse graph, this would be a linear factor worse than this, instead of a logarithmic factor-- again, this linear to log separation. We don't want to have to do this running time if we don't have to. That's the name of the game. And really, all we're going to do in this lecture is try to solve how we can make this running time faster by doing something a little bit more intelligent than running a single source shortest path algorithm from every vertex. How are we going to do that? Well, we could-- let's see. What are we doing? Right. The idea here, if we had a graph-- should my graph be directed or undirected? I'm not sure. Let's see if we can make a directed graph. OK, so here's a directed graph. Why do I not care about undirected graphs? Can anyone
4012	tell me? Yeah, it's because-- I don't care about undirected graphs because, if I had an undirected graph, I could detect whether I had negative weight cycles in constant time-- I'm sorry, in linear time. I could just check each edge, see if it has negative weight, because a negative weight edge, an undirected edge is a cycle of negative weight. So I could just-- if it has any negative edge weights, I could return in linear time that it does, and I can abort. Or it has only positive weights, and I can still use Dijkstra. So that's all good. So we're only concerned about needing to run Bellman-Ford on directed graphs that potentially have negative edge weight. OK, so here's a graph. Let's see. Is this a graph that I want? Sure. Let's say we've got that direction and this direction. Say we have a directed graph like this. And let's say this is s. This is our source. And we have weights being 2-- sorry, weights being 4, 1, 1, 2, 2, 2, 2. So this is
4013	an example of a graph we might want to run all-pairs shortest paths on. Maybe we also have negative weights in this graph. In particular, this has a negative weight cycle. I don't want negative weight cycles, so I'm going to make this 0. So this graph doesn't have negative weight cycles. Great. That's true, great. All right, so here's an example that we might want to compute shortest paths on. There's no s in all-pairs shortest paths. But I'm going to be talking about a couple of shortest paths from s in my next argument, so I'm just labeling that vertex as s. OK, the claim-- the approach we're going to do, we're going to try to take a graph that has negative edge weights, directed graph. We don't know if it has negative cycles or not yet. But we want to compute all-pairs shortest paths, not in this running time, but in this running time. How could we do that? Well, maybe it's possible that we can change the weight of every edge so that they're all positive,
4014	but shortest paths are preserved. So basically, if a particular path-- like OK, the shortest path from s to t here is 1, 2, 3. I could change edge weights in this graph. Say, for example, if I changed 1 to 0 here, that would still make this a shortest path. I haven't done-- I've reweighted the graph. Shortest paths have to be the same in this graph. But now-- sorry. Yeah, this is not a shortest path. OK, I'll make that minus 2, and then these both 2, and I think this 4. Man, I really should have done my example beforehand. OK, so this still doesn't have negative weight cycles. It has a negative weight edge. But this path is longer than this path. So when this was 1, this had length of 3, which was shorter than this path. That is length 4. OK, cool. So this is the shortest path from s to t. I could change weights in this graph,
4015	That changed weights in my graph, but shortest paths remain the same. So maybe there's a way I could reweight my edges so that shortest paths stay the same, shortest paths are preserved. So I'm going to put this back to where it was. So idea-- make edge weights non-negative while preserving shortest paths. In other words, just reweight the edges here so that shortest paths in G-- this is G-- after we reweight will go to some graph G prime, with the same combinatorial structure just different edge weights. And we want shortest paths-- we want these weights to all be non-negative. And we want shortest paths, if there's a shortest path in G, it continues to be a shortest path in the reweighted graph. That's the goal for today. If we can do that transformation and this is not negative, then we're done. We're done because we can just run Dijkstra V times on that new graph, get the shortest path distances, construct a shortest path tree from those distances, and then traverse that tree in the original
4016	graph, and compute shortest paths along that tree. So that's the claim. Claim-- we can compute distances in G-- so we're going to restrict G prime to have with non-negative edge weights. If we have such a G prime with non-negative edge weights, we can compute distances in G from distances in G prime in V times V plus E, which is smaller than our Dijkstra running time. This is our Dijkstra running time. And this is smaller than that. So that would be fine, right? What do we do? We have our new graph G prime. It has all positive edge weights, so we run all-pairs shortest paths in here by just running Dijkstra V times. And then for each vertex s, we have some shortest path tree to all the things that it's connected to. We can look at that path in G. This is the same common [INAUDIBLE] graph, just with different edge weights. We can look at that same tree. I'm not going to be able to draw the exact same tree here. But what I
4017	can do is I can just BFS or DFS along this tree. And every time I have an edge, because each one of these is the shortest path in this tree, I can just compute every time I traverse an edge what its shortest path distance is in G in linear time for that vertex for that particular s. I do that over all s's, and I get this running time. So that's the goal here. All right, so we first wanted to find-- we were wanting to make edge weights non-negative while preserving shortest paths. Because if we could do that, we could solve our original all-pairs shortest paths problem. So this is the proof sketch. But how can we do this? But how? It doesn't even seem like this could be possible, generally. How can I just reweight the edges and maintain that the shortest path trees are the same? That seems hard to do. And in particular, if there's a negative weight cycle in this graph, it's impossible to do. So claim-- not possible if G contains
4018	a negative weight cycle. OK, the exclamation point is just my comment here. So if G contains a negative weight cycle, then in particular, the shortest path distance or a shortest path in G-- if this is G, say we have a negative weight cycle directed cycle C here. In particular, the shortest path from this vertex on the cycle to this vertex on the cycle, what is its shortest path? It's infinite. A shortest path is infinite around this cycle. You just keep going around the cycle over and over and over again because it has a negative weight. Weight of C is less than 0, strictly. That's what a negative weight cycle is. OK, so the shortest path-- a shortest path from s to t has infinite length and, in particular, is non-simple. However-- so shortest path from s to t is non-simple. But as we proved in the last lecture, shortest paths in a graph with non-negative weights are what? Are simple, right? Because they're just shortest path trees. So that's a contradiction. So this is not
4019	possible. So given a graph with negative weights but no negative cycle, it's still not clear how we could find such a reweighting of the graph. Can we do this? Well, we're going to exploit a little idea here. How can we transform the weights of a path? Well, how-- what's a-- a silly idea, I have this silly idea. If I don't want negative edge weights in this graph-- ugh, this is messy in the back. You got edge weights 1, minus 2, 0, 1, 4, 5, and 1. There's only one negative edge weight here. What if I just added a large number, or in particular, the negative of the smallest edge in my graph to every edge in my graph? Then I'll have a graph with non-negative weights. Fantastic. Why is that not a good idea? Well, in particular, if I did that to this graph, if I added 2 to every edge, the weight of this path, which was the shortest path, changed from weight 3 to weight 9, because I added 2 for every edge.
4020	But this path, which wasn't a shortest path in the original graph-- it had weight 4-- increased only by 2. Now that is a shortest path. Or it's a shorter path than this one, so this one can't be a shortest path. So that transformation, sure, would make all the weights non-negative, but would not preserve shortest paths. In particular, if I added the same edge weight to every edge, I will bias toward taking paths that have fewer edges, not just smaller weight. So that first idea doesn't work. Idea-- add large number to each edge. This is bad. Makes weights non-negative, but does not preserve shortest paths. So this is not a good idea-- bad idea. Is there any way you can think of to modify the edge weights in a graph in any way that will preserve shortest paths? So here is an idea for you, which is kind of this critical step in Johnson's and in a lot of graph transformation algorithms. If I have a vertex, say this middle guy, say v, every path from
4021	v goes through an outgoing edge of v. And every path going into v goes through an edge going into v. I haven't said anything-- I've said very stupid things. But that observation is critical here. If I add a number-- or let me see if I got this right in terms of adding and subtracting. If I add a number to all outgoing edges from a vertex, and I subtract that same number from the weights of all of the incoming edges to that vertex, then every path from v is changed by the same amount, because every path from v goes through one of those outgoing edges. And any path going into v has also changed by the same amount. In particular, it's changed by a negative, whatever we added to the outgoing edges. So such a transformation, adding a number from all the outgoing edges from a vertex and subtracting that same number from all the incoming edges, preserves shortest paths. That's a claim. Idea-- this is a better idea. Given vertex v, add-- I'm going to
4022	put this on two lines. Add weight h to all outgoing edges, and subtract weight to all incoming edges. So that's the idea. And the claim is, this transformation, shortest paths are preserved under this transformation.
4023	It's kind of the exact same argument that I had over there. Proof-- consider any path in my graph, either if the path-- path could go through v many times, or it could go through not at all. If my path, if I have a path, in my original graph G, then with path weight w of pi-- this is my path-- it goes through v some number of times. So I'm going to say this is going from s to t. If it crosses v-- if it never crosses v, if it never touches v, the vertex that I transformed, then I argue that the path weight is the same because I didn't do anything to edges that are in this path. Alternatively, this thing goes through v sometimes. If it goes through v in the middle, how is the weight of my path changed? Well, it hasn't, because I added a number to all outgoing edges, so there's an outgoing edge here with weight I've changed by weight h. And there's an incoming edge here that I've changed
4024	by weight negative h. So these cancel out and you've got 0. So passing through a vertex doesn't change the weight of my path. The only way I could change the weight of my path is if v is the start vertex or the end vertex. So it's possible that s is my vertex or t is my vertex. Well, for any path leaving v, I will have increased the weight of that path by h, because I added a weight h to all outgoing edges. So again, while the path weight has changed, since all of the paths leaving v have changed by the same amount, a shortest path will still be a shortest path. And same goes for t. If t, the end vertex is v, I'll have subtracted h from all of my incoming edges, which means that any path ending at t, any directed path ending at t, also changes by the same value. And so shortest paths must be preserved. So shortest paths preserved. So that's pretty cool transformation. I can assign for any vertex
4025	such a transformation which affects all of the edges surrounding it by this h additive factor, either added or subtracted. So maybe-- and I can do this independently for every vertex. The shortest paths were preserved by me doing this to one vertex. Then if I do it to another vertex, then shortest paths are still preserved. And let's prove that real quick. What I'm going to do is I'm going to want to do this to give me flexibility for changing all the edge weights in my graph to have this property. I'm going to set-- or define a potential function h that maps vertices to integers. So this is the potential h of v. And then we're going to make a graph, G prime based on above transformation for each vertex in v. So I'm going to set a number, an h for each vertex. These are independent now. And I'm going to add that potential to all outgoing edges. And I'm going to subtract that potential from all incoming edges. This transformation is going to preserve shortest
4026	paths. Let's actually be a little bit more rigorous that that's the case when we do this multiple times. So claim-- shortest paths are still preserved. All right, well, that's, again, not so difficult to see. Let's consider a path from s to t. It passes through a bunch of vertices. I'm going to label these as v0 to vk so that I can kind of number them. All right, this is v1 here. This is a directed path, v1, 2, 3, 4, all the way up to k. There are k edges in this graph. I claim to you that any path from v0 to vk, any shortest path from v0 to vk remains a shortest path after I reweight everything in this way. So let's say this is path pi, and so it has weight w pi, which is really just the sum of all of the edge weights from vi minus 1 to vi, for i equals 1 to k. This is poor notation. This is the weight of the edge from the vi minus 1 to
4027	i. And we've got-- it indexes from 1-- that's the first edge-- to k, which is the last edge. So that's the weight of my path. The weight of my transformed path-- I'm going to do it down here. It's a little iffy. The weight of my transformed path I'm going to say is the weight in this new weighted graph G prime. This weight of that same path-- it's the same path-- is just going to be the sum of all of the reweighted edges. So i equals 1 to k of my original weight of my edge, so from 0, i minus 1 to vi. But what did I do? This edge is outgoing from vi minus 1. So it's outgoing, so I add that weight-- that potential, sorry. But that edge is also incoming into vi. So when I reweighted the thing, I got a subtraction of h, vi. Now, what happens here in the sum, this term, if I just took the sum over this term, that's exactly my original pathway. So that's good. But you'll
4028	notice that this sum has k terms, and this sum has the subtraction of k other terms. But most of these terms are equal. Along the path, all the incoming and outgoing edges cancel out. So we're left with only adding the potential at the starting vertex and subtracting the potential at the final vertex. So we've got, add h, v0 minus h, vk. And why is that good? Well, that's good because every path from v0 to vk starts at v0 and ends at vk. That's just-- that's how it is. That's how we've defined paths going from v0 to vk. But every such path, we transform the weight of that path by adding a constant associated with the start and adding this value associated with the end. And so every path going from v0 to vk changes by the same amount. And so if this path pi was shortest, it's still shortest in the reweighted graph because I've just changed all paths between those two vertices by the same amount. This is kind of like a telescoping argument
4029	here in that kind of proof. Right. So we have, the weight changes. It could change, but it changes all paths between these two vertices by the same amount, which means that shortest paths are still shortest. Awesome. OK, so the name of the game here is now, we have this really flexible tool. We have this tool where we can add or subtract weight from various edges. But we have to do so in a kind of localized, constrained way. We have to do the same thing around each vertex. But it seems like a powerful transformation technique that maybe we can get this thing that we want, which is a G prime, a reweighting of the graph where all the edge weights are positive or non-negative. So does there exist an h such that the weights are all positive? What does that mean? w prime u, v, the weight in my new graph, in G prime, I want these modified weights, this modified weight of my graph, I want each of these to be non-negative. So does there
4030	exist such a thing? Huh. Well, if I rearrange this equation a little bit, this side, I get something that looks like this. h of v needs to be less than or equal to h of u, plus the weight of some edge from u to v. What does that look like? That looks like almost exactly the definition of the triangle inequality. Shortest path from some vertex here and its shortest path distance from the same vertex here, this is just a statement of the triangle inequality. So if we can set these h's to be the shortest path distance from some vertex and those shortest path distances are finite, and not minus infinity, then this thing will hold by triangle inequality. And in particular, if we were to reweight the edges based on those values of h, then we get new edge rates that are non-negative. Awesome. OK. But there might not be any vertex from which we can access, which we can reach all vertices in the graph. In particular, my graph might not even be connected.
4031	If I want this property, I need all of these-- I don't gain any information if these things are infinite. It's exhaustively true. Infinity is-- I don't even know how to compare infinity and infinity plus a constant. I don't know. So I need all of these things to be finite. So how can I make those things finite? So here's the next idea. Add new vertex s with 0-weight edge to every vertex, V in V. We take our original graph. We add a new super node or auxiliary vertex s, with a 0-weight edge to every vertex in my graph. What does that look like? This is like-- there's my original graph, and now I have this vertex s. But it has directed edges into all of the vertices with 0-weight. That's our picture. And this new thing I'm going to call, maybe, my s graph now. And the claim is, well now, if I run some shortest path algorithm, single source shortest path algorithm this time, from s to compute the shortest path distance to all of
4032	the vertices, the shortest distance to each of the vertices can't be positive, because there's a 0-weight edge. So a minimum weight path is going to be no bigger than 0. If it's finite, then there's a finite length shortest path. If it's minus infinity, then there's a negative rate cycle in my graph and I can stop. So there are either two situations. If delta s,v equals minus infinity-- so I guess this is, run single source shortest paths from s. And really, because this graph could contain negative edge weights and could contain negative cycles, we can't really do better than running Bellman-Ford here from s to compute these paths. If there exists in this new graph this Gs, if there exists a vertex that has negative infinite weight in the reweighted graph-- sorry, in the original graph G-- G hasn't been reweighted yet. If there's a negative weight distance from s, then there was a negative weight cycle in the original graph. Why is that? Well, if this was set to minus infinity, then there is some
4033	negative weight cycle in the graph. The worry is that that negative weight cycle was added to my graph by adding this vertex s. But what do I know about vertex s? It has no incoming edges. So no negative weight cycle could go through s. So any negative weight cycle was in the original graph, and so I can abort. Abort. Yay. Otherwise, what do I do? Well, I know the shortest path distances here would satisfy the triangle inequality. So if I reweight with h of v equal to delta s of v, if we set our potentials in our reweighted graph to be the shortest path distance from our super node s, it satisfies the triangle inequality. And because there's no negative cycles, all of these values are finite. And then this reweighting will lead to a graph with strictly-- or not strictly-- strictly no negative weights or non-negative weights. OK, great. So that's basically it. That's the idea behind Johnson's algorithm.
4034	It's really a reduction problem or a reduction algorithm. We reducing from solving kind of signed all-pairs shortest paths, graphs where their weights could be positive or negative, and we're reducing to creating a graph that has the same shortest paths properties, but only has non-negative edge weights. So we're reducing from a signed context to a non-negative weight context. So Johnson's algorithm, what are the steps? Construct Gs from G, just as up here. I make a new vertex s. I put a 0 weight directed edge from s to every vertex. So that's the first step. Second step-- compute E, s,v for all V in V, i.e-- or e.g-- I guess really it should be i.e. because I don't really have another option here-- but by Bellman-Ford. This is just a single run of Bellman-Ford here. Compute. And then there are two possibilities. If there exists a delta s, v that's minus infinity, then abort. Else, make-- or reweight the graph according to this reweighting scheme, by reweighting each edge in my original graph to have weight-- our
4035	new weight, which is our old weight, plus our transformation. Now, our transformation is now going to set h, v to this delta s, v. So I'm going to add delta s, u, and subtract delta s, v. That's our reweighting scheme. I'm just identifying h, v with this shortest path distance here. And after I reweighted that, I can just solve all-pairs shortest paths on G prime with Dijkstra. And then compute G shortest path distances from G prime shortest path distances. Compute these distances from the other using this algorithm up here-- can compute distances in G from distances in G prime in linear time-- or sorry, v times linear time, linear time for each s-- for each vertex in my graph. OK, so that's the algorithm. It's basically, correctness is trivial. We already proved-- the whole part of this lecture, the interesting part of this lecture was proving that, if we had a transformation based on a potential function that changed outgoing edges in a symmetrically opposite way as incoming edges, then that preserves shortest paths. And
4036	then realizing that the triangle inequality enforces this condition that edge weights will be non-negative under this reweighting, so we find shortest path distances from some other arbitrary vertex, and set our potential functions to be those shortest path distance weights. We do the reweighting, because that reweighting preserves shortest paths, which we already argued. Then we can do-- then this has positive edge weights, so Dijkstra applies. And then computing this takes a small amount of time. OK, what is the running time of this algorithm? So this part, reconstructing this thing, this takes linear time. I'm just adding. I'm just making a new graph of the same size, except I added v edges and one vertex. Computing-- doing Bellman-Ford on this new modified graph, that's just-- I'm doing that once. That takes V times E time. Doing this check, that just takes-- I'm looping over my vertices. That just takes V time. Otherwise, doing this reweighting, I change the weight of every edge. That takes order E time. And then solving G prime-- solving all-pairs shortest paths on
4037	the modified edge weight graph with Dijkstra takes V times Dijkstra. That's-- I could use a little bit more board space here. That's V times V log, V plus E time, which is actually the running time that we're looking for. I wanted to reduce to not using more than this time. We used this amount of time. Let's make sure we still didn't use even more. After that, we compute these paths, as proofed before, in V times V plus E, which is smaller than that. And so summing up all of these running times, this one dominates. And so Johnson's can solve signed weighted all-pairs shortest paths, signed all-pairs shortest paths, not in V times Bellman-Ford, like we had before up here, but faster, in nearly linear for sparse graphs, just without this log factor. So we got quite a big improvement. So that's the nice thing about all-pairs shortest paths is that, really, we don't have to incur this big cost in the context of negative weights. Essentially, we just run Bellman-Ford once to see if there
4038	is a negative weight cycle in my graph. If it is, I save a lot of work by stopping early. So that's Johnson's. That's the end of our graphs lectures. We'll be having a review and problem session about how to solve problems, graph problems using this material. But we've talked about a lot of different things so far. We've talked about graph reachability, connected components, detecting cycles, detecting topological sort orders of a DAG. We've talked about finding negative weight cycles, single source shortest path algorithms, and now finally, today, all-pairs shortest path algorithms, with a new algorithm that's really not an entirely new algorithm. We didn't have to do any proof by induction here. Really, the heavy work that's happening is we're reducing to using either Dijkstra or Bellman-Ford to do the heavy lifting of finding single source shortest paths efficiently. So Johnson's is really just glue to transform a graph in a clever way, and then reducing to using some of the shortest paths algorithms faster. So that's our unit on graphs. Our next lecture, we'll start
4039	talking about a general form of, not presenting you with an algorithm, but how to design your own algorithm in the context of dynamic programming. So see you next lecture.
4040	[SQUEAKING] [RUSTLING] [CLICKING] JUSTIN: OK. So it's a pleasure to see all of you guys. I'm Justin. I'm your third instructor for 6.006. This is my first time with this course. Although, of course, this is material that we all know and love in the computer science department. I'll admit, I find the prospect of teaching sorting to 400 people all at once is mildly, low key terrifying. But we're going to give it a shot. And hopefully, that will subside as the lecture goes on today, all right? So we're going to pick up where we left off in our last lecture and continue on with a similar theme that we're going to see throughout our algorithms class here in 6.006. I think Jason and colleagues have done a really great job of organizing this class around some interesting themes. And so I thought I'd start with just a tiny bit of review
4041	Incidentally, typically, I teach the intro graphics class, the geometry course. And last year, I got feedback that said I have serial killer handwriting. I'm not 100% sure what that means. But we're going to use the slides a tiny bit more than normal, just to make sure you guys can read. And when I'm writing on the board, at any point, if you can't tell what I wrote, it's definitely me and not you. So just let me know. But in any event, in 6.006, all the way back in our lecture 1-- I know that was a long time ago-- we introduced two big keywords that are closely related, but not precisely the same. Hopefully, I've gotten this right. But roughly, there's a theme here which is that there's an object called an interface, which is just a program specification. It's just telling us that there's a collection of operations that we want to implement. So for example, a set, as we're going to see today, is like a big pile of things. And behind the scenes, how
4042	I choose to implement
4043	But the actual way that I interact with it is the same, whether I use an unsorted array, a sorted array, what have you. On the other hand, what happens behind the scenes is something called a data structure, which is a way to actually, in some sense, implement an interface. So this is the object that on my computer is actually storing the information and implementing the set of operations that I've laid out in my interface. And so this sort of distinction, I think, is a critical theme in this course because, for instance, in the first couple weeks, we're going to talk about many different ways to implement a set. I'm going to see that there's a bunch of tradeoffs. Some of them are really fast for certain operations and slow for others. And so essentially, we have two different decisions to make when we choose an algorithm. One is making sure that the interface is correct for the problem that we're concerned with. And the other is choosing an appropriate data structure whose efficiency, and memory
4044	usage, and so on aligns with the priorities that we have for the application we have in mind. So hopefully, this high level theme makes sense. And really, spiritually, I think this is the main message to get out of this course in the first couple of weeks, even though these O's, and thetas,
4045	In any event, today, in our lecture, we're concerned with one particular interface, which is called a set. A set is exactly what it sounds like. It's a big pile of things. And so a set interface is like an object that just you can keep adding things to it. And then querying inside of my set, is this object here? Can I find it? And then maybe I associate with my objects in my set different information. So for example, maybe I have a set which represents all the students in our classroom today. Yeah, and all of you guys are associated with your student ID, which I believe at MIT is a number, which has less than sign, which is convenient. So we can sort all of you guys. And that might be the key that's associated to every object in the room. And so when I'm searching for students, maybe I enter in the student number. And then I want to ask my set, does this number exist in the set of students that are in 6.006?
4046	And if it does, then I can pull that student back. And then associated with that object is a bunch of other information that I'm not using to search-- so for instance, your name, your-- I don't know-- your social security number, your credit card number, all the other stuff that I need to have a more interesting profession.
4047	interface a little bit more. So our set is a container. It contains all of the students in this classroom, in some virtual sense at least. And so to build up our set, of course, we need an operation that takes some iterable object A and builds a set out of it. So in other words, I have all the students in this classroom represented maybe in some other fashion. And I have to insert them all into my set. I can also ask my set for how much stuff is in it. Personally, I would call that size. But length is cool, too. And then of course, there are a lot of different ways that we can interact with our set. So for instance, we could say, is this student taking 6.006? So in set language, one way to understand that is to say that the key-- each person in this classroom is associated with a key. Does that key k exist in my set? In which case, I'll call this find function, which will give me back the
4048	item with key k or maybe null or something if it doesn't exist. Maybe I can delete an object from my set or insert it. Notice that these are dynamic operations, meaning that they actually edit what's inside of my set. And then finally, there are all kinds of different operations that I might want to do to interact with my set beyond is this thing inside of it. So for instance, so for the student ID example, probably finding the minimum ID number in a class isn't a terribly exciting exercise. But maybe I'm trying to find the student who's been at MIT the longest. And so that would be a reasonable heuristic. I actually have no idea whether MIT student IDs are assigned linearly or not. But in any event, I could find the smallest key, the largest key, and so on in my set. And these are all reasonable operations to query, where my object is just
4049	Now, this description here-- notice that I've labeled this as a set interface. This is not a set data structure. And the way to remember that is that I haven't told you how I've actually implemented this. I haven't told you that I'm going to behind the scenes have an array of information, and look inside of it, and that's how I'm going to implement find min or find max with a for loop or whatever. All I'm telling you is that a set is a thing that implements these operations. And behind the scenes, my computer does what it does. Now, it might sound abstract. But it's more or less what you guys do when you write code in Python. I think in Python what we're calling a set is maybe a dictionary. I'm a Matlab Coder. I'm sorry. I'm a numerical analysis kind of guy. But essentially, one of the beautiful things about coding in these high level programming languages is that they take care of these ugly details. And what you're left with is just the high
4050	level interfacing with this object
4051	So of course, in today's lecture, now that we set out our goal, which is to fill in-- if I wanted to write code for a set, how could I do it? Now, of course, our goal is to give different data structures that implement these, and then understand them in terms of their efficiency, data storage, correctness, all that good stuff. So before we get into all these ugly details, let me pause for a second. Are there any questions about this basic interface? You all should feel free to stop me any time because this is going to be hella boring if you're not
4052	Yes? AUDIENCE: Can you explain how [INAUDIBLE].. JUSTIN: That's a good question. So the question was, what exactly is this insert operation doing? That's why working on the analogy of the students in this classroom is a reasonable one. So I'm going to build up an object, which is a student. So in this lecture notes, I think we've been consistent. I caught one or two typos. We're going to think of x as the object that contains all of the information. And then associated with that is one piece, which is called the key. That's where we're going to use a letter k. And that's like your student ID. That's the thing I'm going to use to search. So what the Insert operation does that takes this whole student object x, which includes your ID, your name, your phone number, all that good stuff, and inserts it into the set with the understanding that when I search my set, I'm going to be searching by key. So when I want to find a student, I have to put in
4053	my ID number. Does that makes sense?
4054	Any other questions? That's great. Fabulous. OK. So now, let's talk about how to actually implement this thing. And thankfully, we're already equipped with at least a very simple way that we can implement a set based on what you've already seen in your previous programming classes or even just in the last two lectures, which is one way to understand a set or to implement it rather would be to just store a giant array of objects that are in my set. I suppose continuing with the theme of the last two lectures, this is not a space in memory, but rather a metaphorical array, a theoretical array. But it doesn't really matter. And so one way to store my set would be to just store a bunch of x's in no particular order. Does that make sense? So I have a big piece of memory. Every piece of memory is associated with a different object in my set. Obviously, this is quite easy to build. I just make a big array and dump everything in there. And the
4055	question is, is this particularly efficient or a useful way to implement a set? So for instance, let's say that I have a set of all the students in this classroom. There's some ridiculous number of you guys. So actually, asymptotic efficiency maybe actually matters a little bit. And I want to query, does this student exist in my class? Is Erik Demaine taking 6.006? The answer is no, I think. Teaching, taking? I don't know. But in any event, how do I implement it if my set is unordered? We'll think about it for a second. Yeah? AUDIENCE: [INAUDIBLE] JUSTIN: It's actually an interesting suggestion, which is going to anticipate what's happening later in this lecture, which was to sort the set and then binary search. But let's say that actually I only have to do this once. For some reason, I built up a whole set of the people in this classroom. And I just want to know, is Erik Demaine in this class? So then that algorithm would take n log n time because I've got to
4056	sort everybody. And then I have to do binary search, which is maybe log n time. But I claim that, if the only thing I care about is building up my entire set and searching it once, there's actually a faster algorithm. This is going to be needlessly confusing because we're going to see that this is really not the right way to implement it in about 38 seconds. Yes? AUDIENCE: [INAUDIBLE] JUSTIN: Yeah. Just iterate from beginning to this array and say, is this guy Erik? No. Is this guy Erik? No. Is this guy Erik? Yes. And then return it. So in the worst case, how long will that algorithm take? Well, in the worst case of really bad luck, your instructor is all the way at the end of the list. So in this case, what is that going to mean? That means that I have to walk along the entire array before I find him. So that algorithm takes order n time. And so your colleague's intuition that somehow this is quite inefficient is absolutely correct.
4057	If I know that I'm going to have to search my array many, many times for different people, then probably it makes sense to do a little bit of work ahead of time, like sorting the list. And then my query is much more efficient. But this is all just to say that an unordered array is a perfectly reasonable way to implement this set interface. And then searching that array it will take linear time
4058	And of course, if you go down your list of all of the different operations you might want to do on a set, you'll see that they all take linear time. So for instance, how do I build myself? Well, I have to reserve n slots in memory. And at least according to our model of computation in this class, that takes order n time. Then I'm going to copy everything into the set. Similarly, if I want to insert or delete, what do I have to do? Well, I have to reserve memory, stick something inside of there. In the worst case, we saw this amortize argument before, if your set is allowed to grow dynamically. And finally, if I wanted to find the minimum student ID in my classroom, the only algorithm I can have if my list of students isn't sorted is to what? Just iterate over every single student in the class. And if the guy that I'm looking at has a smaller ID than the one that I found, replace it. Does that make sense
4059	to everybody? So basically, everything you can do in a set you can implement-- and I think all of you guys are more than qualified to implement-- as an unordered array. It's just going to be slow. Yes? AUDIENCE: [INAUDIBLE] JUSTIN: Yeah, that's right. So actually, I don't know in this class. I guess, the interface and the way that we've described it here is dynamic. We can just keep adding stuff to it. In that case, remember this amortized argument from Erik's lecture says that on average that it will take order n time. AUDIENCE: [INAUDIBLE] JUSTIN: What was that? AUDIENCE: [INAUDIBLE] JUSTIN: Oh, that's true. That's an even better-- sorry. Even if it weren't dynamic. If I wanted to replace an existing key-- like, for some reason, two students had the same ID. This is a terrible analogy. I'm sorry. But in any event, if I wanted to replace an object with a new one, well, what would I have to do? I'd have to search for that object first, and then replace it. And that search is
4060	going to take order n time from our argument before. Thank you. OK. So in some sense, we're done. We've now implemented the interface. Life is good. And of course, this is the difference between existence and actually caring about the details inside of this thing. We've shown that one can implement a set. But it's not a terribly efficient way to do it by just storing a big, hot mess, disorganized list of numbers without any order. So instead of that, conveniently, our colleague in the front row here has already suggested a different data structure, which is to store our set not as just a disorganized array in any arbitrary order, but rather to keep the items in our set organized by key. So in other words, if I have this array of all of the students in our classroom, the very first element in my array is going to be the student with the smallest ID number, the second is the second smallest number, all the way to the end of the array, which is the student
4061	with the biggest ID number. Now, does that mean I want to do arithmetic on student ID numbers? Absolutely not. But it's just a way to impose order on that list
4062	OK. So if I want to fill in the set interface and I have somehow a sorted array of students-- so again, they're organized by student ID number-- then my runtime starts to get a little more interesting. Yeah. So now, insertion, deletion they'd still take the same amount of time. But let's say that I want to find the student with the minimum ID number, this find min function. Well, how could I do it in a sorted array? Keyword is sorted here. Where's the min element of an array? Yes? AUDIENCE: [INAUDIBLE] JUSTIN: Yeah. In fact, I can give a moderately faster algorithm, which is just look at the first one. If I want the minimum element of an array and the array is in sorted order, I know that's the first thing. So that's order 1 time to answer that kind of a question. And similarly, if I want the thing with the biggest ID number, I look all the way at the end. Now, in 6.006-- MIT student class numbers are super confusing to me. In
4063	6.0001, 6.042, you guys already I think learned about binary search and even may have implemented it. So what do we know? If my array is sorted, how long does it take for me to search for any given element? Yes? AUDIENCE: Log n time. JUSTIN: Log n time. That's absolutely right because I can cut my array in half. If my key is bigger or smaller, then I look on the left or the right. And so this is a much more efficient means of searching a set. So in particular, 6.006 this year has 400 students. Maybe next year, it has 4,000. And eventually, it's going to have billions. Then what's going to happen? Well, if I use my unordered array and I have a billion students in this class, what's going to happen? Well, then it's going to take me roughly a billion computations to find any one student in this course, whereas log of a billion is a heck of a lot faster. On the other hand, I've swept under the rug here, which is how
4064	do I actually get a sorted array to begin with. And what we're going to see in today's lecture is that that takes more time than building if I just have a disorganized list. Building a disorganized list is an easy thing to do.
4065	But actually, sorting a list of numbers requires a little bit more work. And so this is a great example where there's at least a tiny amount of tradeoff. Now, building my sorted array to represent my set is going to take a little more computation. We're going to see it's n log n time. But then once I've done that step 0, now a lot of these other operations that I typically care about in a set, like searching it for a given key, are going to go a lot faster using binary search. So this is our basic motivator here. And so now, we've seen the setup interface and two potential data structures. And our goal for the day is going to be to fill in the details of that second one. And since you all have already seen binary search, you've probably also already seen sorting. But in any event, today, we're going to focus mostly on the lower left square here, on just how can I take a disorganized list of objects and put it into
4066	sorted order so that I can search for it later. So in other words, our big problem for lecture today is the second thing here, this sorting. Incidentally, in the next couple of lectures, we're going to see other data sets-- or data structures, rather. Sorry, data sets. I used to teach machine learning class. And we'll see that they have different efficiency operations that we can fill in this table. So we're not done yet. But this is one step forward. OK. So hopefully, I have ad nauseum justified why one might want to sort things. And indeed, there are a couple of vocabulary words that are worth noting. So one, so remember that your sorting algorithm is pretty straightforward in terms of how you specify it. So in sorting, your input is an array of n numbers. I suppose actually really that we should think of them like keys. It's not going to matter a whole lot. And our output-- I'm always very concerned that if I write on the board on the back, I have to cover
4067	it up-- is going to be sorted array. And we'll call this guy B. We'll call this one A. This classroom is not optimized for short people.
4068	So there's a lot of variations on the basics sorting problem and the different algorithms that are out there. Two vocabulary words are going to highlight really quick-- one is if your sort is destructive, what that means is that rather than reserving some new memory for my sorted array B and then putting a sorted version of A into B, a destructive algorithm is one that just overwrites A with a sorted version of A. Certainly the C++ interface does this. I assume the Python one does, too. I always forget this detail. In addition to destructive sorts, some sorts are in place, meaning that not only are they destructive, but they also don't use extra memory in the process of sorting. Really, you could imagine a sorting algorithm that has to reserve a bunch of scratch space to do its work, and then put it back into A. For instance, the world's dumbest destructive sort might be to call your non-destructive and then copy it back into A. But that would require order n space to do. So
4069	if my algorithm additionally has the property that it doesn't reserve any extra space, at least up to a constant, then we call that in place. OK. So those are our basic vocabulary words. And they're ways to understand the differences between different sorting algorithms. Yes? AUDIENCE: [INAUDIBLE] JUSTIN: Why do they end up using extra O(1) space? Oh yeah, sure. Any time I just make a temporary variable like a loop counter, that's going to count toward that order 1. But the important thing is that the number of variables I need
4070	OK. So I present to you the beginning and end of our sorting lecture, which is the world's simplest sorting algorithm. I call it permutation sort. I think it's very easy to prove correctness for this particular technique. So in permutation sort, what can I do? Well, I know that if I have an input that's a list of numbers, there exists a permutation of that list of numbers that is sorted by definition because a sort is a permutation of your original list. So what's a very simple sorting algorithm? Well, list every possible permutation, and then just double check which one's in the right order. So there's two key pieces to this particular technique, if we want to analyze it. I don't see a reason to belabor it too much. But one is that we have to enumerate the permutations. Now, if I have a list of n numbers, how many different permutations of n numbers are there? Yes? AUDIENCE: n factorial. JUSTIN: n factorial. So just by virtue of calling this permutation's function, I know that I
4071	incur at least n factorial time. It might be worse. It might be that like actually listing permutations takes a lot of time for some reason, like every permutation itself takes order n time. But at the very least, each one of these things looks like n factorial. I warned you my handwriting is terrible. So that's what this omega thing is doing, if I recall properly. And then secondarily, well, we've got to check if that particular permutation is sorted. How are we going to do that? There's a very easy way to check if a list is sorted. I'm going to do maybe for i equals 1 to n minus 1. Notice not a Python coder. It's going to look different. Then check, is Bi less than or equal to Bi plus 1? And so if this relationship is true for every single i-- that's supposed to be a question mark. This was less than or equal to with a question mark over it. There's my special notation. So if I get all the way to the end
4072	of this for loop and this is true everywhere, then my list is sorted and life is good. So how long does this algorithm take? Well, it's staring you right in the face because you have an algorithm, which is looping from 1 to n minus 1. So this step incurs order n time because theta of n time because it's got to go all the way to the end of the list. So when I put these things together, permutation sort-- well, remember that this check if sorted happens for every single permutation. So at the end of the day, our algorithm takes at least n factorial times n time. It's a great example of something that's even worse than n factorial, which somehow in my head is like the worst possible algorithm. So do you think that Python implements permutation sort? I certainly hope not. Yes? AUDIENCE: [INAUDIBLE] JUSTIN: Right. So the question was, why is it omega and not big O? Which is a fabulous question in this course. So here's the basic issue. I haven't given
4073	you an algorithm for how to compute the set of permutations for a list of numbers. I just called some magic function that I made up. But I know that that algorithm takes at least n factorial time in some sense. Or if nothing else, the list of permutations is n factorial big because that's all the stuff has to compute. So I haven't told you how to solve this problem. But I'm convinced that it's at least this amount of time. So remember that omega means lower bound. So when I put it all together, in some sense-- OK, this isn't satisfying in the sense that I didn't give you precisely the runtime of this algorithm. But hopefully, I've convinced you that it's super useless. Yeah, OK.
4074	But great. So if we go back to our table for the set interface, well, in some sense, if we implemented it using this goofy algorithm, then the lower left entry in our table would be n factorial times n, which wouldn't be so hot. But notice that actually all the rest of our operations are now quite efficient. I can use binary search. I just obtained the algorithm that--
4075	OK. So let's fill in some more interesting algorithms. As usual, I'm talking too much. And I'm nervous about the time. But we can skip one of them if we need to. So how many of us have seen selection sort before? I see your hand. But we're going to defer for a little bit. I'm sorry? AUDIENCE: [INAUDIBLE] JUSTIN: That's fabulous. Why don't we defer to the end of lecture? And we'll do it then. OK. So the first algorithm that we'll talk about for sorting, which is somewhat sensible, is something called selection sort. Selection sort is exactly what it sounds like. So let's say that we have a list of-- whoops, my laptop and the screen are not agreeing. OK. Let's say I have a list of numbers-- 8, 2, 4, 9, 3. There's a message that Jason I think is sending me in the course notes. But I haven't figured it out. But in any event, I want to sort this list of numbers. Here's a simple algorithm for how to do it, which is I
4076	can find the biggest number in this whole list and stick it at the end. So in this case, what's the biggest number in this list everybody? 9. Good. See, this is why you go to MIT. So I'm going to take that 9. I find it. And then swap it out with the 3, which is at the end. And now, what's my inductive hypothesis? Well, in some sense, it's that everything to the right of this little red line that I've drawn here is in sorted order, in this case because there's only one thing. So now, what am I going to do? I'm going to look to the left of the red line, find the next biggest thing. What's that? Come on. AUDIENCE: 8. JUSTIN: There we go. Yeah, wake up. OK. So right, the next biggest one is the 8. So we're going to swap it with the 3, put it at the end, and so on. I think you guys could all finish this off. I suppose there should be one last line here where
4077	everything is green and we're happy. But in some sense, we're pretty sure that an array of one item is in sorted order. And so essentially, from a high level, what does selection sort do? Well, it just kept choosing the element which was the biggest and swapping it into the back and then iterating. Now, in 6.006, we're going to write selection sort in a way that you might not be familiar with. In some sense, this is not so hard to implement with two for loops. I think you guys could all do this at home. In fact, you may have already. But in this class, because we're concerned with proving correctness, proving efficiency, all that good stuff, we're going to write it in kind of a funny way, which is recursive. Now, I can't emphasize strongly enough how little you guys should implement this at home. This is mostly a theoretical version of selection sort rather than one that you would actually want to write in code because there's obviously a much better way to do it.
4078	And you'll see that in your recitation this week, I believe. But in terms of analysis, there's a nice, easy way to write it down. So we're going to take the selection sort algorithm. And we're going to divide it into two chunks. One of them is find me the biggest thing in the first k elements of my array. I shouldn't use k because that means key. The first i elements of my array. And the next one is to swap it into place and then sort everything to the left. That's the two pieces here. So let's write that down. So what did I do? Well, in some sense, in step 1 here, I found the biggest with index less than or equal to i. So I started at the end of the list, and then moved backward. And then step 2 was to swap that into place. Notice when I say swap-- so for instance, when I put the 8 there, well, I had to do something with that 3. So I just put it where the
4079	8 used to be. And then finally, well, am I done? No, I just put the biggest thing at the end of my array. So now, I have to sort from index 1 to i minus 1 because now I know that the last guy is in sorted order. I see you. I'll turn it over to you in just a sec. Yes? AUDIENCE: [INAUDIBLE] JUSTIN: You can't read the handwriting? AUDIENCE: [INAUDIBLE] JUSTIN: This is index less than or equal to i. Great question. I warned you. It's going to be a problem. So let's do step 1 first. So I'm going to put code on the board. And then we're going to fill in the details. Erik is posting on Facebook. I'm going to turn that feature off on my watch later. So right, let's implement this helper function here. This is something we're going to call prefix max. And this is going to find me the biggest element of array between index 0 and index i inclusive, I believe. Yeah? AUDIENCE: [INAUDIBLE] JUSTIN: Well, here's an interesting
4080	observation, really a deep one, which is that the biggest element from 0 to i-- that's an i, sorry. There's two cases. Either it's at index i, meaning I have the first 10 elements of my right-- either it is element number 10 or what's the other case? It ain't, Yeah? In other words, it has index less than i. This is a tautology, rate? Either the biggest thing is at this index or it's not. In which case, it has to be to the left. Does that makes sense? So this gives us a really simple algorithm for finding the biggest element in the array between index 0 and index i, which is what I've shown you on the screen here. I'd write it on the board. But I am a slow writer and already low on time. And so essentially, what did I implement? Well, I found the biggest element between index 0 and index i minus 1. So let's say that I have an array-- I forget the sequence of numbers-- 8, 3, 5, 7, 9. That'll
4081	do it. And so like I give a pointer here, which is i. And the very first thing that I do is I compute the biggest number all the way to the left of this stuff. In this case, that is? AUDIENCE: 8. JUSTIN: 8. There we go. Now, I look at the very last element of my array, which is-- 9. You're killing me today, guys. And then what do I return? Well, I want the biggest one between 0 and index i. So in this case, I return the 9.
4082	So I know Jerry Cain at Stanford likes to talk about the recursive leap of faith that happens. Another term for this is induction. So we want to prove that our algorithm works. Well, what do we have to do? We have to show that when I call this function, it gives me the max of my array between index 0 and index i for all i. So let's maybe do this inductive proof a little bit carefully. And then the rest, we'll be sloppy about it. So the base case is i equals 0. Well, in this case, there's only one element in my array. So it's pretty clear that it's the max. And now, we have to do our inductive step, which means that if I call prefix max with i minus 1, I really do get the max of my array between 0 and index i minus 1. And then really, I can just look at my very deep statement, which is that either my object is at the end of the array or it's not. And
4083	this is precisely what we need to justify the inductive step. Essentially, there are two cases. Either the biggest element of my arrays the last one or it's not. We already, by our inductive hypothesis, have argued that our code can find the biggest element between index 0 and index i minus 1. So as long as we take the max of that and the very last guy, we're in good shape.
4084	OK. So now, we have to justify runtime for this algorithm. And that's actually not 100% obvious from the way I've written it here. There's no for loop. But what do I do? Well, in some sense, if my run time is a function s, well, for one thing, if my array has one element in it, well, my run time might be 7, might be 23. But at the end of the day, it only does one thing. It just returns i. So in other words, it's theta of 1. This isn't terribly insightful. But what else do we know? Well, when I call my function, I call it recursively on one smaller index. And then I do a constant amount of work. So I know that s of n is equal to s of n minus 1 plus theta of 1. I do a little bit of extra computation on top of that. Can anybody guess what this total runtime is going to be? Yes? AUDIENCE: [INAUDIBLE] JUSTIN: Yeah, order n. So let's say that we hypothesize that
4085	this takes n time. You can see that because at step n we call n minus 1, we call it minus 2, and so on, all the way down to 1. If we want to prove this, one of the ways that we-- I think, in theory, you guys have learned in the past-- and you're going to cover it in recitation-- is a technique called substitution. What we do is we're going to look at this relationship. And we're going to hypothesize that we think s of n maybe look something like cn for some constant c that doesn't depend on n. Then all we have to do is double check that that relationship is consistent with our inductive hypothesis, or rather just as a recursive function. And if it is, then we're in good shape. So in this case, well, what do I know? I've guessed that s of n is theta of n. In particular, if I plug into this recursive relationship here, on the left-hand side, I'm going to get cn. On the right-hand side, I'm
4086	going to get c n minus 1 plus theta of 1. We just have to make sure that this is an OK equal sign. So what can I do? I can subtract cn from both sides, maybe put that 1 on the other side here. Then we get the c equals big I of 1. c is, of course, a constant. So we're in good shape. My undergrad algorithms professor told me never to write a victory mark at the end of a proof. You have to do a little square. But he's not here.
4087	So now, I see you. But we're a little low on time. So we'll save it for the lecture. OK. So if we want to implement the selection sort algorithm, well, what do we do? Well, we're going to think of i as the index of that red line that I was showing you before. Everything beyond i is already sorted. So in selection sort, the first thing I'm going to do is find the max element between 0 and i. And then I'm going to swap it into place. So this is just a code version of the technique we've already talked about. Hopefully, this makes sense. So you find the biggest element between 0 and index i. That's what we're going to call j here. I swap that with the one in index i. That's step 2. And then step 3 is I still have to sort everything to the left of index i and that's that recursive call. So if I want to justify the runtime of this particular technique, well, now let's call that t for
4088	time. Well, what do I do? Well, for one, I call selection sort with index i minus 1. So that incurs time that looks like this. But I also call that prefix max function. And how much time does that take? That takes order n time. So at the end of the day, I have some relationship that looks like this. Does that makes sense? So by the way, notice that this order n swallowed up the order 1 computations that I had to do to swap and so on. So remember, there's this nice relationship, which you probably learned in your combinatorics class, which is that 1 plus 2 plus dot, dot, dot plus n. OK. I can never remember exactly the formula. But I'm pretty sure that it looks like n squared. So based on that and taking a look at this recursive thing, which is essentially doing exactly that-- n plus n minus 1 plus n minus 2, and so on-- I might hypothesize that this thing is really order n squared. So if I'm going to
4089	do that, then again if I want to use the same technique for proof, I have to plug this relationship in, and then double check that is consistent. So maybe I hypothesize that t of n equals cn squared. In which case, I plug it in here. I have cn squared equals with a question mark over it cn minus 1 squared plus big O or even theta n here. So if I expand the square, notice I'm going to get c times n squared plus a bunch of linear stuff. This is really cn squared-- I should be careful with that-- minus 2 cn plus c plus theta of n. Notice that there's a cn squared on both sides of this equation. They go away. And what I'm left with is a nice, consistent formula that theta of n equals 2 cn minus c. And indeed, this is an order n expression. So there's order in the universe. Life is good. Yeah, this is the substitution method. And again, I think you'll cover it more in your recitation. So
4090	what have we done? We have derived the selection sort. We've checked that it runs in n squared time. And by this nice, inductive strategy, we know that it's correct. So life is pretty good. Unfortunately, I promised for you guys on the slides that sorting really takes n log n time. And this is an order n squared algorithm. So we're not quite done yet. I'm way over time. So we're going to skip a different algorithm, which is called insertion sort, also runs on n time. Essentially, insertion sort runs in the reverse order. I'm going to sort everything to the left, and then insert a new object, whereas, in selection, I'm going to choose the biggest object and then sort everything to the left. But I'll let you guys piece through that at home.
4091	And instead, we should jump to an algorithm that actually matters, which is something called merge sort. How many of us have encountered merge sort before? Fabulous. Good. So then I'm done. So let's say that I have a list. Now, I'm sending a message back to Jason. I made this one up last night. So I have 7, 1, 5, 6, 2, 4, 9, 3. This is not in sorted order. But I can make a very deep observation, which is that every number by itself is in sorted order if I think of it as an array of length 1. It's really deep, like deep learning deep. So now, what can I do? Well, I could take every pair of numbers, draw a little red box. Well, now, they're not in sorted order any more inside of the red boxes. So I'm going to sort inside of every box. In this case, it's not too exciting because it's just pairs. And now, they're in sorted order because they said they were. Now, I'm going to keep doubling the
4092	size of my boxes. So now, let's say I have box of length 4. What do I know about the left and right-hand sides of the dotted lines here? On the two sides of the dotted lines, the array is in sorted order. There's a 1 and then a 7. Those are in sorted order, 5 and a 6. That's because, in the previous step, I sorted every pair. So when I merge these two sides together, I have an additional useful piece of information, namely that the two sides of the dotted line are already in sorted order. That's going to be our basic inductive step here. So in this case, I merge the two sides. I get 1, 5, 6, 7, and 2, 3, 4, 9. Then finally, I put these two things together. And I have to sort these two. I have to merge these two sorted lists. But they're in sorted order. And that's going to give me a big advantage because-- oops, I lost my chalk. I suppose I've got space on this board here.
4093	Oh no. So if I want to merge 1, 5, 6, 7 and 2, 3, 4, 9, there's a nice, clever technique that we can do that's going to take just linear time. Jason tells me it's the two finger algorithm. I think that's a cute analogy here. So here are my two fingers. They're going to point at the end of the list. And I'm going to construct the merged array backwards. So how many elements are in my merged array, if I'm merging two things of length 4? I don't ask you guys hard questions. It's 8, yeah? 4 plus 4. 8, yeah? So what do I know? I know that my merge array-- 5, 6, 7-- has eight elements. And now, I'm going to have two fingers at the end of my array. Which one should I put at the end of the merged guy? The 7 of the 9? AUDIENCE: The 9 JUSTIN: The 9. Right, thank you. So now, I can move my lower finger to the left because I've already added that. Notice that
4094	I never need to look to the left of where my finger is because they're already in sorted order. Now what should I add, the 4 or the 7? AUDIENCE: 7. JUSTIN: The 7. And so on, dot, dot, dot, yeah? So that's going to be the basic idea of the merge sort. I'm going to take two sorted lists. And I'm going to make a new sorted list, which is twice as long, by using two fingers and moving from the and backward. So that's the basic intuition here. Indeed, there's our sorted list. It's stressing me out that there's no eight. I need the power of 2. So I think merge sort, we're going to present it in a backward way from the previous one, where I'm going to give you the high level algorithm. And then actually, the headache is that merging step, which I have four minutes for. And I apologize for it. So what does the merger sort do? Well, it computes an index c, which is the middle of my array. And it's going
4095	to make a recursive call which is sort the left, which is everything between index A and index C. And then sort everything on the right, which is everything from index C to index B. I know this is confusing because usually letters appear in order. But C, if you think of as standing for center, then it makes sense like. Here's my array. I'm going to choose an index right in the middle. I've done myself a disservice by not using a power of 2. But that's OK. I'm going to say sort everything to the left of the dotted line first. Sort everything to the right of the dotted line second. Now, I have two sorted lists on the two sides of the dotted line. And then I'm going to use my two fingers to put them together. So that's what this is implementing here. See, there's two recursive calls-- sort from A to C, and then sort from C to B. Oops, I didn't actually label this. So this is A, C, B. And then I've got
4096	to call merge.
4097	Now, our implementation of merge-- well, we can also do this in a recursive fashion. But personally, I find this a little complicated. I'm going to admit. But here's the basic idea here, which I'm now rushing. So I'm going to think of my upper finger as finger i and my lower finger as finger j. Does that makes sense? So I have two sorted lists. So maybe like that. I don't know, 1, 3, 5, 7. And then I have a second sorted list here, which is maybe 2, 4, 6, 72, as one does. Then I'm going to have one pointer like this, which is i, and a pointer down here, which is j. And my goal is to construct an array A with a bunch of elements in it. And the way that I'm going to do it is I'm going to use exactly the same kind of recursive argument, that I can either have the biggest element of my be the last element of the first guy or be the last element of the second one.
4098	So here's going to be our recursive call. And in addition to that, for convenience, we'll have a third index, which is B, which is pointing to this thing inside of my sorted array that I'm currently processing Yeah? It's going to start at A, go to B. Incidentally, I see a lot of people taking photos of the slides. These are just copy pasted from the notes. OK. So in this case, what should I put in B for my two arrays? I have 1, 3, 5, 7; 2, 4, 6, 72. 72, yeah? Great. So now, what am I going to do? I'm just going to call the merge function. But I'm going to decrement B because now I'm happy with that last element. And in addition to that, I'm going to decrement j because I already used it up. And so that's our recursive call here. It's saying, if j is less than or equal to 0-- so in other words, I have an element to use in one of the lists of the other. And maybe
4099	the left one is bigger than the right one. That's our first case. That does not apply in this example here. Well, then I should make the last element of a from the first list and then recurse with one fewer element i, and similarly
4100	So if we do our runtime in two minutes or less-- bare with me guys-- well, what is this merge function going to do? Well, in some sense, there's two branches. There's an if statement with two pieces. But both of those pieces call merge with one fewer piece in it. So in some sense, we have s of n equals s of n minus 1 plus theta of 1, which we already know from our previous proof means that s of n is equal to theta of n. So in other words, it takes linear time to merge. It makes sense intuitively because essentially you're touching every one of these things once with your two fingers. And now, probably the hardest part of the lecture, which I left zero time for, is deriving the runtime for the actual merge sort algorithm. And what does that look like? Well, that one's a little bit trickier because, of course, I call the merge sort algorithm twice, each time on a list that's half the size. In this class, we're going to
4101	assume that our list is always a power of 2 in its length. Otherwise, this analysis is a itty bitty bit more of a headache. So first of all, how long does it take to sort an array of length 1? I am not going to ask hard questions. Everybody? Yeah, it's just 1, right? Because there's nothing to do. An array of length 1 has one element and it's sorted. It's also the biggest element and the smallest element. And now, what does our algorithm do? Well, it makes two recursive calls on lists that are half the length. And then it calls that merge function. And we know that the merge function takes theta of n time. Does that make sense? So one thing we might do, because we have some intuition from your 6042 course, is that we think that this thing is order n log n because it makes the two recursive calls. And then it puts them together. And let's double check that that's true really quick using the substitution method. So in particular, on
4102	the left-hand side here, maybe I have cn log n. Now, I have 2 c. Well, I have to put an n over 2 log n over 2 plus theta of n. And I want to double check that this expression is consistent. I've got about a foot to do it in. So remember-- let's see. If we use our favorite identities from high school class that you probably forgot, remember that log of 2 things divided by each other is the difference of the logs. So this is really 2. OK. 2 divided by 2 is 1. So this is c times n times log n minus log of 2 plus theta n. I'm already out of time. But notice that there's a c n log n on the right-hand side. There's a c n log n on the left-hand side. So those two things go away. And what am I going to be left with? I'm going to be left with theta of n equals cn log of 2. Notice that c and log 2 are both constants.
4103	We have a theta event on the left-hand side. So there's order in the universe. And we've derived our runtime. So I know I rest a little bit through merge sort. I'm sure that Erik and Jason can review this a little bit next time. But with that, we'll see you, what? Thursday and Friday. And it's been a pleasure to talk to you all.
4104	[SQUEAKING] [RUSTLING] [CLICKING] JASON KU: Good morning, everyone. Welcome to the 13th lecture of 6.006. Just to recap from last time, we've been talking about shortest-- single source shortest paths on weighted graphs for the past two lectures. Previously we were only talking about unweighted graphs. And so far, up until today, we've talked about three ways to solve single source shortest paths on weighted graphs. Namely the first one used BFS. If you can kind of transform your graph into a linear-sized graph that's unweighted that corresponds to your weighted problem, essentially replacing each weighted edge with of weight w with w single edges. Now that's only good for positive weight things and if the sum of your weights are small. But if the sum of your weights is linear in the combinatorial size of your graph, V plus E, then we can get a linear time algorithm to solve weighted shortest paths using breadth-first search. Then we talked about how we could-- if we-- the problem with weighted shortest paths is if our weights were negative and there
4105	could exist cycles, then we could have negative weight cycles and that would be more difficult to handle, because then you have vertices where you have an unbounded number of edges you might have to go through for a shortest path. There might not be a finite length shortest path. But in the condition where we didn't have cycles in the graph-- of course, we couldn't have negative weight ones, so we were also able to do that in linear time by exploiting the fact that our vertices could be ordered in a topological order, and then we could kind of push shortest path information from the furthest one back to the ones forward. By relaxing edges forward. By maintaining this invariant that we had shortest paths as we were processing these things in topological order. Then last time, we were talking about general graphs, graphs that could contain cycles, and this is our most general algorithm, because if there are negative weight cycles, Bellman-Ford, which we talked about last time, can detect them. And in particular, for any vertex
4106	that had a finite weight shortest paths-- path, we could compute that shortest path for it, compute its distance. And for any one that is reachable from a negative weight cycle, not only could we mark it as minus infinity distance, but we could also find a negative weight cycle essentially by duplicating our graph to make it a DAG and being able to follow pointers back in this expanded DAG that had multiple layers. So that's what we've done up until now. We've gotten linear for some types of graphs. And we've gotten kind of quadratic V times E for general graphs, ones that could contain negative cycles. Now how bad is this? Well, if the graph is sparse, if the number of edges in our graph is on the order of V, then this is quadratic time and V, V squared. But if the graph is dense where we have quadratic-- like the complete graph where every edge is present, then we have quadratically many edges in our graph in V. And so this running time is V
4107	cubed. V cube's not great in terms of its running time. We would like something closer to linear. And so that's what we're going to do today. If we have this restriction where we have non-negative weights, we can have negative weight cycles. And this is a restriction that comes up a lot for many graphs you might encounter. A lot of times you don't have both positive and negative weight. I don't have a negative distance to my house. In any metric we have non-negative weights. So these things come up a lot, and we can actually do quite a bit better, since there are no negative weight cycles, we can get almost linear. It's not going to be quite V plus E as you see up here on the slide. We're going to get something very close. It's V plus the E, but on the V term, we have this logarithmic factor in V. Which remember for all intents and purposes, this log of that thing in real life is not going to be bigger than like a
4108	factor of 30 or something like that. Maybe 60. But it's a small number. And so this is actually pretty good performance. It's almost linear-- that's what I'm saying almost linear here, and that's what we're going to try to do today. So, how do we do this? Well, I'm going to make two observations here, first off. Our idea is going to be to generalize the notion of BFS. When we had BFS, we split up our graph-- to solve unweighted-- solve weighted shortest paths in BFS, we could take our positive edge weights, break them up into individual edges. But if the total weight of our edges was large, then we'd have a problem, because now we've expanded the size of our graph. This is the same issue that we had with something like radix sort where we don't want our algorithm to run in the size of the numbers in our input, we want our algorithm to run in the number of numbers in our input. This is the difference between N and U back when we
4109	were talking about data structures. Here, if the size of our weights are large compared to V and E, then doing this expansion is going to be difficult. But if we had, say, some graph-- this is my graph G, and we had a source vertex s, the idea here is going to still be to try to grow a frontier of increasing distance from my source and try to maintain all of the things within a certain distance from my source. So that's the idea, grow a sphere centered at my source, repeatedly explore closer vertices before I get to further ones. But how can I explore closer vertices if I don't know the distances beforehand? This is kind of-- seems like a circular logic. I'm going to use the distance to my things to compute the distances to my things. That doesn't work so well. So how do we do this? Well, the idea here is to gradually compute the distances-- compute the distances as we go so that we maintain this property. Now this property, this idea
4110	wouldn't work necessarily in the context of negative edge weights. Here, we have this growing frontier, this ball around my source. And as I grow my thing, these things are at further and further distance, because any edge from something back here as I'm growing my ball a certain distance, these things are outside that distance. We're kind of using a key observation here. Here's my observation 1. If weights greater than or equal to 0, then distances increase along shortest paths. Maybe weakly monotonically increase if there are zero-weight edges. But in general, if I had a path going from s to some v, and it's going through some vertex u, I have some shortest path. This is the shortest path from s to v, and it goes through some point u, some vertex u. Then this monotonicity more specifically means that the shortest path from s to u and the shortest path from s to v, which is this whole thing, how do these relate to each other? If this is along that path, then this has to
4111	be at least as large as the subpath. Because all of these-- the weight of this path cannot be negative. So that's the thing that Dijkstra's going to exploit. It essentially means that when I'm expanding this frontier of distance away from x, it's possible if I had negative weight, that this line-- if I had some very negative weight going from a vertex here to a vertex here, this vertex could be within this boundary. Maybe if this distance is x, this guy could be within x. The things that are within distance x of s might not be all contained. There could be a path from here to this other vertex width distance x. It doesn't have this property because I could decrease in distance along the path. So that's the first observation. Second observation, well, let's see if we can piggyback on DAG relaxation. I claim to you that we can solve single source shortest paths faster if we're given an order of vertices in increasing distance beforehand. Distance from s. So here's the idea. I'm not
4112	going to give you the distances to all these vertices. Instead I'm going to give you the order of the vertices in some increasing distance from s. So basically I'm saying, if I had some, I don't know, here's a graph. Let's see if I can remember. OK, and I'm going to put some edges on here. OK. And I'm going to call these vertices 0, 1, 2, 3, and 4. OK. So here's a graph. Maybe I put some edge weights on here. I'm going to say this one is 3, this one is 2, this one is 3, this is 1, this is 1, this is 0, and this is 0. So from vertex 1 to 2, that was the 2 for the labeling of that vertex. That edge is zero-weight. OK. So here's a weighted graph And I don't necessarily know-- I could use Bellman-Ford to find shortest paths from this vertex 0, but the idea here is I'm not going to give you shortest paths, I'm going to try to compute shortest paths, but I'm going
4113	to give you some additional information. I'm going to give you the order of their shortest path distance from the source. And I can just-- I'm going to eyeball this and say-- I'm going to change this slightly to make it a little bit more interesting. I'm going to say this is distance 4. OK. All right, so now what we have is the shortest path distance-- I'm just eyeballing this. The shortest distance to-- bad example. All right. So, these are the weights. Shortest-path distance to 3 is going to be 2, I'm going to say, through there. Shortest-path distance here is 2 also. Shortest-path distance here is also 2 because I can go through both of these 0's and it's not a problem. And then the shortest-path distance here is 2 to here and a 1/3 to there. So these are listed in increasing distance from my source. I had to compute those deltas to convince you that this was the right ordering, but this is a right ordering of these things. Now it's not the only right
4114	ordering, but it is a right ordering. OK, so I'm told-- I'm arguing to you that I could solve a single source shortest paths in linear time if I were to give you the vertices in increasing distance? How could I do that? Well, because of this first observation, I know that if these are increasing in distance, any edge going backwards with respect to this ordering can't participate in shortest paths with one exception. Anyone know what that exception is? No edge can go backwards in this ordering based on this observation except under what condition? Yeah? AUDIENCE: If the weight is 0? JASON KU: If the weight to 0, yeah. So if the weight to 0, just like this situation here, then I could go backwards in the ordering. See, it's problematic. The idea is I'm going to want to construct a DAG so that I can run DAG relaxation. Well, if I have a component here that has 0 weights, I can coalesce this thing down-- I can deal with this component separately. Let's worry about that
4115	separately. If we do, we can collapse this edge down into a single vertex and transform this graph so it does respect the ordering. So I'm going to transform this graph into a new graph. This is a graph-- contains vertex 2 and vertex 0, vertex 1 and 3 here, and vertex 4. OK, now we have-- and I'm only going to keep edges going forward in the-- I'm going to need to collapse this entire section down into one vertex. This doesn't quite work. OK. Let's ignore zero-weight edges for now. Let's assume these are-- all right, there's something broken here. If I have a cycle here-- right now I don't have a cycle of zero-weight. So what I could do is I could take this vertex and put it after both of these vertices. And now I would-- or I could rearrange the order of these three vertices where there's a path of length 0 and get a new ordering that still satisfies the property. And that's always the case because paths can't increase-- paths can't decrease in
4116	weight. I can rearrange the ordering of these things so that 3 comes first, 1 comes second, and 2 comes third of those three vertices. Yeah. So for every set of 0 edges, I can just flip the relationship if they have the same distance. In my input, I'm given vertices that have the same distance from the source. And so if those are the same distance from the source and they're connected by a zero-weight edge, it doesn't hurt me to flip their ordering. So I'm going to do that. So let's convert that into a graph with a different ordering. 0 3 now, 1 2. OK and I have this distance, this edge, this edge, this edge, this edge. This edge. What am I missing? 2 to 3. And here. I think I have all of those edges. Yeah? OK. Now I have the property that every edge that could participate in the shortest path are going forward in the ordering, because all of these are zero-weight. So we flip those around so they're going correct with respect
4117	to the ordering. And any edge going backwards that is positive weight certainly can't be used in any shortest path. So I'm just going to get rid of them. Yeah? What do I do if there's a zero-weight cycle? JASON KU: If there's a zero-weight cycle, I can just coalesce them all together down to a single vertex, because if I reach one of them, I can reach all of them. AUDIENCE: You're getting a topological ordering of-- JASON KU: Exactly. I'm computing-- so the idea here is we're trying to construct a DAG. I can construct this DAG in linear time. And then I can run DAG relaxation on this graph in linear time to get shortest paths. So that's an approach. If I knew the ordering of the vertices in increasing distance, then I could use DAG relaxation. So we're going to use both of these observations. That's how we're going to solve this single source shortage problem with non-negative weights using Dijkstra. So that's finally now where we're coming to. Sorry, I missed a case here when
4118	I was writing up my notes, and I tried to fix it live and hopefully you guys followed me. OK. Dijkstra's algorithm. Did I spell that right? Kind of. OK. What? Dijkstra. OK. Now Dijkstra was this Dutch computer scientist. This is him. Pretty famous, he wrote a monograph on why programming languages should start with 0 indexing as opposed to 1 indexing, so I like him. But in particular, he designed this very nice generalization of BFS for weighted graphs. But maybe I didn't spell this right because when he writes his name, he writes it with a Y with a dash over it. So in reality on a Dutch typewriter, you might have a character that looks like this, Y with a umlaut on top of it. But on modern-- on an English keyboard, this looks pretty similar to an IJ. So in a lot of manuscripts, we write it as D-I-- there's no J sound in Dijkstra. It's coming from this is Y here.
4119	But the basic idea behind Dijkstra is the following idea. Relaxed edges from vertices in increasing distance from source. OK. This is the same kind of difficulty we had before when we were trying to generalize BFS. So how do we know what the next vertex is with increasing distance to s? Well, the second idea is find the next vertex efficiently using a data structure. And the data structure we're going to use is something I like to call a changeable priority queue. So this is a little different than a normal priority queue that we had at the end of our data structures unit. This changeable priority queue has three operations. We're going to say it's a queue. We can build it on an iterable set of items. Just stick x-- like n items in there. We can delete min from the queue. OK, this is the same now as the priority queue. It's this third operation that's going to be different. Decrease the key of an item that has id, id. OK, so this is a little
4120	strange. What the heck is this id? All right, with a change of priority queue, each of our items has two values instead of one value. It has a key, but it also-- on which the priority queue is leading the min item with the minimum key. But also, each item has an ID associated with it, a unique integer. So that when we perform this operation, decrease_key, it can find some item in our data structure with the given ID. And if it's contained there, it's going to change its key to some smaller value k. And don't worry about the edge cases here. We're always going to make sure this k is going to be smaller then whatever that key was to begin with. So this is really a kind of a funky operation. If I had a priority queue, not a changeable priority queue,
4121	to implement a change of priority queue, how could I do it? Well, a regular priority queue is already going to get me these two operations. It's just this one. I essentially need to find something by an ID and then update its key. So the idea how to implement this is going to be to use a regular priority queue. I'm going to call it Q prime. And I'm going to cross-link it with a dictionary D. So these are just regular priority queue on my items that has the key as defined above. But I'm going to cross-link it with a dictionary, a dictionary that maps IDs to their location in the priority queue. We've done this many times in the data structures section. We're trying to cross link to data structures to make a query on a different type of key to find its place in another data structure. So, if we had a priority a dictionary, we could do this stuff pretty fast. In particular, I'm going to assume that our IDs of our vertices are
4122	the integers between 0 and v minus 1. And so for my dictionary, I could get constant time looking up of that ID by using what data structure? AUDIENCE: Hash table. JASON KU: We could get-- OK, so we could get expected constant time if we used a hash table. But if we knew that our vertex IDs were just the numbers from 0 to v minus 1, we could get rid of that expected time by using a direct access array. Great. OK, so that's the assumption. And so really, the name of the game here is to choose a priority queue here that's going to make these things fast when we start to look at Dijkstra. OK, so we're going to use this data structure to keep track of our distance estimates
4123	OK, so this is Dijkstra's algorithm. OK. Set-- so same initialization step. We're going to set-- this is a distance estimate d, not delta. We're going to want the d's be our delta is at the end of the algorithm. That's what we're going to have to prove. So we first set all of them to infinity, and then set d of s, s equal to 0. And here, we're never going to update it again, because our shortest distance is in a graph with non-negative edge weights certainly can't go below 0. All right. Now we build our-- build our changeable priority queue-- queue-- with an item-- I'm going to say an item is-- x is represented by a tuple of its ID, and then its key just for brevity here. With an item v, d of s, v. So I'm going to be storing in my changeable priority queue the vertex label and its shortest-path distance estimate d. And that's going to be the key, the minimum that I'm trying going to be querying on for each the
4124	v and V. So I'm going to build that thing. It's going to then have all of my vertices in my graph. Then while my changeable priority queue still has items, not empty, I'm going to delete some u, d s, u. So some item such that its distance is minimized from Q that has minimum distance. OK. So I'm going to I'm going to look at all the things in my priority queue. At the start it's just going to be s, because everything as shortest-path distance estimate infinite except for s. And so that's clearly the smallest. OK, so I'm going to remove that from my queue, and then I'm going to process it. How am I going to process it? It's the exact same kind of thing as DAG relaxation. I'm going to relax all its outgoing edges. So just for completeness for v in the outgoing adjacencies of u, I'm going to relax-- sorry. We have to check whether we can relax it. Basically if the shortest-path distance estimate to v is greater than going to
4125	u first and then crossing that edge, if going through that is better, this is violating our triangle inequality. And so we relax edge u, v, and by that we mean set this thing to be equal to that thing. That's what we meant by relax. And then we have one other thing to do. We have changed these distance estimates but our Q doesn't know that we change these things. We added these items in here. But it doesn't know that my distances have changed. So we to tell the Q to remember to change its key value associated with the item v. So decrease-- what is it? Decrease key vertex v in Q to the new d s, v, the one that I just decreased here. And I know that I decreased it because I said it to a smaller value. That makes sense. All right, so that's Dijkstra. Let's run it on an example. So here's an example. I have a directed graph. It does contain cycles. In particular, here are some cycles. I think those are
4126	the main ones. There are definitely cycles in this graph. But as you see, all of the weights are non-negative, in particular-- they're positive, actually. It's going to be just helpful in writing out this example. So let's run Dijkstra on this graph. First we initialize and we set the shortest-path distance. I'm going to label it in white here to all of the things. Then I'm going to, as I update it, I'm just going to cross them out and write a new number. So that's what it is at the start. That's initialization, that's after step 1. And then I stick things into my Q. What's in my Q? Here's my Q. It's everything. It's vertices s, a, b, c, d. I got five items in my Q. Really, it's the item pair with its shortest distance estimate, I'm just not going to rewrite that here. So the idea here is-- the while loop, OK. Q is not empty, great. We're going to delete the one with the smallest distance estimate, which is s, right, yeah. So I
4127	remove that, and then I relax edges out of s. So I relax edge here to a. That's better than the distance estimate-- 10 is better than the distance estimate infinite, so I'm going to change this to 10. And then here's another outgoing edge. 3 is better than infinite, so I'm going to change its delta to 3. OK. So now I go back in here and I change the distance estimates associated with my Q. Now, next step of the algorithm, s is done. I've processed everything distance 0 away. But I'm now going to use my priority queue to say which of my vertices has the shortest distance estimate now. So which one is it? a, b, or c, or d? Yeah, it's 3 and c. 3 is smaller than 10. So Q is going to magically delete c for me, tell me what that is, and now I'm going to process that. Now I've changed my boundary to this. And now I relax edges out of c. So here's an edge at a c, that's a
4128	4. A 4 plus the 3 is smaller than 10, so I update it. 3 plus 8 is 11, that's smaller than infinite, so I update it, I relax. 3 plus 2 is smaller than infinite, so I relax that as well. Now of the things still left in my Q, I'm actually going to remove it from my Q instead of crossing it out, maybe that's better. Of the vertices still left in my Q, which has smallest distance? Yeah. d. d has 5, 7, or 11. 5 is the smallest. So I remove d from my cue and I relax edges from it. And now my boundary looks something like this. I relax edges out of it. 5 plus 5, that's 10. 10 is smaller than 11, so that's a 10. And that's the only outgoing edge from d. so I'm done. And then the last, 7 is smaller than 10, I relax edges out of a. a to b, 7 plus 2 is smaller than 10. And now I'm done. So what I did every time I
4129	removed s-- or I removed a vertex, I said its shortest-path distance to the small-- the last value I assigned to it. So this was then 3, and then a was 7, b was 9, and then d was 5. So that's Dijkstra in action. It seems like these are the shortest-path distances, but how do we prove that? Did it do the right thing? Well, let's find out.
4130	just talking about the correctness of Dijkstra's algorithm. OK. Correctness follows from two main observations. So the claim here that we're trying to prove is that d of s equals the delta s-- so the estimates equal the shortest-path distance is at the end of Dijkstra for all v and V at end. And this is going to follow from two observations. So the proof here, first, if ever relaxation sets d of s of v-- it sets the estimate equal to the shortest-path distance, if it ever does that, I argue to you that still true at end. OK, that's not a very strong statement. This is saying if I ever set the distance estimate to the true distance, I'm never going to set it to a different value later on. And why is that? Well, relaxation only ever decreases the distance. Relaxation only decreases d s, v. But we proved in lecture 11-- so two lectures ago that relaxation is safe. And what does safe mean? Safe means that relaxation-- that relaxation will only ever change these distant
4131	estimates to be either infinite-- it was never-- there was never a path to my vertex. Or it was the length of some path to v. Length of some path. OK. So what does that mean? It only decreases, but it's always the length of some path to v. So if this is the length of the shortest path to v, I could never set it to a smaller length, because there are no paths with shorter distance. That's the whole point. OK. So with this observation, I'm going to argue this final claim. It suffices to show that my estimate equals the shortest distance when v is removed from the Q. And since I removed every vertex from the Q in this while loop, I will eventually said to all of the distance estimates to the real distance and we'll be golden. Happy days. All right. So we'll be done if we can prove that statement. All right. So we're going to prove this by induction obviously. Induction on first k vertices removed from the Q. So the Q,
4132	we're popping vertices from this Q in some order. So I'm going to just argue that this claim is true for the first k. Clearly that's true for k equals 1. Base case, k equals 1. What is k equals 1? That means the first word vertex that I pop has this property, which is definitely true, because we set the shortest distance to s to be 0. That's all good. Now we have our inductive step. Assume it's true for k prime-- sorry, k less than k prime. And let's let v prime be k prime vertex popped. v prime. OK. And now let's look at some shortest path from s to v prime. So we got the shortest path from s to v prime. It exists. v prime is accessible. Let's say we pruned our graph to be only the things accessible from s so that, yeah, there exists the shortest path to v prime. And now let's think about these vertices. Some of them were removed from the Q and some of them were not. s was
4133	definitely removed from the Q. But some of these other vertices might not be. I want to be able to induct on this path, in particular, the vertex before me so that I can say that when I removed it and I relax the edge to v prime, then we're all golden. But that might not be the case. There could be a vertex, the vertex preceding me in the graph in this shortest path that was not popped from Q. I need to argue that it was or some other thing. So let's consider the first vertex in this path from s to v. I'm going to call it y, I think. Yeah. A vertex y that is not in Q. After I pop v prime, this is the first-- or before I pop v prime, y is not in the Q. Now these might be the same vertex if all of the preceding ones on this path were in the Q. But in particular, we're going to look at this guy. And say its predecessor's x in the
4134	path. Well what do I know? I know that x is in the queue. Everything here was popped from the Q-- not in. Which means that by induction, the shortest-path distance was set here correctly. So that the distance estimate at y can't be bigger than the shortest path to x plus w x, y. But this is on the shortest path to y, because the subpaths of shortest paths or shortest paths. So this has to equal d s, y, the distance to y. So actually, y is all good here. And so if v prime were y, we'd be done. That's the same argument is DAG relaxation. But we need to prove something about v prime. Well, because we have non-negative weights, the distance to v prime has to be at least as big as this distance, because it's a subpath. So this has to be less than or equal to the true distance to v prime. Because of negative-- non-negative weights, because the weights are non-negative. But because relaxation is safe, we know that our distance estimate
4135	for v prime has to be at least the shortest-path distance. This is because it's safe. This is-- weights are greater than or equal to 0. The last step here is that because we're popping the minimum from our priority queue, the thing with the smallest shortest-path distance, this has to be less than or equal to the shortest-path distance estimate to y. Because this is the smallest among all such vertices in my Q. But these are the same value. So everything between here is the same value. In particular, the estimate here is equal to my true shortest-path distance, which is exactly what we're trying to prove. OK, so that's why Dijkstra's correct. I'm going to spend the last five minutes on the running time of Dijkstra. We set this up so that we did everything in terms of these Q operations. Right so we have these Q operations, we have three of them. I'm going to say if I have a build operation, let's say it takes B time; to lead min, I'm going to say it
4136	takes M time; and this decreased key,
4137	So what is the running time of Dijkstra? If I take a look at that algorithm over there-- well I guess let's switch these back up again. OK, so what does this do? We build once. Then we delete the minimum from the Q how many times? v times. We remove every vertex from our Q. Then for every possible edge, we may need to relax and decrease the key in our queue once for every outgoing edge. So the running time is B plus V times M plus E times D. OK. So how could we implement this priority queue? Well, if we use the stupidest priority queue in the world, here's a list of different implementations we could have for our priority queues. And when I say priority queue, I mean this priority queue. We're already implementing the changeable priority queue by linking it with a dictionary that's efficient If I just use an array, I can find the min in linear time, sure. And I don't have to update that array in any way. I mean, I
4138	can just keep the distances in my direct access array. I don't have to store a separate data structure. I just store the distances in my direct access array D, and so I can find it in constant time and I can update the values stored there. And then whenever I want the minimum, I can just loop through the whole thing. So that gives me a really fast decrease key,
4139	But if we take a look at the running time bound here, we get something, if we replace n with v, we get a quadratic time algorithm in the number of vertices, which for a dense graph, this is in linear time. That's actually pretty good. Dense meaning that I have at least a quadratic number of vertices. So that's actually really good, and it's the stupidest possible data structure we could use for this priority queue. Now we can do a little better, actually, for not dense-- I mean, for sparse graphs where the number of edges is at most v, then this is pretty bad, it's quadratic. We want to do something a little better. Now if we're sparse, a binary heap can delete min in logarithmic time, but it can actually, if I know where I am in the heap and I decrease the key and I'm in a min heap, I can just swap with my parent upwards in the tree in log n time and rebalance the-- refix the binary heap property. And so I
4140	can do that in logarithmic time. And if I do that and I put it into this formula, I actually get n-- or V plus V times log V plus E times log V. And so that's going to give me E log V if I'm assuming that I'm first pruning out all of the things not connected to me, then E asymptotically upper bounds V, and I get this E log V running time, which is pretty good. That's just an extra log factor on linear. Now there's an even better-- well, better is hard to say. Really, there's a different data structure that achieves both bounds for sparse and dense graphs and everything in between.
4141	This data structure is called the Fibonacci heap. We're not going to talk about it in 6.006. They talk about it-- and you can look at chapter 19 in CLRS or you can look at-- I think they talk about it in 6.854 if you're interested in learning about Fibonacci heaps. But these are almost never-- I mean, they get good theoretical bounds. So what you want to say is, whenever we give you a theory problem where you might want to use Dijkstra, you want to use this theoretical running time bound for your problem E plus V log V. But if you happen to know that your graph is sparse or dense, just using an array or a heap is going to get you just as good of a running time. Very close to linear. And so in practice, most people, when they are implementing a graph search algorithm, they know if their graph is sparse or dense, and so they never bother implementing a Fibonacci heap, which is a little complicated. So they're usually either in one
4142	of these first two cases where V squared is linear when your graph is dense, or we're very close to linear, E times log V, which is V log V if your graph is sparse. So that's the running time of Dijkstra. So so far, we've gotten all of these nice bounds. Some special cases where we're-- I mean, special cases where we're linear. Dijkstra where we're close to linear. And Bellman-Ford, if we throw our hands up in the air, there might be negative cycles in our graph, we gotta spend that quadratic running time bound. Now there are faster algorithms, but this is the fastest we're going to teach you in this class. Now and in the next lecture we're going to be talking about all pair shortest paths, and we'll pick it up next time.
4143	all right let's get started welcome back to double06 today we are doing some of the coolest data structures we will see in this class
4144	uh you've certainly seen trees in many forms uh in the past including in this class we've talked to use trees as a lower bound tool for uh in the decision tree model but this lecture and the next lecture we're going to build one data structure that is almost superior to all data structures we have seen and can do almost anything really fast first recall all the data structures we've seen so far arrays linked lists dynamic arrays sorted arrays hash tables and the two sets of operations we're interested in supporting the two interfaces one was sequences where we're maintaining items in a specified order we want to be able to insert an item right after another item or delete an item in the middle of the list and always be able to access the ith item we haven't seen any good data structures for that problem we we're really good at inserting and deleting at the beginning or the end of the sequence but we haven't seen anything that's efficient at ins inserting in the middle
4145	of the list or deleting in the middle of the list linked list you can't even get to the middle in less than linear time uh array you can get to the middle but if you make any changes you have to do this shift which is very expensive so today or sorry next lecture for the first time we will see all of those operations efficient i'll mention our goal where efficient means logarithmic so we're not quite as good as linked lists and dynamic arrays at inserting and deleting at the ends those there that we achieve constant or constant amortized time but up to this log factor we're going to get the best of all worlds where we can solve all the things all the operations that don't build or iterate through the entire structure that of course takes linear time but we can do all the others in logarithmic time for sets sets were maintained maintaining a bunch of items which have intrinsic keys and we want to search by key so hash tables are great
4146	if you're only doing exact searches if you want to find a key and get yes or no is it in there and if it's in there give me the item that's what python dictionaries do and they're great at inserting and deleting but they're really bad at find previous and find next this is a the unsuccessful case if i search for a key and it's not in my structure i would like to know more than just the answer no i'd like to know what the previous and next items that are actually in the structure so what are my nearest matches when i search by key that's a natural query and the only data structure we have that's good at it is a sorted array because binary search gives this to us if we search for a key by binary search and we don't find it the position that we end up at is right between the previous and next one but of course sorted arrays are terrible for dynamic operations we don't know how to maintain
4147	we can't maintain a sorted array without any gaps when we're doing insertions and deletions in some sense today and next class binary trees let us represent a sorted order or in general an order of items dynamically and still allow us to do very fast things like get out of i and find previous of the key so that's our goal we're not going to quite get to this goal today we're going to get an incomparable thing called the height of the tree and then on thursday we'll be able to finish and
4148	so what is a binary tree let me draw an example and then define it more precisely mathematicians will call this a rooted binary tree because in case you've seen that in o42 say here is a picture
4149	so this is an example of a binary tree it has a bunch of nodes which we're drawing in circles it has items in the nodes which were i'm writing as letters here so this is item a item b item c and it has these links between them this is like linked lists but in general a node x is going to have a parent pointer a left child left pointer and a right child right pointer and it also has an item inside of it so i'm going to talk about node.left is a pointer to the left the node down here node.right node.parent node.item gives me so if i look at the node a its item is a so let me draw for you some examples okay the parent of a is nothing so we call a the root node there's going to be a unique node that has no parent it's uh sad to have no parents but there you go then we have node b which whose parent is a node c is parent its
4150	apparent is a node d its parent is b node e its parent is b and node f its parent is d alphabetical order here happens to be ordered by parent
4151	then we have left pointers i'll just do a few of them so left pointer of a is b right pointer of a sorry b the node uh these should all be notes i'm circling for nodes and just writing the letter for the item make it clear that those are different things uh the right pointer for a is c left pointer for b is d right pointer for b is e and so on okay so in other words each of these lines is a bi-directional pointer uh in this direction it's the parent direction in this direction it's left in this case because it's bidirectional we don't draw the arrows we just draw undirected lines okay this is in general what a binary tree looks like a key invariant is that if you take a node and say go to its left pointer left child and then go to that node's parent this should be the same as node right so that's just saying these are in parent is always the inverse of a left or right
4152	operation this is also true for write okay and that's a binary tree now the intuition of what's going on here is you could you could say it's we're inspired by a linked list linked list had a very similar structure maybe an item or there's a node it had an item in it and it had a next pointer and it had a previous pointer so in some sense what we're if it's doubly linked we had a previous pointer it was singly linked we only had a next pointer and if you think about the limits of linked lists especially singly linked lists if you just have one pointer per node you can only build a list and so the result is uh you know this this node is going to have depth linear depth means how many pointers do i have to follow to get here from the root of the structure which for linked lists was the head it was doubly linked okay i can have a head and a tail and i can put bi-directions
4153	on here but then still the middle item has depth linear so there's no way to get there in less than linear time with binary trees because we use two types of next pointers left and right we can build a tree and we know trees in general have logarithmic can have logarithmic height and so it's possible in a tree to get to any node starting from the root in only log n traversals so that's the intuition of what's going on now today we're going to talk about the height of a tree so let me define i'm going to need a couple definitions here
4154	subtree and height of a node uh so a tree decomposes into sub trees so for example the subtree rooted at b or the subtree of b is this portion of the tree so it's that node and all of the descendants of this node so because we have parents and children we can generalize in the familial tree sense we can talk about ancestors of a node so the ancestors of f are its parent its grandparents its great grandparents and so on together all of these are called ancestors it's a it doesn't quite correspond to familiar trees because familial trees you have two parents here you only have a unique parent or the poor root has no parent we also talk about it's like mixed metaphors leaves of the tree these are people with no children parents will complain about this but many like many of us in this room we have no children yet so we were called leaves you can tell your parents hey i'm just a leaf you know blowing in the wind so
4155	uh you know like this it's so many mixed metaphors but we always draw trees downwards like the root structure of a tree yet we call the ends of the roots leaves which is upside down anyway that's trees for you lots of entertaining analogies okay but ancestors are useful descendants are also useful so the descendants of b are all of its children and all of its grandchildren and all the way down but just within the subtree so subtree of x consists of x and its descendants and we think of x being the root of that subtree so we're kind of forgetting about everything outside of the sub tree when we talk about sub tree of x let's talk about the depth of a node depth of the node is i guess the number of its ancestors right um but way i usually think of it is the number of number of edges and in the path from x up to the root so every node has a unique path that goes upwards until it can't go
4156	up anymore so the depth of e is two because there are two edges uh one two in the path from the root a to e so maybe i'll write some depths uh depth of e is two depth of these guys is one depth of the root is zero two three so those are depth i'm going to clean this up a little bit so we can focus on the image all right height so depth is measuring downwards because we you know if you imagine depth within water this is uh the surface of the water and then we measure how deep you are from the surface height is in the reverse direction we're going to measure from the leaf level up because leaves are the bottom of the tree so height of a node is going to be the number of edges in the longest downward path okay which is the same thing as the maximum depth of a node in x's subtree let's do height in red so uh how long is the longest path from
4157	f to a leaf well f is a leaf so all leaves have depth zero sorry height zero get it backwards um d here it's so there are two ways to go down this doesn't go to a leaf uh this one goes to a leaf and its height is zero so this height is one there's one edge to a leaf here b has two leaves it can get to we take the longest one so that's length two a similarly has height three okay so height we measure upward depth we measure downward well one thing we care about uh is just the height of the overall tree uh which is the height of the root and i'm going to call that h because we're going to use it a lot and what we're going to achieve today is all of these running times instead of being log n they're going to be order h so today our goal is to get all the operations we care about in order h type and then next lecture we're going
4158	to guarantee that h is always log n and then we'll get log n time so we need to do a bunch of work to achieve log n today we'll do the work that's all the tree manipulation and as long as your tree is nice and shallow it doesn't have high height if it has logarithmic height everything will be log n of course there are trees that are really bad right we can have a tree a tree like this which is basically a linked list where we only use right pointers and all the left pointers are none so there are height there are trees that are very high have high height um we want to avoid these but we won't worry about that till next lecture question what is the height of node c height of node c is zero because the length of the longest path the number of edges in the longest downward path is zero yeah we're counting edges not vertices uh yeah so the height of the tree is of course just
4159	the depth the maximum depth i think that's right so the height here is three and the maximum depth is this terribly drawn three so these happen to correspond in the maximum case but we use height to always mean maximum and so that's why we talk about the height of the tree depth of the tree is not defined just depths of notes okay um how do we use these trees to represent either a sequence or a set uh i claim that there is a natural order in trees called the traversal order of nodes or items and the tree so i'm going to define a particular order uh say in this example let's do the example first the traversal order is going to be f d b e a c i feel like i'm in music class this is my guitar or something but it's not i hope um if it is a coincidence so what is this order what i'd like to do is um recursively define an order where the root of the tree is
4160	somewhere in the middle and everything in the left subtree is left earlier in the order than the root and everything in the right subtree is later so you can see here c comes after a and then all the other nodes come before a and recursively if i look at a node b this node b which appears over here e is to the right of it but it's this is all to the left of a so e is between b and a would be on the left and then f and d are to the left of that and again f comes before d because f is in the left subtree of d okay so we say for every node the nodes in x dot left are before x and the nodes in x dot right are come after x and this uniquely defines an order called a traversal order it's also called the in-order traversal order it's called in order because it's in the traversal order so it's very circular but you may have seen inorder
4161	traversal this is the same thing there's a very simple algorithm for computing this if i want to iterate uh let's call this yeah if i want to iterate all the nodes within a subtree x rooted by x i just iterate on all of the nodes in the left subtree then i output x itself then i iterate on all the nodes in the right subtree okay you may have seen that algorithm before this is just another way to codify the same thing the result is all the nodes within a subtree appear continuously with no interruptions and then the parent parent's going to come before after depending on whether it's the left or right child okay so and now it's just a matter of connecting the dots because we're representing an order and for sequence that is going to be the sequence order if we want to store n items x0 through x1 we're going to build some kind of tree we're going to put x0 here x1 here x2 here x3 here x4 here x5 here
4162	you can see i'm very used to dealing with traversal orders it takes a little while uh you could also see it here we're going to put x1 on this node x2 sorry x0 here x1 here x2 here and so on that's the same order that i gave okay that's for sequences for sets that order is just going to be the sorted order and we're going to be effectively representing the sorted order of keys say increasing but before we get to that let's talk about different operations we can do just playing around with traversal order and then we're going to use these to build the sequence and set operations that we care about so first operation i'll call subtree first seems appropriate that it's called first it's the first one so given a node which i'll call node uh this defines a subtree which usually we draw subtrees as triangles hanging off of the node so here i would write x and then there's some subtree of all the descendants of x so with subtree first
4163	i would like to say among all the nodes in this subtree which comes first in traversal order so just restricting to that subtree so tree of that so where is it in this tree uh note is actually part of many sub trees good question uh f f is in its own in the sub tree of f uh f is also in the subtree of d f is in the sub tree of b like i drew f is in the subtree of a it's in the subtree of exactly its ancestors but in this operation when we define node our node only defines one sub-tree it is the root of only one sub-tree and that's the sub-tree we're talking about and then i want to know among all those nodes which includes node itself and other things uh which one comes first in this traversal order this is like practice with traversal orders so where should i look for this node yeah the leftmost leaf in the picture it's here but pictures can be deceiving we just
4164	want to go left as much as possible when i say go left i mean this iteration node equals node.left you just look at our definition all the nodes on the left come before x and all the nodes in the right so it's got to be in the left subtree if there is one uh of course we can't do this forever so say until we would fall off the tree which means uh node is none okay but we stopped uh before that would happen so this is like uh the directions like oh you keep driving until you see the store and it's the block right before that it's like well that's not very helpful so uh you keep iterating node equals no dot left until node becomes none and then you undo one step okay you all know how to program that it's not hard um so that last non-none node which might actually be the root it might be node maybe it has no left children but in that case i claim node is the
4165	very first in its in its subtree traversal order because if there are no nodes in the left that come before x then x is actually first okay and that so that's it uh return node so i'm modifying node in place here and the very last one before i hit none that's the minimum that's the first item in the traversal order similarly you can define subtree
4166	successor node so in this case i want to know what is the next after node in the overall tree's traversal order okay here i was restricting to uh a single sub tree now i'm thinking about the entire tree in the entire traversal order and given a node i want to know which one comes next call this the successor i feel like i should make some kind of royal family joke now but i don't know how um so every node has a unique successor let's do let's do some examples so we can start with f the successor of f if we just index into this list the successor is d okay successor of d is b successor b is ease okay it's very easy to read successors off when i have the traversal order written down but let's think about how to do it in the tree okay uh let's see there are going to be two cases if i look at the successor of a it has a right child and in this case the
4167	right child of a is the successor but that's not always the case i don't have a good example but if i had another node here let's call it g uh the successor of a is actually g right because all of these items come after a in the order but which one comes first the leftmost leaf okay that's the problem we just solved so if a has a right child what we want is the leftmost leaf the first thing in that subtree the right subtree right child sub tree so this is case one if uh node.right so if we have a right child then what we want is subtree first of the right child great we can reduce to this other operation but what if the node doesn't have a right child so for example it could be a leaf say we're taking the successor of i mean it doesn't have to be a leaf could be f which has no children it could be d which has one child but no right child so what's
4168	the successor of f well it's d which in this case is the parent but it's not always for example if we do successor of e its parent is actually earlier in the order because e was a right child here f was a left child and so its parent was after successor of d happens to be b because uh it's per it was the left child of its parent okay so that seems like the easy case if we're the left child of our parent then our successor is our parent okay basing on this small example but we can argue it generally in a moment what's the successor of e uh well it's not b because that comes earlier in fact all the things in this in b sub tree come earlier or equal to e um so we have to keep going up and then it turns out the successor of e is a because this subtree was the left child of a because b was a left child with a so the general strategy is
4169	walk up the tree until we are we we go up a traversal whose reverse direction would be left okay so um walk up the tree when i say walk up i mean node equals node.parent iteration until we go up a left branch so this would mean that node before we do the change node equals node.parent node.parent.left okay so we can check that and then after we do that traversal that parent is exactly the node we're looking for okay why is this true in general let me draw a more generic picture so we're starting at some node and let's say its parent is to the right so it comes later in the order for a while sorry get this backwards we're doing successor so it goes to left for a while so these are all these nodes will come earlier in the order because by the definition everything in the right subtree comes after and at some point we have a parent that's to the right meaning this node was the left child of this parent
4170	and that node by definition will come after all of the nodes in here and could there be anything in between node and this uh this parent grandparent ancestor only if there was something in this subtree and we're in the case here where there is no right subtree of our original node so this this is where all the nodes in between node and here would be but there aren't any and therefore this is the successor so that's sort of the general argument why this works i see a question yeah placed into the traverse order so the traversal order is never explicitly computed what we're taught it's always implicit we can't afford to maintain this as say an array this is just in our heads maybe i will draw it with a cloud around it we're just thinking this okay it's not in the computer explicitly in the computer all we store is this and the reason is this is expensive we don't we can't maintain an array of things and be able to insert in the
4171	middle whereas this is cheap i can afford to maintain this structure and do all these things and so the reason we're talking about these operations is they're letting us manipulate the order or in this case letting us iterate through the order so this was an algorithm for iterating through the entire order but that takes linear time this was getting started in the order find me the first first thing the order and this was given one node find me the next one how long do these operations take right at most the height of the entire tree in fact it's going to be the depth of that first node but in the worst case that's the height of the entire tree in general all of these operations are going to be order h we need to think about it in each case except for this one which is order n so iterating through the whole thing um this in this case we're just calling subtree first so that takes order h time here we're walking up the
4172	tree instead of down but that's going to cost exactly the height of the node we happen to stop early but worst case order h for all this all the operations we consider today we just want to get an order h bound and later we will bound h so the point is these are fast if h is small like log n these are almost instantaneous whereas if i had to update the explicit traversal order say as an array i would have to spend linear time every time i make a change and yes it would be fast to do successor if i had this stored explicitly but maintaining it would be impossible maintaining it efficiently would be impossible question questions yes okay cool um so these were queries where i want to follow
4173	changing the traversal sequence so these are insert and delete operations these will correspond roughly to insert at or delete at but they're not quite we're not quite in
4174	inserting or deleting in the middle of a subtree so i'm going to have two nodes so the in the traversal order so node already exists in the tree new is a new node that does not yet exist in the tree hence i call it new and what i'd like to do is insert new right after node and there's a symmetric operation which is insert before it will be implemented almost identically so we'll just focus on after so i want to insert this new node in the traversal order which again is in our heads this is all in in our thought bubble that's what we want to achieve and we have to do it by manipulating this tree and however we change the tree it defines a new traversal order so maybe let's do an example first actually i probably want this universal order keep track of that so uh let's say the first thing we want to do uh is insert g before e i want to illustrate both of the operations insert h after
4175	e a okay um so insert g before e so conceptually what we want to do is insert g here and the way so we're given the node e and we're given a sort of empty node i mean a node that just contains g it doesn't have any pointers yet and we would like to put it before e where should i put it left child all right so that's this is an easy case if i'm trying to insert before and there's no left child stick it there if i'm trying to insert after and there's no right child stick it there easy so let me write down case one so here we're inserting after so if there's no uh right child put new there okay i'm using informal language here putting this new node there b instead of writing for example node.write equals new because that's only one operation you need to do one thing you would do is set node.write equals to new but you also have to set new's parent to be node.write so instead
4176	of worrying about those two pointer changes because we always do bi-directional pointer changes i'm just going to use pseudocode and then in recitation you'll see actual python code that does all this uh so then there's the other case so that should be the second example insert h after a right insert h after a so we already have a node after a in the right child in this right subtree so where do i want to put h relative to a well it should be to the right of a but it should be before c it should be to the left of c so that would mean we want to put it here okay in this case it was pretty easy because this tree was small where do i want to put it in general well wherever subtree first tells me to put it right subtree first is going to give me the successor these are all kind of parallel um we're in the case now where our node has a right child and then successor tells
4177	us where the successor is it is the first node which is the leftmost descendant in the right subtree of the node okay a lot of pointers to follow in that sentence but it's clear in the picture so this in this case we had node and there was no right child so we just added new to be its right child okay in the other case we had a right child so here is node there's uh there's this node here node.right which now we're supposing exists and it defines a whole subtree there's this one which is the first node in the traversal order of the subtree also known as the successor of node so i'll call this successor of node in the current traversal order but of course we'd like to make new the new successor of the node so where does it go here we want to add it as a left child to the old successor okay so put uh node as so take the successor and if you look at the code for successor
4178	we're in this case so we know it will just call subtree first of node.right and remember subtree first went left as much as it possibly could so what that means is this successor node is guaranteed to not have a left child right because it was defined by going right once and then going left as much as you could so there's no more left which means we can make one more left just add new there and we're done now if you look at the traversal order it will be node then new then the old successor and then the rest of that subtree okay it's kind of cool in all cases uh i mean this was constant time here we spent constant time after we called successor successor costs order h time so this is order h new new okay put new there
4179	get the spec right and the example all of these are going to have two cases uh so let me oh i didn't update so now h is after a so it should be like this you can check the new traverse order of this tree is exactly that
4180	next i'm going to do a couple of deletions let's delete f first and then we're going to well this is confusing and then we're going to delete a so where's f we're supposing we're given a pointer to f this node well it's a leaf so if i want to delete it i just erase it easy leaves are easy to delete there's no work to do so what that means is i'm removing the pointer from d
4181	suppose i want to delete the root of the tree this is kind of the hardest case but in general it would be somewhere in between leaf and root so if i want to delete a if i just erased it then suddenly there are these pointers to nowhere and i disconnect the tree into two parts i don't want to do that i need to keep my tree connected so i'm going to play this trick which is i forget if i use successor or predecessor predecessor so i'm going to uh look at a we already have defined successor and there by predecessor so i'm going to look at the predecessor of a which is e you can check that here the one before a is e this is in the left subtree uh find me the rightmost item keep going right until i can't that's e so now these guys are adjacent in the order and i'm about to remove a from the order so i can momentarily cheat and swap their labels i'm going to erase
4182	a and e here and put e after a why because it moves a down in the tree and if i get to the leaf i'm done so i'm not quite done because this is not a leaf so again i look at a's predecessor it's now g predecessor we hope is always in the uh farther down in the tree and then i swap a with g okay i have preserved the traversal order except where a falls just by moving a earlier in the order here and now a is a leaf and i can erase it okay so that's what we're going to follow now in actuality it's a little tricky sometimes we need to use predecessors sometimes we need to use successor okay so the cases are if the node is a leaf just detach it from the parent easy that's sort of our base case in the recursion otherwise there are two cases if so if we're not a leaf that means we have a left child or a right child or both both is
4183	going to be the easy case but in general i have either there's a left child or there's a right child in either case i'm going to be happy so i don't need a both case uh okay so what do i do in if i have a left child that guarantees to me that if the node's predecessor is inside that left sub-tree which means it's lower in the tree if i didn't have a left child the predecessor would actually be higher in the tree and i don't want to go higher okay so if i have a left child i know the predecessor is lower and so i'm going to swap my item the contents of my node with my predecessor's item and then i'm going to recursively delete the predecessor okay that's the case that we looked at in this code in this example because we always had a left child if we have a right child but no left child we just do the reverse we swap with our successors item and then delete the
4184	successor in either case we're going down and so if we start at some node like the route every time we do this operation we're walking down and then we're walking down and in general we'll keep walking down resuming where we left off which means total amount of time we spend is proportional to the height of the tree in the worst case question right so e didn't used to have a right child so we're changing identities of nodes when we do this because we uh this that we didn't actually move this circle the circle stayed in place and what we changed was the item that was stored in that circle so whether you call this node e or a it doesn't really matter it is just the root note okay so we're gonna play a lot of these tricks of moving the items around so far we hadn't been doing that we've just been creating nodes and placing them somewhere but now we're in this delete operation is the first time where we're changing what's stored
4185	in the nodes but we still can define the traversal order right the traverse order of this tree is dbgehc which should be what we get here if i delete f and a and sorry can f trees will not preserve connections that's just the name of the game we are we have to allow this otherwise we can't do anything that's the short version okay okay in the last few minutes let me talk about how we take these trees and implement a set or sequence okay i've already alluded to this so for a sequence we just make the traversal order equal to the the order that we're trying to represent the sequence order and if we're trying to source set items with keys we're going to make the traversal order equal to ordered by increasing key increasing item key some sense that's it but then we need to think about how do we implement all of these operations so maybe most enlightening is for starters is finding a key in a tree so this is going to
4186	correspond to binary search if i'm searching for a key let's say i'm searching for g's key and i know this may be hard in this example maybe i'll replace these all with numbers so i can think about key values okay so let's say 1 7 12 17 19 and 23. this is now in key order if you think of the traversal order the property is that all the keys in the left subtree of the root are less than the root and the root is less than all the keys in the right subtree and recursively all the way down this is something called the binary search tree property bst property these here we're calling them binary tree
4187	search trees term you may have heard before so this is a special case of what we're doing where we're storing the keys in order and then if i want to search for a key like uh 13 i compare that key with the root i see oh it's not equal and it's to the left because it's less than 17. so 13 is left of here 13 is right of 7 13 is right of 12 and so i know that this is where 13 would belong but there's no right child there and so i know in find i just returned nothing if i was doing find previous i would return this note because i have tried to go to the right the last time before i fell off the tree i was trying to go to the right and therefore that last note i had was the previous item if i was trying to define next what would i do i would just take this node and compute its successor which we already know how to do
4188	and that happens to be the root okay so now i can do these inexact searches when i do find previous and find next when i fall off the tree i find either the previous or the next and then with predecessor or successor i can find the other one okay so that's how we can do find and find previous and find next to do uh sequences we need a little bit more work we'll do that next time
4189	[SQUEAKING] [RUSTLING] [CLICKING] ERIK DEMAINE: All right, welcome back to 006. Today we start a totally new section of the class. Up till now, we've mostly been showing you really cool and powerful algorithms, sorting algorithms, graph algorithms, data structures, trees, lots of good stuff that you can apply to solve tons of algorithmic problems, either by reducing to the data structures that we showed you, or reducing to graph problems that we showed you, or by modifying those algorithms a bit. Today we're going to start a new section on algorithmic design-- how to, from scratch, come up with a polynomial time algorithm to solve a problem. And in particular, we're going to talk about a algorithmic design paradigm called dynamic programming, which is extremely powerful. It's probably the most powerful algorithmic design paradigm. Very general. Can solve lots of problems. It's a particular type of recursive algorithm design. And in general, this class-- all of algorithms-- is about recursive algorithm design at some level, because we want to write constant-sized pieces of code that solve problems of arbitrary
4190	size. We have some problem size n and we're trying to write 100 lines of code or whatever, some constant amount that doesn't depend on the problem size. We have one algorithm that solves all instances of the problem. And so we have to write code that is recursive or uses loops or somehow reuses the instructions that we give the computer. And you may know you can convert any algorithm based on loops into an algorithm using recursion. And we're going to take the recursive view today, in particular because it fits very well with our proof-by-induction technique, which we've used throughout this class, but also because it gives us some structure on how different subproblems relate in something called a subproblem graph, that we'll be talking about today. And so we're going to start out with, in general, how do we design recursive algorithms? That's sort of the overall, encompassing everything. We have thought very hard to come up with a cool acronym for this paradigm which we invented called SRTBOT-- thanks, Jason. And so we'll talk-- it's
4191	not actually for sorting. It's just an acronym for sub-problems, relations, topological order, base case, original problem, and time. But it's an acronym that will help you remember all the steps you need in order to specify
4192	And dynamic programming is going to build on this template by adding one new idea called memoization, which is just the idea of reusing work that you've done before. And that's going to let us solve tons of problems. And let's see. I don't-- let's get into it. So we'll start out today with SRTBOT. So here is SRTBOT down the column here. This is a recursive algorithm design paradigm. And in general, what we're going to do is take the problem that we actually want to solve and split it up into lots of possible sub problems. And so the first part is to define what the heck are the subproblems. In general, we'll want some polynomial number of them. But it's pretty open-ended what these look like. And the hardest part, usually, in defining a recursive algorithm is figuring out what the sub problems should be. Usually they're related to the problem you want to solve. Often the problem you want to solve-- this is actually near the last step-- the original problem you're trying to solve is
4193	often one of these sub problems. And then you use the smaller sub problems in order to build up the final, original problem. But sometimes at the end, you need to take a bunch of subproblems and combine them into your original problem. You can think-- one analogy you can think of here is divide and conquer algorithms, which also had this kind of style. But more generally, we're going to relate different sub problem solutions with some recursive structure-- some recurrence relation. This is just a recursive algorithm that defines how to solve one problem in terms of smaller sub-problems for some notion of smaller. And this is given by the topological order. So if we think of the subproblems as a graph and we draw an edge between-- so the vertices of the graph are sub problems. The edges are the dependencies between those subproblems. Then what we'd like is the topological ordering, the topological sort problem we talked about in the context of DFS or DAG shortest paths. What we would like is that the subproblems and
4194	the calls-- the recursive calls between them in this recursive relation-- forms a DAG. We want it to be acyclic, otherwise you have an infinite loop in your recursive calls. If you have a cycle, you'll never terminate. And so to make sure that these dependencies between subproblems given by this recurrence relation is acyclic, one way to do that is to specify a topological order. Or you could prove it some other way. But often it's just a for loop to say, just do it in this order. Then of course any recursive structure needs base cases. So that's a useful step not to forget. We want to solve the original problem using these sub problems. And then we analyze a running time at the end. So six easy steps. Actually, the hardest ones are these two, which are interrelated. And what we're going to see over the next four lectures-- this is the first of four lectures on dynamic programming-- is lots of examples of applying this paradigm over and over together with the memoization idea, which we'll
4195	get to soon.
4196	which is merge sort, so a divide and conquer algorithm, phrased with this structure of SRTBOT. So for the sub problems-- so our original problem is to sort the elements of A. And some sub-problems that we solve along the way are sorting different sub-arrays of A. So for every-- well, not for every i and j, but for some i and js, we sort the items from i up to j minus 1. So I'm going to define that subproblem to be s of ij. So this is something that I might want to solve. The original problem that I want to solve is s of 0 comma n, where n is the length of the array. So that's what I actually care about in the end. But we're going to solve that by writing it recursively in terms of sorting different sub-arrays as follows. This is the recurrence relation. I've written it very simply here. Of course, there's a merge algorithm, which is somewhat complicated. But as we saw the two finger linear time merge algorithm, given two
4197	sorted arrays-- so this is supposed to be the sorted array version of the items i through m. m is the middle element between i and j and the sorted array of the items from m up to j. If we merge those, that gives us the sorted array from i up to j. And that's exactly what merge sort does. So in general, this relation is just some algorithm for if you're given the solutions to some smaller subproblems, how do I solve the subproblem that I want to solve? And so we need to make sure that this problem is bigger than the ones that we recursively call on and that we don't get an infinite cyclic loop of recursions. And here our valid topological order is to say, solve these problems in order where j minus i-- the length of the sub-array-- is increasing. And then you can check because m is strictly between i and j. As long as we're not in a base case, then we know we can-- these subarrays will be smaller than
4198	this one. And so this increasing order gives us a valid topological order on all of the problems, all the subproblems. We have a base case, which is if we don't want to sort anything, that's the empty array, or at least in the original problem. And then running time is-- I mean, there's no better way to solve it than the recurrence that we already saw how to solve. So this is just another way to think of n log n
4199	Let's get to another problem that does not fit recursion so well. But we can make it better. So this is-- we're going to start with a very simple problem, which is computing Fibonacci numbers. It's really just a toy problem to illustrate a very powerful idea, which is memoization. So the problem I'm interested in is I'm given a particular number, n. And I want to compute the nth Fibonacci number. And in case you forgot, the nth Fibonacci number is given by this recurrence. fn is fn minus 1 plus fn minus 2 with base case, let's say, f1 equals f2 equals 1. And so we'd like to compute this. This seems-- this is a recurrence. So it seems very natural to write it as a recursive algorithm. So let's try to do it. We start with what are the sub problems. The obvious sub problems are just the various Fibonacci numbers, f i for i between 1 and n. So there are n of these sub problems. Cool. Let's see. We want a relation between them. Well,
4200	maybe just to distinguish the problems from the Fibonacci numbers, let me write f of i. This is a function, an algorithm we're going to define. And it's defined to be-- the goal we're trying to get is the ith Fibonacci number given i. And then we can write the recurrence relation on these guys, just f of i equals f of i minus 1 plus f of i minus 2. So in other words, recursively compute those Fibonacci numbers then add them together. That's an algorithm. Next is t for topological order. Here, of course, we just want to compute these in order of increasing i from the base case is up. Another way I like to write this is as a for loop for i equals 1 to n. We will see why. But this gives an explicit order to compute these sub problems. And base case is just the same as the Fibonacci numbers, but I guess I should write in parentheses. The original problem we want to solve is f of n. And the time-- all
4201	right, here's where things get interesting or bad. So what is the running time of this recursive algorithm? As I've stated it so far, the running time is given by a recurrence. Let's write the recurrence. So in order to compute f of n, I recursively compute f of i minus 1 or f of n minus 1 here. And I recursively compute f of n minus 2. So that will take t of n minus 2. This first step will take t of n minus 1. And now I need to solve this recurrence. This is not a recurrence that falls to the master method. It doesn't have a divided by. So we have to think about it a little bit. But we don't have to think about it too hard, because this recurrence is the same as this recurrence, which is the same as this recurrence. I've written it three times now. And so the solution to this is the nth Fibonacci number. Oh, sorry. It's a little bit worse because in addition to those recursions, I also
4202	spend constant time to do the addition, maybe more than constant time. But if we just count the number of additions we do, it will be plus 1 additions. OK. But this is bigger than the nth Fibonacci number. And if you know anything about Fibonacci numbers, they grow exponentially. They're about golden ratio to the end. I'm wearing golden ratio, in case you forgot the number. So that's bad, because golden ratio is bigger than 1. So this is exponential growth, as we know, especially in this time, exponential growth is bad. In algorithms, exponential growth is bad, because we can only solve very small problems with exponential growth. Very small n. So this is a terrible way to compute the nth Fibonacci number--
4203	OK, so don't do this. But there's a very tiny tweak to this algorithm that makes it really good, which is memoization. And this is a big idea. It is the big idea of dynamic programming. It's a funny word, probably made up by computer scientists. Instead of memorization, it's memoization, because we're going to write things down in a memo pad. It's the idea. And it's a very simple idea, which is just remember and reuse solutions to sub-problems. So let's draw the recursion tree for this recursive algorithm as we've done it so far. So at the top, we-- let me make a little bit of space. At the top we are calling f of n. And then that calls f of n minus 1 and f of n minus 2. And it does an addition up here. And then this calls f of n minus 2. And this calls f of n minus 3. This calls f of n minus 3. And this calls f of n minus 4. OK. And we notice that this sub problem
4204	is the same as this sub problem. So to compute f of n minus 1, I need f of minus 3. And also to compute f of n minus 2 I need f of n minus 3. So why are we computing it twice? Let's just do it once. When we solve it, let's write it in a table somewhere. And then when we need it again, we'll just reuse that value. Question? AUDIENCE: What about the f of n minus 2? ERIK DEMAINE: f of n minus 2 is also shared. So let me use a different symbol. f of n minus 2 is already here. So this was at the same level. But we also get shared reuse between different levels. In fact, I wouldn't even call f of n minus 3 because this whole part doesn't need to be computed a second time. If I already computed it here, it doesn't matter which one comes first. Let's say this one comes first. Once this is done, I can write it down and reuse it over here. And
4205	then in here, we're going to call f of n minus three. So there's still another computation of f of n minus 3.
4206	OK, so magically this is going to make this algorithm efficient with this very simple tweak. Let me write down the tweak more explicitly. I won't write code here. But just describe it as a data structure. So we're going to maintain our good friend, the dictionary, which is abstract data type or interface. We could use different data structures to do it. But we're going to map some problems to their solutions, at least the ones that we've solved already. And usually we can do this with just a direct access array, though you could use a hash table. Just get expected bounce. So when we write the code for our recursive function--
4207	we can turn this into code. We define f of i. And it says am I in a base case? If so, return this. Otherwise, do this recursive call. That's our recursive algorithm. But we're going to do a little more now. And first we're going to check whether this sub problem that we're trying to solve has already been solved. And if so, we return that storage solution. That's the easy case, but it might not exist. And then we'll compute it in the usual way. So what the code then would look like to define f of i is first we check is i in our data structure. This is usually called the memo. So we say, is this sub-problem-- is i in my memo data structure? If so just return memo of i. Done. No recursion necessary. Otherwise, check if I'm a base case. If so, done. Otherwise, recurse. So recursively call f of i minus 1 and f of i minus 2. And in this recursion, we can see that after we call f of i
4208	minus 1, in fact, it will have already computed f of i minus 2. So while this call is recursive, this one will immediately terminate because i minus 2 will already be in the memo table. And so if you think about what happens, in fact, we'll just have recursion down the left branch of this thing. And all the right branches will be free. We can just look things up in the memo table. So what is the overall running time? For Fibonacci, this should be order n. Why is it order n? This is number of additions. Come back to that in a second. In general, the way to analyze an algorithm like this that uses memoization is we just count how many different sub-problems are there? Because once we solve the sub-problem, we will never solve it again. That's the whole idea of a memo table. So we will solve each sub-problem at most once. And so we just need to count, how much time does it take to solve every sub-problem? And here you can see
4209	it's constant. Either it's a base case and it takes constant time or we recursively call these things. But those are different sub-problems. So we're going to count those later. And then the work that's actually done by this recurrence is a single addition. So in fact, it's n additions. To compute fn would be exactly n additions. So it turns out to be very nice closed form in this case. It should be exactly n sub problems to compute f of n because we started as dot at 1. And each one has one additional-- I guess not the base case. Maybe n minus 2. OK. Definitely order n. Now, there's this one subtlety which-- let's forget about dynamic programming for a moment
4210	talking about the word ram model of computation. A question here that usually doesn't matter in this class. Usually we assume additions take constant time. And we usually do that because it's usually true. And in general, our model is the w bit additions-- where w is our machine word size-- takes constant time. But for this problem and this problem only, pretty much, for Fibonacci numbers, I happen to know that the Fibonacci numbers grow exponentially. So to write them down actually requires theta n bits because they are some constant to the n power. And so they're actually really big . n is probably bigger than w. Usually you think of problems that are much bigger than 64 or whatever your word size happens to be. We do assume that w is at least log n. But n is probably bigger than w. It might be bigger or smaller. We don't know. And in general, to do an n bit addition-- these are n bit additions-- is going to take ceiling of n over w time. So in
4211	the end, we will spend this times n, because we have to do that, many of them, which is n plus n squared over w time. So a bit of a weird running time. But it's polynomial, whereas this original recursive algorithm was exponential here. Using this one simple idea of just remembering the work we've done, suddenly this exponential time algorithm becomes polynomial. Why? Because we have few sub problems. We had n sub problems. And for each sub problem, we could write a recurrence relation that if we already knew the solutions to smaller sub problems, we could compute this bigger problem very efficiently. This happened to be constant time or constant additions. n over w time. But as long as this is polynomial and this is polynomial, we're happy, because we have this nice formula that the time it takes is, at most, the sum over all sub problems of the relation time. So I'm referring to sub problems, like a number of them and the time it takes to evaluate this, ignoring the recursive calls. That's
4212	important. This is the non recursive part. In the notes, I call this non-recursive work. So this formula gives us a way to bound the running time of one of these algorithms if we use memoization. Without memoization, this is not true, Fibonacci to exponential time. But if we add memoization, we know that we only solve each sub-problem once. And so we just need to see, for each one, how much did it cost me to compute it, assuming all the recursion work is free, because that's already taken into account by the summation. So in particular, this summation is at most the number of sub-problems times the time per sub-problem,
4213	We could try to apply that analysis to merge sort, because after all, this is also a recursive algorithm. It happens to not benefit from memoization. But we could throw in memoization. It wouldn't hurt us. But if you think about the call graph here, which is like s of 0 m, which calls s of m-- 0 n over 2 and o of n over 2n and so on. It has the same picture, but there's actually no common substructure here. You'll never see a repeated sub-problem, because this range is completely disjoined from this range. But you could throw in memoization and try to analyze in the same way and say, well, how many sub-problems are there? It looks like there's n choices for i and not quite n choices but it's at most n squared different choices. In fact, it's the triangular number sum of i equals 1 to n of i, different possible choices for inj. But this is theta n squared sub-problems, which seems not so good. And then how much time are we spending
4214	per sub problem? Well, to solve s of ij, we have to merge about that many elements. We know merge takes linear time. And so this takes theta j minus i time to evaluate. And so what we'd like to do is sum over all the sub problems of j minus i. This is the not triangular number but the tetrahedral number, I guess. And so we end up that the running time is, at most, n cubed. Great. So it's true that n log n is less than or equal to n cubed, but obviously not terribly useful. This algorithm by the way we already know how to analyze it is, indeed, n log n. And the running time turns out to be theta n log n. So sometimes this equation is not what you want to use. But often it's good enough. And especially if you just want to get a polynomial upper bound, then you can try to optimize it later. This will give you a polynomial upper bound as long as the number of sub-problems is
4215	polynomial and the time per sub-problem is polynomial. And indeed, n cubed is polynomial. It's not a great polynomial, but this is an alternate way to analyze merge sort. Obviously don't do this for merge sort. But it illustrates the technique. Good so far? Any questions? All right. Let me remember where we are. Cool. So the next thing I'd like to do is show you one more algorithm that we've already seen in this class that fits very nicely into this structure-- arguably is a dynamic program-- and that is DAG shortest paths. So just to close the loop here, when I say dynamic programming, I mean recursion with memoization. I mean, we take-- we write a recursive piece of code, which is like def f of some args, some sub-problem specification. We check is the problem in the memo table? If so, return memo of sub-problem. And otherwise check if it's a base case and solve it if it's a base case. And otherwise, write the recurrence recurse via relation. And set the memo table of the sub-problem
4216	to be one of those things. OK, so this is the generic dynamic program. And implicitly, I'm writing Fibonacci in that way. And all of the dynamic programs have this implicit structure where I start with a memo table which is empty and I always just check if I'm in the memo table. If I am, I return it. Otherwise I compute according to this recursive relation by recursively calling f. And that's it. So this is every DP algorithm is going to have that structure. And it's just using recursion and memoization together. OK, so now let's apply that technique to think about the DAG shortest paths problem. The problem was, I give you a DAG. I give you a source vertex, S-- single source shortest paths. Compute the shortest path weight from S to every vertex. That's the goal of the problem. And we saw a way to solve that, which is DAG relaxation. I'm going to show you a different way, which turns out to be basically the same, but upside down, or flipped left right, depending
4217	which way you direct your edges. So what are our sub-problems? Well, here, actually, they're kind of spelled out for us. We want to compute delta and SV for all these. So that is size of these sub-problems. That turns out to be enough for this overall problem. And the original problem we want to solve is all of the sub-problems. We solve all the sub-problems, we're done. And then we have-- I think we wrote this at some point during the DAG shortest paths lecture-- we have a recursive relation saying that the shortest way to get from s to v is the minimum of the shortest path to get to some vertex u plus the weight of the edge from u to v. Why? Because if we look at a vertex v, unless we started there, we came from somewhere. And so we can consider all of the possible choices for the previous vertex u. And if you start at s and get to v, you must go through one of them. And so this is finding the
4218	best way among all the choices of u. What's the best way to get to u? And then take the edge from u to v for all edges uv. And this is adjacency minus. We don't usually think of that. Usually we look at adjacency plus the outgoing edges. This is the incoming edges. And so u is an incoming-- uv is an incoming edge into v. OK, if we take that minimum-- and of course, possible there is no way to get to v. And so I'll also throw infinity into the set. Take the min of that set. That will give me the shortest pathway in an acyclic graph from s to v. And great, this is recursive. This was a sub problem. These are sub problems which are smaller, I guess. There's no clear notion of smaller here, except we already know the clear notion of smaller is the topological order of our DAG. Because our graph is acyclic, we know it has a topological order. We know how to compute it with DFS. And so that
4219	guarantees there's a topological order to compute these problems. And in fact, the relationship between problems is exactly the given graph, G. In order to compute the shortest pathway from s to v, I need to know the shortest pathway from s to all of the incoming vertices to v. And so this is I guess in the call graph, this vertex calls this vertex, but direct the edge this way to say that this vertex requires-- this vertex needs to be computed before this one. And so then I can complete them in a topological order. OK, we have a base case, which is delta of ss equals 0. And the running time is, again, we can use this formula and say, let's just sum over all the sub problems of the non recursive work in our recurrence relation and so it's computing this min. If I gave you these deltas for free and I gave you these weights, which we know from our weight data structure, how long does it take to compute this min? Well, however many
4220	things there are, however many numbers we're minning, which is the size of the incoming adjacency list plus 1 for that infinity. And so if you compute this sum, sum of incoming edges to every vertex, that's all the edges. So this is v plus e. So in fact, this algorithm is morally the same algorithm as the one that we saw on the DAG shortest path lecture, which was compute a topological order and process vertices in that order and relax edges going out from vertices. So here-- so in that algorithm, we would have tried to relax this edge if there was a better path to v. And the first one certainly is better than infinity. So the first one we relax indeed. The next edge, if this gave a better path from s to v, then we would relax that edge and update the way here and do the same here. In the end, we're just computing this min in the relaxation algorithm but doing it step by step. In the relaxation algorithm, DAG relaxation, for each
4221	"incoming edge to v, we update d of e if it's better. And so if you repeatedly update if you're better, that ends up computing a min. OK, so this is the same algorithm just kind of flipped backwards. A funny thing, although we wrote down the topological order of the sub problem graph here is the topological order of g, because the sub-problem graph is g, the algorithm doesn't actually have to compute one. It's doing it automatically for free. If you think about this algorithm, generic dp algorithm, which is check whether we're in a memo table. If so, return. Otherwise, recurse, or base case. This actually is a depth-first search through the sub-problem graph-- technically through the reverse of the sub-problem graph. If I draw an edge-- so from small to big-- so I'm just saying, I orient the edges from my smaller sub-problems to the ones that need it-- then I'm actually depth-first searching backwards in this graph because the bigger problem calls the smaller problem. And the memo table is serving as the ""have I"
4222	"visited this vertex already"" check in DFS. So this is actually a DFS algorithm. Plus we're doing some computation to actually solve the sub-problems we care about. So implicit in this algorithm, we are doing a DFS, and at the same time, we're doing this shortest path computation in the finishing order of that DFS traversal because all the edges are backwards. This is the same as the reverse finishing order if the graph is forwards. So in the end, we're computing a topological order because dynamic programming includes in it depth first search. A lot of words. But it's kind of cool that this framework just solves DAG shortest paths without much work. I mean, we did a lot of work in shortest paths to prove that this relation is true. Once you know it's true, the algorithm part is pretty much free. You just write down SRTBOT and you're done. OK. This brings us to in general-- at this point we have seen two examples of dynamic programming. I guess technically merge sort you could think of as"
4223	a dynamic program, but it doesn't actually reuse anything. So it's not interesting. And indeed, that gave us a really bad bound. We've definitely seen DAG shortest paths and Fibonacci numbers as two interesting examples. And what the next remainder of this lecture and the next three lectures are going to be about is more and more examples of dynamic programming and how you can use it to solve increasingly general problems. So far, we've just solved an easy problem and a problem we already knew how to solve. Let's go to a new problem, which is bowling. Bowling is popular in Boston. Boston likes to play candlepin bowling, which is a bit unusual. Today we're going to play an even more unusual bowling game, one that I made up based on a bowling game that Henry [INAUDIBLE] made up in 1908. So ancient bowling, I'll call it, or I think linear bowling is what I might call it. I'll just call it bowling here. And now I'm going to attempt to draw a bowling pin. Not bad. They might
4224	get progressively worse. So imagine n identical bowling pins. Please pretend these are identical. And I have a ball which is approximately the same size as a bowling pin. These bowling pins are pretty close together. I should have left a little gap here. And you are a really good bowler. Now, unfortunately, these bowling pins are on a line. And you're bowling from way down at infinity. So when you bowl, you can only hit one pin or two pins or zero pins. But probably you want to hit some pins.
4225	you will just hit that one pin. And if you bowl in the middle between two pins, you will knock down-- that's a ball, sorry-- you will knock down two pins. And this is your model of bowling, model of computation. Now, what makes this interesting is that the pins have values. Pin i has value-- this is obviously a toy problem, though this problem-- this type of bowling does go back to 1908, it was also a toy problem in that setting. So each of these bowling pins has some number on it, let's say 1, 9, 9-- I'll do a slightly more interesting example, maybe another one here and a 2 and a 5 and a 5, something like this. OK. Or maybe make it a little more interesting. Let's put some negative numbers on here. OK. And the model-- so you're at the carnival bowling. Each pin has different-- potentially different values. And the model is if you hit one pin, i, then you get vi points. So that's straight forward. To make it interesting, when you
4226	hit two pins, you get the product. So if I hit two pins, it's always i and i plus 1 for some I. You get vi times vi plus 1 points. This is the game you're playing. And it doesn't really matter that this is a product. Product is just some weird function that's hard to imagine. If you stare at this long enough, you should convince yourself that the optimal solution is probably to-- so, for each of these numbers, I could leave it singleton or pair it with its left neighbor or pair it with its right neighbor. But the pairings can't overlap because once I hit a pin, it's gone. It's knocked over. It disappears. So because of these nine, which are a very high value, what I'd probably like to do is hit both of them together, so pair them up, because 9 times 9 is 81. That's really big, much better than hitting them individually or hitting 9 times 1 or 9 times 2. 1 and 1 is kind of funny, because it's actually better
4227	to hit them individually. That will give you two points, whereas if I'd pair them up, I only get one point. 2 and minus 5, that seems bad. Negative 10 points. My goal is to maximize score. Do you have to hit all the pins? Let's say no, you don't have to hit all the pins. So I could skip the minus fives. But in fact, here, because they're adjacent, minus 5 times minus 5 is good. That's 25 points. So the optimal solution for this particular instance are to hit all the pins, these positive, these together, these together. If I added, for example, another pin of minus 3 here, I would choose not to hit that pin. Good question. So you just play until you are tired.
4228	There are many variations of this game. All of them-- basically any variation-- not literally every variation, but many, many variations of this problem can all be solved quickly with dynamic programming. But let's solve this particular one. OK. So now we're really in algorithmic design mode. We need to think about SRTBOT. And in particular, we need to think about what would the sub problems be here? And at this point, we don't have a lot of help. So I should probably give you some tools. If I want to solve a problem like this, the input is a sequence of numbers. It's a sequenced data structure. Maybe it's an array of numbers, which is this v array. And let's see. A general tool for sub-problem design which will cover most of the problems-- maybe all of the problems that we see in this class for dynamic programming. Here's a trick. If your input is a sequence, here are some good sub-problems to consider. We could do all prefixes. So let's call the sequence x. So we could do
4229	x prefix means up to a given i for all i. We could do all the suffixes, x from i onward for all i. Or we could do substrings, which are the consecutive items from i to j. I don't write subsequence here. Subsequence means you can omit items in the middle. So substring you have to start in some position and do all the things up to j. So these are nice, easy to express in Python notation. And these are great, because they're polynomial. If I have n things-- if the length of my sequence, x, is n, then there are n prefixes-- technically n plus 1. So let's do theta n prefixes. There are theta n suffixes. And there are theta n squared substrings because there's n-- roughly n choices for i and j separately. Sorry? Sub-sequences. Good. Right. I didn't write sub-sequences, because in fact, there are exponentially many sub sequences. It's 2 to the n. For every item, I could choose it or not. So I don't want to parameterize-- I don't want my sub
4230	problems to be sub sequences because that's guaranteed-- well, then you're guaranteed to get an exponential number of sub-problems, which is bad. We'd like to balance the numbers of sub-problems by polynomial. So these are three natural ways to get polynomial bounds. Now, prefixes and suffixes are obviously better because there's fewer of them, linear instead of quadratic. And usually almost every problem you encounter, prefixes and suffixes are equally good. It doesn't really matter which one you choose. So maybe you'd like to think of-- well, we'll get to--
4231	But sometimes it's not enough. And we'll have to go to substrings. That won't be for another lecture or two. Today I claim that prefixes or suffixes are enough to solve the bowling problem. So what we're going to do is think about-- I prefer suffixes usually, because I like to work from left to right, from the beginning to the end. So we're going to think of a suffix of the bowling pins. And so what is the sub-problem on a suffix? Well, a natural version is just to solve the original problem, bowling. How do I maximize my score if all I were given were these pins? Suppose the pins to the left of i didn't exist. How would I maximize my score on the remaining pins? Or for this suffix, given these four pins, what would I do? And there's some weird sub problems here. If I just gave you the last pin, what would you do? Nothing. That's clearly different from what I would do globally here. But I claim if I can solve all suffixes
4232	I can solve my original problem, because one of the suffixes is the whole sequence. So let's do it. Sort by for bowling. So here is our dynamic program. The sub-problems are suffixes. So I'll write b of i is the maximum score we could get possible with our starting-- if we started a game with pins i, i plus 1, up to n minus 1, which is a suffix of the pins. Very important whenever you write a dynamic program to define what your sub-problems are. Don't just say how to compute them, but first say what is the goal of the sub problem. This is a common mistake to forget to state what you're trying to do. So now I have defined b of i. Now, what is the original thing I'm trying to solve? You also put in SRTBOT-- you could put the O earlier, then it actually spells sort. So why don't I do that for fun. The original problem we're trying to solve is b of 0, because that is all of the pins. The
4233	suffix starting at 0 is everything. So if we can solve that, we're done. Next is r for relate. This is the test of, did I get the sub-problems right, is whether I can write a recurrence relation. So let's try to do it. We want to compute b of i. So we have pin i here and then the remaining pins. And the big idea here is to just think about-- the nice thing about suffixes is if I take off something from the beginning, I still have a suffix. Remember, my goal is to take this sub-problem, which is suffix starting at i, and reduce it to a smaller sub problem, which means a smaller suffix. So I'd like to clip off one or two items here. And then the remaining problem will be one of my sub problems. I'll be able to recursively call b of something smaller than i-- or sorry, b of something larger than i will be a smaller subsequence because we're starting later. OK, so what could I do? Well, the idea is
4234	to just look at pin i and think, well, what could I do to pin i? I could not hit it ever with a ball. I could skip it. That's one option. What would be my score then? Well, if I skip pin i, that leaves the remaining pins, which is just a smaller suffix. So that is b of i plus 1. I'm going to write a max out here because I'd like to maximize my score. And one of the options is, forget about pin i. Just solve the rest. Another option is I throw a ball. And I exactly hit pin i. That's one thing I could do. And it would leave exactly the same remainder. So another option is b of i plus 1 plus vi. Why would I prefer this over this? Well, if vi is negative, I'd prefer this. But if vi is positive, I'd actually prefer this over that. So you can figure out which is better, just locally. But then there's another thing I can do, which is maybe I hit this
4235	pin in a pair with some other pin. Now, there's no pin to the left of this one. We're assuming we only have the suffix. And so the only other thing I can do is throw a ball and hit i together with i plus 1. And then I get the product. Now, what pins remain? i plus 2 on. Still a suffix. So if I remove one or two items, of course, I still get a suffix-- in this case, b of i plus 2-- and then the number of points that I add on are vi times vi plus 1. So this is a max of three things. So how long does it take me to compute it? I claim constant time. If I don't count the time it takes to compute these other sub problems, which are smaller because they are smaller suffixes further to the right, then I'm doing a couple of additions-- product, max. These are all nice numbers and I'll assume that they live in the w-bit word, because we're only doing constant sized
4236	products. That's good. So this takes constant, constant non-recursive work. How many sub problems are? Well, it's suffixes, so it's a linear number of sub problems. And so the time I'm going to end up needing is number of sub problems, n, times the non-recursive work I do per sub problem, which is constant. And so this is linear time. Great. And I didn't finish SRTBOT, so there's another t, which is to make sure that there is a topological order and that is in decreasing i order. Or I might write that as a for loop-- for i equals n, n minus 1. This is the order that I would compute my problems because the suffix starting at n is the empty suffix. The suffix starting at 0, that's the one I actually want to compute. That's the final suffix I should be computing. And then we have a b for base case, which is that first case, b of n equals 0, because there's no pins. So I don't get any points. Sad.
4237	OK, so this is it. We just take these components, plug them into this recursive, memoized algorithm, and we have a linear time algorithm. I want to briefly mention a different way you could plug together those pieces, which is called bottom up dp, which is-- let's do it for this example. So if I have-- let's see. Let me start with the base case, b of n equals 0. But now it's an assignment. And I'm going to do for loop from the topological order for i equals n, n minus 1 to 0. Now I'm going to do the relation, b of i equals max of b of i plus 1 and b of i plus 1 plus bi and b of i plus 2 plus di vi plus 1. Technically this only works if i is strictly less than n minus 1. So I should have an if i is less than minus 1 for that last part because I can only do-- I can only hit two pins if there's at least two pins left. And
4238	then return b of 0. So what I just did is a transformation from this SRTBOT template into a non-recursive algorithm, a for loop algorithm, where I wrote my base case first. Then I did my topological order. Then I did my relation. Then at the end, I did my-- not base case. The original problem. And provided you can write your topological order as some for loops. This is actually a great way to write down a dp as code. If I were going to implement this algorithm, I would write it this way, because this is super fast. No recursive calls. Just one for loop. In fact, this is almost a trivial algorithm. It's amazing that this solves the bowling problem. It's in some sense considering every possible strategy I could for bowling these pins. What we're using is what we like to call local brute force, where when we think about pin i, we look at all of the possible things I could do to pin i, here there's really only three options of what I could
4239	do. Now, normally, if I tried all the options for pin i and then all the options for i plus 1 and i plus 2 and so on, that would be exponential. It'd be 3 times 3 times 3. That's bad, but because I can reuse these sub problems, it turns out to only be linear time. It's almost like magic. dp-- dp is essentially an idea of using local brute force. And by defining a small number of sub-problems up front-- and as long as I stay within those sub problems, as long as I'm always recursing into this polynomial space, I end up only doing polynomial work, even though I'm in some sense exploring exponentially many options. And it is because what I do to this pin doesn't depend too much to what I do to a pin much later. There's a lot of intuition going on here for what-- when DP works. But we're going to see a lot more examples of that coming up. And I just want to mention the intuition for how to write
4240	a recurrence like this is to think about-- in the case of suffixes, you always want to think about the first item, or maybe the first couple of items. The case of prefixes, you always think about the last item. And for substrings, it could be any item-- maybe in the middle. If I remove an item from the middle of a substring, I get two substrings, so I can recurse. Here or in general, what we want to do is identify some feature of the solution that if we knew that feature we would be done. We would reduce to a smaller sub problem. In this case, we just say, well, what are the possible things I could do to the first pin? There are three options. If I knew which option it was, I would be done. I could recurse and do my addition. Now, I don't know which thing I want to do. So I just try them all and take the max. And if you're maximizing, you take the max. If you're minimizing, you take the
4241	min. Sometimes you take an or or an and. There might be some combination function. For optimization problems where you're trying to maximize or minimize something, like shortest paths you're trying to minimize, we put them in here. So usually it's min or max. And this is extremely powerful. All you need to do-- the hard part is this inspired design part where you say, what do I need to know that would let me solve my problem? And if you can identify that and the number of choices for what you need to know is polynomial, then you will be able to get a polynomial dynamic program. That's the intuition. You'll see a lot more examples in the next three lectures.
4242	[SQUEAKING] [RUSTLING] [CLICKING] ERIK DEMAINE: All right. Welcome back to 006 and our dynamic programming quadruple of lectures. We are over halfway through, into lecture three of four. Today, we're going to follow up on this idea of problem constraints and expansion that was mentioned, especially, towards the end of last lecture. We saw an example of subproblem expansion by a factor of 2 in the two-player game with coins where we wanted to have two versions of the game, one where I go first and one where you go first. So this was expanding the number of such problems by a factor of 2. Today, we'll see a bunch more examples of this idea, including in one setting we've seen already, which is Bellman-Ford, which you can think of as a dynamic program. Maybe it's a good time to mention that Bellman invented dynamic programming in the '50s. Same Bellman in the Bellman-Ford algorithm. This was actually an independent discovery by both of them-- and other people. He invented dynamic programming, and then, a few years later, he applied
4243	it to solve the single-source shortest paths problem. We saw them in the other order. We saw single-source shortest paths first, because it was a little easier. And now we're seeing the general framework that this fits into.
4244	Why did Bellman call dynamic programming dynamic programming? Mostly because it sounded cool, and he was trying to impress government agencies giving him grants. I mean, how can you argue with something as cool-sounding as dynamic programming? But there is some logic to it. Programming is a reference to an old form of this word, which means optimization. And generally, we're trying to optimize things. And instead of optimizing according to some static kind of approach or program, we're doing it dynamically. This is a reference to the local brute force we're doing to optimize at each stage. You can't tell, at the top, what you're going to do in the middle. And so it's kind of-- each subproblem is behaving differently. And so, in that sense, dynamic. And it sounds cool. All right. Then we'll go to all-pairs shortest paths. We'll see a new algorithm for that that's not asymptotically any better, but it's nice and simple, and another way to-- a cool way to see subproblem expansion. And then we'll look at a couple of sort of practical
4245	problems-- parenthesizing arithmetic expressions and a real-world problem, piano and guitar fingering, so assigning a fingering how to play a piece. And we're going to do that with our SRTBOT framework. Quick recollection of what that is. We define subproblems. And we saw how to do that for sequences. We try either prefixes, suffixes, or substrings. We prefer prefixes and suffixes because there's fewer of them. If there's more than one sequence, we take the product of those spaces. And then the idea we're going to stress today is, we can always add subproblems
4246	"In particular, adding constraints to subproblems, in some sense, lets us remember things about the subproblem that's calling us-- or about the past, is one way to think about it-- or in general, to ""remember state."" Just by adding more subproblems, we can remember more stuff-- not just what things we're working on, but some context. And that's what we'll see lots of examples of today. It will hopefully make sense by the end of the lecture. Then, we need to relate these subproblems with the recurrence relation-- actually, we usually just call it a relation. And the key idea here is to come up with a question that, if you knew the answer to that question, you could reduce the subproblem you're trying to solve to smaller subproblem solutions. This question is sort of the fundamental aspect of-- some fundamental aspect of a solution. Typically, when you're dealing with suffixes, you want to ask some question about the first item, s of i. When you're dealing with prefixes, you want to ask a question about some-- near the last"
4247	item, s of i minus 1. And for substrings, who knows? Somewhere in the middle. We'll see an example of that today. Once you have-- oh, this is a reveal. Something coming later. Once you have identified such a question, the dynamic programming approach is, don't be smart about how to answer that question-- just locally brute force. Try all possible answers to the question. For each one, recurse, and take the best solution according to whatever metric you're trying to do, typically minimization or maximization. Another way to think of this local brute force, which I like to think in my head-- so maybe some people like this, some people don't-- is to think about guessing the answer to the question. So maybe the answer could be 0, 1, or 2. And my algorithm will say, guess which is the right answer. And I'll assume that my algorithm correctly guesses the answer and analyze that. So we can think of the program as going straight through-- guessing the answer and then recursing, and then combining the solutions however. But
4248	then, at the end, of course, we can't assume that the guess was correct. In fact, we have to loop over all of those guesses. So it's the same thing. Just, if you think of it this way, there's less looping in your program. But when you analyze it, definitely, the loop is really there. You have to pay for all of the possible answers. OK. Then we need to make sure this relation is acyclic, get a subproblem DAG. And I like to specify an explicit topological order to make that clear. We have base cases for the relation. We have to solve the original problem in terms of these subproblems, and then we analyze the running time, usually, as the number of subproblems times the non-recursive work in the relation. So recursion is free because we're multiplying by the number of subproblems. You can also sum over the subproblems. Sometimes that gives you a tighter bound. And then, of course, we also have to add on the running time we spend in the original problem. All right. That
4249	was a quick recap. Now, one problem we saw in this framework two lectures ago-- the first lecture was single-source shortest paths in a DAG, which, a lot of dynamic programs actually can be reduced to a single-source shortest paths in a DAG. In fact, the reverse is true. Single-source shortest paths in a DAG can be thought of. The DAG relaxation algorithm we saw is essentially a dynamic program where the subproblems are delta of s, v. The relation of delta of s, v is the min. So what are we thinking about here? We're guessing-- this is sort of a new phrase I want to add. Actually, I wrote it right here. The last edge, u, v, on a shortest s to v path. That's a delta of s, v. The problem we're trying to solve is, find shortest s to v path. And it's some path, and we don't know what it looks like, but some feature of the solution of this path we're trying to find is, well, what's the last edge? It comes from some
4250	vertex here, unless the path is of length 0 and s equals v. That's a special case dealt with in the base case. Otherwise, there's some vertex u before v. We don't know what it is, so we're going to locally brute force, or guess what the right answer is. So look at all incoming edges from u to v, and for each of them, take the recursive shortest path from s to u, plus the weight of the edge. So this is the guessing or local brute force perspective. And the reason this works is because G is acyclic, and so it has a topological order. Otherwise, if the graph has a cycle-- and that's the case we want to go to next-- this recursive call from delta of s, v to delta of s, u will have loops in it. And so you'll never evaluate this recursion. You'll never finish. You'll never minimalize. You'll be sad. It will take infinite time. So don't use this algorithm unless you have a DAG. For DAG, it's great. It's linear time.
4251	So that was a little review.
4252	in general graphs, which we know as Bellman-Ford, but rephrased into the SRTBOT framework. So we defined this problem, in the Bellman-Ford lecture, delta sub k of s, v. Remember, this was the weight of a shortest path from s to v that is restricted to use, at most, k edges. This made the problem feasible. We ended up taking the product of the graph into all of these different subproblems, in fact.
4253	we think of this as a subproblem constraint. What we really want is the shortest s to v path, but that's hard. So we're going to break it up into smaller pieces. For each k between 0 and v, we're going to say, well, let's think about this problem restricted to use, at most, k edges. And for simple paths, if there are no negative weight cycles, we only have to go up to v minus 1. We proved that. And we know we're-- then we're happy. But that's sort of the last thing we want to solve. So if we look down at the original problem we want, it's delta sub v minus 1 of s, v for all v. So if we could solve these subproblems, as we saw with Bellman-Ford, we can solve the original problem-- unless there are negative weight cycles. And we use delta sub v of s, v to check whether they're negative weight cycles. I don't want to repeat that, but that's the all in the original problem. And then we can take
4254	this relation that we wrote for DAG shortest paths and just port it over here. So remember, for a general graph, this has cycles, so we can't use it, because we're just referring to arbitrary delta of s, vs, so there's no reason to expect no cycles there. In fact, the call graph is exactly the graph G, so it has a cycle if and only if G does. But now, over here, I'm running exactly the same formula for this min, but I added a sub k here and a sub k minus 1 here, the observation being, if I've already guessed what the last edge u, v is for this path, then if this whole thing has length at most k, then this piece has length at most k minus 1. So I only need to solve delta sub k minus 1 of s, v here. And so that's what I wrote-- sorry, of s, u. That's what I wrote here. There's one other thing, which is, as I mentioned a little while ago, it could be that
4255	we use fewer than k edges. And so let's consider the case where we don't follow the last edge, and we just add to this min the shortest path using, at most, k minus 1 edges. That's one option for having, at most, k edges. If we wrote equality here, then we would remove that, like the last problem section. OK, good. The key observation here is that this recurrence does not have cycles. Just by adding this index, if we solve these problems in order of increasing k, all of the references from delta sub care in terms of delta k minus 1. And so this is now magically acyclic. This is why Bellman-Ford worked. But now, I think in a very pleasing way, we're taking our graph acyclic. And by spreading it out over various copies of k and referencing always the smaller one, we get an acyclic graph-- acyclic relations. We have base cases, like normal. And then we can analyze the running time in the usual way, which is summing-- how much does this cost? We're
4256	going to take the cost of computing the relation, which is the number of incoming edges to v-- that's this theta-- and then some overall subproblem. So sum over k and sum over v. Wrote it as a sum instead of a product because this thing is theta E. The sum of incoming edges over all vertices is exactly the size of E. And then we sum-- there's no k in this formula, so we just multiply by v and we get v E. So our good friend Bellman-Ford recast kind of the opposite way. Before, we were using relaxations. Now, we're just writing the min explicitly. But essentially the same computation, just in a different order. OK, cool. Those are reviews of old algorithms, but in this new framework to show how powerful it is. Let's look at another example, which is our friend--
4257	A few lectures ago, we saw Johnson's algorithm, which solves this very well. So one option we could use is just this same set of subproblems, but for all u and v. For u and v and v-- that's what we really care about. And then we could say k up to v. Something like that. So this would work, but it would give the same running time as running Bellman-Ford v times. This is one solution we know, but not the best solution we know, for how to solve shortest paths. This would give v squared E, which is at most v to the 4th. For dense graphs, it is theta v to the 4th. So this is v times v times v. But worst case is v to the 4th what I would like to show you now is a different way to solve this problem-- almost identical, but gives v cubed running time, which, for dense graphs, is really good. So we're going to reduce this 4 down to a 3.
4258	It's definitely not an obvious algorithm. It's a very cool idea. And it's a nice example of a different way-- remember, this is subproblem expansion. We took the problems we cared about multiplied by this choice of k. Here, we're going to do the same thing, but define it differently. We're going to define those subproblems differently. First, I want to number the vertices, starting at 1 for convenience. So let's see, y-- and then we're going to define some subproblems, which are delta-- I'll call it u, v, comma k. Maybe, to avoid conflict, I will write a d here. This is just a definition local to this algorithm. So I want the weight of shortest s to v path. So far, just the same as the problem we actually want to solve. This is delta of-- sorry, u, v. But I'm going to add a constraint, which is, using only vertices in u, v and 1 to up to k. This is the divine inspiration to define subproblems this way. It's a different constraint than the one we
4259	saw here, which was using, at most, k edges. So in some sense, what's slow about this algorithm is that we have to loop over all of the incoming vertices. This is expensive. Costs order the degree, which ends up with an E term. We're going to try to convert that E term into a v term by just knowing which vertex to come from-- which sounds impossible. But it turns out, if you write the subproblems this way-- so I'm naming the vertices. And say, well, let me just find a path that uses u, v and the vertex labeled 1. There's only, like, two options. I could go straight from u to v, or I could go from u to 1 to v. And then, how about with 1 and 2, and 1 and 2 and 3? The same vertices. By label instead of by counting them. Slight tweak, but it turns out this speeds up the algorithm. So let me first tell you how many subproblems there are. This is v cubed subproblems. Two choices for u
4260	and v, and I have v choices for-- sorry, I have v choices for u, v choices for v, and v choices for k, roughly. v cubed of these. But the key thing is-- that sounds like a lot. But the relation becomes cheaper now, because I can just write delta u-- sorry, d of u v k is the min of two things, d of u, v, k minus 1 and d of u, k, k minus 1, plus d of k, v, k minus 1. It's a strange formula because we're using indices like k for vertices also, as well as u and v for vertices, but we're also using k as a counter. But we can do this because our vertices are numbered. OK. So the idea is the following. We have vertex u, have a vertex v. And we've already found the shortest path that uses vertices 1 through k minus 1. That's what this quantity is. So it could be-- and now, we're trying to add in this vertex k and think about, what are
4261	all the paths that could go from u to v using 1 up to k? Well, it could be the shortest path from u to v using 1 up to k doesn't use vertex k. That's the first option. Just use vertices 1 up to k minus 1. Maybe we don't need to use k. Or it could be that the path goes through k. Well, it starts at u, and it goes to k, and then it goes from k to v, all using-- for simple paths, if we assume there are no negative weight cycles and you have to run Bellman-Ford to detect them-- but assuming no negative weight cycles, the shortest path from u to v through k must start by using vertices less than k and then use vertices less than k again. And that's what I've written here. It's from u to k using k minus 1 up to k minus 1 labels, and from k to v using labels up to k minus 1. The cool thing here is, the min only has two
4262	terms. So this takes constant time non-recursive work. So this is, k is not on the shortest path. And this is, k is on the shortest path. Cool. So this is constant non-recursive work. If we jump ahead to the running time for this algorithm, we get the number of subproblems, which is v cubed, times the amount of work per subproblem, which is constant. So that's just a v cubed algorithm. For dense graphs, this is really good. When E is v squared, then this is the same thing as v times E, so as good as Bellman-Ford. It's not as good as Johnson for sparse graphs. Sparse graphs, remember-- or, in general, with Johnson, we got v squared log n plus v. And this is always spending v cubed. But it's cool because it's a very simple algorithm. Let's quickly write the topological order. All we need is to guarantee that we solve problems in increasing k order, because every reference here is to a smaller k for the third argument. And so, for example, you can just
4263	write a triply nested loop-- k equals 0, 1 up to v, and u and v, and v and v. So if you wanted to write this algorithm bottom-up, you just write this triple four-loop and then plug in this recurrence relation here. And think of d as a table, as a set mapping, instead of as a function call.
4264	except you also need a base case. The base case here is u, v, 0. So I have to define what that means. But when k equals 0, the 1 through k set is empty. So all I'm allowed to use are my vertices u and v. There are three cases for this-- 0 if u equals v. It's w of u, v if there's an edge from u to v. And it's infinity otherwise. OK. But easy base case, constant time for each. And then the original problems we want to solve are delta u, v, size of v. Because I remember the vertices 1 through size of v. And if k equals size of v, that means I get to use all of my vertices. So that is regular shortest paths. This is assuming no negative weight cycles. We already know how to do negative weight cycle detection, so I'm not going to talk about that again. But then, this will be my shortest pathway because-- yeah. I implicitly assumed here that my path was simple because I
4265	imagined that I only use k once-- 0 or 1 time. And that's true if there are no negative weight cycles. Cool. And we already did the time part of SRTBOT. So v cubed algorithm. Very simple. Basically, five lines of code, and you've got all-pairs shortest paths. And if your graph is dense, this is a great running time. If your graph is not dense, you should use Johnson, like you will in-- or like you have implemented in your problem set. Yeah. AUDIENCE: So how does this this compare to just running Dijkstra's algorithm a bunch of times? ERIK DEMAINE: What about using Dijkstra? Let's compute. Running Dijkstra v times is the running time of Johnson. Running Dijkstra a bunch of times is great if your graph has only non-negative edge weights. Then you should just run Dijkstra. You get this running time. And for sparse graphs, this is superior. If you have negative edge weights, you should run Johnson, which is Bellman-Ford once and then Dijkstra three times. And we're comparing this to v cubed, which we
4266	just got. So this-- I mean, how these compare depends on how v and E relate. On the one hand, maybe v is theta E. That's what I would call a very sparse graph. And it's quite common. Then, the running time we get here is v squared log v-- roughly v squared. On the other hand, if we have a very dense graph, v is theta E squared-- which, for simple graphs, is the most we could hope for-- then this running time is v cubed. If you know the v is near E squared, then this is giving you v cubed anyway, from the vE term. So why not just use this algorithm? And often, you know, a priori, whether your graph is very sparse or very dense or somewhere in between. If it's somewhere in between, you should still use Johnson's algorithm, because you're going to get the benefit from sparsity and only have to pay this vE instead of the v cubed. But if you know ahead of time, constant fraction of the edges are there,
4267	then just use-- or you have a small enough graph that you don't care, just Floyd-Warshall because it's simple and fast. Good question. Any other questions?
4268	a very non-intuitive one, where we use some prefix of the vertices. But notice, it's prefixes again-- a number of the vertices from 1 up to v. And I took a prefix of those vertices. So I just solved the problem using prefix vertices 1 through k. So it's actually a familiar idea. If all you had seen are all dynamic programming examples of prefixes, suffixes, substrings, actually, it's pretty natural way to solve shortest paths-- maybe even more natural than this. Anyway, all right. Enough shortest paths. Let's solve two more problems that are more in our standard wheelhouse that will involve sequences of inputs, not graphs.
4269	First, let me define this problem. OK. We are given a formula with, say, plus and times. Let me give you an actual example-- 7 plus 4 times 3 plus 5. Now, when you read this, because you've been well-trained, you think, OK, I'm going to multiply 4 and 3 first because that has a higher precedence, and then I'll add the results up. But what I'm going to let you do is parenthesize this expression however you want. For example, you can add parentheses here and here. You must make a balanced parenthesis expression, a valid way to pair up-- or not just pair up, but a valid way to evaluate this expression. Any order you want. I could be inconsistent. I could, for example, do this sum, and then do this product, and then do this sum. But some kind of expression tree over this. And each one evaluates to something. This is 11 and this is 8, and so this is 88. And my goal is to maximize that computation. And I claim that this is the
4270	way to maximize that particular example. Let me write it in general, and get my notation to match my notes. Given a formula a 0, star 1, a 1, star 2, a 2, and so on up to star n minus 1, a n minus 1, where each a i is an integer, as we like in this class, and each star i is either plus or times. OK so I'm using star as a generic operator. I chose star because it is the superposition of star on top of a times symbol. So it's clear. So you're given some formula, any mixture of plus and times that you like, involving n integers. And your goal is to place parentheses to maximize the result. So you can try all of the combinations here. If I, for example, take the product of 4 times 3, I get 12. If I do that first, I get 12. Then if I add 5 and 7, I get 24, which is less than 88. And I check them all, and this one is the
4271	maximum for that example. Interesting problem. It's a bit of a toy problem, but it's motivated by lots of actual problems, which I won't go into here. To apply this framework, we need to identify some subproblems.
4272	We're given a sequence of symbols. And so the natural thing is to try prefixes, suffixes, and substrings. I'm going to jump ahead and think about the relation first. I want to identify some question about a subproblem or its solution that would let me reduce to smaller subproblems. This is a little trickier. This is very different. We're not always doing something on the left or on the right, or we can't assume there's something happening on the left, because maybe we take a product in the middle first. If I take a product in the middle first, then I have some result here, but I still have three things. I have the thing to the left, I have the thing in the middle, and I have the thing on the right. It turns out to be very messy to think about what the first operation is. Because we can think of this as a tree, where we take a product here-- we take a sum of 7 and 4 and 3 and 5 over here and then take
4273	the product at the root. But I don't know what the tree is, right? I only know these numbers and these operators, but I don't know how to organize this tree. The idea is, if you think of this tree, what is the one thing that's easiest to identify? It's the root. The root corresponds to the last operation I do in this computation. The last thing I did was take a product. And that's a lot easier, because if I guess who is at the root-- which operator is at the root-- that naturally decomposes into the left subtree and the right subtree. And those will always be substrings. We kind of know this. This node corresponds to everything left of this operator, and this substring or this subtree corresponds to everything to the right of the operator. So this is our idea, is we're going to guess which operation, star i, is evaluated last-- or, in other words, at the root. So this is the question. It has n possible answers-- I guess, actually, n minus 1 from
4274	operator 1, operator n minus 1. And so we'll just brute force all of those choices. I wanted to start here because-- to realize that if, I choose some star i in the middle, which might be the right thing, like in this example. Star i is the middle one-- middle operator. I naturally decompose into everything to the left of that operator and everything to the right of that operator. This is a prefix. This is a suffix. So you might think, oh, my subproblems are all prefixes and all suffixes. But that would be wrong, because if you have a bunch of operators-- and say you choose this one to be last. So I have a prefix here and a suffix here. And then there will be some-- within this suffix, I'll choose some operator to be the root of that one, and I have a prefix and a suffix of this suffix. But in particular, I will have to evaluate this subproblem, which is a prefix of a suffix-- in other words, a substring. So never use
4275	a mixture of prefixes and suffixes. If you need both, you probably need all substrings. So our subproblems are going to be substrings. OK. I'm not going to write the subproblems quite yet, because there's another idea we need. So what do I need to do with the substring? I'm going to guess the middle operator and then evaluate the left substring, evaluate the right substring. What am I trying to do with those substring? I guess I'm trying to solve this problem, which is, place parentheses in order to maximize the result, and then return what the result is. And I can use paren pointers to reconstruct what the parentheses actually are. Once I guess what the last operator is, it enough to maximize the part to the right and maximize the part to the left? Will that always maximize my sum or product according to what this operator is? And if you think about it for a while. Yeah. If I want to maximize the sum, I should maximize the two parts. And if I want to maximize
4276	a product, I should maximize the two parts. That seems right. Except, I didn't say that my integers are positive. That's true if your integers are positive. But to make this problem more interesting, we're going to allow the integers to be negative. For example, 7 plus minus 4 times 3 plus minus 5. So I just added a couple of minuses to a couple of the numbers here. Then it's no longer best to pair them this way. If I pair them this way, like this, or if I add parentheses this way, I get 3 here, and I get minus 2 here. So I get-- the product of that is negative 6, which i probably not the maximum. In fact, I can do better, I believe, by doing the left operator last. So this, I claim, the best parenthisization, if I remembered it correctly. This is, minus 2 times minus 4 is 8, plus 7 is 15. So I got a positive number-- definitely better than the negative number I got. I claim this is the best. And
4277	the key property here is, when we take a product of two negative numbers, we get a positive number. Sometimes, you actually want to make things small, because small might mean very negative. You take two very big negative numbers-- very small negative numbers, in other words. You take their product, you get a very big product, positively, because the signs cancel. OK. So this seems tricky. We want to work on substrings, but we don't know whether we're trying to maximize, or you might think, well, maybe I'm trying to maximize the absolute value. But that's not good. Maybe overall, on this entire expression, I get negative 1 million. And that's not what I wanted. I wanted to maximize the sum. So I still need to solve the max evaluation that I can get, the max parenthesization, but I also need to solve the min parenthesization. If I can solve max and min, I'll know the entire range that I could get. And I really only-- I'll care about min especially when it lets me go negative. But let's
4278	"just solve, in all cases, the min and the max, and then just brute force the rest. That's what I'm going to write down. So that was some motivation and why we are going to define subproblems this way. I'm going to define x of i, comma j, comma opt to be-- opt, here, is going to be either min or max. And this is my subproblem expansion. I really just care about max at the very end, but I'm going to care about min along the way. And i, j is going to specify my substring. So this is going to be the opt value-- opt stands for ""optimum"" here, or ""optimization."" The opt value I can get for the substring a i star plus 1, a i plus 1, and so on to star j minus 1, a j minus 1. OK. Being careful to get my indices correct here. And I want 0 less than or equal to i, less than j, less than equal to n. I claim and opt like this. OK. I'm going to"
4279	get the min value and the max value separately. Those are two different subproblems. This is my expansion. This is the constraint I'm adding. And I'm only focusing on this substring from i inclusive to j exclusive. OK. So I claim those are good subproblems. Let's write down a recurrence relation. OK. Relate. I want to write x of i, j, opt on the left. And I want to optimize-- so this will be min or max-- on a set of choices. What is my set of choices? Well, like I said, I want to guess what is the last operation evaluated. I wrote star i here, but star i is already defined, so I'm going to use star k. So I'm going to guess which of my operations between i plus 1 and j minus 1 is the last one, and I evaluate. And that decomposes everything left of k. So that would be x of i, comma k, comma something. And then we will do operator star k on the part after k, which is from k to
4280	j, something. And I'm choosing between-- I think it's i less than k less than j. k is some operator in between, because I started i plus 1 and I ended j minus 1. So those are the possible choices for k. I tried them all. That's my local brute force. And then I take what I can get on the left, what I can get on the right, and multiply or add them according to whether the operator is plus or times. Now, should I maximize or minimize this one? Should I maximize or minimize this one? I don't know. So I'm just going to do more local brute force. Well, let's just say opt prime for the left-- or maybe I'll call it opt L for the left and opt R for the right part. And I'll just add this to my four-loop. Let's just try opt L and opt R. Just take all possible choices among min and max. Now, you could think hard-- and for addition, for example, if you're maximizing, you really only need to
4281	maximize the two parts. And if you're minimizing, you can prove you all need to minimize the two parts. But for multiplication, it's messy. It could be, really, any of the options. Because sometimes, when you minimize, you get a negative term. Sometimes, you don't. And so it depends what you're trying to do. You have to consider all the signs. But we don't need to think hard. We can just try all options. There's only four choices for opt L and opt R among min and max. You could do min-min, min-max, max-min, and max-max. So try-- it's just a multiplication by 4 in this four-loop. The big cost is actually this one, because there are j minus i choices for k. There's a constant number of choices for opt L and opt R. And you need to prove that this is correct. I won't do it here. But the idea is, if you're trying to minimize or maximize your sum or product, it's enough to know what ranges these could come in. And the optimal choice will always
4282	be an extreme in that range. We consider all of them here. And so we get this recurrence. Now, it needs a base case, and we need to check that it's acyclic. But topological order is just increasing j minus i. This is the usual order for substring problems, because this is increasing length of the substring. So start with very tiny substrings. Here, we'll start with length 1 substrings. We just have an a, i there. So that's going to be our base case. And you grow up to the entire string. And it doesn't matter how we order relative to opt as long as we are increasing in j minus i, because i to k and k to j will always be strictly smaller than i to j, and so this will be acyclic. The base case is x of i, i plus 1, opt. This is always a i. Doesn't matter what opt is, because there's nothing-- there's no choice. You just have a single number in that substring, because we're exclusive on i plus 1. And
4283	then the original problem we want to solve is x of 0, n, max. You could also solve min and see how small you can get it. So if you wanted to maximize the absolute value, you could solve the max problem and the min problem and take the largest of those two options. And how much time does this take? Well, how many subproblems are there? For substring problems, we have n squared subproblems. Now, we multiply the number of subproblems by 2, but that's still n squared. So we have n squared subproblems. And how much work per subproblem are we doing? Well, as I mentioned, we're doing j minus i choices for k and a constant number of choices for opt L and opt R. So this is theta j minus i, which, if I'll be sloppy, that's at most big O of n. And it turns out to be the right answer anyway. So there's a linear amount of non-recursive work. In fact, it's like a triangular number, but that's still theta n cubed. Same running
4284	time as v cubed we just got. But polynomial time. And this is pretty impressive, because we're really brute forcing all possible parenthesizations. There about 4 to the n, exponentially many, parenthesizations of an expression. But we're finding the biggest-- the one that evaluates the largest value and the one that evaluates to the smallest value in just n cubed time-- polynomial. And a key here was subproblem expansion, where we, in addition to solving the max problem, we also solved the min problem, because sometimes, you want to take two very small negative numbers and product them together to get a larger positive number. Cool. Question? AUDIENCE: Would anything go wrong if I added minus or divide? ERIK DEMAINE: So what if I had operators minus and divide? It's a good question. I'm certain that minus should work fine. If we do min and max, this should still evaluate the largest thing for division. I need to think about the cases. I would guess it works, but what we need to prove is that the way to maximize or
4285	minimize a division, say, given two numbers in the left and right, is that it either corresponds to maximizing or minimizing the thing on the left and then maximizing or minimizing the thing on the right. So as long as you have this kind of-- it's not exactly monotonicity. It's just that, in order to compute max or min, it suffices to know the max and min of the two parts. It's like interval arithmetic. You know, interval arithmetic? I want to know, what are the extremes I can get on the output of a division if I'm given that a number is in some interval here and some interval here? If the answer is always, use one of the extreme endpoints here and use one of the extreme endpoints here, then this algorithm will work. Otherwise, all bets are off. Cool. So if you negate-- if you put a minus here, that will work fine, because it's negating this range. And then it's just like sum. But-- AUDIENCE: [INAUDIBLE] ERIK DEMAINE: Oh, a divider-- if you're careful about 0,
4286	yeah. Actually, it doesn't work, because we care about how close this can get to 0 for division. It might be enough to consider those. It's like, instead of minimizing and-- instead of computing this entire interval, if this interval spans 0, maybe I need to know-- if 0 is here, I need to know how close to 0 I can get on the left side and how close to 0 I can get on the right side. Still just four quantities I need to know. I would guess, for division, that's enough. Yeah. Nice. Solved a little problem. Then, we would be multiplying the subproblem space, instead of by 2, by 4. Hey, maybe we should put this on the final. No, just kidding. Now it's in lecture, so we can't use it. But it's a cool set of problems, right? You can do a lot with dynamic programming. You don't need to be that clever, just brute force anything that seems hard. And when it works, it works great. And this class is all about understanding when it
4287	works and when it doesn't work. Of course, we will only give you problems where it works. But it's important to understand when it doesn't work. For example, DAG shortest paths-- that algorithm on a non-DAG, very bad. Infinite time. OK.
4288	Here, we're given a sequence of notes t 0, t 1-- t for note-- up to t n minus 1. These are single notes. And all of the single notes-- all of the single notes, right? And we have fingers on our hands. This is not like two-finger algorithm. This is the five-finger algorithm. So in general, I'm going to assume an arbitrary anthropomorphic object. So this is 5 for humans-- most humans. Some humans-- I think the maximum on each hand is 7. Could be smaller. Maybe you've had an accident.
4289	is assign fingers to notes to tell our pianist which finger to use for each note. Normally, when you're given sheet music, it just gives you a sequence of notes you want to play. It doesn't tell you which finger you want to play it with, unless you have some nice training booklets and they have a little number on top of each. And I number them 1, 2, 3, 4 or 5, and symmetrically, 1, 2, 3, 4, 5. Here's a giant piano for my giant hands. If Jason were here, he could sing these notes. So maybe I play this with my first finger, this with my second finger. Let's just say I'm doing a scale. So I can walk. And now, I think, the typical way to do a scale is to reach over with your first finger-- second finger, I guess, and then do something like this. No? OK. Clearly, I don't know scales or how to play a piano. But there's limits here. I can-- if I'm going from this note and I want to
4290	"go to another note over here, OK, maybe I have a decent span from first finger to fifth finger, but my span for my first finger to my second finger is not as big. I can't reach as far. So if I want to play this note and then this note, I would like to start here with a very extreme figure on the left and then go to at a very extreme figure on the right. I'm going to formalize this problem pretty abstractly, because I don't want to get into music performance. I'm going to say that there is a metric d for, if I'm at note t with finger f, and I want to go to note t prime with finger f prime, then this function, d of t, f, t prime, f prime, gives me the difficulty of doing that-- the difficulty of playing note t with finger f and then playing note t prime with finger f prime. This w is ""with."" So this is a transition difficulty. I'm not going to worry about the"
4291	difficulty of the whole piece other than saying, well, I've got to play this note, then I've got to play this note. And for now, just single notes. You play a single note with your right hand, then you play another single note with your right hand, then another single note with your right hand. Let's assume no pauses for now-- no rests. Great. So we have this difficulty from going from the ith note to the i plus first note. And then our goal is to minimize the sum of difficulties. Minimum sum of d ti fi ti plus 1, plus 1. And these-- f i's and f i plus 1 is what we want to compute. We don't know which fingers to use. We're only given which notes to play. This is actually a natural problem. There are lots of papers about this problem. I've read a bunch of them-- obviously not super well, but how to play scales. But there are notes like-- there are constraints in this-- usually, people write this metric as a sum of
4292	different penalty terms, if I want to minimize difficulty. Difficulty is high if I play a note far on the left. So if I go from a low note to a high note, that's easier to do if I use a lower-numbered finger and go to a higher-numbered finger. You don't want to go, like I was doing, from a high-numbered finger to a low-numbered finger to play a note on the right. That's annoying. I would like to do an assignment, if I can, that avoids that. So I'll just have some penalty of, like, 100 if that happens, and 0 if it doesn't happen, sum up a bunch of terms like that. Other examples are, avoid the fourth and fifth fingers-- weak fingers-- or, if I'm playing a portion of the song that is legato, then I don't want to use the same finger to play two notes right after the other. I've got to use two different fingers for that. So you have a penalty if f i equals f i plus 1 and these two notes
4293	are not the same. Then-- and we're in legato mode-- then we add a penalty term. And things like that. I would prefer-- if I'm going from a very low note to a very high note, I would like to use more extreme fingers. Things like that. But we're just going to assume this d function is given to us. It's some polynomial size. If you imagine the notes on your keyboard are end notes or m notes, then some polynomial and m size to this function. How do we solve this problem? I'm running low on time, so let me give you the idea.
4294	And this is going to use subproblem expansion. So the subproblems are going to be x of i, comma f-- this is the minimum total difficulty to play suffix-- because I like suffixes-- t i up to t n minus 1, starting with finger f on note t i. The obvious subproblems would be without this constraint.
4295	And you could try to define the subproblems just as, what's the best way to play a suffix? But I claim it's important to know which finger we start with. So we're going to multiply the number of subproblems by capital F, which is just 5. So a very small subproblem expansion. And then we're going to constrain these subproblems to say, well, what if I started with my first finger? What if I started with my second finger? What if-- up to the fifth finger. Try them all. Then, it turns out, I can write a relation, which is X of i f equals the min. What should I min over? I'll just guess this-- I'm already told what my first finger is to use-- which finger I should use for t i. So what's the next thing that matters? Well, I guess what finger to use for the t i plus 1, the very next note. What is the next finger I use? I will call that f prime and minimize over f prime, between one and capital,
4296	F of the remaining suffix, starting with f prime, plus my difficulty function from t i, comma f, to t i plus 1, comma f prime. End of bracket. OK. So there's kind of a lot going on here. This is a lowercase f prime. But actually, if you think about what I would like to write the recurrence on, well, I start with the suffix i, I would like to recurse on the smaller suffix, so that's X of i plus 1. So here, if I know that I'm prioritizing my finger number for i, will then I'm in order to even call this function, I need to know what finger I'm using 4 plus 1. Once you decide on these subproblems, it's really obvious you need to guess, what is the next finger, and then recurse on that finger-- recurse on the remaining suffix of that finger. Now, why did we need to know what these fingers were? Why not just guess what the first finger is? Well, it has to do with this difficulty function. For this
4297	difficulty function, I know that I want to measure the difficulty from t i to t i plus 1. And to do that, because this function is parameterized by four things, I need to know both the finger for t i and, at the same time, the finger for t i plus 1. If I remove this f, I could add a min over one finger, but I can't really add a min over two fingers. So what this does, by parameterizing by f here and writing down the optimal for each starting finger f, I can-- in some sense, I'm remembering, in this call, what finger I started with. Because I told it, you have to start with finger f prime. And so locally to X i, f, I know what finger f prime is being used for t i plus 1. And also, because of the definition of X i, f, I know what finger I'm using for t i. And so I get to know both of these fingers. One comes out of this min and the
4298	other is given to me as this parameter. And then, of course, if I can solve these problems, I can solve the original problem by just one more min of 1 up to capital F of x 0 little f. I don't know which finger to start with, but that's just f choices. And so then, this recurrence gives me the overall solution. And I'll just jump to the time. We need a base case and topological order. But it is n f squared time. There are n times f subproblems here. And for each one, I'm doing an optimization over f choices, so I get n times f squared. It's a polynomial. And if f is a constant, this is actually linear time. Very fast DP. Now, what I described here is for one hand, one note at a time. But you can generalize this to two hands, each with one note. Well, that's just ten fingers. So you could solve this separately for the right hand and left hand if you know which notes are being played with
4299	left hand and right hand. But some pieces, that's not obvious. So to make it more interesting, what if you have multiple notes at the same time? And let's say-- I think it's reasonable to say you can only play up to f notes at a time, 1 for each finger. And so you have an upper bound on the number of notes at a time that we're playing, which is good. Oh, I have a drawing of this DP, by the way, as a subproblem DAG. This is the original problem, which is, we don't know which finger to start with. But then we just have a complete bipartite graph here, where we write on each of these edges, what is the difficulty of this transition? The y-axis here is which finger I'm using-- 1, 2, 3, 4, 5-- and the x-axis is which suffix I'm considering. Which note do I start on? And so you could solve this with shortest paths in a DAG, or you could just solve it directly as DP, either top-down or bottom-up. OK.
4300	Jumping ahead, if you do multiple notes at a time, instead of this finger choice, which just had f choices, we have-- what do I write here? t to the f possible states, where t is the maximum number of notes that I could play at once. And usually, this is at most f, 1 for finger. But we could generalize. And this is number of fingers. So I could deal with all 10 fingers of a typical human set of arms-- hands-- and say there's at most 10. And so this is 10 to the 10. It's a big constant, but it's constant-- like 1 billion right? 10 billion? But then it's that times n. And maybe that squared times n will let me exhaustively enumerate all of the possible things I could do be doing with all of my hands. You can apply this not only to piano fingering, but also to guitar fingering-- also to Rock Band. Rock Band is an easy case where you just have five buttons, and usually only four fingers that you use.
4301	And this doesn't really make any sound, so it's not that exciting. So the case where f equals 4 you can apply to optimally figure out which finger-- once you have a difficulty function of what transitions are easy and hard for Rock Band, then you can optimally figure out your fingering for Rock Band songs. With a real guitar, this is a little bit harder because there are actually multiple ways to play the same note. For example, I can play the note of this string like this. These should both sound the same-- if my guitar were perfectly tuned, which it's not. And that's properties of strings and the way these things are played. So in addition to what finger I use, I should also decide which string to play that note on. If all I'm given is sheet music, different notes to play, another thing I could guess is which string to play that note on. So for example, maybe I want to play my favorite song here. [PLAYING MUSIC] AUDIENCE: [APPLAUSE] ERIK DEMAINE: Super Mario Brothers,
4302	my favorite song. I could keep going, but I actually can't keep going. It won't be as impressive. I don't actually know how to play guitar. But there are a lot of choices there, right? I started with playing this note down on this string. That's good. I could have also played it on this string. But that's more work for my finger, so I have a penalty function that says, well, if I play an open string, that's a lot easier. And then I had a transition from here-- this note [PLAYING A NOTE] to this note [PLAYING A NOTE] to this note. [PLAYING A NOTE] And if you focus on my fingering here, I chose to use my index finger for the first one, because that index finger is always the easiest to use, but it also gives me lots of room to move my pinky over to here. And then I like to use my middle finger to come up here. You could also use your index finger. It's just a little bit more of a reach.
4303	So you have to define some difficulty function. It might depend on how big your fingers are. But you can do that, and then optimize, using these algorithms, what is the best guitar fingering for a given piece-- one note a time or several notes at a time. You could even add in parameters like, oh, maybe I want to play a bar. That's not a perfect bar. But this would be great for my playing this note down here and this note here-- bad example. So you could do other things with a guitar to make it more interesting and generalize this dynamic program suitably. But I think this gives you a flavor how, with subproblem expansion, I can capture almost any aspect of a problem that I want. As long as the number of states that I need to keep track of is small, I can just multiply the number of subproblems by that state, and I can keep track of any kind of transition from one state to another, which I could also do with taking the
4304	product of a graph. But dynamic programming gives you a kind of methodical way to think about this, by figuring out some property-- in this case, the state of how my fingers are applied to the instrument-- and then just sort of brute forcing the rest-- a very powerful framework.
4305	all right welcome to the grand finale of dynamic programming in 6006 four of four today we are going to focus in on a particular type of sub problem that we saw at the very beginning with fibonacci which is when you have an integer input and a natural thing to do with that integer input is look at smaller versions of that integer and this is going to lead us to a new notion called pseudo-polynomial time we've talked a lot in this class about polynomial time being a good running time but pseudopolynomial is a pretty good running time and we'll talk about that and it relates to these integers we'll only look at two exam new examples rod cutting and subset sum but then we're going to review all the examples we've seen from kind of diagonal perspective so uh as usual we're applying our swordbot framework with subproblems relations topological order base cases original problem and time quick review uh we saw so the hardest part is getting the right set of sub problems uh and
4306	there are some natural choices for sequences we try prefixes suffixes substrings for integers like in fibonacci there's a given number and you want to compute that at the nth fibonacci number what we ended up doing was solving fibonacci numbers for all input numbers input integers between 0 and that number n or in this case capital k and that's a general technique and we'll see two more examples of that today otherwise we take products of these and often that's enough but sometimes we need to add more sub problems in what we call sub problem expansion often with extra constraints that let us remember some state about the past my canonical example that is the piano fingering where we had to remember what our fingering assignment was in some sense from the previous step in order to compute the transition cost and this is very powerful technique you can also use it to like play super mario brothers optimally if you have a constant size screen and all you need to remember is what's in the constant
4307	size screen if everything outside that screen resets you can just add that state as a parameter to your sub problem and you'll be able to solve solve super mario brothers anyway very very useful and that was sort of the focus of last lecture we won't talk about it much here today and then we relate these sub problems recursively and this is basically the test of whether your sub problem definition was correct is can you write down a recurrence relation which is just a recursive algorithm and there's a nice general procedure for how to come up with these relations which is to just think up some question about the sub-problem solution that if you knew the answer reduced to smaller sub-problems and then you just locally brute force all the answers to that question which i like to think of as guessing the answer correctly and then just directly calling the recursive things but then at the end you have to pay for that guess by looping over all possible guesses in order to guarantee that
4308	you actually find the right one so once you identify this question it's very easy dp is all about just brute force anything that you want and usually that leads to pretty good running time as long as the number of possible answers to that question is polynomial then we need to check this relation is acyclic and then it it's often reduces to finding a path like a shortest path or something in a dag the subproblem dag uh we need some base cases we need to make sure we can solve the original problem using one or more sub problems and then we analyze the running time as usually a number of subproblems times the amount of non-recursive work in the relation plus however much time it took us to solve the original problem okay so that was our framework we've seen it four times now slightly refined each time we've mostly added some general techniques for sub problem
4309	so let's do a new example which is rod cutting this will be pretty straightforward but it will serve as a contrast to the next example we talked about subset sum so what is the problem the name rod coming comes from the book clrs but it's actually a pretty practical problem maybe not for cutting rods but you could imagine you you have some resource of a given length i like to think because i have been uh wood hardwood shelf shopping recently i like to think of you have a big plank of hardwood and you get some price for selling that length but you could also cut that plank into multiple pieces of various lengths that sum to l and you could sell them individually maybe you make more money that way that's what this problem is all about so you're given the value of every possible length you could cut we're going to assume all links have to be integers and scale so that that's true so capital l here is the original length little l
4310	is a candidate length of a piece you might cut and v of l is the value for cutting off a length uh l rod sub rod and we're going to assume when we cut we don't lose any material uh you could probably adjust for that but it's not terribly interesting and we want to know what is the best way to split up our big rod of length capital l into various rods of small l length different potentially different lengths so i'll call this the max value partition in mathematics this is called partition a bunch of numbers that sum to a given number and we want to maximize the total value naturally so here's an example let's say our original length is seven and we have this table for lengths one two three four five six seven all the different lengths i'm going to write down a value that's an integer cutting off a route of that length and selling it select sell price it's presumably monotonic but doesn't have to be maybe people really like
4311	buying powers of two length or something and so those sell higher so it doesn't have to be monotonic but in this example it is and so i have this route of length seven and i could sell it directly for 32 dollars let's say but i could also split it into say uh one a length one rod and a length six or a length one rod and two length threes or a length three and a four anything that sums to seven and probably the most natural thing to do for this problem is like a heuristic this would be a greedy bang for buck heuristic is what it's usually called is to take the ratio how much money do i get for a given length divide v of l by l and try to maximize that that would sort of be if i had to pick a single item and sell many of that type that would be the optimal thing to do so this has a ratio of one that's bad this has a ratio of
4312	five that's better and you stare at it long enough i believe six is the best has the highest ratio slightly more than uh i can't divide um slightly better than um let's see slightly slightly worse than four or was fourth the best slightly worse than four what do you mean oh slightly i see the ratio is slightly less than four thank you yeah uh which all of these others are somewhat worse for example two uh if i double the 3 value i get 26 which is quite a bit less than 31 and i guess the the closest competitor i think is 2 because if you multiply this by 3 you get 30. so if i sold three twos i get 30 but if i sell one six which is the same quantity i get 31 so slight improvement and so this this item maximizes bank for buck that ratio and so one natural partition is six plus one i sell one rod of length six and that leaves a rod of length one and this
4313	will give me uh 31 for the six and one dollar which gives me 32 dollars uh but this turns out to not be the best which is actually the same as if you just sold it outright but in fact you can do better by selling this is not obvious stare at it for a while a three and a four also sums to 7 then we get 13 plus 18 which is hopefully bigger 33 30 get this right nope i did not get it right uh that's too small uh we're going to take these two and sell 3 plus 2 plus 2. then i get 13 plus 10 plus 10 remember two was a close competitor first for the ratio for six so it's a little better to sell twos two twos and then a three because then we get thirty three dollars and that turns out to be the best for this problem and it seems really tricky to figure this out in general there are exponentially many different partitions can't afford to try them
4314	all question can i have negative values can i have negative values in here uh i think that will work fine i'm not allowed to have negative lengths or zero lengths i don't want zero length to actually give you something because then i just cut infinitely many zeros but uh the v of l i think could be negative yeah do i have to use a whole bar uh in this problem yes i think it wouldn't change much if you didn't have to use the whole bar we can think about those after we write the dp so um let's solve this with sort bot so what's the input to this problem well we have uh i didn't mention this is an integer length positive integer length so we have one input which is an integer l and we have another input which is i guess it's like an array of integers so this is a sequence and this is an integer so if we look at our list of nice sub problems we could try prefixes or
4315	suffixes or substrings of the value structure or we could try for that integer smaller integers that's actually what i prefer i think the way to think about this is to jump ahead to what do we want to what feature of the solution do we want to guess and presumably we should think about what is some length of rod that we will cut and sell okay so i have this big rod maybe i sell the whole thing maybe i cut off a thing of size one and sell it maybe i cut off a thing of size two and sell it um but i have to sell something unless i'm not selling anything and so uh that's there's only n different or there's only l different choices for what uh rod lengths to cut off first and so we can just brute force that in order l time so what problem do we get if we cut off an integer of some small l length well we just get the same problem with a rod of length
4316	capital l minus small l the values don't change it happens that i won't use the big values if i cut off some amount of the the problem but i like to think of this as we're just all we're doing is decreasing big l and so my sub problems are going to be uh for each small l less than or equal to big l solve that problem so x of l is max value partition of uh length l little l for little l equals zero one up to big l okay so just same problem but with different choices for big l so this is using this integer sub problem now in this example that happens to correspond to prefixes of the v array because if i only have length up to little l that i really only need the prefix of the value array up to little l so you could think of it that way that's also fine but i think this way is a little more generalizable
4317	sub problems because i can write a recurrence relation which is actually pretty simple like i said uh we want to choose some piece so we're given a rod of length little l i want to choose how much of that rod to sell in the next piece so i could cut off something of length one or i could sell the whole thing or cut off any piece size in between and the money i will get for that is whatever the value of that piece is plus recursively the maximum i can get from all the remaining pieces sorry from the remaining length which is little l minus p okay so very simple inside the formula just the value for the first piece we're guessing what is the first piece we'll cut off and sell we get the value for that piece and then recursively we see what's the best we can do with the remainder now we don't know what size the first piece should be so we just brute force it we try all possible choices
4318	for p and take the max that we get out of this formula over that choice and that's guaranteed to find the best overall because we must cut off some piece now if you wanted to allow not selling anything in the case of negative numbers you could just add a zero to this max and then you might stop early if there's nothing left that's worth selling okay topological order is very simple we just have these capital l different problems and if you look at oh uh yep so we're looking at l minus p p is always at least one so we're always strictly decreasing l in this recursive call and so as long as i solve the problems in order of increasing little l i'll guarantee that whenever i'm solving x of little l i'll have already solved all the things i need to call so if you're writing a bottom up dp this would just be the for loop l equals zero up to big l in that order this is equivalent to the statement
4319	but the key is to check that this is acyclic because we're always referring to smaller l and so increasing l is a valid topological order in this sub-problem uh dag defined here where there's an edge from an earlier thing to evaluate to a later thing to evaluate okay base case would be x of zero that's the first thing we'll want to compute here and indeed this formula doesn't make much sense if i have x of 0 because i can't choose a number p between 1 and 0. even non-strictly and so what does it mean well if i have a rod of length 0 i can't get any money out of it so that's it it's a 0. that's an assumption but a reasonable assumption you don't get something for nothing okay then we have the original problem which is just the length l rod and then the time to compute this thing how many sub problems are there capital l plus one so we'll say theta l sub problems and we'll multiply by uh the
4320	amount of time to evaluate this max just a constant number of things in here not counting the recursive call and so it spent takes little l time little l is certainly at most big l and so we'll say big o of big l time it's actually a triangular number but it will only affect things by a constant factor so we get l squared time and we're done so very simple straightforward dp at this point we've seen much more complicated examples than this but it highlights a question which is is uh theta l squared polynomial time so is this a reasonable running time and i claim the answer is yes this is a reasonable polynomial running time you might say well of course it's a polynomial look this is a polynomial l squared that's a quadratic polynomial but it's a quadratic polynomial in l and we haven't really thought about this too hard but what does it mean to be polynomial time um and this is a notion that's properly called strongly polynomial time we won't
4321	worry about that strongly too much in this class but if you look this up online you'll see the difference polynomial time means that the running time is polynomial in the size of the input and the size of the input is for our model measured in words machine words remember our good old word ram w bit words it's been very useful because it lets us assume things like adding two numbers is constant time as long as these numbers fit in a word as long as they're at most w bits and generally we assume all the things we're manipulating fit in a machine word because that's what the case where we normally work and so the natural way to imp to measure the size of an input so in this example this problem rod cutting the input is a single number l and this value array v of l which is capital l numbers so i would say n integers and we've generally assumed didn't mention integer value here as in throughout this class we assume that
4322	all the integers unless otherwise specified fit in a word so we've got one word here and l words here so the total size of the input to this problem is l plus one integers in this problem input size is l plus one which we can think of as just l that means theta l okay so i explicitly didn't want to use n in this problem because usually we use the letter n for the problem size not quite always but input size always means input size and so here we can compute it in terms of the specification it involves l plus one word inputs and so polynomial time should be polynomial in that input size in l plus one in our example so of course l squared is polynomial and l plus one so good yes okay the next example i'm going to show is going to be very similar but the answer will be no make it more interesting but it'll still seem pretty reasonable so we'll come back to that issue in a moment
4323	let me first show you uh what the subproblem dp looks like for this problem again took me a while to draw so please admire so this is the same example of of these values 1 10 13 18 20 31 32 drawn here on a graph it's the complete graph oriented uh in this increasing way i think this is called a tournament in graph theory uh so we have the base case over here uh this corresponds to a length zero rod where we get no money and over here we have our full rod of length seven and i claim the best that we can do is uh 33 and what's happening here is for every value like three that i could sell a rod of length three for 13 there's an edge that goes from each vertex to 1 3 higher and those all have a weight of 13 on them and then what we're essentially trying to do is find a longest path from here to here longest because we want to maximize the sum
4324	of values that we get and we know if we negate all the weights that's the shortest path problem so we could solve that with shortest paths in a dag but i've drawn here the shortest path tree from the base case um so it actually tells us that if we had a rod of length seven the best thing to do is to sell it directly for thirty one the bold lines here are the shortest path tree or the longest path tree i guess and if we had something in length 10 we should sell it directly if we have something of length 20 we should sell one thing of length 2 and another thing of left sorry one thing of length 4 then we should sell one thing of length 10 of 2 and one of length two we get two times ten points and for the 33 case we sell one thing of length two one thing of length two and then one thing of length three is optimal so you can read lots of information
4325	from this and if you write down the dp code this is effectively what it's computing from left to right okay let's move on to our second problem today which is subset sum so here we are given let's say a multi-set multiset means that i can repeat numbers so this is just a sequence of numbers but i'd like to use set notation because i want to use subsets
4326	and we're also given a target sum and we want to know does any subset sum to the target sum this is actually a similar problem to rod cutting because rod cutting we also had to split up our number l into different values that summed to capital l so capital t here is playing the role of capital l but before we were allowed to cut into any lengths and so it was easy in particular l sums to l here presumably t is not in this multiset and we need to find a combination of numbers here that add up exactly to t sometimes that's possible sometimes it's not we're only allowed to use each number once or as many times as it appears in the subset okay so here's an example say a equals two five seven eight nine uh and two examples are t equals 21 and t equals 25 for that same set so can i get 21 out of these well this involves arithmetic that's hard i think let's see if i add 7
4327	and 8 i get 15 not quite what i want cheat look at my answer uh yeah close i see five seven nine uh so this is a yes answer to the question does there exist any subset because uh 5 7 and 9 sum to exactly 21 and t equals 25 i don't know a good way to prove to you that there's no way to write 25 with these numbers other than i wrote a program that tried all subsets and or you could write a program that runs the dp that we're about to give and it will output no there's no succinct way as far as we know to prove to someone that the answer is no for a given target sum there is a nice succinct way to prove the answer is yes i just give you a subset we'll talk more about that next lecture but these are some examples of the question you might ask and the answer that we're looking for this is what we call a decision problem in its original
4328	form we're just interested in a yes or no answer uh it's a single bit of course in the yes case we might actually want to find the set and we can do that as usual with parent pointers just like in the bold lines over here we'll get to that in a moment um but this is a little bit different from the most the problems we've been seeing with dynamic programming are optimization problems and we're trying to minimize or maximize something and so we always put a min or a max on the outside in the relation here we're going to have to do something that involves boolean values yes or no true or false
4329	um in that we can just use our standard sets of subproblems so just like the previous problem we have on the one hand a sequence of integers and on the other hand we're given a single integer t and what turns out to be right is to use prefix prefixes or suffixes on this sequence and uh integers less than or equal to t let's think about why so that was sort bot for rod cutting this is swordbot for subset sum again i'll look for a look ahead to what feature of the solution should i guess well i have these n numbers each of them could be in my subset or not so i have this binary choice for each ai is it in s or not that's a lot of questions to answer i can't answer them answer them all at once but i could just start with the first one and say well is a 0 an s yes or no there's two answers locally brute force if i do that what happens to my
4330	problem what new sub problems do i run into what do i want to recurse on well i've eliminated a zero that will leave a suffix of the ai's so suffixes on capital a seem like a good idea and what about my target sum well it depends if i put a zero in my set s then the target sum for the remainder is t minus a0 so t went down and so i need i need in my sub problems to represent smaller target sums also so this is how you figure out what sub problems you should use don't you i mean you could just try prefixes on this suffixes on this substrings on this and yes or no do i include smaller versions of t here but you can also just think about try to write a recurrence relation first see what things you are naturally recursing on and then formulate the sub problems that way so that's what i like to do so i'm going to have a sub problem for each suffix uh so
4331	that's x of i and for each target sum and i use these capital letters for the for the actual target sum so that i can use lowercase letters for smaller versions of them so this is going to be uh does any subset remember don't first most important thing is to define what your sub problems are don't just say it's the same problem but where i replace blah blah blah very it can be very ambiguous and so uh does any subset s of the suffix a from i onwards some to little t and we're going to have this sub problem the other important thing is to say how many sub problems there are and what your indices can vary over so i is going to be between 0 and n and t is going to be between 0 and big t okay so number of sub problems is n plus one times t plus one or theta n times t cool now i claim i can write a relation like i said by so we have
4332	this suffix from a from i onwards in a and so i'm just going to because i'm looking at suffixes i want to keep with suffixes so i should try to guess what happens to a of i because then what will remain is a of i plus 1 onwards and a of i can either be in my subset s or not so there's two choices so x of i t is going to be involve two things so there's an operator here and then i have a set of two items which is uh i could choose to not put a of i in my subset in that case i've eliminated a of i and what remains is uh a of i plus 1 onwards and i didn't change my target sum i i haven't put anything in s so i still want to achieve the same sum so this is the case where a i is not in s and then the other case is i put a of i in s in that case again i've
4333	eliminated a of i and so what remains to figure out is what happens to a of i plus 1 onwards but now my target sum is different because i put a number in my set and so among these items they should sum up to not little t anymore but now little t minus what i just added which is a i so then if if in this sub problem i get something that sums to t minus a i and then i add a i to that set i will get something that sums to exactly t and so that's a valid solution to this problem and because we have brute forced all possibilities there were only two uh if we combine these in the suitable way then we will have considered all options now what do we want here so this is normally i'd write max or min but this is a decision problem the output is just yes or no so this is a yes or no answer this is a yes or no answer this
4334	is a yes or no answer and so what i want is or in python this would be called any just are any of these things true because if there's any way to construct a set that sums to t then the answer to this is yes cool so very simple actually just this is one of the simplest recurrences but we're solving what i think is a really impressive problem right we we're asking is there any subset they're exactly two to the n subsets of a here um and we're in some sense considering all two to the n of them but because we split it up into n local choices that are binary and do them only one at a time sort of this is the local brute force versus global brute force global brute force would be trial subsets sum them see which ones add up but we're in some sense collapsing a lot of these choices be in reusing sub problems that's the whole point of dynamic programming we're looking at uh for the the
4335	rest of the of the sequence from i plus one onwards i don't really care exactly which subset you choose i only care what it sums to and that collapses a lot of different options into the same thing i really just want to know is there any way to do it with exactly this sum so i don't have to think i don't i don't need to keep track if if i said give me all of the different subsets that sum to t that would be exponential time but because i'm just asking a yes or no question this choice only takes constant time and we get to sum them instead of product then because we're using memorization that is
4336	that we only have to sum over sub problems because we only compute each sub problem once so without memoization this would take exponential time just like fibonacci with memorization magic i just think this is beautiful so even though it's one of our simpler dps i think it's an impressive one okay uh topological order well let's look at these function calls so here we have to be a little bit careful when we call x recursively we always increment i but sometimes we don't decrement t sometimes t doesn't go down so if i wrote decreasing t here that would be bad because sometimes i call with the same value of t and i don't want to get into i want to ensure that this has already been computed when i try to compute this so i is the right thing and we should say decreasing i it doesn't actually matter how we order with respect to t just any order that is decreasing i will be good because these function calls always increase i okay we need
4337	a base case base cases let's see the natural given this aspect i think the natural thing is to have a base case when my suffix is empty which is when i equals n so this is x of uh n comma t for any little t because we don't have a lot of control of how t is changing but this is easy so this is saying if i give you no numbers what sums can you represent the only sum i can represent is 0. okay so if t equals 0 then the answer is yes and otherwise the answer is no so that's my base case and that's enough and we needed this base case because if we wrote x of n comma t this would try to call x of n plus 1 which doesn't make sense but x of n call in as a natural suffix which we only allowed i to go up to n and that's the empty suffix so this is enough we need the original problem uh which is the entire
4338	string from zero onwards and capital t for little t that's our target sum and then the running time as i said there are n times t sub problems theta and the amount of work we spend for each one that isn't recursion is constant we just do a couple subtractions additions do an or and recursive calls so constant time
4339	show you an example as a subproblem tag really helpful to see how these are hard to draw but they're easy to read i think they're helpful to show what's really going on in this dp this remember every node here corresponds to a possible subproblem we could have so we have the choices for little t on the top the choices for little i on the left so the original problem we care about is i equals 0 t equals 6. this is the same example that i showed you before where we have three or no it's a different example sorry my new set a is three four three one four numbers here my target value is six this is definitely possible i can add three and three this shows that a doesn't have to be sorted we're not assuming anything about the order of a and we're allowed duplicate values and we see indeed there's a y here for yes it is possible and how did i compute that well i just drew a bunch of arrows
4340	so there's vertical arrows here always going from each problem to the next one above it because we have this dependency x i of t calls x of i plus 1 comma t so that's the calls are going in this direction so the dependency order is you have to compute things lower down before you compute things up here um and indeed down here is the base case where we write yes for the first problem and no for all the others because we don't have any numbers we can't represent anything above zero okay and then we have these blue lines i just drew them a different color so they stand out hopefully and they correspond to the numbers here so our first choice is do we include a zero which is three so that's only possible if we're trying to represent a number uh that's greater than or equal to three which reminds me i forgot to write down in this dp i need to say this option is only an option if a i is less
4341	than or equal to t just move my comments here those are the same so this notation means i put this item in this set that we take an or of only if this condition holds okay otherwise i admit it because it's not a choice why is that important because i don't want to call x on a negative value of t we only are allowed to call x here when t is between zero and capital t so that's subtlety but important for a correct dp so then that's why there's no edge from here for example that goes three to the left because there's no vertex there there's no sub problem so only for uh little t from three onwards we have this edge that goes three back and that's just the same pattern over and over then our next number is four and so we have these edges that are go four to the right then our next number is three so we again have edges that go three to the right and then our next
4342	number is one so we have these nice diagonal edges that go one to the right and then what's happening in here at each stage let's take an interesting one maybe this vertex is we look at each of the incoming neighbors and we take the or so the incoming neighbor here has a no incoming neighbor here has a yes and so we write a yes here which means that given just these numbers three and one we can represent the number three namely by taking this edge of weight three sorry of length three and then just going straight down to a base case that's yes that's representing 0. so in this case we this example i didn't draw the parent pointers here but they're in the notes this yes is possible not from going this way but from going this way so we take the number three then we go down which means we skip the number four and then we go left which means we take the number three and then we go down which means
4343	we skip the number one okay so we can represent six as three plus three cool so subset sum not only can we solve the decision problem but by following parent pointers in the yes instances we can actually find a valid subset question you added that condition to the relation good question um so ins uh it's it's a generally useful technique to add if conditions to the cases to only when they apply you can write a lot of dps that way and that's why i wanted to stress it you could instead of adding this condition allow the case that little t is negative but you have to think about how negative would it be you might say well maybe t between minus big t and plus big t is enough i don't think so it should be um we're at some value t and we subtract some ai we don't know how the ai's compared to big t probably they're less than or equal to big t because they're not useful if they're bigger than big
4344	t so you could first prune the ais to guarantee all the ais are less than big t then minus big t to big t would work otherwise it's like minus the maximum ai up to big t would be enough i think yeah does this restrict to only the positive integers in the input ah do i i am implicitly assuming here that all the ai's are positive uh i think you can solve it with negative numbers but it's not uh and maybe we'll do it in recitation it is not as it's not a trivial change to this dp i've definitely thought about it before yeah so i should have said positive integers thank you
4345	but we come back to this question of is this a good algorithm is it polynomial time so we have this running time n times t so a new question is is n times big t polynomial and the answer is no why because for this problem what is the input size how many words of input do i have well i have these n integers and then i also have the target sum so similar to up above our input size is n plus one okay but now the labels really matter before it was l plus one and and our running time was a function of l now our input size is just n plus one but our running time is a function of both n and t not polynomial in input size n plus one you cannot write that n n times capital t is less than or equal to n plus 1 to the 27th power because you just don't know how n and t relate maybe t is at most n then we're happy but
4346	maybe it's not maybe t is 2 to the n why could it be 2 to the n uh because what do we know about capital t we assume implicitly throughout the course the t fits in a word that means it's a w bit number so that means it's at most two to the w and you might think well we know about a relation between w and n so we know t is at most 2 to the w if it's w bits and we know that our assumption is always that w is at least log n that's the word ram trans-dichotomous assumption but notice we don't know anything about an upper bound on w in order to upper bound t in terms of n i'd need to say that w is at most log n then this would be at most n and we'd be done but that's not very interesting and generally we allow w to be arbitrarily large with respect to log n it just has to be at least log n just to
4347	be able to index stuff so but w could be really big much bigger than log n for example w equals n is not a crazy idea i mean if if i have a machine that can represent n numbers why not represent n numbers each of which is n bits long and maybe it takes a little more time to compute on those you might want to scale your running times but it's quite reasonable to think about n-bit numbers and then this is like n times 2 to the n so this would actually be exponential time and if w is 2 to the n n times t is exponential in the problem size which is n plus 1. and that's just an example w could be bigger okay so this is not what we call a polynomial algorithm or strongly polynomial algorithm but it's still pretty good right as long as we know that capital t is not ginormous then this is a great algorithm so it's and we capture that notion with a concept called pseudo-polynomial
4348	it's not the best term but it's the established term it's like polynomial but not quite and the definition of this term so we have the definition of strongly polynomial time uh now uh pseudo-polynomial time this i'll write time here so you can measure other things pseudopolynomial uh is that we're polynomial uh in the input size just like before and the input numbers input integers okay so in this problem the input integers are capital t and a0 a1 up to a n minus 1. so we want now is a polynomial or what some people call a multinomial where our variables are all of these integers and we want to be polynomial in them so we're allowed to take some constant power of capital t and some constant number of the ais we can't just take the product of all of them that would be big
4349	and indeed this is a you might call it a quadratic polynomial in the input size and the and one of the numbers so this is this running time is pseudo poly but not poly and so while normally we think of polynomial time is good exponential time is bad pseudo-polynomial is what we normally call pretty good to be informal yeah so in particular pseudopolynomial implies polynomial in the special case so if the input integers are all at most polynomial in the input size this should sound familiar this is a constraint we've seen before this is the condition when radix sort runs in linear time ready sort runs in linear time exactly when all the input integers are polynomially bounded in n which is the size of the array which is the input size okay so same same condition is appearing again so this is sort of a fundamental setting to think about and let's see so in particular other structures we've seen like counting sort and direct access arrays are also pseudopolynomial any others fibonacci sorry
4350	rate export yes technically also rate of sort are all uh they're not strongly polynomial but they are pseudo-polynomial uh here we thought about this as a dependence on you which we got rid of using hashing but if you just use the order u running time for say build uh that u is is like are bound on the input integers and that's only good when this is polynomial in general it's pseudo-polynomial same with counting sort we had an order u now we improved this in radix sort to this running time that was uh n times log base n of u plus n if you want to be careful um so or put a ceiling uh now this is a running time that's a little bit better and this is usually called weekly polynomial don't want to spend much time on this but weekly polynomial is just like pseudo-polynomial but instead of being polynomial the input size and the input integers your polynomial in the log of the integers so this is better and it's almost as
4351	good as polynomial as strongly polynomial okay we won't really use this notion the only place that appears in this class is in rating sort but future classes you might care about so the the nesting is the best thing you can be is strongly polynomial we just call this polynomial in this class uh then we have weekly polynomial which is almost as good but you have this logarithmic dependence on the numbers and then the next level is pseudopolynomial this is not as good here this really only works well if the numbers are small logarithmic dependence is pretty good because even if they're exponential this is polynomial sounds funny but log of an exponential
4352	last thing i want to talk about is reflecting on all of the dynamic programs we've seen so far and characterizing them according to the the big techniques that we used in sort bot the first big technique was how do we define our sub problems did we take prefixes and suffixes or substrings of a sequence did we have multiple sequences and have to take products of those spaces did we have integers and have to take smaller versions of those integers sometimes that leads to pseudo-polynomial algorithms sometimes not and sometimes we also had sub problems that were defined in terms of vertices this just happened in shortest path problems because that's the only setting where we saw dp over graphs so let me characterize all the dps we've seen in lecture not the recitation ones for now in red so for example with the bowling problem with bowling pins we only had to deal with prefixes or suffixes because yeah we were only we could just think about what happened for the first couple of pins for
4353	example also for lcs we had to take two different sequences but then we just guessed what happened at the in with the first two items of each uh of each sequence and so that only left us with suffixes uh with longest increasing subsequence again we just guessed whether the first or maybe we assumed that the first item was in the longest increasing subsequence and then we tried to guess what the next item was but that again eliminated everything in between so we were just left with a suffix this leads me to another characterization of the kind of dynamic programming techniques which is for in addition to these basic sub-problems we often added constraints and expansion and lis is an example of what we call non-expansive constraint where we just added a constraint to the problem which was i'd want this first item to be in my longest increasing subsequence but that didn't actually change the number of sub-problems so it didn't expand the number of sub problems this is i think the only example we
4354	saw with this feature most of the other times when we added a constraint we also increased the number of sub problems which we'll get to okay also in a certain sense there's multiple ways to think about this one floyd warshall is a problem or we define subproblems based on prefixes of the vertices right we had vertices 1 through n we said is their shortest path using vertices just 1 to i so that's a prefix of the vertex set in a particular order so you can think of floyd warshall as being as involving a prefix you can also think of it as you're given an integer i and you're only allowed to use vertices less than or equal to i and so it's also kind of an integer sub problem but i will leave it up there also the two examples we saw today rod cutting kind of uh you could think of it as either a prefix on the values or i would prefer to think of it down here where we had an integer
4355	and we were considering smaller integers also and but subset sum definitely had a suffix in addition to having an integer subproblem so rod cutting you can put down here because we looked at smaller integers or up here but subset sum really is up here and down here because we both looked at suffixes and smaller values of t okay uh fibonacci also fits down here fibonacci was another case where we had a number n and we looked at integers smaller than n ah good i think i've done these now what problems involve substrings we saw two of them one was the alternating coin game because we were taking from left or right and so we had to look at substrings in between and the other is parenthesization where we had to guess something in the middle and that left the prefix before it and the suffix after both of those are typical ways where you get substring problems uh okay so pseudo poly both of these are pseudo poly and those those are the ones that
4356	we've seen that are dynamic programs pseudopoly and then with vertices it's all the shortest path uh problems where we also had a parameter which was a vertex these are natural because in the goal of sort of single short shortest paths is distance to each vertex and so naturally we had a sub problem for each vertex for dag shortest paths for bellman ford and for floyd warshall okay back to subproblem expansion we saw a couple of examples alternating coin game and parenthesization sorry not parenthesization uh yeah parenthesization sorry arithmetic parenthesization so here we consider two different versions of each subproblem one where i go first and one where you go first and that was really handy though not necessary for parenthesization it turned out we needed both min and max in order to solve max so we really only cared about max so we doubled the number of sub problems to make it solvable for uh piano and guitar fingering we increase the number of sub problems by a constant or f or some f to
4357	the f or some uh for five fingers this is a reasonable constant um for some amount of state that we wanted to keep track of of the past and one example where we had linear expansion sort of is bellman ford so here we were expanding by how many edges are in the shortest path so we really only cared about finding shortest paths we said oh what about at most eye edges so you can think of that as adding a constraint and then there's n different variations of this these sub problems which leads to expansion what you could also think of it as just adding a single constraint which is i care about the number of edges and that input is an integer and then we're looking at the natural subproblem for integers which is we care about up to length n minus 1 and now let's consider all lengths smaller than n minus 1. okay and finally the other main feature we had is in the recurrence relation and all these shortest path tags how
4358	many incoming edges did we have how many different branches did we have to consider and then uh combine in some way so we saw a lot of examples with constant branching fibonacci where we just was the obvious two-way branching bowling where we had a couple of choices at the beginning lcs longest common subsequence where we had a couple choices what to do at the beginning alternating coin game similarly do we take from the left or the right so just two choices floyd warshall there's two choices do we use that vertex or not subset sum do we include this item in the subset or not okay so that was all constant branching in a lot of the graph problems we got ordered degree branching which leads to an order e term in the final running time namely dag shortest paths and bellman ford and then a lot of examples had linear branching um in particular longest increasing subsequence where we didn't know what the next increasing item was so there are n possible choices for it
4359	parenthesization where we had to choose anybody in the middle as the last operator and rod cutting that we saw today we could cut the first rod we cut could be any length and then finally once you've considered all recursed on all these sub problems you have to combine them somehow and in a lot of the problems we actually just take one the one best choice and that is our final solution and in those problems the final solution ends up being finding some kind of shortest path in a dag but there are a few cases where we actually took multiple solutions and combined them together to get the overall solution and this includes fibonacci which is we added them not too interesting floyd warshall we concatenated two paths and parenthesization is maybe the most interesting where we had to take two parts the prefix and the suffix how to solve them and then multiply or add them together and so these problems are not well represented by shortest path and a dag still a dag involved
4360	but it's like a multi-path thing and then finally at the original problem often it's just a single sub-problem is the original problem and there are a few examples namely dag shortest paths and longest increasing subsequence and bellman ford and floyd warshall these were the order that we covered them so the the three shortest paths and then longest increasing subsequence where uh here because we added this condition we had to try all the possible choices for this condition i think uh do we also have one here today no okay um so in fact in retrospect or i mean this we knew this from the beginning but for you in retrospect these four dp lectures were all about showing you these main techniques of dynamic programming from how to set up simple sub problems to different types of basic sub problems to constraining or expanding those sub problems and having initially very simple branching and then getting to bigger branching and different kinds of combination we wanted to show you all these ideas in some order and
4361	if you look back at the sequence that we covered problems we're kind of slowly adding these different main techniques to dp and that's why we chose the examples we did there of course many more examples of dp very powerful technique
4362	[SQUEAKING] [RUSTLING] [CLICKING] ERIK DEMAINE: All right welcome back to 006, Dynamic Programming. We're now in step two out of four-- going to see a bunch more examples-- three more examples of dynamic programming-- longest common subsequence, longest increasing subsequence, and kind of a made up problem from 006, alternating coin game. And through those examples, we're going to explore a few new ideas, things we haven't seen in action before yet-- dealing with multiple sequences, instead of just one; dealing with substrings of sequences, instead of prefixes and suffixes; parent pointers so we can recover solutions, like in shortest paths. And a big one, which will mostly be fleshed out in the next lecture, is subproblem constraint and expansion. This is all part of the SRTBOT paradigm-- remember, subproblems, relations, topological order, base case, original problem, and time. Here is subproblems and relations. I've written down both what these things are and the key lessons we got from the first dynamic programming lecture. Namely, we want to split up our problem into multiple subproblems, and if your input is
4363	a sequence-- that's the main case we've seen so far-- like the bowling problem, for example, then the natural subproblems to try are prefixes, suffixes, or substrings. Prefixes and suffixes are nice, because there's few of them. There's only a linear number of them. In general, we want a polynomial number. Sometimes you can get away with one of these. They're usually about the same. Sometimes you need substrings. There's quadratically many of those. Then, once you set up the subproblems, which-- it's easy to set up some problems, but hard to do it right-- to test whether you did it right is, can I write a recurrence relation that relates one subproblem solution to smaller subproblems solutions? And the general trick for doing this is to identify some feature of the solution you're looking for. So you're trying to solve some subproblem, and you try to ask a question whose answer would let you reduce to a smaller subproblem. So if you can figure out what that question is, and that question only has a polynomial number of answers,
4364	then boom-- and you've only got polynomial number of subproblems, then you will get a polynomial running time. So I have, I think, another way to say this. We just locally brute force all possible answers to whatever question we come up with, as long as there's polynomially many. And then each of them is going to recursively call the smaller subproblems, but because we memoize, we'll only solve each subproblem once. And so on the end, the running time will be, at most, the number of subproblems times the non-recursive work done in that relation. For that to work, of course, the relations between subproblems must be acyclic, so we'd like to give an explicit topological order. Usually it's a couple of for loops. But this is a topological order in the subproblem DAG, which I defined somewhat informally last time. the. Vertices are subproblems, and I want to draw an edge from a smaller problem to a bigger problem, meaning that, if evaluating b in this relation calls a, then I'll draw an arrow from a to b,
4365	from the things I need to do first to the things I'll do later. So then topological order will be ready-- by the time I try to compute b, I will have already computed a. And of course, the relation also needs base cases. And then sometimes the original problem we want to solve is just one of those subproblems. Sometimes we need to combine multiple. We'll see that today. So that's a review of this framework. And let's dive into longest common subsequence. This is kind of a classic problem. It even has applications to things like computational biology. You have two DNA sequences. You want to measure how in common they are. One version of that--
4366	called edit distance-- this is a simplest, cleanest version, where I give you two sequences-- I have an example here. So for example, it could be a sequence of letters. So my first sequence spells hieroglyphology-- study of hieroglyphs. And second sequence spells Michelangelo. And what I'd like is a subsequence. So remember, substring has to be some continuous range, some interval. Subsequence-- you can take any subset of the letters in your sequence or any subset of the items in your sequence. So you can have blanks in between. You can skip over items. And so what we want is the longest sequence that is a subsequence of both the first string, the first sequence, and the second string. And if you stare at this long enough, the longest common subsequence-- I don't think it's unique, but there is a longest common sequence, which is hello hiding in there. And that is a longest common subsequence. So given that input, the goal is to compute hello, or whatever the longest common subsequence is. So we're given-- write this down
4367	carefully-- given two sequences. Let me name them A and B. We want to find the longest sequence L that's a subsequence both A and B. So that's the problem definition, and we're going to see how to solve it using dynamic programming. And whereas, in the bowling problem, we just had a single sequence of numbers-- the values of the bowling pins-- here we have two sequences. And so we need a new trick. Before, we said, OK, if our subproblems-- or sorry-- if our input consists of a single sequence, we'll try prefixes, suffixes, or substrings. Now we've got two sequences, so somehow we need to combine multiple inputs together.
4368	subproblems for multiple inputs. It's a very simple trick. We just take the product, multiply the subproblem spaces. OK. In the sense of cross product of sets, and in particular, from a combinatorial perspective-- so we have two inputs, the first sequence A and the second sequence B. For each of them, there's a natural choice, or there's three natural choices. We could do one of these. I will choose suffixes for A and suffixes for B. You could do some other combination, but that would be enough for here. And then I want to multiply these spaces, meaning the number of subproblems is going to be the product of the number of suffixes here times the number of suffixes here. And in other words, every subproblem in LCS is going to be a pair of suffixes. So let me write that down. So for LCS, our subproblems are L of i, j-- this is going to be the longest common subsequence-- of the suffix of A starting at i and the suffix of B starting at j. And just
4369	to be clear how many there are, I'll give the ranges for i and j-- not going to assume the sequences are the same length, like in the example. So I'll write lengths of A and lengths of B. I like to include the empty suffix. So when j equals the length of B that's 0 items in it, because that makes for really easy base cases. So I'd like to include those in my problems. So that was the S in SRTBOT. Now I claim that set subproblems is enough to do a relation-- recursive relation among them. So I'd like to solve every subproblems L i, j. Relation is actually pretty simple, but it's maybe not so obvious. So the idea is, because we're looking at suffixes, we should always think about what happens in the first letter, because if we remove that first letter, then we get a smaller suffix. If you're doing prefixes, you should always look at the last letter. Either one would work for this problem. So we're doing suffixes. So we look at
4370	A of i and we look at B of j. That's the first letter in the suffix A starting at i and the suffix B starting at j. And there are two cases. They could be equal or different. I think the easier case to think about is when they're different. So like in hieroglyphology and Michelangelo, if we look at the whole string, say, the first letter in the top one is H. The first letter in the second one is M. Those are different letters, so clearly, one of those letters is not in the common subsequence, because they don't match. I can't start with an H. Well, I can start with an H, I could start with an M, but I can't start with both. One of those letters is not in the output. In this example, it's M. But I don't know which one, so I have this question. I want to identify some question. And the question is, should I-- do I know that the H is not in the answer or do I know
4371	that M is not in the answer-- the final longest common subsequence? We don't know which, so we'll just try both. And then we're trying to maximize the length of our common subsequence, so we'll take the max of L i plus 1 j and L i, j minus 1. So the intuition here is one of-- at least one of Ai and Bj is not in the LCS. Got this wrong. j plus 1-- sorry-- thinking about substrings already. Yeah. These are the beginning points, so I want exclude the i-th letter-- so if Ai is not in, then I want to look at the suffix starting at i plus 1. If Bj is not in, then I want to look at the suffix starting at j plus 1. So the indices are always increasing in the function calls. And the other case is that they're equal. So this one I have a little bit harder time arguing. I'm going to write the answer, and then prove that the answer is correct. Here I claim you don't need to
4372	make any choices. There's no question you need to answer. You can actually guarantee that Ai and Bj might as well be in the longest common subsequence. And so I get one point for that and then I recurse on all the remaining letters-- so from i plus 1 on and from j plus 1 on. Why is this OK? Well, we have A, B. We're starting at position i, and starting at position j for B. Think of some optimal solution, some longest common subsequence. So it pairs up letters in some way. This would be some non-crossing pairing between equal letters. So first case is that maybe i and j aren't paired with anything. Well, that's silly, because if they're not paired with anything, you have some bearing on the rest of the items. You can add this pair, and that would be a longer subsequence. So that would be a contradiction. If we're taking-- imagining some hypothetical optimal solution, it has to pair one of these with something. Maybe it pairs i with something else, though. Well,
4373	if we have a longest common subsequence that looks like that, I can just instead pair i with Bj. If I had this pairing, I'm actually not using any of these letters, so why don't I just use this letter instead? So you can argue there is the longest common subsequence that matches Ai with Bj, and so then we can guarantee by that little proof that we get one point for matching them up-- that we don't have to max this with anything. OK, so two cases-- pretty simple formula. And then we're basically done. We just need to fill in the rest of SRTBOT.
4374	So this I'll write as for loops. Because I'm dealing with suffixes, we want to start with the empty suffixes, and then work our way to larger and larger suffixes. So this might seem backwards. If you're doing prefixes, it would be an increasing order. There's all sorts of orders. You could flip the i and j. It's very symmetric, so it doesn't really matter. But anything that's generally decreasing i and j is good. Then we have base cases. These are when one of the sequences is empty. I don't care how many items are in B, but if A has no items, there's no common subsequence. It's empty. And same for no matter how big A is, if I have exhausted the B string-- I start from beyond the last item-- then I should get 0. Then the original problem we want to solve is L 0, 0-- that's just the longest common sequence of the entire A and the entire B-- and time. OK, so for time, we need to know how many subproblems there are. It's
4375	A plus 1 times B plus 1. I'll just call that theta A, B. Assume these are not empty subsequences. So this is the number of subproblems. And then what we care about is, how much time do we spend for each sub problem in evaluating this recurrence relation? So we ignore the cost to recursively call these L's, because they are smaller subproblems. They're already dealt with when I multiply by the number of subproblems. So I just care about this max computation and this equality check, and we'll say those each cost constant time. So this is quadratic time. If the two strings are size n, this is n squared. In general, it's the product of the two string sizes. And that's longest common substring-- so pretty straightforward. Other than this little argument understanding the case when they're equal, the easy case where they're unequal, we just try the only two things we could do. One of Ai and Bj is not in the longest common subsequence, so what I like to say is we guess which of
4376	those is the correct one that is not in the longest common subsequence. And if we guess that it's in A, then we'll recurse on that side. If we guess that it's in j, then we'll recurse on-- by increasing j. I'd like to assume-- not really-- that we always make the correct guess, that we made the correct choice, whether it's i or j. Now, we don't actually know how to do that, so instead, we brute force. We try both of them, and then, because we're trying to maximize, we take the max-- just another way of thinking about it. But overall, very straightforward-- the only added complication here is we had to deal with two sequences simultaneously, and we just took the product of those-- pretty easy. In general, if you have some constant number of sequences, you can afford to do this. You'll still get polynomial. But of course, once you go to n sequences, you can't afford this. You would an n to the n behavior, so that's a limit to how far you could
4377	go. Two sequences is fine, three sequences is fine, but n sequences-- there probably is no polynomial time algorithm for this problem. Cool-- I want to show you an example. I have an example here. I didn't want to try out hieroglyphology versus Michelangelo, so I came up with another example. Their habit is to say hi. So the longest common subsequence of there and habit is HI. And it's a giant-- well, not that giant-- it looks kind of like a grid graph. The base cases are out here, because those correspond-- each of these nodes is a subproblem, and this corresponds to, what is the longest common subsequence between EIR and ABIT? And it should be I. It's the only letter they have in common, and that's why there's a 1 here to say that the longest common subsequence has a 1-- has size 1. The base cases are when either their has been emptied or when habit has been emptied, so those all have 0's on the outside. And then the problem we care about is this
4378	one. It's their versus habit. Claim is the length is 2.
4379	like we talked about with BFS, and shortest paths, and so on. So we had this choice-- sometimes we had a choice-- on whether we recursed here or recursed here was the best thing to do. I'll draw in red the arrow from L i, j-- sorry-- to L i, j from one of these in this case. And in this case, there was no choice, but I'll still draw in red that arrow.
4380	where the letters match. Here H equals H. I equals I here, so I draw this diagonal edge. That's that first case, where the letters are equal, and so I recurse by increasing i and j. That's why I get a diagonal edge. There's also one over here, where T equals T. So for those, we're getting a 1 plus. You see this 1 is 1 larger than the 0. This 2 is 1 larger than the 1. This 1 is one larger than the 0. And for every other vertex, we are rehearsing this way and this way. We see what those two numbers are, and we take the max. So this whole diagram is just filled in by-- for each position, where they're not equal. We look at the guy below. We look at the guy to the right. Those are the slightly smaller substrings. We look at those values. We take the max. As long as you compute this in a generally right-to-left and bottom-up fashion, whenever you're trying to compute a guy, you will have the--
4381	its predecessors already computed. That's the topological order of this graph. And then, at the end, we get our answer, which is 2. And now, if we pay attention to where we came from-- for example, this vertex had to come from this direction-- 2 is the max of 2 and 1, so I highlight the 2 edge. And if I follow this path, there should be a unique path to some base case. We don't know which one. And in this case, the diagonal edges correspond to my matching letters. So there's the H here, followed by the I here. And so HI is our longest common substring. In general, we just follow these pointers backward-- the red pointers-- and we get our answer. So not only do we compute the length of the LCS, but we actually can find the LCS using parent pointers. And this is a concept you can use in most dynamic programs, including all the ones from today. OK, any questions about LCS? All right-- perfectly clear to everyone in the audience. Now we
4382	move onto longest increasing subsequence, which-- did I lose a page here? I just disordered them. OK, this problem has almost the same name,
4383	longest increasing subsequence-- LIS, instead of LCS-- both famous problems, examples of dynamic programming. Here we're just given one sequence, like carbohydrate. So this is a sequence of letters, and I want to find the longest subsequence of this sequence that is increasing-- strictly increasing, let's say-- so in this case, alphabetically. I could include CR, for example, but not CB. That would be a descending subsequence. In this example, the right answer-- or a right answer is abort. There aren't very many English words that are increasing, but there are some, and I looked through all of them. As I just implemented this dynamic program we're about to write down, it took me like two minutes to write down the DP, and then more work to read the dictionary and look for cool examples. So in general, we're given some sequence A, and we want to find the longest increasing subsequence of A-- the longest sequence that is increasing, strictly. We could use the same thing to solve not strictly increasing, but-- so here things are going to be
4384	a little trickier. It's easy, in that we just have a single sequence. So again, we think, OK, let's look at our chart here. We could try prefixes, suffixes, or substrings. I personally prefer suffixes. Jason prefers prefixes. Whatever you prefer is fine, but always, generally, start there, because there's nothing in this problem that makes me think I need to delete things from both ends. AUDIENCE: I have a question. ERIK DEMAINE: Yeah-- question? AUDIENCE: Isn't the answer to this problem always 26? ERIK DEMAINE: Is the answer always, at most, 26? Yes, if you're dealing with English words-- so when I say sequence here, this is a sequence of arbitrary integers-- word size integers. So there you can have a ton of variety. This is just for the fun of examples, I've drawn this. But even if the answer is 26, finding that longest common subsequence is-- the obvious algorithm would be to take all substrings of size 26, which is n to the 26. We're going to do much faster than that here. N squared time. And
4385	then, if you remove the strictly increasing, then it can be arbitrarily large. OK, so let's try to do this. Maybe I won't be so pessimistic to write attempt here. Let's just go for it. So I want some subproblems, and I'm going to choose suffixes. So I'm going to define L of i to be the longest increasing subsequence of the suffix of A starting at i. That's the obvious thing to do. And now I'm going to leave myself a little space, and then I'd like a relation on these. So I'd like to say what L of i is. And what do I have to work with? Well, I have live things larger than i. Those would be smaller suffixes. But let's go back to, what is a question that I could ask about this subproblem that might help me figure out what the longest increasing subsequence looks like? So we're looking at a-- here's A from i on. Longest increasing subsequence is some subsequence. And we'd like to remove letter i. Now, when we do that,
4386	there are two choices. Maybe i is in the longest increasing subsequence, or it's not in. So the question I would like to answer is, is i in the longest increasing subsequence of A-- of A from i onwards? This is a binary question. There are two options-- so again, just like before. And so I can brute force those two options. And then I want the longest one, so I'm going to take the max. So I'd like to take the max of something like Li plus 1. So in the case that I don't put i in the solution, that's fine. Then I just look at i plus 1 on, and recursively compute that, and that would be my answer. And the other option is that I do put i in the longest increasing subsequence, so I do 1 plus the rest L i plus 1. If I close this brace, this would be a very strange recurrence, because this is always bigger than this one. There's something wrong here, and the something wrong is I haven't enforced
4387	increasing at all. There's no constraints here. It's just saying, well, I'll i put in, and then I'll do whatever remains, and I'll pray that that's increasing-- probably won't be, because indeed, if i is a letter-- or is a number that is strictly greater than i plus 1, then this will be wrong. So I really can't always do this. I could check whether i plus 1 is in the answer, but some-- but I don't. I can check whether the letter i is less than letter i plus 1. But maybe I put this in the longest increasing subsequence and then I put this in the longest increasing subsequence, and so I need to compare these two items. But I don't know when that's going to happen. Things seem really hard. And indeed, there's no way, from this subproblem definition, to write down a relation. But there is a slight tweak to this definition that makes it work. So the trouble we have here-- and this is the idea of subproblem constraints or conditions-- the trouble we have
4388	is, when we recursively compute the longest increasing subsequence on the remainder, we don't know the first item in that answer. Maybe it's i plus 1. Maybe it's some guy over here. If we knew who it was, then we could compare that item to item i. And so what we'd like to do is add a constraint to the subproblem that somehow lets us know where the longest increasing subsequence starts. So what I would like to say is long as increasing subsequence of that suffix that starts with A of i. So in other words, it includes A of i. This was a separate question. OK, this is a bit of a funny constraint. It changes the problem. It's no longer what we want to solve. If you think about the original problem, before, it was solving L of 0. We just want the longest increasing subsequence of the whole thing. Now it's not necessarily L of 0. L of 0 means, what is the longest increasing sub sequence of the whole sequence A that includes the first
4389	letter of A? And maybe we do include the first letter of A, maybe we don't we don't know where the longest increasing subsequence starts. Here, for example, it didn't. It started at the second letter. But conveniently, it's OK that we don't know, because that's just another question we could ask is, where do we start? Where might the LIS start? Could start at the first letter, second letter, third letter-- there's only n choices, and let's just take the max of all of them. So before I get to the relation, let's solve this problem. I just want the max of L of i for all i. I guess we've been writing size of A here. OK, the maximum will be the overall longest increasing subsequence. So if I could find longest increasing sub sequence that includes the first letter, or the longest one that includes the second letter, and so on-- so it starts at the first letter, starts at the second letter-- then this max will be the longest overall. This subproblem is not what I
4390	really wanted, but it's still good enough, because it lets me solve my original problem. And this is adding an extra constraint to my problem. And doing this is challenging. Thinking about what the right constraint that would let you solve your problem is tricky, especially in the beginning. But for now, let's just take this as a thing that works. Why does it work? Because now I can say-- well, this term was fine, max-- so I'm trying to write longest increasing subsequence starting with the i-th letter, versus-- yeah, actually, no. This is just going to be different. OK, so now I get to the central issue, which is I know, by the definition of L of i, that I include letter i. This is going to be in my longest increasing subsequence. That's what I'm looking for, this definition. But I don't know what the second letter is-- could be i plus 1, could be i plus 2, could be anything bigger. Whenever there's something I don't know, I'll just brute force it. I don't care that
4391	I don't know. I'll just take a max over all the possible choices. Let's say that the next letter included in the longest increasing subsequence i is j. Then I would like to look at L of j. Now, I don't know what j is, but I'll just brute force all possible choices for j. So that's going to be i strictly less than j, because I don't want include the same letter i again. And otherwise, I would get an infinite recursive loop, if I put less than or equal to here. And maybe I don't do anything else to n. OK, not quite done-- now-- this is the interesting part-- I can enforce increasing, because I can't just choose any letter j to the right of i. Also, the number-- or letter that's written in here has to be greater than the number that's written here. That's the strictly increasing property. So I can add as a constraint in this max to say A of i am strictly less than A of j. And if you wanted non-strictly
4392	increasing, you would add an equal there. This is mathematical notation. In Python, you would say max open paren of this thing for j in this range, if this holds. So I'm just doing for loop, but I only do-- I only look at the possible choices for j when the strict increasing property holds. And then, when that holds, I put-- check this. Now, this set might be empty. I need to define what the max is when it's empty. Oh, I also need a 1 plus, don't I? Let me just do 1 plus. So we're told that i is in the answer, so we always get 1. And then the remainder is this or 0. If there are no Aj's greater than Ai, then we'll default to 0 and say that i is the only item in my increasing subsequence. OK, so there are a few details to get right, but in general, once you figure out what these recurrences look like, they're very simple. This is one line of code, and then all you need in
4393	addition to this is the original subproblem and some other things. We need the base cases, but I should do them in order. Topological order is just the usual for loop, because I'm doing suffixes. It's going to be i equals length of A down to 0. Base case is going to be L of length of A, which is 0, because there's no letters in that suffix. And we already did O, and then time-- is a little different from the past examples. So number of subproblems, just like usual, is linear length of A subproblems. It's only one sequence we're thinking about now, unlike the previous example. But the work we're doing in this relation now is non-trivial work. Before we were just guessing among two different choices. Now we're guessing among up to n different choices. This n here is length of A. And so we have theta length of A, non-recursive work that we're doing in each subproblem. Or you might think of this as choices that we're considering. And for each choice, we're just spending--
4394	I mean, we're just taking a max of those items, adding 1. So that's a constant overhead. And so we just get this product, which is A squared-- cool. So that's longest increasing subsequence. Make sure I didn't miss anything else-- so we're using this idea of asking a question, and guessing or brute forcing the answer to that question in two places. One place is we're promising-- we're requesting that the longest increasing subsequence starts at i, so then the question is, well, what is the very second item that's in the longest increasing subsequence that starts with i? We're calling that j, and we're brute forcing all the possible choices that j could be, which conveniently lets us check, confirm that it's actually an increasing subsequence locally from i to j. And then L of j will take care of the rest. By induction, the rest of the longest increase in subsequence starting at j will also be increasing. And so this guarantees, by induction, the whole thing will be increasing. Then we also use this local brute
4395	force to solve the original problem. So we added this constraint of starting at i, but we didn't actually know overall where to start. But that's fine, because there's only A choices. So I should mention, in the running time analysis-- so they're solving the subproblems. That's fine, but then there's also a plus whatever it costs to solve the original problem. But that's OK. That's length of A. All of this plus length of A is still length of A squared. But if you're doing exponential work here, that would be bad. We have to do some reasonable amount of work to solve the original problem in terms of all the subproblems. I have an example hiding here. This is a little harder to stare at. Here I have empathy. And this example is not-- doesn't have much empathy, because the longest increasing subsequence of empathy is empty. Empty is one of the few English words that's increasing. And the hard part here is drawing the DAG. It's almost the complete graph, but we only draw edges from smaller
4396	letters to bigger letters. So we draw from E to M, from E to P, from E not to A-- there's no edge from E to A-- from E to T, not from E to H, but yes from E to Y. And then we also draw from E to the base case, which is there's no more letters. That edge to the base case is-- corresponds to this 0, or I guess this n, where we say, oh, let's just recurse. Let's just throw away-- actually, maybe we don't need the union 0 there, in fact, because we include L of n, which is the empty substring. Then the definition of L is a little funny. What does it mean to say you start with A of n? Hm? AUDIENCE: If we define A of n. ERIK DEMAINE: Right, A of n is not defined, so that's not so nice. So maybe fix that. n equals case. OK, but I'm still going to draw an edge there-- conceptually say, oh, we're just done at that point. That's the base
4397	case, where we have no string left-- cool. And when I said from to to actually, I meant the reverse. All the edges go from right to left. And then what we're doing is looking for the longest
4398	Longest path is maybe a problem we've talked about in problem session, because it's a DAG-- well, longest path is the same thing as shortest path, if you just negate all the weights. There are no weights in this picture, so if you just put negative 1 on all these edges and ask for the shortest path from the base to anywhere-- so single source shortest paths from this base-- then we would end up getting this path, which, if you look at it, is E-M-P-T-Y, empty. And so that shortest path is indeed the right answer. What I've drawn here is the shortest path tree. So also, if you wanted the longest increasing subsequence starting at A, then it is A-T-Y, just by following the red arrows here. And how do you get that? You just draw the parent pointers, just like we did before.
4399	be solved with shortest paths. Once I construct this graph, you can do the shortest path from some base-- I don't know which one-- to here. If you put negative 1 on all of the diagonal edges and you put weight 0 everywhere else, then that corresponds to-- the shortest path in that graph will correspond to the longest-- the path with the most diagonal edges. And that makes sense, because the diagonal is where we actually get letters in common. And so in this case, it's 2. So both of these dynamic programs could instead-- instead of writing them as a recursive thing with memoization or writing them bottom-up as a for loop and then doing the computation, you could instead construct a graph and then run DAG shortest paths on it. But the point is these are the same thing. It's actually a lot simpler to just write the dynamic programming code, because it's just a for loop and then a recurrence. So you're just updating an array. Because you already know what the topological order is, you
4400	don't have to write a generic depth for search algorithm, take the finishing order, reverse it, and then run this-- run DAG shortest paths with relaxation-- much simpler to just write down the recurrence, once you figured it out. But they are the same in these examples. In Fibonacci, for example, you cannot write Fibonacci as a single source shortest paths problem, but a lot of DPs you can write as shortest paths problem-- just a connection to things we've seen. All right, last example, last problem for today-- we'll do more next week.
4401	Alternating coin game-- this is a two player game. We're going to find the optimal strategy in this game. In general, you have a sequence of coins, and we have two players. They take turns. So given coins of value v0 to v n minus 1-- so it's a sequence. They're given in order-- in some order-- for example, 5, 10, 100, 25-- not necessarily sorted order. And the rules of the game are we're going to take turns. I'm going to take turns with you. I'm going to use I and you to refer to the two players. And so in each turn, either one-- whoever's turn it is, I get to-- we get to choose either the first coin or the last coin among the coins that remain. So at the beginning, I can choose 5 or 25. And I might think, oh, 25's really good. That's better than 5. I should choose that. But then, of course, you're going next, and you're going to choose 100, and you'll win the game. You'll get more of the total
4402	value of the coins. So in this is example, a better strategy is to take the 5, because then the 100 is still in the middle. And so once I take 5, you get to choose 10 or 25. At this point, you'd probably prefer 25, because that's better than 10. But whichever you choose, I can take the 100. And so I get 105 points, and you're going to get 35 points. OK-- good example for me. So that's easy for a simple example, but in general, there are exponentially many strategies here. At each step, either of us could go left or right-- choose is the leftmost or the rightmost. And we're going to give a dynamic programming algorithm that just solves this fast. I didn't mention-- so this algorithm is quadratic time, but it can be made n log n time. It's a fun exercise. Using a lot of the data structure augmentation stuff we've done, you can make this n log n. This algorithm, I think, is going to be n squared time. So I won't
4403	right the problem exactly, but I think you know the rules. Choose leftmost or rightmost coin, alternating moves. So I'd like to define some subproblems. And this is a problem that's very naturally a substring problem. If I just looked at suffixes, that would deal great with-- if I'm deleting coins from the left, but as soon as I delete-- and if I delete coins only from the right, that would give me prefixes. But I'll tell you now, there's no dynamic programming where the answer is suffixes and prefixes. You can do suffixes or prefixes, but if you need both, you almost certainly need substring, because as soon as I delete the first coin, and then maybe you take the second coin-- that's exactly the optimal strategy here-- now you have an arbitrary substring in the middle. But substrings are enough, because we're only leading from the ends. We'll look at substrings. So more precisely-- this is just the intuition-- we're going to define some generic x of i, j is going to be what is the maximum total
4404	value I can get from this game, if we play it on coins of value Vi to Vj. So that's a substring. So this is one way to write down the subproblems, and it's also a good way. You could write down a relation on this definition of subproblems. But I'm low on time. There's two ways to solve this problem. This is a reasonable way, exploiting that the game is zero-sum. But I'd like to change just a little bit to give you, I think, what's a cleaner way to solve the problem, which is to add a third coordinate to my subproblems. So now it's parameterized by three things. P here is-- only has two choices. It's me or you. And this gets at a point that's maybe not totally clear from this definition-- max total value that I can get from these-- this substring of coins. But this is not obviously what I need. So obviously, at the beginning, I want the whole string and I want to know what my maximum value is-- fine. And I
4405	go first in this game. I didn't specify, but I do. [INAUDIBLE] But as soon as I do a move-- as soon as I take the first coin, for example-- it's now your turn. And so I don't really want to know the maximum total value that I would get if I go first. I'd like to say, if player P goes first. I'd really like to know what happens in the case where you go first. So for some of the substrings, I want to know what happens when you go first, and for some of them, I want to know what happens when I go first, because as soon as I make a move, it's your turn. And so we're going to flip back and forth between P being me and P being you-- P-U. So you don't have to parameterize. There's a way to write the recurrence otherwise, but this is, I think, a lot more intuitive, because now we can do a very simple relation, which is as follows. So I'm going to split into two
4406	cases. One is x of i, j, me and the other is x of i, j, you. So x of i, j, me-- so I have some substring from i to j. What could I do? I could take the first coin or I could take the second coin. Which should I do? That's my question. What is my first move? Should I take the first coin or the second coin? So this is my question. What is the first move? There are exactly two possible answers to that question, so we can afford to just brute force them and take the max. If we're moving, we want the maximum number of points we can get-- maximum total value of the two choices. So if I take from the i side, the left side, that would be x sub i plus 1, j. Sorry. And now, crucially, we flip players, because then it's your turn. And if I take from the j side, that will make it j minus 1. This is what I accidentally wrote at the beginning of
4407	lecture. Also flip players. So either I shrink on the i side or I shrink on the j side. Oh, I should add on here the value of the coin that I get, and add on the value the coin that I took. This is an expression inside the max. That sum. And if I take the max those two options, that will give-- that is my local brute force the best choice of how many-- what are the total value of coins I will get out of the remainder, given that you start, plus this coin that I took right now in the first step, and for the two possible choices of what that coin is? OK, what remains is, how do we define this x of i, j, you. This is a little bit funnier, but it's conceptually similar. I'm going to write basically the same thing here, but with me, instead of you-- because again, it flips. This is, if you go first, then the very next move will be me. So this is just the symmetric
4408	formula here. I can even put the braces in-- so far, the same. Now, I don't put in the plus Vi and I don't put in the plus Vj here, because if you're moving, I don't get those points. So there's an asymmetry in this definition. You could define it in different ways, but this is the maximum total value that I would get if you start. So in your first move, you get some points, but I don't get any points out of that. So there's no plus Vi. There's no plus Vj. It's just you either choose the i-th coin or you choose the j-th coin, and then the coins that remain for me shrink accordingly. Now, you're kind of a pain in the ass. You're an adversary you're trying to minimize my score potentially because you're trying to maximize your score. This is a 0 sum game. So anything that you get I don't get. If you want to maximize your score, you're trying to minimize my score. These are symmetric things. And so if you think
4409	for a while, the right thing to put here is min. From our perspective, we're imagining what is the worst case that could happen, no matter what you do. And we don't have control over what you do, and so we'd really like to see, what score would I get if you chose the i-th coin? What score do you get if you chose the j-th coin? And then what we get is going to be the worst of those two possibilities. So when we get to choose, we're maximizing. And this is a general two player phenomenon that, when you choose, we end up minimizing, because that's the saddest thing that could happen to us. OK, this is one way to write a recurrence relation. We have, of course, all of SRTBOT to do, so the topological order here is in increasing length of substance. So the T is increasing j minus i. Start with empty strings. So base case is that x of i, i, me is Vi. So here I'm inclusive in both ends in this definition.
4410	So there is a coin I can take at the end. But if you move last and there's one coin left, then I don't get it, so it's 0. Then we have the original problem that is x i, j, me-- sorry-- x 0, n. That's the entire coin set, starting with me. That was the problem I wanted to do. And then the running time we get is the number of subproblems-- that's theta n squared, because we're doing substrings-- times the amount of non-recursive work I do here. That's just a max of two numbers. Very simple. Constant time. So this is quadratic. Let me show you an example. This is hard to draw, but what I've described here is called solution 2 in the notes. So here's our sequence-- 5, 10, 100, 25-- in both directions. And what we're interested in is all substrings. So over here I've written the choice for i. So we start at one of these, and if you start here, you can't end earlier than there. So that's why we're in the
4411	upper diagonal of this matrix. And then there's two versions of each problem-- the white version and the blue version just down and to the right of it. If you can't see what blue is, this is the version where you start. This is the version where I start. And I've labeled here all of the different numbers. Please admire, because this took a long time to draw. But in particular, we have 105 here, meaning that the maximum points I can get 105. And that's the case because, if we look over there, it is the max of these two incoming values plus the Vi that I get. So either I go to the left and I take that item or I go down and I take that item. So the option here is I went to the left and took-- well, that's going to be tricky to do in time. The claim is that the best answer here is to go here with the 100 and take the 5, because going down corresponds to removing the last item.
4412	If I went to the left, that corresponds to-- sorry-- the first item. If I went to the left, that corresponds to removing the last item, so my options are 10 plus 25, which is 35, versus 100 plus 5. 105 wins, so that's why there's a red edge here showing that was my better choice. And in general, if you follow these parent pointers back, it gives you the optimal strategy in what you should do. First, you should take the 5 is what this is saying, because we just clipped off the 5. We used to start here, and now we start here in this subinterval. Then our opponents, to be annoying, will take the 25-- doesn't actually matter, I think. Then we will take the 100, and then they take the 10, and it's game over. OK, all the numbers here are how many points we get-- doesn't say how many points the opponent gets. Of course, you could add that as well. It's just the total sum minus what we get. Now, let me come back
4413	to high level here.
4414	and this is an idea that we will expand on next lecture. And the idea is that sometimes you start with the obvious subproblems of prefixes, suffixes, or substrings. Here, the obvious version was substrings, because we were moving from both ends. If you don't know, probably suffixes or prefixes are enough. So we start there, but sometimes that's still not enough subproblems. Here, as soon as we made a move, our problem almost turned upside-down, because now it's your turn, instead of my turn. And that was just annoying to deal with, and so we could-- whenever you run into a new type of problem, just build more subproblems. As long as it stays polynomial number, we'll get polynomial time. And so here we doubled the number of subproblems to just the me case and the you case, and that made this recurrence really easy to write. In the notes, you'll see a messier way to write it, if you don't do that. In the examples we'll see next lecture, we're going to do a lot more expansion, maybe
4415	multiplying the number of problems by n or n squared. And this will give us-- it will let us add more constraints to our subproblems, like we did in longest increasing subsequence. We added this constraint that we start with a particular item. The more subproblems we have, we can consider more constraints, because we'll just brute force all the possible constraints that could apply. Well, we'll see more of that next time. That's it for today.
